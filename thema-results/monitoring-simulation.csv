"University","Title","Abstract","Relevance Score","Publication URL","Coordinates"
"""Brunel_University_London""","""PACKET TRANSPORT ON SCALE-FREE NETWORKS | Advances in Complex Systems , Vol 05, No 04 | World Scientific""","""Advances in Complex Systems\nPACKET TRANSPORT ON SCALE-FREE NETWORKS\nBOSILJKA TADIĆ\nJozef Stefan Institute, P.O. Box 3000,  1001 Ljubljana, Slovenia\nG. J. RODGERS\nDepartment of Mathematical Sciences,  Brunel University, Uxbridge, Middlesex UB8 3PH, UK\nReceived: 8 July 2002\nRevised: 27 September 2002\nWe introduce a model of information packet transport on networks in which the packets are posted by a given rate and move in parallel according to a local search algorithm. By performing a number of simulations we investigate the major kinetic properties of the transport as a function of the network geometry, the packet input rate and the buffer size. We find long-range correlations in the power spectra of arriving packet density and the network's activity bursts. The packet transit time distribution shows a power-law dependence with average transit time increasing with network size. This implies dynamic queuing on the network, in which many interacting queues are mutually driven by temporally correlated packet streams.\nKeywords: Internet; traffic; information packet\nPACS: 02.50.cw, 05.40.-a, 89.75Hc\nCited by (38):\nDávid Csercsik , Sándor Imre .  (2017) Cooperation and coalitional stability in decentralized wireless networks. Telecommunication Systems 64:4, 571-584.  Online publication date: 1-Apr-2017. [Crossref]\nYusuke Sakumoto , Hiroyuki Ohsaki .  (2016) Fluid-Based Analysis for Understanding TCP Performance on Scale-Free Structure. Journal of Information Processing 24:4, 660-668.  Online publication date: 1-Jan-2016. [Crossref]\nS. Boccaletti , G. Bianconi , R. Criado , C.I. del Genio , J. Gómez-Gardeñes , M. Romance , I. Sendiña-Nadal , Z. Wang , M. Zanin .  (2014) The structure and dynamics of multilayer networks. Physics Reports 544:1, 1-122.  Online publication date: 1-Nov-2014. [Crossref]\nDavid Lancaster .  (2014) Random walks between leaves of random networks. Physica A: Statistical Mechanics and its Applications 395, 511-522.  Online publication date: 1-Feb-2014. [Crossref]\nAgnieszka Czaplicka , Janusz A. Hołyst , Peter M. A. Sloot .  (2013) Stochastic resonance for information flows on hierarchical networks. The European Physical Journal Special Topics 222:6, 1335-1345.  Online publication date: 1-Sep-2013. [Crossref]\nJ.-Q. Dong , Z.-G. Huang , Z. Zhou , L. Huang , Z.-X. Wu , Y. Do , Y.-H. Wang .  (2012) Enhancing transport efficiency by hybrid routing strategy. EPL (Europhysics Letters) 99:2, 20007.  Online publication date: 1-Jul-2012. [Crossref]\nArnau Gavalda , Jordi Duch , Jesús Gómez-Gardeñes .  (2012) Reciprocal interactions out of congestion-free adaptive networks. Physical Review E 85:2.  Online publication date: 1-Feb-2012. [Crossref]\nTamara Mihaljev , Lucilla de Arcangelis , Hans J. Herrmann .  (2011) Interarrival times of message propagation on directed networks. Physical Review E 84:2.  Online publication date: 1-Aug-2011. [Crossref]\nYusuke Sakumoto , Hiroyuki Ohsaki , Makoto Imase .  (2011) Fluid-Based Analysis of TCP Flows in a Scale-Free Network. 2011 IEEE/IPSJ International Symposium on Applications and the Internet, 37-43. [Crossref]\nGuo-Qing Zhang , Shi Zhou , Di Wang , Gang Yan , Guo-Qiang Zhang .  (2011) Enhancing network transmission capacity by efficiently allocating node capability. Physica A: Statistical Mechanics and its Applications 390:2, 387-391.  Online publication date: 1-Jan-2011. [Crossref]\nSandro Meloni , Jesús Gómez-Gardeñes .  (2010) Local empathy provides global minimization of congestion in communication networks. Physical Review E 82:5.  Online publication date: 1-Nov-2010. [Crossref]\nMahashweta Basu , P K Mohanty .  (2010) Asymmetric simple exclusion process on a Cayley tree. Journal of Statistical Mechanics: Theory and Experiment 2010:10, P10014.  Online publication date: 1-Oct-2010. [Crossref]\nMing Tang , Zonghua Liu , Xiaoming Liang , P. M. Hui .  (2009) Self-adjusting routing schemes for time-varying traffic in scale-free networks. Physical Review E 80:2.  Online publication date: 1-Aug-2009. [Crossref]\nAgata Fronczak , Piotr Fronczak .  (2009) Biased random walks in complex networks: The role of local navigation rules. Physical Review E 80:1.  Online publication date: 1-Jul-2009. [Crossref]\nJinyong Huang , Yankuan Feng , Sandi Zhang .  (2009) Research of complex system theory application on reliability analysis of network system. 2009 8th International Conference on Reliability, Maintainability and Safety, 1141-1145. [Crossref]\nLuciano da Fontoura Costa .  (2009) Systems Biology through complex networks, signal processing, image analysis, and artificial intelligence. 2009 16th International Conference on Digital Signal Processing, 1-8. [Crossref]\nZhang Zhi , Fu Zhong-Qian , Yan Gang .  (2009) Synchronization speed of identical oscillators on community networks. Chinese Physics B 18:6, 2209-2212.  Online publication date: 1-Jun-2009. [Crossref]\nXiang Ling , Rui Jiang , Xiong Wang , Mao-Bin Hu , Qing-Song Wu .  (2008) Traffic of packets with non-homogeneously selected destinations in scale-free network. Physica A: Statistical Mechanics and its Applications 387:18, 4709-4715.  Online publication date: 1-Jul-2008. [Crossref]\nBosiljka Tadić , Zoran Levnajić .  (2008) Robust dynamical effects in traffic and chaotic maps on trees. Pramana 70:6, 1099-1108.  Online publication date: 1-Jun-2008. [Crossref]\nSatyam Mukherjee , Neelima Gupte .  (2008) Message transfer in a communication network. Pramana 70:6, 1109-1116.  Online publication date: 1-Jun-2008. [Crossref]\nG. Yan , Z. -Q. Fu , G. Chen .  (2008) Consensus on de Bruijn graphs. The European Physical Journal B 63:4, 515-520.  Online publication date: 1-Jun-2008. [Crossref]\nSatyam Mukherjee , Neelima Gupte .  (2008) Gradient mechanism in a communication network. Physical Review E 77:3.  Online publication date: 1-Mar-2008. [Crossref]\nZhi-Xi Wu , Wen-Xu Wang , Kai-Hau Yeung .  (2008) Traffic dynamics in scale-free networks with limited buffers and decongestion strategy. New Journal of Physics 10:2, 023025.  Online publication date: 1-Feb-2008. [Crossref]\nMao-Bin Hu , Wen-Xu Wang , Rui Jiang , Qing-Song Wu , Yong-Hong Wu .  (2007) The effect of bandwidth in scale-free network traffic. Europhysics Letters (EPL) 79:1, 14003.  Online publication date: 1-Jul-2007. [Crossref]\nGuo-Qing Zhang , Di Wang , Guo-Jie Li .  (2007) Enhancing the transmission efficiency by edge deletion in scale-free networks. Physical Review E 76:1.  Online publication date: 1-Jul-2007. [Crossref]\nShi-Min Cai , Gang Yan , Tao Zhou , Pei-Ling Zhou , Zhong-Qian Fu , Bing-Hong Wang .  (2007) Scaling behavior of an artificial traffic model on scale-free networks. Physics Letters A 366:1-2, 14-19.  Online publication date: 1-Jun-2007. [Crossref]\nBernard Kujawski , Bosiljka Tadić , G J Rodgers .  (2007) Preferential behaviour and scaling in diffusive dynamics on networks. New Journal of Physics 9:5, 154-154.  Online publication date: 1-May-2007. [Crossref]\nS. Carmi , Z. Wu , E. López , S. Havlin , H. Eugene Stanley .  (2007) Transport between multiple users in complex networks. The European Physical Journal B 57:2, 165-174.  Online publication date: 1-May-2007. [Crossref]\nHiroyuki Ohsaki , Koutaro Yagi , Makoto Imase .  (2007) On the Effect of Scale-Free Structure of Network Topology on End-to-End Performance. 2007 International Symposium on Applications and the Internet, 12-12. [Crossref]\n""","0.43869734","""http://www.worldscientific.com/doi/abs/10.1142/S021952590200064X""","[-0.472855,51.532848]"
"""UCL""","""Iris Publication""","""http://discovery.ucl.ac.uk/1368086/\nAbstract\nA study is presented of the rates of penetration of different transport technologies under policy constraints on CO 2  emissions. The response of this sector is analyzed within an overall national level of restriction, with a focus on automobiles, light trucks, and heavy freight trucks. Using the US as an example, a linked set of three models is used to carry out the analysis: a multi-sector computable general equilibrium model of the economy, a MARKAL-type model of vehicle and fuel supply technology, and a model simulating the split of personal and freight transport among modes. Results highlight the importance of incremental improvements in conventional internal combustion engine technology, and, in the absence of policies to overcome observed consumer discount rates, the very long time horizons before radical alternatives like the internal combustion engine hybrid drive train vehicle are likely to take substantial market share. © 2004 Elsevier Ltd. All rights reserved.\nPublication data is maintained in RPS. Visit https://rps.ucl.ac.uk\n› More search options\n""","0.77357924","""http://iris.ucl.ac.uk/iris/publication/781022/7""",
"""Aston_University""","""Taking the carbon out of the car - Research Explorer : Aston University""","""Taking the carbon out of the car\nResearch output: Contribution to journal › Article\nJulia King ORCiD: http://orcid.org/0000-0002-8563-7646\nAbstract\nEffective measures are being taken to reduce emissions from cars, which are now emerging as a major contributor to climate change. Developed countries will need to reduce emissions by at least 80% by 2050 to achieve stabilization of atmospheric CO2 concentration between 450 and 550 ppm, and have a unique opportunity to avoid the most damaging effects of climate change. The UK is aiming at completely decarbonising transport by 2050 through a combination of more efficient vehicles, cleaner fuels, and smart driving choices. The European Commission has proposed a mandatory CO2 target on new car CO 2 efficiency, which is an urgent needed development. The nation is also using regulatory targets for local schemes, such as free parking or congestion charging, break points for company car tax, and vehicle excise duty. Car ownership and use should thereby continue to drive economic growth and enhance quality of life around the world without destroying the planet.\nDetails\n""","0.5905953","""https://research.aston.ac.uk/portal/en/researchoutput/taking-the-carbon-out-of-the-car(e1096051-23a9-48d4-9a13-6cf1879ba813).html""","[-1.888803,52.487018]"
"""University_of_Lancaster""","""Source-oriented risk assessment of inhalation exposure to ambient polycyclic aromatic hydrocarbons and contributions of non-priority isomers in urban Nanjing, a megacity located in Yangtze River Delta, China - Research Portal | Lancaster University""","""Source-oriented risk assessment of inhalation exposure to ambient polycyclic aromatic hydrocarbons and contributions of non-priority isomers in urban Nanjing, a megacity located in Yangtze River Delta, China\nResearch output: Contribution to journal › Journal article\nPublished\n<mark>Journal publication date</mark>\n05/2017\nEnglish\nAbstract\nSixteen U.S. EPA priority polycyclic aromatic hydrocarbons (PAHs) and eleven non-priority isomers including some dibenzopyrenes were analyzed to evaluate health risk attributable to inhalation exposure to ambient PAHs and contributions of the non-priority PAHs in a megacity Nanjing, east China. The annual average mass concentration of the total 16 EPA priority PAHs in air was 51.1 ± 29.8 ng/m3, comprising up to 93% of the mass concentration of all 27 PAHs, however, the estimated Incremental Lifetime Cancer Risk (ILCR) due to inhalation exposure would be underestimated by 63% on average if only accounting the 16 EPA priority PAHs. The risk would be underestimated by 13% if only particulate PAHs were considered, though gaseous PAHs made up to about 70% of the total mass concentration. During the last fifteen years, ambient Benzo[a]pyrene decreased significantly in the city which was consistent with the declining trend of PAHs emissions. Source contributions to the estimated ILCR were much different from the contributions for the total mass concentration, calling for the introduce of important source-oriented risk assessments. Emissions from gasoline vehicles contributed to 12% of the total mass concentration of 27 PAHs analyzed, but regarding relative contributions to the overall health risk, gasoline vehicle emissions contributed 45% of the calculated ILCR. Dibenzopyrenes were a group of non-priority isomers largely contributing to the calculated ILCR, and vehicle emissions were probably important sources of these high molecular weight isomers. Ambient dibenzo[a,l]pyrene positively correlated with the priority PAH Benzo[g,h,i]perylene. The study indicates that inclusion of non-priority PAHs could be valuable for both PAH source apportionment and health risk assessment.\nRelated projects\nLancaster University Bailrigg Lancaster United Kingdom LA1 4YW\n+44 (0)1524 65201\n""","0.70968103","""http://www.research.lancs.ac.uk/portal/en/publications/sourceoriented-risk-assessment-of-inhalation-exposure-to-ambient-polycyclic-aromatic-hydrocarbons-and-contributions-of-nonpriority-isomers-in-urban-nanjing-a-megacity-located-in-yangtze-river-delta-china(069adafc-4f08-4e87-bd65-806dcf3741d8).html""","[-2.787729,54.010394]"
"""Cranfield_University""","""Modelling and simulation of a fuel cell powered electric drivetrain for wide body passenger aircraftProceedings of the Institution of Mechanical Engineers, Part G: Journal of Aerospace Engineering - R Felix Moreno, JT Economou, D Bray, K Knowles, 2013""","""Night Noise Fact Sheet, BAA Heathrow. Google Scholar\n3.\nMorrell P and Lu Chen Y. Aircraft noise social cost and charge mechanisms ± a case study of Amsterdam Airport Schiphol. Transportation Research Part D 5., 2000, pp.305–320. Google Scholar\n4.\nControl of ground noise and emissions at Heathrow. Operational Safety Instruction, BAA Heathrow, 12 January 2011. Google Scholar\n5.\nInternational Civil Aviation Organization. Focus on: Environment, Quebec, Canada: ICAO, 2010. Google Scholar\n6.\nAircraft emission charges Zurich Airport. Flughafen Zürich AG, Environmental Services, July 2000. Google Scholar\n7.\nJoint demonstration of new electric taxi system. Corporate Communications, Lufthansa Technik AG, Hamburg, Germany, 8 December 2011. Google Scholar\n8.\nSpiegel, C. PEM fuel cell modeling and simulation using Matlab, London: Academic Press, 2008. Google Scholar\n9.\nGou, B, Woon, KN, Diong, B. Fuel cells: modeling, control, and applications, Boca Raton: CRC Press, 2010. Google Scholar\n10.\nKrishnan, R. Permanent magnet synchronous and brushless DC motor drives, Boca Raton: CRC Press, 2010. Google Scholar\n11.\nGenta, G. Motor vehicle dynamics, Singapore: World Scientific Publishing, 1997. Google Scholar , Crossref\n12.\nAdams J, Woong-Chui AY, Oglesby KA, et al. The development of Ford’s P2000 fuel cell vehicle. SAE Paper 2000-01-1061, 2000. Google Scholar\n13.\nGao L, Jiang Z and Dougal RA. Evaluation of active hybrid fuel cell/battery power sources. IEEE Trans Aerosp Electron Syst 2005; 41(1): 346–355. Google Scholar\n14.\nGarcia P, Torreglosa JP, Fernández LM, et al. Viability study of a FC-battery-SC tramway controlled by equivalent consumption minimization strategy. Int J Hydrogen Energy 2012; 37(11): 9368–9382. Google Scholar\n15.\nHoneywell APU reliability exceeds 10,000 hours. Press Release. Honeywell Aerospace Media Center, 15 June 2009. Google Scholar\n16.\nMark 1100 product data sheet. Ballard Power Systems Inc., Burnaby British Columbia, Canada, 2006. Google Scholar\n17.\nFCvelocity-HD6 product data sheet. Ballard Power Systems Inc., Burnaby British Columbia, Canada. 2011. Google Scholar\n18.\nAIAA. Aerospace America. Beyond the more electric aircraft, Reston, VA: American Institute of Aeronautics and Astronautics, 2005. Google Scholar\n""","0.5108637","""http://journals.sagepub.com/doi/10.1177/0954410012473389""","[-0.629225,52.074389]"
"""Cranfield_University""","""Comparative Analysis of Multiple Powertrain Architectures based on a Novel Optimization Framework""","""Comparative Analysis of Multiple Powertrain Architectures based on a Novel Optimization Framework\nPaper #:\nhttps://doi.org/10.4271/2014-01-1105\nCitation:\nMohan, G., Assadian, F., and Longo, S., \""Comparative Analysis of Multiple Powertrain Architectures based on a Novel Optimization Framework,\"" SAE Technical Paper 2014-01-1105, 2014, https://doi.org/10.4271/2014-01-1105 .\n12\nAbstract:\nIdentifying the most appropriate powertrain technology for a given vehicle class and duty cycle can be beneficial to further drive down on carbon emissions. However, with a myriad of powertrain architectures that are emerging in the industry, such as those in Electric Vehicles and Hybrid Vehicles, it becomes more challenging to carry out comprehensive comparative analyses across different permutations of powertrain topologies.This has motivated the authors to research on improving the method used to compare different types of powertrain architectures, and develop a tool that can be used by practitioners for this purpose. Literature survey has indicated that whilst there have been many comparisons made between different types of powertrains, such analyses were often carried out by comparing only limited types of architectures at a time. Additionally, many commercially available tools lack the combination of an optimization algorithm with the ability to simulate different combinations of powertrain architectures concurrently to provide a meaningful comparison.In this paper, a new approach is proposed that simultaneously optimizes powertrain architecture selection and component sizing. Results from this investigation have indicated that such analysis is indeed possible, and this was demonstrated by way of identifying the “transition point” between powertrain architectures. The investigation included the use of a multi-objective optimization with a novel powertrain framework. The capabilities of this framework potentially opens a way for vehicle manufacturers to quantify the benefits that can be achieved from each type of powertrain architecture, and help accelerate the implementation of alternative powertrain technology.\nEvent:\n""","0.67664415","""http://papers.sae.org/2014-01-1105/""","[-0.629225,52.074389]"
"""Imperial_College_London""","""CONTINUUM LIMIT OF SELF-DRIVEN PARTICLES WITH ORIENTATION INTERACTION | Mathematical Models and Methods in Applied Sciences , Vol 18, No supp01 | World Scientific""","""Mathematical Models and Methods in Applied Sciences\nCONTINUUM LIMIT OF SELF-DRIVEN PARTICLES WITH ORIENTATION INTERACTION\nPIERRE DEGOND\nInstitute of Mathematics of Toulouse UMR 5219, (CNRS-UPS-INSA-UT1-UT2), Université Paul Sabatier, 118, Route de Narbonne, 31062 Toulouse Cedex, France\nSÉBASTIEN MOTSCH\nInstitute of Mathematics of Toulouse UMR 5219, (CNRS-UPS-INSA-UT1-UT2), Université Paul Sabatier, 118, Route de Narbonne, 31062 Toulouse Cedex, France\nReceived: 25 September 2007\nThe discrete Couzin–Vicsek algorithm (CVA), which describes the interactions of individuals among animal societies such as fish schools is considered. In this paper, a kinetic (mean-field) version of the CVA model is proposed and its formal macroscopic limit is provided. The final macroscopic model involves a conservation equation for the density of the individuals and a non-conservative equation for the director of the mean velocity and is proved to be hyperbolic. The derivation is based on the introduction of a non-conventional concept of a collisional invariant of a collision operator.\nKeywords: Individual based model; fish behavior; Couzin–Vicsek algorithm; asymptotic analysis; orientation interaction; hydrodynamic limit; collision invariants\nAMSC: 35Q80, 35L60, 82C22, 82C70, 92D50\nCited by (135):\nAlessio Figalli , Moon-Jin Kang , Javier Morales .  (2018) Global Well-posedness of the Spatially Homogeneous Kolmogorov–Vicsek Model as a Gradient Flow. Archive for Rational Mechanics and Analysis 227:3, 869-896.  Online publication date: 1-Mar-2018. [Crossref]\nMartin Burger , Bertram Düring , Lisa Maria Kreusser , Peter A. Markowich , Carola-Bibiane Schönlieb .  (2018) Pattern formation of a nonlocal, anisotropic interaction model. Mathematical Models and Methods in Applied Sciences 28:03, 409-451.  Online publication date: 1-Mar-2018. [ Abstract | PDF (1179 KB) | PDF Plus (1182 KB) ]\nPiotr B. Mucha , Jan Peszek .  (2018) The Cucker–Smale Equation: Singular Communication Weight, Measure-Valued Solutions and Weak-Atomic Uniqueness. Archive for Rational Mechanics and Analysis 227:1, 273-308.  Online publication date: 1-Jan-2018. [Crossref]\nSara Bernardi , Annachiara Colombi , Marco Scianna .  (2018) A discrete particle model reproducing collective dynamics of a bee swarm. Computers in Biology and Medicine.  Online publication date: 1-Jan-2018. [Crossref]\nPierre Degond , Amic Frouvelle , Sara Merino-Aceituno , Ariane Trescases .  (2018) Quaternions in Collective Dynamics. Multiscale Modeling & Simulation 16:1, 28-77.  Online publication date: 1-Jan-2018. [Crossref]\nJ. Barré , C. Bernardin , R. Chetrite .  (2017) Density Large Deviations for Multidimensional Stochastic Hyperbolic Conservation Laws. Journal of Statistical Physics 57.  Online publication date: 7-Dec-2017. [Crossref]\nAdrien Blanchet , Pierre Degond .  (2017) Kinetic Models for Topological Nearest-Neighbor Interactions. Journal of Statistical Physics 169:5, 929-950.  Online publication date: 1-Dec-2017. [Crossref]\nMihai Bostan , Jose Antonio Carrillo .  (2017) Reduced fluid models for self-propelled particles interacting through alignment. Mathematical Models and Methods in Applied Sciences 27:07, 1255-1299.  Online publication date: 30-Jun-2017. [ Abstract | PDF (537 KB) | PDF Plus (595 KB) ]\nDavid Poyato , Juan Soler .  (2017) Euler-type equations and commutators in singular and hyperbolic limits of kinetic Cucker–Smale models. Mathematical Models and Methods in Applied Sciences 27:06, 1089-1152.  Online publication date: 15-Jun-2017. [ Abstract | PDF (672 KB) | PDF Plus (727 KB) ]\nL. Müller , A. Meurer , F. Schneider , A. Klar .  (2017) A numerical investigation of flux-limited approximations for pedestrian dynamics. Mathematical Models and Methods in Applied Sciences 27:06, 1177-1197.  Online publication date: 15-Jun-2017. [ Abstract | PDF (1279 KB) | PDF Plus (1323 KB) ]\nNicola Bellomo , Seung-Yeal Ha .  (2017) A quest toward a mathematical theory of the dynamics of swarms. Mathematical Models and Methods in Applied Sciences 27:04, 745-770.  Online publication date: 1-Apr-2017. [ Abstract | PDF (379 KB) | PDF Plus (422 KB) ]\nTeng-Fei Zhang , Ning Jiang .  (2017) A local existence of viscous self-organized hydrodynamic model. Nonlinear Analysis: Real World Applications 34, 495-506.  Online publication date: 1-Apr-2017. [Crossref]\nDieter Armbruster , Sébastien Motsch , Andrea Thatcher .  (2017) Swarming in bounded domains. Physica D: Nonlinear Phenomena 344, 58-67.  Online publication date: 1-Apr-2017. [Crossref]\nPierre Degond , Angelika Manhart , Hui Yu .  (2017) A continuum model for nematic alignment of self-propelled particles. Discrete and Continuous Dynamical Systems - Series B 22:4, 1295-1327.  Online publication date: 1-Feb-2017. [Crossref]\nAlesandro Arcuri , Nicolas Lanchier .  (2017) Stochastic spatial model for the division of labor in social insects. Mathematical Models and Methods in Applied Sciences 27:01, 45-73.  Online publication date: 1-Jan-2017. [ Abstract | PDF (391 KB) | PDF Plus (438 KB) ]\nAylin Aydoğdu , Marco Caponigro , Sean McQuade , Benedetto Piccoli , Nastassia Pouradier Duteil , Francesco Rossi , Emmanuel Trélat . 2017. Interaction Network, State Space, and Control in Social Dynamics. Active Particles, Volume 1, 99-140. [Crossref]\nSeung-Yeal Ha , Dongnam Ko , Yinglong Zhang , Xiongtao Zhang .  (2016) Emergent dynamics in the interactions of Cucker-Smale ensembles. Kinetic and Related Models 10:3, 689-723.  Online publication date: 1-Dec-2016. [Crossref]\nAlex Mogilner , Angelika Manhart , David G. Drubin .  (2016) Agent-based modeling: case study in cleavage furrow models. Molecular Biology of the Cell 27:22, 3379-3384.  Online publication date: 7-Nov-2016. [Crossref]\nPierre Degond , Silke Henkes , Hui Yu .  (2016) Self-organized hydrodynamics with density-dependent velocity. Kinetic and Related Models 10:1, 193-213.  Online publication date: 1-Nov-2016. [Crossref]\nJunghee Cho , Seung-Yeal Ha , Feimin Huang , Chunyin Jin , Dongnam Ko .  (2016) Emergence of bi-cluster flocking for agent-based models with unit speed constraint. Analysis and Applications 14:01, 39-73.  Online publication date: 1-Jan-2016. [ Abstract | PDF (1472 KB) | PDF Plus (1500 KB) ]\nMihai Bostan .  (2016) MultiScale Analysis for Linear First Order PDEs. The Finite Larmor Radius Regime. SIAM Journal on Mathematical Analysis 48:3, 2133-2188.  Online publication date: 1-Jan-2016. [Crossref]\nNing Jiang , Linjie Xiong , Teng-Fei Zhang .  (2016) Hydrodynamic Limits of the Kinetic Self-Organized Models. SIAM Journal on Mathematical Analysis 48:5, 3383-3411.  Online publication date: 1-Jan-2016. [Crossref]\nAlethea B. T. Barbaro , José A. Can͂izo , José A. Carrillo , Pierre Degond .  (2016) Phase Transitions in a Kinetic Flocking Model of Cucker--Smale Type. Multiscale Modeling & Simulation 14:3, 1063-1088.  Online publication date: 1-Jan-2016. [Crossref]\nIrene M. Gamba , Moon-Jin Kang .  (2016) Global Weak Solutions for Kolmogorov–Vicsek Type Equations with Orientational Interactions. Archive for Rational Mechanics and Analysis 222:1, 317. [Crossref]\nD. Peurichard .  (2016) Macroscopic Model for Cross-Linked Fibers with Alignment Interactions: Existence Theory and Numerical Simulations. Multiscale Modeling & Simulation 14:4, 1175-1210.  Online publication date: 1-Jan-2016. [Crossref]\nMiguel A. Herrero , Juan Soler .  (2015) Cooperation, competition, organization: The dynamics of interacting living populations. Mathematical Models and Methods in Applied Sciences 25:13, 2407-2415.  Online publication date: 15-Dec-2015. [ Abstract | PDF (157 KB) | PDF Plus (223 KB) ]\nPierre Degond , Laurent Navoret .  (2015) A multi-layer model for self-propelled disks interacting through alignment and volume exclusion. Mathematical Models and Methods in Applied Sciences 25:13, 2439-2475.  Online publication date: 15-Dec-2015. [ Abstract | PDF (873 KB) | PDF Plus (862 KB) ]\nDenis F. Hinz , Alexander Panchenko , Tae-Yeon Kim , Eliot Fried .  (2015) Particle-based simulations of self-motile suspensions. Computer Physics Communications 196, 45-57.  Online publication date: 1-Nov-2015. [Crossref]\nMartin Parisot , Mirosław Lachowicz .  (2015) A kinetic model for the formation of swarms with nonlinear interactions. Kinetic and Related Models 9:1, 131-164.  Online publication date: 1-Oct-2015. [Crossref]\nIrene M. Gamba , Jeffrey R. Haack , Sebastien Motsch .  (2015) Spectral method for a kinetic swarming model. Journal of Computational Physics 297, 32-46.  Online publication date: 1-Sep-2015. [Crossref]\nThi-Bich-Ngoc Mac .  (2015) Existence of solution for a system of repulsion and alignment: Comparison between theory and simulation. Discrete and Continuous Dynamical Systems - Series B 20:9, 3013-3027.  Online publication date: 1-Sep-2015. [Crossref]\nMichael Herty , Lorenzo Pareschi , Sonja Steffensen .  (2015) Mean--field control and Riccati equations. Networks and Heterogeneous Media 10:3, 699-715.  Online publication date: 1-Jul-2015. [Crossref]\nEric Carlen , Maria C Carvalho , Pierre Degond , Bernt Wennberg .  (2015) A Boltzmann model for rod alignment and schooling fish. Nonlinearity 28:6, 1783-1803.  Online publication date: 1-Jun-2015. [Crossref]\nPierre Degond , Amic Frouvelle , Jian-Guo Liu .  (2015) Phase Transitions, Hysteresis, and Hyperbolicity for Self-Organized Alignment Dynamics. Archive for Rational Mechanics and Analysis 216:1, 63-115.  Online publication date: 1-Apr-2015. [Crossref]\nPierre Degond , Hui Yu .  (2015) Self-organized hydrodynamics in an annular domain: Modal analysis and nonlinear effects. Mathematical Models and Methods in Applied Sciences 25:03, 495-519.  Online publication date: 1-Mar-2015. [ Abstract | PDF (2216 KB) | PDF Plus (2248 KB) ]\nL. Michailidis , M. Herty , M. Ziegler .  (2015) Kinetic part-feeding models for assembly lines in automotive industries. Mathematical Models and Methods in Applied Sciences 25:02, 283-308.  Online publication date: 1-Feb-2015. [ Abstract | PDF (1566 KB) | PDF Plus (495 KB) ]\nSeung-Yeal Ha , Jinyeong Park , Sang Woo Ryoo .  (2015) Emergence of phase-locked states for the Winfree model in a large coupling regime. Discrete and Continuous Dynamical Systems 35:8, 3417-3436.  Online publication date: 1-Feb-2015. [Crossref]\nGil Ariel , Oren Rimer , Eshel Ben-Jacob .  (2015) Order–Disorder Phase Transition in Heterogeneous Populations of Self-propelled Particles. Journal of Statistical Physics 158:3, 579-588.  Online publication date: 1-Feb-2015. [Crossref]\nJulien Barré , Raphaël Chétrite , Massimiliano Muratori , Fernando Peruani .  (2015) Motility-Induced Phase Separation of Active Particles in the Presence of Velocity Alignment. Journal of Statistical Physics 158:3, 589-600.  Online publication date: 1-Feb-2015. [Crossref]\nTrygve K. Karper , Antoine Mellet , Konstantina Trivisa .  (2015) Hydrodynamic limit of the kinetic Cucker–Smale flocking model. Mathematical Models and Methods in Applied Sciences 25:01, 131-163.  Online publication date: 1-Jan-2015. [ Abstract | PDF (403 KB) | PDF Plus (426 KB) ]\nJan Peszek .  (2015) Discrete Cucker--Smale Flocking Model with a Weakly Singular Weight. SIAM Journal on Mathematical Analysis 47:5, 3671-3686.  Online publication date: 1-Jan-2015. [Crossref]\nBenedetto Piccoli , Francesco Rossi , Emmanuel Trélat .  (2015) Control to Flocking of the Kinetic Cucker--Smale Model. SIAM Journal on Mathematical Analysis 47:6, 4685-4719.  Online publication date: 1-Jan-2015. [Crossref]\nOleksandr Chepizhko , Vladimir Kulinskii .  (2014) The hydrodynamic description for the system of self-propelled particles: Ideal Viscek fluid. Physica A: Statistical Mechanics and its Applications 415, 493-502.  Online publication date: 1-Dec-2014. [Crossref]\nA. Roth , A. Klar , B. Simeon , E. Zharovsky .  (2014) A Semi-Lagrangian Method for 3-D Fokker Planck Equations for Stochastic Dynamical Systems on the Sphere. Journal of Scientific Computing 61:3, 513-532.  Online publication date: 1-Dec-2014. [Crossref]\nR. Etikyala , S. Göttlich , A. Klar , S. Tiwari .  (2014) Particle methods for pedestrian flow models: From microscopic to nonlocal continuum models. Mathematical Models and Methods in Applied Sciences 24:12, 2503-2523.  Online publication date: 1-Nov-2014. [ Abstract | PDF (1642 KB) | PDF Plus (780 KB) ]\nM. Burger , L. Caffarelli , P. A. Markowich .  (2014) Partial differential equation models in the socio-economic sciences. Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences 372:2028, 20130406-20130406.  Online publication date: 6-Oct-2014. [Crossref]\nP. Degond , J.-G. Liu , C. Ringhofer .  (2014) Evolution of wealth in a non-conservative economy driven by local Nash equilibria. Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences 372:2028, 20130394-20130394.  Online publication date: 6-Oct-2014. [Crossref]\nSeung-Yeal Ha , Moon-Jin Kang , Bongsuk Kwon .  (2014) A hydrodynamic model for the interaction of Cucker–Smale particles and incompressible fluid. Mathematical Models and Methods in Applied Sciences 24:11, 2311-2359.  Online publication date: 1-Oct-2014. [ Abstract | PDF (557 KB) | PDF Plus (591 KB) ]\nPierre Degond , Amic Frouvelle , Gaël Raoul .  (2014) Local Stability of Perfect Alignment for a Spatially Homogeneous Kinetic Model. Journal of Statistical Physics 157:1, 84-112.  Online publication date: 1-Oct-2014. [Crossref]\nJan Peszek .  (2014) Existence of piecewise weak solutions of a discrete Cucker–Smale's flocking model with a singular communication weight. Journal of Differential Equations 257:8, 2900-2925.  Online publication date: 1-Oct-2014. [Crossref]\nD J G Pearce , M S Turner .  (2014) Density regulation in strictly metric-free swarms. New Journal of Physics 16:8, 082002.  Online publication date: 1-Aug-2014. [Crossref]\nAxel Klar , Florian Schneider , Oliver Tse .  (2014) Approximate models for stochastic dynamic systems with velocities on the sphere and associated Fokker--Planck equations. Kinetic and Related Models 7:3, 509-529.  Online publication date: 1-Jul-2014. [Crossref]\nMichele Gianfelice , Enza Orlandi .  (2014) Dynamics and kinetic limit for a system of noiseless $d$-dimensional Vicsek-type particles. Networks and Heterogeneous Media 9:2, 269-297.  Online publication date: 1-Jul-2014. [Crossref]\nZhuchun Li , Seung-Yeal Ha , Xiaoping Xue .  (2014) Emergent phenomena in an ensemble of Cucker–Smale particles under joint rooted leadership. Mathematical Models and Methods in Applied Sciences 24:07, 1389-1419.  Online publication date: 30-Jun-2014. [ Abstract | PDF (481 KB) | PDF Plus (462 KB) ]\nJ.A. Carrillo , Y. Huang , S. Martin .  (2014) Nonlinear stability of flock solutions in second-order swarming models. Nonlinear Analysis: Real World Applications 17, 332-343.  Online publication date: 1-Jun-2014. [Crossref]\nAlethea B. T. Barbaro , Pierre Degond .  (2014) Phase transition and diffusion among socially interacting self-propelled agents. Discrete and Continuous Dynamical Systems - Series B 19:5, 1249-1278.  Online publication date: 1-Apr-2014. [Crossref]\nRong Yang , Li Chen .  (2014) Mean-field limit for a collision-avoiding flocking system and the time-asymptotic flocking dynamics for the kinetic equation. Kinetic and Related Models 7:2, 381-400.  Online publication date: 1-Mar-2014. [Crossref]\nPIERRE DEGOND , GIACOMO DIMARCO , THI BICH NGOC MAC .  (2014) HYDRODYNAMICS OF THE KURAMOTO–VICSEK MODEL OF ROTATING SELF-PROPELLED PARTICLES. Mathematical Models and Methods in Applied Sciences 24:02, 277-325.  Online publication date: 1-Feb-2014. [ Abstract | PDF (1046 KB) | PDF Plus (1097 KB) ]\nPierre Degond , Jian-Guo Liu , Christian Ringhofer .  (2014) Large-Scale Dynamics of Mean-Field Games Driven by Local Nash Equilibria. Journal of Nonlinear Science 24:1, 93-115.  Online publication date: 1-Feb-2014. [Crossref]\nG. Albi , D. Balagué , J. A. Carrillo , J. von Brecht .  (2014) Stability Analysis of Flock and Mill Rings for Second Order Models in Swarming. SIAM Journal on Applied Mathematics 74:3, 794-818.  Online publication date: 1-Jan-2014. [Crossref]\nSebastien Motsch , Eitan Tadmor .  (2014) Heterophilious Dynamics Enhances Consensus. SIAM Review 56:4, 577-621.  Online publication date: 1-Jan-2014. [Crossref]\nA. Klar , S. Tiwari .  (2014) A Multiscale Meshfree Method for Macroscopic Approximations of Interacting Particle Systems. Multiscale Modeling & Simulation 12:3, 1167-1192.  Online publication date: 1-Jan-2014. [Crossref]\nQunhui Han , Pak-Wing Fok .  (2014) Reconstructing the Transition Rate Function of a Broadwell Random Walk from Exit Times. SIAM Journal on Applied Mathematics 74:3, 676-696.  Online publication date: 1-Jan-2014. [Crossref]\nMIHAI BOSTAN , JOSE ANTONIO CARRILLO .  (2013) ASYMPTOTIC FIXED-SPEED REDUCED DYNAMICS FOR KINETIC EQUATIONS IN SWARMING. Mathematical Models and Methods in Applied Sciences 23:13, 2353-2393.  Online publication date: 1-Dec-2013. [ Abstract | PDF (487 KB) | PDF Plus (521 KB) ]\nR. C. Fetecau , J. Meskas .  (2013) A nonlocal kinetic model for predator–prey interactions. Swarm Intelligence 7:4, 279-305.  Online publication date: 1-Dec-2013. [Crossref]\nFrancesco Vecil , Pauline Lafitte , Jesús Rosado Linares .  (2013) A numerical study of attraction/repulsion collective behavior models: 3D particle analyses and 1D kinetic simulations. Physica D: Nonlinear Phenomena 260, 127-144.  Online publication date: 1-Oct-2013. [Crossref]\nE. Carlen , R. Chatelin , P. Degond , B. Wennberg .  (2013) Kinetic hierarchy and propagation of chaos in biological swarm models. Physica D: Nonlinear Phenomena 260, 90-111.  Online publication date: 1-Oct-2013. [Crossref]\nTheodore Kolokolnikov , José A. Carrillo , Andrea Bertozzi , Razvan Fetecau , Mark Lewis .  (2013) Emergent behaviour in multi-particle systems with non-local interactions. Physica D: Nonlinear Phenomena 260, 1-4.  Online publication date: 1-Oct-2013. [Crossref]\nJ.A. Carrillo , S. Martin , V. Panferov .  (2013) A new interaction potential for swarming models. Physica D: Nonlinear Phenomena 260, 112-126.  Online publication date: 1-Oct-2013. [Crossref]\nAmanda Galante , Doron Levy .  (2013) Modeling selective local interactions with memory. Physica D: Nonlinear Phenomena 260, 176-190.  Online publication date: 1-Oct-2013. [Crossref]\nERIC CARLEN , PIERRE DEGOND , BERNT WENNBERG .  (2013) KINETIC LIMITS FOR PAIR-INTERACTION DRIVEN MASTER EQUATIONS AND BIOLOGICAL SWARM MODELS. Mathematical Models and Methods in Applied Sciences 23:07, 1339-1376.  Online publication date: 30-Jun-2013. [ Abstract | PDF (469 KB) | PDF Plus (500 KB) ]\nLAURENT NAVORET .  (2013) A TWO-SPECIES HYDRODYNAMIC MODEL OF PARTICLES INTERACTING THROUGH SELF-ALIGNMENT. Mathematical Models and Methods in Applied Sciences 23:06, 1067-1098.  Online publication date: 1-Jun-2013. [ Abstract | PDF (436 KB) | PDF Plus (473 KB) ]\nPierre Degond , Amic Frouvelle , Jian-Guo Liu .  (2013) Macroscopic Limits and Phase Transition in a System of Self-propelled Particles. Journal of Nonlinear Science 23:3, 427-456.  Online publication date: 1-Jun-2013. [Crossref]\nM. Aurangzeb , F. L. Lewis , M. Huber .  (2013) Efficient, swarm-based path finding in unknown graphs using reinforcement learning. 2013 10th IEEE International Conference on Control and Automation (ICCA), 870-877. [Crossref]\nPierre Degond , Jiale Hua .  (2013) Self-organized hydrodynamics with congestion and path formation in crowds. Journal of Computational Physics 237, 299-319.  Online publication date: 1-Mar-2013. [Crossref]\nAmanda Galante , Susanne Wisen , Devaki Bhaya , Doron Levy .  (2012) Modeling local interactions during the motion of cyanobacteria. Journal of Theoretical Biology 309, 147-158.  Online publication date: 1-Sep-2012. [Crossref]\nSEUNG-YEAL HA , MOON-JIN KANG , CORRADO LATTANZIO , BRUNO RUBINO .  (2012) A CLASS OF INTERACTING PARTICLE SYSTEMS ON THE INFINITE CYLINDER WITH FLOCKING PHENOMENA. Mathematical Models and Methods in Applied Sciences 22:07.  Online publication date: 1-Jul-2012. [ Abstract | PDF (422 KB) | PDF Plus (462 KB) ]\nAMIC FROUVELLE .  (2012) A CONTINUUM MODEL FOR ALIGNMENT OF SELF-PROPELLED PARTICLES WITH ANISOTROPY AND DENSITY-DEPENDENT PARAMETERS. Mathematical Models and Methods in Applied Sciences 22:07.  Online publication date: 1-Jul-2012. [ Abstract | PDF (1506 KB) | PDF Plus (575 KB) ]\nAndrew Morozov , Jean-Christophe Poggiale .  (2012) From spatially explicit ecological models to mean-field dynamics: The state of the art and perspectives. Ecological Complexity 10, 1-11.  Online publication date: 1-Jun-2012. [Crossref]\nJAMES H. VON BRECHT , DAVID UMINSKY , THEODORE KOLOKOLNIKOV , ANDREA L. BERTOZZI .  (2012) PREDICTING PATTERN FORMATION IN PARTICLE INTERACTIONS. Mathematical Models and Methods in Applied Sciences 22:supp01.  Online publication date: 1-Apr-2012. [ Abstract | PDF (4998 KB) | PDF Plus (656 KB) ]\nPIERRE DEGOND , JIAN-GUO LIU .  (2012) HYDRODYNAMICS OF SELF-ALIGNMENT INTERACTIONS WITH PRECESSION AND DERIVATION OF THE LANDAU–LIFSCHITZ–GILBERT EQUATION. Mathematical Models and Methods in Applied Sciences 22:supp01.  Online publication date: 1-Apr-2012. [ Abstract | PDF (258 KB) | PDF Plus (280 KB) ]\nN. BELLOMO , J. SOLER .  (2012) ON THE MATHEMATICAL THEORY OF THE DYNAMICS OF SWARMS VIEWED AS COMPLEX SYSTEMS. Mathematical Models and Methods in Applied Sciences 22:supp01.  Online publication date: 1-Apr-2012. [ Abstract | PDF (979 KB) | PDF Plus (553 KB) ]\nFrançois Bolley , José A. Cañizo , José A. Carrillo .  (2012) Mean-field limit for the stochastic Vicsek model. Applied Mathematics Letters 25:3, 339-343.  Online publication date: 1-Mar-2012. [Crossref]\nSeung-Yeal Ha , Sungeun Jung , Marshall Slemrod .  (2012) Fast–slow dynamics of planar particle models for flocking and swarming. Journal of Differential Equations 252:3, 2563-2579.  Online publication date: 1-Feb-2012. [Crossref]\nAmic Frouvelle , Jian-Guo Liu .  (2012) Dynamics in a Kinetic Model of Oriented Particles with Phase Transition. SIAM Journal on Mathematical Analysis 44:2, 791-826.  Online publication date: 1-Jan-2012. [Crossref]\nFRANÇOIS BOLLEY , JOSÉ A. CAÑIZO , JOSÉ A. CARRILLO .  (2011) STOCHASTIC MEAN-FIELD LIMIT: NON-LIPSCHITZ FORCES AND SWARMING. Mathematical Models and Methods in Applied Sciences 21:11, 2179-2210.  Online publication date: 1-Nov-2011. [ Abstract | PDF (436 KB) | PDF Plus (463 KB) ]\nSebastien Motsch , Eitan Tadmor .  (2011) A New Model for Self-organized Dynamics and Its Flocking Behavior. Journal of Statistical Physics 144:5, 923-947.  Online publication date: 1-Sep-2011. [Crossref]\nAbdelghani Bellouquid , Nicola Bellomo .  (2011) On the modeling of crowd dynamics: Looking at the beautiful shapes of swarms. Networks and Heterogeneous Media 6:3, 383-399.  Online publication date: 1-Aug-2011. [Crossref]\nRAZVAN C. FETECAU .  (2011) COLLECTIVE BEHAVIOR OF BIOLOGICAL AGGREGATIONS IN TWO DIMENSIONS: A NONLOCAL KINETIC MODEL. Mathematical Models and Methods in Applied Sciences 21:07, 1539-1569.  Online publication date: 1-Jul-2011. [ Abstract | PDF (427 KB) | PDF Plus (458 KB) ]\nSebastien Motsch , Laurent Navoret .  (2011) Numerical Simulations of a Nonconservative Hyperbolic System with Geometric Constraints Describing Swarming Behavior. Multiscale Modeling & Simulation 9:3, 1253-1275.  Online publication date: 1-Jul-2011. [Crossref]\nPierre Degond , Sébastien Motsch .  (2011) A Macroscopic Model for a System of Swarming Agents Using Curvature Control. Journal of Statistical Physics 143:4, 685-714.  Online publication date: 1-May-2011. [Crossref]\nN. Bellomo , C. Bianca , V. Coscia .  (2011) On the modeling of crowd dynamics: An overview and research perspectives. SeMA Journal 54:1, 25-46.  Online publication date: 1-Apr-2011. [Crossref]\nMartial Agueh , Reinhard Illner , Ashlin Richardson .  (2011) Analysis and simulations of a refined flocking and swarming model of Cucker-Smale type. Kinetic and Related Models 4:1, 1-16.  Online publication date: 1-Jan-2011. [Crossref]\nNicola Bellomo , Christian Dogbe .  (2011) On the Modeling of Traffic and Crowds: A Survey of Models, Speculations, and Perspectives. SIAM Review 53:3, 409-463.  Online publication date: 1-Jan-2011. [Crossref]\nSeung-Yeal Ha , Eunhee Jeong , Moon-Jin Kang .  (2010) Emergent behaviour of a generalized Viscek-type flocking model. Nonlinearity 23:12, 3139-3156.  Online publication date: 1-Dec-2010. [Crossref]\nRenjun Duan , Massimo Fornasier , Giuseppe Toscani .  (2010) A Kinetic Flocking Model with Diffusion. Communications in Mathematical Physics 300:1, 95-145.  Online publication date: 1-Nov-2010. [Crossref]\nN. Bellomo , C. Bianca , M.S. Mongiovì .  (2010) On the modeling of nonlinear interactions in large complex systems. Applied Mathematics Letters 23:11, 1372-1377.  Online publication date: 1-Nov-2010. [Crossref]\nPIERRE DEGOND , TONG YANG .  (2010) DIFFUSION IN A CONTINUUM MODEL OF SELF-PROPELLED PARTICLES WITH ALIGNMENT INTERACTION. Mathematical Models and Methods in Applied Sciences 20:supp01, 1459-1490.  Online publication date: 1-Sep-2010. [ Abstract | PDF (452 KB) | PDF Plus (484 KB) ]\nN. BELLOMO , H. BERESTYCKI , F. BREZZI , J.-P. NADAL .  (2010) MATHEMATICS AND COMPLEXITY IN LIFE AND HUMAN SCIENCES. Mathematical Models and Methods in Applied Sciences 20:supp01, 1391-1395.  Online publication date: 1-Sep-2010. [ Abstract | PDF (95 KB) | PDF Plus (109 KB) ]\nI. Bonzani .  (2010) Some theoretical reasonings on the use and abuse of empirical data for vehicular traffic modelling. Mathematical and Computer Modelling 52:5-6, 715-723.  Online publication date: 1-Sep-2010. [Crossref]\nSeung-Yeal Ha , Taeyoung Ha , Jong-Ho Kim .  (2010) Asymptotic dynamics for the Cucker–Smale-type model with the Rayleigh friction. Journal of Physics A: Mathematical and Theoretical 43:31, 315201.  Online publication date: 6-Aug-2010. [Crossref]\nN. Bellomo .  (2010) Modeling the hiding–learning dynamics in large living systems. Applied Mathematics Letters 23:8, 907-911.  Online publication date: 1-Aug-2010. [Crossref]\nPierre Degond , Laurent Navoret , Richard Bon , David Sanchez .  (2010) Congestion in a Macroscopic Model of Self-driven Particles Modeling Gregariousness. Journal of Statistical Physics 138:1-3, 85-125.  Online publication date: 1-Feb-2010. [Crossref]\nC. Bianca .  (2010) On the modelling of space dynamics in the kinetic theory for active particles. Mathematical and Computer Modelling 51:1-2, 72-83.  Online publication date: 1-Jan-2010. [Crossref]\nJ. A. Carrillo , M. Fornasier , J. Rosado , G. Toscani .  (2010) Asymptotic Flocking Dynamics for the Kinetic Cucker–Smale Model. SIAM Journal on Mathematical Analysis 42:1, 218-236.  Online publication date: 1-Jan-2010. [Crossref]\nI. Bonzani , L. Mussone .  (2009) On the derivation of the velocity and fundamental traffic flow diagram from the modelling of the vehicle–driver behaviors. Mathematical and Computer Modelling 50:7-8, 1107-1112.  Online publication date: 1-Oct-2009. [Crossref]\nN. BELLOMO , H. BERESTYCKI , F. BREZZI , J.-P. NADAL .  (2009) MATHEMATICS AND COMPLEXITY IN LIFE AND HUMAN SCIENCES. Mathematical Models and Methods in Applied Sciences 19:supp01, 1385-1389.  Online publication date: 1-Aug-2009. [ Abstract | PDF (85 KB) | PDF Plus (95 KB) ]\nI. Bonzani , L.M. Gramani Cumin .  (2009) Critical analysis and perspectives on the hydrodynamic approach for the mathematical theory of vehicular traffic. Mathematical and Computer Modelling 50:3-4, 526-541.  Online publication date: 1-Aug-2009. [Crossref]\nE. De Angelis , R. Revelli , L. Ridolfi .  (2009) Transport–diffusion models with nonlinear boundary conditions and solution by generalized collocation methods. Computers & Mathematics with Applications 58:3, 558-565.  Online publication date: 1-Aug-2009. [Crossref]\nN. Bellomo , M. Delitala .  (2009) On the coupling of higher and lower scales using the mathematical kinetic theory of active particles. Applied Mathematics Letters 22:5, 646-650.  Online publication date: 1-May-2009. [Crossref]\nN. Bellomo , A. Bellouquid .  (2009) On the derivation of macroscopic hyperbolic equations for binary multicellular growing mixtures. Computers & Mathematics with Applications 57:5, 744-756.  Online publication date: 1-Mar-2009. [Crossref]\nN. Bellomo , M. Delitala .  (2008) From the mathematical kinetic, and stochastic game theory to modelling mutations, onset, progression and immune competition of cancer cells. Physics of Life Reviews 5:4, 183-206.  Online publication date: 1-Dec-2008. [Crossref]\n""","0.16702092","""http://www.worldscientific.com/doi/abs/10.1142/S0218202508003005""","[-0.178219,51.500505]"
"""Queen's_University_Belfast""","""A self-learning teaching-learning based optimization for dynamic economic/environmental dispatch considering multiple plug-in electric vehicle loads - Queen's University Belfast Research Portal - Research Directory & Institutional Repository for QUB""","""A self-learning teaching-learning based optimization for dynamic economic/environmental dispatch considering multiple plug-in electric vehicle loads\nResearch output: Contribution to journal › Article\nPublished\nView graph of relations\nEconomic and environmental load dispatch aims to determine the amount of electricity generated from power plants to meet load demand while minimizing fossil fuel costs and air pollution emissions subject to operational and licensing requirements. These two scheduling problems are commonly formulated with non-smooth cost functions respectively considering various effects and constraints, such as the valve point effect, power balance and ramp rate limits. The expected increase in plug-in electric vehicles is likely to see a significant impact on the power system due to high charging power consumption and significant uncertainty in charging times. In this paper, multiple electric vehicle charging profiles are comparatively integrated into a 24-hour load demand in an economic and environment dispatch model. Self-learning teaching-learning based optimization (TLBO) is employed to solve the non-convex non-linear dispatch problems. Numerical results on well-known benchmark functions, as well as test systems with different scales of generation units show the significance of the new scheduling method.\nDocuments\nA self-learning TLBO based dynamic economic/environmental dispatch considering multiple plug-in electric vehicle loads\nRights statement: Copyright The Author(s) 2014. This article is published with open access at Springerlink.com. This article is distributed under the terms of the Creative Commons Attribution License which permits any use, distribution, and reproduction in any medium, provided the original author(s) and the source are credited.\nFinal published version, 1 MB, PDF-document\nDOI\n""","0.6897876","""http://pure.qub.ac.uk/portal/en/publications/a-selflearning-teachinglearning-based-optimization-for-dynamic-economicenvironmental-dispatch-considering-multiple-plugin-electric-vehicle-loads(9e4d050b-ff75-498b-8e2c-d84e7d1b4416).html""","[-5.934759,54.583863]"
"""Queen's_University_Belfast""","""An Analysis of the Effect of Electric Vehicle Charging on the Operation of the Single Electricity Market - Queen's University Belfast Research Portal - Research Directory & Institutional Repository for QUB""","""An Analysis of the Effect of Electric Vehicle Charging on the Operation of the Single Electricity Market\nResearch output: Contribution to conference › Paper\nPublished\nView graph of relations\nTo meet European Union renewable energy and greenhouse gas emissions reduction targets the Irish government set a target in 2008 that 10% of all vehicles in the transport fleet be powered by electricity by 2020. Similar electric vehicle targets have been introduced in other countries. However, reducing energy consumption and decreasing greenhouse gas emissions in transport is a considerable challenge due to heavy reliance on fossil fuels. In fact, transport in the Republic of Ireland in 2009 accounted for 29% of non-emissions trading scheme greenhouse gas emissions, 32% of energy-related greenhouse gas emissions, 21% of total greenhouse gas emissions and approximately 50% of energy-related non-emission trading scheme greenhouse gas emissions. In this paper the effect of electric vehicle charging on the operation of the single wholesale electricity market for the Republic of Ireland and Northern Ireland is analysed. The energy consumed, greenhouse gas emissions generated and changes to the wholesale price of electricity under peak and off-peak charging scenarios are quantified and discussed. Results from the study show that off-peak charging is more beneficial than peak charging.\nLinks\n""","1.2415924","""http://pure.qub.ac.uk/portal/en/publications/an-analysis-of-the-effect-of-electric-vehicle-charging-on-the-operation-of-the-single-electricity-market(55546d45-53a3-47bf-a513-df92b534dedb).html""","[-5.934759,54.583863]"
"""Imperial_College_London""","""Ecological regression analysis of environmental benzene exposure and childhood leukaemia: sensitivity to data inaccuracies, geographical scale and ecological bias - Best - 2001 - Journal of the Royal Statistical Society: Series A (Statistics in Society) - Wiley Online Library""","""Journal of the Royal Statistical Society: Series A (Statistics in Society)\n2001\nPages 155–174\nEcological regression analysis of environmental benzene exposure and childhood leukaemia: sensitivity to data inaccuracies, geographical scale and ecological bias\nAuthors\nCited by (CrossRef): 37 articles Check for updates\nCitation tools\nNicky Best Department of Epidemiology and Public Health, Imperial College School of Medicine, Norfolk Place, London, W2 1PG, UK n.best@ic.ac.uk\nAbstract\nBenzene is classified as a group 1 human carcinogen by the International Agency for Research on Cancer, and it is now accepted that occupational exposure is associated with an increased risk of various leukaemias. However, occupational exposure accounts for less than 1% of all benzene exposures, the major sources being cigarette smoking and vehicle exhaust emissions. Whether such low level exposures to environmental benzene are also associated with the risk of leukaemia is currently not known. In this study, we investigate the relationship between benzene emissions arising from outdoor sources (predominantly road traffic and petrol stations) and the incidence of childhood leukaemia in Greater London. An ecological design was used because of the rarity of the disease, the difficulty of obtaining individual level measurements of benzene exposure and the availability of data. However, some methodological difficulties were encountered, including problems of case registration errors, the choice of geographical areas for analysis, exposure measurement errors and ecological bias. We use a Bayesian hierarchical modelling framework to address these issues, and we investigate the sensitivity of our inference to various modelling assumptions.\nArticles related to the one you are viewing\nCiting Literature\nNumber of times cited: 37\n1\nTakahiro Yoshida, Morito Tsutsumi, On the effects of spatial relationships in spatial compositional multivariate models, Letters in Spatial and Resource Sciences, 2018\nCrossRef\n2\nJay M. Ver Hoef, Erin E. Peterson, Mevin B. Hooten, Ephraim M. Hanks, Marie-Josèe Fortin, Spatial autoregressive models for statistical inference from ecological data, Ecological Monographs, 2018\nCrossRef\n4\nPeter F. Infante, Residential Proximity to Gasoline Stations and Risk of Childhood Leukemia, American Journal of Epidemiology, 2017, 185, 1, 1\nCrossRef\n5\nEarl W. Duncan, Nicole M. White, Kerrie Mengersen, Spatial smoothing in Bayesian models: a comparison of weights matrix specifications and their impact on inference, International Journal of Health Geographics, 2017, 16, 1\n6\nSandy Burden, David Steel, Empirical Zoning Distributions for Small Area Data, Geographical Analysis, 2016, 48, 4, 373\nWiley Online Library\n7\nJeffrey M. Switchenko, Catherine Bulka, Kevin Ward, Jean L. Koff, A. Rana Bayakly, P. Barry Ryan, Lance A. Waller, Christopher R. Flowers, Resolving uncertainty in the spatial relationships between passive benzene exposure and risk of non-Hodgkin lymphoma, Cancer Epidemiology, 2016, 41, 139\nCrossRef\n8\nJavier García-Pérez, Gonzalo López-Abente, Diana Gómez-Barroso, Antonio Morales-Piga, Elena Pardo Romaguera, Ibon Tamayo, Pablo Fernández-Navarro, Rebeca Ramis, Childhood leukemia and residential proximity to industrial and urban sites, Environmental Research, 2015, 140, 542\nCrossRef\n9\nSu Yun Kang, James McGree, Peter Baade, Kerrie Mengersen, An investigation of the impact of various geographical scales for the specification of spatial dependence, Journal of Applied Statistics, 2014, 41, 11, 2515\nCrossRef\n10\nSibylle Sturtz, Katja Ickstadt, Comparison of Bayesian methods for flexible modeling of spatial risk surfaces in disease mapping, Biometrical Journal, 2014, 56, 1, 5\nCrossRef\n17\nSebastien Haneuse, Scott Bartell, Designs for the Combination of Group- and Individual-level Data, Epidemiology, 2011, 22, 3, 382\nCrossRef\n18\nIrene L. Hudson, Linda Moore, Eric J. Beh, David G. Steel, Ecological inference techniques: an empirical evaluation using data describing gender and voter turnout at New Zealand elections, 1893â1919, Journal of the Royal Statistical Society: Series A (Statistics in Society), 2010, 173, 1, 185\nWiley Online Library\n19\nLéa Fortunato, Chantal Guihenneuc-Jouyaux, Dominique Laurier, Margot Tirmarche, Jacqueline Clavel, Denis Hémon, Mathematical Methods in Survival Analysis, Reliability and Quality of Life, 2010, 61\nCrossRef\n20\nOri Eitan, Yuval, Micha Barchana, Jonathan Dubnov, Shai Linn, Yohay Carmel, David M. Broday, Spatial analysis of air pollution and cancer incidence rates in Haifa Bay, Israel, Science of The Total Environment, 2010, 408, 20, 4429\n""","0.3362838","""http://onlinelibrary.wiley.com/doi/10.1111/1467-985X.00194/abstract""","[-0.178219,51.500505]"
"""University_of_Surrey""","""PM10 and Heavy Metals in Suburban and Rural Atmospheric Environments of Northern India | Journal of Hazardous, Toxic, and Radioactive Waste | Vol 16, No 2""","""Journal of Hazardous, Toxic, and Radioactive Waste\nThis study assesses the ambient air concentration of\nPM\n10\nand heavy metals at six different sites (including three sub-urban and three rural) in Roorkee, India. Monthly measurements were carried out continuously between January and March 2007 at all sites.\nPM\nconcentrations at the rural sites ranged from\n37\nm\n3\nat sub-urban sites. These concentrations were well above the CPCB (Central Pollution Control Board, Delhi) standards during all sampling months except February. Conversely, lowest\nPM\n10\nconcentration during February was the result of removal of particles by heavy rain before the sampling days. In the case of heavy metals, highest concentrations for Cr, Fe, Mn, Zn, and Al were 2.04, 30, 0.80, 7.13, and\n15.6\n, respectively, at rural sites compared with 0.28, 0.37, and\n0.02\nfor Ni, Cu, and Cd, respectively, at an industrial site. Main sources of\nPM\n10\nand heavy metals at sub-urban sites were road dust, traffic exhaust, tire abrasion, industrial emissions, and oil lubricants use at vehicle-servicing centers. Heavy metals and\nPM\n10\nat the rural sites originate from coal and wood burning, sugar mill and brick furnace emissions, fertilizers use in farming, agricultural activity, road construction activity, and the dust from long-range transport along with naturally occurring resuspended dust. Among all, wood burning was identified as the most significant source of elevated\nPM\nconcentrations at rural sites. As opposed to the\nPM\n10\nthat remains a concern, concentrations of all heavy metals were found to be far below the standard limits prescribed by the World Health Organization (WHO) and the United States Environmental Protection Agency (EPA). An integrated assessment of air pollution and health risk is believed to be required to be carried out to draw better conclusions about air quality conditions in study areas.\n""","0.5018203","""https://ascelibrary.org/doi/10.1061/%28ASCE%29HZ.2153-5515.0000101""","[-0.589514,51.242722]"
"""Cranfield_University""","""A measurement strategy for non-dispersive ultra-violet detection of formaldehyde in indoor air: spectral analysis and interferent gases - IOPscience""","""Paper • The following article is OPEN ACCESS\nA measurement strategy for non-dispersive ultra-violet detection of formaldehyde in indoor air: spectral analysis and interferent gases\nJ J Davenport1,4, J Hodgkinson1,3, J R Saffell2 and R P Tatam1\nPublished 14 December 2015 • © 2016 IOP Publishing Ltd\nAuthor affiliations\n1 Engineering Photonics, Cranfield University, Cranfield, Bedfordshire MK43 0AL, UK\n2 Alphasense Ltd, Sensor Technology House, 300 Avenue West, Skyline 120, Great Notley, Essex CM77 7AA, UK\n3 Author to whom any correspondence should be addressed.\n4 Now at: Biomedical Engineering Research Group, Electrical and Electronic Engineering, City University, London EC1V 0HB, UK.\nDates\n0957-0233/27/1/015802\nAbstract\nWe have conducted an extensive review of published spectra in order to identify a region with potential for detection of formaldehyde in indoor air. 85 chemicals and chemical groups common to the indoor environment were identified, 32 of which had absorption spectra in the UV–vis region. Of these, 11 were found to overlap with the formaldehyde UV region. It was found that the region between 320 to 360 nm is relatively free from interference from indoor gases, with NO2 being the only major interferent. A method is proposed for a low resolution (3 nm) spectroscopic detection method, specifically targeted at formaldehyde absorption features at 327 nm with a reference at 334 nm. 32 ppb of NO2 was found to have a cross-sensitivity with equivalent magnitude to 100 ppb of formaldehyde. A second reference at 348 nm would reduce this cross-sensitivity.\nExport citation and abstract\nOriginal content from this work may be used under the terms of the Creative Commons Attribution 3.0 licence . Any further distribution of this work must maintain attribution to the author(s) and the title of the work, journal citation and DOI.\n1. Introduction\nFormaldehyde, also known as methanal, methyl aldehyde and methylene oxide, is the first member of the aldehyde chemical family and has the chemical formula CH2O. Under standard conditions it is a colourless gas. It is toxic, allergenic and a potential human carcinogen [ 1 – 3 ]. It has been shown to cause inflammation of lung epithelial cells [ 4 ] and to be dangerous at the ppb level (parts-per-billion, 1 molecule in 109 of air) [ 5 ]. The World Health Organisation (WHO) has set a guideline level of prolonged formaldehyde exposure at 80 ppb, and many countries have set theirs in line with this [ 6 , 7 ]. Some countries have guideline levels as high as 100 ppb, such as Canada, Singapore and South Korea [ 7 ].\nFormaldehyde is also a valuable industrial chemical with limited alternatives [ 1 , 2 , 7 ]. Formaldehyde resin is used as an adhesive in plywood [ 8 , 9 ] and in carpeting [ 10 ], and is also used in the production of paints [ 11 ] and wallpapers [ 12 ]. Emission levels are highest when products are new, generally decreasing exponentially, but can take multiple years to reach safe levels [ 6 , 7 , 13 ]. As a result formaldehyde gas can build up in enclosed areas and, particularly when new furnishings or carpeting have been installed, it can pose a serious risk to health.\nOptical sensors generally offer a number of advantages for gas detection including fast response times, reliable components and, for absorption based sensors, non-contact operation. Table 1 gives some examples of reported optical detection methods for formaldehyde.\nTable 1. Examples of some present detection methods for formaldehyde.\nTechnique\n[ 20 ]\nTechniques requiring chemical indicators can be difficult to implement as standalone sensors. For example the sensor of Kudo et al [ 6 ] requires circulation of a chemical reagent and pH buffer for correct operation, which precludes its use as a compact sensor for field use requiring minimal human intervention.\nIn tuneable diode laser spectroscopy (TDLS), a tuneable diode laser is used as a light source and its wavelength is tuned to scan across the absorption spectrum of the target gas. TDLS is sensitive; Wysocki et al [ 14 ] demonstrating a detection limit of 3.5 ppb with a response time of 1 s. Richter et al [ 16 ] achieved a greater sensitivity of 74 ppt at 3.5 μm but at a decreased response time (once per minute rather than once every few seconds). TDLS systems demonstrate good species selectivity, often with no spectral overlap between absorption lines, and excellent signal-to-noise ratios, but can expensive and complex to manufacture. This is especially true when using quantum cascade lasers (QCLs), interband cascade lasers (ICLs) or difference frequency generation (DFG) sources to access the mid infrared region. Sensitivity can be improved by the use of multipass optical cells or cavity-enhanced techniques such as off-axis integrated cavity output spectroscopy (OA-ICOS) or cavity ringdown spectroscopy (CRDS), but these further add to system complexity, footprint and cost.\nPhotoacoustic spectroscopy (PAS) relies on the photo-acoustic effect whereby sound is produced by the absorption of light from a modulated source. PAS has been shown to give reasonable sensitivity and response time (detection of formaldehyde at 3 ppb at one measurement per three minutes being shown by Angelmahr et al [ 19 ]) but can be susceptible to background acoustic noise. The QEPAS technique, as demonstrated by Horstjann et al for formaldehyde [ 20 ], aims to solve this problem using a quadrupole acoustic sensor, however to sensitively detect formaldehyde still requires the use of a costly QCL source.\nDifferential optical absorption spectroscopy (DOAS) is commonly used for outdoor formaldehyde detection. It typically uses a region of the spectrum between approximately 320 and 360 nm [ 21 – 24 ] because there are several clear formaldehyde absorption peaks with relatively little interference from other outdoor gases. Stutz and Platt [ 25 ] have published algorithms required to separate measurements of concentrations of ozone, nitrogen dioxide, sulfur dioxide and formaldehyde in the atmosphere. Hausmann et al [ 26 ] have estimated the level of error when using UV DOAS techniques to measure concentrations of OH, SO2, C10H8 and formaldehyde in the atmosphere, in the presence of instrumental noise. Both papers reveal a high degree of complexity in spectral post-processing required to separate these species at trace atmospheric levels using their UV absorption spectra. DOAS, like many optical spectroscopic gas detection methods, relies on high resolution (sub nanometer) spectral measurements [ 21 ].\nMany of these developments have been applied to the measurement of formaldehyde in outdoor air, to understand outdoor pollution or atmospheric processes. In contrast, the indoor environment has different emission sources, and their concentrations are often higher since significant concentrations of gases can build up in enclosed areas [ 27 ]. Weschler has published a comprehensive review of the number of gases and volatiles present, identifying 85 chemical species and families [ 27 ]. To enable reliable measurements of formaldehyde in the indoor environment, it is therefore important to consider the role of spectral interference for the mixture of gases commonly found in indoor air. This is especially true of measurements made in the UV region, where such effects can often be the limiting factor.\nDooly et al [ 28 ] have shown the corrections required to measure NO concentrations in the presence of other vehicle exhaust gases, in particular including UV-absorbing species NO2 and SO2. A high resolution (0.7 nm) spectrometer was used for this work. Absorbances at a wavelength of 227 nm had to be corrected by measurements made at 287 and 413 nm to account for the presence of two additional absorbing species. Use of narrow spectral bins simplified the analysis required by limiting the range of potential interferents at each wavelength. Nevertheless, some cross-response to the interfering species remained.\nIn this paper, consideration is made of the UV absorption spectra of a range of gases commonly found in the indoor environment, finding that the 320–360 nm region (as used in DOAS) is also appropriate for indoor air. For chemical species selectivity, previous work shows that high resolution spectral measurements are often required, especially in the UV region where spectra from multiple species can overlap. In contrast, a proposal is described here for a lower resolution (3 nm) formaldehyde detection method, taking advantage of features of the formaldehyde absorption spectrum. Measurement and reference channels are selected to give a formaldehyde-specific detection method with the potential for a greatly simplified system suitable for measurement of formaldehyde in the indoor environment. The anticipated level of cross-sensitivity has been quantified for potentially interfering gases present at levels typical of the indoor environment.\nThe method described here has a number of advantages over current systems that it shares with non-dispersive infra-red gas detection (NDIR), including simplicity of manufacture, requirement of few, low cost components and a small size [ 29 ]. It follows similar principles to NDIR except that it operates in the ultra-violet region of the spectrum. It permits low resolution measurements targeted at specific features of the absorption spectra of the gases being analyzed. This is only possible with a detailed understanding of the environment being tested and the spectra of the species common to it, and only if a spectral region can be identified where interference is minimal.\n2. Spectroscopy theory\nPhotons passing through a sample of gas can only be absorbed when they match a specific energy transition of the molecules present. Absorption is related to gas concentrations and is given by the Beer–Lambert law:\nwhere I is the final intensity of light transmitted through a sample at wavelength λ, I0 is the initial intensity at that wavelength, σ is the absorption cross-section per molecule of absorbing gas at that wavelength, l is the light path length through the sample and N is the number density of absorbing gas molecules. Absorbance is a term defined as the ratio of absorbed intensity to initial intensity, given by equation ( 2 ). It has units AU (absorption units) which are dimensionless.\nAt low values of σlN, this approximates to the linear form:\nThe UV absorption spectrum of formaldehyde is shown in figure 1 .\nZoom In\nStandard image High-resolution image Export PowerPoint slide\nWhen two or more species are present that absorb at the same wavelength, their absorption cross-sections in equation ( 1 ) are additive. It is not always possible to isolate individual absorption spectra from the spectrum of a complicated sample. In this report the UV absorption spectrum of formaldehyde is compared to those of gases likely to be present in indoor environments in an attempt to understand and minimize spectral interference.\n3. Gases present in indoor air\nThe substances considered in this review were predominantly based on a comprehensive study of pollutants in indoor air by Weschler [ 27 ]. Weschler's study focused mainly on homes in the United States and collected and compared published data from many other studies. Some of the underlying data in these sources was obtained using detection methods such as gas chromatographs linked to mass spectrometers [ 31 , 32 ]. Other data was inferred from the presence of emitting materials such as medium density fiber board (MDF).\nMany of the above gas detection methods take multiple hours to run [ 33 , 34 ] and so short-lived species may have gone undetected and been left out of Weschler's study. One such compound, nitrous acid, is produced from the heterogeneous hydrolysis of nitrogen dioxide with wet surfaces [ 35 ] and has been found to persist for around 10 min in forest atmospheres [ 36 ]. The nitrous acid absorption spectrum does interfere with formaldehyde, as described later in this paper.\nSeveral other studies had found nitrous acid to be present in the indoor environment [ 35 , 37 ] and so it was added to the list of compounds considered here. Otherwise, Weschler's report appears to be comprehensive and is well regarded by several other authors [ 7 , 38 ]. It has therefore been used as the bench mark for formaldehyde selectivity in this paper.\nThe substances identified for this review can be divided into three basic categories: inorganic gases, volatile organic compounds (including semi-volatiles) and airborne particles. Each of these categories has some broadly similar properties and gases in a category will frequently have similar sources. The general properties and sources of these categories are discussed below.\nThe source of many inorganic gases in modern buildings is cooking and heating appliances [ 39 ] as well as indoor smoking and various industrial processes. In the UK, indoor concentrations of carbon monoxide, nitrogen dioxide and nitric oxide have been on the decrease in recent years due to a decrease in smoking and other factors [ 27 , 40 , 41 ]. The trend of indoor ozone is less clear [ 42 ].\nThe category 'volatile organic compounds' covers a wide variety of large, organic molecules that can still readily be gaseous at room temperature. Formaldehyde is a volatile organic compound, as are some other members of the aldehyde chemical group. This category also includes alkanes, aromatics such as benzene and toluene and many more.\nIndoor sources of these gases include emissions from resins, rubber and carpets, smoking and indoor chemical reactions [ 27 , 43 ]. Indoor concentrations of some compounds such as aromatics and some of the more volatile compounds, are currently decreasing or remaining constant due to decreases in source abundance [ 44 – 46 ]. Some of the longer-chain aldehydes and many semi-volatile organic compounds are currently on the increase, potentially due to increases in preceding reactions and increases in certain cosmetic products [ 27 , 47 , 48 ].\nThe final category includes metal particles, mineral fibers, dust components, mould spores and many others [ 27 ]. Their sources are widespread, including lead-based paints, indoor smoking, industrial processes and even human skin. The concentrations of many airborne particles are decreasing due to legal restrictions on certain sources, but it is difficult to draw general trends [ 27 , 49 , 50 ].\nSmall particles are known to exhibit a spectroscopic scattering effect that is analogous to the absorption cross-section in the Beer–Lambert law. It is variable with wavelength and so airborne particles can exhibit broad spectral features similar to light absorption features [ 51 ]. Some airborne particles also exhibit fluorescence effects in the UV [ 51 , 52 ]. Airborne particles were not considered in this project but may have to be considered or eliminated when using a detection system 'in situ', potentially by filtering. Many gas detectors, for example those based on non-dispersive infrared detection, are based on gas diffusion into the optical path through a particulate filter [ 29 ].\n4. Results of spectral survey\nA full list of all substances and substance groups considered in this survey is given in table 2 . In total 85 substances and substance groups were identified, 32 of which had absorption spectra in the UV–vis region. Of these, 11 were found to overlap with the formaldehyde UV absorption region. References are given for the UV spectral data found for these substances.\nTable 2. List of all substances and substance groups considered in this survey.\nSubstance\nStandard image High-resolution image Export PowerPoint slide\nOn examining this data, the spectral region between 320 and 360 nm was identified as having very limited spectral interference from other gases (highlighted in figure 2 ). Most of the potentially interfering species did not have significant absorption in this region, and some of the highest formaldehyde absorption peaks can be found here. Nitrogen dioxide appears to be the most significant source of interference in this region, with some interference from nitrous acid as well. This was a surprising result given the number of species considered.\n5. Proposed detection method\nWe propose a method for formaldehyde detection based on non-dispersive spectroscopy using the absorption region identified above. Non-dispersive spectroscopy uses elements such as bandpass filters to limit the wavelengths reaching detectors [ 79 ]. This removes the need for dispersive elements such as optical gratings. A diagram of a typical non-dispersive spectroscopic system is shown in figure 3 .\nZoom In\nStandard image High-resolution image Export PowerPoint slide\nThe total equivalent absorbances of these four example channels were found to be A: 9.0 × 10−4 AU, B: 6.1 × 10−5 AU, C: 2.3 × 10−5 AU. The absorbances from the detection channel A was more than a factor of 10 higher than for reference channels B and C.\nUsing a reference channel as the initial intensity and a detection channel as the final intensity, the absorbance of a sample can be found in real time. The reference channel allows fluctuations in source intensity and other changes to be compensated. Using channel A as a detection channel (giving ID in equation ( 4 )) and channel B as a reference channel (giving IR in equation ( 4 )), 10 ppm of formaldehyde in a 1 m gas cell has a calculated equivalent absorbance of 4.2 × 10−4 AU. This assumes that the light source is ideally 'white', i.e. has a flat spectral output, additional scaling factors being required if it is not.\n6. Results\nIn order to verify the effectiveness of this theoretical method, the effective absorbances of expected interfering species were calculated using the method of section 5 , with channel A as a detection channel and channel B as a reference. Spectral data was used from the same sources as for figure 2 . Typical concentrations were used in the calculation, as found in indoor air in previous studies. The results are given in table 3 . Note that some species give a 'negative absorbance', where they absorb more strongly in the reference region than in the detection region. Also given is the concentration required to give a signal level equivalent to that of 100 ppb formaldehyde. For most species the required concentration is significantly above the typical value. NO2 is expected to be the most significant interfering species for this method, as the required concentration is  −32 ppb (NO2 exhibits an apparent negative absorbance with our proposed detection scheme), which is of a similar order of magnitude to the level that can be found in indoor air.\nTable 3. Calculated absorbances of expected interference when using channels A and B from figure 4 and based on spectral data and typical indoor concentrations from the literature. A 1 m path length has been used for all absorbances calculated for this table.\nSpecies\n""","0.14017439","""http://iopscience.iop.org/article/10.1088/0957-0233/27/1/015802/meta""","[-0.629225,52.074389]"
"""Imperial_College_London""","""Technologies to measure indicators for road user charging | Proceedings of the Institution of Civil Engineers - Transport""","""Proceedings of the Institution of Civil Engineers - Transport\nProceedings of the Institution of Civil Engineers - Transport\nISSN 0965-092X | E-ISSN 1751-7710\nTechnologies to measure indicators for road user charging\nAuthors: \nMSc, PhD, FRIN, FInstCES, MICE, MIHT\nx\nEdward J. Bloustein School of Planning and Public Policy, Rutgers University, New Brunswick, NJ, USA\n, ,\nPublished Online: May 25, 2015\nKey:\nTrial content\nAbstract\nA technically and economically feasible road user charging scheme should be based on quantities that are readily and accurately measurable, as well as being directly variable with the amount of road use and its impact on the environment and society. A key requirement for a pricing scheme is that the charging regime used should be easy for motorists to understand, but at the same time flexible enough for the operator to implement a wide range of policies to meet different aims. A set of variable road user charging indicators is identified herein by considering both the associated costs of a trip and the operational requirements for a feasible road pricing scheme. The study then focused on identifying a set of currently feasible technologies to measure these variables in real-time with high accuracy. Particular attention was paid to the need accurately to track vehicle movements and link these movements to geographical areas and road types, and the key pollutants and particulate matter, all of which have different potential effects that are in some cases dependent on location and time of emissions. Other issues, such as congestion measurement, are also discussed.\nKeywords:\n""","0.61529344","""https://www.icevirtuallibrary.com/doi/10.1680/tran.2010.163.2.63""","[-0.178219,51.500505]"
"""Queen's_University_Belfast""","""D3.1 Benefits Analysis of the Initial Operational Cruiser-Feeder Concept - Queen's University Belfast Research Portal - Research Directory & Institutional Repository for QUB""","""D3.1 Benefits Analysis of the Initial Operational Cruiser-Feeder Concept\nResearch output: Chapter in Book/Report/Conference proceeding › Chapter (peer-reviewed)\nPublished\nView graph of relations\nThe REsearch on a CRuiser Enabled Air Transport Environment (RECREATE) project is considers the introduction and airworthiness of cruiser-feeder operations for civil aircraft. Cruiser-feeder operations are investigated as a promising pioneering idea for the air transport of the future. The soundness of the concept of cruiser-feeder operations for civil aircraft can be understood, taking air-to-air refueling operations as an example. For this example, a comprehensive estimate of the benefits can be made, which shows a fuel burn reduction potential and a CO2 emission reduction of 31% for a typical 6000 nautical miles flight with a payload of 250 passengers. This reduction potential is known to be large by any standard. The top level objective of the RECREATE project is to demonstrate on a preliminary design level that cruiser-feeder operations (as a concept to reduce fuel burn and CO2 emission levels) can be shown to comply with the airworthiness requirements for civil aircraft. The underlying Scientific and Technological (S&T) objectives are to determine and study airworthy operational concepts for cruiser-feeder operations, and to derive and quantify benefits in terms of CO2 emission reduction but also other benefits.\nWork Package (WP) 3 has the objective to substantiate the assumed benefits of the cruiser/feeder operations through refined analysis and simulation. In this report, initial benefits evaluation of the initial RECREATE cruiser/feeder concepts is presented. The benefits analysis is conducted in delta mode, i.e. comparison is made with a baseline system. Since comparing different aircraft and air transport systems is never a trivial task, appropriate measures and metrics are defined and selected first. Non-dimensional parameters are defined and values for the baseline system derived.\nThe impact of cruiser/feeder operations such as air-to-air refueling are studied with respect to fuel-burn (or carbon-dioxide), noise and congestion. For this purpose, traffic simulations have been conducted.\nCruiser/feeder operations will have an impact on dispatch reliability as well. An initial assessment of the effect on dispatch reliability has been made and is reported.\nFinally, a considerable effort has been made to create the infrastructure for economic delta analysis of the cruiser/feeder concept of operation. First results of the cost analysis have been obtained.\nOriginal language\n""","0.43749276","""http://pure.qub.ac.uk/portal/en/publications/d31-benefits-analysis-of-the-initial-operational-cruiserfeeder-concept(466ae9f5-d2ef-45e7-9ad0-3fc1d1e69e76).html""","[-5.934759,54.583863]"
"""UCL""","""Iris Publication""","""Log In\nPlease report any queries concerning the funding data grouped in the sections named \""Externally Awarded\"" or \""Internally Disbursed\"" (shown on the profile page) to           your Research Finance Administrator. Your can find your Research Finance Administrator at https://www.ucl.ac.uk/finance/research/rs-contacts.php by entering your department\nPlease report any queries concerning the student data shown on the profile page to:\nTransport modelling: carbon, cold starts, speed, and congestion modelling with National Travel Survey data\nPublication Type:\n""","0.8784642","""http://iris.ucl.ac.uk/iris/publication/1066408/1""",
"""Queen's_University_Belfast""","""A Parametric Study Of A Turbogenerator On A Diesel-Electric Hybrid Bus - Queen's University Belfast Research Portal - Research Directory & Institutional Repository for QUB""","""A Parametric Study Of A Turbogenerator On A Diesel-Electric Hybrid Bus\nResearch output: Chapter in Book/Report/Conference proceeding › Conference contribution\nPublished\nView graph of relations\nThe fuel consumption of automotive vehicles has become a prime consideration to manufacturers and operators as fuel prices continue to rise steadily, and legislation governing toxic emissions becomes ever more strict. This is particularly true for bus operators as government fuel subsidies are cut or removed.\nIn an effort to reduce the fuel consumption of a diesel-electric hybrid bus, an exhaust recovery turbogenerator has been selected from a wide ranging literature review as the most appropriate method of recovering some of the wasted heat in the exhaust line. This paper examines the effect on fuel consumption of a turbogenerator applied to a 2.4-litre diesel engine.\nA validated one-dimensional engine model created using Ricardo WAVE was used as a baseline, and was modified in subsequent models to include a turbogenerator downstream, and in series with, the turbocharger turbine. A fuel consumption map of the modified engine was produced, and an in-house simulation tool was then used to examine the fuel economy benefit delivered by the turbogenerator on a bus operating on various drive-cycles.\nA parametric study is presented which examined the performance of turbogenerators of various size and power output. The operating strategy of the turbogenerator was also discussed with a view to maximising turbine efficiency at each operating point.\nThe performance of the existing turbocharger on the hybrid bus was also investigated; both the compressor and turbine were optimised and the subsequent benefits to the fuel consumption of the vehicle were shown.\nThe final configuration is then presented and the overall improvement in fuel economy of the hybrid bus was determined over various drive-cycles.\nDOI\n""","0.42049357","""http://pure.qub.ac.uk/portal/en/publications/a-parametric-study-of-a-turbogenerator-on-a-dieselelectric-hybrid-bus(27602084-4f9e-4cd8-8a13-58c4323e933e).html""","[-5.934759,54.583863]"
"""Imperial_College_London""","""The role of CO2 capture and utilization in mitigating climate change :  Nature Climate Change :  Nature Research""","""The role of CO2 capture and utilization in mitigating climate change\nAuthor information\nTo offset the cost associated with CO2 capture and storage (CCS), there is growing interest in finding commercially viable end-use opportunities for the captured CO2. In this Perspective, we discuss the potential contribution of carbon capture and utilization (CCU). Owing to the scale and rate of CO2 production compared to that of utilization allowing long-term sequestration, it is highly improbable the chemical conversion of CO2 will account for more than 1% of the mitigation challenge, and even a scaled-up enhanced oil recovery (EOR)-CCS industry will likely only account for 4–8%. Therefore, whilst CO2-EOR may be an important economic incentive for some early CCS projects, CCU may prove to be a costly distraction, financially and politically, from the real task of mitigation.\nSubject terms:\nView all figures\nFigure 1: Illustration of the calculation of the mitigation challenge.\nHere, historical data is sourced from BP data 2 , the low-mitigation scenario chosen here is the IEA's 6DS, and the objective is to meet the IEA's 2DS for 2050 3 . In this example, the MC equates to approximately 800 GtCO2 in the period to 2050.\nView in article\nFigure 2: Global CO2-EOR capacity compared with regional CO2 sequestration targets.\nData from refs 13 , 17 , 22 . The error bars included on this data indicate an average calculated variance of 30%. The reported variance is in the range 25–35%.\nView in article\nFigure 3: The effect of blending methanol with gasoline.\nIt can be observed that, as methanol is added to gasoline, the energy density of the fuel decreases, whilst the CO2 footprint per unit of energy service delivered increases. Therefore, the substitution of methanol for gasoline will potentially increase the CO2 emissions associated with delivering that energy service.\nView in article\nFigure 4: CCS versus CCU—a perspective for the period 2010 to 2050.\nCO2-EOR has the potential to materially contribute to the sequestration of CO2 whereas the contribution of CCU is negligible.\nAuthor information\nThe continued growth in anthropogenic CO2 emissions would appear to be characterized by one word—inexorable. Despite a growing number of climate change mitigation policies, anthropogenic CO2 emissions in the period 2000–2014 grew at an average rate of 2.6% per year, in contrast with an average rate of 1.72% per year in the period 1970–2000 1 , 2 . Indeed, in the period 2010–2014, emissions increased from approximately 31.9 to 35.5 GtCO2 per year; an average rate of 2.75% per year 2 . With the exception of a one-year reduction from 2008 to 2009, every year of this century has seen a year-on-year increase in anthropogenic CO2 emissions.\nIt has become commonplace to discuss future emission trajectories in terms of scenarios from, for example, the International Energy Agency (IEA) or the IPCC. Both the IEA and IPCC project that a world commensurate with no more than 2 °C of warming above pre-industrial levels is one in which total anthropogenic CO2 emissions are reduced to something less than 20 GtCO2 per year by 2050, with further reductions to near-zero or even net-negative emissions by the end of the century. This is typically referred to as the two-degree scenario or 2DS. At the other end of the spectrum, allowing anthropogenic emissions to increase to 60 GtCO2 per year by 2050 is commensurate with warming of approximately 6 °C above pre-industrial levels—this is the six degree scenario, 6DS 1 , 3 .\nThe conclusion one can draw from the foregoing data is that if anthropogenic emissions of CO2 continue along any of the recent growth trends, we are poised to very significantly overshoot the 6DS. To even meet the 6DS, we would need to reduce the annual rate of growth of emissions to 1.4% and to meet the 2DS, the rate of growth needs to be −1.5% if global emissions peak in the 2020s. If emissions peak later, the required rate of reduction similarly increases. For the remainder of this analysis, we hypothesize a world, inspired by recent success in Paris, that reduces emissions to a level commensurate with the 6DS by 2020 and aims thereafter to transition to a world commensurate with the 2DS, focusing on the period to 2050. This allows us to introduce the quantity mitigation challenge (MC), the amount of avoided CO2 emissions (against a reference case) by a given date, tf, in order to reduce emissions to a level commensurate with meeting the 2DS, E2DS. E2DS is a function of the year in which emissions peak, tp, the emission rate in that year, Etp, and lastly the rate at which CO2 would be emitted in tf according to a low mitigation scenario (LMS) reference scenario, ELMS. Therefore, MC can be expressed as equation (1):\nIn addition to being a function of tf, ELMS is also a function of tp, and the average rate of growth of anthropogenic CO2 associated with the LMS scenario in the period (tf–tp). Therefore, ELMStp = Etp(1+r)(tf–tp). Thus, in order to meet the IEA's 2DS with the 6DS as a baseline, it is necessary to avoid the cumulative emission of approximately 800 GtCO2 in the period to 2050 ( Fig. 1 ).\nFigure 1: Illustration of the calculation of the mitigation challenge.\nHere, historical data is sourced from BP data 2 , the low-mitigation scenario chosen here is the IEA's 6DS, and the objective is to meet the IEA's 2DS for 2050 3 . In this example, the MC equates to approximately 800 GtCO2 in the period to 2050.\nNext\nGlobally, despite an increasing emphasis on renewable energy, annual investment in fossil energy has more than doubled in real terms in the period 2000–2013, totalling more than US$950 billion at the end of this period 4 . It is therefore not unreasonable to suggest that fossil fuels will continue to be important to, if not dominate, the world's energy landscape for some time to come, with some estimates indicating that fossil fuels will still account for over 65% of the total energy mix in 2100 5 , despite increasing penetration of renewable electricity generation 6 . For this energy mix to be coherent with the long-term ambition of substantially mitigating anthropogenic CO2 emissions, the widespread deployment of CCS technology 7 , 8 , 9 will most likely be a vital part of the least-cost energy system of the future, working in conjunction with renewable energy to deliver energy which is low carbon, available, and affordable.\nFrom one perspective, CCS is a readily deployable technology solution, relying on well-understood components 7 , 8 , 9 . Two leading options for decarbonizing both the power and industrial sectors are the oxy-combustion of fuel or post-combustion scrubbing of the exhaust gas arising from a conventional combustion process. Both of these technologies are highly mature. Alkanolamine gas scrubbing was first patented in the 1930s and has since been widely used for natural gas sweetening 10 . Oxy-combustion, which relies on the cryogenic separation of air, was developed by Linde in 1902 and was operating at 30,000 toxygen per day at the Shell Pearl gas to liquids project in Qatar in 2006. This is sufficient oxygen to supply a 2 GW oxy-combustion power plant. Similarly, CO2 transport and injection has been practiced at scale for EOR since the 1950s. As of 2014, there are over 3,000 miles of high-pressure pipeline which transport over 60 million tonnes of CO2 per year for EOR in 113 projects in the US alone, with approximately 120 projects worldwide 11 , 12 . Similarly, the distribution and capacity of CO2 storage locations are also reasonably well-characterized, with first order estimates of theoretical global CO2 storage capacity of approximately 11,000 GtCO2 (ref. 13 ). Of this, approximately 1,000 GtCO2 capacity is provided by oil and gas reservoirs with approximately 9,000–10,000 GtCO2 capacity provided by deep saline aquifers 14 , 15 , 16 . Furthermore, there is also significant potential capacity in unmineable coal seams, with the additional economic benefit that this is may be accompanied by the recovery of coal-bed methane.\nIn order to stabilize atmospheric CO2 concentrations at a level of 450 ppm, that is, a concentration consistent with a world with a high likelihood of not exceeding 2 °C of warming, it is expected that it will be necessary to store 120–160 GtCO2 via CCS in the period to 2050 17 , with similar trends expected to the end of the century. Therefore we have more than enough CO2 storage capacity to meet this target and, even without identification of further storage sinks, sufficient to meet even ambitious CO2 sequestration needs for well beyond the next century, giving ample time for the likely lengthy transition from fossil fuels. Finally, the world's first commercial CCS-equipped power station has started operation at the Boundary Dam facility in Saskatchewan, Canada, with a second project also in operation in Alberta, where Shell are capturing the CO2 arising from H2 production 18 . CCS is inarguably a well-understood, mature technology that is deployable at commercial scale today.\nHowever, despite CCS relying on well-known and well-understood technology components, the transition to its widespread deployment continues to be an uphill battle. The financing of this transition is a particular challenge, one which requires the combination of strong policy and price signals to ensure that low-carbon and energy efficiency investments offer a sufficiently attractive risk-adjusted return.\nIt is in this context that CCU is often mentioned. As a relatively benign material, it is possible to convert CO2 into a wide variety of end products, in addition to its potential for enhanced hydrocarbon recovery. In this context, therefore, why should we not actively and favourably consider the reuse of captured CO2?\nCertainly it represents a beguiling opportunity—convert a waste product into high-value end products and kick-start a highly skilled regional manufacturing industry. Moreover, global demand for the potential products, such as methanol, appears healthy 19 .\nTherefore, it is easy to see why the prospect of CO2 utilization is an attractive one for a wide variety of academic, industrial, and political stakeholders. However, serious questions arise when the narrative around CO2 utilization becomes one of utilization in parallel with storage or utilization instead of storage. As will be discussed subsequently in this paper, from the perspective of mitigating anthropogenic climate change, CO2 utilization is highly unlikely to ever be a realistic alternative to long-term, secure, geological sequestration.\nThe remainder of this paper is laid out as follows; we first discuss the scale at which various CCU options could be deployed, we then go on to discuss the rate at which they could be deployed before finally discussing how much of the CO2 used in the various options corresponds to permanent storage. In all cases, this is contextualized with reference to the aforementioned mitigation challenge.\nIt's a matter of scale\nAuthor information\nTo put this in some perspective, current total global anthropogenic emissions are about 35.5 GtCO2 per year. Typical CO2 injection and storage conditions are approximately 10 MPa and 40 °C, corresponding to a CO2 density of approximately 600 kg m−3. This corresponds to approximately 1.64 × 108 m3 per day, or more than 1,033 million barrels (MMbbl) of CO2 per day. This is in contrast to current global oil production rates of approximately 87–91 MMbbl per day 20 , 21 . This means that global CO2 production today is approximately a factor of 10 greater than global oil production today, and, at current rates of growth, may be as much as a factor of 20 greater in 2050 22 .\nGiven that CCS is expected to account for the mitigation of approximately 14–20% of total anthropogenic CO2 emissions, in 2050 the CCS industry will need to be larger by a factor of 2–4 in volume terms than the current global oil industry. In other words, we have 35 years to deploy an industry that is substantially larger than one which has been developed over approximately the last century, resulting in the sequestration of 8–10 GtCO2 per annum by 2050 22 with a cumulative CO2 storage target of approximately 120–160 GtCO2 in the period to 2050 17 and between 1,200–3,300 GtCO2 over the course of the twenty-first century 13 . This is an exceptionally challenging task, similar in scale to wartime mobilization, but it is a task we should not be daunted by. Neither should we be distracted by focussing too much on the long-term solution without giving sufficient attention to the short-to-medium-term necessity of fossil-fuel decarbonization in a manner that allows them to operate in sympathy with intermittent generation from renewable sources 23\nIt is important to note that when CO2 utilization has traditionally been discussed, this has been in the context of CO2-EOR in the United States. In this paper we include CO2-EOR within a definition that considers any use of CO2, physical or chemical, that prevents immediate release of CO2 to the atmosphere as part of CCU. EOR is already a very mature technology with a history reaching back several decades, having well-defined techno-economic parameters, and is often considered to be an important part of the CCU landscape. In the early years of its development, CO2-EOR faced the challenge of relatively low oil prices and relatively high CO2 prices. Reservoir management was therefore optimized to maximize profit, not CO2 sequestration. At the time of writing, CO2-EOR provides approximately 5% of the total US crude oil production 24 , and whilst it has the potential to be appreciably expanded 25 , it is important to note the relationship between CO2 price and oil price. At oil prices of approximately US$100 per bbl, CO2 needs to be available at less than US$45 per tonne (ref. 12 ) for CO2-EOR to be economically viable. This is the case in the US, where the business model is very mature and the CO2-EOR capacity exists onshore, but this may not hold for the rest of the world. Thus, current oil prices in the range of US$40–60 per bbl and CO2 costs of US$60–80 per tonne (refs 26 , 27 ) make CO2-EOR less viable as a means of balancing the costs of large scale CCS operations, and separate economic or policy incentives are likely to be required.\nNevertheless, there is little question that CO2-EOR offers a large, near-term option to store large quantities of CO2 at lower net cost, with more than 90% of the world's oil reservoirs seemingly suitable for CO2-EOR 12 , if treated early enough, before the reservoir pressure drops below the minimum miscibility pressure. Thus, there exists the theoretical potential to produce 470 billion bbl of additional oil, corresponding to a cumulative theoretical CO2 injection capacity in the range of 70–140 Gt (refs 12 , 28 ).\nHowever, this may be a highly optimistic estimate of the total deployable CO2-EOR capacity. As illustrated in Fig. 2 , the majority of this capacity exists in the Middle East and North Africa and in the US at 50% and 13% respectively, whereas the estimated CO2-EOR in South Asia is essentially zero and the Asia Pacific region accounts for only about 3%.\nFigure 2: Global CO2-EOR capacity compared with regional CO2 sequestration targets.\nData from refs 13 , 17 , 22 . The error bars included on this data indicate an average calculated variance of 30%. The reported variance is in the range 25–35%.\nNext\nIn other words, there appears to be an unfortunate disconnect between regions of substantial CO2-EOR potential and those regions with the largest anticipated population growth, dependence on fossil fuels, and hence requirement to sequester CO2 over the course of the next century. In fact, the only regions where it appears certain that there is sufficient CO2-EOR capacity to meet the CO2 storage requirements to 2050 are the Middle East and Africa—although the requirements are close in North America and the former Soviet Union. Given the size and rate of growth of the CO2-EOR industry in the US, it is likely that the US will be a leader in the deployment of CO2-EOR. If we accept the availability of a CCS-derived stream of CO2 as a prerequisite for CO2-EOR, it would make sense to estimate the scale of likely CO2-EOR activities as matching regional CCS targets. Thus, a more realistic estimate is likely to be on the order of 40 GtCO2 cumulatively injected for CO2-EOR. Thereafter, if we consider the average CO2 footprint of a barrel of oil consumed, 0.43 tCO2 per bbl (ref. 29 ), this results in revising the above estimate down to approximately 35 GtCO2, or something in the range of 4.5% of the total CO2 mitigation challenge.\nIt is, however, important to further note that, given the appropriate incentives and regulatory environment, it is possible to operate a CO2-EOR operation so as to maximize the storage of CO2 per bbloil recovered 30 . This can have the effect of reducing the amount of oil recovered per tCO2 injected from approximately 3.33 bbloil per tCO2 to 1.11 bbloil per tCO2. At the lower end, once the CO2 emissions associated with the consumption of that oil are accounted for, this can result in the storage of up to 0.52 tCO2 stored per tCO2 injected, increasing the contribution of CO2-EOR to something in the range of 8% of the total CO2 mitigation challenge. A final point for consideration here is that oil derived from CO2-EOR could well displace oil that would otherwise be derived from unconventional sources which are known to have a CO2 intensity of 108–173% of conventional oil 31 . This displacement effect is estimated to be on the order of 80%, owing to market elasticities 30 . Therefore, assuming a constant demand, the deployment of CO2-EOR could lead to the avoidance of CO2 that would otherwise be emitted by the production of unconventional hydrocarbon resources, in addition to the reduced environmental and social risks of oil production via CO2-EOR in mature fields relative to unconventional hydrocarbon production.\nObviously, CO2-EOR is not the only route to CO2 utilization—there are also CO2 conversion options. There has been active interest in the chemical conversion of CO2 into platform chemicals, plastics, and other materials and fuels since the 1850s 32 , 33 , 34 , 35 with the synthesis of salicylic acid, sodium carbonate via the Solvay process, and urea developed in 1869, 1882, and 1922 respectively 36 , 37 , 38 . It is therefore important to recognize that the focus on CO2 utilization is not a recent phenomenon. Overall, current annual global CO2 utilization is on the order of 200 Mt (ref. 35 ) and it has been suggested that this is likely capped at approximately 650–700 Mt in 2050 (ref. 33 ). Whilst this estimate was made in 2006, it is in line with current growth rates of the global chemical industry 39 . Further, of these conversion products, approximately 75% is accounted for by compounds which would not correspond to long-term sequestration of CO2 as the incorporated CO2 is released once the products are used. Therefore, given a 3% per year growth rate of CO2 utilization and a sequestration rate of 25%, this corresponds to a cumulative total of 15.42 GtCO2 utilized by 2050 and 3.86 GtCO2 sequestered—about 0.49% of the 800 GtCO2 mitigation challenge.\nMineral carbonation is another process that is under consideration 40 . Whilst this process does correspond to the effectively permanent sequestration of CO2 in a solid form, this is a reaction that happens naturally—albeit at an exceptionally slow rate. Accelerating the rate of these reactions requires mining (or other collection process), transporting, crushing, grinding and handling of vast quantities of material suitable for carbonation. This requires very large quantities of decarbonized electricity—which then begs the question: is there not a more profitable purpose to which we could put this decarbonized electricity—electrification of heating, or charging an electric vehicle, for example, and allow the carbonation of this material to take place naturally, noting that this may take an extremely long time?\nFurthermore, whilst it is possible to convert CO2 into liquid fuels such as methanol for use in ground transport 41 , this would result in the near-immediate release of the CO2 to the atmosphere, and, although potentially reducing emissions relative to a baseline, cannot be considered to contribute directly and significantly to the CO2 mitigation challenge; capturing CO2 directly from a vehicle is unlikely to be feasible in the medium term.\nLeaving the toxicity of methanol to one side, at 43–44 GJ per tmethanol (ref. 42 ), the energy required to convert CO2 into methanol is substantial relative to the energy density of methanol (19.7 GJ per tmethanol). This corresponds to an energy return on energy invested (EROEI) 43 of approximately 0.45. More than 80% of this energy is associated with the generation of renewable electrolytic H2, with approximately 10% required for the capture of CO2 from a fossil-fired power station. If we were to consider the direct capture of CO2 from the air as the CO2 source, then one might expect the specific energy footprint of CO2-derived methanol to increase to the order of 60 GJ per tmethanol, or an EROEI of approximately 0.33. This represents a substantial quantity of renewable energy, which compares extremely poorly with the methanol's energy density (lower heating value basis), and could arguably be put to better use elsewhere.\nBy way of comparison, conventional coal and oil–gas production processes have an EROEI of approximately 46 and 20 respectively 44 , 45 , with wind, solar photovoltaic, geothermal, and biodiesel having an EROEI of approximately 18–20, 10, 9 and 2–5 respectively 44 , 46 .\nGiven that a fuel or energy needs an EROEI of at least 3 to be considered useful to society 43 , 44 , the energy required to produce methanol would have to be reduced by a factor of 6–10, depending on the source of the CO2, in order to become viable: this is a substantial challenge.\nThe relatively low energy density of methanol also presents substantial challenges to its use as a fuel. Gasoline has an energy density of 46.4 MJ per kg and upon combustion produces 3.09 kgCO2 per kg, whereas methanol has an energy density of 19.7 MJ per kg and upon combustion produces 1.38 kgCO2 per kg.\nAs can be observed from Fig. 3 , owing to the reduced energy density of methanol, its use as a fuel will result in the emission of approximately 5% more CO2 than would have otherwise been the case.\nFigure 3: The effect of blending methanol with gasoline.\nIt can be observed that, as methanol is added to gasoline, the energy density of the fuel decreases, whilst the CO2 footprint per unit of energy service delivered increases. Therefore, the substitution of methanol for gasoline will potentially increase the CO2 emissions associated with delivering that energy service.\nNext\nMoreover, the processes for converting CO2 to methanol do not have a perfect yield. There will be some fraction of CO2 purged from the process—typical numbers are 0.08 tCO2 purged and 0.67 tmethanol produced per tCO2 feedstock 42 . Consider, then, that 1 bbloil will yield 19 gallons of gasoline, and supply 2,469 MJ per bbloil, therefore emitting 164.46 kgCO2 per bbloil. To deliver the same amount of energy requires 125.36 kgmethanol per barrel of oil equivalent. When this methanol is combusted, and accounting for the CO2 that was emitted in the initial production of the methanol, this corresponds to approximately 188 kgCO2 per barrel of oil equivalent or approximately 14% more CO2 than would have been produced had conventionally-sourced crude oil been used. This demonstrates the difficulty in using methanol production as a carbon sequestration process.\nIn order to compare CO2-EOR and methanol production on the basis of energy service, we first recall that, depending on the version of EOR practiced 30 , between 1.1–3.3 bbloil per tCO2 are produced and that each bbl will produce 12 gallons of diesel and 19 gallons of gasoline, which delivers 4,284 MJ per bbloil. In the default CO2-EOR case, 3.3 bbloil per tCO2 are produced and where the EOR operation is optimized for storing CO2, this is reduced to 1.1 bbloil per tCO2.\nThis leads to the net emission of 0.43 and −52 tCO2 per tCO2 injected, respectively and delivering 4,760–14,279 MJ per tCO2 injected or between 0.03 and −0.11 kgCO2 per MJ ( Table 1 ). Displacing this service with CO2-derived methanol would require the production of 242–725 kgmethanol, leading to the emission of approximately 0.08 kgCO2 per MJ. Thus, from the perspective of both EROEI and a carbon balance, the utilization of CO2 for EOR would appear to be preferable to the conversion of CO2 to methanol. In all cases, CO2-derived methanol would appear to increase the quantity of CO2 emitted whilst delivering the same service and, under some circumstances, CO2-EOR can result in the net sequestration of CO2, whereas it does not appear that this is feasible with methanol.\nTable 1: Comparison of the CO2 footprint associated with CO2-EOR and CO2-derived methanol.\nAuthor information\nIn order to reduce global CO2 emissions to 80% of 1990 levels by 2050, it will be necessary to reduce anthropogenic emissions by approximately 42 GtCO2 per year by 2050 compared to a 1990 baseline in line with the IEA and IPCC scenarios. To achieve this, it is anticipated that, amongst other things, it will be necessary to sequester a cumulative 120–160 GtCO2 in the period to 2050 3 , 15 , 22 , or 16–20% of the cumulative mitigation challenge. This corresponds to a rate of CO2 sequestration of approximately 2.5 GtCO2 per year by 2030, increasing to 8–10 GtCO2 per year by 2050 3 , 15 , 22 , with further increases in the rate of sequestration in the period to 2100 1 .\nAs discussed previously, CO2-EOR is a potential sink for a substantial amount of CO2. One of the major barriers—if not the major barrier—to higher levels of CO2-EOR on a global basis is an insufficient supply of affordable CO2. In 2004, there was a supply shortfall of approximately 40 MtCO2 per year for CO2-EOR in the Permian Basin. Subsequently, between 2007 and 2010, an additional supply of approximately 5 MtCO2 per year was sourced in response to this demand 28 . This is very possibly the world's first example of a demand pull on anthropogenic CO2 capture. Recent years have seen a steadily increasing share of this CO2 supply being provided by anthropogenic sources; as of 2010 this was 12 Mt per year 12 . This represents a very significant rate of increase in the size of this industry, and we would cautiously suggest that a global rate of increase in CO2-EOR activity of 11% per year is feasible, given appropriate initial conditions such as secure supplies of CO2. From a baseline of approximately 0.06 GtCO2 per year used for CO2-EOR, this could grow to perhaps 26–27 GtCO2 per year in 2050. This could correspond to a cumulative total of approximately 40–60 GtCO2 injected, and 35–70 GtCO2 stored. As previously, this represents about 4–8% of the ~800 GtCO2 mitigation challenge by 2050.\nConcerning other options for CO2 conversion, data from some recent estimates of current and near-term market sizes is presented in Table 2 . It should be noted that the two largest sinks for CO2—urea and methanol—do not correspond to storing CO2 for any significant period of time. Similarly, the technological category appears to be a catch-all for CO2 utilization in food and drink manufacture, fire suppression, as an inerting agent and dry ice, and other miscellaneous activities. Again, these options do not correspond to long-term sequestration of CO2.\nTable 2: Present and short-term uses of CO2 based on production data and forecasts from ref. 35 .\n""","0.379396","""http://www.nature.com/nclimate/journal/v7/n4/full/nclimate3231.html""","[-0.178219,51.500505]"
"""Imperial_College_London""","""An Objective Evaluation of Characterisation Matrix for Two Wheeler Powertrain with Control Oriented Mathematical Model""","""An Objective Evaluation of Characterisation Matrix for Two Wheeler Powertrain with Control Oriented Mathematical Model\nPaper #:\nhttps://doi.org/10.4271/2015-01-1629\nCitation:\nDas, H., Evangelou, S., and Jabez Dhinagar, S., \""An Objective Evaluation of Characterisation Matrix for Two Wheeler Powertrain with Control Oriented Mathematical Model,\"" SAE Technical Paper 2015-01-1629, 2015, https://doi.org/10.4271/2015-01-1629 .\n17\nAbstract:\nThe objective of this paper is to estimate characteristics parameters of two wheeler powertrain with simulated vehicle model. The evaluation is applied to define required characteristics for future motor integrated powertrain. The main parameters for the characteristics matrix are Fuel consumption and NOx gas emission. In the 1st phase of work, a mathematical model for the complete powertrain is developed using suitable modelling approach for different sub-modules of the complete system. The objectives of the model are, to simulate dynamic power-flow from the engine to wheel and to simulate NOx gas emission. The powertrain model consists of a carburetted spark ignition (S.I) engine and gear transmission system. The S.I engine model is capable of simulating dynamic torque output of engine as well as the NOx gas emission. The model is experimentally compared with available test data of production ready engine from TVS Motor Company, India. The dynamic effects of change of ignition timing and fueling on torque output and NOx gas emissions are simulated based on this model and discussed on the paper. The paper adapted two types of transmission model, one with Continuous Variable Transmission (CVT) and other one with Fixed Geared Transmission. The mathematical model for the CVT system is developed to capture automatic gear shift actuation and power transfer to the wheel. The model simulates the toque control system of the driven pulley as well as speed control system of the drive pulley. The mathematical model for the fixed gear ratio system with wet clutch system is proposed to simulate the manual gear based powertrain. The above mentioned model demands computationally intensive resources due to presence of higher order dynamics, mathematical discontinuity and non-linear functions. So this model is not suitable for control design application. In 2nd phase of work, the model is converted to lower complexity control oriented model by using feed-forward approach. The control oriented model is capable of simulating the wheel torque fluctuation and NOx gas emission variation with the change of engine operating point. The main parameters for the characteristic matrix can be evaluated by simulating the above mentioned control oriented model in a drive cycle. In the 3rd phase of work, the control oriented vehicle model is coupled with a Driver model for drive cycle simulation. The main characteristic parameters for both the powertrain configurations are captured from the drive cycle simulation. The results of the simulation are categorized and discussed in the final phase of work. This best found values of two parameters for both the configurations are utilized to build the characteristics matrix.\nEvent:\n""","0.4299792","""http://papers.sae.org/2015-01-1629/""","[-0.178219,51.500505]"
"""University_of_Aberdeen""","""Europe as a multilevel federation: Journal of European Public Policy: Vol 24, No 4""","""Europe as a multilevel federation\nAbstract\nABSTRACT\nEuropean federalism must be conceived at multiple levels, not just that of the state and the EU. A regional level has emerged below and across the states, as a result of spatial rescaling: the migration of functional systems, political change and the institutionalization of the regional level. The sub-state region remains a contested space, both as to its territorial boundary and its control. The EU itself has used the regional level for the framing and implementation of its own policies. Regional politics are characterized by inter-regional competition. Demands for recognition and autonomy from below have added another dimension. There is not a uniform regional level of politics or policy but a variety of constructions of the region. Federalism helps us understand this changing dynamic, if it is seen not as a specific form of government but as a general principle of order, combining unity with diversity.\nKEYWORDS: Competition ,  federalism ,  regions ,  rescaling\nIntroduction\nAs the editors of this collection note, EU studies have been dominated by a division between intergovernmental and neo-functionalist perspectives. For the intergovernmentalist, the unit of analysis is the nation-state, often seen as a more-or-less unitary actor, but this risks reifying the state and seeing it as the sole interface between Europe and sectoral or territorial actors within states. Neo-functionalism overcomes this methodological statism but is criticized for its teleology and failure to explain what has actually happened. Both approaches eschew normative questions. The federalist perspective opens the European level as a political arena, examining policy-making and interest mediation and the complex relationships between national and European levels. It reintroduces normative issues like balancing power, subsidiarity, sovereignty, representation and solidarity.\nThis is a useful move but incomplete. If we are to apply federal perspective at the European level, then logically we must open up to other spatial levels, including the sub-state level. Yet the sub-state level is not a fixed and knowable set of units that might be captured by a federal-type constitution, but a highly heterogeneous and shifting field. Spatial rescaling is altering the relationships between function, political mobilization and institutions. European integration and regional government can be seen as twin efforts to recapture policy fields that have escaped the purview of nation-states but, as Livingston ( 1952 Livingston, W.S. (1952) ‘A note on the nature of federalism’, Political Science Quarterly 67(1): 81–95. doi: 10.2307/2145299 [Crossref] , [Web of Science ®]   [Google Scholar] ) noted, there is often a disjunction between federal institutions and underlying sociological patterns. Rescaling upwards and downwards are contested projects, which cannot be resolved by reference to purely functional arguments.\nThe importance of the sub-state level has been emphasized in a series of debates around the Europe of the Regions; the territorial perspective on EU policy and delivery; the impact of Europe on intra-state federalism; the potential for accommodating self-determination claims within the overarching European framework; and the representation of territorial interests in the EU policy process. There is a search for mechanisms to institutionalize this ‘third level’, but they have reached no resolution. The multilevel governance approach opens up the black box of the state and emphasizes complexity, but it has weak ontological and normative foundations. The federal perspective has the analytical advantage of focusing on relationships among territory, function and institutions while also addressing normative issues including representation, sovereignty and solidarity. It must, however, take account of recent developments in federal theory, which historicize it and point away from the US model. That is the point of departure for this paper, which sees federalism as a set of analytical principles, rather than a fixed form of government. Europe is not a federation in most recognizable senses but federalism can help us to understand its territorial dimension. In the following I develop this by means of the notion of rescaling.\nRescaling Europe\nModernist social science long predicted the eclipse of territory as a principle of social organization (Durkheim [ 1964 Durkheim, E. (1964) The Division of Labour in Society,\nNew York\n: Free Press.  [Google Scholar] ]). Accounts of state-building saw it as a process of territorial integration and functional differentiation in which politics followed behind social change. For Deutsch ( 1972 Deutsch, K.W. (1972) Nationalism and Social Communication: An Inquiry Into the Foundations of Nationality,\nCambridge\n,\nMA\n: MIT Press.  [Google Scholar] ), this would reach its limits when one nation-building project met another or when cleavages were so deep as to force the establishment of another state. As Rokkan ( 1999 Rokkan, S. (1999) State Formation, Nation-Building and Mass Politics in Europe. The Theory of Stein Rokkan, edited by Peter Flora, Stein Kuhnle and Derek Urwin,\nOxford\n: Oxford University Press.  [Google Scholar] ) showed, however, some of the major social fault-lines continued to run through states. A conceptual map of Europe could be drawn that was not confined to the boundaries between states but recognized the underlying complexities. The idea that territory would disappear as a principle of social organization resurfaced in the aftermath of the Cold War, with a spate of publications around the theme of the end of territory or the borderless world (Badie [ 1995 Badie, B. (1995) La fin des territoires. Essai sur le désordre international et sur l’utilité social du respect,\nParis\n: Fayard.  [Google Scholar] ]; Ohmae [ 1995 Ohmae, K. (1995) The End of the Nation State: The Rise of Regional Economies,\nNew York\n: The Free Press.  [Google Scholar] ]). Most of these in fact referred to the end of the state as the dominant marker of territory as seen in realist accounts of international relations, and belong in the broad category of globalization studies. If we detach territory conceptually from the nation-state, however, we get a more complex picture. There was less a de-territorialization of economic and social systems than a re-territorialization as functions and political articulation were moving to new scales above across, and below the state. This is the process of rescaling, in which territory not only survives as a legacy of the past but is continually reproduced (Brenner [ 2009 Brenner, N. (2009) ‘Open questions on state rescaling’, Cambridge Journal of Regions, Economy and Society 2(1): 123–39. doi: 10.1093/cjres/rsp002 [Crossref] , [Web of Science ®]   [Google Scholar] ]; Jessop et al. [ 2008 Jessop, B., Brenner, N. and Jones, M. (2008) ‘Theorizing socio-spatial relations’, Environment and Planning D: Society and Space 26: 389–401. doi: 10.1068/d9107 [Crossref] , [Web of Science ®]   [Google Scholar] ]; Keating [ 2013 Keating, M. (2013) Rescaling the European State. The Making of Territory and the Rise of the Meso,\nOxford\n: Oxford University Press. [Crossref]   [Google Scholar] ]).\nThe best documented forms of rescaling are functional, in which economic and social systems are escaping the purview of the state and migrating to new levels. There is a substantial literature on economic rescaling at the global level, focused on the internationalization of markets, free flows of capital, a new international division of labour and the rise of global corporations. Transnational free trade regimes and global trading rules are both cause of, and reaction to, these processes. There is a literature on the rise of sub-state regions as economic spaces and frames for understanding economic change. Some of this is rooted in spatial location theory, economies of proximity and transport costs (Krugman [ 2011 Krugman, P. (2011) ‘The new economic geography, now middle-aged’, Regional Studies 45(1): 1–7. doi: 10.1080/00343404.2011.537127 [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ]). Institutional versions focus on the provision of public goods and the balance between competition and cooperation in fostering growth. These fade into sociological explanations, based on social capital and behaviour, and into cultural explanations rooted in historically conditioned social norms. Regions and localities are presented as not merely locations of production but as production systems (Crouch et al. [ 2001 Crouch, C., Le Galès, P., Trigilia, C. and Voelzkow, H. (2001) Local Production Systems in Europe. Rise or Demise?,\nOxford\n: Oxford University Press.  [Google Scholar] ]). A further move is to see these regional systems as being in competition with each other in global markets. The argument is that Ricardian comparative advantage, in which each region has its place in the global division of labour, has given way to absolute or competitive advantage (Scott [ 1998 Scott, A. (1998) Regions and the World Economy. The Coming Shape of Global Production, Competition, and Political Order,\nOxford\n: Oxford University Press.  [Google Scholar] ]). While this idea has been challenged intellectually (on the grounds that it reifies the region and that only firms compete), the theme of territorial competitiveness has been taken up by states, the European Commission and international organizations.\nWelfare has been linked to the nation-state since this is the focus both of affective solidarity and of social compromise and provides the institutional infrastructure for welfare programmes. Yet as the field of welfare itself reconfigures to adapt to changing demographic structures and new social risks, there is a rescaling, to sub-state and transnational levels (Ferrera [ 2005 Ferrera, M. (2005) The New Boundaries of Welfare,\nOxford\n: Oxford University Press. [Crossref]   [Google Scholar] ]; Kazepov and Barberis [ 2008 Kazepov, Y. and Barberis, E. (2008) ‘La dimensione territoriale delle politiche sociali in Europa: alcune riflessioni sui processi di rescaling e governance’, Revista Delle Politiche Sociali 3: 51–78.  [Google Scholar] ]). Other examples of functional rescaling include the simultaneous localization and internationalization of higher education, or the way in which urban dynamics challenge old conceptions of the functions of government or social stratification (Keating [ 2013 Keating, M. (2013) Rescaling the European State. The Making of Territory and the Rise of the Meso,\nOxford\n: Oxford University Press. [Crossref]   [Google Scholar] ]).\nThere is a corresponding rescaling of systems of regulation and policy-making. It is tempting to see the rescaling of government as a response to functional imperatives, as in the neo-functionalist approach. Alesina and Spoloare ( 2003 Alesina, A. and Spoloare, E. (2003) The Size of Nations,\nCambridge\n,\nMA\n: MIT Press.  [Google Scholar] ) explain the ‘size of nations’ by reference to functional imperatives, arguing that the benefits of scale that existed in an earlier age have disappeared because of open markets and transnational order, so that smaller units are viable and desirable. Ohmae ( 1995 Ohmae, K. (1995) The End of the Nation State: The Rise of Regional Economies,\nNew York\n: The Free Press.  [Google Scholar] ) similarly describes a (rather imaginary) world of small competing ‘regional states’ as the inexorable consequence of functional change and globalization. Hooghe and Marks ( 2009 Hooghe, L. and Marks, G. (2009) ‘Does efficiency shape the territorial structure of government?’, Annual Review of Political Science 12: 225–41. doi: 10.1146/annurev.polisci.12.041107.102315 [Crossref] , [Web of Science ®]   [Google Scholar] ) invoke functional arguments to explain (at least partially) decentralization and the division of competences within states. Yet there is a danger here of a functionalist trap. Purely functional arguments risk becoming teleological in that the beneficial outcome is seen as the cause of the change that it followed. What is needed is a mechanism by which the functional requirements can impose change. So a variant of the functionalist argument is that changes in the level at which activities are regulated are a response by policy makers to considerations of efficiency. This moves the argument away from causes to reasons but reasons are never simply given by neutral consideration of efficiency; they always have some underlying normative principle. So public choice exponents have preferred smaller units of government so that they will compete and align preferences with territory (Tiebout [ 1956 Tiebout, C. (1956) ‘A pure theory of local expenditures’, Journal of Political Economy 64: 416–24. doi: 10.1086/257839 [Crossref] , [Web of Science ®]   [Google Scholar] ]); others have preferred larger units to constrain competition and allow redistribution. Interests are also at stake, since some may be better connected to particular scales than others and boundaries of territorial jurisdictions may be drawn to favour specific social groups.\nBoth European integration and decentralization are better appreciated not as a functional imperative but as a design on the part of state actors to recapture and regulate functions that have escaped their purview as a result of rescaling and to impose a specific logic on to them. If this is presented as a matter of technical imperatives, that may be a rationalization for more normative objectives or in an effort to depoliticize difficult policy spheres, especially when they can be taken both out of contested politics and to a spatial scale that itself is insulated from direct political contestation. So in the Eurozone monetary policy has been taken up to the supranational level and also, in conformity with contemporary professional wisdom, placed in the hands of an independent institution. At the sub-state regional level, development policy has often been depoliticized, entrusted to agencies and ad hoc bodies with the single goal of competitive growth. An example is the repeated efforts to establish a regional level of planning and intervention in England, stopping short of devolving political power. 1 1.  In the 1960s there were regional planning boards and councils: in the 1970s metropolitan counties (abolished in the 1980s); in the 1980s Urban Development Corporations; in the 1990s Regional Offices; in the 2000s regional development agencies and unelected councils; now there are city regions looking like the metropolitan counties but with only one elected official, the mayor. View all notes In France, the state has consistently sought to reinforce its own territorial administration to match any political decentralization.\nDe-politicization is rarely effective in the long term, given patterns of social stratification and conflict and the distributive effects of any given policy or strategy. So we see a re-politicization of the new spaces emerging at various territorial levels and a contestation over their boundaries, their social significance and their institutionalization. Opposition movements may mobilize at the sub-state level where they are weak at the centre. Autonomist and identitarian movements map onto territory, creating a bottom-up regionalism. Faced with the need for functional capacity on the one hand, and bottom-up pressures for more popular input, contestation of priorities and legitimation on the other, many states have instituted an intermediate, regional or ‘meso’ level of government (Keating [ 1998 Keating, M. (1998) The New Regionalism in Western Europe. Territorial Restructuring and Political Change,\nCheltenham\n: Edward Elgar.  [Google Scholar] , 2013 Keating, M. (2013) Rescaling the European State. The Making of Territory and the Rise of the Meso,\nOxford\n: Oxford University Press. [Crossref]   [Google Scholar] ]; Swenden [ 2006 Swenden, W. (2006) Federalism and Regionalism in Western Europe,\nBasingstoke\n: Palgrave. [Crossref]   [Google Scholar] ]). There also is a rescaling of the representation of social and economic interests and their reconfiguration at new levels, in response both to functional rescaling and the establishment of regional government (Keating and Wilson [ 2014 Keating, M. and Wilson, A. (2014) ‘Regions with regionalism? The rescaling of interest groups in six European States’, European Journal of Political Research 53(4): 840–57. doi: 10.1111/1475-6765.12053 [Crossref] , [Web of Science ®]   [Google Scholar] ]). So the new spaces are ‘filled in’ socially and politically and the political agenda is structured in different ways. In the 1980s and 1990s it was argued that Europe had regions without regionalism as the formal structures of administration did not correspond with any sociological reality (Le Galès [ 1997 Le Galès, P. (1997) ‘Gouvernement et gouvernance des regions: faiblesses structurelles et nouvelles mobilisations’, in P. Le Galès and C. Lequesne (eds), Les paradoxes des regions en Europe,\nParis\n: La Découverte, pp. 237–64.  [Google Scholar] ]; Pastori [ 1980 Pastori, G. (1980) ‘Le regioni senza regionalismo’, Il Mulino 10(2): 268–83.  [Google Scholar] ]; Trigilia [ 1991 Trigilia, C. (1991) ‘The paradox of the region: economic regulation and the representation of interests’, Economy and Society 20(3): 306–27. doi: 10.1080/03085149100000015 [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ]); now the regionalism is there (Keating and Wilson [ 2014 Keating, M. and Wilson, A. (2014) ‘Regions with regionalism? The rescaling of interest groups in six European States’, European Journal of Political Research 53(4): 840–57. doi: 10.1111/1475-6765.12053 [Crossref] , [Web of Science ®]   [Google Scholar] ]). As emerging spaces are politicized and excluded groups seek entry into the governing arrangements, the political agenda is broadened. State regional policies focused on economic development in a narrow economic sense are challenged in respect of their social and environmental impact.\nIn this way, regions are constituted as political communities. This does not mean, pace Alesina and Spoloare ( 2003 Alesina, A. and Spoloare, E. (2003) The Size of Nations,\nCambridge\n,\nMA\n: MIT Press.  [Google Scholar] ), homogeneous spaces in which people share the same policy preferences or ethnic identity. A political community, rather, is a frame of reference for deliberation and social compromise. There is a parallel here with the European project, operating at a new supranational level, which has also been progressively politicized. Just as we get different visions of Europe – market driven, social, technocratic, instrumental, cultural and so on, so regions are constructed and imagined differently. Their construction and meaning is thus contested and highly political. Their territorial boundaries are similarly not pre-given but reflect political preferences and power relations.\nRescaling has also been induced by the EU’s own spatial policies, which were introduced (as regional, then structural and then cohesion policy) in order to correct the tendency of the single market to concentrate development and exacerbate territorial disparities. In the early days, it was assumed that the single market would eliminate territorial disparities as goods, services, capital and labour could move freely, so that each territory would specialize on the basis of comparative advantage. From the 1970s it was apparent that this was not happening and support grew for an explicit policy of territorial equalization across the Community. This coincided with the increasing difficulty that states experienced in using regional policies to integrate their national territory economically. Diversionary policies are expensive and difficult when firms can relocate elsewhere in Europe or outside Europe, one of the factors encouraging competitive regionalism. European competition policy itself bars state aid, including regional subsidies, except under strict conditions. The resulting disparities created pressure for the EU itself to enter the field with its own spatial policies.\nFrom its beginnings in the 1970s, the instrument was contested among the European Commission, member states and regional governments, with a Europeanization and then a partial renationalization (Hooghe and Keating [ 1994 Hooghe, L. and Keating, M. (1994) ‘The politics of European Union regional policy’, Journal of European Public Policy 1(3): 367–93. doi: 10.1080/13501769408406965 [Taylor & Francis Online]   [Google Scholar] ]). It was torn between a social rationale, as a territorial compensation measure, and an economic one, as efficiency-enhancing. In recent years, the Commission has emphasized territorial competitiveness, in line with current thinking. It has also sought a territorial perspective on other policy instruments, including planning, research and environment, but this has not progressed far, given the reluctance of sectorally based directorates to accept a spatial approach. Regional policy is frequently in conflict with competition policy, which is more strongly embedded in the institutions and enforced by the Court of Justice.\nIn elaborating and especially in implementing its spatial policies, the Commission has sought territorial collaborators and partnerships including regional governments, economic actors and civil society. This has the effect of increasing the salience of the regional and local level and creating links between it and the EU itself. During the 1990s, it was sometimes imagined that the Commission’s aim was to restructure territorial government, bring regions into being or even by-pass the nation-state, but this was misleading (Keating et al. [ 2015 Keating, M., Hooghe, L. and Tatham, M. (2015) ‘Bypassing the nation-state? Regions and the EU policy process’, in J. Richardson and S. Mazey (eds), European Union: Power and Policy, 4th edn.,\nLondon\n: Routledge, pp. 445–66.  [Google Scholar] ]). The Commission was concerned above all to strengthen the capacity for delivering policy and, if this meant strengthening the centre, then they pressed for that, as in the new accession countries in 2004 (Hughes et al. [ 2004 Hughes, J., Sasse, G. and Gordon, C. (2004) Europeanization and Regionalization in the EU’s Enlargement to Central and Eastern Europe,\nBasingstoke\n: Palgrave. [Crossref]   [Google Scholar] ]; Keating and Hughes [ 2003 Keating, M. and Hughes, J. (2003) The Regional Challenge in Central and Eastern Europe. Territorial Restructuring and European Integration, Brussels: Presses interuniversitaires européennes/Peter Lang.  [Google Scholar] ]). In much of Western Europe, however, structural policy was represented by local politicians as the fruit of their own efforts in Brussels, creating a vision of regions operating in European space. It was also true that in many cases the Commission and the regions shared a common interest in denationalizing the policy and ensuring that the moneys flowed as directly as possible from Brussels to the regions.\nSo neither the nation-state nor the European Union has experienced a straightforward functional imperative to territorial integration and homogenization. On the contrary, they have promoted territorial differentiation in new forms. The conjuncture of rescaling towards Europe and down towards the regions has created multiple levels of politics and of authoritative decision-making, which escape the logic of EU-state relationships. It has posed a challenge to traditional efforts to understand the European Union based on either intergovernmentalism or a federalism based on the member states. These issues fed into a set of movements around a Europe of the Regions, or the politics of three-levels (Bullman [ 1994 Bullman, U. (1994) Die Politik der dritten Ebene. Regionen im Europa der Union, Baden-Baden: Nomos.  [Google Scholar] ]). This was a very diverse project, whose common aim was to find a place for sub-state regions in the emerging transnational order, with a strong orientation towards European federalism as an alternative to intergovernmentalism. The movement culminated in the 1990s. Regions gained little from the Convention on the Future of Europe, where the Committee of the Regions was present with observer status, or from the subsequent Lisbon treaty, and the movement declined after that.\nMultilevel governance or multilevel federalism\nOne conceptualization of the emerging spatial order, and alternative to both intergovernmental and neo-functionalist accounts, has been that of multilevel governance (Bache and Flinders [ 2004 Bache, I. and Flinders, M. (eds) (2004) Multi-level Governance,\nOxford\n: Oxford University Press. [Crossref]   [Google Scholar] ]; Hooghe and Marks [ 2001 Hooghe, L. and Marks, G. (2001) Multilevel Governance and European Integration,\nLanham\n,\nMD\n: Rowman & Littlefield.  [Google Scholar] ]; Piattoni [ 2010 Piattoni, S. (2010) The Theory of Multi-Level Governance. Conceptual, Empirical, and Normative Challenges,\nOxford\n: Oxford University Press. [Crossref]   [Google Scholar] ]). The idea is that power has been pulled out of the state, both laterally, by the implication of non-governmental actors in policy-making, and vertically by the emergence of new territorial levels so that networks span both the public-private and the territorial divides. This has the virtue of addressing the complexity of modern policy-making and regulation, taking us back to the ideas, rooted in classical sociology and theories of local government (Maas [ 1959 Maas, A. (1959) ‘Divisions of powers: an areal analysis’, in A. Maas (ed.), Area and Power: A Theory of Local Government,\nGlencoe\n: Free Press, pp. 22–36.  [Google Scholar] ]), that social systems are differentiated functionally and territorially, but without the teleological assumption of much modernization theory, that function would overcome territory.\nIt is not clear, however, that multilevel governance provides the analytical, ontological or normative tools to address these issues. The concept of governance itself is notoriously loose. Sometimes it is a broader than government, referring to social order in general, with government as a sub-category (Pierre and Peters [ 2000 Pierre, J. and Peters, B.G. (2000) Governance, Politics and the State,\nBasingstoke\n: Palgrave.  [Google Scholar] ]). Sometimes it is narrower, a form of regulation based on networks rather than hierarchy (Bellamy and Palumbo [ 2010 Bellamy, R. and Palumbo, A. (eds) (2010) From Government to Governance,\nLondon\n: Ashgate.  [Google Scholar] ]). This, however, poses an ontological problem. Network governance, derived as it is from organization theory, takes as its unit of analysis organizations or actors within them, but these remain socially disembedded, rather than corresponding to broader patterns of social stratification. Second, governance lacks a theory of power, focusing on interaction and cooperation in networks but without providing tools to explore who wins and loses and how. It seems better designed for consensus management than social conflict, which is no doubt why the concept has been appropriated by international agencies set on depoliticization. Third, governance theories lack a normative dimension, which would allow us to pose questions about democracy, participation, accountability and distribution. There is sometimes an implicit normativity, but this cuts both ways. On the one hand, it is suggested that network or corporatist governance are somehow more participative, although this remains empirically unproven (Smismans [ 2006 Smismans, S. (2006) New Modes of Governance and the Participatory Myth, European Governance Papers (EUROGOV) N-06-01, www.connex-network.org   [Google Scholar] ]). On the other hand, there is an argument that it undermines representative elected government. Fourth, if governance is seen as the interlinking of public and private power, then it is not clear that it adds to studies of interest group politics, neo-corporatism and social concertation. Multilevel governance approaches, moreover, lack of a theory of territory; indeed, the concept of level seems to be used in a very imprecise way. Multilevel governance works tend to confine the vertical level to relations among institutions of different territorial reach, without embracing the deeper implications of territory and scale.\nOf course, it may just be that the very lack of conceptual precision around multilevel governance makes it attractive in the absence of a clear way of thinking about the organization of space. In this sense, it describes a negative, the escape of functional systems from existing forms of regulation and politics and from existing territorial boundaries, rather than to a particular mode of governing or regulation.\nIf intergovernmentalism, neo-functionalism and multilevel governance cannot capture the emerging complex, multiscalar order in Europe, federalism may serve better as a way both of analyzing and appraising it. Yet we must note the editors’ warnings on how federalism is to be interpreted. It is not to be seen as confined to states or, especially, to the experience of the United States of America. Federalism is a broad principle not to be confused with federation as a specific constitutional design (King [ 1982 King, P. (1982) Federalism and Federation,\nBaltimore\n: The Johns Hopkins University Press.  [Google Scholar] ]). It is an analytical device but also has a normative underpinning, based on values including shared rule, self-rule and solidarity. It does address some of the ontological weaknesses of multilevel governance in that the focus is on government as authoritative decision making. Federalism is about dividing and sharing power at a territorial level and the relationship between those levels. There is an emphasis on territory, enriched if federalism is combined with the insights of rescaling theory. Federalism does address normative issues including legitimacy and sovereignty and electoral consent. It incorporates arguments about citizenship and representation.\nFederalism comes in different forms, as recognized in the literature (Burgess [ 2006 Burgess, M. (2006) Comparative Federalism. Theory and Practices,\nLondon\n: Routledge.  [Google Scholar] , 2012 Burgess, M. (2012) In Search of the Federal Spirit. New Theoretical and Empirical Perspectives in Comparative Federalism,\nOxford\n: Oxford University Press. [Crossref]   [Google Scholar] ]). There is a distinction between coordinate and cooperative federalism, with a newer variant, competitive federalism. There is also a debate about whether federalism requires a unitary national identity or whether it can usefully be applied in plurinational polities. These debates are highly pertinent to the debate about rescaling.\nCoordinate, cooperative and competitive federalism\nThere is a classic distinction between coordinate federalism, in which competences are clearly divided between the levels, and cooperative federalism, in which they are shared. In some respects, Europe challenges both varieties by undermining existing federal or quasi-federal arrangements within member states with a significant meso level. This includes Germany, Austria, Belgium, Spain, the United Kingdom and to a lesser extent Italy and other states. Competences belonging to the regional level have been Europeanized, which results in a double loss of power for the regions. The European Union may encroach on regional competences, so taking away what the state has conceded. At the same time states can re-enter these policy fields since it is they who are represented in the Council of the EU. In the 2000s, Europeanization has also penetrated down to the local and regional level through its requirement for debt and deficit limits, which apply to all levels, while it is the state that is responsible for ensuring compliance internally.\nRegional responses have alternated between seeking to protect their own competences (in coordinate mode) and seeking entry into European policy-making (in cooperative mode) – between ‘leave us out and ‘let us in’ (Jeffery [ 2005 Jeffery, C. (2005) ‘Regions and the European Union: letting them in and leaving them alone’, in S. Wetherill and U. Bernitz (eds), The Role of Regions and Sub-National Actors in Europe,\nOxford\n: Hart, pp. 33–46.  [Google Scholar] ]). Some regions, including the German Länder, have been at pains to curtail European interventions in their reserved spheres, coinciding with a push to simplify German federalism itself and reduce its coordinate elements. It was pursued by seeking application of the principles of subsidiarity and proportionality embodied in the treaties at the regional level rather than stopping at the states. Provisions were incorporated into the Lisbon Treaty but the mechanisms to enforce this are weak. The main thrust, however has been for regions to seek to get into the EU policy process (‘let us in’).\nTo the functional and institutional arguments for involvement, regional advocates added some normative ones, claiming that regional governments were democratically elected and thus had a higher legitimacy than other organizations lobbying in Brussels and even than the Economic and Social Committee; stronger regions could also make a contribution to realizing the aim of subsidiarity. Enhancing their influence would address the democratic deficit, bringing government closer to the citizen.\nProvisions for the participation of regions in EU policy were made in the (Maastricht) Treaty on European Union through two channels: directly into the EU and via member states. The Committee of the Regions was established as a consultative body with the same status as the Economic and Social Committee. Some enthusiasts saw it as an embryonic territorial third legislative chamber. Its scope was subsequently expanded to cover a wider range of policy areas and to include the European Parliament as well as the Commission but it remains purely consultative. Its other principal weakness lies in the variation of what constitutes a region across the different EU states. There are federal units, such as the German Länder, which have a defined role in national policy making. There are devolved regions such as those in Spain and Italy, with their own power but not formally part of a federal system. The alliance of Regions with Legislative Powers was an effort to stake out a distinct position but the meaning of ‘legislative powers’ differs from one state to another and the distinction was more political than legal. There are cities, which have insisted on parity of status with regions, although their competences are different. Then there are stateless nations, which sought to play the Europe of the Regions card while also insisting on their own specificity (see below). Cities insisted that they were as important as regions and should have the same status.\nThe main channel for participating via the member states is a provision that, where regional governments exist with a ministerial structure 2 2.  This is subtly different from a legislative region although it may amount to the same thing in pointing to a differentiation of executive from legislature. View all notes they can, where national law permits, represent their state in the Council of the European Union. They do not, however, represent themselves and representation is confined to matters of regional competence. Provisions for determining the line to take in negotiation vary from Belgium, where each federal unit has a veto, through Germany, where the Länder agree a position among themselves, to the United Kingdom, where the central government has the final say.\nThe European Commission has, for its part, sought to incorporate regions into the policy process, both to increase policy effectiveness and to enhance its visibility and legitimacy at the sub-state level. It insists that its collaborators should not merely be regional governments but the social partners as well.\nIn recent years, coordinate and cooperative federalism have been joined by a third variety, competitive federalism (Dente [ 1997 Dente, B. (1997) ‘Federalismo e politiche pubbliche’, in A. Martelli (ed.), Quale federalismo per l’Italia? Terzo rapporto sulle priorità Nazionali,\nMilan\n: Fondazione Rosselli/ Mondadori, pp. 189–205.  [Google Scholar] ]). Federated units compete in two senses: they seek to innovate in policy; and they compete economically, notably for inward investment and technological advantage. The latter draws upon ideas of competitive regionalism, in which regions are conceived of not merely as spaces of production but as production systems in a world that is moving from traditional ideas of comparative advantage towards absolute advantage (Scott [ 1998 Scott, A. (1998) Regions and the World Economy. The Coming Shape of Global Production, Competition, and Political Order,\nOxford\n: Oxford University Press.  [Google Scholar] ]). Whether regions (as opposed to firms) actually do compete is a matter on which economists disagree so that territorial competition is a political construction, postulating a common territorial interest, alongside or displacing sectoral and class conflicts. The idea is attractive to regional politicians, who can extend their appeal to the entire population using a type of neo-mercantilist rhetoric. The idea of territorial competition is also used by states and the European Commission as a way of disengaging from difficult distributive issues and exploiting the positive connotations of competition in the modern era. European spatial policy is increasingly justified by a rhetoric of competitiveness (Begg [ 2010 Begg, I. (2010) ‘Cohesion or confusion: a policy searching for objectives’, Journal of European Integration, 32(1): 77–96. doi: 10.1080/07036330903375115 [Taylor & Francis Online]   [Google Scholar] ]), even to the paradoxical recommendation, inspired by the work of Porter ( 2001 Porter, M. (2001) ‘Regions and the new economics of competition’, in A.J. Scott (ed.), Global City Regions. Trends, Theory, Policy,\nOxford\n: Oxford University Press, pp. 139–57.  [Google Scholar] ) that all regions should become more competitive although logically this is impossible.\nCompetitive federalism is thus a normatively charged notion. If not controlled, it may provoke a ‘race to the bottom’, as governments cut taxes and attract firms and wealthy taxpayers, so undermining solidarity and welfare systems (Volden [ 2002 Volden, C. (2002) ‘The politics of competitive federalism: a race to the bottom in welfare benefits?’, American Journal of Political Science 46(2): 352–63. doi: 10.2307/3088381 [Crossref] , [Web of Science ®]   [Google Scholar] ]). In the traditional European welfare state, this was restrained by the centralization of key tax powers and systems of territorial redistribution. These relied on conceptions of national solidarity as well as more instrumental considerations. So within a national market, transfers from wealthy to poor regions could be accepted to the degree that the money came back to the wealthy regions in the form of orders for their goods. Spatial balance could enhance national efficiency by addressing market imperfections that resulted in congestion in some regions and under-used capacity in others. If regions are competing within European space rather than cooperating in national space, these factors are weakened.\nMore broadly, the European project may be separating previously linked policy spheres and undermining national welfare bargains. Bartolini ( 2005 Bartolini, S. (2005) Restructuring Europe. Centre Formation, System Building, and Political Structuring Between the Nation State and the European Union,\nOxford\n: Oxford University Press. [Crossref]   [Google Scholar] ) has drawn attention to the tensions that the new European division of competences provokes. Market regulation is taken up to the European level, while market compensation in the form of welfare states remains national. National social compromises unravel as selected actors (notably mobile business) can exercise ‘partial exit’ by upscaling to the European level or moving out altogether. We can extend this analysis to the sub-state level, where there is a further disarticulation of policy spheres by territory. Regions, even more than states, are borderless spaces, from which wealthy taxpayers and investors may rather easily relocate.\nTheories of fiscal federalism address this issue by advocating that redistributive policies should be located at the highest level. Non-redistributive policies, about the allocation of local public goods on the basis of local preferences, on the other hand, could be decentralized, so meeting the criterion of allocative efficiency (Oates [ 1999 Oates, W.E. (1999) ‘An essay on fiscal federalism’, Journal of Economic Literature 37(3): 1120–49. doi: 10.1257/jel.37.3.1120 [Crossref] , [Web of Science ®]   [Google Scholar] ]). The EU, however, has a weak redistributive capacity. Cohesion policy is the main instrument, but the Commission has to justify even this in the name of competitiveness. Wasteful competition is regulated in Europe by the competition policy, whose state aids rules powerfully constrain the ability of both states and non-state governments to subsidize investment; but there are frequent complaints that this restrains their ability to sustain vital public services. State aid rules have been invoked to strike down subsidies for the proliferation of regional airports and low-cost airlines, but have also, for example, affected the ability of governments to cross-subsidize vital ferry services to fragile communities.\nMoreover, the old distinctions among production-enhancing, redistributive and allocative policies are breaking down with the recognition that all public policies have a distributive impact (Keating [ 2013 Keating, M. (2013) Rescaling the European State. The Making of Territory and the Rise of the Meso,\nOxford\n: Oxford University Press. [Crossref]   [Google Scholar] ]). So it is not sufficient to argue that the redistributive capacity should be concentrated at the level of the nation state. If solidarity is important, it needs to be built in to all levels as well as into the system of relationships among the levels. The trick for European federalism would thus be to provide incentives for the ‘race to the top’ in social provision that has also been seen in some member states (Gallego and Subirats [ 2011 Gallego, R. and Subirats, J. (2011) ‘Comporta el desplegament autonòmic un augment de les desigualtats a Espanya? Descentralització, polítiques de benestar i justicia social’, in R. Gallego and J. Subirats (eds), Autonomies i desigualtats a Espanya: Perceptions, evolució social i polítiques de benestar,\nBarcelona\n: Institut d’Estudis Autonómics, pp. 23–31.  [Google Scholar] ]). Arguments about rescaling and regions in Europe thus intersect with arguments about the social dimension. Federalism, as the editors note, is about differentiation but it is also about solidarity. This is recognized in the incorporation into the Lisbon Treaty of the objective of territorial, alongside social and economic cohesion, but the redistributive capacity of the EU is weak compared with national federal systems.\nPlurinational federalism\nOne vision of federalism insists that there must be a unitary demos and telos so that there is no disagreement about the foundations of sovereignty and the federation can be symmetrical. This monist approach (Karmis and Norman [ 2005 Karmis, D. and Norman, W. (2005) ‘The revival of federalism in normative political theory in theories of federalism’, in D. Karmis and W. Norman (eds), Theories of Federalism. A Reader,\nNew York\n: Palgrave Macmillan, pp. 3–22. [Crossref]   [Google Scholar] ]) has been associated with writers from varied perspectives, including Carl Schmitt (Cyr [ 2010 Cyr, H. (2010) ‘Fédéralisme et le concept du politique chez Carl Schmitt: Le problème de l'homogénéité de l'unité politique et le pluralisme fédéral’, in M. Seymour (ed.), Plurinational Federalism,\nBrussels\n: P.I.E./Peter Lang, pp. 46–59.  [Google Scholar] ]) and later Tarlton ( 1965 Tarlton, C. (1965) ‘Symmetry and asymmetry as elements of federalism: a theoretical speculation’, Journal of Politics 27(4): 861–74. doi: 10.2307/2128123 [Crossref] , [Web of Science ®]   [Google Scholar] ). John Stuart Mill is often quoted in favour of the monist view but, while arguing for homogeneity as a favourable condition for federalism, he did concede that plural federations might be necessary in some circumstances (Mill [ 1972 Mill, J.S. (1972) Considerations on Representative Government,\nLondon\n: Dent.  [Google Scholar] ]). It is argued that asymmetrical federations are unstable and that units based on national distinctiveness will arrogate sovereignty to themselves and generate centrifugal and even separatist tendencies. This underlies objections in Canada, Spain and the United Kingdom (before the end of the twentieth century) to asymmetrical territorial government and a preference for either centralization or symmetrical devolution. The paradox is that federalism is ruled out as a way of addressing diversity.\nIn recent years, however, there is a literature questioning this and advocating the idea of multinational federalism and asymmetrical solutions (Burgess [ 2006 Burgess, M. (2006) Comparative Federalism. Theory and Practices,\nLondon\n: Routledge.  [Google Scholar] , 2012 Burgess, M. (2012) In Search of the Federal Spirit. New Theoretical and Empirical Perspectives in Comparative Federalism,\nOxford\n: Oxford University Press. [Crossref]   [Google Scholar] ]; Burgess and Gagnon [ 2010 Burgess, M. and Gagnon, A.-G. (eds) (2010) Federal Democracies,\nLondon\n: Routledge.  [Google Scholar] ]; Requejo [ 1999 Requejo, F. (1999) ‘Cultural pluralism, nationalism and federalism: a revision of democratic citizenship in plurinational states’, European Journal of Political Research 35: 255–86. doi: 10.1111/1475-6765.00449 [Crossref] , [Web of Science ®]   [Google Scholar] ]; Noël [ 2013 Noël, A. (2013) ‘Ideology, identity, majoritarianism: on the politics of federalism’, in G. Skogstad, D. Cameron, M. Papillon and K. Banting (eds), The Global Promise of Federalism,\nToronto\n: University of Toronto Press, pp. 166–87.  [Google Scholar] ]) and stressing the pluralist basis of federalism (Hueglin [ 2013 Hueglin, T. (2013) ‘Federalism and democracy: a critical reassessment’, in G. Skogstad, D. Cameron, M. Papillon and K. Banting (eds), The Global Promise of Federalism,\nToronto\n: University of Toronto Press, pp. 17–42.  [Google Scholar] ]). In these cases, federalism is possible in the absence of shared demos and telos, by mutual accommodation and effective institutions. Multinational federations may leave critical foundational issues (such as the locus of sovereignty) in abeyance and leave the future open-ended in a rescaling world where the ontological basis of self-government is itself shifting as new territorial scales are constructed and given meaning. It is consistent with a view of Europe that sees it as a work in permanent construction without a clear end state. It also implies relaxing assumptions about the automatic legitimacy of existing states as the only basis for Europe. Now that states themselves are challenged from above and below, they increasingly have to justify their own legitimacy. There have been debates about national identity in France, Spain, the Netherlands, Germany and the United Kingdom, while state-wide parties have insisted on the primacy of the state for security, control of migration or social solidarity. The fact that they have to make these arguments explicitly illustrates the point that there is no a priori reason to give normative supremacy to one level of another.\nEurope has seen a recurrence of autonomist, nationalist and secessionist movements challenging state claims, notably in Spain, Belgium and the United Kingdom but also in Italy. In central and eastern Europe, irredentist pressures challenge state boundaries, for example in the name of ethnic Hungarians in Romania and Slovakia. Many of these movements are based on historic territories, which have been repoliticized and draw on themes of the new regionalism and the European context to present themselves as viable economic units. In wealthier territories, there are complaints about the cost of subsidizing their poorer compatriots when they need to compete in Europe; such is the case in Catalonia, Flanders and northern Italy. There is no objective way of distinguishing nationalist from regionalist movements, but there is an important difference in their self-representation and demands. Movements adopt the language of nationalism to claim sovereignty, that is, original authority not derived from the state. They argue that they constitute a people or demos, which has a right to its own polity and to share in the construction of the European project. For some of these (like the Scottish National Party) Europe lowers the threshold for independence by externalizing costly policies, guaranteeing market access and increasing the viability of small states. They argue that if Malta or Cyprus can be full members of the European Union, there is no reason to exclude them merely because they do not presently have their own state.\nOther movements (including at various times moderate Flemish nationalists, Plaid Cymru, the Basque Nationalist Party, and until recently the Catalan Convergència i Unió) have seen in Europe an opportunity to move beyond the old nation-state model altogether and embrace a ‘post-sovereigntist’ vision of self-determination (Keating [ 2001 Keating, M. (2001) Plurinational Democracy. Stateless Nations in a Post-Sovereignty Era,\nOxford\n: Oxford University Press. [Crossref]   [Google Scholar] ]; MacCormick [ 1999 MacCormick, N. (1999) Questioning Sovereignty,\nOxford\n: Oxford University Press. [Crossref]   [Google Scholar] ]). This does not mean that sovereignty has disappeared but that it is transformed and is divided and shared, with multiple sources of original authority. The post-sovereigntist argument often looks back historically (Herrero de Miñon [ 1998 Herrero de Miñon, M. (1998) Derechos Históricos y Constitución,\nMadrid\n: Tecnos.  [Google Scholar] ]), especially in places where the monistic view of state sovereignty has never been universally accepted (Scotland and the Basque Country are examples). It also looks forward, as its exponents explicitly link the idea to a view of Europe as a political order in its own right, enjoying elements of original authority, not merely derivative of state sovereignty (MacCormick [ 1999 MacCormick, N. (1999) Questioning Sovereignty,\nOxford\n: Oxford University Press. [Crossref]   [Google Scholar] ]). It is more difficult to translate this into practice. Some have dreamed of a Europe of the Peoples without the existing states but this assumes that the peoples who would underpin this are easily identifiable. Challenged on what their final ambition is, Basque, Catalan and Flemish nationalist politicians will often throw the question back by asking where Europe is going, since that is the essential context\nEurope has had limited success in addressing the nationalities question. It has no common doctrine on the recognition of secessionist states in the wider European neighbourhood, as the confused response to the break-up of Yugoslavia showed. Some member states recognize the independence of Kosovo while others, struggling with internal tensions, do not. Within the EU, there is a similar reticence. There is no clear doctrine about secession within member states or what the European Free Alliance (representing minority nationalist parties) has called ‘internal enlargement’. Spokespersons for the European Commission and Council have argued that, were Catalonia to become independent, it would put itself outside the European Union. 3 3.  José Manuel Barroso, as Commission President, declared “La UE se basa en los tratados, aplicables únicamente a los Estados miembros que los han aprobado y ratificado. Si una parte del territorio de un Estado miembro dejase de ser parte de ese Estado para convertirse en un nuevo Estado independiente, los Tratados ya no serían aplicables en dicho territorio. En otras palabras, un nuevo Estado independiente, por el hecho de alcanzar la independencia, pasaría a convertirse en un tercer país con respecto a la UE y los Tratados dejarían de ser aplicables en su territorio.’ http://www.publico.es/politica/barroso-responde-mas-catalunya-quedaria.html View all notes Rather incongruously, this seems to accept that Catalonia could become independent in the first place and thus be outside both Spain and the EU. It would be more consistent to say that Catalonia cannot be outside the EU because it can never leave Spain. Commission President José Manuel Barroso declared that Scotland would put itself outside the EU and would find it difficult if not impossible to get back in (Andrew Marr Show, BBC Television, 16-02-2014); this despite the fact that the UK government itself had pledged to respect the result of the referendum. Weiler ( 2014 Weiler, J. (2014) ‘Scotland and the EU: a comment’, http://ukconstitutionallaw.org/2014/09/10/debate-j-h-h-weiler-scotland-and-the-eu-a-comment/   [Google Scholar] ) insists on a linear progression through the state to Europe so that Catalonia and Scotland must forfeit the right to be part of the European order should they democratically assume the sovereign status of Spain and the United Kingdom. In fact, there is a legal vacuum over the question of whether a seceding region could convert itself into a member state.\nWhile EU leaders have rejected the right of stateless nations to independence and membership of the Union, the EU has also failed to provide many opportunities for the expression of the post-sovereign perspective or plurinational and multilevel federalism as alternatives. There are opportunities for stateless nations acting as regions but the EU does not recognize a distinction between regional demands and self-determination claims. States wishing to accede to the EU have to respect the rights of national minorities but this ceases once they become members; the existing states have never wanted the principle applied to themselves.\nEurope has provided a new discursive space for the articulation of nationalist demands, linked to ideas of multinational federalism (Keating [ 2004 Keating, M. (2004) ‘European integration and the nationalities question’, Politics and Society 31(1): 1–22.  [Google Scholar] ]). Yet the promise that Europe could provide a plurinational federalism in which demands for recognition and autonomy could be accommodated without a proliferation of new states has been disappointed. States are more willing to agree to autonomy for internal nationalities but are insistent that accommodation must occur within their boundaries. The failure of Europe to provide new opportunities to express national diversity, as the post-sovereigntists have demanded, is one factor that has led nationalist movements back into support for classic independence, as the case of Catalonia.\nConcluding reflections: Europe as multilevel federation\nThe idea that Europe could or should be a federation in the American tradition is based, as the editors make clear, on a category error. Federalism is a principle that takes multiple institutional forms in different contexts. Similarly, a conception of Europe of the Regions in which the third level has a clearly articulated federal status, and constitutes one of the building blocks of the Union, is misplaced. Yet the federal principle can provide both analytical and normative leverage over the emerging multilevel politics. It draws attention away from a strictly statist ontology and towards the multiple levels of interest articulation, social compromise and policy resolution. It looks away from functionalism towards a more political explanation for institutional change. The new levels are not conceptualized merely as organizations in interaction but as political communities of greater or lesser cohesion and as governments resting on popular consent. Such communities are constructed in multiple ways in the process of rescaling and should not be reified or endowed with unitary interests but represent both political arenas and actors within a larger system. They have received some institutional recognition and are incorporated into cooperative policy processes, but are not strongly entrenched. They have succeeded in incorporating the federal principles of subsidiarity into the treaties, albeit in a weak form. The idea of competitive federalism is relevant for examining the politics of regions within the European market and the Commission’s spatial strategy. It coexists uneasily with the commitment to cohesion, as is the case in modern federations. The protagonism of regions, however, has been curtailed by the ‘new intergovernmentalism’ (Bickerton et al. [ 2015 Bickerton, C., Hodson, D. and Puetter, U. (2015) ‘The new intergovernmentalism and the study of European integration’, in C. Bickerton, D. Hodson and U. Puetter (eds), The New Integovernmentalism. States and Supranational Actors in the Post-Maastricht Era,\nOxford\n: Oxford University Press, pp. 1–48. [Crossref]   [Google Scholar] ]) in the EU, which has closed off opportunities for regions, which have always preferred the community method.\nThe principle of plurinational federalism has analytical value in examining the rise of autonomist movements that saw in the EU both a set of legitimating principles (shared sovereignty) and political and institutional opportunities to steer a third way between independence and union. States, however, have guarded their own sovereignty even as it has eroded in practice. EU policy-makers have avoided the issue, lacking the mandate or interest to intervene in matters of national sovereignty.\nDisclosure statement\n""","0.09309875","""http://www.tandfonline.com/doi/full/10.1080/13501763.2016.1273374""","[-2.099122,57.165019]"
"""Imperial_College_London""","""Optimal operation of freeway weaving segment with combination of lane assignment and on-ramp signal control: Transportmetrica A: Transport Science: Vol 12, No 5""","""Original Articles\nOptimal operation of freeway weaving segment with combination of lane assignment and on-ramp signal control\nAccepted author version posted online: 25 Jan 2016\nPublished online: 22 Feb 2016\nGet access /doi/full/10.1080/23249935.2016.1146927?needAccess=true\nABSTRACT\nLane assignment and on-ramp signal control are two potential methods for mitigating traffic congestion of weaving segments. Unlike methods in the existing literature, where the optimisation strategy is selected beforehand, this paper proposes an integrated optimisation model for a one-side weaving segment that explicitly takes into consideration the two optimisation strategies and their combinations. Therefore, the benefits and drawbacks of different design types could be fairly compared. A mixed-integer-non-linear programme is formulated to simultaneously optimise the optimisation strategy, lane markings, and signal timings. The results of extensive numerical and simulation analyses show that the proposed model could significantly improve the capacity of a weaving segment, especially under a high weaving volume ratio. Furthermore, the lane assignment strategy, combination of lane assignment and on-ramp control, and on-ramp signal control strategy may have better performances when the weaving volume ratio is low, medium, and high, respectively.\n""","0.595832","""http://www.tandfonline.com/doi/full/10.1080/23249935.2016.1146927""","[-0.178219,51.500505]"
"""Imperial_College_London""","""Multi-class dynamic traffic assignment with physical queues: intersection-movement-based formulation and paradox: Transportmetrica A: Transport Science: Vol 12, No 10""","""KEYWORDS: Multi-class dynamic traffic assignment ,  approach proportion ,  variational inequality ,  extragradient method ,  paradox\n1.  Introduction\nDynamic traffic assignment (DTA) is an important topic due to its wide applications in transport planning and management (Szeto and Lo 2006 Szeto, W. Y., and H. K. Lo. 2006. “Dynamic Traffic Assignment: Properties and Extensions.” Transportmetrica 2 (1): 31–52. doi: 10.1080/18128600608685654 [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ). In general, DTA can be classified into the simulation-based approach (e.g. Yagar 1971 Yagar, S. 1971. “Dynamic Traffic Assignment by Individual Path Minimisation and Queuing.” Transportation Research 5 (3): 179–196. doi: 10.1016/0041-1647(71)90020-7 [Crossref]   [Google Scholar] ; Mahmassani, Hu, and Jayakrishnan 1995 Mahmassani, H. S., T. Hu, and R. Jayakrishnan. 1992. “Dynamic Traffic Assignment and Simulation for Advanced Network Informatics (DYNASMART).” Proceedings of the 2nd international CAPRI seminar on Urban Traffic Networks. Capri, July.  [Google Scholar] ; Mahut and Florian 2010 Mahut, M., and M. Florian. 2010. “Traffic Simulation with Dynameq.” In Fundamentals of Traffic Simulation, edited by Jaume Barceló, 323–361.\nNew York\n: Springer. [Crossref]   [Google Scholar] ) and the analytical approach (see Ran and Boyce 1996 Ran, B., and D. E. Boyce. 1996. Modeling Dynamic Transportation Network: An Intelligent Transportation System Oriented Approach.\nSpringer\n: Heidelberg. [Crossref]   [Google Scholar] ; Peeta and Ziliaskopoulos 2001 Peeta, S., and A. K. Ziliaskopoulos. 2001. “Foundations of Dynamic Traffic Assignment: The Past, the Present and the Future.” Networks and Spatial Economics 1 (3–4): 233–265. doi: 10.1023/A:1012827724856 [Crossref]   [Google Scholar] ; Szeto and Lo 2005 Szeto, W. Y., and H. K. Lo. 2005. “Dynamic Traffic Assignment: Review and Future Research Directions.” Journal of Transportation Systems Engineering and Information Technology 5 (5): 85–100.  [Google Scholar] ; and Szeto and Wong 2012 Szeto, W. Y., and S. C. Wong. 2012. “Dynamic Traffic Assignment: Model Classifications and Recent Advances in Travel Choice Principles.” Central European Journal of Engineering 2 (1): 1–18. [Crossref]   [Google Scholar] for comprehensive reviews). The simulation-based approach focuses on enabling practical deployment for realistic networks, its applicability in real-life networks, and its ability to capture traffic dynamics and microscopic driver behaviour such as lane-changing behaviour. However, the solution properties of the corresponding models, such as solution existence and uniqueness, are not guaranteed and cannot be determined in advance.\nIn contrast, the analytical approach is more suitable for analysing the properties of DTA via various frameworks. These frameworks include the optimisation model (Merchant and Nemhauser 1978a Merchant, D. K., and G. L. Nemhauser. 1978a. “A Model and an Algorithm for the Dynamic Traffic Assignment Problems.” Transportation Science 12 (3): 183–199. doi: 10.1287/trsc.12.3.183 [Crossref]   [Google Scholar] , 1978b Merchant, D. K., and G. L. Nemhauser. 1978b. “Optimality Conditions for a Dynamic Traffic Assignment Model.” Transportation Science 12 (3): 200–207. doi: 10.1287/trsc.12.3.200 [Crossref]   [Google Scholar] ; Carey 1987 Carey, M. 1987. “Optimal Time-Varying Flows on Congested Networks.” Operations Research 35 (1): 58–69. doi: 10.1287/opre.35.1.58 [Crossref] , [Web of Science ®]   [Google Scholar] ; Carey and Watling 2012 Carey, M., and D. Watling. 2012. “Dynamic Traffic Assignment Approximating the Kinematic Wave Model: System Optimum, Marginal Costs, Externalities and Tolls.” Transportation Research Part B: Methodological 46 (5): 634–648. doi: 10.1016/j.trb.2012.01.008 [Crossref] , [Web of Science ®]   [Google Scholar] ), optimal control (Friesz et al. 1989 Friesz, T. L., J. Luque, R. L. Tobin, and B. W. Wie. 1989. “Dynamic Network Traffic Assignment Considered as a Continuous Time Optimal Control Problem.” Operations Research 37 (6): 893–901. doi: 10.1287/opre.37.6.893 [Crossref] , [Web of Science ®]   [Google Scholar] ; Ran, Boyce, and LeBlanc 1993 Ran, B., D. E. Boyce, and L. J. LeBlanc. 1993. “A New Class of Instantaneous Dynamic User-Optimal Traffic Assignment Models.” Operations Research 41 (1): 192–202. doi: 10.1287/opre.41.1.192 [Crossref] , [Web of Science ®]   [Google Scholar] ; Chow 2009a Chow, A. H. F. 2009a. “Dynamic System Optimal Traffic Assignment – A State-Dependent Control Theoretic Approach.” Transportmetrica 5 (2): 85–106. doi: 10.1080/18128600902717483 [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] , 2009b Chow, A. H. F. 2009b. “Properties of System Optimal Traffic Assignment with Departure Time Choice and Its Solution Method.” Transportation Research Part B: Methodological 43(3): 325–344. doi: 10.1016/j.trb.2008.07.006 [Crossref] , [Web of Science ®]   [Google Scholar] ; Ma et al. 2014a Ma, R., X. J. Ban, and J.-S. Pang. 2014a. “Continuous-time Dynamic System Optimum for Single-Destination Traffic Networks with Queue Spillbacks.” Transportation Research Part B: Methodological 68: 98–122. doi: 10.1016/j.trb.2014.06.003 [Crossref] , [Web of Science ®]   [Google Scholar] , 2014b Ma, R., X. J. Ban, and J.-S. Pang. 2014b. “Continuous-time Dynamic User Equilibrium Model with Departure-Time Choice and Capacitated Queue.” Proceedings of the 5th International Symposium on Dynamic Traffic Assignment, Salerno, Italy, 17–19 June.  [Google Scholar] ), variational inequality (Friesz et al. 1993 Friesz, T. L., D. Bernstein, T. E. Smith, R. L. Tobin, and B. W. Wie. 1993. “A Variational Inequality Formulation of the Dynamic Network User Equilibrium Problem.” Operations Research 41 (1): 179–191. doi: 10.1287/opre.41.1.179 [Crossref] , [Web of Science ®]   [Google Scholar] ; Ran and Boyce 1996 Ran, B., and D. E. Boyce. 1996. Modeling Dynamic Transportation Network: An Intelligent Transportation System Oriented Approach.\nSpringer\n: Heidelberg. [Crossref]   [Google Scholar] ; Chen and Hsueh 1998 Chen, H. K., and C. F. Hsueh. 1998. “A Model and an Algorithm for the Dynamic User-Optimal Route Choice Problem.” Transportation Research Part B: Methodological 32 (3): 219–234. doi: 10.1016/S0191-2615(97)00026-X [Crossref] , [Web of Science ®]   [Google Scholar] ; Huang and Lam 2002 Huang, H. J., and W. H. K. Lam. 2002. “Modeling and Solving the Dynamic User Equilibrium Route and Departure Time Choice Problem in Network With Queues.” Transportation Research Part B: Methodological 36 (3): 253–273. doi: 10.1016/S0191-2615(00)00049-7 [Crossref] , [Web of Science ®]   [Google Scholar] ; Lo and Szeto 2002a Lo, H. K., and W. Y. Szeto. 2002a. “A Cell-Based Variational Inequality Formulation of the Dynamic User Optimal Assignment Problem.” Transportation Research Part B: Methodological 36 (5): 421–443. doi: 10.1016/S0191-2615(01)00011-X [Crossref] , [Web of Science ®]   [Google Scholar] , 2002b Lo, H. K., and W. Y. Szeto. 2002b. “A Cell-Based Dynamic Traffic Assignment Model: Formulation and Properties.” Mathematical and Computer Modelling 35 (7–8): 849–865. doi: 10.1016/S0895-7177(02)00055-9 [Crossref] , [Web of Science ®]   [Google Scholar] ; Szeto and Lo 2004 Szeto, W. Y., and H. K. Lo. 2004. “A Cell-Based Simultaneous Route and Departure Time Choice Model with Elastic Demand.” Transportation Research Part B: Methodological 38 (7): 593–612. doi: 10.1016/j.trb.2003.05.001 [Crossref] , [Web of Science ®]   [Google Scholar] , 2006 Szeto, W. Y., and H. K. Lo. 2006. “Dynamic Traffic Assignment: Properties and Extensions.” Transportmetrica 2 (1): 31–52. doi: 10.1080/18128600608685654 [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ; Han, Friesz, and Yao 2013c Han, K., T. L. Friesz, and T. Yao. 2013c. “Existence of Simultaneous Route and Departure Choice Dynamic User Equilibrium.” Transportation Research Part B: Methodological 53: 17–30. doi: 10.1016/j.trb.2013.01.009 [Crossref] , [Web of Science ®]   [Google Scholar] ), nonlinear complementarity problem (NCP) (Wie, Tobin, and Carey 2002 Wie, B. W., R. L. Tobin, and M. Carey. 2002. “The Existence, Uniqueness and Computation of an Arc-Based Dynamic Network User Equilibrium Formulation.” Transportation Research Part B: Methodological 36 (10): 897–918. doi: 10.1016/S0191-2615(01)00041-8 [Crossref] , [Web of Science ®]   [Google Scholar] ; Ban et al. 2008 Ban, X. J., H. X. Liu, M. C. Ferris, and B. Ran. 2008. “A Link-Node Complementarity Model and Solution Algorithm for Dynamic User Equilibria with Exact Flow Propagations.” Transportation Research Part B: Methodological 42 (9): 823–842. doi: 10.1016/j.trb.2008.01.006 [Crossref] , [Web of Science ®]   [Google Scholar] ), nonlinear equation system (Long et al. 2015b Long, J. C., W. Y. Szeto, Q. Shi, Z. Y. Gao, and H. J. Huang. 2015b. “A Nonlinear Equation System Approach to the Dynamic Stochastic User Equilibrium Simultaneous Route and Departure Time Choice Problem.” Transportmetrica A: Transport Science 11 (5): 388–419. doi: 10.1080/23249935.2014.1003112 [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ), fixed point problem (Szeto, Jiang, and Sumalee 2011 Szeto, W. Y., Y. Jiang, and A. Sumalee. 2011. “A Cell-Based Model for Multi-Class Doubly Stochastic Dynamic Traffic Assignment.” Computer-Aided Civil and Infrastructure Engineering 26: 595–611. doi: 10.1111/j.1467-8667.2011.00717.x [Crossref] , [Web of Science ®]   [Google Scholar] ; Meng and Khoo 2012 Meng, Q., and H. L. Khoo. 2012. “A Computational Model for the Probit-Based Dynamic Stochastic User Optimal Traffic Assignment Problem.” Journal of Advanced Transportation 46 (1): 80–94. doi: 10.1002/atr.149 [Crossref] , [Web of Science ®]   [Google Scholar] ), differential variational inequality (Friesz et al. 2013 Friesz, T. L., K. Han, P. A. Neto, A. Meimand, and T. Yao. 2013. “Dynamic User Equilibrium Based on a Hydrodynamic Model.” Transportation Research Part B: Methodological 47 (1): 102–126. doi: 10.1016/j.trb.2012.10.001 [Crossref] , [Web of Science ®]   [Google Scholar] ; Friesz and Meimand 2014 Friesz, T. L., and A. Meimand. 2014. “A Differential Variational Inequality Formulation of Dynamic Network User Equilibrium with Elastic Demand.” Transportmetrica A: Transport Science 10 (7): 661–668. doi: 10.1080/18128602.2012.751684 [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ), and differential complementarity problem (Ban et al. 2012b Ban, X. J., J. S. Pang, H. X. Liu, and R. Ma. 2012b. “Modeling and Solving Continuous-Time Instantaneous Dynamic User Equilibria: A Differential Complementarity Systems Approach.” Transportation Research Part B: Methodological 46 (3): 389–408. doi: 10.1016/j.trb.2011.11.002 [Crossref] , [Web of Science ®]   [Google Scholar] ) frameworks.\nAll of the preceding analytical frameworks are formulated as either path-based models (e.g. Friesz et al. 1993 Friesz, T. L., D. Bernstein, T. E. Smith, R. L. Tobin, and B. W. Wie. 1993. “A Variational Inequality Formulation of the Dynamic Network User Equilibrium Problem.” Operations Research 41 (1): 179–191. doi: 10.1287/opre.41.1.179 [Crossref] , [Web of Science ®]   [Google Scholar] ; Huang and Lam 2002 Huang, H. J., and W. H. K. Lam. 2002. “Modeling and Solving the Dynamic User Equilibrium Route and Departure Time Choice Problem in Network With Queues.” Transportation Research Part B: Methodological 36 (3): 253–273. doi: 10.1016/S0191-2615(00)00049-7 [Crossref] , [Web of Science ®]   [Google Scholar] ; Lo and Szeto 2002a Lo, H. K., and W. Y. Szeto. 2002a. “A Cell-Based Variational Inequality Formulation of the Dynamic User Optimal Assignment Problem.” Transportation Research Part B: Methodological 36 (5): 421–443. doi: 10.1016/S0191-2615(01)00011-X [Crossref] , [Web of Science ®]   [Google Scholar] , 2002b Lo, H. K., and W. Y. Szeto. 2002b. “A Cell-Based Dynamic Traffic Assignment Model: Formulation and Properties.” Mathematical and Computer Modelling 35 (7–8): 849–865. doi: 10.1016/S0895-7177(02)00055-9 [Crossref] , [Web of Science ®]   [Google Scholar] ; Szeto and Lo 2004 Szeto, W. Y., and H. K. Lo. 2004. “A Cell-Based Simultaneous Route and Departure Time Choice Model with Elastic Demand.” Transportation Research Part B: Methodological 38 (7): 593–612. doi: 10.1016/j.trb.2003.05.001 [Crossref] , [Web of Science ®]   [Google Scholar] , 2006 Szeto, W. Y., and H. K. Lo. 2006. “Dynamic Traffic Assignment: Properties and Extensions.” Transportmetrica 2 (1): 31–52. doi: 10.1080/18128600608685654 [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ; Perakis and Roels 2006 Perakis, G., and Roels, G. 2006. “An Analytical Model for Traffic Delays and the Dynamic User Equilibrium Problem.” Operations Research 54 (6): 1151–1171. doi: 10.1287/opre.1060.0307 [Crossref] , [Web of Science ®]   [Google Scholar] ; Szeto 2008 Szeto, W. Y.. 2008. “Enhanced Lagged Cell-Transmission Model for Dynamic Traffic Assignment.” Transportation Research Record: Journal of the Transportation Research Board 2085: 76–85. doi: 10.3141/2085-09 [Crossref] , [Web of Science ®]   [Google Scholar] ; Szeto, Jiang, and Sumalee 2011 Szeto, W. Y., Y. Jiang, and A. Sumalee. 2011. “A Cell-Based Model for Multi-Class Doubly Stochastic Dynamic Traffic Assignment.” Computer-Aided Civil and Infrastructure Engineering 26: 595–611. doi: 10.1111/j.1467-8667.2011.00717.x [Crossref] , [Web of Science ®]   [Google Scholar] ) or link-based models (e.g. Carey 1987 Carey, M. 1987. “Optimal Time-Varying Flows on Congested Networks.” Operations Research 35 (1): 58–69. doi: 10.1287/opre.35.1.58 [Crossref] , [Web of Science ®]   [Google Scholar] ; Ran and Boyce 1996 Ran, B., and D. E. Boyce. 1996. Modeling Dynamic Transportation Network: An Intelligent Transportation System Oriented Approach.\nSpringer\n: Heidelberg. [Crossref]   [Google Scholar] ; Chen and Hsueh 1998 Chen, H. K., and C. F. Hsueh. 1998. “A Model and an Algorithm for the Dynamic User-Optimal Route Choice Problem.” Transportation Research Part B: Methodological 32 (3): 219–234. doi: 10.1016/S0191-2615(97)00026-X [Crossref] , [Web of Science ®]   [Google Scholar] ; Wie, Tobin, and Carey 2002 Wie, B. W., R. L. Tobin, and M. Carey. 2002. “The Existence, Uniqueness and Computation of an Arc-Based Dynamic Network User Equilibrium Formulation.” Transportation Research Part B: Methodological 36 (10): 897–918. doi: 10.1016/S0191-2615(01)00041-8 [Crossref] , [Web of Science ®]   [Google Scholar] ; Ban et al. 2008 Ban, X. J., H. X. Liu, M. C. Ferris, and B. Ran. 2008. “A Link-Node Complementarity Model and Solution Algorithm for Dynamic User Equilibria with Exact Flow Propagations.” Transportation Research Part B: Methodological 42 (9): 823–842. doi: 10.1016/j.trb.2008.01.006 [Crossref] , [Web of Science ®]   [Google Scholar] ). The merit of path-based models is that the path-related information, such as path flows and sets, can be obtained and imported to dynamic network loading (DNL) models to model flow propagation at merges and diverges and track spillback queues. Nevertheless, a path-based model normally suffers from the computational burden of path enumeration or relies on path-generation heuristics with no guarantee on convergence to handle huge path sets, even for medium networks. Instead, link-based models can avoid these two demerits and thus be applied to large networks. However, link-based models cannot be used to capture realistic traffic dynamics such as queue spillback (in one exception, Ma et al. ( 2014b Ma, R., X. J. Ban, and J.-S. Pang. 2014b. “Continuous-time Dynamic User Equilibrium Model with Departure-Time Choice and Capacitated Queue.” Proceedings of the 5th International Symposium on Dynamic Traffic Assignment, Salerno, Italy, 17–19 June.  [Google Scholar] ) proposed a link-based dynamic user optimal (DUO) model that could capture queue spillback for single-destination cases). If it is not captured, the flow pattern and locations of severe congestion may be estimated incorrectly and the strategy adopted may actually worsen network performance (Lo and Szeto 2004 Lo, H. K., and W. Y. Szeto. 2004. “Modeling Advanced Traveler Information Services: Static Versus Dynamic Paradigms.” Transportation Research Part B: Methodological 38 (6): 495–515. doi: 10.1016/j.trb.2003.06.001 [Crossref] , [Web of Science ®]   [Google Scholar] , 2005 Lo, H. K., and W. Y. Szeto. 2005. “Road Pricing for Hyper-congestion.” Transportation Research Part A 39 (7–9): 705–722.  [Google Scholar] ).\nTo retain the benefits of both the link- and path-based models, Long et al. ( 2013 Long, J. C., H. J. Huang, Z. Y. Gao, and W. Y. Szeto. 2013. “An Intersection-Movement-Based Dynamic User Optimal Route Choice Problem.” Operations Research 61 (5): 1134–1147. doi: 10.1287/opre.2013.1202 [Crossref] , [Web of Science ®]   [Google Scholar] , 2015a Long, J. C., W. Y. Szeto, H. J. Huang, and Z. Y. Gao. 2015a. “An Intersection-Movement-Based Stochastic Dynamic User Optimal Route Choice Model for Assessing Network Performance.” Transportation Research Part B: Methodological 74: 182–217. doi: 10.1016/j.trb.2014.12.008 [Crossref] , [Web of Science ®]   [Google Scholar] ) developed intersection-movement-based DTA models for general networks with multiple destinations. They formulated the traffic assignment problem in terms of approach proportions, that is, the proportion of traffic on the current link or node that selects a downstream link when leaving an intersection (or a node). This definition requires either two adjacent links or one origin link and one outgoing link to define an intersection movement. This is different from the classical definition, according to which only downstream links are used to define the proportion. An approach-proportion implicitly contains the traveller’s path information, as a path can be deduced by checking the downstream links involved in defining the approach proportions from origin to destination. As a result, this type of model can retain the advantages of both the link- and path-based models. First, as in link-based models, path enumeration and path-set generation can be avoided in the solution procedure for intersection-movement-based models. Second, as in path-based models, the realistic effects of physical queues can be captured in intersection-movement-based models when a physical queue DNL model is adopted, as the approach proportions contain the traveller’s path information. However, compared with link-based models, intersection-movement-based models have more decision variables, as each link flow or demand rate is disaggregated by downstream links (which very often number more than one) to define intersection movements and the corresponding approach proportions.\nMost of the preceding models, including the intersection-movement-based DTA models, consider only a single vehicle class. It is important to capture multiple vehicle classes in a DTA model and the interactions between different types of vehicles for several reasons. First, interactions between vehicle classes have been identified as a cause of traffic hysteresis, capacity decreases, and the wide scattering of flow–density relationships in a congested regime (Ngoduy 2010 Ngoduy, D. 2010. “Multi-Class First-Order Modelling of Traffic Networks Using Discontinuous Flow-Density Relationships.” Transportmetrica 6 (2): 121–141. doi: 10.1080/18128600902857925 [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ). Second, it is clear that trucks have a great influence on highway capacity, as they travel more slowly than cars and can become moving bottlenecks. Therefore, without considering different vehicle types and their interactions, realistic traffic dynamics and queue spillback cannot be modelled properly and the total system travel time cannot be estimated precisely. Third, many empirical studies have shown that vehicle emissions are closely related to speed and vehicle type; for example, the emissions of trucks are greater than those of cars. Therefore, it is important to capture traffic heterogeneity in estimating total vehicle emissions. Fourth, it is essential to distinguish user classes in the application of class-specific or priority control or when different types of traffic information are available to different user classes (Ngoduy 2010 Ngoduy, D. 2010. “Multi-Class First-Order Modelling of Traffic Networks Using Discontinuous Flow-Density Relationships.” Transportmetrica 6 (2): 121–141. doi: 10.1080/18128600902857925 [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ).\nThis paper develops a multi-class intersection-movement-based DTA model based on the DUO principle and concept of approach proportion. The problem is formulated as a VI problem. The DNL model proposed by Bliemer ( 2007 Bliemer, M. C. J. 2007. “Dynamic Queuing and Spillback in Analytical Multi-Class Dynamic Network Loading Model.” Transportation Research Record: Journal of the Transportation Research Board 2029 (1): 14–21. doi: 10.3141/2029-02 [Crossref] , [Web of Science ®]   [Google Scholar] ) is modified and incorporated into the VI formulation. Unlike some single-class DNL models (Ban et al. 2012a Ban, X. J., J. S. Pang, H. X. Liu, and R. Ma. 2012a. “Continuous-Time Point-Queue Models in Dynamic Network Loading.” Transportation Research Part B: Methodological 46 (3): 360–380. doi: 10.1016/j.trb.2011.11.004 [Crossref] , [Web of Science ®]   [Google Scholar] ; Han, Friesz, and Yao 2013a Han, K., T. L. Friesz, and T. Yao. 2013a. “A Partial Differential Equation Formulation of Vickrey’s Bottleneck Model, Part I: Methodology and Theoretical Analysis.” Transportation Research Part B: Methodological 49: 55–74. doi: 10.1016/j.trb.2012.10.003 [Crossref] , [Web of Science ®]   [Google Scholar] , 2013b Han, K., T. L. Friesz, and T. Yao. 2013b. “A Partial Differential Equation Formulation of Vickrey’s Bottleneck Model, Part II: Numerical Analysis and Computation.” Transportation Research Part B: Methodological 49: 75–93. doi: 10.1016/j.trb.2012.10.004 [Crossref] , [Web of Science ®]   [Google Scholar] ), this DNL model can capture car–truck interactions and allow approach proportions to be used as inputs. An extragradient method that requires only mild assumptions is adopted to solve the problem. Numerical examples are set to illustrate the importance of considering multiple vehicle classes. In addition, a car–truck interaction paradox, which states that allowing trucks to travel in a network or increasing the demand of trucks can improve total car travel time, is proposed, discussed, and examined. The findings have important implications for managing road networks with multiple types of traffic. For example, it is possible to relax road restrictions for trucks or large vehicles so that the total car travel time can be further improved or vice versa. The findings also open up new research directions for traffic management such as road restrictions and priority control for specific vehicle classes. This paper makes two main contributions. First, it proposes a multi-class intersection-movement-based DTA model that considers interactions between different types of vehicles and physical queues. Second, it proposes and examines the paradox associated with the interactions between trucks and cars.\nThe remainder of this paper proceeds as follows. Section 2 introduces the VI formulation for the intersection-movement-based multi-class DTA problem. It then depicts the DNL model encapsulated for calculating the mapping function in the VI formulation. Section 3 presents the extragradient solution method. Numerical examples are given in Section 4. Finally, Section 5 provides our conclusions and future research directions.\n2.  Formulation\n2.1  Notations\nWe consider a network with multiple origins and destinations and various classes of vehicles according to vehicle type. The network is formed by nodes and links. To simplify the presentation of the formulation, the network is designed to have the following properties. First, a node in a network can only have one status, that is, an origin, a destination, or an intermediate node. Second, at least two links are required to connect an origin and a destination. Third, there is one dummy link coming out from a destination with an infinite capacity. The first requirement can easily be satisfied by designing the network carefully. The second requirement is always satisfied for large networks. For small networks, this requirement can be satisfied by breaking down each link directly connecting an origin and a destination into a pair of links: one going into an intermediate node, and one coming out from the node. The third requirement aims to avoid developing additional sub-models to deal with flow propagation for the links going into a destination.\nThe following notations are used throughout this paper.\n2.1.1  Sets\n""","0.34379032","""http://www.tandfonline.com/doi/full/10.1080/23249935.2016.1190421""","[-0.178219,51.500505]"
"""Queen's_University_Belfast""","""Determining the regional potential for a grass biomethane industry - Queen's University Belfast Research Portal - Research Directory & Institutional Repository for QUB""","""Determining the regional potential for a grass biomethane industry\nResearch output: Contribution to journal › Article\nPublished\nView graph of relations\nGrass biogas/biomethane has been put forward as a renewable energy solution and it has been shown to perform well in terms of energy balance, greenhouse gas emissions and policy constraints. Biofuel and energy crop solutions are country-specific and grass biomethane has strong potential in countries with temperate climates and a high proportion of grassland, such as Ireland. For a grass biomethane industry to develop in a country, suitable regions (i.e. those with the highest potential) must be identified. In this paper, factors specifically related to the assessment of the potential of a grass biogas/biomethane industry are identified and analysed. The potential for grass biogas and grass biomethane is determined on a county-by-county basis using multi-criteria decision analysis. Values are assigned to each county and ratings and weightings applied to determine the overall county potential. The potential for grass biomethane with co-digestion of slaughter waste (belly grass) is also determined. The county with the highest potential (Limerick) is analysed in detail and is shown to have ready potential for production of gaseous biofuel to meet either 50% of the vehicle fleet or 130% of the domestic natural gas demand, through 25 facilities at a scale of ca. 30ktyr                         of feedstock. The assessment factors developed in this paper can be used in other resource studies into grass biomethane or other energy crops.\nDOI\n""","0.49132305","""http://pure.qub.ac.uk/portal/en/publications/determining-the-regional-potential-for-a-grass-biomethane-industry(7ed9acee-e98e-487d-8365-84f31417ca64).html""","[-5.934759,54.583863]"
"""Imperial_College_London""","""Associations between Active Travel to Work and Overweight, Hypertension, and Diabetes in India: A Cross-Sectional Study""","""Associations between Active Travel to Work and Overweight, Hypertension, and Diabetes in India: A Cross-Sectional Study\n* E-mail: c.millett@imperial.ac.uk\nAffiliations School of Public Health, Imperial College, London, United Kingdom,      South Asia Network for Chronic Disease, Public Health Foundation of India, New Delhi, India\n⨯\nAffiliation South Asia Network for Chronic Disease, Public Health Foundation of India, New Delhi, India\n⨯\nAffiliation Department of Non-communicable Disease Epidemiology, London School of Hygiene & Tropical Medicine, London, United Kingdom\n⨯\nAffiliation St. John's Research Institute, Bangalore, India\n⨯\nAffiliation St. John's Research Institute, Bangalore, India\n⨯\nAffiliation Indira Gandhi National Open University, Bangalore, India\n⨯\nAffiliation Centre for Chronic Disease Control, New Delhi, India\n⨯\nAffiliation Public Health Foundation of India, New Delhi, India\n⨯\nAffiliation Department of Non-communicable Disease Epidemiology, London School of Hygiene & Tropical Medicine, London, United Kingdom\n⨯\nAffiliation School of Social and Community Medicine, University of Bristol, Bristol, United Kingdom\n⨯\nAffiliations South Asia Network for Chronic Disease, Public Health Foundation of India, New Delhi, India,      Department of Non-communicable Disease Epidemiology, London School of Hygiene & Tropical Medicine, London, United Kingdom\n⨯\n¶Membership of the Indian Migration Study group is provided in the Acknowledgments\n⨯\nAssociations between Active Travel to Work and Overweight, Hypertension, and Diabetes in India: A Cross-Sectional Study\nChristopher Millett, \nAbstract\nBackground\nIncreasing active travel (walking, bicycling, and public transport) is promoted as a key strategy to increase physical activity and reduce the growing burden of noncommunicable diseases (NCDs) globally. Little is known about patterns of active travel or associated cardiovascular health benefits in low- and middle-income countries. This study examines mode and duration of travel to work in rural and urban India and associations between active travel and overweight, hypertension, and diabetes.\nMethods and Findings\nCross-sectional study of 3,902 participants (1,366 rural, 2,536 urban) in the Indian Migration Study. Associations between mode and duration of active travel and cardiovascular risk factors were assessed using random-effect logistic regression models adjusting for age, sex, caste, standard of living, occupation, factory location, leisure time physical activity, daily fat intake, smoking status, and alcohol use. Rural dwellers were significantly more likely to bicycle (68.3% versus 15.9%; p<0.001) to work than urban dwellers. The prevalence of overweight or obesity was 50.0%, 37.6%, 24.2%, 24.9%; hypertension was 17.7%, 11.8%, 6.5%, 9.8%; and diabetes was 10.8%, 7.4%, 3.8%, 7.3% in participants who travelled to work by private transport, public transport, bicycling, and walking, respectively. In the adjusted analysis, those walking (adjusted risk ratio [ARR] 0.72; 95% CI 0.58–0.88) or bicycling to work (ARR 0.66; 95% CI 0.55–0.77) were significantly less likely to be overweight or obese than those travelling by private transport. Those bicycling to work were significantly less likely to have hypertension (ARR 0.51; 95% CI 0.36–0.71) or diabetes (ARR 0.65; 95% CI 0.44–0.95). There was evidence of a dose-response relationship between duration of bicycling to work and being overweight, having hypertension or diabetes. The main limitation of the study is the cross-sectional design, which limits causal inference for the associations found.\nConclusions\nWalking and bicycling to work was associated with reduced cardiovascular risk in the Indian population. Efforts to increase active travel in urban areas and halt declines in rural areas should be integral to strategies to maintain healthy weight and prevent NCDs in India.\nPlease see later in the article for the Editors' Summary\nEditors' Summary\nBackground\nNoncommunicable diseases (NCDs) and obesity (excessive body fat) are major threats to global health. Every year, more than 36 million people (including 29 million in LMICs) die from NCDs—nearly two-thirds of the world's annual deaths. Cardiovascular diseases (conditions that affect the heart and the circulation), diabetes, cancer, and respiratory diseases are responsible for most NCD-related deaths. Obesity is a risk factor for all these NCDs and the global prevalence of obesity (the proportion of the world's population that is obese) has nearly doubled since 1980. In 2008, 35% of adults were overweight and 11% were obese. One reason for the growing burden of both obesity and NCDs is increasing physical inactivity. Regular physical activity helps to maintain a healthy body weight and to prevent or delay the onset of NCDs. For an adult, 30 minutes of moderate physical activity—walking briskly or cycling, for example—five times a week is sufficient to promote and maintain health. But the daily lives of people in both developed and developing countries are becoming increasingly sedentary and, nowadays, at least 60% of the world's population does not do even this modest amount of exercise.\nWhy Was This Study Done?\nStrategies to increase physical activity levels often promote active travel (walking, cycling, and using public transport). The positive impact of active travel on physical activity levels and cardiovascular health is well established in high-income countries, but little is known about the patterns of active travel or the health benefits associated with active travel in poorer countries. In this cross-sectional study (an investigation that measures population characteristics at a single time point), the researchers examine the mode and duration of travel to work in rural and urban India and associations between active travel and overweight/obesity, hypertension (high blood pressure, a risk factor for cardiovascular disease), and diabetes. In India, a lower middle-income country, the prevalence of overweight and NCDs is projected to increase rapidly over the next two decades. Moreover, rapid unplanned urbanization and a large increase in registered motor vehicles has resulted in inadequate development of the public transport infrastructure and hazardous conditions for walking and cycling in most Indian towns and cities.\nWhat Did the Researchers Do and Find?\nFor their study, researchers analyzed physical activity and health data collected from participants in the Indian Migration Study, which examined the association between migration from rural to urban areas and obesity and diabetes risk. People living in rural areas were more likely to cycle to work than people living in towns and cities (68.3% versus 15.9%). Among people who travelled to work by private transport, public transport, walking, and cycling, the prevalence of overweight or obesity was 50.0%, 37.6%, 24.9%, and 24.2%, respectively. Similar patterns were seen for the prevalence of hypertension and diabetes. After adjustment for factors that affect the risk of obesity, hypertension, and diabetes (for example, daily fat intake and leisure time physical activity), people walking or cycling to work were less likely to be overweight or obese than those travelling by public transport, and those cycling to walk were less likely to have hypertension or diabetes. Finally, people with long cycle rides to work had a lower risk of being overweight or having hypertension or diabetes than people with short cycle rides.\nWhat Do These Findings Mean?\nThese findings suggest that, as in high-income settings, walking and cycling to work are associated with a reduced risk of cardiovascular disease in India. Because this was a cross-sectional study, these findings do not prove that active travel reduces the risk of cardiovascular disease—people who cycle to work may share other unknown characteristics that are actually responsible for their reduced risk of cardiovascular disease. Moreover, this study did not consider non-cardiovascular outcomes associated with active travel that might affect health such as increased exposure to air pollution. Nevertheless, these findings suggest that programs designed to maintain healthy weight and prevent NCDs in India should endeavor to increase active travel in urban areas and to halt declines in rural areas by, for example, increasing investment in public transport and improving the safety and convenience of walking and cycling routes in urban areas.\nAdditional Information\nInformation about the Indian Migration Study is available\nCitation: Millett C, Agrawal S, Sullivan R, Vaz M, Kurpad A, Bharathi AV, et al.  (2013) Associations between Active Travel to Work and Overweight, Hypertension, and Diabetes in India: A Cross-Sectional Study. PLoS Med 10(6):            e1001459.                  https://doi.org/10.1371/journal.pmed.1001459\nAcademic Editor: Kavi Bhalla, Johns Hopkins Bloomberg School of Public Health, United States of America\nReceived: October 17, 2012; Accepted: April 23, 2013; Published: June 11, 2013\nCopyright: © 2013 Millett et al. This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.\nFunding: This study was supported by a Wellcome Trust project grant GR070797MF. CM is supported by the Higher Education Funding Council for England and the National Institute for Health Research. CM's research in India is supported by a Wellcome Trust Capacity Strengthening Strategic Award to the Public Health Foundation of India and a consortium of UK universities. SA is supported by a Wellcome Trust Strategic Award Grant No Z/041825. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.\nCompeting interests: AK has provided consultancy for McCain Foods, and the honoraria went entirely to charity. GDS is a member of the PLOS Medicine Editorial Board. All other authors have declared that no competing interests exist.\nAbbreviations: AAR,             adjusted risk ratio; BMI,             body mass index; BP,             blood pressure; HOMA,             homeostasis model assessment; IMS,             Indian Migration Study; LMICs,             low- and middle-income countries; MET,             metabolic equivalent task; NCD,             noncommunicable disease; SD,             standard deviation; SLI,             standard of living index; WHO,             World Health Organization\nIntroduction\nActive travel (walking, bicycling, and use of public transport) is increasingly being promoted as an integral component of strategies to increase physical activity levels and address the growing burden of obesity and non-communicable diseases (NCDs) globally [1] , [2] . The Action Plan of the World Health Organization's (WHO's) Global Strategy for the Prevention and Control of NCDs urges member states to “introduce transport policies that promote active and safe methods of travelling to and from schools and workplaces” and to “ensure that physical environments support safe active commuting.” [3] . While a number of high-income countries, most notably the Netherlands, Denmark, and Germany, have implemented effective policies to increase active travel [4] , such efforts remain largely undeveloped in low- and middle-income countries (LMICs) such as India, where the bulk of the NCD burden falls.\nEfforts to increase active travel in India face a number of powerful countervailing influences, including rapid, unplanned urbanisation and substantial growth in motor vehicle ownership. The percentage of the Indian population living in urban areas increased from 23% in 1980 to 31% in 2010 and is projected to exceed 50% by 2050. There was a 38-fold increase (3 to 115 million) in the number of registered motor vehicles in the country between 1981 and 2009 [5] . Successive governments have prioritised investment in road infrastructure since the National Highway Act in 1995 and planning for urban growth at the local level has generally been weak and haphazard [6] . In combination, these factors have resulted in inadequate development of the public transport infrastructure and hazardous conditions for walking and bicycling in most Indian cities and towns.\nThe positive impacts of active travel on physical activity levels and cardiovascular health are well established in high income countries [7] , [8] . For example, a US study found that users of public transport, walk for an average of 19 min as part of their daily commute and that 29% of public transport users achieve recommended levels of daily physical activity from this travel alone [9] . However, there has been little research examining patterns of active travel and the associated health benefits in India and other LMICs. Further, there is sparse information on how patterns of active travel differ in rural and urban India. This is an important knowledge gap given that the prevalence of overweight, diabetes, and cardiovascular disease (CVD) is substantially higher in urban India [10] – [12] . This study has two aims: (1) to characterise modes of active travel to work in urban and rural populations in India; (2) to examine associations between modes of active travel (walking, bicycling, public transport) to work and overweight and obesity, hypertension, and diabetes in India.\nMethods\nStudy Design and Respondents\nThis study used data from the Indian Migration Study (IMS) conducted during 2005–2007. The design and sampling methodology of the IMS has been described previously [10] , [13] . Briefly, the IMS is a cross-sectional sib-pair study, part of a larger cardiovascular risk factor surveillance system [14] . The IMS was carried out in factory settings in four cities from northern (Lucknow, Hindustan Aeronautics Ltd), central (Nagpur, Indorama Synthetics Ltd), and southern India (Hyderabad, Bharat Heavy Electricals Ltd; and Bangalore, Hindustan Machine Tools Ltd). Information on rural-to-urban migration was solicited from factory workers and their co-resident spouses. Factory workers and their co-resident spouses who had migrated from rural to urban areas, along with a 25% random sample of urban non-migrants and their co-resident spouses, were asked to participate in the study. Each migrant participant was asked to identify a non-migrant sibling residing in a rural area, preferably of the same gender and close to them in age, who was then also invited to participate in the study. In a small number of cases where no rural sibling was available (<5%), a cousin or a close friend from the same village was invited. There were no other exclusion criteria at this recruitment stage. This convenience sampling strategy resulted in rural dwelling siblings being drawn from anywhere in the country (18 of the 29 states), reflecting the migration patterns of the factory workers and their spouses. A substantial proportion came from the four large states in which the factories were based (Uttar Pradesh, Maharashtra, Andhra Pradesh, and Karnataka). The urban participants were also asked to identify a non-migrant, urban dwelling sibling for inclusion in the study.\nOf the 7,594 migrant and non-migrant factory workers and their co-resident spouses identified as being eligible for the India Migration Study, 7,102 (94%) agreed in principle to complete the clinical examination with their sibling, of whom 3,537 (50%) sib-pairs eventually participated by the close of field work. The final IMS sample was 7,067 respondents as seven respondents did not complete the clinical examination. Our analysis is based on 3,902 respondents aged ≥18 y who reported being in the workforce. Exclusions included respondents who reported being unemployed/did housework (2,508), had no information on their mode of transport to work (308), or had no information on their migration status (349). Ethics committee approval for the IMS was obtained from the All India Institute of Medical Sciences Ethics Committee, reference number A-60/4/8/2004.\nData Collection and Measurements\nAn interviewer-administered questionnaire was used to collect socio-demographic, physical activity, and health data from respondents. Trained personnel took anthropometric measures of height and weight from all participants during a clinic visit. Height was measured to the nearest 0.1 cm using a portable stadiometer with a base plate (Leicester height measure, Chasmore Ltd.). Weight was measured twice, to the nearest 0.1 kg using a digital scale (Model PS16), with participants removing their shoes and wearing light clothing. Blood pressure was measured twice using an Omron M5-I automatic machine in sitting position using the right upper arm and an appropriate sized cuff after a period of 5-min rest. The average of these two measures taken was used for these analyses. Participants were asked to attend the clinic visit fasting and the time of last meal was recorded. Glucose was measured on the day of blood sample collection in local laboratories at each site with the GOD-PAP method using RANDOX kits. The quality of local assays was checked with regular external standards and internal duplicate assays and monitored by a reference laboratory at the All India Institute of Medical Sciences. Daily fat intake was assessed from a validated, interviewer-administered semi-quantitative food frequency questionnaire which is described elsewhere [15] . The questionnaire assessed frequency of intake (daily, weekly, monthly, yearly) of 184 commonly consumed food items. Information collected in the food frequency questionnaire was converted into average daily consumption of nutrient and food groups, using nutrient databases that were developed for the study. A validated, interviewer-administered questionnaire was used to assess physical activity in the past month across multiple domains including discretionary leisure time, household chores, work, sleep, sedentary activities, and other common daily activities in the IMS [16] . Respondents were asked whether they undertook sports, games, or other physical activities such as walking for leisure. Those responding affirmatively were asked about the frequency (daily; 5–6 times/week; 2–4 times/week; once a week, 2–3 times/month; once a month) and the average duration in minutes of each leisure activity undertaken. Metabolic equivalent tasks (METs) were estimated as the ratio of resting metabolic rate where 1 MET is equivalent to the energy expenditure value of sitting quietly using an established method [16] . Activity data, including for leisure time physical activity, were summarised as MET hours per day. All protocols and equipment were pilot tested prior to the study commencing. Fieldworkers at the four study sites underwent joint training sessions and standardisation at the outset and subsequently every 6 mo. Anthropometric instruments were calibrated at the start of each clinic session.\nPredictor Variable\nActive Travel To Work.\nInformation on mode and duration of travel to work was gathered from respondents as part of the questionnaire on physical activity [16] . Mode of transport to work was categorized as private transport (car and motorcycles), public transport (three wheeler, bus, and train), walking and bicycling. Respondents were asked to estimate the duration of travel to their workplace in minutes. We doubled this to obtain the total amount of daily travel to and from the workplace. We categorized respondents according to whether their daily active travel (to and from work) was 30 min or greater, reflecting international guidelines on recommended physical activity levels [1] .\nOutcome Variables\nOverweight was defined using two cut points; body mass index (BMI)≥23 kg/m2 (suitable for Asian populations [17] ) and BMI≥25 kg/m2. Obesity was defined as BMI≥30 kg/m2. Hypertension was defined as a report of a doctor diagnosis of hypertension. Undiagnosed hypertension was defined as a systolic BP≥140 mm Hg or a diastolic BP≥90 mm Hg in the absence of a doctor diagnosis. Diabetes was defined as a report of a doctor diagnosis of diabetes. Undiagnosed diabetes was defined by WHO fasting plasma glucose criterion of >7.0 mmol/l in the absence of a doctor diagnosis of diabetes [18] . Homeostasis model assessment (HOMA) scores to estimate insulin resistance were calculated from fasting blood glucose and serum insulin levels using a standard formula of plasma glucose (mol/l)×plasma insulin (mU/l)/22.5), on the basis of the original approach [19] . HOMA has been validated by comparison with biochemical markers of insulin resistance in healthy Indian people, yielding moderate correlations [20] . We have divided the HOMA scores into tertiles and created a binary variable (high versus medium/low). Our rationale for using both doctor diagnosed and undiagnosed hypertension and diabetes as outcome measures was to address the possibility of reverse causality, i.e., individuals with diagnosed diabetes and hypertension may receive physician advice to increase physical activity. The number of participants with missing data for our main outcomes was negligible (<10 respondents for each variable). Full details on data completeness in the study can be found elsewhere [10] .\nCovariates\nCovariates in our analysis included age, sex, caste/tribe status, standard of living index (SLI), occupation, factory location, leisure time physical activity (MET hours/day), daily fat intake (grams per day), current alcohol intake (yes/no), and smoking status (current smoker/non smoker). “Scheduled castes” and “scheduled tribes” are identified by the Government of India as socially and economically backward and needing protection from social injustice and exploitation. “Other backward class” is a diverse collection of intermediate castes that were considered low in the traditional caste hierarchy but are clearly above scheduled castes. “General” is thus a default residual group that enjoys higher status in the caste hierarchy. The SLI is based on following assets in the household: quality of house; toilet facilities; source of lighting and drinking water; possession of clock, radio, television, bicycle, motorcycle, car, tractor, refrigerator, and telephone. A score of less than 20 indicates low SLI, 21–26 indicates medium SLI, and 27 and above indicates high SLI. Occupation was categorized as manual and non-manual.\nStatistical Analysis\nAs the study is based on factory workers, their spouses, and a sibling of each factory worker and spouse these data cannot be treated as coming from independent individuals and the data structure must be accounted for in the statistical analysis [10] . A general multilevel random effects model framework that can accommodate this data structure was used [21] . In the multilevel model the between-pair variation is specified explicitly and included in the model.\nStandard descriptive analysis was done using chi square tests. Association between mode of transport and duration of travel was assessed using random-effect logistic regression models after adjusting for the sib-pair design, factory location, and potential confounders. Separate models were run with BMI and MET hours/day as additional covariates. Comparisons were made between mode of transport and duration of travel using the logistic regression with a pair-specific random effect to estimate the within-pair comparisons for all the binary outcomes. Odds ratios for associations between mode of transport and outcomes were calculated and adjustments made for age, sex, caste, standard of living, occupation, factory location, leisure time physical activity, daily fat intake, smoking status, and alcohol use as these may confound the associations. We then corrected for possible overestimation of odds ratios for common outcomes by adjusting to approximate risk ratios using an established method [22] . All statistical analyses were conducted using STATA software version 10 (StataCorp. 2009. Stata Statistical Software: Release 10. StataCorp LP).\nResults\nOf the 3,902 eligible participants, 1,366 were rural dwellers and 2,536 were urban dwellers ( Table 1 ). There were no major differences between migrant and non-migrant urban dwellers so they were combined into a single group. The mean age of respondents was 42.2 y (standard deviation [SD] 9.6) and 87.2% were men. A significantly higher percentage of rural dwellers were employed in manual occupations than urban dwellers (75.1%, 51.9%, respectively; p<0.001). Rural dwellers were significantly more likely to belong to lower caste groups and be in the lowest SLI group than (69.8%, 16.7%; p<0.001). Rural dwellers were significantly less likely to be overweight (19.1%, 44.5%; p<0.001) and significantly less likely to have doctor diagnosed hypertension (5.1%, 15.3%; p<0.001) or doctor diagnosed diabetes (2.8%, 9.7%; p<0.001) than urban dwellers.\nDownload:\nhttps://doi.org/10.1371/journal.pmed.1001459.t007\nDiscussion\nWe found a lower likelihood of overweight in participants that walked or bicycled to work compared to those that used private transport. Participants who bicycled to work were less likely to have hypertension or diabetes than those that travelled to work by private transport. These findings are consistent with a growing evidence base derived from studies conducted in high-income settings and upper middle-income countries [23] . This includes evidence that individuals who take active transport to work have higher overall levels of physical activity and are less likely to be overweight or obese [24] – [26] . A meta-analysis of studies conducted prior to 2007 found that active travel to work was associated with an 11% reduction in cardiovascular outcomes (pooling cardiovascular mortality, incident coronary heart disease, stroke, hypertension diabetes) [7] . The CARDIA study found that active commuting was inversely associated with BMI, obesity, triglyceride level, blood pressure, and fasting insulin and positively associated with high density lipoprotein (HDL) cholesterol [27] . An earlier study conducted in Copenhagen found that bicycling to work was associated with 28% decrease in mortality after adjustment for leisure time physical activity [28] . A Finnish study found that daily walking or cycling to and from work for more than 30 min was inversely associated with risk of type 2 diabetes [29] .\nWe were able to identify a dose response relationship between duration of bicycling to work and being overweight, having hypertension and diabetes in both unadjusted and adjusted analyses, which strengthens a causal interpretation of these associations. For duration of walking, dose response relationships were seen in unadjusted analyses but attenuated for hypertension and diabetes. The similar findings in our main analyses, which allow for the sib-pair design, to those from our analyses that examine associations in between and within sib-pairs, provide stronger evidence that these associations are robust. The only exception to this is the association between walking to work and overweight, which is significant in the between-sibling-pairs analysis but not so (attenuates to null) in the within-sibling-pairs analysis. While this does raise a question about the robustness of this association, the most likely explanation is that this is a chance finding given the consistency of other comparisons made. The strengths of our study include the large sample and use of sibling pair design. However, like all cross-sectional studies, the data from this study may be prone to recall bias and there remains the possibility of residual confounding (the sib pair design increases the potential for confounding although it reduces the potential for confounding by genetic factors). For example, duration of active travel is based on self-report and may not be accurate. As only the main mode of travel was recorded, we did not have information on how long respondents spent walking (or cycling) to access points if public transport was used. In an effort to address the possibility of reverse causality, i.e., individuals with diagnosed hypertension may receive physician advice to increase physical activity, we examined associations between active travel and undiagnosed hypertension and diabetes. Several of these findings were consistent with a protective effect of active travel although only the association between bicycling and undiagnosed hypertension was statistically significant. Longitudinal studies are required to better determine cause and effect. There is a risk of selection bias in this study due to non-response and missing values. Our sample size was too small to examine associations between mode of active travel and cardiovascular risk factors in rural and urban groups separately. We did not have information on exposure to ambient or household air pollution, which has been associated with an elevated risk of hypertension and diabetes [30] , [31] . However, as this exposure is likely to be socially patterned, adjustment for socio-economic factors (which is done in our analyses) will provide some control for these possible effects. Our urban sample consisted of factory employees whose patterns of active travel may differ from urban residents generally. Mean travel times for walking (22 min) and cycling (26 min) to and from work among respondents living in urban areas appear low indicating that many lived close to the factories. This may mean that the proportion of people undertaking active travel in our sample is higher and the associated cardiovascular benefits identified here are lower (given the mean duration is lower than that recommend by international guidance [1] ) than is typical for similar populations in India. Unfortunately there are few data on patterns of active travel in India available to compare our findings with. However, the high percentage of urban respondents using private transport for commuting (45%) reflects recent dramatic growth in car and motorbike ownership and lack of investment in public transport infrastructure in India [5] , [6] . We were not able to examine non-cardiovascular outcomes that may be of interest (e.g., injuries sustained during active travel, exposure to air pollution, effects on mental health outcomes).\nIndia is facing a growing burden of NCDs, particularly from diabetes and CVD [11] , [32] . For example, total deaths from CVD are projected to increase from 2.7 million in 2004 to 4.0 million in 2030 33] . While the prevalence of overweight and obesity remained relatively stable in India since the 1990s [34] , [35] , this is projected to increase rapidly in the next two decades [36] . Our findings indicate that increasing active travel could be important in restraining this increase. Differences in active travel in urban and rural groups found in our study may partly explain the higher prevalence of diabetes and hypertension in urban India and the negative impact of rural-to-urban migration on CVD risk factors [10] , [37] .\nEfforts to increase active travel in urban areas and halt declines in rural areas should be integral to strategies to maintain healthy weight and prevent NCDs in India. This should include greater investment in public transport and improving the safety and convenience of bicycling and walking in Indian towns and cities [38] – [40] . Specific measures to discourage car use should also be considered and could include carbon rationing, road pricing, car parking restrictions, and reduced speed limits [41] . Direct to consumer subsidies and workplace facilities, such as bicycle parking and showers, to encourage active travel over private vehicle use have been associated with improved health outcomes in high-income countries and should be considered [42] . Further research evaluating the impact of interventions to increase active travel in India and other LMICs is warranted. An assessment of potential future health benefits of increasing active travel should account for the potentially deleterious effects of increased exposure to air pollution and road traffic injuries alongside the substantial long term benefits of reduced carbon emissions.\nSupporting Information\n(DOCX)\nAcknowledgments\nAn earlier version of the paper was presented at the Geneva Health Forum, Geneva, Switzerland, 18–20 April 2012. We are grateful to the study sponsor, the field staff, and the participants of the Indian Migration Study.\nThe Indian Migration Study group comprises:\nNew Delhi: K. Srinath Reddy, Dorairaj Prabhakaran, Tulsi Patel, Lakshmy Ramakrishnan, Ruby Gupta, Tanica Lyngdoh; Lucknow: R.C. Ahuja, R.K. Saran; Nagpur: Prashant Joshi, N.M. Thakre; Hyderabad: K.V.R. Sarma, S. Mohan Das, R.K Jain, S.S. Potnis; Bangalore: Anura V. Kurpad, Mario Vaz, A.V. Barathi, Murali Mohan; Pune: Chittaranjan Yajnik; Bristol: George Davey Smith, Yoav Ben Shlomo; London School of Hygiene & Tropical Medicine: Shah Ebrahim, Sanjay Kinra.\nAuthor Contributions\nConceived and designed the experiments: CM SA SE. Performed the experiments: CM SA SE. Analyzed the data: SA. Wrote the first draft of the manuscript: CM. Contributed to the writing of the manuscript: CM SA RS MV AK AVB DP KSR SK GDS SE. ICMJE criteria for authorship read and met: CM SA RS MV AK AVB DP KSR SK GDS SE. Agree with manuscript results and conclusions: CM SA RS MV AK AVB DP KSR SK GDS SE.\nReferences\n1. World Health Organization (2010) Global recommendations on physical activity for health. Geneva: World Health Organization.\n2. United Nations General Assembly (2011) Political Declaration of the High-level Meeting of the General Assembly on the Prevention and Control of Non-communicable Diseases. New York: United Nations.\n3. World Health Organzation (2008) 2008–2013 action plan for the global strategy for the prevention and control of noncommunicable diseases. Geneva: World Health Organzation.\n4. Pucher J, Buehler R (2008) Making cycling irresistible: lessons from The Netherlands, Denmark and Germany. Transport Reviews 28: 495–528.\n""","0.14871724","""http://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.1001459""","[-0.178219,51.500505]"
"""Imperial_College_London""","""Keratinocyte growth factor therapy in murine oleic acid-induced acute lung injury | Lung Cellular and Molecular Physiology""","""Submit a Manuscript\nKeratinocyte growth factor therapy in murine oleic acid-induced acute lung injury\nK. Ulrich, M. Stern, M. E. Goddard, J. Williams, J. Zhu, A. Dewar, H. A. Painter, P. K. Jeffery, D. R. Gill, S. C. Hyde, D. M. Geddes, M. Takata, E. W. F. W. Alton\nAmerican Journal of Physiology - Lung Cellular and Molecular Physiology Published 10 May 2005 Vol. 288 no. 6, L1179-L1192 DOI: 10.1152/ajplung.00450.2004\nK. Ulrich\nDepartment of Gene Therapy, National Heart and Lung Institute, and Anaesthetics and Intensive Care, Chelsea and Westminster Hospital, and Electron Microscopy Unit, National Heart and Lung Institute, Faculty of Medicine, Imperial College London, London; and Gene Medicine Research Group, Nuffield Department of Clinical Laboratory Sciences, University of Oxford, United Kingdom\nSearch for this author on this site\nM. Stern\nDepartment of Gene Therapy, National Heart and Lung Institute, and Anaesthetics and Intensive Care, Chelsea and Westminster Hospital, and Electron Microscopy Unit, National Heart and Lung Institute, Faculty of Medicine, Imperial College London, London; and Gene Medicine Research Group, Nuffield Department of Clinical Laboratory Sciences, University of Oxford, United Kingdom\nSearch for this author on this site\nM. E. Goddard\nDepartment of Gene Therapy, National Heart and Lung Institute, and Anaesthetics and Intensive Care, Chelsea and Westminster Hospital, and Electron Microscopy Unit, National Heart and Lung Institute, Faculty of Medicine, Imperial College London, London; and Gene Medicine Research Group, Nuffield Department of Clinical Laboratory Sciences, University of Oxford, United Kingdom\nSearch for this author on this site\nJ. Williams\nDepartment of Gene Therapy, National Heart and Lung Institute, and Anaesthetics and Intensive Care, Chelsea and Westminster Hospital, and Electron Microscopy Unit, National Heart and Lung Institute, Faculty of Medicine, Imperial College London, London; and Gene Medicine Research Group, Nuffield Department of Clinical Laboratory Sciences, University of Oxford, United Kingdom\nSearch for this author on this site\nJ. Zhu\nDepartment of Gene Therapy, National Heart and Lung Institute, and Anaesthetics and Intensive Care, Chelsea and Westminster Hospital, and Electron Microscopy Unit, National Heart and Lung Institute, Faculty of Medicine, Imperial College London, London; and Gene Medicine Research Group, Nuffield Department of Clinical Laboratory Sciences, University of Oxford, United Kingdom\nSearch for this author on this site\nA. Dewar\nDepartment of Gene Therapy, National Heart and Lung Institute, and Anaesthetics and Intensive Care, Chelsea and Westminster Hospital, and Electron Microscopy Unit, National Heart and Lung Institute, Faculty of Medicine, Imperial College London, London; and Gene Medicine Research Group, Nuffield Department of Clinical Laboratory Sciences, University of Oxford, United Kingdom\nSearch for this author on this site\nH. A. Painter\nDepartment of Gene Therapy, National Heart and Lung Institute, and Anaesthetics and Intensive Care, Chelsea and Westminster Hospital, and Electron Microscopy Unit, National Heart and Lung Institute, Faculty of Medicine, Imperial College London, London; and Gene Medicine Research Group, Nuffield Department of Clinical Laboratory Sciences, University of Oxford, United Kingdom\nSearch for this author on this site\nP. K. Jeffery\nDepartment of Gene Therapy, National Heart and Lung Institute, and Anaesthetics and Intensive Care, Chelsea and Westminster Hospital, and Electron Microscopy Unit, National Heart and Lung Institute, Faculty of Medicine, Imperial College London, London; and Gene Medicine Research Group, Nuffield Department of Clinical Laboratory Sciences, University of Oxford, United Kingdom\nSearch for this author on this site\nD. R. Gill\nDepartment of Gene Therapy, National Heart and Lung Institute, and Anaesthetics and Intensive Care, Chelsea and Westminster Hospital, and Electron Microscopy Unit, National Heart and Lung Institute, Faculty of Medicine, Imperial College London, London; and Gene Medicine Research Group, Nuffield Department of Clinical Laboratory Sciences, University of Oxford, United Kingdom\nSearch for this author on this site\nS. C. Hyde\nDepartment of Gene Therapy, National Heart and Lung Institute, and Anaesthetics and Intensive Care, Chelsea and Westminster Hospital, and Electron Microscopy Unit, National Heart and Lung Institute, Faculty of Medicine, Imperial College London, London; and Gene Medicine Research Group, Nuffield Department of Clinical Laboratory Sciences, University of Oxford, United Kingdom\nSearch for this author on this site\nD. M. Geddes\nDepartment of Gene Therapy, National Heart and Lung Institute, and Anaesthetics and Intensive Care, Chelsea and Westminster Hospital, and Electron Microscopy Unit, National Heart and Lung Institute, Faculty of Medicine, Imperial College London, London; and Gene Medicine Research Group, Nuffield Department of Clinical Laboratory Sciences, University of Oxford, United Kingdom\nSearch for this author on this site\nM. Takata\nDepartment of Gene Therapy, National Heart and Lung Institute, and Anaesthetics and Intensive Care, Chelsea and Westminster Hospital, and Electron Microscopy Unit, National Heart and Lung Institute, Faculty of Medicine, Imperial College London, London; and Gene Medicine Research Group, Nuffield Department of Clinical Laboratory Sciences, University of Oxford, United Kingdom\nSearch for this author on this site\nE. W. F. W. Alton\nDepartment of Gene Therapy, National Heart and Lung Institute, and Anaesthetics and Intensive Care, Chelsea and Westminster Hospital, and Electron Microscopy Unit, National Heart and Lung Institute, Faculty of Medicine, Imperial College London, London; and Gene Medicine Research Group, Nuffield Department of Clinical Laboratory Sciences, University of Oxford, United Kingdom\nPDF\nAbstract\nAlveolar type II (ATII) cell proliferation and differentiation are important mechanisms in repair following injury to the alveolar epithelium. KGF is a potent ATII cell mitogen, which has been demonstrated to be protective in a number of animal models of lung injury. We have assessed the effect of recombinant human KGF (rhKGF) and liposome-mediated KGF gene delivery in vivo and evaluated the potential of KGF as a therapy for acute lung injury in mice. rhKGF was administered intratracheally in male BALB/c mice to assess dose response and time course of proliferation. SP-B immunohistochemistry demonstrated significant increases in ATII cell numbers at all rhKGF doses compared with control animals and peaked 2 days following administration of 10 mg/kg rhKGF. Protein therapy in general is very expensive, and gene therapy has been suggested as a cheaper alternative for many protein replacement therapies. We evaluated the effect of topical and systemic liposome-mediated KGF-gene delivery on ATII cell proliferation. SP-B immunohistochemistry showed only modest increases in ATII cell numbers following gene delivery, and these approaches were therefore not believed to be capable of reaching therapeutic levels. The effect of rhKGF was evaluated in a murine model of OA-induced lung injury. This model was found to be associated with significant alveolar damage leading to severe impairment of gas exchange and lung compliance. Pretreatment with rhKGF 2 days before intravenous OA challenge resulted in significant improvements in Po2, Pco2, and lung compliance. This study suggests the feasibility of KGF as a therapy for acute lung injury.\nacute respiratory distress syndrome\noleic acid\ngene therapy\nards (acute respiratory distress syndrome) is a term generally applied to patients with severe manifestations of acute lung injury (ALI) and is characterized by severe alveolar damage. In histopathological terms, this encompasses capillary congestion, interstitial and alveolar edema, hyaline membrane formation, and alveolar type I (ATI) cell necrosis ( 4 ). ATI cells are large, with volumes of ∼3,000 μm3/cell, and each cell forms a thin (∼0.2 μm) cytoplasmic sheet ( 51 ) to facilitate gas exchange, which extends from the nucleus to cover the surface of one or more alveoli. Related to both this morphology and their inability to undergo mitosis and cellular repair, ATI cells are particularly sensitive to damage by injurious agents. The alveolar type II (ATII) cell is cuboidal and contains numerous cytoplasmic organelles, including lamellar bodies, for the cytoplasmic production and storage of surfactant ( 27 ). Importantly, the ATII cell is critical to the repair process following alveolar epithelial injury and has been shown to be involved in a combination of proliferation and differentiation ( 1 ), migration ( 30 , 76 ), and spreading ( 30 ) to cover areas of denuded alveolar epithelium. Thus ATII cell proliferation is believed to be particularly important during repair, as ATII cells differentiate into ATI cells, and thus replace ATI cells lost during the injury phase.\nHuman keratinocyte growth factor (KGF) was first cloned in 1989 from an embryonic fibroblast cell line by Finch et al. ( 19 ). KGF is a heparin-binding growth factor that is secreted by fibroblasts and is known to act via a receptor specific to epithelial cells ( 37 ). KGF induces potent proliferative activity in a variety of epithelial cells including keratinocytes, important to hair follicle development ( 8 ) and skin growth during wound healing ( 35 ). Additionally, KGF stimulates proliferation of mammary ( 62 ) and pancreatic ductal epithelia ( 75 ). Importantly, KGF also stimulates proliferation of ATII cells in vitro ( 47 ) and in vivo ( 18 ). Intratracheal administration of recombinant human KGF (rhKGF) to normal rat lungs results in ATII cell hyperplasia 2 days following administration ( 63 ). This process initially produces a “piled up” appearance to the alveolar epithelium, caused by the increased number of ATII cells. By day 3, however, the newly formed ATII cells appear to migrate outward to cover a larger area of the alveoli, and by day 6, the alveolar epithelium appears normal. However, not all newly formed ATII cells differentiate into ATI cells, and apoptosis has been shown to be involved in maintaining homeostasis between cell populations in the lung ( 18 , 57 ).\nAdministration of exogenous rhKGF has been shown to ameliorate lung injury in a range of animal models. A number of studies have demonstrated that KGF pretreatment resulted in reduced mortality following intratracheal instillation of hydrochloric acid ( 43 , 71 ), intratracheal bleomycin ( 55 , 73 ), hyperoxia ( 5 , 46 ) and Pseudomonas aeruginosa-induced lung injury ( 65 ). Amelioration of both morphological damage to the alveolar epithelium and inflammation has been demonstrated in the bleomycin ( 22 ) and hydrochloric acid models ( 43 , 71 ), P. aeruginosa-induced lung injury ( 65 ), and hyperoxia-induced lung injury ( 5 , 46 ). Exogenous KGF upregulates active ion transport by increasing the expression of sodium pumps, primarily the Na+-K+-ATPase α1-subunit ( 6 ). Thus in the α-naphthylthiourea model of acute permeability edema, KGF administration reduced lung wet-to-dry weight ratios and bronchoalveolar lavage (BAL) protein ( 21 , 36 ). Both of these effects were also demonstrated in P. aeruginosa-induced ( 65 ) and ventilator-induced lung injury ( 67 ).\nThe protective effects of KGF observed in the above studies suggest that, in addition to ATII cell hyperplasia, KGF may have many other beneficial effects on ALI. These may include scavenging of reactive oxygen species and increased DNA repair ( 59 , 69 ). Additionally, KGF has been implicated in the reduction of alveolar epithelial susceptibility to mechanical deformation in vitro ( 44 ), possibly related to changes in the cytoskeleton or the extracellular matrix. Furthermore, KGF accelerates the rate of wound closure during mechanical deformation in various cell lines and primary cells by a combination of increased cell migration rate and cell spreading ( 20 , 66 ). Atabai et al. ( 2 ) demonstrated that KGF-treated cells were more adherent to the extracellular matrix. Enhanced epithelial cell adherence to the denuded basement membrane may provide more rapid restoration of the alveolar architecture following lung injury ( 49 ). KGF also directly affects the expression of surfactant ( 70 ) and has been shown to stimulate the synthesis of all surfactant components in rat fetal ATII cells, thereby promoting maturation of the lung epithelium ( 7 ).\nThese studies raise the possibility that exogenous recombinant KGF protein might be used to stimulate alveolar epithelial repair in ALI and thus become a future therapy for ARDS. However, the significant cost of large quantities of rhKGF would likely limit the possibilities of prophylactic studies, particularly in larger animals and humans. Gene therapy, in which transfer of KGF DNA to alveolar epithelial cells may result in prolonged protein expression, has been proposed as an alternative approach. Thus, topical or systemic application of KGF-encoding plasmid DNA, complexed with cationic liposomes, may result in sufficient expression to produce ATII cell proliferation. Recently, the feasibility of this approach was demonstrated by Jeschke et al. ( 28 ) using liposome-mediated KGF gene transfer to improve dermal and epidermal regeneration following thermal injury in rats.\nSeveral experimental models of lung injury have been developed that demonstrate pathophysiological changes similar to those in ARDS ( 50 ). ALI induced by intravenous administration of oleic acid (OA) resembles ARDS in many morphological, histological, and physiological respects (reviewed in Ref. 53 ). OA-induced lung injury has been studied in many laboratory animal species and is consistently associated with severe respiratory distress characterized by hypoxemia and reduced lung compliance due to acute alveolar damage, intra-alveolar hemorrhage, and leakage of proteinaceous fluid into the air spaces ( 10 , 58 ). Histological changes include intra-alveolar edema and hemorrhage, epithelial disruption, fibrin deposition, and formation of hyaline membranes ( 11 , 29 , 52 ). The model has, however, not been well characterized in mice. Gene therapy for ARDS remains a relatively unexplored possibility, and mice have been used extensively as models of gene transfer to the lungs. With a view to investigating the potential of KGF gene therapy for ARDS, we therefore characterized a murine model of OA-induced lung injury and subsequently assessed the potential of both recombinant KGF protein and liposome-mediated gene transfer to ameliorate alveolar damage. For the latter, we assessed both topical and systemic administration, since KGF is a secreted protein, which may produce its biological effects whether produced by alveolar epithelium or pulmonary endothelium.\nMATERIALS AND METHODS\nPlasmid DNA\nThe human KGF (hKGF) cDNA was kindly supplied by Stuart Aaronson (Derald H. Ruttenberg Cancer Center, Mount Sinai School of Medicine, New York, NY) as a 2.1-kb insert in a pCEV9 backbone. The hKGF insert was excised from the pCEV9 backbone by restriction enzyme digestion and ligated into the eukaryotic expression vector pCI (Promega). The resulting plasmid was termed pCIhKGF. Evaluation of in vivo transfection efficiency was carried out using a plasmid expressing the reporter gene chloramphenicol acetyltransferase (pCF1CAT), kindly supplied by Genzyme (Framingham, MA). Large-scale purification of plasmid DNA for in vivo gene transfer was carried out using Qiagen EndoFree Giga plasmid purification columns according to the manufacturer's recommendations (Qiagen, Crawley, UK).\nIntratracheal Administration of rhKGF\nExperiments were carried out under the guidelines of the Animals (Scientific procedures) Act 1986, United Kingdom. Male BALB/c mice (6–8 wk, 19–25 g, Harlan) were anesthetized with Hypnorm/Midazolam/water (Hypnorm:MZ:H2O; 1:1:3, 0.1 ml/10 g body wt). The trachea was visualized by blunt dissection and KGF (Amgen, Thousand Oaks, CA), and 1, 5, 10, or 15 mg/kg body wt was injected directly into the trachea in a volume of no more than 60 μl. Control animals received an equal volume of KGF reconstitution solution (sterile H2O, 0.0055% Tween 20, Amgen). The incision was closed with two sutures using 6/0 silk braided suture (Johnson & Johnson, Edinburgh, UK), and the animals were left in a heated cage at 30°C until they fully recovered from the anesthetic. Analgesic (Vetagesic, 1 in 100 dilution, 6 μl/g body wt) was administered before surgery.\nImmunohistochemical Quantification of ATII Cell Proliferation\nAt appropriate time points (24 h to 1 wk) following rhKGF administration, animals were killed by dorsal arteriosection under terminal anesthesia, the trachea was cannulated, and the lungs expanded with 800–900 μl of 10% formalin (Sigma, Poole, UK). The lungs were removed in toto, immersed in 10% formalin, fixed overnight at room temperature, processed, and embedded in paraffin wax. Serial 4- to 5-μm sections were cut, and the first section was stained with Harris's hematoxylin and eosin (BDH, Lutterworth, UK) for overall morphology. ATII cells were stained with a rabbit anti-sheep surfactant protein B (SP-B) polyclonal antibody (Chemicon International, Southampton, UK). The SP-B antibody binds to the surfactant producing lamellar bodies within the ATII cell, which following binding to a secondary detection antibody can be visualized as a characteristic brown stain. The antibody also stains SP-B within Clara cells in the airways and any SP-B that has been engulfed by alveolar macrophages. However, airways were not included in the quantification process, and alveolar macrophages are morphologically and spatially distinct from ATII cells. Cross-reactivity was therefore not a confounding problem. Briefly, paraffin-embedded sections were dewaxed, and endogenous peroxidase activity was blocked with 3% H2O2. This was followed by 2-h incubation with normal goat serum (DAKO, Ely, UK). Primary antibody binding [rabbit anti-sheep SP-B (Chemicon)] was carried out for 1.5 days at 4°C, followed by binding of biotinylated goat anti-rabbit IgG secondary antibody for 1 h, incubation with streptavidin-horseradish peroxidase (DAKO) for 1 h, and incubation in 3,3′-diaminobenzidine tetrahydrochloride (DAKO) for 15 min. The slides were counterstained in Mayer's hematoxylin (BDH) for 1–2 min and then washed, dehydrated in graded alcohol, and mounted with DPX mountant (BDH). Immunoreactive ATII cells were identified as cells with brown staining within the cytoplasm and quantified by counting 10 randomly selected fields of view per slide (×200, 1 slide/animal). All slides were evaluated in a blinded fashion.\nTopical Gene Transfer\nPreparation of lipid67/KGF pDNA complexes.\nThe cationic liposome GL67 (Genzyme) was rehydrated in sterile endotoxin-free water to a final concentration of 1.2 mM. Plasmid DNA was resuspended in sterile endotoxin-free water to a final concentration of 1.6 mg/ml. Equal volumes of DNA and lipid were incubated separately at 30°C for 5 min to equilibrate temperature. Subsequently, the lipid was gently added to the DNA. The mixture was left to complex at 30°C for 15 min.\nIntranasal instillation of vector-DNA complexes.\nAnimals were individually anesthetized with methoxyflurane (Metofane; Mallingckrodt Veterinary, Mundelein, IL) in a closed chamber and held vertically while pressure was applied to the lower mandible to immobilize the tongue and prevent swallowing. Lipid-DNA complexes (80 μg pCIhKGF complexed with 120 μg GL67 in a total volume of 100 μl) were applied dropwise onto the nostrils of the animal with a pipette, allowing the mixture to be inhaled naturally. Control animals received the same volume of lipid complexed with an irrelevant plasmid (pCF1CAT).\nSystemic Gene Transfer\nPreparation of lipid and DNA.\nSequential injection of lipid and DNA was carried out as described by Tan et al. ( 60 ). Lipid [1,3-dioleoyl-3-trimethylammonium propane (DOTAP)/cholesterol in a 1:1 molar ratio, kindly supplied by Dr. Leaf Huang, Pittsburgh, PA] was diluted with 5% dextrose to contain 900 nmol of lipid in 100 μl. DNA (pCIhKGF or pCF1CAT) was prepared with sterile water to contain 50 μg in 100 μl.\nSequential injection of lipid and DNA.\nAnimals were anesthetized with Avertin (2.5%, 0.1 ml/10 g), the tail was heated transiently with warm water, and 100 μl of lipid solution (900 nmol) were injected into the tail vein. Two minutes later, 100 μl of the DNA (50 μg, pCIhKGF or pCF1CAT) solution were injected in a similar manner, and the animal was left to recover from the anesthetic in a heated cage at 30°C.\nTaqMan RT-PCR for Detection of Vector-Specific Expression\nWhole lungs were submerged in RNAlater (Ambion, Huntingdon, Cambridgeshire, UK) and stored at 4°C until further analysis. Samples were homogenized in 4 ml of RLT (Qiagen) before extraction of total RNA using RNeasy mini protocol (Qiagen). Levels of plasmid-derived mRNA were quantified by real-time quantitative multiplex TaqMan RT-PCR using the ABI Prism 7700 Sequence Detection System and Sequence Detector version 1.6.3 software (Applied Biosystems, Warrington, Cheshire, UK). The oligonucleotide primer and fluorogenic probe sequences were designed using Primer Express Software version 1.0 (Applied Biosystems). Plasmid-specific mRNA from the pCIhKGF was quantified using forward primer (5′-GCTTCTGACACAACAGTCTCGAA-3′), reverse pCI primer (5′-GGAGTGGACACCTGCCCA-3′), and the fluorogenic pCI probe (5′-FAM-TGCCTCACGACCAACTTCTGCAGC-TAMRA-3′). 18S ribosomal RNA was quantified using Ribosomal RNA Control Reagents (Applied Biosystems).\nRNA was heated to 75°C for 5 min and then reverse transcribed with TaqMan RT reagents (Applied Biosystems). The RT-reaction mix (5 μl) consisted of 1× TaqMan RT buffer, 5.5 mM MgCl2, 500 μM each dNTP, 0.4 U/μl RNase inhibitor, 1.25 U/μl MultiScribe reverse transcriptase, 0.4 μM pCI reverse primer, 0.4 μM reverse rRNA primer, and ∼5 ng total RNA. Reactions were incubated at 48°C for 30 min followed by 95°C for 5 min. Subsequently, triplicate 25-μl PCRs were performed for each sample. Each 25-μl reaction consisted of 1× TaqMan Universal PCR Mastermix (Applied Biosystems), 300 nM forward pCI primer, 300 nM reverse pCI primer, 100 nM pCI probe, 50 nM forward rRNA primer, 50 nM reverse rRNA primer, 50 nM rRNA probe, and 5 μl reverse-transcribed template. Reactions were incubated at 50°C for 2 min and then 95°C for 10 min followed by 40 cycles of 95°C for 15 s and 60°C for 1 min.\nControls included no template and no reverse transcriptase control in which total RNA or MultiScribe reverse transcriptase and RNase inhibitor were omitted from the reverse transcriptase reaction, respectively. Relative levels of plasmid-derived mRNA were determined using the ΔCT method (as described in Ref. 1a ). In this study, the amount of pCI plasmid was normalized to 18S rRNA (endogenous reference) and expressed relative to a calibrator that was used throughout the study. The calibrator was total RNA extracted from mouse lung treated with 100 μg of pCIkLux in 150 μl via intranasal instillation (as described above) and harvested 24 h postdose.\nDetection of Transgene Expression\nKGF expression in lung homogenate.\nKGF ELISA was carried out using ELISA development reagents according to the manufacturer's recommendations (R&D Systems, Abingdon, UK). Lung homogenates (100 μl) from KGF-transfected mice or rhKGF standards were tested. Absorbance was determined in a microplate reader at 450 nm (wavelength correction 540 and 570 nm). The KGF concentration was calculated from a standard curve using known amounts of hKGF (1,000 pg/ml to 15.6 pg/ml) correlated to amount of protein detected in the lung homogenate.\nInduction of Lung Injury\nMale BALB/c mice (6–8 wk, 19–25 g; Harlan, Bicester, UK) were anesthetized with Avertin (2.5%, 0.1 ml/10 g). The trachea was visualized by blunt dissection, and the animal was intubated via the oral route with a 22-gauge cannula (3S Healthcare, London, UK). Mechanical ventilation (120 strokes/min, stroke volume 200 μl) was carried out using a MiniVent (type 845; Hugo Sachs Elektronik). OA (0.2 ml/kg or 0.4 ml/kg body wt; Sigma, Poole, UK) suspended in 50 μl of sterile PBS was administered through the tail vein with a 0.5-ml insulin syringe (3S Healthcare). Control animals received 50 μl of PBS. Animals were monitored for the 1-h duration of the experiment and then killed by anesthetic overdose.\nLung Wet-To-Dry Weight Ratios\nLungs were removed in toto at the end of the experiment. The trachea and esophagus were separated from the lungs by blunt dissection, and the wet weight of the latter was determined. Subsequently, the lungs were incubated at 55°C overnight to remove all moisture. The dry weight was then measured, and the ratio of wet-to-dry weight was calculated.\nBAL\nThe animal was extubated, and a 22-gauge cannula (3S Healthcare) was inserted into the trachea. The lungs were lavaged with 500 μl of PBS three times (total volume 1.5 ml). Retrieval volume was maximized by compression of the thorax following the last lavage.\nTotal Cell Counts\nBAL fluid (BALF) samples were centrifuged at 900 relative centrifugal force (gav) for 5 min at 4°C, the supernatant was removed, and the pellet was resuspended in 100 μl of PBS. Ten microliters of the cell suspension were stained with crystal violet stain (BDH), and nucleated cells were counted in a Neubauer hemocytometer. A total of 0.5 × 106 cells in a volume of 100 μl of PBS were centrifuged (Cytospin 3; Shandon, Astmoor, UK) onto slides (700 gav for 4 min) and stained for 5 min with May and Grunwald and Giemsa stains (BDH). The slides were quantified for macrophages, neutrophils, and lymphocytes by counting a total of 200 cells/slide at ×25 magnification.\nMacrophage Inflammatory Protein-2 in Lung Homogenates\nMacrophage inflammatory protein-2 (MIP-2) levels were measured using a precoated murine MIP-2 colorimetric sandwich ELISA kit (R&D Systems) according to the manufacturer's recommendations. The MIP-2 concentration in the lung homogenate supernatant was calculated from a standard curve using known amounts of murine MIP-2 in a range from 7.8 pg/ml to 500 pg/ml.\nBALF\nTotal protein and lactate dehydrogenase measurements.\nThe total protein concentration in the BALF supernatant was measured by the Folin-Lowry method ( 48 ). Lactate dehydrogenase (LDH) levels were determined by the rate of pyruvate substrate conversion to lactate according to the manufacturer's recommendations (Sigma Diagnostics, Poole, UK).\nAlbumin estimation.\nTo quantify the leak of albumin from the serum into the alveoli, the albumin concentration in the BAL supernatant was measured. This was carried out according to the manufacturer's recommendations (Sigma Diagnostics). The absorbance was measured spectrophotometrically at 628 nm (Unicam UV1; Thermo Electron Spectrometry, Cambridge, UK). The albumin concentration in the samples was calculated from a standard curve generated by using known amounts of murine albumin (Sigma) in the range of 5–100 mg/ml.\nQuantification of Lung Injury\nLight microscopy.\nAll slides were coded and evaluated in a blinded fashion to prevent bias. A point scoring system was used to quantify the extent of lung injury and was defined semiquantitatively as the presence of any one of: 1) capillary congestion; 2) alveolar/interstitial edema; 3) presence of fibrin; 4) alveolar/interstitial hemorrhage; 5) necrosis; or 6) alveolar/interstitial neutrophils. The mean % damage score for an animal was calculated by counting a total of 24 randomly selected fields/slide (×200 magnification) for one section. For quantification, each field of view was required to contain >50% alveolar tissue.\nTransmission electron microscopy.\nThe lungs were inflated with fixative (2.5% glutaraldehyde, 50 mM sodium cacodylate buffer) in situ to a constant pressure of 25–30 cm and removed in toto into fixative and stored at 4°C for a minimum of 24 h. Samples of parenchyma of the left lobe and right upper lobe were postfixed in 1% osmium tetroxide in 50 mM sodium cacodylate buffer, dehydrated in graded alcohol and propylene oxide, and subsequently embedded in Araldite epoxy resin. Blocks were initially cut as semithin sections (1 μm) on a Reichart Ultracut E and stained with 1% toluidine blue (in 1% sodium tetraborate) for the purposes of orientation and initial morphological assessment. Ultrathin (80–100 nm) sections were cut, contrasted with uranyl acetate and lead citrate, and examined with a Hitachi 7000 transmission electron microscope.\nPhysiological Measurements of Lung Function: Dosing Optimization\nAdministration of OA for the physiological measurements of lung function was undertaken via a catheter placed in the jugular vein, as tail vein administration proved difficult and unreliable due to the experimental set up needed for lung function measurements. More efficient OA delivery is likely through the jugular compared with the tail vein. In keeping with this, administration of 0.2 ml/kg through the jugular vein resulted in 100% mortality within 1 h, equivalent to that seen with 0.4 ml/kg through the tail vein. Reduction of the jugular dose to 0.1 ml/kg prevented premature deaths over the 1-h time period, as was the case for 0.2 ml/kg administration by tail vein injection. Thus 0.1 ml/kg was used for all studies of lung mechanics and blood gas analysis.\nPhysiological Measurements of Lung Function\nLung physiological measurements were carried out as previously described in detail by Wilson et al. ( 68 ). In brief, male BALB/c mice (8–10 wk, 22–28 g, Harlan) were anesthetized by intraperitoneal injection of Hypnorm/Midazolam (Hypnorm:MZ:water 1:1:3, 0.1 ml/10 g) and placed in the supine position. An endotracheal cannula [0.76-mm inner diameter (ID), 1.22-mm outer diameter (OD)] was inserted via tracheotomy and secured with a suture. Animals were ventilated with a custom-made mouse jet ventilator system, as described by Ewart et al. ( 17 ). Airway pressure was monitored by a pressure transducer (MLT0380; ADInstruments , Chalgrove, UK), and airway flow was determined by a differential pressure transducer (PX137; OMEGA Engineering, Manchester, UK) connected to a miniature pneumotachogram in the ventilator circuit. A polyvinyl chloride (PVC) catheter (0.28-mm ID, 0.6-mm OD; Critchley Electrical Products, Silverwater, Australia) was introduced into the left carotid artery for monitoring arterial pressure using a pressure transducer (MLT844, ADInstruments ) and measurement of blood gases. Rectal temperature was maintained between 36 and 37°C by the use of a heated pad. All data collected from the ventilator and blood pressure transducers during the experiment were recorded by PowerLab Data Recording System ( ADInstruments ).\nAfter standardization of volume history of the lungs with a sustained inflation of 35 cm/H2O for 5 s, the animals were ventilated with a tidal volume of 9–10 ml/kg, a respiratory rate of 120 breaths/min, and inspiratory:expiratory ratio of 1:2 throughout the experiment. Administration of OA was carried out via a jugular vein cutdown and cannulation. Briefly, 0.1 ml/kg of OA was loaded into 0.28-mm single-lumen PVC tubing (Critchley Electrical Products) and connected to the jugular vein line with a 30-gauge needle. OA was infused at a controlled rate using a syringe pump (0.3 ml/h, KD Scientific). Control animals received an equal volume of sterile PBS. Respiratory system compliance and resistance were measured every 15 min by the end-inflation occlusion technique. Blood gas analyses were made on serial arterial blood samples (60 μl) collected via the carotid cannula before and at 30 min and 1 h after OA administration and analyzed by a fetal scalp blood gas analyzer (Chiron Rapidlab 248; Bayer Diagnostics, Newbury, UK).\nStatistical Analysis\nData are cases represented in summary plots that are based on the median, quartiles, and extreme values. The box represents the interquartile range, which contains the 50% of values. The whiskers are lines that extend from the box to the highest and lowest values, excluding outliers, which are defined separately with circles. A line across the box indicates the median. Selected data (see Figs. 3A and 4 ) are represented as dot plots or as median ± first and third data quartile (see Fig. 9 ). Comparison of data between groups used the Kruskal-Wallis analysis of variance for multiple unpaired, nonparametric groups, followed (where permitted) by Mann-Whitney's U-test, with the Bonferroni correction for multiple comparisons. The null hypothesis was rejected at P < 0.05.\nRESULTS\nrhKGF Produces A Dose- and Time-Related Increase in ATII Cells\nIntratracheal instillation of rhKGF at 1–15 mg/kg body wt resulted in a significant (P < 0.01 for all groups) increase in SP-B-positive cells compared with animals receiving diluent alone 2 days following administration ( Fig. 1A ). The KGF-induced increase in ATII cell numbers was dose related with a peak of proliferation following 10 mg/kg of rhKGF [23 ± 2.7 compared with 8.2 ± 1 ATII cells/field of view (×200 magnification) following administration of diluent]. Representative images of SP-B immunohistochemical staining in animals receiving the diluent alone or rhKGF at 10 mg/kg body wt are shown in Fig. 2 . To ensure SP-B antibody specificity, morphological counting of ATII cells using hematoxylin and eosin-stained sections was also carried out. Significantly (P < 0.01) increased numbers of ATII cells were seen at all KGF doses (1 mg/kg, 15.2 ± 3.4; 5 mg/kg, 21.5 ± 5.2; 10 mg/kg, 28.4 ± 3.6; 15 mg/kg, 28.3 ± 2.2 compared with 10.1 ± 1.4 in animals receiving the diluent). In agreement with SP-B immunohistochemistry, 10 mg/kg produced the peak effect.\n""","0.1703136","""http://ajplung.physiology.org/content/288/6/L1179""","[-0.178219,51.500505]"
"""StaffOxfordUniversityVariousDepartments1""","""Chronic creatine kinase deficiency eventually leads to congestive heart failure, but severity is dependent on genetic background, gender and age — Radcliffe Department of Medicine""","""Publications\nChronic creatine kinase deficiency eventually leads to congestive heart failure, but severity is dependent on genetic background, gender and age\nChronic creatine kinase deficiency eventually leads to congestive heart failure, but severity is dependent on genetic background, gender and age\nLygate CA., Medway DJ., Ostrowski PJ., Aksentijevic D., Sebag-Montefiore L., Hunyor I., Zervou S., Schneider JE., Neubauer S.\nThe creatine kinase (CK) energy transport and buffering system supports cardiac function at times of high demand and is impaired in the failing heart. Mice deficient in muscle- and mitochondrial-CK (M/Mt-CK-/-) have previously been described, but exhibit an unexpectedly mild phenotype of compensated left ventricular (LV) hypertrophy. We hypothesised that heart failure would develop with age and performed echocardiography and LV haemodynamics at 1 year. Since all previous studies have utilised mice with a mixed genetic background, we backcrossed for[10 generations on to C57BL/6, and repeated the in vivo investigations. Male M/Mt-CK-/- mice on the mixed genetic background developed congestive heart failure as evidenced by significantly elevated end-diastolic pressure, impaired contractility, LV dilatation, hypertrophy and pulmonary congestion. Female mice were less severely affected, only showing trends for these parameters. After backcrossing, M/Mt-CK-/- mice had LV dysfunction consisting of impaired isovolumetric pressure changes and reduced contractile reserve, but did not develop congestive heart failure. Body weight was lower in knockout mice as a consequence of reduced total body fat. LV weight was not significantly elevated in relation to other internal organs and gene expression of LVH markers was normal, suggesting an absence of hypertrophy. In conclusion, the consequences of CK deficiency are highly dependent on genetic modifiers, gender and age. However, the observation that a primary defect in CK can, under the right conditions, result in heart failure suggests that impaired CK activity in the failing heart could contribute to disease progression. © The Author(s) 2012.\n""","0.4429465","""https://www.rdm.ox.ac.uk/publications/342974""",
"""University_of_Birmingham""","""Public health policy and walking in England—analysis of the 2008 ‘policy window’ | BMC Public Health | Full Text""","""Public health policy and walking in England—analysis of the 2008 ‘policy window’\nAbstract\nBackground\nAlthough the government in England has a long-standing interest in walking promotion, this has not been accompanied by a coherent strategic plan or investment to support physical activity behaviour change. However, in 2008 the government announced its intention to invest £7 million into walking promotion. This article utilises Kingdon’s Multiple Streams framework as an organising principle through which to interrogate the reasons behind the increased emphasis on walking promotion as part of the public health policy agenda in England.\nMethods\nThe research adopted a case study design. Data were obtained through document analysis of relevant policies and semi-structured interviews with experts in the walking sector, including both government and non-government representatives.\nResults\nKingdon’s Multiple Streams theory proposes that at certain points in time, ‘policy windows’ are created through the convergence of a problem, an appropriate solution, and a receptive political environment, and this policy window presents an opportunity for major policy change. The findings of this research suggest that the success of London in securing the 2012 Olympic and Paralympic Games was the primary trigger in the creation of a policy window for walking promotion in recent years.\nConclusions\nDespite previous interest in walking promotion from the health and transport sectors, it was the recent alignment with the sports agenda that led to increased political commitment. This raises concerns that the research evidence on the health benefits of physical activity and rising levels of inactivity in England, are insufficient to secure government support and investment, and that multi-sector lobbying and joined-up political action may be critical in advancing this agenda.\nKeywords\nPublic healthPolicyWalkingEnglandMultiple Streams\nBackground\nEpidemiological research clearly demonstrates that adults who are physically active have a reduced risk of developing many non-communicable diseases (NCDs) including coronary heart disease (CHD), stroke, hypertension, and type II diabetes [ 1 ]. Despite these benefits, modernisation, urbanisation, and advances in technology have led to reductions in physical activity levels globally [ 2 ]. In 2011, the World Health Organization (WHO) estimated that more than 30 % of adults worldwide did not engage in sufficient levels of physical activity to benefit their health and prevent disease [ 3 ]. Consequently, physical inactivity has been identified as the fourth leading risk factor for premature mortality, accounting for an estimated 6 % of global mortality (3.2 million deaths annually) [ 4 ]. In England, recent surveillance data suggests that over 40 % of adults are failing to meet recommended physical activity levels [ 5 ]. As a result, physical inactivity is thought to cause 3.1 % of morbidity and mortality in England, and is responsible for 35,000 deaths annually [ 6 ].\nBrisk walking is a ‘sufficient’ activity to benefit health [ 7 – 9 ] and is viewed as one of the most acceptable and accessible forms of physical activity [ 10 ]. Walking is free of charge, does not require specialist equipment or facilities, and can be easily incorporated into everyday life. Walking is an ideal introduction to physical activity for people who are overweight or extremely unfit [ 11 ], and being a low impact activity, walking poses relatively few risks of injury [ 12 ]. For these reasons, walking has been identified as the form of activity with the greatest potential for increasing the overall activity levels of an inactive population [ 9 , 13 ] and also as the most likely way that all adults can achieve recommended physical activity levels [ 14 ].\nThere is increasing recognition among physical activity researchers, of the role of policy in addressing population levels of physical inactivity [ 15 , 16 ]. The development of a national policy framework is important to raise the profile of physical activity as a priority area and to provide a coherent action plan or programme of activities aimed at increasing population prevalence of physical activity [ 17 ]. Due to its broad accessibility and acceptability it has been proposed that “walking must be central to any strategy to increase physical activity” [ 18 ].\nPhysical activity and health began to be recognised as an issue requiring government support in England in the early 1990s. The ACTIVE for LIFE campaign, which was funded by the Department of Health (DH), aimed to raise awareness of the health benefits of being active and encourage regular physical activity as part of a healthy lifestyle. The campaign had a strong focus on walking, but was not accompanied by a strategic plan or investment in infrastructure or programs to support physical activity behaviour change.\nDespite initial leadership for the physical activity and health agenda from DH, the Department for Transport (DfT) began to recognise the role of walking and cycling in meeting its objectives around reducing congestion and carbon emissions. In 1996 DfT published a National Cycling Strategy [ 19 ] and announced its intentions to develop a national walking strategy [ 20 ]. Although a strategy to promote walking did not emerge until 2004, this also came from DfT in the form of Walking and Cycling: An Action Plan.\nPhysical activity promotion generally, and walking promotion specifically, has the potential to contribute to the aims and objectives of a wide range of government departments. In addition, many of the actions to promote walking fall within the remit of different departments such as health, transport, education, environment, and urban planning. Thus there has been no natural ‘home’ for walking promotion, which has presented challenges to developing a coherent and coordinated national policy.\nSince the early 2000s, several non-government organisations have established large scale walking initiatives. For example, the Countryside Agency established the national ‘Walking for Health’ programme (originally known as the Walking the Way to Health Initiative) and also the National Step-O-Meter Programme. These activities were traditionally funded through agencies such as the British Heart Foundation and the Big Lottery, as opposed to the government. However, in 2008 the government announced its intention to invest £7 million in a programme of “innovative campaigns to encourage people to walk more” [ 21 ]. This level of commitment and investment in walking promotion was unprecedented and presented a real opportunity for those working in physical activity and walking promotion to develop and deliver large-scale interventions aimed at improving the nation’s health.\nIn order to move beyond simply a description of this example of policy development, this article turns to the study of policy agendas and considerations of how issues come to be issues in the first place, how agendas change over time, and the factors which determine why some issues are given more government attention than others [ 22 ]. The conceptual framework put forward in this article, Kingdon’s Multiple Streams theory [ 23 ], serves to shed light on and explain the increased emphasis on walking promotion as part of the public health policy agenda in England. In doing so, this paper aims to answer the following questions:\n1.\nMethods\nConceptual framework\nDue to the complex nature of the policy making process, a range of theories and conceptual frameworks have been developed; these constructs serve the purpose of focusing the policy analyst’s attention on important elements within the policy process, while helping the analyst to apply structure or typologies to an otherwise chaotic and unwieldy course of events. Kingdon’s Multiple Streams framework is particularly focused on the agenda setting process and, as such, lends itself to answering the questions posed in this article [ 23 ]. This framework suggests that the policy process consists of three distinct sets of processes or ‘streams’: 1) problems; 2) policies; and 3) politics. At key points in time the three streams are joined—a problem is recognised, an appropriate solution is identified, and the political ‘mood’ is right for the government to embrace and drive forward policy change. This confluence of the three streams is referred to as a ‘policy window’; a juncture at which an opportunity for major policy change can be grasped. Kingdon’s framework is put forward as a useful heuristic device with which to understand agenda setting and policy change.\nStudy design\nThe research adopted a case study design. Therefore the focus was on gaining in-depth insights into the political processes surrounding walking promotion in England, rather than making generalisations about the applicability of the findings to other cases. Data were obtained through document analysis and semi-structured interviews and triangulation techniques were used to verify the validity of the results [ 24 ]. The focus of the research was on the period up to October 2012. The study was approved by Loughborough University Research Ethics Committee.\nDocument analysis\nA literature and web search was undertaken to identify both past and present documents relevant to walking policy in England. The web-search mainly focused on the websites of DH, DfT, and the Department for Culture, Media and Sport (DCMS). Various search terms were used including ‘physical activity’, ‘active travel’ and ‘walking’, and all identified documents were considered. To ensure the comprehensive inclusion of relevant documents, all interviewees were asked to identify documents that they felt were important for understanding the development, content, and/or implementation of walking policy in England. Any documents which had not been previously identified were obtained and included in the analysis. A list of the key documents included in the analysis is provided in Table  1 .\nTable 1\nWalk England (2008).\n \nAlthough each of these organisations is concerned, in some way, with walking promotion, the aims and objectives of each organisation differ and include access to the countryside, pedestrian safety, and transport emissions. The organisations vary substantially in terms of their size and resources; the largest organisations are the Ramblers and Sustrans, while the smallest organisation is Walk England. The primary purpose was not to compare across cases but to consider each organisation’s perspective in order to reach well-rounded conclusions about the development and dynamics of walking promotion as a public health policy issue in England.\nKey representatives from each of these organisations were identified using existing knowledge of the organisations and by searching their respective websites. The selected interviewees were either the Chief Executive Officer (CEO) (particularly for smaller organisations) or, if appropriate, the strategic lead for walking and/or health (particularly for organisations with a broader agenda). In addition, DH and DfT have been identified as the ‘main players’ in promoting physical activity for adults [ 25 ]. Interviews were conducted with representatives from each of these departments; the interviewees were the Head of Physical Activity and the Head of Active Travel, respectively.\nSnowball sampling was used to complement the purposive approach [ 26 ]. This involved asking each of the interviewees to identify other colleagues or acquaintances with relevant knowledge and experience who they felt would make a valuable contribution to the research. This approach led to the identification of interviewees from several other organisations including Intelligent Health (a limited company which aims to create physical activity opportunities close to where people live and work), Knowledge into Action (a charity focused on improving health and healthcare), and Sport England (the DCMS funded body responsible for the delivery of sport in England from grassroots to elite level), as well as several independent consultants and other known advocates.\nThe interview schedule typically included the following themes: how walking fits within the aims and objectives of the different organisations; the roles of the different NGOs within the broad field of walking promotion; which aspects of the broad walking agenda agencies are mostly closely aligned to; how the organisations are funded; who they are accountable to; the main programs that the organisations deliver; relationships/collaborations with other organisations; relationships with government; level of political influence of each NGO; perceptions of how the issue of walking has been dealt with by the government; and barriers to establishing greater political support and investment into walking promotion in England. The interview schedule for the government representatives included questions on: how responsibility for walking promotion has been allocated or dispersed across government; consultation and decision making processes related to the development of walking policy; the main challenges in developing and implementing policy to promote walking; and relationships and interactions with the key NGOs on walking related issues.\nFifteen interviews were conducted in total and took place between April and October 2012. The duration of interviews ranged from 35 min to two hours, and the typical length was one hour. All interviews were recorded on a digital audio device, with consent, and were subsequently transcribed verbatim. Each transcript was sent to the respective interviewee, to confirm that it accurately conveyed what was said or intended. In total, the interview data consisted of 285 pages of transcript.\nData analysis\nBoth the documents and the interview transcripts were uploaded into NVivo qualitative software package and analysed using inductive content analysis. Therefore, the coding categories and the names for each concept and theme were derived directly and inductively from the data. The coding themes were then allocated to one of the following three groupings: problems; policies; and politics, in order to analyse the results in relation to Kingdon's Multiple Streams framework [ 23 ]. To confirm the reliability of the analysis, all data were coded on two separate occasions, allowing the lead researcher to confirm or refine the coding system developed during the initial analysis.\nResults\nThe following section is set out according to the broad, yet distinct categories in Kingdon’s Multiple Streams framework: problems; policies; and politics. The article focuses on events and decisions taking part in each of these ‘streams’ before considering how these factors have converged to make a ‘policy window’ for increased support and investment in walking promotion in England.\nThe problem stream\nWalking levels in England have been in decline since the mid-1970s and this reduction in walking has been accompanied by an increase in car use [ 27 ]. The consequences of this shift include reduced overall physical activity levels, increased traffic congestion, and higher levels of carbon emissions. The problems associated with low levels of walking have been recognised by several well established interest groups/organisations, which formed a key focus of the empirical research. These types of interest groups play an important role in nearly every aspect of health policy, from bringing issues to the attention of government, proposing new policy options, and building pressure for action [ 28 ].\nIt is imperative that issues are defined in a way which will attract political interest. According to Weiss [ 29 ], issue definition is concerned with the organisation of a set of facts, beliefs, and perceptions, or ‘how people think about circumstances’. The way in which an issue is ‘packaged’ determines how it is perceived by both policymakers and the public and thus can impact upon the agenda-building process [ 30 ]. ‘Symbols’, which can be described as “objects to which people attach political significance”, are used to attract attention to an issue, to define an issue in a specific way, and to mobilise support for specific policy options over others [ 30 ]. The issue of walking promotion has been defined or ‘packaged’ in three primary ways: as a health issue; a transport issue; and as an environment issue; and this has impacted on how responsibility for walking promotion has been dealt with by the government. A senior staff member from the Ramblers stated, for example:\n“I think it has been spread between transport and health and environment… and it’s kind of shifted and moved around depending on whether you’re talking about the countryside or whether you’re talking about urban walking, or obesity or issues like that” (London, May 2012).\nSometimes recognition that a problem exists is sufficient for the problem to make it onto the political agenda; however there are usually many problems competing for recognition, meaning that only a fraction of them make it into the formal process of political deliberations. Which problems receive government attention is often influenced by ‘policy entrepreneurs’ [ 23 , 31 ]. These entrepreneurs are highly motivated individuals who seek to raise the profile of an issue among both government officials and the general public. Policy entrepreneurs typically hold positions of leadership within relevant interest groups and are usually well connected politically. The main roles of an entrepreneur are to define and reframe problems, advocate new ideas, specify policy alternatives, broker ideas among policy actors, mobilise public opinion, and help set the decision-making agenda [ 32 ].\nThere have been several long standing advocates for walking promotion, who have been instrumental in bringing the issue to the attention of government and for encouraging political action. These include Dr William Bird, a general practitioner who was instrumental in the establishment of the national led walk program Walking for Health, and Sir Muir Gray, who has held several senior positions in preventive health and has been described as a “a ceaseless champion of walking as a means of tackling obesity and inactivity” [ 33 ]. A former employee at DH reflected on the powerful influence of these types of policy entrepreneurs:\n“They can walk the talk. They brought good examples of what was happening elsewhere… you talk about people being influential and stuff like that. It's a fact of life that certain people will like other people and listen to what they say. And it happens more than you could ever believe in terms of someone having the ear of a Minister” (London, July 2012).\nThe lobbying efforts of these policy entrepreneurs have been facilitated by several factors including growing research evidence on the health benefits of walking [ 9 , 10 ] and prevalence data on rising levels of inactivity, for example from the ‘Allied Dunbar Fitness Survey’ [ 34 ], and more recently the Health Survey for England [ 5 , 35 ]. One of the biggest challenges for these policy entrepreneurs, however, has been to convince policymakers that walking promotion legitimately falls within the government’s remit. There is a long history of policy in England which emphasises the importance of individuals taking responsibility for their own health behaviours. For example, Saving Lives: Our Healthier Nation [ 36 ], identified behavioural risk factors such as smoking and physical activity as an individual responsibility and beyond the remit of the government. Even some of the more recent policy documents, including Healthy Lives, Healthy People—A Call to Action on Obesity in England [ 37 ], emphasise the need for individuals to take responsibility for their own health by making healthier lifestyle choices. Therefore the challenge has not only been to convince the government of the magnitude and consequences of the problem of low walking levels but also to convince them that dealing with the problem is a government responsibility.\nAn additional barrier to walking promotion, which was expressed by representatives from both DH and DfT, is the perception that walking is such a simple behaviour that the general public will not view walking promotion as sufficiently complex or necessitating high level expertise, to warrant political attention, and thus this will not be considered an appropriate use of scarce government resource. This sentiment is captured by the following quote from a senior government official:\n“Governments can feel a little foolish promoting walking in a sense that it's a Daily Mail headline—Government tells people to walk!—Government gives people lessons on walking! Suddenly you can be ridiculed because it’s such a natural thing to do” (London, April 2012).\nThe policy stream\nThe linking of solutions to policy problems is thought to increase the chances of gaining political attention and support for an issue. Having pre-formulated policy solutions can increase the government’s confidence that there are appropriate solutions to the identified problem and thus that the problem can be dealt with in a timely fashion without the need for drawn-out political deliberations on appropriate policies. Therefore once one or more problems are identified, ‘policy communities’, consisting of experts in the area, try to affix solutions to the problem, usually driven by their own values and interests [ 38 ].\nEach of the key walking organisations has conceptualised different policy solutions, including led walk schemes, infrastructure changes to improve the environment for walking, and resources such as websites and maps. Multiple Streams theory holds that the survival of ideas and solutions in the policy stream is determined by three factors.\nFirst, the degree of technical feasibility, which relates to how easily a theoretically sound idea can actually be translated into practice. Ideas that can make the transition from theory to practice with the least difficulty are thought to stand a better chance of survival.\nSecond, survival is determined by whether solutions are widely supported by a range of specialists within the policy community. The more wide-spread support there is for a policy solution, the greater the likelihood that the solution will be adopted.\nThe third factor relates to budgetary implications, with less costly solutions often receiving a greater level of support from policymakers [ 22 ].\nIn recent years two walking programmes have received substantial government resource; Natural England’s Walking for Health programme and Walk England’s Walk4Life Miles project, which received £3 million and £1.4 million respectively from DH in 2008. Natural England’s Walking for Health programme is a led walk initiative, established in 2000. Walking for Health had already expanded into a national programme and in 2010 the programme consisted of over 600 local schemes, all of which were delivered by a network of over 11,000 trained volunteers [ 39 ]. This programme, in many ways, met Kingdon’s proposed criteria for survival within the policy stream. Walking for Health had a proven track record of feasibility, the programme had widespread support from various stakeholders (and particularly Dr William Bird), and it could be delivered at relatively low cost due to the engagement of a large network of (existing) volunteers.\nWalk England’s Walk4Life Miles project was a new initiative which would involve setting up 2012 one mile sign-posted walking routes across the country. It was envisaged that the one-mile routes would be safe, attractive, and connected to where people live, and that people would be able to use the miles to test their fitness, using the principles of the Rockport One-Mile Walk Test [ 40 ]. The aim of the project was to get 30,000 people to improve their fitness and sustain an increase in physical activity [ 41 ]. The simplicity of this intervention would facilitate judgements of feasibility and cost and, although there was not wide spread support for the initiative from the walking sector as a whole, it was lobbied for fiercely by Walk England, as illustrated by the following quote:\n“I found out that Walk England had snaffled a million quid… the reason that happened was that [they] never got off the phone from [the Department of Health]. They badgered, badgered, badgered, badgered and badgered. And just badgered [the Department of Health] so badly that in the end that’s what happened” (London, May 2012).\nAlthough the ‘evidence-based policy movement’ has sought to promote the rigorous analysis of policy options in order to improve decision-making [ 42 , 43 ], the findings of this research lend support to Head’s suggestion that policy development is often based more on politics and professional judgement, rather than on research evidence alone [ 43 ], and highlights the influence that key ‘policy entrepreneurs’ can have in the decision making process.\nThe politics stream\nThe politics stream relates to the political ‘mood’ and openness to change based on the current political climate [ 22 , 23 ]. Clearly a range of factors such as impending elections, a change in government, and interest group activity can lead to the inclusion or exclusion of different topics on the political agenda, as well as influencing how these problems are perceived by the electorate and policymakers, and how potential solutions are evaluated.\nIn July 2005 it was announced that London would host the 2012 Olympic and Paralympic Games. Subsequently DCMS released Before, During and After: Making the Most of the London 2012 Games [ 21 ], which outlined the Government’s intention to make the UK a world-leading sporting nation. However a key feature of both the bid and the subsequent policy was the promise of delivering a ‘physical activity legacy’ which would inspire population increases in sport and physical activity, or, as one interviewee summarised it, political interest in physical activity and walking promotion was bolstered by the world’s largest sports mega-event: “The driver, I would say, was the Olympics, because funding was allocated to help meet that target” (London, July 2012).\nSpecifically this policy identified the target of getting two million more people ‘active’ by 2012, and committed to investing £7 million into walking promotion as a key approach to achieving this target. Interestingly, the basis of this legacy is the belief that elite sport success can act as a catalyst for increased physical activity and sport participation among the masses; a belief that has little evidence from previous sports mega-events [ 44 – 47 ].\nThe ‘policy window’\nAt key points in time the three streams outlined above are joined together: a problem is recognised, an appropriate solution is identified, and the political ‘mood’ is right for the government to embrace and drive forward policy change. This confluence of the three streams is referred to by Kingdon as a ‘policy window’.\nThe success of London in securing the 2012 Olympic and Paralympic Games was the primary trigger in the creation of a policy window for walking promotion in recent years. The profile of hosting this mega-event meant that political interest was high, and the subsequent promise of delivering a physical activity legacy provided a ‘problem’ in that the government were now required to provoke large scale increases in physical activity [ 21 , 48 ]. Time and resources were allocated to delivering this target and thus the government were seeking appropriate policy solutions in which to invest. A former employee at DH recollected on this situation:\n“We had a target to meet and we had to get two million people active so we had to find programmes that would do that and it was very clear that the biggest potential was in walking. I think what possibly wasn’t clear was what the right interventions were” (London, July 2012).\nTherefore, the role of interest groups and policy entrepreneurs was to identify appropriate policy solutions and to convince the government of their value. Two organisations were successful in this endeavour, Natural England and Walk England.\nA key feature of the policy window however, is that as quickly as it opens, it may close, due to other competing agendas or simply a change in the political ‘climate’. In May 2010 there was a general election and a change in government. When the new government came into power, the UK (and the rest of the world) was in the midst of an economic recession. In an attempt to address the economic crisis the coalition government undertook a review of non-departmental public bodies, including Natural England. The review concluded that Walking for Health was peripheral to Natural England’s core objectives and was not something that it should be delivering. A competitive tendering process ensued and in March 2012, the Ramblers took over the coordination of the Walking for Health programme [ 49 ].\nIn addition, there was a Treasury review of the public spending commitments made by the previous government between 1st January 2010 and the General Election [ 50 ]. This review examined £34 billion of spending that was approved during the previous government’s final few months in office. The aim of the review was to assess whether these commitments were affordable, whether they would deliver value for money, and whether they were considered a priority for the new government. In total 12 projects were cancelled because they were deemed unaffordable and not a government priority, one of which was Walk England’s Walk4Life Miles project. This is an example of the ‘window of opportunity’ closing due to a change in politics.\nDiscussion\nThis article reports on the application of Kingdon’s Multiple Streams theory to explain the recent rise of walking promotion on the political agenda in England. The framework provided a useful structure for the study of agenda setting in this discrete area of policy, thus reinforcing the utility and wide applicability of Kingdon’s Multiple Streams theory for policy analysis.\nThe analysis identified the London 2012 Olympic and Paralympic Games as the primary driver behind the government’s increased interest in walking promotion in England. Both the 2012 Games bid and the subsequent policy used the rhetoric of inspiring population level increases in physical activity. It is interesting to note that despite a long-standing interest in walking from DH and DfT, it was alignment with the sports agenda that led to increased investment in walking promotion in recent years. This is supported by the concept of ‘generalisation of interests’ which proposes that if policy entrepreneurs are able to demonstrate the relevance of an issue to a broad audience (and a range of government departments), this increases the appeal of the issue and the likelihood of securing government engagement and support [ 51 , 52 ].\nThe £7 million investment into walking promotion in 2008 was motivated by the perceived potential of sports mega-events to lead to population level increases in sport and physical activity participation; however, there is little evidence to support this notion [ 44 – 47 ]. Hosting sports mega-events does, however, generate political interest and thus sport can be a strong ‘symbol’ for getting physical activity onto the political agenda. Therefore further research is needed to understand how these events may be better utilised as a vehicle for encouraging mass participation in sport and physical activity. It should be noted that linking physical activity promotion with sports mega-events alone is insufficient, as it fails to recognise the importance of physical activity as a critical lifestyle behaviour for the prevention and control of NCDs. In addition, this sort of interest and commitment is often short-lived and is not sustained beyond the event itself. In the case of the London 2012 Games, the target of getting two million more people active as a result of hosting the Games was dropped even before the event took place [ 53 , 54 ].\nFollowing the government’s promise to deliver a physical activity ‘legacy’ as a result of hosting the Games, it committed to investing in a suite of “innovative campaigns to encourage people to walk more” [ 21 ]. The government elected to fund two walking initiates; Natural England’s Walking for Health programme and Walk England’s Walk4Life Miles project, neither of which were supported by a robust scientific evidence base.\nAlthough there is some evidence that walking in groups is an effective approach to increasing physical activity levels [ 55 ], relatively little is known about the effectiveness of other approaches to encourage people to walk more. The National Institute for Health and Care Excellence advocate for action to promote both leisure and transport related walking [ 14 ], through a range of portfolios including leisure services, parks, transport, and the environment, however further research is needed on exactly what types of interventions are effective and cost-effective.\nIn the absence of strong evidence of effectiveness, the lobbying efforts of policy entrepreneurs will be particularly critical. In addition it is advantageous to package interventions in a way which attracts political interest and aligns with other government priorities. In recent years, Walk England were particularly successful in this regard; the concept of 2012 routes gave this intervention a (albeit loose) connection to the 2012 Games and provided DH with a clear policy solution linked to the legacy target. Thus although the initiative was innovative, lacked a sound theoretical or empirical evidence base, and did not meet Kingdon’s criteria of having wide-spread support, Walk England were able to secure government investment.\nFurther research is clearly needed to build the evidence base on effective walking interventions. In the meantime, lobbying for interventions which lack evidence of effectiveness should be undertaken with caution. If these programs do not lead to the desired outcome in terms of increasing physical activity levels, they will have the adverse effect of undermining the government’s trust and confidence, which is likely to lead to reductions in future support and investment.\nEvidently there is still work to be done to a) raise awareness of the health benefits of physical activity; b) emphasise the importance and potential of walking promotion for influencing population levels of physical activity; c) build the evidence base on effective approaches to promoting walking; and d) encourage the development and implementation of policy level actions, with sustained support and investment, to increase population levels of physical activity and reduce NCD prevalence.\nConclusion\nThis paper utilised Kingdon’s Multiple Streams framework as an organising principle through which to interrogate the reasons behind the government’s increased interest and investment in walking promotion in 2008. Overall it appears that government interest in walking promotion in England has largely been motivated by sport and the promise of delivering a ‘legacy’ as a result of hosting the London 2012 Olympic and Paralympic Games. This raises concerns that the research evidence on the health benefits of physical activity and rising levels of inactivity in England, are insufficient to secure government support and investment, and that multi-sector lobbying and joined-up political action may be critical in advancing this agenda.\nDeclarations\nAcknowledgements\nThis manuscript is an output from the lead author’s PhD research which was undertaken at Loughborough University and supervised by Professor Barrie Houlihan.\nCompeting interests\nThe authors declare that they have no competing interests.\nAuthors’ contributions\nKM collected the data, undertook the analysis, and prepared the draft manuscript. JG contributed substantial intellectual content and made a significant contribution to writing and revising the manuscript. Both authors read and approved the final manuscript.\nAuthors’ Affiliations\n(1)\nBritish Heart Foundation Centre on Population Approaches for Non-Communicable Disease Prevention, Nuffield Department of Population Health, University of Oxford\n(2)\nSchool of Sport, Exercise and Rehabilitation Sciences, University of Birmingham\nReferences\nPhysical Activity Guidelines Advisory Committee. Physical activity guidelines advisory committee report 2008. Washington, DC; 2008. Google Scholar\nNg S, Popkin B. Time use and physical activity: a shift away from movement across the globe. Obes Rev. 2012;13(8):659–80. View Article PubMed PubMed Central Google Scholar\nWorld Health Organization. Global status report on noncommunicable disease 2010. Geneva: World Health Organization; 2011. Google Scholar\nWorld Health Organization. Global health risks: Mortality and burden of disease attributable to selected major risks. Geneva: World Health Organization; 2009. Google Scholar\nHealth and Social Care Information Centre. Health Survey for England, 2012 [Internet]. Leeds, UK; 2013. Available from: http://www.hscic.gov.uk/catalogue/PUB13218 .\nDepartment of Health. Let’s Get moving commissioning guidance—a physical activity care pathway. London: Department of Health; 2009. Google Scholar\nBlair S, Kohl III H, Paffenbarger Jr R, Clark D, Cooper K, Gibbons L. Physical fitness and all-cause mortality—a prospective study of healthy men and women. J Am Med Assoc. 1989;262:2395–401. View Article Google Scholar\nAinsworth B, Haskell W, Whitt M, Irwin M, Swartz A, Strath S, et al. Compendium of physical activities: an update of activity codes and MET intensities. Med Sci Sports Exerc. 2000;32(9 Suppl):S498–504. View Article PubMed Google Scholar\nMorris J, Hardman A. Walking to health. Sport Med. 1997;23(5):306–32. View Article Google Scholar\nBlair S, Kohl III H, Gordon N, Paffenbarger Jr R. How much physical activity is good for health? Annu Rev Public Health. 1992;13:99–126. View Article PubMed Google Scholar\nDavison R, Grant S. Is walking sufficient exercise for health? Sport Med. 1993;16(6):369–73. View Article Google Scholar\nParkkari J, Kannus P, Natri A, Lapinleimu I, Palvanen M, Heiskanen M, et al. Active living and injury risk. Int J Sports Med. 2004;25(3):209–16. View Article PubMed Google Scholar\nHillsdon M, Thorogood M. A systematic review of physical activity promotion strategies. Br J Sports Med. 1996;30(2):84–9. View Article PubMed PubMed Central Google Scholar\nNational Institute for Health and Clinical Excellence. Walking and cycling: local measures to promote walking and cycling as forms of travel or recreation. London: National Institute for Health and Clinical Excellence; 2012. Google Scholar\nSallis J, Bauman A, Pratt M. Environmental and policy interventions to promote physical activity. Am J Prev Med. 1998;15(4):379–97. View Article PubMed Google Scholar\nKohl III H, Craig C, Lambert E, Inoue S, Alkandari J, Leetongin G, et al. The pandemic of physical inactivity: global action for public health. Lancet. 2012;380:294–305. View Article PubMed Google Scholar\nDaugbjerg S, Kahlmeier S, Racioppi F, Martin-Diener E, Martin B, Oja P, et al. Promotion of physical activity in the European region: content analysis of 27 national policy documents. J Phys Act Health. 2009;6:805–17. View Article PubMed Google Scholar\nSharp I, White J, Rogers L. Physical activity: An agenda for action. London: National Forum for Coronary Heart Disease Prevention; 1995. Google Scholar\nDepartment for Transport. The national cycling strategy. London: Department for Transport; 1996. Google Scholar\nDepartment for Transport. Developing a strategy for walking. London: Department for Transport; 1996. Google Scholar\nDepartment for Culture Media and Sport. Before, during and after: making the most of the London 2012 games. London: Department for Culture Media and Sport; 2008. Google Scholar\nKingdon J. Agendas, alternatives and public policies. 2nd ed. New York: Harper Collins College Publishers; 1995. Google Scholar\nKingdon J. Agendas, alternatives and public policies. Boston: Little Brown; 1984. Google Scholar\nGrix J. The foundations of research. 2nd ed. Palgrave Macmillan: Basingstoke, Hampshire; 2010. Google Scholar\nParliamentary Office of Science and Technology. Postnote—Health benefits of physical activity transport. London: Parliamentary Office of Science and Technology; 2001. Google Scholar\nOliver P. Snowball sampling. In: Jupp V, editor. The SAGE dictionary of social research methods. London: Sage; 2006. Google Scholar\nDepartment of Health. At least five a week. Nutrition Bulletin. London: Department of Health; 2004. Google Scholar\nPeterson M. Motivation, mobilisation and monitoring: the role of interest groups in health policy. J Health Polit. 1999;24:416–20. Google Scholar\nWeiss J. The powers of problem definition: the case of government paperwork. Policy Sci. 1989;22:97–121. View Article Google Scholar\nZahariadis N. Ambiguity and choice in public policy: political decision making in modern democracies. Washington, DC: Georgetown University Press; 2003. Google Scholar\nPolsby N. Political innovation in America: the politics of policy initiation. New Haven, Connecticut: Yale University Press; 1984. Google Scholar\nRoberts N, King P. Policy entrepreneurs: Their activity structure and function in the policy process. J Public Adm Res Theory. 1991;2:147–75. Google Scholar\nDe Moor D. Dr. Gray’s walking cure. Book reviews: Winter 2009. 2009. Google Scholar\nCouncil S. Health Education Authority. London: Allied Dunbar Fitness Survey; 1992. Google Scholar\nStamatakis E, Ekelund U, Wareham N. Temporal trends in physical activity in England: the health survey for England 1991 to 2004. Prev Med (Baltimore). 2007;45(6):416–23. View Article Google Scholar\nDepartment of Health. Saving lives: Our healthier nation. London: Department of Health; 1999. Google Scholar\nDepartment of Health. Healthy lives, healthy people: a call to action on obesity in England. London: Department of Health; 2011. Google Scholar\nMarsh D, Rhodes R. Policy networks in British government. Clarendon: Oxford, UK; 1992. View Article Google Scholar\nWalking for Health. The future of walking for health [Internet]. 2011. Available from: http://www.walkingforhealth.org.uk/news/2011/02/future-walking-for-health .\nKline G, Porcari J, Hintermeister R, Freedson P, Ward A, McCarron R, et al. Estimation of VO2 max from a one-mile track walk, gender, age and body weight. Med Sci Sports Exerc. 1987;19(3):253–9. View Article PubMed Google Scholar\nWalk England. Active challenge routes. Bristol; 2010 Google Scholar\nBrownson R, Baker E, Left T. Evidence based public health. New York: Oxford University Press; 2011. Google Scholar\nHead B. Reconsidering evidence-based policy: key issues and challenges. Policy Soc. 2010;29(2):77–94. View Article Google Scholar\nWeed M, Coren E, Fiore J, Wellard I, Chatziefstathiou L, Mansfield D, et al. Developing a physical activity legacy from the London 2012 Olympic and Paralympic Games: a policy-led systematic review. Perspect Public Heal. 2012;132(2):75–80. View Article Google Scholar\nCoalter F. London 2012: a sustainable sporting legacy? In: Vigor A, Mean M, editors. After the Goldrush: a sustainable Olympics for London. London: ippr and Demos; 2004. Google Scholar\nMahtani K, Protheroe J, Slight S, Demarzo M, Blakeman T, Barton C, et al. Can the London 2012 Olympics “inspire a generation” to do more physical or sporting activities? An overview of systematic reviews. BMJ Open. 2013. Google Scholar\nGrix J, Carmichael F. Why do governments invest in elite sport? A polemic. Int J Sport Policy Polit. 2012;4(1):73–90. View Article Google Scholar\nDepartment for Culture Media and Sport. Plans for the legacy from the 2012 Olympic and paralympic games. London: Department for Culture Media and Sport; 2010. Google Scholar\nMacmillan Cancer Support, Ramblers. The Ramblers and Macmillan Cancer Support to take over Walking for Health [Internet]. 2012. Available from: http://www.ramblers.org.uk/media-centre/press-releases/2012/march/ramblers-and-macmillan-take-over-walking-for-health.aspx .\nTreasury HM. Statement by the Chief Secretary to the Treasury, Rt Hon Danny Alexander MP, on review to public spending commitments made since 1 January 2010 [Internet]. 2010. Available from: http://www.hm-treasury.gov.uk/statement_cst_170610.htm . Google Scholar\nRommetvedt H. Politikkens almenngjøring og den ny-pluralistiske parlamentarismen. Bergen: Fagbokforlaget; 2002. Google Scholar\nBergsgard N, Rommetvedt H. Sport and politics: the case of Norway. Int Rev Sociol Sport. 2006;41(7):7–27. View Article Google Scholar\nGibson O. Jeremy Hunt admits London 2012 legacy targets will be scrapped [Internet]. The Guardian. 2011. Available from: http://www.theguardian.com/sport/2011/mar/28/jeremy-hunt-london-2012-legacy .\nGibson O. Hugh Robertson admits to struggling with legacy for grassroots sport [Internet]. The Guardian. 2012. Available from: http://www.theguardian.com/sport/2012/mar/05/hugh-robertson-legacy-games-2012 .\nKassavou A, Turner A, French D. Do interventions to promote walking in groups increase physical activity? A meta-analysis. Int J Behav Nutr Phys Act. 2013;10:18. View Article PubMed PubMed Central Google Scholar\nCopyright\n© Milton and Grix. 2015\nThis article is published under license to BioMed Central Ltd. This is an Open Access article distributed under the terms of the Creative Commons Attribution License ( http://creativecommons.org/licenses/by/4.0 ), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly credited. The Creative Commons Public Domain Dedication waiver ( http://creativecommons.org/publicdomain/zero/1.0/ ) applies to the data made available in this article, unless otherwise stated.\n""","0.22153483","""https://bmcpublichealth.biomedcentral.com/articles/10.1186/s12889-015-1915-y""","[-1.933663,52.454008]"
"""Cranfield_University""","""Multi-objective optimisation for battery electric vehicle powertrain topologiesProceedings of the Institution of Mechanical Engineers, Part D: Journal of Automobile Engineering - Pongpun Othaganont, Francis Assadian, Daniel J Auger, 2017""","""[UK] Department for Transport. Policy, Transport emissions, https://www.gov.uk/government/publications/plug-in-car-grant,Plug-incargrant (2014, accessed 27 August, 2014). Google Scholar\n3.\nGuzzella L, Sciarretta A. Vehicle propulsion systems: introduction to modeling and optimization. Berlin: Springer, 2005. Google Scholar\n4.\nDextreit C, Assadian F, Kolmanovsky V, . Hybrid electric vehicle energy management using game theory. SAE paper 2008-01-1317, 2008. Google Scholar\n5.\nDextreit C, Kolmanovsky V. Game theory controller for hybrid electric vehicles. IEEE Trans Control Systems Technol 2014; 22(2): 652–663. Google Scholar Crossref\n6.\nWeissinger C, Buecherl D, Herzog H. Conceptual design of a pure electric vehicle. In: 2010 IEEE vehicle power and propulsion conference, Lille, France, 1–3 September 2010, pp. 1–5. New York: IEEE. Google Scholar\n7.\nHayes JG, Oliveria RPR, Vaughan S, Egan MG. Simplified electric vehicle power train models and range estimation. In: 2011 IEEE vehicle power and propulsion conference, Chicago, Illinois, USA, 6–9 September 2011, pp. 1–5. New York: IEEE. Google Scholar\n8.\nPearre NS, Kempton W, Guensler RL, Elango V. Electric vehicles: how much range is required for a day’s driving? Transpn Res Part C: Emerging Technol 2011; 19(6): 1171–1184. Google Scholar Crossref\n9.\nEhsani M, Gao Y, Emadi A. Modern electric, hybrid electric, and fuel cell vehicles: fundamentals, theory, and design. 2nd edition.Boca Raton, Florida: CRC Press, 2009, p. 557. Google Scholar\n10.\nGuiron Z, Henghai Z, Houyu L. The driving control of pure electric vehicle. Procedia Environ Sci 2011; 10(A): 433–438. Google Scholar Crossref\n11.\nWang R, Chen Y, Feng D, . Development and performance characterization of an electric ground vehicle with independently actuated in-wheel motors. J Power Sources 2011; 196(8): 3962–3971. Google Scholar Crossref\n12.\nLightning Car Company. A new way of motoring, http://www.lightningcarcompany.co.uk (2014, accessed 27 August 2014). Google Scholar\n13.\nvan Schalkwyk DJ, Kamper MJ. Effect of hub motor mass on stability and comfort of electric vehicles. In: 2006 IEEE vehicle power and propulsion conference, Windsor, Ontario, Canada, 6–8 September 2006, pp. 1–6. New York: IEEE. Google Scholar\n14.\nJain M, Williamson SS. Suitability analysis of in-wheel motor direct drives for electric and hybrid electric vehicles. In: 2009 IEEE electrical power and energy conference, Montreal, Quebec, Canada, 22–23 October 2009, pp. 1–5. New York: IEEE. Google Scholar\n15.\nYan X, Patterson D. Improvement of drive range, acceleration and deceleration performance in an electric vehicle propulsion system. In: 30th annual IEEE power electronics specialists conference, Charleston, South Carolina, USA, 1 July 1999, Vol 2, pp. 638–643. New York: IEEE. Google Scholar\n16.\nBenysek G, Jarnut M. Electric vehicle charging infrastructure in Poland. Renewable Sustainable Energy Rev 2012; 16(1): 320–328. Google Scholar Crossref\n17.\nZhou B, Jiang Q, Yang Y, Wang J. Analysis of energy consumption and powertrain parameters optimization of BEV based on running cycle. In: 2010 IEEE 11th international conference on computer-aided industrial design and conceptual design, Yiwu, Zhejiang, People’s Republic of China, 17–19 November 2010, pp. 1284–1290. New York: IEEE. Google Scholar\n18.\nHu X, Murgovski N, Johannesson LM, Egardt B. Optimal dimensioning and power management of a fuel cell/battery hybrid bus via convex programming. IEEE/ASME Trans Mechatronics 2016; 20(1): 457–468. Google Scholar Crossref\n19.\nOthaganont P, Assadian F, Auger D. Sensitivity analyses for cross-coupled parameters in automotive powertrain optimization. Energies 2014; 7(6): 3733–3747. Google Scholar Crossref\n20.\nWipke KB, Cuddy MR, Burch SD. ADVISOR 2.1: a user-friendly advanced powertrain simulation using a combined backward/forward approach. IEEE Trans Veh Technol 1999; 48(6): 1751–1761. Google Scholar Crossref\n21.\nMohan G, Assadian F, Longo S. Comparative analysis of forward-facing models vs backward-facing models in powertrain component sizing. In: 2013 4th IET hybrid and electric vehicles conference, London, UK, 6–7 November 2013, pp. 1–6. New York: IEEE. Google Scholar\n22.\nYang Y, Hu X, Pei H, Peng Z. Comparison of power-split and parallel hybrid powertrain architectures with a single electric machine: dynamic programming approach. Appl Energy 2016; 168: 683–690. Google Scholar Crossref\n23.\nMohan G, Assadian F, Longo S. An optimization framework for comparative analysis of multiple vehicle powertrains. Energies 2013; 6: 5507–5537. Google Scholar Crossref\n24.\nLeitman S, Brant B. Build your own electric vehicle. 2nd edition.New York: McGraw-Hill, 2009. Google Scholar\n25.\nLarminie J, Lowry J. Electric vehicle technology explained. Chichester, West Sussex: John Wiley, 2004. Google Scholar\n26.\nChen GH, Tseng KJ. Design of a permanent-magnet direct-driven wheel motor drive for electric vehicle. In: 27th annual IEEE power electronics specialists conference, Baveno, Italy, 23–27 June 1996, Vol 2, pp. 1933–1939. New York: IEEE. Google Scholar\n27.\nQian H, Xu G, Yan Q, . Energy management for four-wheel independent driving vehicle. In: 2010 IEEE/RSJ international conference on intelligent robots and systems, Taipei, Republic of China, 18–22 October 2010, pp. 5532–5537. New York: IEEE. Google Scholar\n28.\nTesla Motors. Home page, http://www.teslamotors.com (2014, accessed 27 August 2014). Google Scholar\n29.\nCaricchi F, Crescimbini F, Di Napoli A, Marcheggiani M. Prototype of electric vehicle drive with twin water-cooled wheel direct drive motors. In: 27th annual IEEE power electronics specialists conference, Baveno, Italy, 23–27 June 1996, Vol 2, pp. 1926–1932. New York: IEEE. Google Scholar\n30.\nQian H, Lam TL, Li W, . System and design of an omni-directional vehicle. In: IEEE international conference on robotics and biomimetics, Bangkok, Thailand, 21–26 February 2008, pp. 389–394. New York: IEEE. Google Scholar\n31.\nRahman KM, Patel NR, Ward TG, . Application of direct-drive wheel motor for fuel cell electric and hybrid electric vehicle propulsion system. IEEE Trans Ind Applic 2006; 42(5): 1185–1192. Google Scholar Crossref\n32.\nTao G, Ma Z, Zhou L, Li L. A novel driving and control system for direct-wheel-driven electric vehicle. In: 2004 12th symposium on electromagnetic launch technology, Snowbird, Utah, USA, 25–28 May 2004, pp. 514–517. New York: IEEE. Google Scholar\n33.\nYang Y-P, Hu T-H. A new energy management system of directly-driven electric vehicle with electronic gearshift and regenerative braking. In: 2007 American control conference, New York, USA, 9–13 July 2007, pp. 4419–4424. New York: IEEE. Google Scholar\n34.\nTie SF, Tan CW. A review of energy sources and energy management system in electric vehicles. Renewable Sustainable Energy Rev 2013; 20: 82–102. Google Scholar Crossref\n35.\nDejun Y, Hori Y. A novel traction control of EV based on maximum effective torque. In: IEEE 2008 vehicle power and propulsion conference, Harbin, Heilongjiang, People’s Republic of China, 3–5 September 2008, pp. 1–6. New York: IEEE. Google Scholar\n36.\nHori Y. Future vehicle driven by electricity and control-research on four wheel motored “UOT Electric March II”. In: 2002 7th international workshop on advanced motion control, Maribor, Slovenia, 3–5 July 2002, pp. 1–14. New York: IEEE. Google Scholar\n37.\nSakai S, Sado H, Hori Y. Motion control in an electric vehicle with four independently driven in-wheel motors. IEEE/ASME Trans Mechatronics 1999; 4(1): 9–16. Google Scholar Crossref\n38.\nWang J, Wang Q, Jin L, Song C. Independent wheel torque control of 4WD electric vehicle for differential drive assisted steering. Mechatronics 2011; 21(1): 63–76. Google Scholar Crossref\n39.\nSorniotti A, Boscolo M, Turner A, Cavallino C. Optimization of a multi-speed electric axle as a function of the electric motor properties. In: 2010 IEEE vehicle power and propulsion conference, Lille, France, 1–3 September 2010, pp. 1–6. New York: IEEE. Google Scholar\n40.\nLukic SM, Emado A. Modeling of electric machines for automotive applications using efficiency maps. In: Electrical insulation conference and electrical manufacturing coil winding technology conference, Indianapolis, Indiana, USA, 23–25 September 2003, pp. 543–550. New York: IEEE. Google Scholar\n41.\nSato Y, Ishikawa S, Okubo T, . Development of high response motor and inverter system for the Nissan LEAF electric vehicle. SAE paper 2011-01-0350, 2011. Google Scholar\n42.\nProtean Electric. In-wheel motor, torque-speed characteristics. Company website, www.proteanelectric.com/specifications (2015, accessed 7 July 2015). Google Scholar\n43.\nYASA. In-wheel motor torque–speed characteristics, http://www.yasamotors.com/products (2015, accessed 7 July 2015). Google Scholar\n44.\nSimpson A. Cost–benefit analysis of plug-in hybrid electric vehicle technology. In: 22nd international battery, hybrid and fuel cell electric vehicle symposium and exhibition, Yokohama, Japan, 22–28 October 2006, paper NREL/CP-540-40485. Golden, Colorado: National Renewable Energy Laboratory. Google Scholar\n45.\nNissan Motor Co. EV/HEV safety, LEAF battery specifications, www.nhtsa.gov/pdf/ev/Nissan_Presentation-Bob_Yakushi.pptx (2012, accessed 7 July 2015). Google Scholar\n46.\nThe MathWorks, Inc. Global Optimization Toolbox R2014a user’s guide. Natick, Massachusetts The MathWorks, Inc., 2014, section 5.3. Google Scholar\n47.\nOthaganont P, Assadian F, Marco J. Battery electric vehicle powertrain simulation to optimise range and performance’. In: International conference on powertrain modelling and control, Bradford, West Yorkshire, UK, 4–6 September 2012. The University of Bradford School of Engineering, Design and Technology. Google Scholar\nVol 231, Issue 8, 2017\nVehicle model and simulation technique\nVehicle simulations without optimisation\nMulti-objective optimisation for different BEV topologies\nConclusions\n""","0.7736695","""http://journals.sagepub.com/doi/abs/10.1177/0954407016671275""","[-0.629225,52.074389]"
"""UCL""","""Iris Publication""","""http://discovery.ucl.ac.uk/1336844/\nAbstract\nThe potential impact of advances in data mining, data fusion and information management on the efficient exploitation of the transport infrastructure are addressed. It is argued that the energy currently consumed in transport is poorly exploited for a number of reasons that the application of intelligent infrastructure analysis can significantly address: traffic congestion implies reduced fuel efficiency; the average number of people travelling per car is very low; and public/private transport combination options are difficult to plan. Relevant advances in intelligent information systems are reviewed, and a number of scenarios illustrating how these weaknesses might be addressed are presented. For each, the feasibility of the required technology and the timescales for deployment are discussed.\nPublication data is maintained in RPS. Visit https://rps.ucl.ac.uk\n› More search options\n""","0.8863025","""http://iris.ucl.ac.uk/iris/publication/382866/7""",
"""Imperial_College_London""","""Realising transition pathways for a more electric, low-carbon energy system in the United Kingdom: Challenges, insights and opportunitiesProceedings of the Institution of Mechanical Engineers, Part A: Journal of Power and Energy - Jason Chilvers, Timothy J Foxon, Stuart Galloway, Geoffrey P Hammond, David Infield, Matthew Leach, Peter JG Pearson, Neil Strachan, Goran Strbac, Murray Thomson, 2017""","""Figure 5. The dynamic relationship between energy security, framing of energy and governance logics.\nSource: Johnson et al. 30\nShifting views about how security affected the framing of energy emerged between WWI and WWII; leading to the prevalence again of hybrid governance. A relational approach was used by Johnson et al. 30 to explore the emergence of policy support for fuels and their final withdrawal. That showed how and why emerging technological substitutes can founder and transitions fail in times of economic instability. It led to shifting hybrid state and market governance between incumbents (i.e. the oil majors) and newcomers (e.g. DCL and ICI). These studies consequently reflect a partial historical analogue for the hybrid roles of the state and the market in energy governance (e.g. UK Electricity Market Reform (EMR)), as well as the changing priorities within the energy policy trilemma between climate change mitigation and the provision of secure and affordable energy services. The case studies also provide insights about technological substitutes and new infrastructures (electrifying transport and heat), as well as concerns about the influence of incumbent actors and institutions influence to either advance or constrain low-carbon transitions.\nA further supply-side study of the development of the integrated UK natural gas system over the period 1960–2010 by Arapostathis et al. 31 has illustrated the way in which such integration was closely linked to governance patterns. This explored the development of the gas system in two transitions: (i) from town to natural gas with state governance logic (under the management of the nationalised British Gas Corporation); and (ii) then privatisation and liberalisation after 1987. The latter major structural change is regulated by Ofgem, with a Uniform Network Code (UNC) overseen by the Joint Office of Gas Transporters. Vertical integration has been aided by new control and communication technologies, together with internationalisation via gas interconnectors. That reduced uncertainties, but increased the system’s complexity. This case study 31 provided an analogue for the challenges of integrating large, infrastructural technical systems for a sustainability transition. It is inscribed within the MLP approach yet concentrates on system integration as a complex and uncertain socio-technical process. It indicates how quite dramatic changes in the UK natural gas structure are mirrored in regime formation (see Figure 1 ).\nLittle historical work has been undertaken on energy demand reduction. A study of electric heating in early post-war Britain 32 when electric fires were used at peak times and were therefore particularly problematic in terms of energy end-use, offers insights into the challenges often associated with demand reduction. The Electricity Development Association (EDA), originally established as a public relations arm of the UK electricity industry, tried simultaneously to reduce undesirable peak demand, whilst encouraging increased demand more generally. In the late 1940s, it recommended that electric fires should not be used to meet peak demand. However, in the 1950s and 1960s it concentrated on promoting off-peak heating appliances. It first sought to do this in the United Kingdom via under-floor heating, and then block storage heaters typically composed of clay bricks or other ceramic material. The study under the auspices of the transition pathways consortium by Carlsson-Hyslop 32 analysed the way in which the London County Council (LCC) and its tenants adopted and adapted electric underfloor heating. It concluded that attempts by the electricity industry during the period 1945–1964 had only a limited effect on the trend towards rising energy end-use demand. This was, in part, due to EDA promotional efforts. This analysis is consistent with that on households’ engagement with customer-facing elements of a smarter grid, such as smart meters or energy monitors (see, e.g. a predecessor consortium study by Hargreaves et al. 33 ). Social variables like daily routines, individual preferences and social relations in a household were found by Hargreaves et al. 33 to be important for energy demand reduction. This may reflect a co-evolution of technology with social practices, changing routines, and behaviour. It illustrates the kinds of processes, practices, interactions and modes of governance that need to be considered if demand management/energy efficiency are to succeed in containing energy use and GHGs, whilst enhancing the quality of people’s lives.\nPolicy makers tend to have little institutional memory of what has worked or has not worked in terms of energy sector interventions, because job changes are used to enable UK civil servants to gain experience and avoid accumulating positional or departmental loyalty, and because ministers often serve for short periods (from 2008 to 2015 of the four Secretaries of State for Energy and Climate Change, one served for less than 2 years and another for just over 1 year). Historical analyses/stories of past transitions therefore help them (and other stakeholders) to understand how and why transitions have previously succeeded or failed. They also indicate how long they can take to implement and the reasons why. Overall insights and lessons from such studies can be summarised as:\nThe historical studies have shown that rapid change is possible, but not necessarily frequent. It may require a recognition of the need to change, openness to experiment and a high degree of co-ordination (e.g. the natural gas transition). These studies illustrate how co-evolutionary and co-constructed are the material or physical aspects with the social, political and institutional aspects. For example, the 1966–1977 conversion from town gas to natural gas required both technical changes, including building the national gas grid and installing new burners in millions of gas appliances, along with major institutional reorganisation, new workforce training and political support. 31\nHistorical studies of two alternatives to petrol in the inter-war period 30 show how and why emerging technological substitutes can founder and potential transitions fail in times of economic instability, shifting governance and competition between incumbents and newcomers.\nA further supply-side study of the development of the integrated UK natural gas system over the period 1960–201031 suggests that such integration was closely linked to governance patterns. It indicated how quite dramatic changes in the UK natural gas structure are largely reflected in regime formation and change.\nThere is little historical work on demand reduction. However, the recent study of the EDA and domestic electric heating in post-war Britain 32 suggests that their attempts had limited impacts on the trend of rising demand, and thereby illustrates the challenges facing demand reduction today.\nHorizon scanning and technology assessment of energy systems\nSection:\nTechnological choices in the UK power sector are likely to vary significantly out to 2050. For example, over the last few years the outlook for both coal-fired power stations with CCS and nuclear power has changed dramatically. The UK Government indicated (in November 2015) their wish to phase out unabated coal-fired power stations by 2025, and giving new gas-fired power stations priority. Likewise, the prospects of new nuclear build has been hit by both concerns following the 2011 Fukushima disaster in Japan and a reassessment of the economics of nuclear power by some of the big players, such as the investment decision by the French utility eDF Energy in regard to the construction of the Hinkley Point C nuclear power plant (in Somerset). These short-term changes in attitudes to low-carbon technologies mean that the technology choices implicit in each of the existing pathways need to be kept under continuous review. Horizon scanning involves a portfolio of methods that enable energy researchers and other power sector stakeholders to increase their awareness of important emerging influences on the UK energy system and its environment. It provides a major strand in proactive risk management 11 and strategic thinking as the UK energy sector moves forward. Parker et al., 34 for example, used a modified Delphi technique for horizon scanning in order to identify some 30 emergent policy issues, which strongly featured science and technology, and which would necessitate public engagement as the policies were being developed. This was driven, in part, by concerns over the use of hydraulic fracturing (or fracking) by fossil fuel companies for shale gas extraction in the United Kingdom. A disparate group of people with interests over the science and policy interface (e.g. policy makers and advisers, academics and the private sector) initially elicited a long list of issues. These were then refined into a shorter list that were viewed as being of top priority for policy makers. They included challenges related to energy and environment, such as policies concerning interdisciplinary whole energy systems science (incorporated by a partner in the Realising Transition Pathways Consortium (Jason Chilvers) 34 ). A variety of alternative techniques are available for use in identifying emerging issues in the UK energy sector. Arup Foresight (part of the independent firm of designers, planners, engineers and consultants) have, for example, employed STEEP (social, technological, economic, environmental, political) analysis to examine drivers for change in both the energy and climate change fields. The Realising Transition Pathways Consortium have used a similar approach, in conjunction with more formal methods of Technology Assessment 35 , 36 to evaluate a number of the main disruptive energy technologies. These studies have sought to identify the components of a balance sheet of technological credits and debits in order to evaluate their societal impacts, and to determine whether they are compatible with Britain’s move towards a low-carbon future in 2050 and beyond.\nIndicative energy technology assessments (ETAs) have been carried out for a variety of energy technologies, e.g. UK shale gas extraction, 37 carbon capture and storage (CCS), 38 , 39 advanced rechargeable batteries, 40 rare earth elements (REE) as a constraint on clean energy technologies, 41 nuclear power plants 42 and tidal power barrages. 43 These ETAs were all indicative in the sense of being a simplified evaluation and illustration of the performance of state-of-the-art devices. Nevertheless, such assessments provide a valuable evidence base for developers, policy makers and other stakeholders. Each technology was evaluated using a combination of quantitative and qualitative methods within the spirit of the STEEP approach. The most controversial of these studies was arguably that concerning the benefits and ‘costs’ of shale gas fracking in Britain. 34 , 37 Exploratory drilling in the United Kingdom is at an early stage, with great uncertainty over the scale of the potential shale gas resource. 37 However, such activities are already meeting fierce community resistance. Like all energy technologies, it exhibits unwanted side-effects that simply differ in their level of severity compared to other options. Successful extraction might contribute positively in terms of fuel security and independence, as well as jobs and growth. 37 Shale gas may also make a contribution to attaining the UK’s statutory GHG emissions targets, although potentially harmful environmental impacts need to be satisfactorily resolved via appropriate monitoring and robust regulation. It is unlikely that gas bills for UK household and industrial consumers would fall dramatically as they have done in North America, because Britain is linked to the wider European gas market. Anything produced in the United Kingdom would be a ‘drop in the ocean’ compared to imports via either pipelines or by way of liquefied natural gas (LNG) tankers. Finally, the socio-economic advantages and disadvantages of shale gas fracking are not evenly distributed between various communities and demographic groups. 37 Community engagement in a genuinely participative process – where the government is prepared to change course in response to the evidence and public opinion – will consequently be critically important for the adoption of any new energy option.\nCCS facilities coupled to fossil fuelled power plants or industrial sites provide a key climate change mitigation strategy that potentially permits the continued use of fossil fuel resources, whilst reducing the CO2 emissions. Hammond and Spargo 39 highlight the potential design routes for the capture, transport, clustering and storage of CO2 from UK power plants. Both currently available and novel CCS technologies were evaluated. Due to lower operating efficiencies, the CCS plants showed a longer energy payback period and a lower energy gain ratio than conventional plant. There are also several technical and financial obstacles that need to be overcome, 38 including the adoption of an appropriate legislative framework and the need for full CCS chain risk assessments. There are uncertainties over the full-scale power plant CCS technical performance and costs, which may only become clearer when the first demonstrators are operational. Unfortunately, the UK Government cancelled (on 25 November 2015) their £1 bn CCS competition shortly before the winning consortium was due to be announced. Inevitably, the bidding companies were dismayed by this outcome and the prospects for CCS in Britain in the short term now looks rather bleak. Prior to this, the Government had established a CCS Cost Reduction Task Force 44 as an industry-led joint venture to assist with the challenge of making CCS a commercially viable operation by the early 2020s. The main cost-reduction opportunities were seen as being 44 : (i) transport and storage scale and utilisation, (ii) improved financeability for the CCS chain, and finally (iii) improved engineering designs and performance. Greater financial incentives for carbon abatement could, in principal, be secured through a higher carbon price from the European Union Emissions Trading Scheme (EU ETS), although that has been a significant disappointment in terms of the carbon price level. A collaborative study between the Energy Technologies Institute (ETI), a public-private partnership of key industrial companies and UK funders of energy RD&D, and the Ecofin Research Foundation (ERF) 45 has recently examined the conditions required for mobilising private sector financing of CCS in the United Kingdom. They argue that this technology would be a ‘huge prize’ that could cut the annual costs of meeting the 2050 carbon target by up to 1% of gross domestic product (GDP). 38 , 39 , 45 But they noted that the prevailing financial market conditions are demanding. In order to meet this challenge, they suggest that the United Kingdom needs to build confidence in long-term policy, develop attractive pricing for CCS contracts with suitable risk sharing, put in place an appropriate regulatory and market framework, and devise new ways to offset North Sea storage liability risks. 45 Many believe that the UK Government will need to return to CCS deployment in order to meet its 2050 GHG emissions reduction target in a cost-effective way. 46\nTwo other large-scale power generators that could be available to help secure a low-carbon future for the United Kingdom are nuclear power plants 42 and tidal barrages. 43 The lives of existing nuclear plant has typically been extended to around 40 years (e.g. Hunterston B was financed for 25 years with an expectation of 35 years, and subsequently extended by 7 years). Nevertheless Britain, as with other nuclear-powered European countries, will be progressively decommissioning its older nuclear power stations during the next decade or so. This will leave only the Sizewell B pressurised water reactor (PWR) station in the United Kingdom, with nuclear power holding a considerably reduced share of electricity generation (perhaps as low as 3% by 2020 from around 20% in the winter of 2013–2014). A new generation of nuclear power stations may therefore need to be part of the power generation mix in order to decarbonise the electricity sector by around 2030–2050. In Europe these plants are likely to be variants of the third-generation European pressurised reactor (EPR) design. Emerging (novel) nuclear reactor designs are thought to be inherently safer and less costly 42 ; perhaps having a 25% lower generating cost than present systems. However, the research by the former UK Sustainable Development Commission 47 suggests that a doubling of Britain’s existing nuclear capacity would only yield an 8% cut on CO2 emissions by 2035. Over the longer term, it is likely that the European governments will want to keep a watching brief on advanced nuclear reactors (including modular designs) that are currently being developed in France/Germany, South Africa and the United States. Nevertheless, they will no doubt want to be reassured that such new technologies will be commercially viable. 42 The adoption of either short- or medium-term technologies would obviously be critically dependent on public attitudes to nuclear power in Britain and elsewhere. 1 , 11 , 42 Both the Cardiff-Weston and the smaller Shoots barrages on the River Severn between Somerset and south Wales have been evaluated by Hammond et al. 43 using various ETA techniques to determine their net energy output, carbon footprint and financial investment criteria, alongside various critical technical and environmental issues. These tidal power schemes were assessed over their foreseen lifespan of 120 years in terms of its cradle-to-site, operation and maintenance requirements. The proposed Cardiff-Weston Barrage would yield relatively attractive figures of merit in terms of its net energy and carbon emissions, although its financial performance is poorer than alternative power generators. Comparisons were made with the much smaller, Shoots Barrage scheme that would be located up-river of the Severn road crossings, and which is favoured by environmental groups, because of its more benign ecological and environmental impacts. 43\nThe suitability of advanced rechargeable battery technologies (ARBT) for different applications, such as electric vehicles (EV), consumer electronics, load levelling and stationary power storage, has been the subject of another ETA. 40 These energy storage devices were compared to more mature nickel–cadmium (Ni–Cd) batteries in order to gain a sense of perspective regarding the performance of the ARBT. Lithium (Li)-ion batteries (LIB) currently dominate the rechargeable battery market and are likely to continue to do so in the short term in view of their excellent all-round performance, 40 and firm grip on consumer electronics. However, in view of the competition from Li-Ion Polymer (LIP) batteries their long-term future is uncertain. Although, if safety concerns are overcome and costs fall significantly, there may be growth in the EV sector and to a lesser extent load-levelling, where LIB can exploit their relatively high cycle life. 40 Rare earth batteries and magnets are key elements of hybrid vehicles and gearless wind turbines, and phosphors are critical in energy saving lighting. Hammond and Mitchell 41 argued that ‘rare earth elements' (REE) may place a significant constraint on the development of some low-carbon (or clean) energy technologies. These materials are not actually rare in terms of their abundance, but the number and location of mines are restricted due, in part, to economic considerations. Current REE reserves stand at about 110 million tonnes with around half in the People’s Republic of China (PRC), although other countries like the United States, Commonwealth of Independent States (CIS) (the former Soviet Republics) and Australia hold substantial reserves. Production in China dominates the market, with ∼97% of the global total, and this will remain so until new mines are developed. The PRC has limited its export of REE in order to give preference to the export of manufactured products. Diversity of the global supply chain is therefore a crucial issue moving forward (see Figure 6 ). It is likely that supply constraints will become less critical in the medium to long term as more mines come into operation, and thus further reserves become available. 41 Such constraints could be eased by reducing the amount of material required per application, or changing the technology altogether. LIB, 40 for example, are already a viable replacement for nickel-metal-hydride units in hybrid vehicles. Their costs have fallen from >£1680/kWh in 1990 to <£140/kWh today. REE are not currently recycled, either pre or post-use. There are processes available that could be utilised for this purpose, although they do not currently appear to be economically viable options. 41\nDownload in PowerPoint\nFigure 6. Diversity of global ‘rare earth elements’ (REE) supply over the medium term. Note: ‘Current’ reflects the 2011 baseline. 41\nIn order to round-off these ETA-like studies, an evaluation of the energy densities and spatial footprints of both conventional and renewable generators was undertaken by Cheng and Hammond 48 on a life-cycle (or cradle-to-gate) basis. It was stimulated by a desire to test an assertion by Fells 49 that renewable energy technologies for electricity generation (such as bioenergy plants, solar PV cell arrays, wind turbines and the like) have a low energy density in comparison with fossil fuel or nuclear power stations. He suggested, for example, that if all the wind farms operating in the world in about the year 2000 were to be concentrated on the South Downs of England, then only 10% of UK electricity demand would be met. On a similar basis, he argued 49 that in order to replace Scotland’s two nuclear power stations a total of 10,000 250 kW LIMPET-type wave power generators (i.e. shoreline oscillating water column devices) would be required of the type installed on the island of Islay (one of the Hebridean islands; off the north west coast of Scotland). In the case of biomass energy, Fells 49 postulated that an area the size of the county of Kent would have to be covered in coppiced willow in order to replace half of the output from Dungeness B nuclear power station (a 1040 MW plant consisting of two AGRs, and located in the same county). The nuclear fuel cycle (both with diffusion and centrifuge enrichment) was found by Cheng and Hammond 48 to have the highest energy density of the technologies they examined, with bioenergy plants having the lowest. Their results are summarised in Table 2 , where they are compared with those of Gagnon et al. 50 and of the US Environmental Working Group (EWG). 51 Onshore wind power exhibited a relatively promising energy density and is greater than that of its offshore counterpart, the energy density of the latter fell below that of solar PV arrays. Thus, renewables were found to produce dilute electricity overall with a spatial footprint that is orders-of-magnitude higher than for conventional sources. That was in line with the views of Fells, 49 although there are many other sustainability criteria that will determine their usefulness in the transition towards a low carbon future. 48\nTable 2. A comparison of the spatial footprints per unit of output from various power generators.\nTable 2. A comparison of the spatial footprints per unit of output from various power generators.\nSource: Adapted from Cheng and Hammond. 48\nView larger version\nThe horizon scanning and technology assessment of the energy options 34 – 36 that will influence the three UK transition pathways contributes to an understanding the future interplay of the energy policy trilemma, i.e. achieving deep GHG emission cuts, whilst maintaining a secure and affordable energy system, and addressing how resulting tensions might be resolved. Overall insights and lessons from such studies can be summarised, for example, as:\nShale gas extraction has potential unwanted side-effects, and is already meeting community resistance and controversy. A balance sheet approach has been used to determine the benefits and disbenefits of shale gas fracking. 37 It may contribute to energy security, jobs and growth, as well as attaining national GHG targets over the medium term. Thus, it might form the basis of a transitional energy strategy for the United Kingdom, although the wider environmental impacts will require appropriate and robust regulations to be enforced.\nCarbon capture and storage (CCS) from fossil-fuel power stations is likely to be a key technology in achieving a low carbon future in the United Kingdom at a reasonable cost. 38 Energy and carbon analyses have been undertaken, along with indicative cost estimates, for fossil-fuelled power stations with and without CCS. 39 It could significantly cut GHG emissions, provided technological and financial obstacles can be overcome.\nLarge-scale nuclear power plants and tidal power barrages both exhibit attractive figures of merit in terms of their overall energy performance and near-zero carbon emissions, but have very long financial payback periods. 40 , 43 The latter makes them difficult to undertake with the support of only private sector investors. Nuclear power also gives rise to ongoing problems with high and intermediate-level waste disposal, 40 although a deep underground repository is the preferred option. The siting of such a facility has yet to be resolved in the United Kingdom. A tidal barrage built across the Severn Estuary would inevitably give rise to significant ecological modifications to the aquatic environment. 43\nThe suitability of ARBT have been evaluated for different applications. 40 While LIBs are likely to continue to dominate the rechargeable battery market in the short term, their long-term future is uncertain, because of competition from LIP batteries. There may be some LIBs growth in the electric vehicle sector, if safety concerns are overcome and costs fall significantly, and somewhat less in load-levelling, through their relatively high cycle life.\nRare earth batteries and magnets are key elements in the hybrid vehicles and gearless wind turbines, as are phosphors in energy-saving lighting, but short-term economic mining constraints on REE may limit their development. 41 Such concerns could also be eased by using less material per application, recycling REE, either pre- or post-use, or changing the technology altogether.\nThe energy densities and spatial footprints of various power generators were evaluated on a life-cycle basis. 48 The nuclear fuel cycle was found to have the highest energy density, with bioenergy plants having the lowest. Onshore wind power exhibited a relatively promising energy density; being greater than that for its offshore counterpart. The energy density of the latter fell below that of solar PV arrays.\nElectricity system and network modelling and evaluation\nSection:\nBackground\nA number of reputable studies have been undertaken over recent years that support low or zero carbon energy scenarios for the United Kingdom. These include those produced by the British Government’s Department of Energy and Climate Change (the DECC 2050 Calculator 52 ), the UK Energy Research Centre (the UKERC Energy 2050 Project 53 ), and the Tyndall Centre for Climate Change Research. 54 They all enable insights to be drawn regarding the realism of each scenario set, and reflect a range of aspirations from those wishing to achieve 2050 carbon reduction targets: 80% in the case of DECC 52 and UKERC 53 projections. However, the five Tyndall decarbonisation scenarios 54 focused on an earlier 60% carbon reduction target for 2050, although they employ a distinctive backcasting approach generated and reviewed with the aid of stakeholders. On the other hand, the DECC 2050 Calculator is basically an engineering-based, Excel spreadsheet model that is open source and arguably transparent. The tool permits users to select their own combination of technologies to achieve an 80% reduction in GHG emissions by 2050, whilst ensuring that energy supply and demand are balanced. The UKERC Energy 2050 Project 53 employed a core four-scenario core set that was underpinned by a single cost-optimisation model (UK MARKAL). It took ‘an eclectic approach to scenario building’ 53 with a backcasting dimension to achieve a combination of UK energy resilience and climate change mitigation. In contrast, the quantification of the three pathways developed by the Realising Transition Pathways Consortium was underpinned by a suite of multiple models.\nFrom narrative descriptions of the transition pathways to model formulation\nA range of models were developed to elaborate/explore demand, supply and infrastructure aspects 26 and feed into revising the pathways, both quantitatively and qualitatively in the second iteration for version 2.1 of the transition pathways. Qualitatively this has involved building narrative stories out to 2050, whilst quantitatively it has necessitated the construction of matching, consistent spreadsheets of demand, supply, technologies and (implicit) infrastructure. This was a challenging and time-consuming process, but one that yielded a valuable learning experience. Electricity models were used to variously address hourly, annual and seasonal balancing on regional, national and international scales. An informative multi-modelling comparison of the pathways was then undertaken to innovatively link and embed narrative storylines to technological, economic, social and institutional drivers and constraints. The framework of eight models and appraisal tools (see Figure 7 for the suite of individual models as of April 2013) were iteratively linked and checked for consistency between the various tools and the narrative descriptions of the pathways. This exercise was undertaken by the postgraduate researchers functioning as what was known in the Realising Transition Pathways Consortium as the Engine Room 55 the researchers working independently of the consortium leadership (the academic co-investigators).\nFigure 7. The framework of quantitative models utilised within the Realising Transition Pathways project.\nSource: The Transition Pathways Consortium. 55\nThis cross-scale study was based on the storyline or narrative description of the CC pathway, 8 , 24 which was then evaluated via six power system models and two appraisal techniques. It was used to iteratively link the CC narrative with the models/appraisal tools. Harmonised assumptions on power system inputs and system output targets for each model or tool were initially extracted from the CC pathway storyline. 8 , 24 The framework of models (see again Figure 7 ) was then employed to map the key features of each model/appraisal tool in terms of their temporal, spatial and disciplinary perspectives. Clearly, the narrative description of the CC pathway 8 , 24 was found to be critical for transmitting information about governance logic and the choices of key actors. Nevertheless, many of these parameters were found to be inconsistent. Typically, the CC storyline resulted in an overestimate of demand reduction levels, the uptake of CCS and marine renewables. This is because the narrative storyline tends to underestimate the technical and economic challenges associated with these levels of demand reduction and uptake of CCS and marine renewables. These were subsequently highlighted through the quantitative modelling analysis. Likewise, the narrative description led to an underestimate of the supply-demand balancing requirement, the need for back-up capacity, and the role of nuclear power and interconnectors with Europe, compared to the challenges identified through the modelling in achieving these outcomes.\nThe eight models and appraisal tools (in the order of their breadth of power system boundaries, and in line with the sequence indicated in Figure 7 ) were:\nDemand: This energy demand model (for full details see Barton et al. 28 ) is a highly disaggregated simulation model of UK energy demand for both the domestic and non-domestic sectors. Its primary inputs are a range of characteristics, 26 , 52 including energy service levels, user practices, choices of appliances, building fabric, fuels, deployment of distributed generation, and other parameters, with its main output being final energy demand across the UK building stock.\nFESA: The future energy scenario analysis (FESA) model (for full details see Barnacle et al. 27 ) is a single-year UK power generation and demand simulation model, incorporating 1-hour time steps for dispatch modelling. The overall structure of this model is depicted in Figure 8 . It utilises 2001 UK Met Office weather data on temperature, wind speeds, solar radiation and wave height. The FESA model incorporates technical feasibility constraints on the power network, and enables hourly grid-balancing.\nD-EXPANSE: This model (dynamic version ofexploration ofpatterns innear-optimal energyscenarios; for full details see Trutnevyte 56 ) is a power system optimisation model. D-EXPANSE systematically explores the various near-cost-optimal pathways, as well as the structural uncertainty, based on key inputs of demand, technology costs and characteristics, fuel prices and power system transmission topology. Its main output in terms of UK power systems configuration and costs has been validated by comparing its outputs with that for a variety of existing, well-established whole system models and their cost estimates for the UK. 55\nEconA: The economic appraisal (EconA) appraisal technique (for full details see Trutnevyte et al. 55 ), is an accounting model that systematically calculate and compare investment and total system costs for power generation, transmission and distribution under the three UK transition pathways. The key inputs are the ranges of component technology costs, efficiencies and other technical characteristics. The quantitative output is disaggregated into shares of different power generation technologies, thereby allowing the assessment of economic feasibility of any given pathway (such as the CC pathway in the contribution of Trutnevyte et al. 55 ).\nBLUE-MLP: This model (behaviourlifestyles anduncertaintyenergy model withmulti-levelperspective on transitions) is a probabilistic systems dynamics simulation model (for full details see Trutnevyte et al. 55 ). Its key inputs derive from sector- and actor-specific behavioural elements 55 that arise from the MLP transitions approach 17 , 20 (see again the schema depicted in Figure 1 ), and include the macro-landscape pressures landscape (including government decisions or developments in the international context), the social-technical regime (e.g. the current UK power system structure and its regulation), and niche innovations (e.g. lifestyle-influenced changes in demand). Its key outputs are technology and demand change uncertainty ranges for future energy and emissions pathways.\nEEA: The tool designated as energy and environmental appraisal (EEA) is an accounting framework based on the environmental life-cycle assessment (LCA) of the UK power system (for full details see Hammond et al. 57 and see section ‘Whole systems energy and environmental appraisal of the different energy mixes’ below). Based on a broad inputs set of technology-specific emissions factors, 26 , 58 the key outputs are 18 environmental impact categories 57 that are evaluated from cradle-to-gate, accounting for both upstream and operational (or stack) emissions. The categories included climate change (via GHG emissions), fossil fuel depletion, human toxicity, particulate matter formation and agricultural land use change.\nHESA/UK+: This optimisation model is an enhanced version of the hybrid energy system analysis (HESA) tool (for full details see Barnacle et al. 27 ). The model cost-optimises the UK electricity network, based on the energy hub concept, using key inputs of national power demand and generation mixes as input assumptions/parameters. The principal output is spatial disaggregation of generation, storage, transmission and distribution in terms of 17 onshore nodes, five offshore zones and 39 connections.\nHAPSO: The holistic approach to power system optimisation (HAPSO) model is a bottom-up, cost-minimisation power system model (for full details see Strbac et al. 59 ), with key inputs of technology costs and characteristics as well as electricity system topology. The model’s key output is the optimal power generation, storage, transmission, and distribution network infrastructure requirements, as well as their associated cost. The model then simultaneously estimates long-term investment requirements and short-term operational decisions, including in regard to hourly dispatch, demand side response (DSR; whereby customers are financially incentivised to lower, or shift, their electricity use in order to reduce demand at peak times), storage cycles and power interconnection.\nDownload in PowerPoint\nFigure 8. A schematic representation of the Future Energy Scenario Analysis (FESA) model. Source: Updated from Barton et al. 28\nThese models and appraisals yield a broad spectrum of cross-scales insights 55 covering system boundaries, time, space, and disciplines (see Figure 7 ). They were found to reveal a rather fragile nature of the transition pathway narrative descriptions or storylines. 55 The CC pathway storyline was found, for example, to imply an overestimation of the potential for power demand reduction and for the uptake of marine renewables. The necessity for CCS to meet the 2050 UK GHG emissions target was likewise overestimated. However, they were found to downplay the challenge of supply-demand balancing and the need to use gas power plants as a back-up capacity, as well as the role of nuclear power and electricity interconnectors with Europe.\nThese and other findings have benefited from a whole systems and collaborative working aimed at elaborating and examining pathways for realising a transition to a low carbon, secure and affordable UK energy system by 2050. Thus,\nA critical review of quantitative models for exploring socio-technical transitions has aided interdisciplinary learning between the different developers and users of the storylines, models and appraisal tools. 8 , 24 , 26 – 28 , 55 – 58\nThe iterative improvement of the qualitative narrative descriptions for the pathways, combined with that for a diverse range of models and appraisal techniques, is likely to be a key element in the robust development of future transition pathways and energy scenarios. 55\nAnnual demand modelling\nThe Demand model 28 , 55 assembles trends for the overall annual demand for electricity and fuels to 2050. The model builds from bottom-up representations of the energy service demands in the major sectors, the performance of existing buildings and end-use equipment, and the prospects for technological improvements and behaviour changes. Heating technologies in the domestic, service and commercial sectors are modelled in detail; industrial process heat is represented through underlying sub-sector demands and expected trends. Data were drawn initially from the Energy Consumption in the United Kingdom (ECUK) 60 database with further disaggregation by end-use and service employing assumptions about future technical change developed based on multiple sources. 28 The trends for electrification of transport are modelled, linked to work within the project. 61 Assumptions were compared to those in the DECC 2050 Calculator. 52\nIntroducing the spatial dimension to demand, the HESA model 26 , 27 utilises network theory to calculate flows, the energy hub concept to represent the conversion of energy between carriers (i.e. generation, including renewable energy sources), and deterministic least-cost optimisation (of fuel, generation, transport). The UK+ model includes physical descriptors of all generators, energy demands and storage requirements. It contains the 17 UK onshore nodes, as well as having nodes representing five offshore zones (Norway, Belgium, Netherlands, France and the UK Continental Shelf (UKCS)). The model contains multiple carrier transportation networks to/from international nodes (39 connections facilitate the transportation of electricity, gas, coal, oil, biomass and CO2) with demand and supply capability to represent international nodes (thereby facilitating international trade in energy carriers). HESA and UK+ have been used in combination to model an integrated multi-energy carrier network and applied to local, regional and national scale case studies in the context of the transition pathways, e.g. combined gas and electricity bulk flows with constraints across the United Kingdom.\nThis combination of models 55 indicates a temporal mismatch between low-carbon supply and demand may lead to very low utilisation factors of dispatchable generation, i.e. power plants that can be turned on, off, or have their output varied in a relatively short time at the request of the network operator or plant owner. This affects financing of gas-fired power stations, as well as hampering the prospects for CCS. Supply-demand balancing leads to increasing curtailment of renewables and additional fossil fuel use, illustrates the potential for electricity storage, but suggests that innovation would be required for longer term storage. This combination of models has also been employed for stress testing, optimisation and uncertainty analysis of the pathways. Different technology mixes were found to drive different regional patterns of investment as displayed in Figure 9 . Consistently high investment is required in the South East, South West, East of England and in Scotland. Other regions, such as the North East of England, were found to be exposed to large swings in potential investment under different pathways. Thus, the lessons learned from annual demand modelling were:\nAn increase in capacity of the electrical North-South corridor is essential for the success of all three pathways. A decrease in use of the national natural gas transmission system as a result of decarbonisation means an under-utilisation of the network. Total transmission and generation costs are likely to increase out to 2050 across all three of the UK transition pathways.\nEven in a system with greater localised energy sources (such as under the TF pathway) there is still a need for national energy infrastructures for electricity and gas.\nNote: Estimated via the FESA model. 27 , 28 , 55\nThe temporal mismatch between low-carbon generation and demand profiles may lead to very low utilisation factors of dispatchable generation. This is likely to affect financing of gas-fired power stations, and hampers prospects for CCS, which will need to be fitted to fossil-fired generation to achieve long-term carbon budgets. The supply-demand balancing issues will lead to increasing curtailment of renewables and additional consumption of fossil fuel. This leads to significant potential for electricity storage, although innovation will be needed to bring forward options for longer term storage. Thus, overall insights and lessons from hourly grid-balancing can therefore be summarised as:\nOne year, hourly modelling of Great Britain (GB) – the UK less Northern Ireland – grid balancing using the FESA model indicates a temporal mismatch of low-carbon generation against conventional demand profiles. This presents a much greater challenge to grid balancing than often assumed, e.g. in the DECC 2050 Calculator. 52\nAmbitious low-carbon pathways can lead to very low utilisation factors of dispatchable generation, including that with CCS, which could undermine the economic viability of this innovative, disruptive technology.\nA future system operator (in 2050 or beyond) will need to bear in mind a number of factors in order to secure grid-balancing 27 : the size of the interconnector compared to the peak surplus power requirements; the economic value of exported electricity (which may be quite low) compared to the value of fuel saved by using more resistive heating; and the necessity of maintaining a stable electricity grid (in the frequency and voltage domains) in the absence of conventional, thermal electricity generators.\nIn the absence of very large-scale long-term energy storage, significant curtailment of renewables and additional consumption of fossil fuel may arise at times.\nThe role and value of demand side response\nDemand response is a key option for supply-demand balancing 28 , 59 , 61 – 65 (see Figure 11 ), which offers benefits to all parts of the energy system that have been estimated to amount to some £4 bn per year. Electrification of heating and transport services may provide new opportunities for DSR. For example, research into social practices and service expectations combined with technical modelling (see the subsequent section) indicate that, if householders would tolerate a drop in indoor temperature of 1 ℃ for up to ten days a year, between 3 and 9 GW of peak supply capacity could be avoided. The key aim of DSR is therefore to explore the technical performance of various demand response concepts via time-step modelling techniques, but recognising the critical sensitivity to input assumptions regarding the level of expectations of the users. In order to model the potential demand response characteristics of individual load types, data was initially collected on multiple building loads for incorporation into the HESA/UK+ model combination. The data were then exchanged with the Demand and FESA models. An integrated scheduling algorithm was devised as an extension and redevelopment of the FESA model 26 – 28 (see again Figure 8 ) to allow demand response to compete on a level field against storage and controllable generation. The main calculations were translated into the VBA (i.e. visual basic for applications) code for greater visibility and future flexibility. It has been recognised that changes in the supplier/consumer relationship and in service expectations of consumers will inevitably impact on energy demand out to 2050 and beyond. Consequently, it is important to at least qualitatively ‘model’ consumer practices (see again the subsequent section) and to explore the relationships among customers, suppliers and consumers/prosumers. (Energy prosumers (see Figure 12 ) are those that produce (via distributed energy resources (DERs)), consume, manage or trade energy according to their own requirements and aspirations.) Smart DSP 28 can help to meet the challenges of flexible demand. Thus, water heating has been found to be capable of time-shifting (see again Figure 11 ) by around 50% for up to 7 h, space heating by 100% for up to 1 h, and EVs and plug-in hybrid electric vehicles (PHEVs) charging by 100% for up to 7 h.\nDownload in PowerPoint\nFigure 12. Structural opportunities to control flexible demand, including an illustration of the roles of the transmission network operator (TNO), distribution network operator (DNO), and flexible prosumers.\nThe penetration of renewable generation, particularly onshore and offshore wind turbine arrays, in the UK energy mix may reach as much as 15% by 2020. By that time the number of EVs in use may have reached over one million. Thus, the UK power system will be affected by an increasing imbalance, due to this rise in electricity demand (from EVs) and uncontrolled supply (from wind). Smart EV charging strategies 61 can therefore help the power system cope with high penetrations of local renewable energy sources (RES). Huang and Infield 61 recognised that domestic vehicles are typically parked for around 95% of the time, and hence EVs can be utilised as a ready form of responsive demand. They adopted a Monte Carlo model together with state-of-charge (SOC) information, as part of a whole systems framework, in order to estimate EV charging profiles. Wind farm data was taken from operational sites in Scotland. It was found that the cost over several small EV charging events was essentially free, provided that the surplus wind was greater than 1 MW. Likewise, the impact of the widespread adoption of high-performance heat pumps, alongside the large-scale penetration of wind generators, was recently studied by Cooper et al. 62 They devised a model using dynamic simulations of individual (air-sourced) heat pumps and dwellings, which indicated that increases in peak net-demand is highly sensitive to assumptions regarding the heat pumps themselves, their installation, building fabric (i.e. thermal insulation) performance and grid characteristics. If 80% of dwellings in the United Kingdom were to adopt such heat pumps, for example, then peak net-demand could rise by around 100% (54 GW), although this increase could fall to just 30% (16 GW) under favourable conditions. 62 Smart DSP could reduce this further to 20%, or even 15% with extensive use of thermal storage (as depicted in Figure 11 ). In contrast, should 60% of dwellings take up heat pumps, then the rise in peak net-demand could be as low as 5.5 GW, and consequently the electrification of heating would be more manageable for the network. 62\nAnother study by Teng et al. 63 examined the demand for ancillary services under a future GB electricity system as a result of the high penetration of wind generators with limited inertia capability. Under these circumstances, the network may be required to deal with sudden frequency drops following a loss of generator. An advanced stochastic generation scheduling model was employed to quantify the frequency response requirements and the contribution that could be made by DSR. 63 It suggested that the provision of frequency response from DSR could greatly reduce the system operation cost and wind curtailment. These DSR benefits were found to have significant diurnal and seasonal variation, whereas an even more rapid (near-instant) delivery of frequency response from DSR could yield substantial additional value. Competing technologies to DSR that can provide frequency regulation, such as battery storage 41 or more flexible conventional generation could potentially reduce its value by between 15% and 35%. 63 This would still leave significant room to deploy DSR as a cost-efficient frequency response provider within a future low-carbon electricity system.\nIt is critical to reflect how investors will take decisions to invest in (or to retire) generation plant within a market and policy context. Accounting for the incentives provided to companies through the trading arrangements is hence fundamental for modelling how investors take decisions going forward. As well as power market revenues, renewable and low-carbon generators are also reliant on subsidies to ensure their profitability, which is important for the investment decision-making process. Investors will form ‘rational expectations’ regarding the future when making investment decisions, taking into account power market conditions (e.g. electricity prices, demand growth, demand flexibility, changes in trading and regulatory arrangements, etc.) over the life of the asset based on all the information available to them at the time. Quantitative modelling studies have therefore been conducted in order to evaluate the competitiveness of demand response against other technologies, using a range of GB network case studies related to the transition pathways. A holistic approach (via the whole-electricity system investment model (WeSIM) 64 ; a successor to the HAPSO model 55 ) has been employed to assess the benefits of demand responses on power generation, transmission and distribution systems under each of the three pathways scenarios (see Figure 13 ). WeSIM, employed by Pudjianto et al., 64 is an enhanced model with respect to the modelling of demand and has more functionalities. It was used to provide useful insights on the characteristics of different pathways in terms of the expected increase in future peak demand, driven primarily by electrification of heating and transport sectors, 61 , 62 as well as the consequences for future power system infrastructure requirements. This approach 64 simultaneously optimised investment into new generation, network and storage capacity, while minimising system operation cost, and also considering reserve and security requirements. The analysis distinguished between bulk and distributed storage applications, while also considering the competition against other technologies, such as flexible generation, interconnection and DSR 64 (see again Figure 13 ). The results demonstrated that the DSR savings are potentially significant and that the MR pathway, for example, could save up to £90 bn of investment by 2050. A key issue arising from these studies is that the postulated generation capacity under the pathways may not be sufficient to meet security standards. This highlights the importance of considering the security of supply aspect in the development of future generation portfolios. Analysis of the electricity price characteristics of the three pathways showed that some generators with relatively very low load factors bring into question the feasibility of generation in an energy-only market. There are significant multi-stream savings that arise from DSR (multiple applications, including energy arbitrage, system balancing and capacity) across all pathways (amounting to some £4 bn/year by 2050). The benefits of whole-system based DSR applications are higher than those of the (non-coordinated) transmission network operator (TNO) or distribution network operator (DNO)-centric DSR applications: see again Figure 12 . This highlights the need for such whole system control co-ordination between the TNO and DNO in order to improve the interaction with DSR control.\nDownload in PowerPoint\nFigure 13. Annual versus peak electricity demand under the three UK transition pathways. Note: Estimated via WeSIM 64 ; a successor to the HAPSO model. 55\nEnergy storage (ES) represents one of the key enabling technologies to facilitate an efficient system integration of intermittent RES in conjunction with the electrification of heating and transport demand (see Figure 11 ). A stochastic optimisation method was used to quantify the benefit of distributed energy storage from the owner perspective. 65 A large set of case studies were carried out 65 in order to quantify the commercial and emissions benefits of ES in respect to energy and ancillary service markets, the revenue obtained from feed-in tariffs (FiTs), and the consequent reduction in operational CO2 emissions. ES was found to be able to provide opportunities for temporal arbitrage, because of the volatility of day-ahead and real-time (balancing) energy prices with a value of between £100/kWh and £650/kWh. 65 Its value in terms of anciliary services, such as frequency response, was estimated to be up to about £200/kWh on top of the basic value of ES. The value of ES for FiT revenue maximisation was found to decrease with increasing capacity from £108/kWh to £38/kWh. 65 When ES is charged during low-emission periods and discharged in high-emission ones, then the carbon footprint falls by around 10% even with losses taken into account. Teng et al. 65 observed that current and near-term batteries did not appear to be cost-effective for power generation applications. Thus, they noted that LIBs were most effective (∼£480/kWh) for kW/kWh applications with reasonable charge/discharge cycle lives. 41 (The cost of LIBs are today about ∼£140/kWh (similar to the price in 2012 noted by Hammond and Hazeldine 40 of ∼£135/kWh) having fallen from >£1675/kWh in 1990.) This contrasts with sodium-nickel chloride devices (so-called ZEBRA 41 , 65 batteries) at ∼£329/kWh. Teng et al. 65 expect the costs of lithium ion batteries to halve by 2020, although they expect those for the ZEBRA battery technologies to remain largely unchanged.\nThe technical performance and social acceptability of a range of proposed DSR concepts has been examined via an integrated approach in order to quantify the changes in electricity load profiles of the type represented in Figure 11 . The benefits of DSR options to the various classes of consumers were quantified for a range of scenarios appropriate to the different transition pathways. McKenna and Thomson 66 examined, for example, the way in which domestic consumers with rooftop solar PV arrays could benefit financially from time-shifting. They used an internet discussion forum to determine whether consumers with such PV systems engage in DSR activities so that they benefit further from free, self-produced electricity. Washing machines, dishwashers and electric space and water heaters were the most commonly employed appliances to shift demand. 66 The results suggest that, while price is an effective driver of DSR, there are other factors that generate demand response of the sort depicted in Figure 11 . They indicate that consumers with PV are often willing to be more flexible than is commonly assumed. This behavioural response could possibly be used in future to devise innovative tariffs that might stimulate demand shifting. 68 These value assessments are important elements in assessing the take-up, scale and effectiveness of DSR that can be expected.\nThese and other findings have benefited from a whole systems and collaborative working approach for elaborating and examining the transition pathways for realising a low carbon, secure and affordable UK energy system by 2050. Thus, the insights and lessons learned from studying the role and value of DSR were:\nDemand side participation (DSP) concepts are mainly short term (minutes to hours), whereas flexibility is needed over several days or more. The rigid patterns of modern living and consumer expectations based on life-long experience of fossil-fuelled supplies make such flexibility challenging, but are important to explore. Fully automated DSR concepts, such as ‘smart’ controllers for EV charging and heat-pumps, have been studied in some detail.\nBattery energy storage and controlled EV charging helps cut peak demands, but typically provides only a few hours of storage, doing little to address longer term weather-related variations. A Monte Carlo model of EV movements and home based charging 61 has been used to analyse the impact on a typical low voltage distribution network with typical household loads, suggests voltage impacts to be the most critical: voltages could easily become unacceptable without demand side management. The extension of EV charging to allow workplace charging seems to relieve the distribution network loads and help avoid voltages outside the statutory range.\nDecarbonised electrification of heating could make a useful contribution to the reduction in UK CO2 emissions, but may cause a challenging increase in peak power demand, net of non-dispatchable generation. This can be reduced, although not entirely eliminated by thermal energy storage and DSP. In addition, it has been shown 62 that high-performance (air-sourced) heat pumps, with appropriate installation and better insulated buildings, could make the rise in peak net-demand far more manageable.\nAn integrated market model (developed in WeSIM 64 ) has been used to analyse the evolution in electricity prices in different system backgrounds with different DSR technologies, network development, carbon prices and energy policies (related to market integration with the EU). When viewed in the context of a high share of renewable generation (such as under the TF pathway), the magnitude and volatility of electricity prices tend to increase, particularly driven by higher carbon prices and greater variable generation. The price differential between exporting and importing regions also widens from increased congestion in the national/cross-border transmission system.\nThere are significant multi-stream savings from DSR (via multiple applications, including energy arbitrage, system balancing, capacity) across all pathways; amounting to £4bn/year by 2050. These benefits of whole-system based DSR applications are higher than those of (non-coordinated) transmission system operator (TSO) or distribution system operator (DSO)-centric DSR applications. This highlights the importance of whole system control co-ordination.\nThe transition pathways have been costed under very different governance and institutional arrangements. Economic feasibility of generation in all three pathways will depend on the revenue from secondary markets/sources, such as capacity (ancillary service) market, FiT, tax incentives, etc., although the ratio of the revenue needed from primary and secondary markets is case specific.\nAttending to the social dimensions of realising transition pathways\nSection:\nThere is growing awareness that meeting the challenges of a low-carbon transition will require socio-technical solutions, and that consequently the social sciences have a key role to play in devising them, including working with engineers and physical scientists in an interdisciplinary manner. 66 – 68 A team of social scientists worked work interactively in collaboration with engineers in the present consortium to enhance consideration of the social dimensions of the project. This included work to open up assumptions about actor dynamics and social change as well as roles of the public and civil society in realising the UK transitions pathways. 66 – 68\nBuilding on the concept of the action-space devised in the first phase of the Transition Pathways project 8 , 24 , 30 (see section ‘Insights from historical transitions’ above), a relational co-productionist approach grounded in ideas form science and technology studies (STS) was developed to map relations between social actors across the UK electricity system and the spaces through which they participate in energy system change was developed to described the way in which different patterns of interaction between market, government and civil society actors lead to particular modes and logics of governance. 8 , 24 , 30 An important means of mapping actors and action spaces was through a systematic qualitative analysis of twelve contrasting visions of the low-carbon transition. This analysis showed that while some visions assume a technologically focused transition driven by the energy trilemma and centred on economic growth, alternative visions (particularly those from of civil society actors) place more emphasis on social and cultural change, issues of equity and fairness, and do not assume or depend on existing models of economic growth. Chilvers and Longhurst 67 studied four diverse sites of civil society engagement in low carbon transitions: the DECC Energy 2050 Public Dialogue (DECC 2050), the Camp for Climate Action (CCA; direct action events at various coal-fired power stations over 2006–2011), the Visible Energy Trial 8 , 33 (VET) and the Dyfi Solar Club (DSC; a community energy initiative in Machynlleth, Powys, Wales). They revealed that powerful forms of enrolment, exclusion and the partiality of visions and actions are common to all form of participation in transitions. Such analyses play a valuable role in transition pathways analyses through revealing social dimensions and informing how modelling studies frame the energy problem, bound the study system, and communicate uncertainties. It helped the wider consortium and technical analysts realise that that transitions are never smooth and will always be subject to contestation, negotiation and social change.\nThe other way in which social dimensions of energy transitions were attended to during the second phase of the realising transitions pathways project was through taking forward novel interdisciplinary (ID) experiments to co-produce social science and engineering insights on energy demand response in real time. These studies included a meta-review of social science evidence, leading into the design of small-scale integration experiments. The first of the ID experiments was a Service expectation experiment (see Figure 14 , and the summary in Table 3 ) in which the social science input into existing models was evaluated in order to improve model assumptions about how indoor comfort expectations could change over time. Such service expectations are often held to be stable, but social science literature suggests they vary in different ways. A range of service expectation scenarios were studied based on the outcomes from the review (such as more demanding standards, wider comfort zone and local diversity). The FESA model 26 – 28 ( Figure 8 ) was employed in order to examine various behavioural scenarios with variable service expectations. The work indicated that if householders (consumers or flexible prosumers; see Figure 12 ) were tolerant of a small internal temperature change either side of their desired set-point, and even allowing these for just a few hours per year this could yield large reductions in peak demands (a few GW): see again Figure 11 . This opened up the prospect of new behavioural scenarios for models, new parameters and boundaries. The term framing, used in Table 3 , implies the inevitable process of selective influence over the perception of an individual (involved in the experiment) in such a way as to encourage particular (potentially biased) interpretations and to discourage others. This experiment suggested that new levels of detail are required in existing FESA-like models (e.g. around heating/cooling technologies, housing stock, etc.). 26 – 28\nView larger version\nThe second strain of social science-led, ID experiment (by Higginson et al. 68 ), termed Modelling practices experiment (and again summarised in Table 3 ), was designed to develop new approaches to modelling based on social science understandings of, and data about, social practices. It encouraged the social scientists to communicate their ideas more clearly, whilst allowing engineers to think critically about the embedded assumptions in their models in relation to society and social change. Social practice theory together with network analysis 68 was adopted to provide a network diagram to visualise different practices. ID participants then collaboratively generate mappings of ecologies of practices: see Figure 15 that illustrates various social activities and practices in the home. The elements of practices – represented by circles – are distinguished in terms of images, skills (e.g. washing) and stuff (e.g. dirty clothes). Thus, washing clothes as an energy service is not merely determined by the washing machine, tumble drier and iron, but depends on much else. These other social factors include the meaning of clean, the way the different schedules in the household come together, the organisation of laundry and the way it is done in the household, and so on, i.e. the images and skills that are part of the practice of laundry. Graphs of practice networks such as this can be populated with empirical survey data. Higginson et al. 68 recently used this approach to examine from a survey of different types (or variants) of laundry practice. They gleaned insights into energy intensity, flexibility and the rootedness of practices, i.e. the extent to which they were entrenched or established. It was argued that this permitted the social practices to be represented graphically using a quantitative format ( Figure 15 ) without being overly reductive. This modelling practices experiment opened up new socio-technical discussions about core/periphery elements, variants of practice and so on, but also closes down discussion about the situatedness of practices (see Table 3 ).\nDownload in PowerPoint\nFigure 15. A simplified network representation linking social activities and practices in the home: identifying ‘hubs’, ‘anchors’ and ‘clusters’.\nThrough these ID experiments engineers had become more aware and reflective of the tacit social assumptions and limitation of their models, while social scientists became more aware of the complexity of energy models and the difficulty of making even small changes to their inbuilt assumptions. Importantly, these collaborations produced new findings and insights only possible through interdisciplinary working. Bringing together practice theory with network analysis extended and scaled up understandings of energy-related practices, generating new insights on the constraints and potentials for modelling flexibility and energy demand response. In the service expectation experiment, integrating social science insights into the FESA model showed how even small changes in thermal comfort expectations can lead to significant savings in terms of energy demand, which could prove crucial in realising low carbon transitions.\nKey challenges, insights and opportunities identified in these studies attending to the social dimensions of energy transition pathways include:\nNew evidence that quantitative energy modelling approaches routinely neglect important social aspects of energy transitions and how society will influence future pathways, including changes in how energy problems are framed, service expectations of users, the roles of public engagement and institutional changes.\nSocial science analyses can provide important new evidence about the relations between actors and forms of participation in energy transitions, which is important evidence in its own right and in sensitising models to alternative framings, social futures and uncertainites inherent to scenarios and model projections.\nIf interdisciplinary collaboration is well designed, open, collaborative and based on trust it is possible to integrate engineering and social science expertise, which produces new insights beyond what is possible with single-discipline approaches – for example, showing prospects for energy demand flexibility and responsiveness greater than previously estimated.\nThere is no single best practice approach to interdisciplinary energy research. An effective approach is to develop forms of integration between social science and engineering modeling approaches that are appropriate, diverse and can be evaluated and learned from over time.\nInvolving social scientists in real-time interdisciplinary collaboration with physical scientists can hold the key to producing whole systems energy models that are more responsible, anticipatory and accountable to the social implications and effects of energy transition pathways.\nDistributed energy\nSection:\nThe TF pathway explores a low-carbon transition led by civil society, which focuses on decentralised or distributed solutions to energy problems. Currently, less than 1% of UK electricity demand is met by community- or local authority-owned distributed electricity generation. A major driver for the TF pathway is seen to be a step change in the role of the civic energy sector (communities, co-operatives, local authorities, town and parish councils, social housing providers) through participation in, and ownership of, electricity generation schemes. ESCos are presumed to emerge, with incentives aligned with energy efficiency improvements. Because this pathway deviates most from the current energy market, and has no recent precedent, it has interested bodies including the public-private ETI (e.g. their Patchwork scenario) and the UK energy market regulator (Ofgem). The consortium postgraduate researchers (the Engine Room (see section ‘From narrative descriptions of the transition pathways to model formulation’ above); again working independently of the consortium leadership – the academic co-investigators) were asked to evaluate the implications of this novel pathway, and they produced a Distributing Power report. 69 With strong demand reduction and management, 50% of 2050 final electricity usage could be met via distributed generation with emerging technologies, new infrastructures (including interconnections), and new institutions. Although challenging to the current power system operational norms, a transition to 50% distributed generation by 2050 was found to be technologically feasible. However, it would require the installation and full utilisation of smart grid technology, alongside DSP, demand management, and other techniques and technologies. A more distributed system would clearly need regional energy strategies and local capacity building for city regions, municipalities, communities and citizens. A distributed energy system opens up new avenues for energy transition finance, while challenging incumbent utility business models. (The integrated market simulation model (WeSIM 64 ), described in section ‘Hourly demand profile modelling’ above, can be used to optimise real-time dispatch in a chronological fashion, as well as reflecting entry and exit decisions by investors, using an iterative process.) The model for investment in conventional and renewable generation was used to calculate the electricity prices (including energy and scarcity prices that reflect the scarcity in generation capacity during peak demand), generation and transmission revenues. It highlighted the finding that electricity prices are expected to be more volatile in the future and that the impact of demand response on average electricity price is modest but it reduces significantly the volatility.\nThe Distributing Power report 69 draws on empirical research, engagement with a wide range of stakeholders from the energy sector, and from experience in Germany, Denmark and in the United Kingdom. It offers insights into the barriers and the technological transformation that might be required for a move to a highly distributed energy future. This decentralised generation would be required to satisfy the TF pathway with an increase in regional, national and international interconnection in order to ensure electricity imports from neighbouring countries. 69 Much of the energy value that currently leaks out of the UK economy could then be captured at the local level. Such distributed energy systems have often been equated with increased energy independence. But significant reduction in electricity demand would be necessary, including improved energy efficiency and conservation. Households, for example, would need to more than halve current levels of electricity consumption by 2050. 69 National energy planning with regional and local support for a civic energy sector would be needed. This implies a much greater role for national and local government. The traditional business models of the Big Six incumbent electricity suppliers would inevitably be challenged as they lose market share to local generation and supply businesses. New infrastructure, like smart grids and emerging decentralised technologies (such as in-home fuel cells), would be necessary; requiring a large-scale expansion from 2020 onwards. The impact to consumer bills would only be marginally more expensive out to 2030, 69 although they could be significantly cheaper in the long term (to 2050) compared to the MR and CC pathways. While the Distributing Power report 69 assesses the impact of one distributed generation future, there are others which might see a greater role for solar, onshore wind, or other generation mixes.\nTraditionally, renewable electricity generation capacity in the United Kingdom has been built by large-scale commercial developers and/or utilities, whose finances are globally mobile. The Distributing Power report 69 suggests a possible alternative of a proliferation of distributed energy generators, which are owned fully or in part by municipalities, communities, or small-scale investors. (A companion piece to the Distributing Power report, 69 produced by Johnson and Hall, 70 has examined the distributional implications of the TF pathway.) Citizens would thereby gain more control over their energy use. Centralised generation would still be necessary for base-load and peaking capacity. However, for this to be viable in a distributed generation future, the government would need to provide the right incentives for new large-scale plant and infrastructure. The civic energy sector, defined as energy generation by communities, co-operatives, local authorities, town and parish councils or social housing providers, currently relies on motivated individuals and communities and often, voluntary work. The development of a decentralised future along the lines proposed for the TF pathway would require strong project management and professional expertise to deal with a range of technical, financial, legal and administrative issues. In order to move to a distributed approach, regional energy strategies and local capacity building would be essential to aggregate these local energy schemes into a coherent civic energy generation sector. 69 , 70 This would mean complementing national energy planning with regional and local support for a civic energy sector and implies a much greater role for both national and local government.\nThe launch of the Distributing Power report 69 in February 2015 informed the wider UK energy debate, and is leading to further work with key stakeholders, including an invited submission to the Ofgem non-traditional business models process. The headline messages were: 69\nAll UK energy projections, including a distributed energy future (such as that encapsulated in the TF pathway), require international interconnection. In addition, the TF pathway relies heavily on energy demand reduction, DSP and demand-side management. Households would need to more than halve their current levels of electricity consumption by 2050.\nA distributed energy system opens up new avenues for energy transition finance, while challenging incumbent utility business models. Around 50% of final electricity demand by 2050 could be met via distributed generation, but new infrastructures and emerging technologies would be required: from smart grids at a national level and to the likes of in-home fuel cells locally. A large-scale expansion would need to occur under the TF pathway from 2020 onwards. Thus, national energy planning with regional and local support for a civic energy sector would be needed.\nA high-level of distributed generation would require an increase in regional, national and international interconnection, such as electricity imports from neighbouring countries. Distributed energy systems have often been equated with increased energy independence. Much of the energy value that currently leaks out of the UK economy could be captured at the local level.\nThe traditional business models of the Big Six incumbent electricity suppliers would be challenged as they lose market share to local generation and supply businesses. In order to move towards a more distributed system, regional energy strategies and local capacity building would be essential for city regions, municipalities, communities and citizens.\nThe impact to consumer bills within a highly distributed power system (of the sort proposed for the TF pathway) would only be marginally more expensive in the medium term out to 2030, although it could be significantly cheaper over the long term to 2050 in comparison to those under the alternative MR and CC pathways.\nWhole systems energy and environmental appraisal of the different energy mixes\nSection:\nThe energy and environmental appraisal of the three transition pathways and associated power technologies have been evaluated within the context of a transparent sustainability appraisal framework, i.e. economic, social, environmental and technical benefits. 57 , 58 , 71 This process employed a toolkit of techniques to explore and evaluate the whole systems consequences of the selected transition pathways, such as the (embodied and process) energy and carbon implications of the pathways and technology mixes, their environmental burdens (as indicated by environmental LCA 57 , 58 , 72 – 75 ), and aggregate carbon and environmental footprints. A comprehensive review of the LCA of energy systems 57 included an overview of the historic development of LCA from the early 1990s, and its subsequent codification by the International Standards Organization (ISO). Environmental appraisal of energy systems needs to be conducted on a life-cycle basis, i.e. embracing the full range of extraction, production, distribution, and end-of-life processes or technologies. 57 , 58 , 72 – 75 In a full or detailed LCA, the energy and materials used and pollutants or wastes released into the environment as a consequence of an activity or service are quantified over the whole life-cycle; typically from cradle-to-gate. 57 Such studies are often geographically diverse; i.e. the energy and material inputs associated with the activity may be drawn from any continent or geo-political region of the world. They involve four main LCA stages that follow a logical sequence of goal definition and scoping, inventory analysis, impact assessment, and interpretation. The current strengths and weaknesses of LCA have been identified for the benefit of energy practitioners and policy analysts 57 (see Table 4 ). Comparisons were made with related approaches, such as carbon and environmental footprinting. 71\nTable 4. An outline of the strengths and weaknesses of environmental LCA.\nTable 4. An outline of the strengths and weaknesses of environmental LCA.\nSource: Hammond et al. 57\nView larger version\nAn examination of the whole system environmental burdens of the present transition pathways (version 2.1) was undertaken by Hammond and O’Grady 58 (as an extension of the earlier LCA study by Hammond et al. 75 (of version 1.1 of the pathways)), whereby GHG emissions reflected the sum of both upstream and operational emissions. The latter (‘stack’) emissions are those directly associated with the combustion of fossil fuels within power stations. Thus, the whole system emissions amount to those related to the ‘cradle-to-gate’. The national electricity network (operated by TNOs and DNOs) represents the downstream boundary known as the gate (hence, cradle-to-gate 75 ). In the studies by Hammond et al. 75 and Hammond and O’Grady, 58 they highlighted the significance of upstream emissions and their (technological and policy) implications, in contrast to the emphasis on power plant operational emissions conventionally presented by other analysts. These upstream environmental impacts arise from the energy requirements for extraction, processing/refining, transport and fabrication, as well as methane leakages from coal mining activities – a major contribution – and natural gas pipelines. The total carbon dioxide equivalent (CO2e) emissions associated with various power generators and UK electricity transition pathways towards a low carbon future are depicted in Figure 16 . This illustrates the GHG trajectory under each of the three transition pathways out to 2050. It was also found that CO2e capture facilities coupled to fossil-fuelled plants deliver only a 70% reduction in GHG emissions (including both upstream and operational emissions), in contrast to the normal presumption of a 90% saving.\nFigure 16. ‘Whole systems’ (upstream plus operational (or ‘stack’)) GHG emissions under the three UK transition pathways (1990–2050).\nGHG: greenhouse gas.\nSource: Adapted from Hammond and O’Grady. 58\nThe transition pathways LCA study by Hammond et al. 75 yielded estimates of pollutants or wastes released into the environment as a consequence of the UK ESI in terms of 18 separate impact indicators (together with a tentative single score, aggregate LCA measure). The lower the resulting score for each category (or the single score indicator) the better, although they doesn’t adequately reflect, for example, the impacts associated with nuclear power generation. Nuclear is low carbon, but has a number of other health and environmental impacts associated with the potential release of ionising radiation from nuclear power stations and processing plants. These are generally not effectively accounted for in LCA software tools, 75 because they do not have an underlying basis in ecotoxicology. Statistical weighting of the different LCA categories is normally achieved by the engagement of a panel of experts. It is therefore highly subjective, and this process would not be advisable in many cases. Clearly, it is difficult to manage something like 18 different impact categories, and consequently it is necessary to focus on key categories. Large impacts were found in terms of categories such as Human Toxicity, Freshwater Eutrophication, Marine Ecotoxicity and Natural Land Transformation 75 particularly under the MR pathway. Carbon emissions are the currency of debate in a climate-constrained world, 4 , 58 and consequently GHG emissions are typically given greater emphasis. There is likely to be a significant fall in carbon emissions from the UK power generation sector (see Figure 16 ) of some 31–51% by 2020, 65–86% by 2030 and 78–93% in 2050. 58 The lower figures relate to the MR pathway, whilst the higher ones are associated with the TF pathway. Notwithstanding the emphasis on GHG emissions, some of the other environmental burdens may need to be monitored.\nThe British Government’s independent Committee on Climate Change (CCC) has advocated deep cuts in power sector operational emissions through the 2020s, 46 with UK electricity generation being largely decarbonised by 2030–2040. In contrast, the present transition pathways projections (see again Figure 16 ) 58 indicate that the UK ESI could not be fully decarbonised by 2050 on the whole systems basis employed in the process-LCA studies. 58 , 75 This is because the present estimates take account of upstream, fugitive GHG emissions, whereas the projections by bodies like the CCC and Department of Energy and Climate Change (DECC) generally do not. Nevertheless, the transition pathways suggest that the ESI will be able to bear a significant share of the overall 80% carbon reduction target by 2050. The CCC analysis indicates that average operational emissions from the power generation sector would fall to around 50 gCO2/kWhe by 2030. 46 In contrast, the present MR pathway ( Figure 16 ) indicates that whole system emissions from the UK ESI are likely to only fall, accounting for upstream emissions, to ∼202 gCO2e/kWhe by 2030 and ∼105 gCO2e/kWhe by 2050. 58 The least impactful pathway (TF) suggests 58 that GHG emissions will fall to only ∼108 gCO2e/kWhe by 2030 and ∼53 gCO2e/kWhe by 2050 ( Figure 16 ). If the United Kingdom is to genuinely meet its legally-binding carbon reduction targets, then it will be necessary to account for upstream emissions from power generation. 58 , 75 Otherwise, even if the current UK carbon reduction targets are met, there will remain further emissions upstream.\nAn alternative way of evaluating the environmental impacts of the three UK transition pathways is via carbon and environmental footprinting. 4 , 71 Environmental or ecological footprints have been widely used in recent years as indicators of resource consumption and waste absorption associated transformed on the basis of biologically productive land area (in global hectares (gha)) required per functional unit (such as kWhe). They represent a partial measure of the extent to which an activity is sustainable. 4 , 71 In contrast, carbon footprints are the amount of carbon (or carbon dioxide equivalent) emissions associated with such activities in units of mass or weight (like kilograms per functional unit), although they can be translated into a component of the environmental footprint (on a gha basis). In order to determine the footprints associated with three UK transition pathways, the overall environmental footprint has been disaggregated into various components 71 : bioproductive and built land, carbon emissions, embodied energy, materials and waste, transport, and water consumption (see Figure 17 ). The total environmental footprint in the baseline year of 2010 was found from historic data to be 43 Mgha. In this case, the carbon and embodied energy footprint components were responsible for 80% to the total environmental footprint.\nFigure 17. Environmental footprints of the three UK transition pathways in 2050.\nSource: Adapted from Hammond. 71\nFuture environmental footprints were estimated for each of the three transition pathways. 4 , 71 Electricity demand was projected to decrease significantly under the TF pathway by 2050, but its total environmental footprint was nevertheless greater than either that under the MR or CC pathways (see again Figure 17 ). This is mainly due to the increase in the contribution of the bioproductive and built land component and that of the carbon footprint (rising to 10.9 and 12.5 Mgha respectively by 2050), 71 which are both seen to be higher than in either of the MR and CC cases. Thus increase in these TF pathway components was mainly due to increased usage of solid biofuels for power generation. In order to reduce the overall TF footprint it would therefore be necessary to adopt other renewable power technologies, like offshore wind and solar PV arrays, to satisfy the increase demands caused by electrification of heat and transport. The MR and CC pathways gave rise (see again Figure 17 ) to footprints of 23 and 25 Mgha respectively in 2050, as compared to 43 Mgha in the 2010 base year. 71 Here, the embodied energy component was the largest amongst the various footprint components; rising to 14 and 13 Mgha respectively by 2050. This was due to the large-scale use of fossil-fuelled power plants. There is a large reduction in carbon emissions under the MR pathway (over an 86% reduction compared to 2010 levels), whilst the CC pathway exhibits a slightly smaller fall (albeit nearly an 80% reduction). On the other hand, the TF pathway displays only 42% reduction in carbon emissions by 2050 ( Figure 17 ). Water and waste footprint components made almost negligible contributions under all three transition pathways (only ∼1% footprint share), although this was recognised as probably being an artefact of the footprint methodology and assumptions adopted. 71 Bioenergy and biofuel footprints and land-take (see again Table 2 ) reflect relatively large environmental burdens when compared to other fuels.\nThe carbon and environmental burdens associated with the three UK transition pathways have been assessed via environmental LCA and footprinting methods. Overall insights and lessons from such studies can be summarised as:\nA critical state-of-the-art review of this environmental LCA methodology57 has identified its current strengths and weaknesses for energy practitioners and policy analysts.\nThe extraction and delivery of fuel requires energy and creates GHG emissions. The upstream emissions associated with various power generators and UK electricity transition pathways have been evaluated on a whole systems basis. There will remain further emissions upstream that are unaccounted for by the CCC and DECC. They only account for upstream fugitive GHG emissions beyond UK borders.58,75\nThe carbon and environmental footprints of the three UK transition pathways have also been evaluated.71 The overall environmental footprints were disaggregated into: built land, carbon emissions, embodied energy, materials and waste, transport, and water consumption. This component-based approach has enabled the sustainability challenges to be assessed quite broadly, along with specific issues (e.g. the linkages associated with the so-called energy-land-water nexus).\nEconomic analysis and appraisal\nSection:\nAny transition pathway in the UK energy system will require very large expenditures in the capital intensive energy sector. The costs and potential benefits of such investments, as well as how these investments position key market participants in relation to a range of economic risks, are a critical element to the economic appraisal of such pathways. Economic considerations are the core consideration of market-led actors, while the government – in its social planning role – has a wider consideration of costs under a multi-criteria approach, but one in which a socially optimal transition pathway would reduce costs as far as possible. Many analysis frameworks of possible future energy transitions conduct only a post-calculation of costs (e.g. via the DECC 2050 Calculator or analysis by the UK energy market regulator (Ofgem)), whereas costs are a critical input into the formulation and decision making process in any transition pathway.\nMany existing energy modelling studies have been criticised for their limited treatment of societal actors and associated socio-political dynamics, together with poor representation of the co-evolving nature of society and technology. 76 It has therefore been argued that they consequently find it demanding to analyse socio-technical change. In parallel, it is evident that some of the prominent conceptual frameworks of socio-technical energy transitions (STET) find it difficult to operationalise policy development requirements in quantitative energy analyses. A review and critique of quantitative models for exploring STET was therefore undertaken by Li et al., 76 alongside their application to the energy supply, buildings and transport sectors. They subsequently devised a novel taxonomy for describing STET models 76 for integrating both quantitative modelling and conceptual socio-technical transitions, which incorporated techno-economic detail, explicit actor heterogeneity, and transition pathway dynamics. This study also highlighted a number of the challenges associated with their theoretical and behavioural validation, and proposed future development priorities for STET models. 76\nA stylised probabilistic energy system model (BLUE-MLP) has been constructed with key behavioural parameters on price and non-price drivers. The model has been extended to incorporate alternative actors, spatial and temporal detail. The initial version of the BLUE model was critically reviewed and validated by embedding it in the multi-model comparison exercise (see section ‘From narrative descriptions of the transition pathways to model formulation’ above, and Trutnevyte et al. 55 ). In addition, a literature overview for understanding the state-of-the-art research in behaviour and transition modelling was carried out. Participation in the qualitative-quantitative knowledge integration for demand response (see the above section) helped to collect further ideas on developing BLUE. The initial Excel economic appraisal of the transition pathways covers electricity generation, transmission and distribution. It takes account of the temporal and market participant elements. 77 The Excel economic appraisal (EconA) was embedded in the afore-mentioned multi-model comparison activity (see again section ‘From narrative descriptions of the transition pathways to model formulation’ above 55 ) in order to validate its findings against other realising transition pathway models. The implications of the multi-model comparison activity for the EconA and D-EXPANSE model were summarised by Trutnevyte et al. 55 (see both the sections ‘From narrative descriptions of the transition pathways to model formulation’ and ‘Annual demand modelling’ above). The D-EXPANSE model was used to model the UK power sector transition between 1990 and 2010, in order to get insights about the structural uncertainty of cost optimisation, and to systematically translate the transition pathways narratives into quantitative representations.\nClearly the costs and affordability of energy transitions are one of the most influential drivers in terms of the energy policy trilemma. But so also are the interactions between the power sector and other key economic sectors that drive decarbonisation in line with climate targets. A collaborative study between energy-economic modellers and power systems engineers from the Realising Transition Pathways Consortium therefore undertook a cost appraisal of the UK transition to a low-carbon electricity system under alternate governance logics. 77 This novel approach linked the quantitative electricity system transition pathways and their economic appraisal. Retirement of existing power plant capacity and the installation of new build was based on either DECC planned retirements 77 or estimated lifetimes. Costs of the transmission and distribution network infrastructures (see Figure 12 ) were modelled via the WeSIM 64 model – a successor to the HAPSO model 55 , 77 (see both the sections ‘From narrative descriptions of the transition pathways to model formulation’ and ‘Hourly demand profile modelling’ above). Outside the power system, only the costs of heat-producing devices (such as resistive heaters and gas boilers, community-scale and micro-CHP, and heat pumps) were included in the analysis. It focused on monetary costs and did not account for externalities, associated with the costs of different impacts on the environment 77 (like those considered within an LCA study, such as that described in the above section). The results (see Figure 18 ) contrast the dominant market-led MR transition pathway with alternate pathways that have either stronger governmental control elements (CC pathway), or bottom-up proactive engagement of civil society (TF pathway). The MR pathway exhibited the lowest investment costs out to 2050, whereas the CC pathway had slightly higher total system costs; presuming its implied government policies could be enacted and maintained. The bottom-up, more decentralised (TF) pathway was found to come at the expense of higher investment costs, 77 although it encourages wider participation with civil society. It requires significantly higher investment in renewable electricity generation, electric heating, and particularly EV transport. The spatial distribution of investment requirements under each UK pathway was another issue explored by the partnership of energy-economic modellers and power systems engineers (see Figure 9 ) (and section ‘From narrative descriptions of the transition pathways to model formulation’ above).\nDownload in PowerPoint\nFigure 18. Relative capital investment costs for the three UK transition pathways out to 2050. Source: Updated estimates based on Trutnevyte et al. 77\nEconomic appraisal of the three UK transition pathways 55 , 76 , 77 contributes to an understanding the future interplay of the energy policy trilemma, i.e. achieving deep GHG emission cuts, whilst maintaining a secure and affordable energy system. The insights and lessons from these studies can be summarised as:\nInvestment costing of the three UK transition pathways under very different governance and institutional arrangements was achieved via a novel collaborative study between energy-economic modellers and power systems engineers. 77 It showed that the TF pathway gave rise to the highest investment costs, due to the need for large-scale renewables (such as wind farms), electric heating, and principally EVs and their transport/charging infrastructure.\nFrom this novel STET taxonomy for integrating both quantitative modelling and conceptual socio-technical transitions, 76 methodological improvements in economic analysis of transition pathways were identified as being as important as the analytical insights from any given modelling comparison. For example, firstly understanding the spatial and temporal boundaries of any cost calculation, and secondly assessing if demand reductions are induced by policy instruments (a welfare loss) or attributed to lifestyle evolutions (no welfare loss) are fundamental challenges.\nStimulating investment in low-carbon options\nSection:\nAnalysis of historical energy transitions 30 – 32 (see section ‘Insights from historical transitions’ above) demonstrates that rapid change is possible, but not frequent, and requires a high degree of co-ordination of actions, driven by recognised need to change, e.g. the shift from Town Gas to natural gas. Potential low-carbon investors in the United Kingdom are faced with uncertainty about national policy priorities, and there are structural constraints on low-carbon investment, including immaturity of the sector and mismatches between fund manager and renewable energy investment timescales. 80 The economic feasibility of generation under all three transition pathways will depend on revenues from secondary markets/sources (e.g. the capacity market, FiT and various tax incentives). However, the ratio of the revenue needed from primary and secondary markets is case specific. Comparison with the situation in Germany demonstrates the valuable role that can be played by locally focused institutions, where civic ownership is supported by a local banking sector. 83\nA review of socio-technical systems research by Bolton and Foxon 78 argued that this approach can be operationalised to assess policy and societal challenges of large-scale investments in the low-carbon infrastructure. They observed that the United Kingdom is moving into a new phase of energy governance with significant demand for new investment to meet long-term climate policy objectives, as well as shorter term energy security challenges. The UK Government’s recent EMR aims to promote investment in large-scale low carbon technologies, through incentive schemes such as the contract for difference (CfD) and FiTs. They provide a guaranteed price for low carbon generation and thereby remove one significant uncertainty, although policy and political risks still remain. In further research, Bolton et al. 79 interviewed a range of energy policy and industry stakeholders, revealing different views on governance of energy systems. Those in favour of a liberalised market approach thought that the government should just set the rules, but otherwise not interfere to address price and other risks. In contrast, the mainstream investment community continues to be concerned that other risks could prevent large-scale investment in low-carbon generation. The Levy Control Framework, which was put in place out to 2020 with no clarity as to if it will be extended beyond that, has created an additional policy uncertainty for investors. Capacity markets have been introduced in order to ensure security of energy supply, indicating that this has greater priority than meeting carbon budgets (as reflected in recent UK Government energy policy pronouncements). This again creates uncertainty for investors, as experience indicates that regulatory frameworks and incentives are liable to change over time. In order to bring in new actors, such as mainstream institutional investors, better understanding of how they perceive these risks and uncertainties is required.\nA socio-technical approach has been employed 78 to this important area of policy debate in three specific areas: understanding long-term uncertainty and investment risks; avoiding technological lock-in; and accelerating the diffusion of low carbon finance niches. It explored the dynamics of long-term structural change in capital intensive systems (such as energy, housing and water supply with the aim of seeking to redirect them towards more sustainable long-term trajectories. Bolton and Foxon 78 argue that interventions need to balance the demands of private investors with wider social objectives. A better understanding of investment risk and uncertainty is required. Insights from the MLP of transitions theory suggest that it is necessary to avoid lock-in to current technologies, and the need to support low carbon finance niches.\nIn a follow-up study, Bolton et al. 79 examined the way in which actors in the UK electricity sector are attempting to deliver investment in low-carbon technologies. Such generation capacity is relatively immature and is capital intensive, although they have low operational costs. Empirical research 79 investigating the agency of incumbent regime actors in the face of uncertainty was based on interviews with 36 stakeholders from private and civic energy companies, mainstream and alternative investors, renewables project developers, energy policy makers and civil society. It was found that low-carbon generation does not readily fit into existing electricity markets and investment templates that were designed for a fossil fuel based energy system. The findings of Bolton et al. 79 can inform contemporary debates on the politics and governance of sustainability transitions and offers critical insights on the role of markets and finance in shaping socio-technical change. Key electricity market and infrastructure policies in the United Kingdom were analysed 79 in order to determine ways that low carbon technologies could be made investable. This research argued that this could be achieved by reducing uncertainty, better management of investment risks, and repositioning actors within the electricity socio-technical regime.\nThe role of financial markets in capitalising low-carbon energy systems and long-term change has been explored. 80 Capital requirements for energy system transitions are typically very large, and yet the literature has been curiously quiet on the role of capital markets in financing energy transitions. Stakeholder interviews identified that there are relatively few deals, whilst learning and adaptation are slow. Economic incentives, such as the CfD and FiT strike prices, or renewable obligation certificates (ROCs), are only one type of driver for change. This implies that providing stable incentives may not lead to market penetration of renewables investment. Hall et al. 80 have analysed the UK EMR process and the provision of renewable energy finance, and argued that an adaptive market hypothesis provides a useful framework for understanding the evolution of electricity markets in response to low carbon policy incentives. They demonstrated that the market for renewable energy finance does not conform to the standard efficient markets hypothesis, due to structural and behavioural constraints on investment. However, considering financial markets as being adaptive enables the range of policy responses for the acquisition of low-carbon investment to be much broader. 80\nPrimary data collection was undertaken by Hall and Foxon 81 to characterise the importance of a smart grid infrastructure within a UK energy transition. The UK economy and electricity system have co-evolved, but there remains a mismatch between the distribution of benefits and costs of investing in this infrastructure; leading to a problem of value capture and redeployment. Some benefits of smart grids are less easy to price directly, and are more accurately classified as public goods, such as energy security and decarbonisation. Hall and Foxon 81 drew on semi-structured interviews and focus groups involving UK smart grid stakeholders. This led them to identify municipal-scale developments as potential sources for new business models to deliver smart infrastructure. Municipalities may thus pursue specific economic opportunities with DNOs to make smart grid investments. This supports recent practical interest in an expanded role for municipalities as partners and investors in smart grid infrastructures.\nTransforming energy distribution networks will also play a key enabling role in a low-carbon energy transition in the energy, water and mobility sectors. But Bolton and Foxon 82 have argued that there is relatively little understanding of the social and institutional dimension of these systems, or appropriate institutional challenges to their transformation. This may be because the prevalent model of infrastructure governance in the energy and other sectors has prioritised short-term time horizons and static efficiencies. Bolton and Foxon 82 therefore discuss the appropriate governance strategies for developing flexible and sustainable systems of energy distribution. They draw on ideas from the social shaping of technology in order to develop a broader understanding of infrastructure change as a dynamic socio-technical process. A range of governance challenges to the development of electricity and heat networks are examined along the different phases of the infrastructure life cycle. Lessons are then drawn for the development of governance frameworks for the transformation of energy infrastructure more widely. 82 In the case of electricity distribution in Britain, the regulator (Ofgem) has sought to design suitable incentives to overcome barriers to long-term investment and innovation, although these are at an early stage of implementation. UK local authorities, by contrast, have struggled to finance large-scale infrastructure investments in the area of district heating (so energy-efficient and popular in the Scandinavian countries).\nA comparative analysis of recent energy policy developments in selected European countries (e.g. the German Energiewende) and on the implications of developments at a European level on UK energy policy (e.g. carbon pricing and market unbundling) has been reported by Hall et al. 83 Field research on the German situation drew out the implications for ownership, governance and financing of low carbon energy infrastructure. The German system differs from UK system in at least four ways. It had a much greater degree of decentralisation and municipal ownership, following post-War reconstruction. Their low-carbon transition or Energiewende was seen as a national priority. More decentralised political institutions in the German federal system enable a greater degree of energy policy experimentation. Finally, a more bank-based financial system in Germany, including a well-developed local banking system, contrasts with the centralised and market-based financial system in the United Kingdom. These local German banks have often built on local knowledge and encouraged small-scale renewable investment. They became key promoters of civic and community ownership of electricity generation assets. Such municipal ownership might again enable a similar, more long-term perspective to be taken in the United Kingdom, with a focus on good, safe, reliant energy infrastructure. Further economic and social benefits might then accrue to local municipalities.\nThese roles of actors, governance arrangements and regulations have been analysed in relation to realising market-led, government-led and civil society-led low carbon transition pathways, leading to the following findings:\nEnergy systems can best be understood as socio-technical systems made up of interacting technological and institutional elements, coevolving over time. Governance and regulatory frameworks are critical in managing risks for decision-makers and investors.\nChanges to investment support for low-carbon electricity generation have led to increasing risks and uncertainties, and concerns that long-term governmental commitment to decarbonisation may be undermined if the salience of energy security and cost priorities grows.\nAnalyses of energy finance as an adaptive market 80 help identify the lack of a mature community of investors, mismatches between investment and fund manager timescales, and lack of suitable investment vehicles. Capital markets are likely to change over the long-term to yield more adaptive markets for energy finance.\nThe economic feasibility of generation in all three pathways will depend on the revenue from secondary markets/sources, such as the capacity (ancillary service) market, FiT, and various tax incentives, although the ratio of the revenue needed from primary and secondary markets is case specific.\nA comparative UK–Germany analysis 83 has shown the importance of the local banking sector in facilitating civic ownership structures there.\nThe possibility of a low-carbon, decentralised transition (like that envisaged under the TF pathway) driven by civic energy systems has highlighted the role of local banking systems, and of shared values (including public service and local economic development). 83\nConcluding remarks\nSection:\nThe British Government has set a legally binding target of reducing the nation’s CO2 emissions by 80% by 2050 in comparison to a 1990 baseline. 6 This would ideally require the UK ESI to be decarbonised by around 2030–2050 in order to give more head room for carbon mitigation in other, more challenging sectors (such as industry and transport). 46 A set of three low-carbon transition pathways were developed and analysed via an innovative collaboration between engineers, social scientists and policy analysts. The pathways focus on the power sector, including the potential for increasing use of low-carbon electricity for heating and transport, within the context of critical European Union developments and policies. Their development started from narrative storylines regarding different governance framings, drawing on interviews and workshops with stakeholders and analysis of historical analogies. The quantified UK pathways were named Market Rules (MR), Central Co-ordination (CC) and Thousand Flowers (TF); each representing a dominant logic of governance arrangements – recently described by the Chief Executive Officer of a prominent UK renewable electricity supplier and generator company (unconnected with the project) as reflecting blue, red and green pathways respectively. These pathways have been used to explore what is needed to realise a transition that successfully addresses the so-called energy policy trilemma, i.e. the simultaneous delivery of low carbon, secure and affordable energy services. Such energy transitions are never smooth and always subject to contestation, negotiation and social change. The UK ESI has already undergone quite rapid change over the last few years. 84 Coal power station closures, for example, have amounted to 15 GW between 2010 and 2015; with combined cycle gas turbine plant closures accounting for a further 4 GW. In contrast, there has been a rapid rise in solar PV systems that now stands at around 853,000 installations, for which rooftop solar alone now accounts for >1% of UK electricity supply. 84 The recent British Government energy policy reset, the components of which will only become clear during 2017 (although some senior executives in the UK power sector speculate that it will propose roughly 30% nuclear, 30% renewables, and 30% gas) will lead to additional changes going forward. Thus, if the three transition pathways were being developed today they would no doubt contain rather different energy mixes. The TF pathway might contain more solar PV, but less bioenergy, for instance. Nevertheless, the insights gained from this exercise still provide a valuable evidence base for developers, policy makers and other stakeholders.\nA fundamental requirement for identifying and addressing the multiple challenges and opportunities posed by energy policy and climate change necessitates a combination of academic knowledge with that from industry, commerce, regulatory bodies, political and societal communities. This ambitious goal appears to be more achievable in processes that combine the analytic (the systematic application of expert knowledge) with the ‘deliberative’ (the systematic application of opportunities for face-to-face discussions between experts, stakeholders and citizens). 85 , 86 The ‘Realising Transition Pathways’ Consortium has adopted the practice of the co-production of knowledge to explore and integrate different kinds of expertise in order to provide opportunities for reflection and evaluation. It has attempted to achieve a level of joint working that allows the effective sharing of disciplinary-specific and professional expertise. New evidence and case studies of UK energy transitions provide practical advice on how sustainable energy transitions will depend on science and policy institutions becoming more responsive and adaptive to distributed societal actions. Here the challenges, insights and opportunities that have been gleaned from this research are highlighted (via bullet point summaries at the end of each principal section above).\nAnalytical tools were developed and applied to assess the technical feasibility, social acceptability, and environmental and economic impacts of the pathways. Technological and behavioural developments were examined, alongside appropriate governance structures and regulations for these low-carbon transition pathways, as well as the roles of key energy system actors (both large and small). An assessment of the part that could possibly be played by future demand responses was also undertaken in order to understand the factors that drive energy demand and energy-using behaviour. A set of interacting and complementary engineering and techno-economic models or tools were then employed to analyse electricity network infrastructure investment and operational decisions to assist market design and subsidy mechanisms. This provided a basis for integrating the analysis within a whole systems framework of electricity system development, together with the evaluation of future economic benefits, costs and uncertainties. Likewise, the energy and environmental performance of the different energy mixes were appraised on a life-cycle basis to determine the GHG emissions and other ecological or health burdens associated with each of the three transition pathways. The UK Carbon Budgets 46 are presently on track for an 80% reduction (in production emissions) by 2050, although it has been observed here 58 that the impact of upstream (and consumption) GHG emissions are generally excluded. The impact of such upstream emissions on the carbon performance of technologies (such as combined heat and power (CHP) and CCS) and the transition pathways themselves 58 distinguish the present findings from those of other analysts, such as the CCC and DECC. None of the three pathways yield zero GHG emissions by 2050, which suggests that the UK electricity sector cannot realistically be decarbonised by 2030–2040 as advocated by the CCC. 46\nSocio-technical solutions are required on both the demand and supply-side of any future UK energy system. Reduction in energy demand for heat, power and transport will be a significant element of any energy strategy aimed at limiting global warming to <2 ℃ under whatever pathways actually results out to mid-century. 87 , 88 Improvements in energy efficiency can be obtained from better thermal insulation of the building fabric, smart appliances and controls, alongside the adoption of efficient heating systems, such as heat pumps, community energy schemes and the like. In addition, lifestyle or workplace changes, DSR and DSP may well be needed, but these will be partially offset by so-called rebound effects. Decarbonising the supply-side is likely to see the continued adoption of new nuclear build (although the whole system costs may be prohibitive), offshore wind, and rooftop solar PV. It will inevitably need the take-up of CCS (as well as carbon capture and utilisation (CCU)) for a cost-efficient transition, together with sustainable bioenergy and biofuels, and possibly hydrogen (H2) as a fuel and energy storage media in the long term. Unfortunately, there are constraints over the use of bioenergy resources, including uncertainties over the availability of UK sustainably-sourced biomass, land use challenges, and competition with food supply. Finally, the energy infrastructure in Britain will need renewal in order to make it more resilient (e.g. to climate change impacts) and to potentially accommodate greater decentralised or distributed generation, including greater use of both large and small energy storage devices. Significant generation, transmission and distribution network reinforcements (operating with much lower utilisation factors) will be needed to meet future changes in demand and generation patterns. However, smart power innovations (a combination of interconnectors, storage and demand flexibility (or DSR)) could generate £8 bn per year of savings (according to a report for the recently-established UK National Infrastructure Commission 89 ; for which a member of the Realising Transition Pathways Consortium (Goran Strbac and his team) played a key role 90 ). Indeed, in a risk assessment study of the UK power sector, Hammond and Waldron 11 found that lack of investment in new infrastructure to be ranked the second highest risk to the power sector by different stakeholder groups (academic researchers, civil servants, electricity companies, green groups, power system engineers and various others). The electricity grid was found to be arguably the most vulnerable part of the power system; reinforcing the case for UK network renewal and reconfiguration by the middle of the 21st century. 4 , 11 Innovation, systems integration, and whole systems thinking to identify sustainable energy options (sometimes termed optionality in industry), as examined in the present study, will therefore be critically important in the transition towards a low-carbon future.\nAcknowledgements\nThe authors are particularly grateful for the critical, but supportive, views of members of the project Advisory Board (chaired by James Smith, former chairman of Shell UK and presently chairman of the UK Carbon Trust) made up of industrial representatives, UK Government policy makers and other stakeholders. The authors are also grateful for insights provided by an anonymous reviewer from climate, energy and innovation policy perspectives. However, the views expressed in this paper are the responsibility of the authors alone and not the external collaborators or the funding body.\nThe authors’ names are listed alphabetically.\nDeclaration of Conflicting Interests\nThe author(s) declared no potential conflicts of interest with respect to the research, authorship, and/or publication of this article.\nFunding\nThe author(s) disclosed receipt of the following financial support for the research, authorship, and/or publication of this article: This work draws on research undertaken as part of a major research grant awarded by the UK Engineering and Physical Sciences Research Council (EPSRC) entitled ‘Realising Transition Pathways - Whole Systems Analysis for a UK More Electric Low Carbon Energy Future’ [under Grant EP/K005316/1]. The authors are grateful to this sponsor, as well as for the interchanges with the main UK-based post-doctoral researchers associated with the project (see the project website www.realisingtransitionpathways.org.uk for a full list of those involved).\nReferences\n""","0.120429866","""http://journals.sagepub.com/doi/10.1177/0957650917695448""","[-0.178219,51.500505]"
"""Imperial_College_London""","""Realising transition pathways for a more electric, low-carbon energy system in the United Kingdom: Challenges, insights and opportunitiesProceedings of the Institution of Mechanical Engineers, Part A: Journal of Power and Energy - Jason Chilvers, Timothy J Foxon, Stuart Galloway, Geoffrey P Hammond, David Infield, Matthew Leach, Peter JG Pearson, Neil Strachan, Goran Strbac, Murray Thomson, 2017""","""Figure 5. The dynamic relationship between energy security, framing of energy and governance logics.\nSource: Johnson et al. 30\nShifting views about how security affected the framing of energy emerged between WWI and WWII; leading to the prevalence again of hybrid governance. A relational approach was used by Johnson et al. 30 to explore the emergence of policy support for fuels and their final withdrawal. That showed how and why emerging technological substitutes can founder and transitions fail in times of economic instability. It led to shifting hybrid state and market governance between incumbents (i.e. the oil majors) and newcomers (e.g. DCL and ICI). These studies consequently reflect a partial historical analogue for the hybrid roles of the state and the market in energy governance (e.g. UK Electricity Market Reform (EMR)), as well as the changing priorities within the energy policy trilemma between climate change mitigation and the provision of secure and affordable energy services. The case studies also provide insights about technological substitutes and new infrastructures (electrifying transport and heat), as well as concerns about the influence of incumbent actors and institutions influence to either advance or constrain low-carbon transitions.\nA further supply-side study of the development of the integrated UK natural gas system over the period 1960–2010 by Arapostathis et al. 31 has illustrated the way in which such integration was closely linked to governance patterns. This explored the development of the gas system in two transitions: (i) from town to natural gas with state governance logic (under the management of the nationalised British Gas Corporation); and (ii) then privatisation and liberalisation after 1987. The latter major structural change is regulated by Ofgem, with a Uniform Network Code (UNC) overseen by the Joint Office of Gas Transporters. Vertical integration has been aided by new control and communication technologies, together with internationalisation via gas interconnectors. That reduced uncertainties, but increased the system’s complexity. This case study 31 provided an analogue for the challenges of integrating large, infrastructural technical systems for a sustainability transition. It is inscribed within the MLP approach yet concentrates on system integration as a complex and uncertain socio-technical process. It indicates how quite dramatic changes in the UK natural gas structure are mirrored in regime formation (see Figure 1 ).\nLittle historical work has been undertaken on energy demand reduction. A study of electric heating in early post-war Britain 32 when electric fires were used at peak times and were therefore particularly problematic in terms of energy end-use, offers insights into the challenges often associated with demand reduction. The Electricity Development Association (EDA), originally established as a public relations arm of the UK electricity industry, tried simultaneously to reduce undesirable peak demand, whilst encouraging increased demand more generally. In the late 1940s, it recommended that electric fires should not be used to meet peak demand. However, in the 1950s and 1960s it concentrated on promoting off-peak heating appliances. It first sought to do this in the United Kingdom via under-floor heating, and then block storage heaters typically composed of clay bricks or other ceramic material. The study under the auspices of the transition pathways consortium by Carlsson-Hyslop 32 analysed the way in which the London County Council (LCC) and its tenants adopted and adapted electric underfloor heating. It concluded that attempts by the electricity industry during the period 1945–1964 had only a limited effect on the trend towards rising energy end-use demand. This was, in part, due to EDA promotional efforts. This analysis is consistent with that on households’ engagement with customer-facing elements of a smarter grid, such as smart meters or energy monitors (see, e.g. a predecessor consortium study by Hargreaves et al. 33 ). Social variables like daily routines, individual preferences and social relations in a household were found by Hargreaves et al. 33 to be important for energy demand reduction. This may reflect a co-evolution of technology with social practices, changing routines, and behaviour. It illustrates the kinds of processes, practices, interactions and modes of governance that need to be considered if demand management/energy efficiency are to succeed in containing energy use and GHGs, whilst enhancing the quality of people’s lives.\nPolicy makers tend to have little institutional memory of what has worked or has not worked in terms of energy sector interventions, because job changes are used to enable UK civil servants to gain experience and avoid accumulating positional or departmental loyalty, and because ministers often serve for short periods (from 2008 to 2015 of the four Secretaries of State for Energy and Climate Change, one served for less than 2 years and another for just over 1 year). Historical analyses/stories of past transitions therefore help them (and other stakeholders) to understand how and why transitions have previously succeeded or failed. They also indicate how long they can take to implement and the reasons why. Overall insights and lessons from such studies can be summarised as:\nThe historical studies have shown that rapid change is possible, but not necessarily frequent. It may require a recognition of the need to change, openness to experiment and a high degree of co-ordination (e.g. the natural gas transition). These studies illustrate how co-evolutionary and co-constructed are the material or physical aspects with the social, political and institutional aspects. For example, the 1966–1977 conversion from town gas to natural gas required both technical changes, including building the national gas grid and installing new burners in millions of gas appliances, along with major institutional reorganisation, new workforce training and political support. 31\nHistorical studies of two alternatives to petrol in the inter-war period 30 show how and why emerging technological substitutes can founder and potential transitions fail in times of economic instability, shifting governance and competition between incumbents and newcomers.\nA further supply-side study of the development of the integrated UK natural gas system over the period 1960–201031 suggests that such integration was closely linked to governance patterns. It indicated how quite dramatic changes in the UK natural gas structure are largely reflected in regime formation and change.\nThere is little historical work on demand reduction. However, the recent study of the EDA and domestic electric heating in post-war Britain 32 suggests that their attempts had limited impacts on the trend of rising demand, and thereby illustrates the challenges facing demand reduction today.\nHorizon scanning and technology assessment of energy systems\nSection:\nTechnological choices in the UK power sector are likely to vary significantly out to 2050. For example, over the last few years the outlook for both coal-fired power stations with CCS and nuclear power has changed dramatically. The UK Government indicated (in November 2015) their wish to phase out unabated coal-fired power stations by 2025, and giving new gas-fired power stations priority. Likewise, the prospects of new nuclear build has been hit by both concerns following the 2011 Fukushima disaster in Japan and a reassessment of the economics of nuclear power by some of the big players, such as the investment decision by the French utility eDF Energy in regard to the construction of the Hinkley Point C nuclear power plant (in Somerset). These short-term changes in attitudes to low-carbon technologies mean that the technology choices implicit in each of the existing pathways need to be kept under continuous review. Horizon scanning involves a portfolio of methods that enable energy researchers and other power sector stakeholders to increase their awareness of important emerging influences on the UK energy system and its environment. It provides a major strand in proactive risk management 11 and strategic thinking as the UK energy sector moves forward. Parker et al., 34 for example, used a modified Delphi technique for horizon scanning in order to identify some 30 emergent policy issues, which strongly featured science and technology, and which would necessitate public engagement as the policies were being developed. This was driven, in part, by concerns over the use of hydraulic fracturing (or fracking) by fossil fuel companies for shale gas extraction in the United Kingdom. A disparate group of people with interests over the science and policy interface (e.g. policy makers and advisers, academics and the private sector) initially elicited a long list of issues. These were then refined into a shorter list that were viewed as being of top priority for policy makers. They included challenges related to energy and environment, such as policies concerning interdisciplinary whole energy systems science (incorporated by a partner in the Realising Transition Pathways Consortium (Jason Chilvers) 34 ). A variety of alternative techniques are available for use in identifying emerging issues in the UK energy sector. Arup Foresight (part of the independent firm of designers, planners, engineers and consultants) have, for example, employed STEEP (social, technological, economic, environmental, political) analysis to examine drivers for change in both the energy and climate change fields. The Realising Transition Pathways Consortium have used a similar approach, in conjunction with more formal methods of Technology Assessment 35 , 36 to evaluate a number of the main disruptive energy technologies. These studies have sought to identify the components of a balance sheet of technological credits and debits in order to evaluate their societal impacts, and to determine whether they are compatible with Britain’s move towards a low-carbon future in 2050 and beyond.\nIndicative energy technology assessments (ETAs) have been carried out for a variety of energy technologies, e.g. UK shale gas extraction, 37 carbon capture and storage (CCS), 38 , 39 advanced rechargeable batteries, 40 rare earth elements (REE) as a constraint on clean energy technologies, 41 nuclear power plants 42 and tidal power barrages. 43 These ETAs were all indicative in the sense of being a simplified evaluation and illustration of the performance of state-of-the-art devices. Nevertheless, such assessments provide a valuable evidence base for developers, policy makers and other stakeholders. Each technology was evaluated using a combination of quantitative and qualitative methods within the spirit of the STEEP approach. The most controversial of these studies was arguably that concerning the benefits and ‘costs’ of shale gas fracking in Britain. 34 , 37 Exploratory drilling in the United Kingdom is at an early stage, with great uncertainty over the scale of the potential shale gas resource. 37 However, such activities are already meeting fierce community resistance. Like all energy technologies, it exhibits unwanted side-effects that simply differ in their level of severity compared to other options. Successful extraction might contribute positively in terms of fuel security and independence, as well as jobs and growth. 37 Shale gas may also make a contribution to attaining the UK’s statutory GHG emissions targets, although potentially harmful environmental impacts need to be satisfactorily resolved via appropriate monitoring and robust regulation. It is unlikely that gas bills for UK household and industrial consumers would fall dramatically as they have done in North America, because Britain is linked to the wider European gas market. Anything produced in the United Kingdom would be a ‘drop in the ocean’ compared to imports via either pipelines or by way of liquefied natural gas (LNG) tankers. Finally, the socio-economic advantages and disadvantages of shale gas fracking are not evenly distributed between various communities and demographic groups. 37 Community engagement in a genuinely participative process – where the government is prepared to change course in response to the evidence and public opinion – will consequently be critically important for the adoption of any new energy option.\nCCS facilities coupled to fossil fuelled power plants or industrial sites provide a key climate change mitigation strategy that potentially permits the continued use of fossil fuel resources, whilst reducing the CO2 emissions. Hammond and Spargo 39 highlight the potential design routes for the capture, transport, clustering and storage of CO2 from UK power plants. Both currently available and novel CCS technologies were evaluated. Due to lower operating efficiencies, the CCS plants showed a longer energy payback period and a lower energy gain ratio than conventional plant. There are also several technical and financial obstacles that need to be overcome, 38 including the adoption of an appropriate legislative framework and the need for full CCS chain risk assessments. There are uncertainties over the full-scale power plant CCS technical performance and costs, which may only become clearer when the first demonstrators are operational. Unfortunately, the UK Government cancelled (on 25 November 2015) their £1 bn CCS competition shortly before the winning consortium was due to be announced. Inevitably, the bidding companies were dismayed by this outcome and the prospects for CCS in Britain in the short term now looks rather bleak. Prior to this, the Government had established a CCS Cost Reduction Task Force 44 as an industry-led joint venture to assist with the challenge of making CCS a commercially viable operation by the early 2020s. The main cost-reduction opportunities were seen as being 44 : (i) transport and storage scale and utilisation, (ii) improved financeability for the CCS chain, and finally (iii) improved engineering designs and performance. Greater financial incentives for carbon abatement could, in principal, be secured through a higher carbon price from the European Union Emissions Trading Scheme (EU ETS), although that has been a significant disappointment in terms of the carbon price level. A collaborative study between the Energy Technologies Institute (ETI), a public-private partnership of key industrial companies and UK funders of energy RD&D, and the Ecofin Research Foundation (ERF) 45 has recently examined the conditions required for mobilising private sector financing of CCS in the United Kingdom. They argue that this technology would be a ‘huge prize’ that could cut the annual costs of meeting the 2050 carbon target by up to 1% of gross domestic product (GDP). 38 , 39 , 45 But they noted that the prevailing financial market conditions are demanding. In order to meet this challenge, they suggest that the United Kingdom needs to build confidence in long-term policy, develop attractive pricing for CCS contracts with suitable risk sharing, put in place an appropriate regulatory and market framework, and devise new ways to offset North Sea storage liability risks. 45 Many believe that the UK Government will need to return to CCS deployment in order to meet its 2050 GHG emissions reduction target in a cost-effective way. 46\nTwo other large-scale power generators that could be available to help secure a low-carbon future for the United Kingdom are nuclear power plants 42 and tidal barrages. 43 The lives of existing nuclear plant has typically been extended to around 40 years (e.g. Hunterston B was financed for 25 years with an expectation of 35 years, and subsequently extended by 7 years). Nevertheless Britain, as with other nuclear-powered European countries, will be progressively decommissioning its older nuclear power stations during the next decade or so. This will leave only the Sizewell B pressurised water reactor (PWR) station in the United Kingdom, with nuclear power holding a considerably reduced share of electricity generation (perhaps as low as 3% by 2020 from around 20% in the winter of 2013–2014). A new generation of nuclear power stations may therefore need to be part of the power generation mix in order to decarbonise the electricity sector by around 2030–2050. In Europe these plants are likely to be variants of the third-generation European pressurised reactor (EPR) design. Emerging (novel) nuclear reactor designs are thought to be inherently safer and less costly 42 ; perhaps having a 25% lower generating cost than present systems. However, the research by the former UK Sustainable Development Commission 47 suggests that a doubling of Britain’s existing nuclear capacity would only yield an 8% cut on CO2 emissions by 2035. Over the longer term, it is likely that the European governments will want to keep a watching brief on advanced nuclear reactors (including modular designs) that are currently being developed in France/Germany, South Africa and the United States. Nevertheless, they will no doubt want to be reassured that such new technologies will be commercially viable. 42 The adoption of either short- or medium-term technologies would obviously be critically dependent on public attitudes to nuclear power in Britain and elsewhere. 1 , 11 , 42 Both the Cardiff-Weston and the smaller Shoots barrages on the River Severn between Somerset and south Wales have been evaluated by Hammond et al. 43 using various ETA techniques to determine their net energy output, carbon footprint and financial investment criteria, alongside various critical technical and environmental issues. These tidal power schemes were assessed over their foreseen lifespan of 120 years in terms of its cradle-to-site, operation and maintenance requirements. The proposed Cardiff-Weston Barrage would yield relatively attractive figures of merit in terms of its net energy and carbon emissions, although its financial performance is poorer than alternative power generators. Comparisons were made with the much smaller, Shoots Barrage scheme that would be located up-river of the Severn road crossings, and which is favoured by environmental groups, because of its more benign ecological and environmental impacts. 43\nThe suitability of advanced rechargeable battery technologies (ARBT) for different applications, such as electric vehicles (EV), consumer electronics, load levelling and stationary power storage, has been the subject of another ETA. 40 These energy storage devices were compared to more mature nickel–cadmium (Ni–Cd) batteries in order to gain a sense of perspective regarding the performance of the ARBT. Lithium (Li)-ion batteries (LIB) currently dominate the rechargeable battery market and are likely to continue to do so in the short term in view of their excellent all-round performance, 40 and firm grip on consumer electronics. However, in view of the competition from Li-Ion Polymer (LIP) batteries their long-term future is uncertain. Although, if safety concerns are overcome and costs fall significantly, there may be growth in the EV sector and to a lesser extent load-levelling, where LIB can exploit their relatively high cycle life. 40 Rare earth batteries and magnets are key elements of hybrid vehicles and gearless wind turbines, and phosphors are critical in energy saving lighting. Hammond and Mitchell 41 argued that ‘rare earth elements' (REE) may place a significant constraint on the development of some low-carbon (or clean) energy technologies. These materials are not actually rare in terms of their abundance, but the number and location of mines are restricted due, in part, to economic considerations. Current REE reserves stand at about 110 million tonnes with around half in the People’s Republic of China (PRC), although other countries like the United States, Commonwealth of Independent States (CIS) (the former Soviet Republics) and Australia hold substantial reserves. Production in China dominates the market, with ∼97% of the global total, and this will remain so until new mines are developed. The PRC has limited its export of REE in order to give preference to the export of manufactured products. Diversity of the global supply chain is therefore a crucial issue moving forward (see Figure 6 ). It is likely that supply constraints will become less critical in the medium to long term as more mines come into operation, and thus further reserves become available. 41 Such constraints could be eased by reducing the amount of material required per application, or changing the technology altogether. LIB, 40 for example, are already a viable replacement for nickel-metal-hydride units in hybrid vehicles. Their costs have fallen from >£1680/kWh in 1990 to <£140/kWh today. REE are not currently recycled, either pre or post-use. There are processes available that could be utilised for this purpose, although they do not currently appear to be economically viable options. 41\nDownload in PowerPoint\nFigure 6. Diversity of global ‘rare earth elements’ (REE) supply over the medium term. Note: ‘Current’ reflects the 2011 baseline. 41\nIn order to round-off these ETA-like studies, an evaluation of the energy densities and spatial footprints of both conventional and renewable generators was undertaken by Cheng and Hammond 48 on a life-cycle (or cradle-to-gate) basis. It was stimulated by a desire to test an assertion by Fells 49 that renewable energy technologies for electricity generation (such as bioenergy plants, solar PV cell arrays, wind turbines and the like) have a low energy density in comparison with fossil fuel or nuclear power stations. He suggested, for example, that if all the wind farms operating in the world in about the year 2000 were to be concentrated on the South Downs of England, then only 10% of UK electricity demand would be met. On a similar basis, he argued 49 that in order to replace Scotland’s two nuclear power stations a total of 10,000 250 kW LIMPET-type wave power generators (i.e. shoreline oscillating water column devices) would be required of the type installed on the island of Islay (one of the Hebridean islands; off the north west coast of Scotland). In the case of biomass energy, Fells 49 postulated that an area the size of the county of Kent would have to be covered in coppiced willow in order to replace half of the output from Dungeness B nuclear power station (a 1040 MW plant consisting of two AGRs, and located in the same county). The nuclear fuel cycle (both with diffusion and centrifuge enrichment) was found by Cheng and Hammond 48 to have the highest energy density of the technologies they examined, with bioenergy plants having the lowest. Their results are summarised in Table 2 , where they are compared with those of Gagnon et al. 50 and of the US Environmental Working Group (EWG). 51 Onshore wind power exhibited a relatively promising energy density and is greater than that of its offshore counterpart, the energy density of the latter fell below that of solar PV arrays. Thus, renewables were found to produce dilute electricity overall with a spatial footprint that is orders-of-magnitude higher than for conventional sources. That was in line with the views of Fells, 49 although there are many other sustainability criteria that will determine their usefulness in the transition towards a low carbon future. 48\nTable 2. A comparison of the spatial footprints per unit of output from various power generators.\nTable 2. A comparison of the spatial footprints per unit of output from various power generators.\nSource: Adapted from Cheng and Hammond. 48\nView larger version\nThe horizon scanning and technology assessment of the energy options 34 – 36 that will influence the three UK transition pathways contributes to an understanding the future interplay of the energy policy trilemma, i.e. achieving deep GHG emission cuts, whilst maintaining a secure and affordable energy system, and addressing how resulting tensions might be resolved. Overall insights and lessons from such studies can be summarised, for example, as:\nShale gas extraction has potential unwanted side-effects, and is already meeting community resistance and controversy. A balance sheet approach has been used to determine the benefits and disbenefits of shale gas fracking. 37 It may contribute to energy security, jobs and growth, as well as attaining national GHG targets over the medium term. Thus, it might form the basis of a transitional energy strategy for the United Kingdom, although the wider environmental impacts will require appropriate and robust regulations to be enforced.\nCarbon capture and storage (CCS) from fossil-fuel power stations is likely to be a key technology in achieving a low carbon future in the United Kingdom at a reasonable cost. 38 Energy and carbon analyses have been undertaken, along with indicative cost estimates, for fossil-fuelled power stations with and without CCS. 39 It could significantly cut GHG emissions, provided technological and financial obstacles can be overcome.\nLarge-scale nuclear power plants and tidal power barrages both exhibit attractive figures of merit in terms of their overall energy performance and near-zero carbon emissions, but have very long financial payback periods. 40 , 43 The latter makes them difficult to undertake with the support of only private sector investors. Nuclear power also gives rise to ongoing problems with high and intermediate-level waste disposal, 40 although a deep underground repository is the preferred option. The siting of such a facility has yet to be resolved in the United Kingdom. A tidal barrage built across the Severn Estuary would inevitably give rise to significant ecological modifications to the aquatic environment. 43\nThe suitability of ARBT have been evaluated for different applications. 40 While LIBs are likely to continue to dominate the rechargeable battery market in the short term, their long-term future is uncertain, because of competition from LIP batteries. There may be some LIBs growth in the electric vehicle sector, if safety concerns are overcome and costs fall significantly, and somewhat less in load-levelling, through their relatively high cycle life.\nRare earth batteries and magnets are key elements in the hybrid vehicles and gearless wind turbines, as are phosphors in energy-saving lighting, but short-term economic mining constraints on REE may limit their development. 41 Such concerns could also be eased by using less material per application, recycling REE, either pre- or post-use, or changing the technology altogether.\nThe energy densities and spatial footprints of various power generators were evaluated on a life-cycle basis. 48 The nuclear fuel cycle was found to have the highest energy density, with bioenergy plants having the lowest. Onshore wind power exhibited a relatively promising energy density; being greater than that for its offshore counterpart. The energy density of the latter fell below that of solar PV arrays.\nElectricity system and network modelling and evaluation\nSection:\nBackground\nA number of reputable studies have been undertaken over recent years that support low or zero carbon energy scenarios for the United Kingdom. These include those produced by the British Government’s Department of Energy and Climate Change (the DECC 2050 Calculator 52 ), the UK Energy Research Centre (the UKERC Energy 2050 Project 53 ), and the Tyndall Centre for Climate Change Research. 54 They all enable insights to be drawn regarding the realism of each scenario set, and reflect a range of aspirations from those wishing to achieve 2050 carbon reduction targets: 80% in the case of DECC 52 and UKERC 53 projections. However, the five Tyndall decarbonisation scenarios 54 focused on an earlier 60% carbon reduction target for 2050, although they employ a distinctive backcasting approach generated and reviewed with the aid of stakeholders. On the other hand, the DECC 2050 Calculator is basically an engineering-based, Excel spreadsheet model that is open source and arguably transparent. The tool permits users to select their own combination of technologies to achieve an 80% reduction in GHG emissions by 2050, whilst ensuring that energy supply and demand are balanced. The UKERC Energy 2050 Project 53 employed a core four-scenario core set that was underpinned by a single cost-optimisation model (UK MARKAL). It took ‘an eclectic approach to scenario building’ 53 with a backcasting dimension to achieve a combination of UK energy resilience and climate change mitigation. In contrast, the quantification of the three pathways developed by the Realising Transition Pathways Consortium was underpinned by a suite of multiple models.\nFrom narrative descriptions of the transition pathways to model formulation\nA range of models were developed to elaborate/explore demand, supply and infrastructure aspects 26 and feed into revising the pathways, both quantitatively and qualitatively in the second iteration for version 2.1 of the transition pathways. Qualitatively this has involved building narrative stories out to 2050, whilst quantitatively it has necessitated the construction of matching, consistent spreadsheets of demand, supply, technologies and (implicit) infrastructure. This was a challenging and time-consuming process, but one that yielded a valuable learning experience. Electricity models were used to variously address hourly, annual and seasonal balancing on regional, national and international scales. An informative multi-modelling comparison of the pathways was then undertaken to innovatively link and embed narrative storylines to technological, economic, social and institutional drivers and constraints. The framework of eight models and appraisal tools (see Figure 7 for the suite of individual models as of April 2013) were iteratively linked and checked for consistency between the various tools and the narrative descriptions of the pathways. This exercise was undertaken by the postgraduate researchers functioning as what was known in the Realising Transition Pathways Consortium as the Engine Room 55 the researchers working independently of the consortium leadership (the academic co-investigators).\nFigure 7. The framework of quantitative models utilised within the Realising Transition Pathways project.\nSource: The Transition Pathways Consortium. 55\nThis cross-scale study was based on the storyline or narrative description of the CC pathway, 8 , 24 which was then evaluated via six power system models and two appraisal techniques. It was used to iteratively link the CC narrative with the models/appraisal tools. Harmonised assumptions on power system inputs and system output targets for each model or tool were initially extracted from the CC pathway storyline. 8 , 24 The framework of models (see again Figure 7 ) was then employed to map the key features of each model/appraisal tool in terms of their temporal, spatial and disciplinary perspectives. Clearly, the narrative description of the CC pathway 8 , 24 was found to be critical for transmitting information about governance logic and the choices of key actors. Nevertheless, many of these parameters were found to be inconsistent. Typically, the CC storyline resulted in an overestimate of demand reduction levels, the uptake of CCS and marine renewables. This is because the narrative storyline tends to underestimate the technical and economic challenges associated with these levels of demand reduction and uptake of CCS and marine renewables. These were subsequently highlighted through the quantitative modelling analysis. Likewise, the narrative description led to an underestimate of the supply-demand balancing requirement, the need for back-up capacity, and the role of nuclear power and interconnectors with Europe, compared to the challenges identified through the modelling in achieving these outcomes.\nThe eight models and appraisal tools (in the order of their breadth of power system boundaries, and in line with the sequence indicated in Figure 7 ) were:\nDemand: This energy demand model (for full details see Barton et al. 28 ) is a highly disaggregated simulation model of UK energy demand for both the domestic and non-domestic sectors. Its primary inputs are a range of characteristics, 26 , 52 including energy service levels, user practices, choices of appliances, building fabric, fuels, deployment of distributed generation, and other parameters, with its main output being final energy demand across the UK building stock.\nFESA: The future energy scenario analysis (FESA) model (for full details see Barnacle et al. 27 ) is a single-year UK power generation and demand simulation model, incorporating 1-hour time steps for dispatch modelling. The overall structure of this model is depicted in Figure 8 . It utilises 2001 UK Met Office weather data on temperature, wind speeds, solar radiation and wave height. The FESA model incorporates technical feasibility constraints on the power network, and enables hourly grid-balancing.\nD-EXPANSE: This model (dynamic version ofexploration ofpatterns innear-optimal energyscenarios; for full details see Trutnevyte 56 ) is a power system optimisation model. D-EXPANSE systematically explores the various near-cost-optimal pathways, as well as the structural uncertainty, based on key inputs of demand, technology costs and characteristics, fuel prices and power system transmission topology. Its main output in terms of UK power systems configuration and costs has been validated by comparing its outputs with that for a variety of existing, well-established whole system models and their cost estimates for the UK. 55\nEconA: The economic appraisal (EconA) appraisal technique (for full details see Trutnevyte et al. 55 ), is an accounting model that systematically calculate and compare investment and total system costs for power generation, transmission and distribution under the three UK transition pathways. The key inputs are the ranges of component technology costs, efficiencies and other technical characteristics. The quantitative output is disaggregated into shares of different power generation technologies, thereby allowing the assessment of economic feasibility of any given pathway (such as the CC pathway in the contribution of Trutnevyte et al. 55 ).\nBLUE-MLP: This model (behaviourlifestyles anduncertaintyenergy model withmulti-levelperspective on transitions) is a probabilistic systems dynamics simulation model (for full details see Trutnevyte et al. 55 ). Its key inputs derive from sector- and actor-specific behavioural elements 55 that arise from the MLP transitions approach 17 , 20 (see again the schema depicted in Figure 1 ), and include the macro-landscape pressures landscape (including government decisions or developments in the international context), the social-technical regime (e.g. the current UK power system structure and its regulation), and niche innovations (e.g. lifestyle-influenced changes in demand). Its key outputs are technology and demand change uncertainty ranges for future energy and emissions pathways.\nEEA: The tool designated as energy and environmental appraisal (EEA) is an accounting framework based on the environmental life-cycle assessment (LCA) of the UK power system (for full details see Hammond et al. 57 and see section ‘Whole systems energy and environmental appraisal of the different energy mixes’ below). Based on a broad inputs set of technology-specific emissions factors, 26 , 58 the key outputs are 18 environmental impact categories 57 that are evaluated from cradle-to-gate, accounting for both upstream and operational (or stack) emissions. The categories included climate change (via GHG emissions), fossil fuel depletion, human toxicity, particulate matter formation and agricultural land use change.\nHESA/UK+: This optimisation model is an enhanced version of the hybrid energy system analysis (HESA) tool (for full details see Barnacle et al. 27 ). The model cost-optimises the UK electricity network, based on the energy hub concept, using key inputs of national power demand and generation mixes as input assumptions/parameters. The principal output is spatial disaggregation of generation, storage, transmission and distribution in terms of 17 onshore nodes, five offshore zones and 39 connections.\nHAPSO: The holistic approach to power system optimisation (HAPSO) model is a bottom-up, cost-minimisation power system model (for full details see Strbac et al. 59 ), with key inputs of technology costs and characteristics as well as electricity system topology. The model’s key output is the optimal power generation, storage, transmission, and distribution network infrastructure requirements, as well as their associated cost. The model then simultaneously estimates long-term investment requirements and short-term operational decisions, including in regard to hourly dispatch, demand side response (DSR; whereby customers are financially incentivised to lower, or shift, their electricity use in order to reduce demand at peak times), storage cycles and power interconnection.\nDownload in PowerPoint\nFigure 8. A schematic representation of the Future Energy Scenario Analysis (FESA) model. Source: Updated from Barton et al. 28\nThese models and appraisals yield a broad spectrum of cross-scales insights 55 covering system boundaries, time, space, and disciplines (see Figure 7 ). They were found to reveal a rather fragile nature of the transition pathway narrative descriptions or storylines. 55 The CC pathway storyline was found, for example, to imply an overestimation of the potential for power demand reduction and for the uptake of marine renewables. The necessity for CCS to meet the 2050 UK GHG emissions target was likewise overestimated. However, they were found to downplay the challenge of supply-demand balancing and the need to use gas power plants as a back-up capacity, as well as the role of nuclear power and electricity interconnectors with Europe.\nThese and other findings have benefited from a whole systems and collaborative working aimed at elaborating and examining pathways for realising a transition to a low carbon, secure and affordable UK energy system by 2050. Thus,\nA critical review of quantitative models for exploring socio-technical transitions has aided interdisciplinary learning between the different developers and users of the storylines, models and appraisal tools. 8 , 24 , 26 – 28 , 55 – 58\nThe iterative improvement of the qualitative narrative descriptions for the pathways, combined with that for a diverse range of models and appraisal techniques, is likely to be a key element in the robust development of future transition pathways and energy scenarios. 55\nAnnual demand modelling\nThe Demand model 28 , 55 assembles trends for the overall annual demand for electricity and fuels to 2050. The model builds from bottom-up representations of the energy service demands in the major sectors, the performance of existing buildings and end-use equipment, and the prospects for technological improvements and behaviour changes. Heating technologies in the domestic, service and commercial sectors are modelled in detail; industrial process heat is represented through underlying sub-sector demands and expected trends. Data were drawn initially from the Energy Consumption in the United Kingdom (ECUK) 60 database with further disaggregation by end-use and service employing assumptions about future technical change developed based on multiple sources. 28 The trends for electrification of transport are modelled, linked to work within the project. 61 Assumptions were compared to those in the DECC 2050 Calculator. 52\nIntroducing the spatial dimension to demand, the HESA model 26 , 27 utilises network theory to calculate flows, the energy hub concept to represent the conversion of energy between carriers (i.e. generation, including renewable energy sources), and deterministic least-cost optimisation (of fuel, generation, transport). The UK+ model includes physical descriptors of all generators, energy demands and storage requirements. It contains the 17 UK onshore nodes, as well as having nodes representing five offshore zones (Norway, Belgium, Netherlands, France and the UK Continental Shelf (UKCS)). The model contains multiple carrier transportation networks to/from international nodes (39 connections facilitate the transportation of electricity, gas, coal, oil, biomass and CO2) with demand and supply capability to represent international nodes (thereby facilitating international trade in energy carriers). HESA and UK+ have been used in combination to model an integrated multi-energy carrier network and applied to local, regional and national scale case studies in the context of the transition pathways, e.g. combined gas and electricity bulk flows with constraints across the United Kingdom.\nThis combination of models 55 indicates a temporal mismatch between low-carbon supply and demand may lead to very low utilisation factors of dispatchable generation, i.e. power plants that can be turned on, off, or have their output varied in a relatively short time at the request of the network operator or plant owner. This affects financing of gas-fired power stations, as well as hampering the prospects for CCS. Supply-demand balancing leads to increasing curtailment of renewables and additional fossil fuel use, illustrates the potential for electricity storage, but suggests that innovation would be required for longer term storage. This combination of models has also been employed for stress testing, optimisation and uncertainty analysis of the pathways. Different technology mixes were found to drive different regional patterns of investment as displayed in Figure 9 . Consistently high investment is required in the South East, South West, East of England and in Scotland. Other regions, such as the North East of England, were found to be exposed to large swings in potential investment under different pathways. Thus, the lessons learned from annual demand modelling were:\nAn increase in capacity of the electrical North-South corridor is essential for the success of all three pathways. A decrease in use of the national natural gas transmission system as a result of decarbonisation means an under-utilisation of the network. Total transmission and generation costs are likely to increase out to 2050 across all three of the UK transition pathways.\nEven in a system with greater localised energy sources (such as under the TF pathway) there is still a need for national energy infrastructures for electricity and gas.\nNote: Estimated via the FESA model. 27 , 28 , 55\nThe temporal mismatch between low-carbon generation and demand profiles may lead to very low utilisation factors of dispatchable generation. This is likely to affect financing of gas-fired power stations, and hampers prospects for CCS, which will need to be fitted to fossil-fired generation to achieve long-term carbon budgets. The supply-demand balancing issues will lead to increasing curtailment of renewables and additional consumption of fossil fuel. This leads to significant potential for electricity storage, although innovation will be needed to bring forward options for longer term storage. Thus, overall insights and lessons from hourly grid-balancing can therefore be summarised as:\nOne year, hourly modelling of Great Britain (GB) – the UK less Northern Ireland – grid balancing using the FESA model indicates a temporal mismatch of low-carbon generation against conventional demand profiles. This presents a much greater challenge to grid balancing than often assumed, e.g. in the DECC 2050 Calculator. 52\nAmbitious low-carbon pathways can lead to very low utilisation factors of dispatchable generation, including that with CCS, which could undermine the economic viability of this innovative, disruptive technology.\nA future system operator (in 2050 or beyond) will need to bear in mind a number of factors in order to secure grid-balancing 27 : the size of the interconnector compared to the peak surplus power requirements; the economic value of exported electricity (which may be quite low) compared to the value of fuel saved by using more resistive heating; and the necessity of maintaining a stable electricity grid (in the frequency and voltage domains) in the absence of conventional, thermal electricity generators.\nIn the absence of very large-scale long-term energy storage, significant curtailment of renewables and additional consumption of fossil fuel may arise at times.\nThe role and value of demand side response\nDemand response is a key option for supply-demand balancing 28 , 59 , 61 – 65 (see Figure 11 ), which offers benefits to all parts of the energy system that have been estimated to amount to some £4 bn per year. Electrification of heating and transport services may provide new opportunities for DSR. For example, research into social practices and service expectations combined with technical modelling (see the subsequent section) indicate that, if householders would tolerate a drop in indoor temperature of 1 ℃ for up to ten days a year, between 3 and 9 GW of peak supply capacity could be avoided. The key aim of DSR is therefore to explore the technical performance of various demand response concepts via time-step modelling techniques, but recognising the critical sensitivity to input assumptions regarding the level of expectations of the users. In order to model the potential demand response characteristics of individual load types, data was initially collected on multiple building loads for incorporation into the HESA/UK+ model combination. The data were then exchanged with the Demand and FESA models. An integrated scheduling algorithm was devised as an extension and redevelopment of the FESA model 26 – 28 (see again Figure 8 ) to allow demand response to compete on a level field against storage and controllable generation. The main calculations were translated into the VBA (i.e. visual basic for applications) code for greater visibility and future flexibility. It has been recognised that changes in the supplier/consumer relationship and in service expectations of consumers will inevitably impact on energy demand out to 2050 and beyond. Consequently, it is important to at least qualitatively ‘model’ consumer practices (see again the subsequent section) and to explore the relationships among customers, suppliers and consumers/prosumers. (Energy prosumers (see Figure 12 ) are those that produce (via distributed energy resources (DERs)), consume, manage or trade energy according to their own requirements and aspirations.) Smart DSP 28 can help to meet the challenges of flexible demand. Thus, water heating has been found to be capable of time-shifting (see again Figure 11 ) by around 50% for up to 7 h, space heating by 100% for up to 1 h, and EVs and plug-in hybrid electric vehicles (PHEVs) charging by 100% for up to 7 h.\nDownload in PowerPoint\nFigure 12. Structural opportunities to control flexible demand, including an illustration of the roles of the transmission network operator (TNO), distribution network operator (DNO), and flexible prosumers.\nThe penetration of renewable generation, particularly onshore and offshore wind turbine arrays, in the UK energy mix may reach as much as 15% by 2020. By that time the number of EVs in use may have reached over one million. Thus, the UK power system will be affected by an increasing imbalance, due to this rise in electricity demand (from EVs) and uncontrolled supply (from wind). Smart EV charging strategies 61 can therefore help the power system cope with high penetrations of local renewable energy sources (RES). Huang and Infield 61 recognised that domestic vehicles are typically parked for around 95% of the time, and hence EVs can be utilised as a ready form of responsive demand. They adopted a Monte Carlo model together with state-of-charge (SOC) information, as part of a whole systems framework, in order to estimate EV charging profiles. Wind farm data was taken from operational sites in Scotland. It was found that the cost over several small EV charging events was essentially free, provided that the surplus wind was greater than 1 MW. Likewise, the impact of the widespread adoption of high-performance heat pumps, alongside the large-scale penetration of wind generators, was recently studied by Cooper et al. 62 They devised a model using dynamic simulations of individual (air-sourced) heat pumps and dwellings, which indicated that increases in peak net-demand is highly sensitive to assumptions regarding the heat pumps themselves, their installation, building fabric (i.e. thermal insulation) performance and grid characteristics. If 80% of dwellings in the United Kingdom were to adopt such heat pumps, for example, then peak net-demand could rise by around 100% (54 GW), although this increase could fall to just 30% (16 GW) under favourable conditions. 62 Smart DSP could reduce this further to 20%, or even 15% with extensive use of thermal storage (as depicted in Figure 11 ). In contrast, should 60% of dwellings take up heat pumps, then the rise in peak net-demand could be as low as 5.5 GW, and consequently the electrification of heating would be more manageable for the network. 62\nAnother study by Teng et al. 63 examined the demand for ancillary services under a future GB electricity system as a result of the high penetration of wind generators with limited inertia capability. Under these circumstances, the network may be required to deal with sudden frequency drops following a loss of generator. An advanced stochastic generation scheduling model was employed to quantify the frequency response requirements and the contribution that could be made by DSR. 63 It suggested that the provision of frequency response from DSR could greatly reduce the system operation cost and wind curtailment. These DSR benefits were found to have significant diurnal and seasonal variation, whereas an even more rapid (near-instant) delivery of frequency response from DSR could yield substantial additional value. Competing technologies to DSR that can provide frequency regulation, such as battery storage 41 or more flexible conventional generation could potentially reduce its value by between 15% and 35%. 63 This would still leave significant room to deploy DSR as a cost-efficient frequency response provider within a future low-carbon electricity system.\nIt is critical to reflect how investors will take decisions to invest in (or to retire) generation plant within a market and policy context. Accounting for the incentives provided to companies through the trading arrangements is hence fundamental for modelling how investors take decisions going forward. As well as power market revenues, renewable and low-carbon generators are also reliant on subsidies to ensure their profitability, which is important for the investment decision-making process. Investors will form ‘rational expectations’ regarding the future when making investment decisions, taking into account power market conditions (e.g. electricity prices, demand growth, demand flexibility, changes in trading and regulatory arrangements, etc.) over the life of the asset based on all the information available to them at the time. Quantitative modelling studies have therefore been conducted in order to evaluate the competitiveness of demand response against other technologies, using a range of GB network case studies related to the transition pathways. A holistic approach (via the whole-electricity system investment model (WeSIM) 64 ; a successor to the HAPSO model 55 ) has been employed to assess the benefits of demand responses on power generation, transmission and distribution systems under each of the three pathways scenarios (see Figure 13 ). WeSIM, employed by Pudjianto et al., 64 is an enhanced model with respect to the modelling of demand and has more functionalities. It was used to provide useful insights on the characteristics of different pathways in terms of the expected increase in future peak demand, driven primarily by electrification of heating and transport sectors, 61 , 62 as well as the consequences for future power system infrastructure requirements. This approach 64 simultaneously optimised investment into new generation, network and storage capacity, while minimising system operation cost, and also considering reserve and security requirements. The analysis distinguished between bulk and distributed storage applications, while also considering the competition against other technologies, such as flexible generation, interconnection and DSR 64 (see again Figure 13 ). The results demonstrated that the DSR savings are potentially significant and that the MR pathway, for example, could save up to £90 bn of investment by 2050. A key issue arising from these studies is that the postulated generation capacity under the pathways may not be sufficient to meet security standards. This highlights the importance of considering the security of supply aspect in the development of future generation portfolios. Analysis of the electricity price characteristics of the three pathways showed that some generators with relatively very low load factors bring into question the feasibility of generation in an energy-only market. There are significant multi-stream savings that arise from DSR (multiple applications, including energy arbitrage, system balancing and capacity) across all pathways (amounting to some £4 bn/year by 2050). The benefits of whole-system based DSR applications are higher than those of the (non-coordinated) transmission network operator (TNO) or distribution network operator (DNO)-centric DSR applications: see again Figure 12 . This highlights the need for such whole system control co-ordination between the TNO and DNO in order to improve the interaction with DSR control.\nDownload in PowerPoint\nFigure 13. Annual versus peak electricity demand under the three UK transition pathways. Note: Estimated via WeSIM 64 ; a successor to the HAPSO model. 55\nEnergy storage (ES) represents one of the key enabling technologies to facilitate an efficient system integration of intermittent RES in conjunction with the electrification of heating and transport demand (see Figure 11 ). A stochastic optimisation method was used to quantify the benefit of distributed energy storage from the owner perspective. 65 A large set of case studies were carried out 65 in order to quantify the commercial and emissions benefits of ES in respect to energy and ancillary service markets, the revenue obtained from feed-in tariffs (FiTs), and the consequent reduction in operational CO2 emissions. ES was found to be able to provide opportunities for temporal arbitrage, because of the volatility of day-ahead and real-time (balancing) energy prices with a value of between £100/kWh and £650/kWh. 65 Its value in terms of anciliary services, such as frequency response, was estimated to be up to about £200/kWh on top of the basic value of ES. The value of ES for FiT revenue maximisation was found to decrease with increasing capacity from £108/kWh to £38/kWh. 65 When ES is charged during low-emission periods and discharged in high-emission ones, then the carbon footprint falls by around 10% even with losses taken into account. Teng et al. 65 observed that current and near-term batteries did not appear to be cost-effective for power generation applications. Thus, they noted that LIBs were most effective (∼£480/kWh) for kW/kWh applications with reasonable charge/discharge cycle lives. 41 (The cost of LIBs are today about ∼£140/kWh (similar to the price in 2012 noted by Hammond and Hazeldine 40 of ∼£135/kWh) having fallen from >£1675/kWh in 1990.) This contrasts with sodium-nickel chloride devices (so-called ZEBRA 41 , 65 batteries) at ∼£329/kWh. Teng et al. 65 expect the costs of lithium ion batteries to halve by 2020, although they expect those for the ZEBRA battery technologies to remain largely unchanged.\nThe technical performance and social acceptability of a range of proposed DSR concepts has been examined via an integrated approach in order to quantify the changes in electricity load profiles of the type represented in Figure 11 . The benefits of DSR options to the various classes of consumers were quantified for a range of scenarios appropriate to the different transition pathways. McKenna and Thomson 66 examined, for example, the way in which domestic consumers with rooftop solar PV arrays could benefit financially from time-shifting. They used an internet discussion forum to determine whether consumers with such PV systems engage in DSR activities so that they benefit further from free, self-produced electricity. Washing machines, dishwashers and electric space and water heaters were the most commonly employed appliances to shift demand. 66 The results suggest that, while price is an effective driver of DSR, there are other factors that generate demand response of the sort depicted in Figure 11 . They indicate that consumers with PV are often willing to be more flexible than is commonly assumed. This behavioural response could possibly be used in future to devise innovative tariffs that might stimulate demand shifting. 68 These value assessments are important elements in assessing the take-up, scale and effectiveness of DSR that can be expected.\nThese and other findings have benefited from a whole systems and collaborative working approach for elaborating and examining the transition pathways for realising a low carbon, secure and affordable UK energy system by 2050. Thus, the insights and lessons learned from studying the role and value of DSR were:\nDemand side participation (DSP) concepts are mainly short term (minutes to hours), whereas flexibility is needed over several days or more. The rigid patterns of modern living and consumer expectations based on life-long experience of fossil-fuelled supplies make such flexibility challenging, but are important to explore. Fully automated DSR concepts, such as ‘smart’ controllers for EV charging and heat-pumps, have been studied in some detail.\nBattery energy storage and controlled EV charging helps cut peak demands, but typically provides only a few hours of storage, doing little to address longer term weather-related variations. A Monte Carlo model of EV movements and home based charging 61 has been used to analyse the impact on a typical low voltage distribution network with typical household loads, suggests voltage impacts to be the most critical: voltages could easily become unacceptable without demand side management. The extension of EV charging to allow workplace charging seems to relieve the distribution network loads and help avoid voltages outside the statutory range.\nDecarbonised electrification of heating could make a useful contribution to the reduction in UK CO2 emissions, but may cause a challenging increase in peak power demand, net of non-dispatchable generation. This can be reduced, although not entirely eliminated by thermal energy storage and DSP. In addition, it has been shown 62 that high-performance (air-sourced) heat pumps, with appropriate installation and better insulated buildings, could make the rise in peak net-demand far more manageable.\nAn integrated market model (developed in WeSIM 64 ) has been used to analyse the evolution in electricity prices in different system backgrounds with different DSR technologies, network development, carbon prices and energy policies (related to market integration with the EU). When viewed in the context of a high share of renewable generation (such as under the TF pathway), the magnitude and volatility of electricity prices tend to increase, particularly driven by higher carbon prices and greater variable generation. The price differential between exporting and importing regions also widens from increased congestion in the national/cross-border transmission system.\nThere are significant multi-stream savings from DSR (via multiple applications, including energy arbitrage, system balancing, capacity) across all pathways; amounting to £4bn/year by 2050. These benefits of whole-system based DSR applications are higher than those of (non-coordinated) transmission system operator (TSO) or distribution system operator (DSO)-centric DSR applications. This highlights the importance of whole system control co-ordination.\nThe transition pathways have been costed under very different governance and institutional arrangements. Economic feasibility of generation in all three pathways will depend on the revenue from secondary markets/sources, such as capacity (ancillary service) market, FiT, tax incentives, etc., although the ratio of the revenue needed from primary and secondary markets is case specific.\nAttending to the social dimensions of realising transition pathways\nSection:\nThere is growing awareness that meeting the challenges of a low-carbon transition will require socio-technical solutions, and that consequently the social sciences have a key role to play in devising them, including working with engineers and physical scientists in an interdisciplinary manner. 66 – 68 A team of social scientists worked work interactively in collaboration with engineers in the present consortium to enhance consideration of the social dimensions of the project. This included work to open up assumptions about actor dynamics and social change as well as roles of the public and civil society in realising the UK transitions pathways. 66 – 68\nBuilding on the concept of the action-space devised in the first phase of the Transition Pathways project 8 , 24 , 30 (see section ‘Insights from historical transitions’ above), a relational co-productionist approach grounded in ideas form science and technology studies (STS) was developed to map relations between social actors across the UK electricity system and the spaces through which they participate in energy system change was developed to described the way in which different patterns of interaction between market, government and civil society actors lead to particular modes and logics of governance. 8 , 24 , 30 An important means of mapping actors and action spaces was through a systematic qualitative analysis of twelve contrasting visions of the low-carbon transition. This analysis showed that while some visions assume a technologically focused transition driven by the energy trilemma and centred on economic growth, alternative visions (particularly those from of civil society actors) place more emphasis on social and cultural change, issues of equity and fairness, and do not assume or depend on existing models of economic growth. Chilvers and Longhurst 67 studied four diverse sites of civil society engagement in low carbon transitions: the DECC Energy 2050 Public Dialogue (DECC 2050), the Camp for Climate Action (CCA; direct action events at various coal-fired power stations over 2006–2011), the Visible Energy Trial 8 , 33 (VET) and the Dyfi Solar Club (DSC; a community energy initiative in Machynlleth, Powys, Wales). They revealed that powerful forms of enrolment, exclusion and the partiality of visions and actions are common to all form of participation in transitions. Such analyses play a valuable role in transition pathways analyses through revealing social dimensions and informing how modelling studies frame the energy problem, bound the study system, and communicate uncertainties. It helped the wider consortium and technical analysts realise that that transitions are never smooth and will always be subject to contestation, negotiation and social change.\nThe other way in which social dimensions of energy transitions were attended to during the second phase of the realising transitions pathways project was through taking forward novel interdisciplinary (ID) experiments to co-produce social science and engineering insights on energy demand response in real time. These studies included a meta-review of social science evidence, leading into the design of small-scale integration experiments. The first of the ID experiments was a Service expectation experiment (see Figure 14 , and the summary in Table 3 ) in which the social science input into existing models was evaluated in order to improve model assumptions about how indoor comfort expectations could change over time. Such service expectations are often held to be stable, but social science literature suggests they vary in different ways. A range of service expectation scenarios were studied based on the outcomes from the review (such as more demanding standards, wider comfort zone and local diversity). The FESA model 26 – 28 ( Figure 8 ) was employed in order to examine various behavioural scenarios with variable service expectations. The work indicated that if householders (consumers or flexible prosumers; see Figure 12 ) were tolerant of a small internal temperature change either side of their desired set-point, and even allowing these for just a few hours per year this could yield large reductions in peak demands (a few GW): see again Figure 11 . This opened up the prospect of new behavioural scenarios for models, new parameters and boundaries. The term framing, used in Table 3 , implies the inevitable process of selective influence over the perception of an individual (involved in the experiment) in such a way as to encourage particular (potentially biased) interpretations and to discourage others. This experiment suggested that new levels of detail are required in existing FESA-like models (e.g. around heating/cooling technologies, housing stock, etc.). 26 – 28\nView larger version\nThe second strain of social science-led, ID experiment (by Higginson et al. 68 ), termed Modelling practices experiment (and again summarised in Table 3 ), was designed to develop new approaches to modelling based on social science understandings of, and data about, social practices. It encouraged the social scientists to communicate their ideas more clearly, whilst allowing engineers to think critically about the embedded assumptions in their models in relation to society and social change. Social practice theory together with network analysis 68 was adopted to provide a network diagram to visualise different practices. ID participants then collaboratively generate mappings of ecologies of practices: see Figure 15 that illustrates various social activities and practices in the home. The elements of practices – represented by circles – are distinguished in terms of images, skills (e.g. washing) and stuff (e.g. dirty clothes). Thus, washing clothes as an energy service is not merely determined by the washing machine, tumble drier and iron, but depends on much else. These other social factors include the meaning of clean, the way the different schedules in the household come together, the organisation of laundry and the way it is done in the household, and so on, i.e. the images and skills that are part of the practice of laundry. Graphs of practice networks such as this can be populated with empirical survey data. Higginson et al. 68 recently used this approach to examine from a survey of different types (or variants) of laundry practice. They gleaned insights into energy intensity, flexibility and the rootedness of practices, i.e. the extent to which they were entrenched or established. It was argued that this permitted the social practices to be represented graphically using a quantitative format ( Figure 15 ) without being overly reductive. This modelling practices experiment opened up new socio-technical discussions about core/periphery elements, variants of practice and so on, but also closes down discussion about the situatedness of practices (see Table 3 ).\nDownload in PowerPoint\nFigure 15. A simplified network representation linking social activities and practices in the home: identifying ‘hubs’, ‘anchors’ and ‘clusters’.\nThrough these ID experiments engineers had become more aware and reflective of the tacit social assumptions and limitation of their models, while social scientists became more aware of the complexity of energy models and the difficulty of making even small changes to their inbuilt assumptions. Importantly, these collaborations produced new findings and insights only possible through interdisciplinary working. Bringing together practice theory with network analysis extended and scaled up understandings of energy-related practices, generating new insights on the constraints and potentials for modelling flexibility and energy demand response. In the service expectation experiment, integrating social science insights into the FESA model showed how even small changes in thermal comfort expectations can lead to significant savings in terms of energy demand, which could prove crucial in realising low carbon transitions.\nKey challenges, insights and opportunities identified in these studies attending to the social dimensions of energy transition pathways include:\nNew evidence that quantitative energy modelling approaches routinely neglect important social aspects of energy transitions and how society will influence future pathways, including changes in how energy problems are framed, service expectations of users, the roles of public engagement and institutional changes.\nSocial science analyses can provide important new evidence about the relations between actors and forms of participation in energy transitions, which is important evidence in its own right and in sensitising models to alternative framings, social futures and uncertainites inherent to scenarios and model projections.\nIf interdisciplinary collaboration is well designed, open, collaborative and based on trust it is possible to integrate engineering and social science expertise, which produces new insights beyond what is possible with single-discipline approaches – for example, showing prospects for energy demand flexibility and responsiveness greater than previously estimated.\nThere is no single best practice approach to interdisciplinary energy research. An effective approach is to develop forms of integration between social science and engineering modeling approaches that are appropriate, diverse and can be evaluated and learned from over time.\nInvolving social scientists in real-time interdisciplinary collaboration with physical scientists can hold the key to producing whole systems energy models that are more responsible, anticipatory and accountable to the social implications and effects of energy transition pathways.\nDistributed energy\nSection:\nThe TF pathway explores a low-carbon transition led by civil society, which focuses on decentralised or distributed solutions to energy problems. Currently, less than 1% of UK electricity demand is met by community- or local authority-owned distributed electricity generation. A major driver for the TF pathway is seen to be a step change in the role of the civic energy sector (communities, co-operatives, local authorities, town and parish councils, social housing providers) through participation in, and ownership of, electricity generation schemes. ESCos are presumed to emerge, with incentives aligned with energy efficiency improvements. Because this pathway deviates most from the current energy market, and has no recent precedent, it has interested bodies including the public-private ETI (e.g. their Patchwork scenario) and the UK energy market regulator (Ofgem). The consortium postgraduate researchers (the Engine Room (see section ‘From narrative descriptions of the transition pathways to model formulation’ above); again working independently of the consortium leadership – the academic co-investigators) were asked to evaluate the implications of this novel pathway, and they produced a Distributing Power report. 69 With strong demand reduction and management, 50% of 2050 final electricity usage could be met via distributed generation with emerging technologies, new infrastructures (including interconnections), and new institutions. Although challenging to the current power system operational norms, a transition to 50% distributed generation by 2050 was found to be technologically feasible. However, it would require the installation and full utilisation of smart grid technology, alongside DSP, demand management, and other techniques and technologies. A more distributed system would clearly need regional energy strategies and local capacity building for city regions, municipalities, communities and citizens. A distributed energy system opens up new avenues for energy transition finance, while challenging incumbent utility business models. (The integrated market simulation model (WeSIM 64 ), described in section ‘Hourly demand profile modelling’ above, can be used to optimise real-time dispatch in a chronological fashion, as well as reflecting entry and exit decisions by investors, using an iterative process.) The model for investment in conventional and renewable generation was used to calculate the electricity prices (including energy and scarcity prices that reflect the scarcity in generation capacity during peak demand), generation and transmission revenues. It highlighted the finding that electricity prices are expected to be more volatile in the future and that the impact of demand response on average electricity price is modest but it reduces significantly the volatility.\nThe Distributing Power report 69 draws on empirical research, engagement with a wide range of stakeholders from the energy sector, and from experience in Germany, Denmark and in the United Kingdom. It offers insights into the barriers and the technological transformation that might be required for a move to a highly distributed energy future. This decentralised generation would be required to satisfy the TF pathway with an increase in regional, national and international interconnection in order to ensure electricity imports from neighbouring countries. 69 Much of the energy value that currently leaks out of the UK economy could then be captured at the local level. Such distributed energy systems have often been equated with increased energy independence. But significant reduction in electricity demand would be necessary, including improved energy efficiency and conservation. Households, for example, would need to more than halve current levels of electricity consumption by 2050. 69 National energy planning with regional and local support for a civic energy sector would be needed. This implies a much greater role for national and local government. The traditional business models of the Big Six incumbent electricity suppliers would inevitably be challenged as they lose market share to local generation and supply businesses. New infrastructure, like smart grids and emerging decentralised technologies (such as in-home fuel cells), would be necessary; requiring a large-scale expansion from 2020 onwards. The impact to consumer bills would only be marginally more expensive out to 2030, 69 although they could be significantly cheaper in the long term (to 2050) compared to the MR and CC pathways. While the Distributing Power report 69 assesses the impact of one distributed generation future, there are others which might see a greater role for solar, onshore wind, or other generation mixes.\nTraditionally, renewable electricity generation capacity in the United Kingdom has been built by large-scale commercial developers and/or utilities, whose finances are globally mobile. The Distributing Power report 69 suggests a possible alternative of a proliferation of distributed energy generators, which are owned fully or in part by municipalities, communities, or small-scale investors. (A companion piece to the Distributing Power report, 69 produced by Johnson and Hall, 70 has examined the distributional implications of the TF pathway.) Citizens would thereby gain more control over their energy use. Centralised generation would still be necessary for base-load and peaking capacity. However, for this to be viable in a distributed generation future, the government would need to provide the right incentives for new large-scale plant and infrastructure. The civic energy sector, defined as energy generation by communities, co-operatives, local authorities, town and parish councils or social housing providers, currently relies on motivated individuals and communities and often, voluntary work. The development of a decentralised future along the lines proposed for the TF pathway would require strong project management and professional expertise to deal with a range of technical, financial, legal and administrative issues. In order to move to a distributed approach, regional energy strategies and local capacity building would be essential to aggregate these local energy schemes into a coherent civic energy generation sector. 69 , 70 This would mean complementing national energy planning with regional and local support for a civic energy sector and implies a much greater role for both national and local government.\nThe launch of the Distributing Power report 69 in February 2015 informed the wider UK energy debate, and is leading to further work with key stakeholders, including an invited submission to the Ofgem non-traditional business models process. The headline messages were: 69\nAll UK energy projections, including a distributed energy future (such as that encapsulated in the TF pathway), require international interconnection. In addition, the TF pathway relies heavily on energy demand reduction, DSP and demand-side management. Households would need to more than halve their current levels of electricity consumption by 2050.\nA distributed energy system opens up new avenues for energy transition finance, while challenging incumbent utility business models. Around 50% of final electricity demand by 2050 could be met via distributed generation, but new infrastructures and emerging technologies would be required: from smart grids at a national level and to the likes of in-home fuel cells locally. A large-scale expansion would need to occur under the TF pathway from 2020 onwards. Thus, national energy planning with regional and local support for a civic energy sector would be needed.\nA high-level of distributed generation would require an increase in regional, national and international interconnection, such as electricity imports from neighbouring countries. Distributed energy systems have often been equated with increased energy independence. Much of the energy value that currently leaks out of the UK economy could be captured at the local level.\nThe traditional business models of the Big Six incumbent electricity suppliers would be challenged as they lose market share to local generation and supply businesses. In order to move towards a more distributed system, regional energy strategies and local capacity building would be essential for city regions, municipalities, communities and citizens.\nThe impact to consumer bills within a highly distributed power system (of the sort proposed for the TF pathway) would only be marginally more expensive in the medium term out to 2030, although it could be significantly cheaper over the long term to 2050 in comparison to those under the alternative MR and CC pathways.\nWhole systems energy and environmental appraisal of the different energy mixes\nSection:\nThe energy and environmental appraisal of the three transition pathways and associated power technologies have been evaluated within the context of a transparent sustainability appraisal framework, i.e. economic, social, environmental and technical benefits. 57 , 58 , 71 This process employed a toolkit of techniques to explore and evaluate the whole systems consequences of the selected transition pathways, such as the (embodied and process) energy and carbon implications of the pathways and technology mixes, their environmental burdens (as indicated by environmental LCA 57 , 58 , 72 – 75 ), and aggregate carbon and environmental footprints. A comprehensive review of the LCA of energy systems 57 included an overview of the historic development of LCA from the early 1990s, and its subsequent codification by the International Standards Organization (ISO). Environmental appraisal of energy systems needs to be conducted on a life-cycle basis, i.e. embracing the full range of extraction, production, distribution, and end-of-life processes or technologies. 57 , 58 , 72 – 75 In a full or detailed LCA, the energy and materials used and pollutants or wastes released into the environment as a consequence of an activity or service are quantified over the whole life-cycle; typically from cradle-to-gate. 57 Such studies are often geographically diverse; i.e. the energy and material inputs associated with the activity may be drawn from any continent or geo-political region of the world. They involve four main LCA stages that follow a logical sequence of goal definition and scoping, inventory analysis, impact assessment, and interpretation. The current strengths and weaknesses of LCA have been identified for the benefit of energy practitioners and policy analysts 57 (see Table 4 ). Comparisons were made with related approaches, such as carbon and environmental footprinting. 71\nTable 4. An outline of the strengths and weaknesses of environmental LCA.\nTable 4. An outline of the strengths and weaknesses of environmental LCA.\nSource: Hammond et al. 57\nView larger version\nAn examination of the whole system environmental burdens of the present transition pathways (version 2.1) was undertaken by Hammond and O’Grady 58 (as an extension of the earlier LCA study by Hammond et al. 75 (of version 1.1 of the pathways)), whereby GHG emissions reflected the sum of both upstream and operational emissions. The latter (‘stack’) emissions are those directly associated with the combustion of fossil fuels within power stations. Thus, the whole system emissions amount to those related to the ‘cradle-to-gate’. The national electricity network (operated by TNOs and DNOs) represents the downstream boundary known as the gate (hence, cradle-to-gate 75 ). In the studies by Hammond et al. 75 and Hammond and O’Grady, 58 they highlighted the significance of upstream emissions and their (technological and policy) implications, in contrast to the emphasis on power plant operational emissions conventionally presented by other analysts. These upstream environmental impacts arise from the energy requirements for extraction, processing/refining, transport and fabrication, as well as methane leakages from coal mining activities – a major contribution – and natural gas pipelines. The total carbon dioxide equivalent (CO2e) emissions associated with various power generators and UK electricity transition pathways towards a low carbon future are depicted in Figure 16 . This illustrates the GHG trajectory under each of the three transition pathways out to 2050. It was also found that CO2e capture facilities coupled to fossil-fuelled plants deliver only a 70% reduction in GHG emissions (including both upstream and operational emissions), in contrast to the normal presumption of a 90% saving.\nFigure 16. ‘Whole systems’ (upstream plus operational (or ‘stack’)) GHG emissions under the three UK transition pathways (1990–2050).\nGHG: greenhouse gas.\nSource: Adapted from Hammond and O’Grady. 58\nThe transition pathways LCA study by Hammond et al. 75 yielded estimates of pollutants or wastes released into the environment as a consequence of the UK ESI in terms of 18 separate impact indicators (together with a tentative single score, aggregate LCA measure). The lower the resulting score for each category (or the single score indicator) the better, although they doesn’t adequately reflect, for example, the impacts associated with nuclear power generation. Nuclear is low carbon, but has a number of other health and environmental impacts associated with the potential release of ionising radiation from nuclear power stations and processing plants. These are generally not effectively accounted for in LCA software tools, 75 because they do not have an underlying basis in ecotoxicology. Statistical weighting of the different LCA categories is normally achieved by the engagement of a panel of experts. It is therefore highly subjective, and this process would not be advisable in many cases. Clearly, it is difficult to manage something like 18 different impact categories, and consequently it is necessary to focus on key categories. Large impacts were found in terms of categories such as Human Toxicity, Freshwater Eutrophication, Marine Ecotoxicity and Natural Land Transformation 75 particularly under the MR pathway. Carbon emissions are the currency of debate in a climate-constrained world, 4 , 58 and consequently GHG emissions are typically given greater emphasis. There is likely to be a significant fall in carbon emissions from the UK power generation sector (see Figure 16 ) of some 31–51% by 2020, 65–86% by 2030 and 78–93% in 2050. 58 The lower figures relate to the MR pathway, whilst the higher ones are associated with the TF pathway. Notwithstanding the emphasis on GHG emissions, some of the other environmental burdens may need to be monitored.\nThe British Government’s independent Committee on Climate Change (CCC) has advocated deep cuts in power sector operational emissions through the 2020s, 46 with UK electricity generation being largely decarbonised by 2030–2040. In contrast, the present transition pathways projections (see again Figure 16 ) 58 indicate that the UK ESI could not be fully decarbonised by 2050 on the whole systems basis employed in the process-LCA studies. 58 , 75 This is because the present estimates take account of upstream, fugitive GHG emissions, whereas the projections by bodies like the CCC and Department of Energy and Climate Change (DECC) generally do not. Nevertheless, the transition pathways suggest that the ESI will be able to bear a significant share of the overall 80% carbon reduction target by 2050. The CCC analysis indicates that average operational emissions from the power generation sector would fall to around 50 gCO2/kWhe by 2030. 46 In contrast, the present MR pathway ( Figure 16 ) indicates that whole system emissions from the UK ESI are likely to only fall, accounting for upstream emissions, to ∼202 gCO2e/kWhe by 2030 and ∼105 gCO2e/kWhe by 2050. 58 The least impactful pathway (TF) suggests 58 that GHG emissions will fall to only ∼108 gCO2e/kWhe by 2030 and ∼53 gCO2e/kWhe by 2050 ( Figure 16 ). If the United Kingdom is to genuinely meet its legally-binding carbon reduction targets, then it will be necessary to account for upstream emissions from power generation. 58 , 75 Otherwise, even if the current UK carbon reduction targets are met, there will remain further emissions upstream.\nAn alternative way of evaluating the environmental impacts of the three UK transition pathways is via carbon and environmental footprinting. 4 , 71 Environmental or ecological footprints have been widely used in recent years as indicators of resource consumption and waste absorption associated transformed on the basis of biologically productive land area (in global hectares (gha)) required per functional unit (such as kWhe). They represent a partial measure of the extent to which an activity is sustainable. 4 , 71 In contrast, carbon footprints are the amount of carbon (or carbon dioxide equivalent) emissions associated with such activities in units of mass or weight (like kilograms per functional unit), although they can be translated into a component of the environmental footprint (on a gha basis). In order to determine the footprints associated with three UK transition pathways, the overall environmental footprint has been disaggregated into various components 71 : bioproductive and built land, carbon emissions, embodied energy, materials and waste, transport, and water consumption (see Figure 17 ). The total environmental footprint in the baseline year of 2010 was found from historic data to be 43 Mgha. In this case, the carbon and embodied energy footprint components were responsible for 80% to the total environmental footprint.\nFigure 17. Environmental footprints of the three UK transition pathways in 2050.\nSource: Adapted from Hammond. 71\nFuture environmental footprints were estimated for each of the three transition pathways. 4 , 71 Electricity demand was projected to decrease significantly under the TF pathway by 2050, but its total environmental footprint was nevertheless greater than either that under the MR or CC pathways (see again Figure 17 ). This is mainly due to the increase in the contribution of the bioproductive and built land component and that of the carbon footprint (rising to 10.9 and 12.5 Mgha respectively by 2050), 71 which are both seen to be higher than in either of the MR and CC cases. Thus increase in these TF pathway components was mainly due to increased usage of solid biofuels for power generation. In order to reduce the overall TF footprint it would therefore be necessary to adopt other renewable power technologies, like offshore wind and solar PV arrays, to satisfy the increase demands caused by electrification of heat and transport. The MR and CC pathways gave rise (see again Figure 17 ) to footprints of 23 and 25 Mgha respectively in 2050, as compared to 43 Mgha in the 2010 base year. 71 Here, the embodied energy component was the largest amongst the various footprint components; rising to 14 and 13 Mgha respectively by 2050. This was due to the large-scale use of fossil-fuelled power plants. There is a large reduction in carbon emissions under the MR pathway (over an 86% reduction compared to 2010 levels), whilst the CC pathway exhibits a slightly smaller fall (albeit nearly an 80% reduction). On the other hand, the TF pathway displays only 42% reduction in carbon emissions by 2050 ( Figure 17 ). Water and waste footprint components made almost negligible contributions under all three transition pathways (only ∼1% footprint share), although this was recognised as probably being an artefact of the footprint methodology and assumptions adopted. 71 Bioenergy and biofuel footprints and land-take (see again Table 2 ) reflect relatively large environmental burdens when compared to other fuels.\nThe carbon and environmental burdens associated with the three UK transition pathways have been assessed via environmental LCA and footprinting methods. Overall insights and lessons from such studies can be summarised as:\nA critical state-of-the-art review of this environmental LCA methodology57 has identified its current strengths and weaknesses for energy practitioners and policy analysts.\nThe extraction and delivery of fuel requires energy and creates GHG emissions. The upstream emissions associated with various power generators and UK electricity transition pathways have been evaluated on a whole systems basis. There will remain further emissions upstream that are unaccounted for by the CCC and DECC. They only account for upstream fugitive GHG emissions beyond UK borders.58,75\nThe carbon and environmental footprints of the three UK transition pathways have also been evaluated.71 The overall environmental footprints were disaggregated into: built land, carbon emissions, embodied energy, materials and waste, transport, and water consumption. This component-based approach has enabled the sustainability challenges to be assessed quite broadly, along with specific issues (e.g. the linkages associated with the so-called energy-land-water nexus).\nEconomic analysis and appraisal\nSection:\nAny transition pathway in the UK energy system will require very large expenditures in the capital intensive energy sector. The costs and potential benefits of such investments, as well as how these investments position key market participants in relation to a range of economic risks, are a critical element to the economic appraisal of such pathways. Economic considerations are the core consideration of market-led actors, while the government – in its social planning role – has a wider consideration of costs under a multi-criteria approach, but one in which a socially optimal transition pathway would reduce costs as far as possible. Many analysis frameworks of possible future energy transitions conduct only a post-calculation of costs (e.g. via the DECC 2050 Calculator or analysis by the UK energy market regulator (Ofgem)), whereas costs are a critical input into the formulation and decision making process in any transition pathway.\nMany existing energy modelling studies have been criticised for their limited treatment of societal actors and associated socio-political dynamics, together with poor representation of the co-evolving nature of society and technology. 76 It has therefore been argued that they consequently find it demanding to analyse socio-technical change. In parallel, it is evident that some of the prominent conceptual frameworks of socio-technical energy transitions (STET) find it difficult to operationalise policy development requirements in quantitative energy analyses. A review and critique of quantitative models for exploring STET was therefore undertaken by Li et al., 76 alongside their application to the energy supply, buildings and transport sectors. They subsequently devised a novel taxonomy for describing STET models 76 for integrating both quantitative modelling and conceptual socio-technical transitions, which incorporated techno-economic detail, explicit actor heterogeneity, and transition pathway dynamics. This study also highlighted a number of the challenges associated with their theoretical and behavioural validation, and proposed future development priorities for STET models. 76\nA stylised probabilistic energy system model (BLUE-MLP) has been constructed with key behavioural parameters on price and non-price drivers. The model has been extended to incorporate alternative actors, spatial and temporal detail. The initial version of the BLUE model was critically reviewed and validated by embedding it in the multi-model comparison exercise (see section ‘From narrative descriptions of the transition pathways to model formulation’ above, and Trutnevyte et al. 55 ). In addition, a literature overview for understanding the state-of-the-art research in behaviour and transition modelling was carried out. Participation in the qualitative-quantitative knowledge integration for demand response (see the above section) helped to collect further ideas on developing BLUE. The initial Excel economic appraisal of the transition pathways covers electricity generation, transmission and distribution. It takes account of the temporal and market participant elements. 77 The Excel economic appraisal (EconA) was embedded in the afore-mentioned multi-model comparison activity (see again section ‘From narrative descriptions of the transition pathways to model formulation’ above 55 ) in order to validate its findings against other realising transition pathway models. The implications of the multi-model comparison activity for the EconA and D-EXPANSE model were summarised by Trutnevyte et al. 55 (see both the sections ‘From narrative descriptions of the transition pathways to model formulation’ and ‘Annual demand modelling’ above). The D-EXPANSE model was used to model the UK power sector transition between 1990 and 2010, in order to get insights about the structural uncertainty of cost optimisation, and to systematically translate the transition pathways narratives into quantitative representations.\nClearly the costs and affordability of energy transitions are one of the most influential drivers in terms of the energy policy trilemma. But so also are the interactions between the power sector and other key economic sectors that drive decarbonisation in line with climate targets. A collaborative study between energy-economic modellers and power systems engineers from the Realising Transition Pathways Consortium therefore undertook a cost appraisal of the UK transition to a low-carbon electricity system under alternate governance logics. 77 This novel approach linked the quantitative electricity system transition pathways and their economic appraisal. Retirement of existing power plant capacity and the installation of new build was based on either DECC planned retirements 77 or estimated lifetimes. Costs of the transmission and distribution network infrastructures (see Figure 12 ) were modelled via the WeSIM 64 model – a successor to the HAPSO model 55 , 77 (see both the sections ‘From narrative descriptions of the transition pathways to model formulation’ and ‘Hourly demand profile modelling’ above). Outside the power system, only the costs of heat-producing devices (such as resistive heaters and gas boilers, community-scale and micro-CHP, and heat pumps) were included in the analysis. It focused on monetary costs and did not account for externalities, associated with the costs of different impacts on the environment 77 (like those considered within an LCA study, such as that described in the above section). The results (see Figure 18 ) contrast the dominant market-led MR transition pathway with alternate pathways that have either stronger governmental control elements (CC pathway), or bottom-up proactive engagement of civil society (TF pathway). The MR pathway exhibited the lowest investment costs out to 2050, whereas the CC pathway had slightly higher total system costs; presuming its implied government policies could be enacted and maintained. The bottom-up, more decentralised (TF) pathway was found to come at the expense of higher investment costs, 77 although it encourages wider participation with civil society. It requires significantly higher investment in renewable electricity generation, electric heating, and particularly EV transport. The spatial distribution of investment requirements under each UK pathway was another issue explored by the partnership of energy-economic modellers and power systems engineers (see Figure 9 ) (and section ‘From narrative descriptions of the transition pathways to model formulation’ above).\nDownload in PowerPoint\nFigure 18. Relative capital investment costs for the three UK transition pathways out to 2050. Source: Updated estimates based on Trutnevyte et al. 77\nEconomic appraisal of the three UK transition pathways 55 , 76 , 77 contributes to an understanding the future interplay of the energy policy trilemma, i.e. achieving deep GHG emission cuts, whilst maintaining a secure and affordable energy system. The insights and lessons from these studies can be summarised as:\nInvestment costing of the three UK transition pathways under very different governance and institutional arrangements was achieved via a novel collaborative study between energy-economic modellers and power systems engineers. 77 It showed that the TF pathway gave rise to the highest investment costs, due to the need for large-scale renewables (such as wind farms), electric heating, and principally EVs and their transport/charging infrastructure.\nFrom this novel STET taxonomy for integrating both quantitative modelling and conceptual socio-technical transitions, 76 methodological improvements in economic analysis of transition pathways were identified as being as important as the analytical insights from any given modelling comparison. For example, firstly understanding the spatial and temporal boundaries of any cost calculation, and secondly assessing if demand reductions are induced by policy instruments (a welfare loss) or attributed to lifestyle evolutions (no welfare loss) are fundamental challenges.\nStimulating investment in low-carbon options\nSection:\nAnalysis of historical energy transitions 30 – 32 (see section ‘Insights from historical transitions’ above) demonstrates that rapid change is possible, but not frequent, and requires a high degree of co-ordination of actions, driven by recognised need to change, e.g. the shift from Town Gas to natural gas. Potential low-carbon investors in the United Kingdom are faced with uncertainty about national policy priorities, and there are structural constraints on low-carbon investment, including immaturity of the sector and mismatches between fund manager and renewable energy investment timescales. 80 The economic feasibility of generation under all three transition pathways will depend on revenues from secondary markets/sources (e.g. the capacity market, FiT and various tax incentives). However, the ratio of the revenue needed from primary and secondary markets is case specific. Comparison with the situation in Germany demonstrates the valuable role that can be played by locally focused institutions, where civic ownership is supported by a local banking sector. 83\nA review of socio-technical systems research by Bolton and Foxon 78 argued that this approach can be operationalised to assess policy and societal challenges of large-scale investments in the low-carbon infrastructure. They observed that the United Kingdom is moving into a new phase of energy governance with significant demand for new investment to meet long-term climate policy objectives, as well as shorter term energy security challenges. The UK Government’s recent EMR aims to promote investment in large-scale low carbon technologies, through incentive schemes such as the contract for difference (CfD) and FiTs. They provide a guaranteed price for low carbon generation and thereby remove one significant uncertainty, although policy and political risks still remain. In further research, Bolton et al. 79 interviewed a range of energy policy and industry stakeholders, revealing different views on governance of energy systems. Those in favour of a liberalised market approach thought that the government should just set the rules, but otherwise not interfere to address price and other risks. In contrast, the mainstream investment community continues to be concerned that other risks could prevent large-scale investment in low-carbon generation. The Levy Control Framework, which was put in place out to 2020 with no clarity as to if it will be extended beyond that, has created an additional policy uncertainty for investors. Capacity markets have been introduced in order to ensure security of energy supply, indicating that this has greater priority than meeting carbon budgets (as reflected in recent UK Government energy policy pronouncements). This again creates uncertainty for investors, as experience indicates that regulatory frameworks and incentives are liable to change over time. In order to bring in new actors, such as mainstream institutional investors, better understanding of how they perceive these risks and uncertainties is required.\nA socio-technical approach has been employed 78 to this important area of policy debate in three specific areas: understanding long-term uncertainty and investment risks; avoiding technological lock-in; and accelerating the diffusion of low carbon finance niches. It explored the dynamics of long-term structural change in capital intensive systems (such as energy, housing and water supply with the aim of seeking to redirect them towards more sustainable long-term trajectories. Bolton and Foxon 78 argue that interventions need to balance the demands of private investors with wider social objectives. A better understanding of investment risk and uncertainty is required. Insights from the MLP of transitions theory suggest that it is necessary to avoid lock-in to current technologies, and the need to support low carbon finance niches.\nIn a follow-up study, Bolton et al. 79 examined the way in which actors in the UK electricity sector are attempting to deliver investment in low-carbon technologies. Such generation capacity is relatively immature and is capital intensive, although they have low operational costs. Empirical research 79 investigating the agency of incumbent regime actors in the face of uncertainty was based on interviews with 36 stakeholders from private and civic energy companies, mainstream and alternative investors, renewables project developers, energy policy makers and civil society. It was found that low-carbon generation does not readily fit into existing electricity markets and investment templates that were designed for a fossil fuel based energy system. The findings of Bolton et al. 79 can inform contemporary debates on the politics and governance of sustainability transitions and offers critical insights on the role of markets and finance in shaping socio-technical change. Key electricity market and infrastructure policies in the United Kingdom were analysed 79 in order to determine ways that low carbon technologies could be made investable. This research argued that this could be achieved by reducing uncertainty, better management of investment risks, and repositioning actors within the electricity socio-technical regime.\nThe role of financial markets in capitalising low-carbon energy systems and long-term change has been explored. 80 Capital requirements for energy system transitions are typically very large, and yet the literature has been curiously quiet on the role of capital markets in financing energy transitions. Stakeholder interviews identified that there are relatively few deals, whilst learning and adaptation are slow. Economic incentives, such as the CfD and FiT strike prices, or renewable obligation certificates (ROCs), are only one type of driver for change. This implies that providing stable incentives may not lead to market penetration of renewables investment. Hall et al. 80 have analysed the UK EMR process and the provision of renewable energy finance, and argued that an adaptive market hypothesis provides a useful framework for understanding the evolution of electricity markets in response to low carbon policy incentives. They demonstrated that the market for renewable energy finance does not conform to the standard efficient markets hypothesis, due to structural and behavioural constraints on investment. However, considering financial markets as being adaptive enables the range of policy responses for the acquisition of low-carbon investment to be much broader. 80\nPrimary data collection was undertaken by Hall and Foxon 81 to characterise the importance of a smart grid infrastructure within a UK energy transition. The UK economy and electricity system have co-evolved, but there remains a mismatch between the distribution of benefits and costs of investing in this infrastructure; leading to a problem of value capture and redeployment. Some benefits of smart grids are less easy to price directly, and are more accurately classified as public goods, such as energy security and decarbonisation. Hall and Foxon 81 drew on semi-structured interviews and focus groups involving UK smart grid stakeholders. This led them to identify municipal-scale developments as potential sources for new business models to deliver smart infrastructure. Municipalities may thus pursue specific economic opportunities with DNOs to make smart grid investments. This supports recent practical interest in an expanded role for municipalities as partners and investors in smart grid infrastructures.\nTransforming energy distribution networks will also play a key enabling role in a low-carbon energy transition in the energy, water and mobility sectors. But Bolton and Foxon 82 have argued that there is relatively little understanding of the social and institutional dimension of these systems, or appropriate institutional challenges to their transformation. This may be because the prevalent model of infrastructure governance in the energy and other sectors has prioritised short-term time horizons and static efficiencies. Bolton and Foxon 82 therefore discuss the appropriate governance strategies for developing flexible and sustainable systems of energy distribution. They draw on ideas from the social shaping of technology in order to develop a broader understanding of infrastructure change as a dynamic socio-technical process. A range of governance challenges to the development of electricity and heat networks are examined along the different phases of the infrastructure life cycle. Lessons are then drawn for the development of governance frameworks for the transformation of energy infrastructure more widely. 82 In the case of electricity distribution in Britain, the regulator (Ofgem) has sought to design suitable incentives to overcome barriers to long-term investment and innovation, although these are at an early stage of implementation. UK local authorities, by contrast, have struggled to finance large-scale infrastructure investments in the area of district heating (so energy-efficient and popular in the Scandinavian countries).\nA comparative analysis of recent energy policy developments in selected European countries (e.g. the German Energiewende) and on the implications of developments at a European level on UK energy policy (e.g. carbon pricing and market unbundling) has been reported by Hall et al. 83 Field research on the German situation drew out the implications for ownership, governance and financing of low carbon energy infrastructure. The German system differs from UK system in at least four ways. It had a much greater degree of decentralisation and municipal ownership, following post-War reconstruction. Their low-carbon transition or Energiewende was seen as a national priority. More decentralised political institutions in the German federal system enable a greater degree of energy policy experimentation. Finally, a more bank-based financial system in Germany, including a well-developed local banking system, contrasts with the centralised and market-based financial system in the United Kingdom. These local German banks have often built on local knowledge and encouraged small-scale renewable investment. They became key promoters of civic and community ownership of electricity generation assets. Such municipal ownership might again enable a similar, more long-term perspective to be taken in the United Kingdom, with a focus on good, safe, reliant energy infrastructure. Further economic and social benefits might then accrue to local municipalities.\nThese roles of actors, governance arrangements and regulations have been analysed in relation to realising market-led, government-led and civil society-led low carbon transition pathways, leading to the following findings:\nEnergy systems can best be understood as socio-technical systems made up of interacting technological and institutional elements, coevolving over time. Governance and regulatory frameworks are critical in managing risks for decision-makers and investors.\nChanges to investment support for low-carbon electricity generation have led to increasing risks and uncertainties, and concerns that long-term governmental commitment to decarbonisation may be undermined if the salience of energy security and cost priorities grows.\nAnalyses of energy finance as an adaptive market 80 help identify the lack of a mature community of investors, mismatches between investment and fund manager timescales, and lack of suitable investment vehicles. Capital markets are likely to change over the long-term to yield more adaptive markets for energy finance.\nThe economic feasibility of generation in all three pathways will depend on the revenue from secondary markets/sources, such as the capacity (ancillary service) market, FiT, and various tax incentives, although the ratio of the revenue needed from primary and secondary markets is case specific.\nA comparative UK–Germany analysis 83 has shown the importance of the local banking sector in facilitating civic ownership structures there.\nThe possibility of a low-carbon, decentralised transition (like that envisaged under the TF pathway) driven by civic energy systems has highlighted the role of local banking systems, and of shared values (including public service and local economic development). 83\nConcluding remarks\nSection:\nThe British Government has set a legally binding target of reducing the nation’s CO2 emissions by 80% by 2050 in comparison to a 1990 baseline. 6 This would ideally require the UK ESI to be decarbonised by around 2030–2050 in order to give more head room for carbon mitigation in other, more challenging sectors (such as industry and transport). 46 A set of three low-carbon transition pathways were developed and analysed via an innovative collaboration between engineers, social scientists and policy analysts. The pathways focus on the power sector, including the potential for increasing use of low-carbon electricity for heating and transport, within the context of critical European Union developments and policies. Their development started from narrative storylines regarding different governance framings, drawing on interviews and workshops with stakeholders and analysis of historical analogies. The quantified UK pathways were named Market Rules (MR), Central Co-ordination (CC) and Thousand Flowers (TF); each representing a dominant logic of governance arrangements – recently described by the Chief Executive Officer of a prominent UK renewable electricity supplier and generator company (unconnected with the project) as reflecting blue, red and green pathways respectively. These pathways have been used to explore what is needed to realise a transition that successfully addresses the so-called energy policy trilemma, i.e. the simultaneous delivery of low carbon, secure and affordable energy services. Such energy transitions are never smooth and always subject to contestation, negotiation and social change. The UK ESI has already undergone quite rapid change over the last few years. 84 Coal power station closures, for example, have amounted to 15 GW between 2010 and 2015; with combined cycle gas turbine plant closures accounting for a further 4 GW. In contrast, there has been a rapid rise in solar PV systems that now stands at around 853,000 installations, for which rooftop solar alone now accounts for >1% of UK electricity supply. 84 The recent British Government energy policy reset, the components of which will only become clear during 2017 (although some senior executives in the UK power sector speculate that it will propose roughly 30% nuclear, 30% renewables, and 30% gas) will lead to additional changes going forward. Thus, if the three transition pathways were being developed today they would no doubt contain rather different energy mixes. The TF pathway might contain more solar PV, but less bioenergy, for instance. Nevertheless, the insights gained from this exercise still provide a valuable evidence base for developers, policy makers and other stakeholders.\nA fundamental requirement for identifying and addressing the multiple challenges and opportunities posed by energy policy and climate change necessitates a combination of academic knowledge with that from industry, commerce, regulatory bodies, political and societal communities. This ambitious goal appears to be more achievable in processes that combine the analytic (the systematic application of expert knowledge) with the ‘deliberative’ (the systematic application of opportunities for face-to-face discussions between experts, stakeholders and citizens). 85 , 86 The ‘Realising Transition Pathways’ Consortium has adopted the practice of the co-production of knowledge to explore and integrate different kinds of expertise in order to provide opportunities for reflection and evaluation. It has attempted to achieve a level of joint working that allows the effective sharing of disciplinary-specific and professional expertise. New evidence and case studies of UK energy transitions provide practical advice on how sustainable energy transitions will depend on science and policy institutions becoming more responsive and adaptive to distributed societal actions. Here the challenges, insights and opportunities that have been gleaned from this research are highlighted (via bullet point summaries at the end of each principal section above).\nAnalytical tools were developed and applied to assess the technical feasibility, social acceptability, and environmental and economic impacts of the pathways. Technological and behavioural developments were examined, alongside appropriate governance structures and regulations for these low-carbon transition pathways, as well as the roles of key energy system actors (both large and small). An assessment of the part that could possibly be played by future demand responses was also undertaken in order to understand the factors that drive energy demand and energy-using behaviour. A set of interacting and complementary engineering and techno-economic models or tools were then employed to analyse electricity network infrastructure investment and operational decisions to assist market design and subsidy mechanisms. This provided a basis for integrating the analysis within a whole systems framework of electricity system development, together with the evaluation of future economic benefits, costs and uncertainties. Likewise, the energy and environmental performance of the different energy mixes were appraised on a life-cycle basis to determine the GHG emissions and other ecological or health burdens associated with each of the three transition pathways. The UK Carbon Budgets 46 are presently on track for an 80% reduction (in production emissions) by 2050, although it has been observed here 58 that the impact of upstream (and consumption) GHG emissions are generally excluded. The impact of such upstream emissions on the carbon performance of technologies (such as combined heat and power (CHP) and CCS) and the transition pathways themselves 58 distinguish the present findings from those of other analysts, such as the CCC and DECC. None of the three pathways yield zero GHG emissions by 2050, which suggests that the UK electricity sector cannot realistically be decarbonised by 2030–2040 as advocated by the CCC. 46\nSocio-technical solutions are required on both the demand and supply-side of any future UK energy system. Reduction in energy demand for heat, power and transport will be a significant element of any energy strategy aimed at limiting global warming to <2 ℃ under whatever pathways actually results out to mid-century. 87 , 88 Improvements in energy efficiency can be obtained from better thermal insulation of the building fabric, smart appliances and controls, alongside the adoption of efficient heating systems, such as heat pumps, community energy schemes and the like. In addition, lifestyle or workplace changes, DSR and DSP may well be needed, but these will be partially offset by so-called rebound effects. Decarbonising the supply-side is likely to see the continued adoption of new nuclear build (although the whole system costs may be prohibitive), offshore wind, and rooftop solar PV. It will inevitably need the take-up of CCS (as well as carbon capture and utilisation (CCU)) for a cost-efficient transition, together with sustainable bioenergy and biofuels, and possibly hydrogen (H2) as a fuel and energy storage media in the long term. Unfortunately, there are constraints over the use of bioenergy resources, including uncertainties over the availability of UK sustainably-sourced biomass, land use challenges, and competition with food supply. Finally, the energy infrastructure in Britain will need renewal in order to make it more resilient (e.g. to climate change impacts) and to potentially accommodate greater decentralised or distributed generation, including greater use of both large and small energy storage devices. Significant generation, transmission and distribution network reinforcements (operating with much lower utilisation factors) will be needed to meet future changes in demand and generation patterns. However, smart power innovations (a combination of interconnectors, storage and demand flexibility (or DSR)) could generate £8 bn per year of savings (according to a report for the recently-established UK National Infrastructure Commission 89 ; for which a member of the Realising Transition Pathways Consortium (Goran Strbac and his team) played a key role 90 ). Indeed, in a risk assessment study of the UK power sector, Hammond and Waldron 11 found that lack of investment in new infrastructure to be ranked the second highest risk to the power sector by different stakeholder groups (academic researchers, civil servants, electricity companies, green groups, power system engineers and various others). The electricity grid was found to be arguably the most vulnerable part of the power system; reinforcing the case for UK network renewal and reconfiguration by the middle of the 21st century. 4 , 11 Innovation, systems integration, and whole systems thinking to identify sustainable energy options (sometimes termed optionality in industry), as examined in the present study, will therefore be critically important in the transition towards a low-carbon future.\nAcknowledgements\nThe authors are particularly grateful for the critical, but supportive, views of members of the project Advisory Board (chaired by James Smith, former chairman of Shell UK and presently chairman of the UK Carbon Trust) made up of industrial representatives, UK Government policy makers and other stakeholders. The authors are also grateful for insights provided by an anonymous reviewer from climate, energy and innovation policy perspectives. However, the views expressed in this paper are the responsibility of the authors alone and not the external collaborators or the funding body.\nThe authors’ names are listed alphabetically.\nDeclaration of Conflicting Interests\nThe author(s) declared no potential conflicts of interest with respect to the research, authorship, and/or publication of this article.\nFunding\nThe author(s) disclosed receipt of the following financial support for the research, authorship, and/or publication of this article: This work draws on research undertaken as part of a major research grant awarded by the UK Engineering and Physical Sciences Research Council (EPSRC) entitled ‘Realising Transition Pathways - Whole Systems Analysis for a UK More Electric Low Carbon Energy Future’ [under Grant EP/K005316/1]. The authors are grateful to this sponsor, as well as for the interchanges with the main UK-based post-doctoral researchers associated with the project (see the project website www.realisingtransitionpathways.org.uk for a full list of those involved).\nReferences\n""","0.10045669","""http://journals.sagepub.com/doi/10.1177/0957650917695448""","[-0.178219,51.500505]"
"""The_University_of_Edinburgh""","""Shoe leather epidemiology: active travel and transport infrastructure in the urban landscape - Edinburgh Research Explorer""","""Shoe leather epidemiology: active travel and transport infrastructure in the urban landscape\nResearch output: Contribution to journal › Article\nExport citation\nDownload as Adobe PDF\nRights statement: © 2010 Ogilvie et al; licensee BioMed Central Ltd. This is an Open Access article distributed under the terms of the Creative Commons Attribution License (http://creativecommons.org/licenses/by/2.0), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.\nFinal published version, 1 MB, PDF-document\nInternational Journal of Behavioral Nutrition and Physical Activity\nVolume\nPublished - May 2010\nAbstract\nBackground: Building new transport infrastructure could help to promote changes in patterns of mobility, physical activity, and other determinants of population health such as economic development. However, local residents may not share planners' goals or assumptions about the benefits of such interventions. A particularly contentious example is the construction of major roads close to deprived residential areas. We report the qualitative findings of the baseline phase of a longitudinal mixed-method study of a new urban section of the M74 motorway in Glasgow, Scotland, that aims to combine quantitative epidemiological and spatial data with qualitative interview data from local residents. Methods: We interviewed 12 residents purposively sampled from a larger study cohort of 1322 to include men and women, different age groups, and people with and without cars, all living within 400 metres of the proposed route of the new motorway. We elicited their views and experiences of the local urban environment and the likely impact of the new motorway using a topic guide based on seven key environmental constructs (aesthetics, green space, convenience of routes, access to amenities, traffic, road danger and personal danger) reflecting an overall ecological model of walking and cycling. Results: Traffic was widely perceived to be heavy despite a low local level of car ownership. Few people cycled, and cycling on the roads was widely perceived to be dangerous for both adults and children. Views about the likely impacts of the new motorway on traffic congestion, pollution and the pleasantness of the local environment were polarised. A new motorway has potential to cause inequitable psychological or physical severance of routes to local amenities, and people may not necessarily use local walking routes or destinations such as parks and shops if these are considered undesirable, unsafe or 'not for us'. Public transport may have the potential to promote or discourage active travel in different socioeconomic contexts. Conclusions: Altering the urban landscape may influence walking and cycling in ways that vary between individuals, may be inequitable, and may not be predictable from quantitative data alone. A more applied ecological behavioural model may be required to capture these effects.\n""","0.48669717","""http://www.research.ed.ac.uk/portal/en/publications/shoe-leather-epidemiology-active-travel-and-transport-infrastructure-in-the-urban-landscape(af5354d4-73ed-4f5f-a212-821dbcd1d674).html""","[-3.187347,55.947691]"
"""StaffOxfordUniversityVariousDepartments1""","""Chronic creatine kinase deficiency eventually leads to congestive heart failure, but severity is dependent on genetic background, gender and age. — Radcliffe Department of Medicine""","""Publications\nChronic creatine kinase deficiency eventually leads to congestive heart failure, but severity is dependent on genetic background, gender and age.\nChronic creatine kinase deficiency eventually leads to congestive heart failure, but severity is dependent on genetic background, gender and age.\nLygate CA., Medway DJ., Ostrowski PJ., Aksentijevic D., Sebag-Montefiore L., Hunyor I., Zervou S., Schneider JE., Neubauer S.\nThe creatine kinase (CK) energy transport and buffering system supports cardiac function at times of high demand and is impaired in the failing heart. Mice deficient in muscle- and mitochondrial-CK (M/Mt-CK(-/-)) have previously been described, but exhibit an unexpectedly mild phenotype of compensated left ventricular (LV) hypertrophy. We hypothesised that heart failure would develop with age and performed echocardiography and LV haemodynamics at 1 year. Since all previous studies have utilised mice with a mixed genetic background, we backcrossed for >10 generations on to C57BL/6, and repeated the in vivo investigations. Male M/Mt-CK(-/-) mice on the mixed genetic background developed congestive heart failure as evidenced by significantly elevated end-diastolic pressure, impaired contractility, LV dilatation, hypertrophy and pulmonary congestion. Female mice were less severely affected, only showing trends for these parameters. After backcrossing, M/Mt-CK(-/-) mice had LV dysfunction consisting of impaired isovolumetric pressure changes and reduced contractile reserve, but did not develop congestive heart failure. Body weight was lower in knockout mice as a consequence of reduced total body fat. LV weight was not significantly elevated in relation to other internal organs and gene expression of LVH markers was normal, suggesting an absence of hypertrophy. In conclusion, the consequences of CK deficiency are highly dependent on genetic modifiers, gender and age. However, the observation that a primary defect in CK can, under the right conditions, result in heart failure suggests that impaired CK activity in the failing heart could contribute to disease progression.\n""","0.44038236","""https://www.rdm.ox.ac.uk/publications/341124""",
"""StaffCambridgeUniversityEngineering""","""Using electric vehicles for road transport - CUED Publications database""","""CUED Publications database\nLogin\nUsing electric vehicles for road transport\nMcCulloch, MD and Bishop, JDK and Doucette, RT (2012) Using electric vehicles for road transport. In: Energy, Transport, &amp; the Environment: Addressing the Sustainable Mobility Paradigm. UNSPECIFIED, pp. 223-252.\nFull text not available from this repository.\nAbstract\n© Springer-Verlag London 2012. All rights are reserved. Road vehicles account for almost half of the energy used in all transport modes globally. Reducing energy use in vehicles is key to meeting the forecast increase in demand for transport, while improving energy security and mitigating climate change. Non-powertrain vehicle options may reduce fuel consumption by at least 15%. Electric motors are the significant powertrain option to reduce energy use in vehicles because they are more efficient than the internal combustion engine and can recover a portion of the vehicle kinetic energy during braking. Conventionally, batteries are used to meet both the power and energy demands of electric vehicles and their variants. However, batteries are well-suited to store energy, while ultra-capacitors and high-speed flywheels are better placed to meet the bidirectional, high power requirements of real-world driving. Combining technologies with complementary strengths can yield a lower cost and more efficient energy storage system. While pure and hybrid electric vehicles use less energy than internal combustion engine vehicles, their ability to mitigate climate change is a function of the emissions intensity of the processes used to generate their electricity.\nItem Type:\n""","0.6768818","""http://publications.eng.cam.ac.uk/681604/""",
"""Imperial_College_London""","""Health and environmental co-benefits and conflicts of actions to meet UK carbon targets: Climate Policy: Vol 16, No 3""","""Health and environmental co-benefits and conflicts of actions to meet UK carbon targets\nGet access /doi/full/10.1080/14693062.2014.980212?needAccess=true\nAbstract\nMany actions to reduce GHG emissions have wider impacts on health, the economy, and the environment, beyond their role in mitigating climate change. These ancillary impacts can be positive (co-benefits) or negative (conflicts). This article presents the first quantitative review of the wider impacts on health and the environment likely to arise from action to meet the UK's legally-binding carbon budgets. Impacts were assessed for climate measures directed at power generation, energy use in buildings, and industry, transport, and agriculture. The study considered a wide range of health and environmental impacts including air pollution, noise, the upstream impacts of fuel extraction, and the lifestyle benefits of active travel. It was not possible to quantify all impacts, but for those that were monetized the co-benefits of climate action (i.e. excluding climate benefits) significantly outweigh the negative impacts, with a net present value of more than £85 billion from 2008 to 2030. Substantial benefits arise from reduced congestion, pollution, noise, and road accidents as a result of avoided journeys. There is also a large health benefit as a result of increased exercise from walking and cycling instead of driving. Awareness of these benefits could strengthen the case for more ambitious climate mitigation action.\nPolicy relevance\nThis article demonstrates that actions to mitigate GHG emissions have significant wider benefits for health and the environment. Including these impacts in cost–benefit analysis would strengthen the case for the UK (and similar countries) to set ambitious emissions reduction targets. Understanding co-benefits and trade-offs will also improve coordination across policy areas and cut costs. In addition, co-benefits such as air quality improvements are often immediate and local, whereas climate benefits may occur on a longer timescale and mainly in a distant region, as well as being harder to demonstrate. Dissemination of the benefits, along with better anticipation of trade-offs, could therefore boost public support for climate action.\n""","0.44783527","""http://www.tandfonline.com/doi/full/10.1080/14693062.2014.980212""","[-0.178219,51.500505]"
"""Cranfield_University""","""Automotive Damper Model for Use in Multi-Body Dynamic SimulationsProceedings of the Institution of Mechanical Engineers, Part D: Journal of Automobile Engineering - P J Allen, A Hameed, H Goyder, 2006""","""Section:\n1.\nHall B. B., Gill K. F. Performance of a telescopic dual-tube automotive damper and implications for ride prediction. Proc. IMechE, Part D: J. Automobile Engineering, 1986, 200 (D2). Google Scholar Link\n2.\nKaradayi R., Masada G. Y. A nonlinear shock absorber model. Proceedings of ASME Symposium on Simulation and Control of Ground Vehicles and Transportation Systems, 7–12 December 1996, AMD-Vol. 80, DSC-Vol. 2. Google Scholar\n3.\nHagedorn P., Wallaschek J. On equivalent harmonic and stochastic linearization for nonlinear shock-absorbers. Proceedings of Nonlinear Stochastic Dynamic Engineering Systems IUTAM Symposium, Innsbruk/Igls, Austria, 21–26 June 1987. Google Scholar\n4.\nWallaschek J. Dynamics of non-linear automobile shock-absorbers. Int. J. Non-linear Mechanics, 1990, 25 (2/3), 299–308. Google Scholar Crossref\n5.\nSurace C., Worden K., Tomlinson G. R. An improved nonlinear model for an automotive shock absorber. Nonlinear Dynamics, 1992, 3, 413–429. Google Scholar\n6.\nLee K. Numerical modelling for the hydraulic performance prediction of automotive monotube dampers. Veh. Syst. Dynamics Suppl., 1997, 28, 25–39. Google Scholar Crossref\n7.\nMostofi A. The incorporation of damping in lumped-parameter modelling techniques. Proc. IMechE, Part K: J. Multi-body Dynamics, 1999, 213, 11–17 Google Scholar Link\n8.\nRao M. D., Gruenberg S., Torab H., Griffiths D. Vibration testing and dynamic modelling of automotive shock absorbers. Int. Soc. Opt. Engng, 2000, 3989, 423–429. Google Scholar\n9.\nPurdy D. J. Theoretical and experimental investigation into an adjustable automotive damper. Proc. IMechE, Part D: J. Automobile Engineering, 2000, 214, 265–283. Google Scholar Link\n10.\nYung V. Y.B., Cole D. J. Analysis of high frequency forces generated by hydraulic automotive dampers. Veh. Syst. Dynamics Suppl., 2002, 37, 441–452 Google Scholar Crossref\n11.\nYung V. Y.B., Cole D. J. Mechanisms of highfrequency force generation in hydraulic automotive dampers. Veh. Syst. Dynamics Suppl., 2004, 41, 617–626. Google Scholar\n12.\nDuym S., Stiens R., Reybrouck K. Evaluation of shock absorber models. Veh. Syst. Dynamics, 1997, 27, 109–127. Google Scholar Crossref\n13.\nDuym S., Reybrouck K. Physical characterization of nonlinear shock absorber dymamics. Eur. J. Mech. Engng, 1998, 43 (4), 181–188 Google Scholar\n14.\nDuym S. Simulation tools, modelling and identification, for an automotive absorber in the context of vehicle dynamics. Veh. Syst. Dynamics, 2000, 33, 261–285. Google Scholar Crossref\n15.\nDuym S., Stiens R., Baron G., Reyybrouck K. Physical modelling of the hysteretic behaviour of automotive shock absorbers. SAE Trans., J. Passenger Cars, SAE paper 970101, 1997. Google Scholar\n16.\nLion A., Loose S. A thermomechanically coupled model for automotive shock absorbers: Theory, experiment and vehicle simulation on test tracks. Veh. Syst. Dynamics, 2002, 37, 241–261. Google Scholar Crossref\n17.\nHolman T. J. Rotary hydraulic suspension for high mobility off-road vehicles. International Society for Terrain Vehicle Systems 8th International Conference on Performance of Off-road Vehicles and Machines, 1984, pp. 1065–1075. Google Scholar\n18.\nMassey B. S. Mechanics of fluids, 2nd edition, 1970, p. 131, Fig. 5.6 (Van Nostrand Reinhold, London). Google Scholar\n19.\nBerg M. A non-linear rubber spring model for rail vehicle dynamics analysis. Veh. Syst. Dynamics, 1998, 30, 197–212. Google Scholar Crossref\n20.\nEastop T. D., McConkey A. Applied thermodynamics for engineering technologists, 4th edition, 1986 (Longman Scientific and Technical, Essex, UK). Google Scholar\n21.\nScholar C., Perkins N. C. Longitudinal vibration of elastic vehicle track systems. SAE paper 971090, 1997. Google Scholar\n""","0.6723235","""http://journals.sagepub.com/doi/10.1243/09544070JAUTO321""","[-0.629225,52.074389]"
"""Brunel_University_London""","""A lightweight communication library for distributed computing - IOPscience""","""A lightweight communication library for distributed computing\nDerek Groen1,2, Steven Rieder1,2, Paola Grosso2, Cees de Laat2 and Simon Portegies Zwart1\nPublished 10 August 2010 • 2010 IOP Publishing Ltd\n1 Leiden Observatory, Leiden University, PO Box 9513, 2300 RA Leiden, The Netherlands\n2 University of Amsterdam, Amsterdam, The Netherlands\nDates\nIn final form 23 June 2010\nPublished 10 August 2010\n1749-4699/3/1/015002\nAbstract\nWe present MPWide, a platform-independent communication library for performing message passing between computers. Our library allows coupling of several local message passing interface (MPI) applications through a long-distance network and is specifically optimized for such communications. The implementation is deliberately kept lightweight and platform independent, and the library can be installed and used without administrative privileges. The only requirements are a\nC++\ncompiler and at least one open port to a wide-area network on each site. In this paper we present the library, describe the user interface, present performance tests and apply MPWide in a large-scale cosmological\nN\n-body simulation on a network of two computers, one in Amsterdam and the other in Tokyo.\nExport citation and abstract\nBibTeX RIS\n1. Introduction\nA parallel application can run concurrently on multiple supercomputers, provided one is able to coordinate the tasks between them and limit the performance overhead of the wide-area communications. The advantage of using a distributed infrastructure lies in the enormous amounts of storage, RAM and computing performance it makes available. Distributed computing therefore allows us to solve large-scale scientific problems [ 1 ]. Starting from the coupling of Intel Paragons over an ATM network [ 2 ] in the early 1990s, distributed parallel applications have become very popular.\nAn efficient method to program a parallel application is the message passing interface (MPI [ 3 ]), a language-independent communication protocol that coordinates the computing tasks in parallel programs. MPI is often used for intra-site parallelization, but it can also be used for message passing in a distributed infrastructure. In this case, processes exchange data with their local peers as well as processes at other sites. Prior efforts in the use of MPI on distributed infrastructures are abundant [ 4–6 ], and several implementations have emerged that support execution across sites [ 7 , 8 ]. With respect to N-body simulations, Gualandris et al [ 9 ] have demonstrated that it is possible to use grid-enabled clusters of PCs connected via regular internet, grid middleware and MPICH-G2 [ 8 ]. However, the vast majority of MPI implementations require all participating nodes to have public IP addresses, which is generally undesirable for supercomputer environments for security reasons. Furthermore, these implementations do not have a built-in optimization to fully exploit dedicated network circuits, a central component in multi-supercomputer infrastructures.\nThe lack of flexibility in deployment and link-specific optimizations of grid-oriented MPI implementations in distributed supercomputer environments led us to develop MPWide, a lightweight socket library specially aimed for wide-area message passing between supercomputers. In this paper we present several performance results and apply MPWide to parallelize a large-scale cosmological N-body simulation across two supercomputers.\n2. Related work\nSeveral grid message-passing libraries and frameworks have been developed with the intent of making distributed computing possible between sites that have restrictive firewall policies. PACX-MPI [ 10 ] is specifically geared for parallelization across sites and does not require compute nodes to have a public IP address. Instead, it forwards inter-site communications through two forwarding demon processes on each site. Such a setup works reasonably well for applications that have been parallelized over multiple supercomputers using regular internet [ 11 ], but the two communication process restriction is less optimal when using multiple sites in a dedicated network environment. The interoperable MPI (IMPI) [ 12 ] standard has also been designed to specifically facilitate execution across sites, but at the time of writing very few of the vendor-tuned implementations on supercomputers support IMPI. Also, IMPI requires the installation of a centralized and globally accessible server and does not support path-specific optimizations.\nNetIbis [ 13 ] and PadicoTM [ 14 ] are two communication frameworks that are able to establish connections using bootstrap links, thus not requiring public IP addresses. However, PadicoTM also requires the use of a centralized rendezvous node for bootstrapping, and thereby some means of centralized connectivity. Both Ibis [ 15 ] and NetIbis are sufficiently flexible to use in a restricted supercomputer environment, but introduce a communication overhead compared to regular socket communications. These libraries are therefore less suitable for high-performance message passing over dedicated inter-supercomputer networks.\n3. Architecture of MPWide\n3.1. Design\nMPWide is a lightweight communication library that connects multiple applications on different supercomputers, each of them running with the locally recommended MPI implementation. It can be installed by a local user without administrative privileges, has a very limited set of software requirements, and the application programmer interface is similar to that of MPI. The applications are deployed separately for each supercomputer, and use MPWide to connect with each other upon startup. We are considering adding support for automated deployment, but to accomplish this we require a method to initiate applications on remote sites. The development of such a mechanism is not straightforward, because the access and security policies tend to be different for each supercomputer.\nMPWide has been designed to facilitate message passing between supercomputers and construct/modify custom communication topologies. The MPWide library is linked to the application at compile time and requires only the presence of UNIX sockets and a C++ compiler. MPWide provides an abstraction layer on top of regular sockets with methods to construct a communication topology, to adjust the parameters of individual communication paths and to perform message passing and forwarding across the topology. MPWide does not link against local MPI implementations, but can be used to combine multiple programs parallelized with MPI. Maintaining separate implementations for intra- and inter-site message passing makes it easier to specifically optimize and debug long-distance communication paths while relying on well-tested and vendor-tuned software for optimal intra-site communication performance.\n3.1.1. Data transport in the wide-area network\nDedicated network circuits are excellently suited for facilitating data transport between supercomputers. The highly deterministic bandwidths of optical circuits (or light paths) reduce the communication time while properly tuned transport layer protocols increase the application throughput in the absence of competing traffic.\nDuring the development of MPWide, we have examined the communication performance of several protocols by transferring data between two nodes in The Netherlands using a 10 Gbps optical network that was looped via Chicago, USA. We ran tests using both the transmission control protocol (TCP) and the user datagram protocol (UDP) network protocols. Plain UDP does not ensure the integrity of data packets however, and is therefore unsuitable for message passing. As an alternative, we instead tested the performance of two modified UDP implementations that feature mechanisms to ensure data integrity. These are reliable blast UDP (RBUDP [ 16 ], which is part of the Quanta toolkit [ 17 ]) and the UDP-based data transfer protocol (UDT [ 18 ]). The tests using TCP were run both with a single communication stream and with multiple streams in parallel.\nWe achieved a network throughput of less than 1 Gbps using RBUDP or UDT, and a throughput of up to 6 Gbps using parallel TCP streams. A full technical report on these preliminary performance tests can be found in [ 19 ]. Based on these results we decided to rely on multiple streams with a TCP-based protocol. This is a well-known and proven technique to improve network performance in the WAN [ 20 ].\n3.1.2. Functionality and programming interface\nIn MPWide, the communication takes place through channels. Each channel makes use of a single socket and provides a bidirectional connection between two ports on two hosts. On network paths where the use of parallel TCP streams provides a performance benefit, it is possible to use multiple channels concurrently on the same path. The message passing and forwarding functions in MPWide are designed to operate concurrently on multiple channels when needed.\nChannels are locally defined at initialization and may be closed, modified and reopened at any time during execution. This allows us to alter the communication topology at run-time, for example to restart or migrate part of the MPWide-enabled application.\nOnce one or more communication channels have been established, the user can transfer data using the communication calls in the MPWide API. Table  1 provides an overview of the functionality provided by MPWide.\nTable 1. List of MPWide function calls. In addition to this list, each function has a variant call with a prefix 'P' that operates on one send and/or recv buffer per channel.\nCommand name\nDownload figure: Standard Export PowerPoint slide\n3.2. Forwarder\nWhen running an application across multiple sites, the processes on one site are not always directly able to communicate with the other site. In many cases this problem can be resolved by forwarding the messages to intra-cluster communication nodes, which do have access to all other sites through the wide-area (dedicated) network. However, when the application uses a topology containing multiple dedicated networks, it will be necessary to forward messages from one network to another. The\nfunction provides such message forwarding for MPWide channels, and has been incorporated into the MPWide Forwarder. The Forwarder provides message forwarding for MPWide in user space, connecting an MPWide channel from one network to that of another. It can therefore serve as a relay process between nodes that are otherwise unable to contact each other or be put on intermediate nodes on very long network lines to mitigate the performance impact of packet loss. The latter method has been implemented and applied previously in the Phoebus project [ 21 ].\n3.3. Implementation\nWe implemented MPWide using C++ in combination with GNU C sockets and POSIX threads [ 22 ]. MPWide creates and destroys threads on the fly whenever a communication call is made. With modern kernels, the overhead of creating and destroying threads is very small, and using MPWide we were able to reach nearly 10 Gbps with message passing tests over local networks. For longer network paths, the high latency results in an even smaller relative overhead for thread creation/destruction. We have considered creating threads only at startup and managing them at run-time, but these modifications would increase the complexity of the code and only offer a limited performance benefit, as threading overhead plays a marginal role in wide-area communication performance.\nAside from the ability to hardwire each communication, the library also supports a number of customizable parameters:\nnumber of concurrent streams for each communication call;\ndata feeding pace of sending and receiving;\nTCP window size for each individual socket.\nThe maximum number of streams and the TCP window size may be restricted by local system policies. However, we were able to use up to 128 streams on most systems without requiring administrative rights. The code has been packaged and is publicly available at http://castle.strw.leidenuniv.nl/software/mpwide.html .\n4. Benchmarking MPWide\nWe have run a series of tests to measure the performance of MPWide between two local supercomputer nodes, as well as two nodes connected by a 10 Gbps international network connection.\nFor the local tests, we use two nodes of the Huygens supercomputer 3 in Amsterdam, The Netherlands, where the nodes are connected by eight parallel Infiniband links, each of which supports a maximum bandwidth of 20 Gbps. Our local tests use one out of these eight Infiniband links. Each run consists of 100 two-way message exchanges, where we record the average throughput and the standard error. First we performed eight different tests using messages of 8 MB and respectively 1, 2, 4, 8, 16, 32, 64 and 124 TCP streams in parallel. Due to system limitations, we were unable to perform tests using more than 124 streams on this particular site. We then repeated the same series of runs with message sizes of 64 and 512 MB.\nThe national tests were carried out between two sites of the Distributed ASCI Supercomputer 3 (DAS-3 4 ), one at the University of Amsterdam and one at the Delft University of Technology. Both sites are connected to regular internet with a 10 Gbps interface from the head node and with a 1 Gbps interface from each compute node. A detailed specification can be found in columns 4 and 5 of table  2 . We performed the tests using the system default TCP window sizes (16 kB send and 85 kB recv).\nTable 2. Specifications of the Huygens and Louhi supercomputers, as well as the two sites of the DAS-3 Dutch Grid.\n \n1\n2\nFor the international tests, we performed the same series of message exchanges, but now using one Huygens node and one node of the Louhi supercomputer 5 in Helsinki, Finland, which are both connected to the DEISA shared network with a 10 Gbps interface. The round-trip time of this network between Huygens and Louhi is 37.6 ms and we applied a TCP window size of 16 MB. The specifications of both supercomputers can be found in columns 2 and 3 of table  2 .\n4.1. Results\n4.1.1. Local tests\nThe results of the local performance tests, performed in March 2009, are found in figure  2 . The local network line has a very low latency (<0.1 ms) and is therefore quickly saturated when using multiple streams. In our results we found an increase in throughput when using two or four streams, but using more concurrent streams results in a performance decrease. When increasing the number of streams, the overhead caused by creating and destroying threads also increases, and may have contributed to this performance loss. However, if this were the case, we would observe a much steeper decline in performance for 8 MB messages than for 512 MB messages, as these communications take less time overall, and are thus more easily dominated by threading overhead. We therefore conclude that this overhead is caused by saturation of the local network line. The maximum throughput achieved in these tests is close to the theoretical maximum bandwidth of 10 Gbps. This proves that the MPWide library can efficiently utilize the available bandwidth, if optimal settings are used.\nZoom In\nDownload figure: Standard Export PowerPoint slide\n4.1.2. National tests\nWe carried out the national tests over two sites of the DAS-3 Dutch Grid. One site resides at the University of Amsterdam and the other site is located at the Delft University of Technology. The round-trip time of the path between Amsterdam and Delft is 2.1 ms. The results of these tests are found in figure  3 . Although the tests used the regular internet backbone, the fluctuations in our measurements are limited. When exchanging messages of 8 MB size, we obtain the best performance using a single stream, as the use of additional streams results in a lower and more variable performance. This is caused by the fact that message passing performance over multiple streams is limited by the slowest streams. For larger message sizes, however, using a single stream does not result in an optimal performance. Instead, we find that the best results are obtained using 8 streams (for 64 MB) to 32 streams (for 512 MB). Although a high peak performance is obtained when using 64 or more streams, the sustained performance is lower because the excess streams can cause network congestion. The round-trip time of 2.1 ms did not significantly reduce the achieved throughput in our tests.\nZoom In\nDownload figure: Standard Export PowerPoint slide\n4.1.3. International tests\nWe show the results of the international tests between Louhi and Huygens, performed in March 2009, in figure  4 . The tests were performed over a shared 10 Gbps network with frequent background network traffic. To minimize the impact of this background traffic, we performed our tests during a quiet period of the day. However, a few of our tests had background interference, causing fluctuations in the measured throughput. When exchanging 8 MB messages, the throughput rate no longer increases once we scale beyond eight parallel streams. Here, the throughput rate is limited to about 3.5 Gbps due to the high network latency and the small message size. For message sizes of 64 MB and especially 512 MB, the network latency no longer constrains the achieved throughput rate. As a result, we achieved a higher throughput when using more streams. Similar to the national tests, we notice larger fluctuations in performance for larger message sizes. The highest average throughput we achieved was about 4.64 Gbps, using 64 streams and a message size of 512 MB.\nZoom In\nDownload figure: Standard Export PowerPoint slide\n5. Testing performance in a production environment\nWe originally developed MPWide to manage the long-distance message passing in the CosmoGrid project [ 23 ]. CosmoGrid is a large-scale cosmological project that aims to perform a dark matter simulation of a cube with sides of 30 Mpc using supercomputers on two continents. In this simulation, we use the cosmological Λ Cold Dark Matter model [ 24 ], which defines a constant fraction of the overall energy density for dark energy to model the accelerating expansion of the universe. We apply this model to simulate the dark matter particles with a parallel tree/particle-mesh N-body integrator, GreeM [ 25 ]. This integrator can be run either as a single MPI application or as multiple MPI applications on different supercomputers. In the latter case, the wide-area communications are performed using MPWide. We use GreeM to calculate the dynamical evolution of 20483 (~8.590 billion) particles over a period of time from redshift z=65.35 to z=0. More information about the parameters used and the scientific rationale can be found in [ 23 ].\nBefore the simulation is launched, the initial condition is decomposed in slices for each site, and in blocks within that slice for each process. Each block contains an equal number of particles but may vary in volume. A simulation process loads one block during startup, and calculates tree and particle mesh force interactions at every step. These force calculations require the exchange of particles with neighboring processes (and sites, see figure  5 ) as well as the exchange of mesh cells. In addition, a number of smaller communications are performed to balance the load across all processes.\nZoom In\nDownload figure: Standard Export PowerPoint slide\nWe have used GreeM together with MPWide in a set of test runs, which consist of full-length simulations of a limited scale (2563 particles). Also, we have performed a run across two supercomputers, which consists of a limited part of the production simulation described earlier.\n5.1. Test experiments\nWe have run three test simulations, where each one uses a different infrastructure. All runs were carried out over two sites, with 30 calculation processes and one communication process per site. We performed one run on the DAS-3 testbed and one run across the Huygens and Louhi supercomputers. Both infrastructures are described in section  4 , and for both infrastructures we carried out simulations with communication over one TCP stream, as the average data volume is only a few MB per communication.\nFor the third run we used the Huygens supercomputer in combination with a Cray XT-4 supercomputer located at the Center for Computational Astrophysics in Tokyo, Japan. The Cray XT-4 consists of 740 nodes, which run on a quad-core 2.2 GHz AMD Opteron and have 8 GB RAM each. To exchange data between the sites, we reserved and used a 10 Gbps dedicated light path in the GLIF network [ 26 ], which has a round-trip time of 273 ms. This run was performed prior to the other two runs, using an older version of the code and the library. Unfortunately, we were unable to reserve the light path for a new test run using our improved setup. For this test we used 64 concurrent TCP streams.\nA detailed overview of the communication topology during the simulation can be found in figure  6 . Each of the supercomputers has been equipped with one specialized communication node. These nodes are each connected to the high-speed local supercomputer network and are linked together by the 10 Gbps light path. MPWide is used to transfer the locally gathered data to the communication node, forward it to the other site using the light path, and finally to deliver the data to the remote MPI simulation.\nZoom In\nDownload figure: Standard Export PowerPoint slide\n5.1.1. Results on the DAS-3 Dutch Grid\nThe performance results of our test simulation on the DAS-3 can be found in figure  7 . Here we find that the simulation performance is dominated by calculation, with a communication overhead less than 20% of the overall wall-clock time throughout the run. As we used regular internet for the wide-area communication, our simulation performance is subject to the influence of background network traffic. The two performance dips, which can be found around steps 1300 and 1350, are most likely caused by incidental increases in background traffic.\nZoom In\nDownload figure: Standard Export PowerPoint slide\n5.1.2. Results on Amsterdam and Helsinki supercomputers\nThe performance results of our test simulation between Amsterdam and Helsinki are shown in figure  8 . The obtained performance is similar to that on the DAS-3, although two differences can be noted. Firstly, the calculation time is ~25% lower due to the superior performance of the supercomputer nodes. Secondly, although the average communication performance is similar to that observed on the DAS-3, we observe more variability in the communication performance. We are at this point uncertain about the exact nature of this variability. The DEISA network is shared with other institutions, so the presence of background traffic may have decreased our communication performance.\nZoom In\nDownload figure: Standard Export PowerPoint slide\n5.1.3. Results on Amsterdam and Tokyo supercomputers\nThe run between Huygens and the Tokyo Cray-XT4 was carried out in October 2008, before any of the other experiments in this paper, and served as a dress rehearsal for both the Tree-PM simulation code and MPWide. The simulated problem was of equal size to the previous simulations and used the same number of processes. However, we performed the run using an older version of the code and different initial condition files. The performance results of this run can be found in figure  9 . During this test run, the time spent on calculation is roughly constant throughout the run, with a peak occurring during startup and a few points where snapshots are written. The time spent in communication is generally lower than the calculation time, taking about 7–10 s per step. However, we also observe a number of communication performance drops. These temporary decreases in performance were almost exclusively caused by single communications stalling for an extended period, which in turn were caused by periods of packet loss.\nZoom In\nDownload figure: Standard Export PowerPoint slide\n5.2. Production\nWe have executed a production-sized simulation between Amsterdam and Tokyo to measure the performance of the code when it is used for production. Based on the results described in section  5.1.3 , we made a few changes to the network settings before performing the second run. We disabled the TCP memory suppression mode, increased the TCP window sizes and increased the\nqueue limit for upper-layer processing. Due to the limited length of our network reservation, we were not able to test the effects of modifying each of these settings in detail.\nThe production-sized run was performed on 752 cores in total. The topology of this run was asymmetric, using 500 cores on Huygens and 250 cores on the Cray for calculation. The full run lasted just under 12 h, during which we performed 102 simulation steps. The performance results of this run can be found in figure  10 . In this full-scale run, the calculation time dominated the overall performance, and was slightly higher at startup and during steps where snapshots were written. The communication performance is generally more constant than in the small-scale run between Amsterdam and Tokyo, with fewer and less severe performance drops and a slight increase in time after step 30 in the simulation. This increase may have been caused by the TCP buffering sizes, which the local system may change during run-time. Overall, the total communication time per step was between 50 and 60 s for most of the simulation, and constituted about one eighth of the total execution time.\nZoom In\nDownload figure: Standard Export PowerPoint slide\n6. Conclusions and future work\nWe present MPWide, a communication library to perform message passing between supercomputers. MPWide provides message passing that is intrinsically parallelized, and can be used for high-performance computing across multiple supercomputers. The library allows for customization of individual connections and has a lightweight design, which makes it well-suited for connecting different supercomputer platforms. We have shown results from local and wide-area performance tests, and applied MPWide to combine two MPI applications into a very large parallel simulation across several wide-area computer infrastructures. During our tests, we reached a sustained throughput of up to 4.64 Gbps over a long-distance 10 Gbps network. In addition, we were able to run an N-body simulation across two continents with 20483 particles. During this simulation, about one eighth of the execution time was spent on communications.\nGiven that the parallel application is sufficiently scalable (which is the case for the N-body integrator used in this work), MPWide can be used to efficiently parallelize production applications across multiple supercomputers. Future efforts to improve the usability of MPWide may include the integration with debugging tools and visualization toolkits, the introduction of group communicators and collective operations (similar to\nin MPI implementations), and the addition of an automatic deployment mechanism.\nAcknowledgments\nWe thank Jun Makino for his valuable help, input and hospitality during the development of this library. We are grateful to Tomoaki Ishiyama for his work on interfacing and running the TreePM code with MPWide and his valuable feedback during development. We also thank Hans Blom for highly useful discussions and for performing preliminary tests. Performing the intercontinental simulations would not have been possible without the help of Keigo Nitadori, Steve McMillan, Kei Hiraki, Stefan Harfst, Walter Lioen, Petri Nikunen, Ronald van der Pol, Mark van der Sanden, Peter Tavenier, Huub Stoffers, Alan Verlo, Joni Virtanen and Seiichi Yamamoto. This research was supported by The Netherlands Organization for Scientific Research (NWO) grant nos. 639.073.803, 643.200.503 and 643.000.803, the European Commission grant for the QosCosGrid project (grant number: FP6-2005-IST-5 033883), SURFNet with the GigaPort project, NAOJ, the International Information Science Foundation (IISF), The Netherlands Advanced School for Astronomy (NOVA), the Leids Kerkhoven-Bosscha fonds (LKBF) and the Stichting Nationale Computerfaciliteiten (NCF). We thank the DEISA Consortium ( www.deisa.eu ), co-funded through the EU FP6 project RI-031513 and the FP7 project RI-222919, for support within the DEISA Extreme Computing Initiative (GBBP project).\nFootnotes\n""","0.15382336","""http://iopscience.iop.org/article/10.1088/1749-4699/3/1/015002/meta;jsessionid=08E8555EBD3A1015798A1874CBEEA61C.c1.iopscience.cld.iop.org""","[-0.472855,51.532848]"
"""Cranfield_University""","""The impact of structural composite materials. Part 2: hypervelocity impact and shockThe Journal of Strain Analysis for Engineering Design - Gareth J Appleby-Thomas, Paul J Hazell, 2012""","""Fair H. Hypervelocity then and now. Int J Impact Engng 1987; 5: 1–11. Crossref\n2.\nSchonberg WP. Protecting Earth-orbiting spacecraft against micro-meteoroid/orbital debris impact damage using composite structural systems and materials: An overview. Adv Space Res 2010; 45(6): 709–720. Crossref\n3.\nSibeaud J-M, Thamié L, Puillet C. Hypervelocity impact on honeycomb target structures: Experiments and modeling. Int J Impact Engng 2008; 35(12): 1799–1807. Crossref\n4.\nCook S, Hueter U. NASA’s integrated space transportation plan – 3rd generation reusable launch vehicle technology update. Acta Astronautica 2003; 53: 719–728. Crossref\n5.\nMoses PL, Rausch VL, Nguyen LT, . NASA hypersonic flight demonstrators—overview, status, and future plans. Acta Astronautica 2004; 55: 619–630. Crossref\n6.\nBernhard RP, Christiansen EL, Kerr JH. Space shuttle meteoroid and orbital debris impact damage. Int J Impact Engng 2001; 26: 33–38. Crossref\n7.\nRyan S, Schäfer F, Guyot M, Hiermaier S, Lambert M. Characterizing the transient response of CFRP/Al HC spacecraft structures induced by space debris impact at hypervelocity. Int J Impact Engng 2008; 35(12): 1756–1763. Crossref\n8.\nCallister WDJr. Materials science and engineering: an introduction. 5th ed. New York: John Wiley, pp.755–761.\n9.\nLamontage CG, Manuelpillai GN, Taylor EA, . Normal and oblique hypervelocity impacts on carbon fibre/PEEK composites. Int J Impact Engng 1999; 23: 519–532. Crossref\n10.\nWhipple FL. Meteorites and space travel. Astronom J 1947; 52: 131. Crossref\n11.\nIsbell WM, Tedeschi WJ. Hypervelocity research and the growing problem of space debris. Int J Impact Engng 1993; 14: 359–372. Crossref\n12.\nSchonberg WP, Compton LE. Application of the NASA/JSC Whipple shield ballistic limit equations to dual-wall targets under hypervelocity impact. Int J Impact Engng 2008; 35(12): 1792–1798. Crossref\n13.\nHazell PJ, Appleby-Thomas GJ, Trinquant X, . In-fiber shock propagation in Dyneema®. J Appl Phys 2011; 110(4): 043504. Crossref\n14.\nBurlayenko VN, Sadowski T. A numerical study of the dynamic response of sandwich plates initially damaged by low-velocity impact. Comput Mater Sci 2012; 52(1): 212–216. Crossref\n15.\nSilvestrov VV, Plastinin AV, Gorshkov NN. Hypervelocity impact on laminate composite panels. Int J Impact Engng 1995; 17: 751–762. Crossref\n16.\nSchonberg WP. Protecting spacecraft against orbital debris impact damage using composite materials. Compos. Part A 2000; 31(8): 869–878. Crossref\n17.\nLambert M, Schäfer FK, Geyer T. Impact damage on sandwich panels and multi-layer insulation. Int J Impact Engng 2001; 26: 369–380. Crossref\n18.\nWeeden B. Space Policy. Overview of the legal and policy challenges of orbital debris removal. Space Policy 2011; 27: 38–43. Crossref\n19.\nGraham GA, Kearsley AT, Grady MM, . Hypervelocity impacts in low Earth orbit: cosmic dust versus space debris. Adv Space Res 1999; 23(1): 95–100. Crossref\n20.\nMilowicki GV, Johnson-Freese J. Strategic choices: examining the United States military response to the Chinese anti-satellite test. Astropolitics 2008; 6: 1–21. Crossref\n21.\nSchneider E, Schäfer F. Hypervelocity impact research – acceleration technology and applications. Adv Space Res 2001; 28(9): 1417–1424. Crossref\n22.\nField JE, Walley SM, Proud WG, . Review of experimental techniques for high rate deformation and shock studies. Int J Impact Engng 2004; 30(7): 725–775. Crossref\n23.\nTennyson RC, Lamontagne C. Hypervelocity impact damage to composites. Compos Part A 2000; 31(8): 785–794. Crossref\n24.\nLamontage CG, Manuelpillai GN, Kerr JH, . Projectile density, impact angle and energy effects on hypervelocity impact damage to carbon fibre/PEEK composites. Int J Impact Engng 2001; 26: 381–398. Crossref\n25.\nNumata D, Ohtani K, Anyoji M, . HVI tests on CFRP laminates at low temperature. Int J Impact Engng 2008; 35(12): 1695–1701. Crossref\n26.\nHanada T, Liou J-C. Comparison of fragments created by low- and hyper-velocity impacts. Adv Space Res 2008; 41(7): 1132–1137. Crossref\n27.\nJohnson NL, Krisko PH, Liou J-C, . NASA’s new breakup model of evolve 4.0. Adv Space Res 2001; 28(9): 1377–1384. Crossref\n28.\nWilliamsen JE, Evans SW. Predicting orbital debris shape and orientation effects on spacecraft shield ballistic limits based on characteristic length. Int J Imapct Engng 2006; 33: 862–871. Crossref\n29.\nWilliamsen JE, Schonberg WP, Evans H, . A comparison of NASA, DoD, and hydrocode ballistic limit predictions for spherical and non-spherical shapes versus dual- and single wall targets, and their effects on orbital debris penetration risk. Int J Impact Engng 2008; 35(12): 1870–1877. Crossref\n30.\nKrisko PH, Horstman M, Fudge ML. SOCIT4 collisional-breakup test data analysis: With shape and materials characterization. Adv Space Res 2008; 41(7): 1138–1146. Crossref\n31.\nTedeschi WJ, Connell Cdr JC, McKnight DS, . Determining the effects of space debris impacts on spacecraft structures. Acta Astronautica 1992; 26(7): 501–512. Crossref\n32.\nWicklein M, Ryan S, White DM, . Hypervelocity impact on CFRP: Testing, material modelling, and numerical simulation. Int J Impact Engng 2008; 35(12): 1861–1869. Crossref\n33.\nRyan S, Schaefer F, Destefanis R, . A ballistic limit equation for hypervelocity impacts on composite honeycomb sandwich panel satellite structures. Adv Space Res 2008; 41(7): 1152–1166. Crossref\n34.\nClegg RA, White DM, Riedel W, . Hypervelocity impact damage prediction in composites: Part I—material model and characterization. Int J Impact Engng 2006; 33: 190–200. Crossref\n35.\nRiedel W, Nahme H, White DM, . Hypervelocity impact damage prediction in composites: Part II—experimental investigations and simulations. Int J Impact Engng 2006; 33: 670–680. Crossref\n36.\nAppleby-Thomas GJ, Hazell PJ, Stennett C, . Shock propagation in a cemented tungsten carbide. J Appl Phys 2009; 105(6): 064916. Crossref\n37.\nYuan F, Tsai L, Prakash V, . Spall strength of glass fiber reinforced polymer composites. Int J Solids Struct 2007; 44: 7731–7747. Crossref\n38.\nRyan S, Wicklein M, Mouritz A, . Theoretical prediction of dynamic composite material properties for hypervelocity simulations, Int J Impact Engng 2009; 36.\n39.\nNaik NK, Kavala VR. High strain rate behaviour of woven fabric composites under compressive loading. Mater Sci Engng A 2008; 474: 301–311. Crossref\n40.\nNaik NK, Shankar PJ, Kavala VR, . High strain rate mechanical behavior of epoxy under compressive loading: Experimental and modelling studies. Mater Sci Engng A 2011, 528, 846–854. Crossref\n41.\nSkidmore IC. An introduction to shock waves in solids. Appl Mat Res 1965; 131–147.\n42.\nDavison L, Graham RA. Shock compression of solids. Phys Reports (Review Section of Phys. Letters) 1979; 55: 255–379. Crossref\n43.\nMeyers MA. Dynamic behavior of materials. New York: John Wiley, 1994. Crossref\n44.\nMillett JCF, Bourne NK., Meziere YJE, . The effect of orientation on the shock response of a carbon fibre–epoxy composite. Comp Sci Techol 2007; 67: 3253–3260. Crossref\n45.\nDavison L. Fundamentals of shock wave propagation in solids. Berlin, Springer-Verlag, 2008, pp.31–43.\n46.\nIsbell WM. Shock Waves: Measuring the dynamic response of materials. London, Imperial College Press, London, 2005, pp.8–11. Crossref\n47.\nChéret R. The life and work of Pierre-Henri Hugoniot. Shock Waves 1992; 2(1): 1–4. Crossref\n48.\nRuoff L. Linear shock–velocity–particle–velocity relationship. J Appl Phys 1967; 38: 4976–4980. Crossref\n49.\nCarter WJ, Marsh SP. Hugoniot Equation of State of Polymers. Report LA-13006-MS. Los Alamos National Laboratory, Los Alamos (USA).\n50.\nPorter D, Gould PJ. A general equation of state for polymeric materials, J Phys IV 2006; 134: 373–378.\n51.\nWood DC, Hazell PJ, Appleby-Thomas GJ, . The shock response of a tape wrapped carbon fiber composite. In: Elert ML, Buttler WT, Borg JP, . (eds). Shock compression of condensed matter -2011, AIP Conference Proceedings 1426, 2012, pp.183–186. Crossref\n52.\nShepherd CJ, Appleby-Thomas GJ, Wilgeroth JM, . On the response of ballistic soap to one-dimensional shock loading. Int J Impact Engng 2011; 38(12): 981–988. Crossref\n53.\nWood DC, Hazell PJ, Appleby-Thomas GJ, . Shock behaviour of a phenolic resin. J Mater Sci 2011; 46(18): 5991–5999. Crossref\n54.\nHazell PJ, Stennett C, Cooper G. The shock and release behavior of an aerospace-grade cured aromatic amine epoxy resin. Polymer Comp 2008; 29: 1106–1110. Crossref\n55.\nDandekar DP, Hall CA, Chhabildas LC, . Shock response of a glass-fiber-reinforced polymer composite. Compos. Struct 2003; 6: 51–59. Crossref\n56.\nZaretsky E, deBotton G, Perl M. The response of a glass fibers reinforced epoxy composite to an impact loading. Int J Solids and Struct 2004; 41(2): 569–584. Crossref\n57.\nMillett JCF, Bourne NK, Meziere YJE, . The effect of orientation on the shock response of a carbon fibre-epoxy composite. Compos Sci Technol 2007; 67: 3253–3260. Crossref\n58.\nRiedel W, Nahme H, Thoma K. Equation of State Properties of Modern Composite Materials: Modeling Shock, Release and Spallation. In: Furnish MD, Gupta YM, Forbes JW (eds), Shock compression of condensed matter. American Institute of Physics, 2004, pp.701–706. Crossref\n59.\nAhuk AZ, Kanel GI, Lash AA. Glass epoxy composite behaviour under shock loading. J. de Physique IV, Colloque C8 supplement of the Journal de Physique III, Vol. 4, September 1994, pp.403–407.\n60.\nMillett JCF, Meziere YJE, Bourne NK. The response to shock loading of a glass-fibre-epoxy composite: Effects of fibre orientation to the loading axis. J Phys D: Appl Phys 2007; 40: 5358–5365. Crossref\n61.\nBushman AV, Efremov VP, Lomonosov IV, . Shock compressibility and equation of state of carbon plastic at high energy. Teplofiz Vys Temp 1990; 28: 1232–1234.\n62.\nHéreil PL, Allix O, Gratton M. Shock behaviour of 3D carbon-carbon composite. J Phys IV 1997, 7, 529–534.\n63.\nWinter RE, Harris EJ. The effect of shape and mounting on the piezo-resistive response of embedded manganin conductors. J Phys D: Appl Phys 2006; 39: 5323–5330. Crossref\n64.\nWinter RE, Harris EJ. Simulations of embedded lateral stress gauge profiles in shocked targets. J Phys D: Appl. Phys. 2008; 41: 035503. Crossref\n65.\nWinter RE, Owen GD, Harris EJ. Experimental measurement of stress perturbations caused by lateral gauges. J Phys D: Appl Phys 2008; 41: 202006. Crossref\n66.\nAppleby-Thomas GJ, Hazell PJ, . On the interpretation of lateral manganin gauge stress measurements in polymers. J Appl Phys 2010; 108: 033524. Crossref\n67.\nMeziere YJE, Millett JCF, Bourne NK. The effect of fibre orientation on the shock response of a glass-fibre-epoxy composite. In: Elert GJ, Furnish MD, Chau R, . (eds), Shock compression of condensed matter – 2007. Elsevier Science Publishers, BV, 2007, pp.715–718.\n68.\nZhuk AZ, Kanel GI, Lash AA. Glass-epoxy composite behaviour under shock loading. J. De Physique IV 1994; 4: 404–407.\n69.\nAppleby-Thomas GJ, Hazell PJ, Stennett C. The variation in lateral and longitudinal stress gauge response within an RTM 6 epoxy resin under one-dimensional shock loading. J Mater Sci 2009; 44(22); 6187–6198. Crossref\n70.\nGerlach R, Siviour CR, Petrinic N, . Experimental characterisation and constitutive modelling of RTM-6 resin under impact loading. Polymer 2008; 49: 2728–2737. Crossref\n71.\nEden G, Carden MH, Collyer AM, . Shock wave propagation in a 3-D quartz phenolic composite. In: Schmidt SC, Johnson JN, Davison LW (eds). Shock compression of condensed matter – 1989. Elsevier Science Publishers, BV, 1990, pp.217–220.\n72.\nHolmes BS, Tsou FK. Steady shock waves in composite materials. J Appl Phys 1972; 43: 957–961. Crossref\n73.\nTsou FK, Chou PC. Analytical study of Hugoniot in unidirectional fiber reinforced composites. J Compos Mater 1969; 3: 500–514. Link\n74.\nHazell PJ, Stennett C, Cooper G. The effect of specimen thickness on the shock propagation along the in-fibre direction of an aerospace-grade CFRP laminate. Compos Part A: Appl Sci 2009; 40: 204–209. Crossref\nVol 47, Issue 7, 2012\nDevelopment of numerical hypervelocity models\nThe shock response of composite materials\nSummary and concluding remarks\n""","0.21012434","""http://journals.sagepub.com/doi/10.1177/0309324712448299""","[-0.629225,52.074389]"
"""Cranfield_University""","""On the trade-off between minimum fuel burn and maximum time between overhaul for an intercooled aeroengineProceedings of the Institution of Mechanical Engineers, Part G: Journal of Aerospace Engineering - E Najafi Saatlou, KG Kyprianidis, V Sethi, AO Abu, P Pilidis, 2014""","""Karl A. Assessing variability to achieve robust design. INSIGHTS, htpp:// www.simulia.com (2010). Google Scholar\n4.\nRyan R, Blair J, Townsend J, et al. Working on the boundaries: Philosophies and practices of the design process. NASA Technical Paper 3642, Marshall Space Flight Center, MSFC, Alabama, USA, 1996. Google Scholar\n5.\nSobieszczanski-Sobieski J and Haftka RT. Multidisciplinary aerospace design optimization: Survey of recent developments, structural optimization. In: AIAA 34th aerospace sciences meeting and exhibit, Reno, 1996. AIAA paper 96–0711. Google Scholar\n6.\nJones MJ, Bradbrook SJ and Nurney K. A preliminary engine design process for an affordable capability. In: Proceedings of RTO AVS symposium on “reduction of military vehicle acquisition time and cost through advanced modelling and virtual simulation”, RTO-MP-089-52, Paris, France, 2002. Google Scholar\n7.\nGayraud S. Design of a decision support system for combined cycle schemes. MPhil Thesis, Cranfield University, UK. Google Scholar\n8.\nWhellens MW and Singh R. Propulsion system optimisation for minimum global warming potential. In: Proceedings of the 23rd ICAS congress, Toronto, Canada. Google Scholar\n9.\nOgaji SOT, Pilidis P and Hales R. TERA – A tool for aero-engine modelling and management. In: Second world congress on engineering asset management and the fourth international conference on condition monitoring, Harrogate, UK, 2007. Google Scholar\n10.\nDi Lorenzo G, Friconneau V, Brandt P, et al. Technoeconomic environmental risk analysis technological perspective application to low carbon plant. In: IDGTE conference, UK, 2007. Google Scholar\n11.\nPilidis P, Schuddebeurs J, Norman P et al. An assessment method of marine gas turbine propulsion systems. In: AES conference, London, UK, 2007. Google Scholar\n12.\nKhan RSR, Lagana MC, Ogaji SOT, et al. Risk analysis of gas turbines for natural gas liquefaction. In: Proceedings of the ASME Turbo Expo 2010: Power for land sea and air, Glasgow, Scotland, UK, 2010. ASME paper GT2010-23261. Google Scholar\n13.\nKhan RSR, Barreiro J, Lagana MJ, et al. An assessment of the emissions and global warming potential of gas turbines for LNG applications. In: Proceedings of the ASME Turbo Expo 2009: Power for land sea and air, Orlando, FL, USA, 2009. ASME paper GT2009–59184. Google Scholar\n14.\nMorquillas JM and Pilidis P. Recycling of gas turbines from obsolete aircraft. ASME paper 90-GT-309, Brussels, Belgium. Google Scholar\n15.\nUlizar I and Pilidis P. Handling of a semiclosed cycle GT with a carbon dioxide-argon working fluid. ASME paper 99-GT-374, Indianapolis, USA, June, 1999; ASME J Eng Gas Turbines Power 2000; 122(3). Google Scholar\n16.\nZwebek, A, Pilidis, P. Degradation effects on CCGT plant performance, Part II: Steam turbine cycle component degradation effects. ASME J Eng Gas Turbines Power 2003; 125: 658–663. Google Scholar , Crossref\n17.\nKumar KNP, Tourlidakis A and Pilidis P. HTGR closed cycle gas turbine plant analysis: Options & procedures for startup with hot gas injection. In: ASME Turbo Expo 2002: Land, sea, and air, Amsterdam, The Netherlands, 2002. Google Scholar\n18.\nBretschneider S, Arago O and Staudacher S. Architecture of a techno and environmental risk assessment tool using a multi-modular build approach. In: Proceedings of ISABE, Beijing, China, 2007. ISABE-2007–1103. Google Scholar\n19.\nKyprianidis KG. Future aero engine designs: An evolving vision. In: Benini E (ed.) Advances in gas turbine technology, chap. 1. InTech: Rijeka, Croatia, 2011, pp. 3–24. Google Scholar\n20.\nKyprianidis KG, Colmenares Quintero RF, Pascovici DS, et al. EVA - A tool for environmental assessment of novel propulsion cycles. In: Proceedings of the ASME Turbo Expo 2008: Power for land sea and air, Berlin, Germany, 2008. ASME paper GT2008-50602. Google Scholar\n21.\nKyprianidis KG. Multi-disciplinary conceptual design of future jet engine systems. PhD Thesis, Cranfield University, UK, 2010. Google Scholar\n22.\nKyprianidis KG, Au D, Ogaji SOT, et al. Low pressure system component advancement and its impact on future turbofan engine emissions. In: Proceedings of ISABE, Montreal, Canada, 2009. ISABE-2009-1276. Google Scholar\n23.\nWalsh, P, Fletcher, P. Gas turbine performance, Oxford: Blackwell Science, 2004. Google Scholar , Crossref\n24.\nMacMillan WL. Development of a modular type computer program for the calculation of gas turbine off-design performance. PhD Thesis, Cranfield University, UK, 1974. Google Scholar\n25.\nFawke AJ and Saravanamuttoo HIH. Digital computer methods for prediction of gas turbine dynamic response. Society of Automotive Engineers Paper 710550, 1971. Google Scholar\n26.\nOnat E and Klees GW. A method to estimate weight and dimensions of large and small gas turbine engines. NASA CR 159481, 1979. Google Scholar\n27.\nKays, WM, London, AL. Compact heat exchangers, 3rd ed. Malabar, FL: Krieger Publishing Company, 1998, pp. 213–213. Google Scholar\n28.\nJenkinson, LR, Simpkin, P, Rhodes, D. Civil jet aircraft design, New York: Elsevier, 1999. Google Scholar , Crossref\n29.\nRoskam, J. Airplane design, Part 5: Component weight estimation, Lawrence, KS: DARcorp, 2003. Google Scholar\n30.\nTorenbeek, E. Synthesis of subsonic airplane design, Norwell, MA: Kluwer Academic, 1982. Google Scholar , Crossref\n31.\nESDU TR 97016. Estimation of airframe drag by summation of components: Principles and examples. London, UK, September 1997. Google Scholar\n32.\nLaskaridis P. Performance investigations and systems architectures for the more electric aircraft. PhD Thesis, Cranfield University, UK, 2004. Google Scholar\n33.\nSpera DA and Grisaffe SJ. Life prediction of turbine components on-going studies at the NASA Lewis Research Center. NASA TM X 2664, NASA Lewis Research Center, Cleveland, OH, USA, 1973. Google Scholar\n34.\nHaslam AS and Cookson RA. Mechanical design of turbomachinery. Course’s Lecture Notes, School of Engineering, Cranfield University, UK, 2007. Google Scholar\n35.\nTong, M, Halliwell, I, Ghosn, L. A computer code for gas turbine engine weight and disk life estimation. J Eng Gas Turbine Power 2004; 126(2): 265–271. Google Scholar , Crossref\n36.\nLarson, FR, Miller, J. A time-temperature relationship for rupture and creep stress. Trans ASME 1952; 74: 765–775. Google Scholar\n37.\nBirks, N, Meier, GH, Pettit, FS. Introduction to high temperature oxidation of metals, 2nd ed. Cambridge, UK: Cambridge University Press, 2006. Google Scholar , Crossref\n38.\nSwaminathan, PV, Alen, MJ, Touchton, LG. Temperature estimation and life prediction of turbine blades using post-service oxidation measurements. Trans ASME - J Eng Gas Turbines Power 1997; 119(4): 922–929. Google Scholar , Crossref\n39.\nKyprianidis, KG, Grönstedt, T, Ogaji, SOT. Assessment of future aero engine designs with intercooled and intercooled recuperated cores. ASME J Eng Gas Turbines Power 2011; 133(1): 011701–011701. Google Scholar , Crossref\n""","0.29424834","""http://journals.sagepub.com/doi/10.1177/0954410013518509""","[-0.629225,52.074389]"
"""Imperial_College_London""","""Chemical composition and sources of particle pollution in affluent and poor neighborhoods of Accra, Ghana - IOPscience""","""Letter • The following article is OPEN ACCESS • The following article is IOPselect\nChemical composition and sources of particle pollution in affluent and poor neighborhoods of Accra, Ghana\nZheng Zhou1,2, Kathie L Dionisio1,2, Thiago G Verissimo3, Americo S Kerr3, Brent Coull2,4, Raphael E Arku2, Petros Koutrakis2, John D Spengler2, Allison F Hughes5, Jose Vallarino2, Samuel Agyei-Mensah6 and Majid Ezzati7\nPublished 30 October 2013 • 2013 IOP Publishing Ltd\n1 Department of Global Health and Population, Harvard School of Public Health, Boston, MA, USA\n2 Department of Environmental Health, Harvard School of Public Health, Boston, MA, USA\n3 Institute of Physics, University of Sao Paulo, Sao Paulo, Brazil\n4 Department of Biostatistics, Harvard School of Public Health, Boston, MA, USA\n5 Department of Physics, University of Ghana, Legon, Ghana\n6 Department of Geography and Resource Development, University of Ghana, Legon, Ghana\n7 Medical Research Council–Public Health England Centre for Environment and Health, Department of Epidemiology and Biostatistics, School of Public Health, Imperial College London, UK\nDates\nDownload video Download transcript\nThe highest levels of air pollution in the world now occur in developing country cities, where air pollution sources differ from high-income countries. We analyzed particulate matter (PM) chemical composition and estimated the contributions of various sources to particle pollution in poor and affluent neighborhoods of Accra, Ghana. Elements from earth's crust were most abundant during the seasonal Harmattan period between late December and late January when Saharan dust is carried to coastal West Africa. During Harmattan, crustal particles accounted for 55 μg m−3 (37%) of fine particle (PM2.5) mass and 128 μg m−3 (42%) of PM10 mass. Outside Harmattan, biomass combustion, which was associated with higher black carbon, potassium, and sulfur, accounted for between 10.6 and 21.3 μg m−3 of fine particle mass in different neighborhoods, with its contribution largest in the poorest neighborhood. Other sources were sea salt, vehicle emissions, tire and brake wear, road dust, and solid waste burning. Reducing air pollution in African cities requires policies related to energy, transportation and urban planning, and forestry and agriculture, with explicit attention to impacts of each strategy in poor communities. Such cross-sectoral integration requires emphasis on urban environment and urban poverty in the post-2015 Development Agenda.\nExport citation and abstract\nSupplementary data\n1. Introduction\nThe highest levels of air pollution in the world now occur  in cities in Asia, Middle East, and Africa [ 1 ]. In these settings, the concentrations of fine particles (less than 2.5 μm in aerodynamic diameter; PM2.5), which are associated with hazardous effects on health, approach or reach 100 μg m−3, compared to less than 20 μg m−3 in most European and North American cities [ 1 ]. The sources of air pollution in developing country cities include those that are common in high-income nations, e.g., vehicle emissions, as well as biomass and coal combustion for household and commercial purposes and resuspended dust from unpaved roads. In coastal West Africa, sea salt and long-range-transported Saharan dust may also be sources of particles in some seasons [ 2 – 4 ]. Yet little is known about the relative contributions of these sources to pollution levels in African cities, where the urban population is growing faster than any other region; neither is it known how the source diversity affects particle chemistry, which may in turn affect both health hazards and impacts on anthropogenic climate change.\nWe conducted a study in Accra, Ghana, one of Africa's fastest growing cities to understand the levels, chemical properties, and sources of particle pollution. Three quarters of sub-Saharan Africa's population use biomass fuels as their main source of energy, including over one half of urban households [ 5 , 6 ]. In Accra, and other developing country cities, there are significant differences in road conditions, traffic patterns, and fuel use between the affluent neighborhoods and poor 'slum' areas [ 6 – 8 ]. For this reason, we collected data at sites located in poor and affluent neighborhoods.\n2. Materials and methods\nWe collected particulate matter (PM) samples between September 2007 and August 2008 in four neighborhoods of varying degrees of poverty and affluence. The four neighborhoods lie on a line from the coast to Accra's northern boundaries: James Town/Usher Town (JT), Asylum Down (AD), Nima (NM) and East Legon (EL) (figure  1 ). JT and NM are densely populated low-income communities where most residents use biomass for cooking at home and for street food. AD is a middle-class neighborhood and EL is an upper-class, sparsely-populated residential neighborhood where most families live on large plots of land and in modern low-rise homes. Fewer people use biomass fuels in AD and EL than in JT and NM.\nZoom In\nZoom Out\nReset image size\nFigure 1. Study neighborhoods and measurement sites. The polygons on the central panel show census enumeration areas (EAs). Each EA has approximately the same population; hence the area of an EA is inversely related to population density. EAs are categorized according to quintile in terms of per cent of household using biomass fuels. Each color represents a different quintile. The sites were at locations that were typical of each neighborhood's living environment, with the EL site being far from major traffic and the AD site being next to a road with moderate traffic. In NM we also had a second site next to a road with heavy traffic. The distances of measurement sites to the ocean coast were: JT 0.5 km, AD 3 km, NM 4.5 km, and EL 9 km.\nDownload figure:\nStandard image High-resolution image Export PowerPoint slide\nBetween September 2007 and August 2008, we simultaneously operated five monitoring sites in four neighborhoods (JT, AD, NM-1, NM-2, and EL). Measurements were done for one 48-h period every six days. We also used geo-coded data from the Ghana Population and Housing Census on household socioeconomic status and fuel use and data from the Ghana Survey Department on road locations and types.\nPM mass concentrations were measured on a Mettler Toledo MT5 microbalance at the Harvard School of Public Health Laboratory. The elemental concentrations of the samples were quantified by energy dispersive x-ray fluorescence (ED-XRF) at the Institute of Astronomy, Geophysics and Atmospheric Science, University of Sao Paulo, Brazil. Measured elements in our study included sodium (Na), magnesium (Mg), aluminum (Al), silicon (Si), sulfur (S), chlorine (Cl), potassium (K), calcium (Ca), titanium (Ti), vanadium (V), chromium (Cr), nickel (Ni), manganese (Mn), iron (Fe), copper (Cu), zinc (Zn), bromine (Br), and lead (Pb). We converted the major crustal elements to their most abundant oxide forms as most of earth's crust consists of mineral oxides. We also converted sulfur (S) to sulfate (SO42−), the most common form in the atmosphere. Other elements, whose forms in the atmosphere vary by source, are reported in their elemental form. Gallium (Ga), selenium (Se), rubidium (Rb), yttrium (Y), niobium (Nb), barium (Ba), and hafnium (Hf) were excluded from the analysis because a relatively large number of the measured concentrations were below the limit of detection.\nBlack carbon (BC) concentrations were estimated primarily using data on reflectance coefficients. For 52 site-days, we also collected co-located PM samples on quartz fiber filters, which were used to directly measure BC concentrations. We used site-days with both direct measurement and data on reflectance coefficient to develop a regression equation that related the natural logarithm (ln) of BC concentration to the reflectance coefficient. The regression equation was then used to estimate the BC concentrations of the remaining samples whose reflectance, but not BC, had been measured. We used the positive matrix factorization (PMF) of the elemental mass to identify and quantify the sources of PM at five sites [ 9 ].\nDetails on methods for particle sample collection, measurement of total and elemental mass concentrations, and the PMF model are described in the supplementary material (available at stacks.iop.org/ERL/8/044025/mmedia ).\n3. Results\n3.1. Particle chemical composition\nParticle mass concentrations were reported elsewhere [ 10 ]. Here, we analyzed and report the elemental composition of PM2.5 and PM10; PM10 includes both fine and coarse fractions in the respirable range. Total particle mass, crustal components like SiO2, and to a lesser extent K peaked sharply in all neighborhoods between December and February (figure  2 ), the seasonal Harmattan period when northeast trade winds blow from the Sahara at an altitude of about 1500 m, carrying large amounts of Saharan dust and emissions from dry-season bushfires [ 2 – 4 ]. SO42− also had a strong seasonal pattern, peaking in January and August and being lowest in May and October. The latter months coincide with rainy seasons, when wet deposition helps remove the water-soluble SO42−. In contrast to these components, chlorine concentration changed little over time but had a noticeable spatial pattern, being highest in JT and lowest in EL; JT also had higher sodium (Na) concentrations; see tables  1 and 2 . JT is close to the ocean and hence has more particles from sea spray. Black carbon, K, and SO42− were also higher in JT, the neighborhood with the highest biomass use density (figure  1 ). K and SO42− are linked to biomass burning and BC to emissions from combustion sources including biomass smoke. Potassium in biomass smoke is emitted mostly as potassium salts such as KCl and K2SO4; with aging, most KCl particles are converted to K2SO4 [ 11 , 12 ].\nZoom In\nZoom Out\nReset image size\nFigure 2. Concentrations of total particle mass and of selected elements for (a) PM2.5 and (b) PM10 over the study period at the five measurement sites. Changes along the horizontal direction show variations over time and the spread along the vertical direction shows variation across measurement sites. For comparison, the World Health Organization (WHO) guideline for annual mean PM2.5 concentration is 10 μg m−3.\nDownload figure:\nTable 1.                    Average concentrations of total PM2.5 mass and its chemical components at five monitoring sites during the non-Harmattan months.\nChemical species\n49%\n49%\naUnits are in ng m−3 except for total mass, which is in μg m−3. bMean ± standard deviation. Numbers in parenthesis show the per cent of total mass. cThe 52 site-days with direct BC measurements using PM samples on quartz fiber filters also provided data on organic carbon (OC), measured following NIOSH Protocol 5040. For those 52 samples, OC accounted for 11–44% (mean 26%) of total PM mass. Mean OC/BC ratio in these samples was 1.7 (SD 0.6). In these samples, the correlation between OC and BC was around 0.6.\nTable 2.                    Average concentrations of total PM10 mass and its chemical components at five monitoring sites during the non-Harmattan months.\nChemical species\n54%\n53%\naUnits are in ng m−3 except for total mass, which is in μg m−3. bMean ± standard deviation. Numbers in parenthesis show the per cent of total mass.\nBetween 49% and 59% of PM10 mass was in the fine fraction at different sites (table  3 ). The proportion of mass in the fine fraction was below 40% for crustal oxides (MgO, Al2O3, SiO2, CaO, TiO2, MnO, and Fe2O3) and for elements in sea salt (Na and Cl), indicating that they were mostly in the form of coarse particles. In contrast, 60% or more of SO42−, K, Ni, Zn, Br, Pb and BC mass was in the fine fraction, which can penetrate deeper into lungs. These elements are mainly associated with biomass and solid waste burning, motor vehicle emissions, and industrial sources.\nTable 3.                    Average PM2.5-to-PM10 ratio of total PM mass and its chemical components at five monitoring sites during the non-Harmattan season.\nThere was strong correlation among the concentrations of crustal elements (tables S1 and S2, available at stacks.iop.org/ERL/8/044025/mmedia ), especially during Harmattan (correlation coefficients ≥0.9), when the Saharan dust falls on the city. During Harmattan, crustal elements were also highly correlated with total particle mass. Sea salt elements (Na and Cl) were also correlated with one another in non-Harmattan months, when a sea breeze is more frequent. Similarly, there was moderate correlation among Br, Pb, and Zn, which are all present in vehicle emissions, tire and brake wear, road dust, and in smoke generated from burning solid waste [ 13 , 14 ].\n3.2. Source contributions\nWe identified 5–6 potential sources for fine particles and 4–5 for PM10 at different sites during non-Harmattan months (figure  3 ). The estimated contributions of sea salt to total PM2.5 mass ranged between around 2 μg m−3 in NM-2 and EL (4.5 and 9 km from the coast) to 13.9 μg m−3 (25% of total PM2.5 mass) in JT (500 m from the coast) during non-Harmattan months. Similarly, sea salt contribution to PM10 was smallest in EL and largest in JT, accounting for 6.4 μg m−3 (14%) and 27.5 μg m−3 (31%) of total PM10 mass, respectively. In contrast to sea salt, crustal sources made up a larger share of total particle mass in EL, the northernmost neighborhood. For example 38% of PM2.5 and 46% of PM10 mass in EL were from crustal sources, compared to only 17% and 16% in JT. Despite having a larger share from crustal sources, lower total particle mass in EL meant that the absolute contribution of crustal aerosols was only slightly higher than other neighborhoods, e.g., 10.5 μg m−3 in PM2.5 compared to 9.5 μg m−3 in JT. This higher absolute contribution may have been because more spread-out low-rise homes do not block the windblown Saharan or local dust.\nZoom In\nZoom Out\nReset image size\nFigure 3. Contributions of pollution sources to particle mass during (a) non-Harmattan months, by neighborhood and (b) peak Harmattan (25 December 2007 to 30 January 30 2008). Sea salt is characterized primarily by Na, Cl, and S (in aged sea salt, the Cl ion is replaced by SO42− as a result of reaction with sulfuric acid; this chemical transformation is more pronounced in coastal areas than in inland regions [ 15 ]). Crustal sources are characterized by Si, Al, Mg, Ti, Mn and Fe. Biomass smoke is primarily characterized by K, Cl, S, and black carbon (BC) [ 12 ]. Road dust and traffic particles are characterized by Al, Si, Ca, Fe, and BC. Solid waste burning is characterized by Br [ 14 ]. During Harmattan, data from the five sites were pooled to increase sample size, after confirming that source profiles (but not contributions) were similar across sites.\nDownload figure:\nStandard image High-resolution image Export PowerPoint slide\nBiomass smoke contributed more particle pollution in NM and JT, where the density of households who use biomass fuels is substantially higher [ 6 ], than in AD and EL; biomass-related particles accounted for 15.7–21.3 μg m−3 of PM2.5 mass in the former two neighborhoods, compared to 10.6 μg m−3 in AD and 11.2 μg m−3 in EL. Road dust and traffic aerosols had a more important role in the two sites near traffic routes, one of NM's sites by a busy road and the AD site. A last source, which is likely to be burning of solid waste, was identified for fine particles in all neighborhoods except affluent EL, being largest in JT where old tires and other solid waste are commonly burned.\nThere was about 10 times as much particle mass from crustal sources during Harmattan as there had been in other months (figure  3 ). During Harmattan, there was also an increase in particle pollution from resuspended road dust and from biomass burning. The absolute amount of particle mass from other sources changed little, leading to a reduction in their share of total mass.\n4. Strengths and limitations\nTo our best knowledge, this paper uses one of the richest data sets on particle air pollution levels, chemical composition, and sources in a developing country city. The unique data come from our own measurements in poor and affluent neighborhoods and in different seasons, combined with data from the Population and Housing Census and the Survey Department, all with detailed geospatial information. The consistent and comparable data in poor and affluent neighborhoods alone allow us to examine, for the first time, how air pollution levels, composition, and sources differ in relation to socioeconomic status.\nSimilar to all field measurement studies, our work is affected by some limitations. Logistical difficulties and time-intensive field work restricted our ability to run multiple measurement sites simultaneously in each study neighborhood to assess within-neighborhood variation. It would have been desirable to conduct consecutive 48 h measurements, but this was beyond our resources.\nLimitations in the analysis include the reliance of source apportionment analysis on relatively stable source profiles across samples. In reality, source profiles may somewhat differ overtime, even at the same site. The choice of the number of PM sources is based on the best compromise between the goodness of model fit and the physical meaningfulness of the resolved factors; we tried the source apportionment with different numbers of factors and compared the results before selecting the current number of sources. In addition, labeling PM sources after PMF analysis also involves some subjectivity. All of these limitations should inform the design of future research on the sources of urban air pollution in cities in low- and middle-income countries where combustion and non-combustion sources are changing relatively rapidly.\n5. Discussion and conclusions\nOur findings on the chemical composition and sources of air pollution provide a number of important directions for air pollution control in rapidly expanding developing country cities like Accra. First, the role of urban biomass burning as a source of air pollution creates both policy complexities and opportunities. Large-scale transitions to cleaner fuels such as liquefied petroleum gas (LPG) may require targeted subsidies for fuel and/or financial assistance towards the initial cost of an LPG stove for poor households. Perhaps more importantly, sustained use of clean fuels requires improving the energy delivery and distribution infrastructure so that people can have regular trouble-free access to fuel purchase, currently not available in poor neighborhoods [ 6 ]. On the other hand, addressing household fuel use in cities can take advantage of high population density and urban infrastructure versus in rural areas, where long distances and poor roads and energy infrastructures make fuel switching more challenging. In addition to urban biomass use, long-range transport of particles from wild bushfires or from land clearing/preparation for agriculture by burning may be responsible for urban particle pollution in West Africa [ 16 ]. Reducing regional biomass pollution requires attention to land use and agriculture policies and should be accompanied by local strategies for wildfire management [ 17 ].\nSecond, while resuspended dust may seem outside the realm of policy interventions, local and regional strategies do exist: road and urban dust can be addressed through paving roads, traffic control, and, where affordable, regular road cleaning. Regional dust pollution is intensified by deforestation and desertification, and can be gradually reduced through afforestation and grassland restoration [ 18 – 21 ]. Beyond ecological considerations, such strategies should be connected with programs related to population growth and mobility, and those that improve the economic conditions of rural households who rely on land resources. The important role of seasonal dust as a pollution source also demonstrates the need for research on the acute and chronic health effects of exposure to crustal particles [ 22 , 23 ], and whether air pollution regulations in developing countries should be based on total particle mass or specifically target combustion sources.\nThird, while traffic sources accounted for a relatively small share of particle pollution in Accra, their absolute contribution towards PM2.5 was over 10 μg m−3 in some neighborhoods, larger than WHO guidelines for total PM2.5 concentration. If African cities follow Asian and Middle Eastern megacities, where traffic management and pollution is a major policy challenge, there will be even more traffic-related pollution. Curbing and reducing traffic air pollution will inevitably require a sustainable pro-poor public transportation system, as implemented in cities like Bogota [ 24 ]. African countries are a market for old cars that do not meet emissions standards in Europe and North America [ 25 ]. While the lower cost of used vehicles may help meet transportation needs in low-resource settings, there is a need to assess whether their economic benefits outweigh their health hazards, especially if the harms disproportionately affect poor urban communities relative to the benefits. Fourth, there was a larger contribution from burning of solid waste in poor neighborhoods, where trash collection is less frequent than in affluent neighborhoods. This demonstrates the need for equitable provision of urban services, now largely absent from poor slums.\nAir pollution regulation and technological advances related to emissions from vehicles, power plants, and factories, have led to cleaner cities in high-income countries. Some cities have also benefited from reducing pollution from local or regional dust, for example through sweeping and washing roads, stabilizing the road surface with dust suppressants, and planting trees. Lower particle pollution has in turn contributed to improved health [ 26 ]. The highest pollution levels, and about 90% of the global disease burden from air pollution, now occur outside the Americas and Europe [ 1 , 27 ]. Therefore, while efforts to further reduce air pollution in these regions continue, there is an urgent need to tackle air pollution in cities in the developing world. The diversity of sources demonstrates the need for integration of policies and interventions across environment, energy, transportation, urban development and even forestry and agriculture sectors, while explicitly considering the benefits and harms of each strategy for poor communities. The post-2015 Development Agenda provides an opportunity for such integration if urban environment and urban poverty take a central role in the discussions and the recommended policies and related targets.\nAcknowledgments\nWe thank the residents of Jamestown/Ushertown, Asylum Down, Nima, and East Legon for their hospitality; Nana Prempeh and Adam Abdul Fatah for field assistance; and the Legal Resources Center and the Department of Geography and Resource Development at the University of Ghana for valuable help with logistical arrangements. Funding for field data collection was provided by National Science Foundation Grant 0527536, and laboratory support was provided by the Harvard National Institute on Environmental Health Sciences Center for Environmental Health. Majid Ezzati is supported by a UK MRC Strategic Award. This research was approved by Institutional Review Boards of the Harvard School of Public Health and Noguchi Memorial Institute for Medical Research at the University of Ghana.\nReferences\n""","0.336246","""http://iopscience.iop.org/article/10.1088/1748-9326/8/4/044025/meta""","[-0.178219,51.500505]"
"""Imperial_College_London""","""Chemical composition and sources of particle pollution in affluent and poor neighborhoods of Accra, Ghana - IOPscience""","""Letter • OPEN ACCESS • IOPselect\nChemical composition and sources of particle pollution in affluent and poor neighborhoods of Accra, Ghana\nZheng Zhou1,2, Kathie L Dionisio1,2, Thiago G Verissimo3, Americo S Kerr3, Brent Coull2,4, Raphael E Arku2, Petros Koutrakis2, John D Spengler2, Allison F Hughes5, Jose Vallarino2, Samuel Agyei-Mensah6 and Majid Ezzati7\nPublished 30 October 2013 • 2013 IOP Publishing Ltd\n1 Department of Global Health and Population, Harvard School of Public Health, Boston, MA, USA\n2 Department of Environmental Health, Harvard School of Public Health, Boston, MA, USA\n3 Institute of Physics, University of Sao Paulo, Sao Paulo, Brazil\n4 Department of Biostatistics, Harvard School of Public Health, Boston, MA, USA\n5 Department of Physics, University of Ghana, Legon, Ghana\n6 Department of Geography and Resource Development, University of Ghana, Legon, Ghana\n7 Medical Research Council–Public Health England Centre for Environment and Health, Department of Epidemiology and Biostatistics, School of Public Health, Imperial College London, UK\nDates\nView all Environ. Res. Lett. video abstracts\nThe highest levels of air pollution in the world now occur in developing country cities, where air pollution sources differ from high-income countries. We analyzed particulate matter (PM) chemical composition and estimated the contributions of various sources to particle pollution in poor and affluent neighborhoods of Accra, Ghana. Elements from earth's crust were most abundant during the seasonal Harmattan period between late December and late January when Saharan dust is carried to coastal West Africa. During Harmattan, crustal particles accounted for 55 μg m−3 (37%) of fine particle (PM2.5) mass and 128 μg m−3 (42%) of PM10 mass. Outside Harmattan, biomass combustion, which was associated with higher black carbon, potassium, and sulfur, accounted for between 10.6 and 21.3 μg m−3 of fine particle mass in different neighborhoods, with its contribution largest in the poorest neighborhood. Other sources were sea salt, vehicle emissions, tire and brake wear, road dust, and solid waste burning. Reducing air pollution in African cities requires policies related to energy, transportation and urban planning, and forestry and agriculture, with explicit attention to impacts of each strategy in poor communities. Such cross-sectoral integration requires emphasis on urban environment and urban poverty in the post-2015 Development Agenda.\nExport citation and abstract\nSupplementary data\n1. Introduction\nThe highest levels of air pollution in the world now occur  in cities in Asia, Middle East, and Africa [ 1 ]. In these settings, the concentrations of fine particles (less than 2.5 μm in aerodynamic diameter; PM2.5), which are associated with hazardous effects on health, approach or reach 100 μg m−3, compared to less than 20 μg m−3 in most European and North American cities [ 1 ]. The sources of air pollution in developing country cities include those that are common in high-income nations, e.g., vehicle emissions, as well as biomass and coal combustion for household and commercial purposes and resuspended dust from unpaved roads. In coastal West Africa, sea salt and long-range-transported Saharan dust may also be sources of particles in some seasons [ 2 – 4 ]. Yet little is known about the relative contributions of these sources to pollution levels in African cities, where the urban population is growing faster than any other region; neither is it known how the source diversity affects particle chemistry, which may in turn affect both health hazards and impacts on anthropogenic climate change.\nWe conducted a study in Accra, Ghana, one of Africa's fastest growing cities to understand the levels, chemical properties, and sources of particle pollution. Three quarters of sub-Saharan Africa's population use biomass fuels as their main source of energy, including over one half of urban households [ 5 , 6 ]. In Accra, and other developing country cities, there are significant differences in road conditions, traffic patterns, and fuel use between the affluent neighborhoods and poor 'slum' areas [ 6 – 8 ]. For this reason, we collected data at sites located in poor and affluent neighborhoods.\n2. Materials and methods\nWe collected particulate matter (PM) samples between September 2007 and August 2008 in four neighborhoods of varying degrees of poverty and affluence. The four neighborhoods lie on a line from the coast to Accra's northern boundaries: James Town/Usher Town (JT), Asylum Down (AD), Nima (NM) and East Legon (EL) (figure  1 ). JT and NM are densely populated low-income communities where most residents use biomass for cooking at home and for street food. AD is a middle-class neighborhood and EL is an upper-class, sparsely-populated residential neighborhood where most families live on large plots of land and in modern low-rise homes. Fewer people use biomass fuels in AD and EL than in JT and NM.\nZoom In\nZoom Out\nReset image size\nFigure 1. Study neighborhoods and measurement sites. The polygons on the central panel show census enumeration areas (EAs). Each EA has approximately the same population; hence the area of an EA is inversely related to population density. EAs are categorized according to quintile in terms of per cent of household using biomass fuels. Each color represents a different quintile. The sites were at locations that were typical of each neighborhood's living environment, with the EL site being far from major traffic and the AD site being next to a road with moderate traffic. In NM we also had a second site next to a road with heavy traffic. The distances of measurement sites to the ocean coast were: JT 0.5 km, AD 3 km, NM 4.5 km, and EL 9 km.\nDownload figure:\nStandard image High-resolution image Export PowerPoint slide\nBetween September 2007 and August 2008, we simultaneously operated five monitoring sites in four neighborhoods (JT, AD, NM-1, NM-2, and EL). Measurements were done for one 48-h period every six days. We also used geo-coded data from the Ghana Population and Housing Census on household socioeconomic status and fuel use and data from the Ghana Survey Department on road locations and types.\nPM mass concentrations were measured on a Mettler Toledo MT5 microbalance at the Harvard School of Public Health Laboratory. The elemental concentrations of the samples were quantified by energy dispersive x-ray fluorescence (ED-XRF) at the Institute of Astronomy, Geophysics and Atmospheric Science, University of Sao Paulo, Brazil. Measured elements in our study included sodium (Na), magnesium (Mg), aluminum (Al), silicon (Si), sulfur (S), chlorine (Cl), potassium (K), calcium (Ca), titanium (Ti), vanadium (V), chromium (Cr), nickel (Ni), manganese (Mn), iron (Fe), copper (Cu), zinc (Zn), bromine (Br), and lead (Pb). We converted the major crustal elements to their most abundant oxide forms as most of earth's crust consists of mineral oxides. We also converted sulfur (S) to sulfate (SO42−), the most common form in the atmosphere. Other elements, whose forms in the atmosphere vary by source, are reported in their elemental form. Gallium (Ga), selenium (Se), rubidium (Rb), yttrium (Y), niobium (Nb), barium (Ba), and hafnium (Hf) were excluded from the analysis because a relatively large number of the measured concentrations were below the limit of detection.\nBlack carbon (BC) concentrations were estimated primarily using data on reflectance coefficients. For 52 site-days, we also collected co-located PM samples on quartz fiber filters, which were used to directly measure BC concentrations. We used site-days with both direct measurement and data on reflectance coefficient to develop a regression equation that related the natural logarithm (ln) of BC concentration to the reflectance coefficient. The regression equation was then used to estimate the BC concentrations of the remaining samples whose reflectance, but not BC, had been measured. We used the positive matrix factorization (PMF) of the elemental mass to identify and quantify the sources of PM at five sites [ 9 ].\nDetails on methods for particle sample collection, measurement of total and elemental mass concentrations, and the PMF model are described in the supplementary material (available at stacks.iop.org/ERL/8/044025/mmedia ).\n3. Results\n3.1. Particle chemical composition\nParticle mass concentrations were reported elsewhere [ 10 ]. Here, we analyzed and report the elemental composition of PM2.5 and PM10; PM10 includes both fine and coarse fractions in the respirable range. Total particle mass, crustal components like SiO2, and to a lesser extent K peaked sharply in all neighborhoods between December and February (figure  2 ), the seasonal Harmattan period when northeast trade winds blow from the Sahara at an altitude of about 1500 m, carrying large amounts of Saharan dust and emissions from dry-season bushfires [ 2 – 4 ]. SO42− also had a strong seasonal pattern, peaking in January and August and being lowest in May and October. The latter months coincide with rainy seasons, when wet deposition helps remove the water-soluble SO42−. In contrast to these components, chlorine concentration changed little over time but had a noticeable spatial pattern, being highest in JT and lowest in EL; JT also had higher sodium (Na) concentrations; see tables  1 and 2 . JT is close to the ocean and hence has more particles from sea spray. Black carbon, K, and SO42− were also higher in JT, the neighborhood with the highest biomass use density (figure  1 ). K and SO42− are linked to biomass burning and BC to emissions from combustion sources including biomass smoke. Potassium in biomass smoke is emitted mostly as potassium salts such as KCl and K2SO4; with aging, most KCl particles are converted to K2SO4 [ 11 , 12 ].\nZoom In\nZoom Out\nReset image size\nFigure 2. Concentrations of total particle mass and of selected elements for (a) PM2.5 and (b) PM10 over the study period at the five measurement sites. Changes along the horizontal direction show variations over time and the spread along the vertical direction shows variation across measurement sites. For comparison, the World Health Organization (WHO) guideline for annual mean PM2.5 concentration is 10 μg m−3.\nDownload figure:\nTable 1.                    Average concentrations of total PM2.5 mass and its chemical components at five monitoring sites during the non-Harmattan months.\nChemical species\n49%\n49%\naUnits are in ng m−3 except for total mass, which is in μg m−3. bMean ± standard deviation. Numbers in parenthesis show the per cent of total mass. cThe 52 site-days with direct BC measurements using PM samples on quartz fiber filters also provided data on organic carbon (OC), measured following NIOSH Protocol 5040. For those 52 samples, OC accounted for 11–44% (mean 26%) of total PM mass. Mean OC/BC ratio in these samples was 1.7 (SD 0.6). In these samples, the correlation between OC and BC was around 0.6.\nTable 2.                    Average concentrations of total PM10 mass and its chemical components at five monitoring sites during the non-Harmattan months.\nChemical species\n54%\n53%\naUnits are in ng m−3 except for total mass, which is in μg m−3. bMean ± standard deviation. Numbers in parenthesis show the per cent of total mass.\nBetween 49% and 59% of PM10 mass was in the fine fraction at different sites (table  3 ). The proportion of mass in the fine fraction was below 40% for crustal oxides (MgO, Al2O3, SiO2, CaO, TiO2, MnO, and Fe2O3) and for elements in sea salt (Na and Cl), indicating that they were mostly in the form of coarse particles. In contrast, 60% or more of SO42−, K, Ni, Zn, Br, Pb and BC mass was in the fine fraction, which can penetrate deeper into lungs. These elements are mainly associated with biomass and solid waste burning, motor vehicle emissions, and industrial sources.\nTable 3.                    Average PM2.5-to-PM10 ratio of total PM mass and its chemical components at five monitoring sites during the non-Harmattan season.\nThere was strong correlation among the concentrations of crustal elements (tables S1 and S2, available at stacks.iop.org/ERL/8/044025/mmedia ), especially during Harmattan (correlation coefficients ≥0.9), when the Saharan dust falls on the city. During Harmattan, crustal elements were also highly correlated with total particle mass. Sea salt elements (Na and Cl) were also correlated with one another in non-Harmattan months, when a sea breeze is more frequent. Similarly, there was moderate correlation among Br, Pb, and Zn, which are all present in vehicle emissions, tire and brake wear, road dust, and in smoke generated from burning solid waste [ 13 , 14 ].\n3.2. Source contributions\nWe identified 5–6 potential sources for fine particles and 4–5 for PM10 at different sites during non-Harmattan months (figure  3 ). The estimated contributions of sea salt to total PM2.5 mass ranged between around 2 μg m−3 in NM-2 and EL (4.5 and 9 km from the coast) to 13.9 μg m−3 (25% of total PM2.5 mass) in JT (500 m from the coast) during non-Harmattan months. Similarly, sea salt contribution to PM10 was smallest in EL and largest in JT, accounting for 6.4 μg m−3 (14%) and 27.5 μg m−3 (31%) of total PM10 mass, respectively. In contrast to sea salt, crustal sources made up a larger share of total particle mass in EL, the northernmost neighborhood. For example 38% of PM2.5 and 46% of PM10 mass in EL were from crustal sources, compared to only 17% and 16% in JT. Despite having a larger share from crustal sources, lower total particle mass in EL meant that the absolute contribution of crustal aerosols was only slightly higher than other neighborhoods, e.g., 10.5 μg m−3 in PM2.5 compared to 9.5 μg m−3 in JT. This higher absolute contribution may have been because more spread-out low-rise homes do not block the windblown Saharan or local dust.\nZoom In\nZoom Out\nReset image size\nFigure 3. Contributions of pollution sources to particle mass during (a) non-Harmattan months, by neighborhood and (b) peak Harmattan (25 December 2007 to 30 January 30 2008). Sea salt is characterized primarily by Na, Cl, and S (in aged sea salt, the Cl ion is replaced by SO42− as a result of reaction with sulfuric acid; this chemical transformation is more pronounced in coastal areas than in inland regions [ 15 ]). Crustal sources are characterized by Si, Al, Mg, Ti, Mn and Fe. Biomass smoke is primarily characterized by K, Cl, S, and black carbon (BC) [ 12 ]. Road dust and traffic particles are characterized by Al, Si, Ca, Fe, and BC. Solid waste burning is characterized by Br [ 14 ]. During Harmattan, data from the five sites were pooled to increase sample size, after confirming that source profiles (but not contributions) were similar across sites.\nDownload figure:\nStandard image High-resolution image Export PowerPoint slide\nBiomass smoke contributed more particle pollution in NM and JT, where the density of households who use biomass fuels is substantially higher [ 6 ], than in AD and EL; biomass-related particles accounted for 15.7–21.3 μg m−3 of PM2.5 mass in the former two neighborhoods, compared to 10.6 μg m−3 in AD and 11.2 μg m−3 in EL. Road dust and traffic aerosols had a more important role in the two sites near traffic routes, one of NM's sites by a busy road and the AD site. A last source, which is likely to be burning of solid waste, was identified for fine particles in all neighborhoods except affluent EL, being largest in JT where old tires and other solid waste are commonly burned.\nThere was about 10 times as much particle mass from crustal sources during Harmattan as there had been in other months (figure  3 ). During Harmattan, there was also an increase in particle pollution from resuspended road dust and from biomass burning. The absolute amount of particle mass from other sources changed little, leading to a reduction in their share of total mass.\n4. Strengths and limitations\nTo our best knowledge, this paper uses one of the richest data sets on particle air pollution levels, chemical composition, and sources in a developing country city. The unique data come from our own measurements in poor and affluent neighborhoods and in different seasons, combined with data from the Population and Housing Census and the Survey Department, all with detailed geospatial information. The consistent and comparable data in poor and affluent neighborhoods alone allow us to examine, for the first time, how air pollution levels, composition, and sources differ in relation to socioeconomic status.\nSimilar to all field measurement studies, our work is affected by some limitations. Logistical difficulties and time-intensive field work restricted our ability to run multiple measurement sites simultaneously in each study neighborhood to assess within-neighborhood variation. It would have been desirable to conduct consecutive 48 h measurements, but this was beyond our resources.\nLimitations in the analysis include the reliance of source apportionment analysis on relatively stable source profiles across samples. In reality, source profiles may somewhat differ overtime, even at the same site. The choice of the number of PM sources is based on the best compromise between the goodness of model fit and the physical meaningfulness of the resolved factors; we tried the source apportionment with different numbers of factors and compared the results before selecting the current number of sources. In addition, labeling PM sources after PMF analysis also involves some subjectivity. All of these limitations should inform the design of future research on the sources of urban air pollution in cities in low- and middle-income countries where combustion and non-combustion sources are changing relatively rapidly.\n5. Discussion and conclusions\nOur findings on the chemical composition and sources of air pollution provide a number of important directions for air pollution control in rapidly expanding developing country cities like Accra. First, the role of urban biomass burning as a source of air pollution creates both policy complexities and opportunities. Large-scale transitions to cleaner fuels such as liquefied petroleum gas (LPG) may require targeted subsidies for fuel and/or financial assistance towards the initial cost of an LPG stove for poor households. Perhaps more importantly, sustained use of clean fuels requires improving the energy delivery and distribution infrastructure so that people can have regular trouble-free access to fuel purchase, currently not available in poor neighborhoods [ 6 ]. On the other hand, addressing household fuel use in cities can take advantage of high population density and urban infrastructure versus in rural areas, where long distances and poor roads and energy infrastructures make fuel switching more challenging. In addition to urban biomass use, long-range transport of particles from wild bushfires or from land clearing/preparation for agriculture by burning may be responsible for urban particle pollution in West Africa [ 16 ]. Reducing regional biomass pollution requires attention to land use and agriculture policies and should be accompanied by local strategies for wildfire management [ 17 ].\nSecond, while resuspended dust may seem outside the realm of policy interventions, local and regional strategies do exist: road and urban dust can be addressed through paving roads, traffic control, and, where affordable, regular road cleaning. Regional dust pollution is intensified by deforestation and desertification, and can be gradually reduced through afforestation and grassland restoration [ 18 – 21 ]. Beyond ecological considerations, such strategies should be connected with programs related to population growth and mobility, and those that improve the economic conditions of rural households who rely on land resources. The important role of seasonal dust as a pollution source also demonstrates the need for research on the acute and chronic health effects of exposure to crustal particles [ 22 , 23 ], and whether air pollution regulations in developing countries should be based on total particle mass or specifically target combustion sources.\nThird, while traffic sources accounted for a relatively small share of particle pollution in Accra, their absolute contribution towards PM2.5 was over 10 μg m−3 in some neighborhoods, larger than WHO guidelines for total PM2.5 concentration. If African cities follow Asian and Middle Eastern megacities, where traffic management and pollution is a major policy challenge, there will be even more traffic-related pollution. Curbing and reducing traffic air pollution will inevitably require a sustainable pro-poor public transportation system, as implemented in cities like Bogota [ 24 ]. African countries are a market for old cars that do not meet emissions standards in Europe and North America [ 25 ]. While the lower cost of used vehicles may help meet transportation needs in low-resource settings, there is a need to assess whether their economic benefits outweigh their health hazards, especially if the harms disproportionately affect poor urban communities relative to the benefits. Fourth, there was a larger contribution from burning of solid waste in poor neighborhoods, where trash collection is less frequent than in affluent neighborhoods. This demonstrates the need for equitable provision of urban services, now largely absent from poor slums.\nAir pollution regulation and technological advances related to emissions from vehicles, power plants, and factories, have led to cleaner cities in high-income countries. Some cities have also benefited from reducing pollution from local or regional dust, for example through sweeping and washing roads, stabilizing the road surface with dust suppressants, and planting trees. Lower particle pollution has in turn contributed to improved health [ 26 ]. The highest pollution levels, and about 90% of the global disease burden from air pollution, now occur outside the Americas and Europe [ 1 , 27 ]. Therefore, while efforts to further reduce air pollution in these regions continue, there is an urgent need to tackle air pollution in cities in the developing world. The diversity of sources demonstrates the need for integration of policies and interventions across environment, energy, transportation, urban development and even forestry and agriculture sectors, while explicitly considering the benefits and harms of each strategy for poor communities. The post-2015 Development Agenda provides an opportunity for such integration if urban environment and urban poverty take a central role in the discussions and the recommended policies and related targets.\nAcknowledgments\nWe thank the residents of Jamestown/Ushertown, Asylum Down, Nima, and East Legon for their hospitality; Nana Prempeh and Adam Abdul Fatah for field assistance; and the Legal Resources Center and the Department of Geography and Resource Development at the University of Ghana for valuable help with logistical arrangements. Funding for field data collection was provided by National Science Foundation Grant 0527536, and laboratory support was provided by the Harvard National Institute on Environmental Health Sciences Center for Environmental Health. Majid Ezzati is supported by a UK MRC Strategic Award. This research was approved by Institutional Review Boards of the Harvard School of Public Health and Noguchi Memorial Institute for Medical Research at the University of Ghana.\nReferences\n""","0.336246","""http://iopscience.iop.org/article/10.1088/1748-9326/8/4/044025/meta;jsessionid=1D70779DE8C3BF42A901D43B8A45DE6B.c4.iopscience.cld.iop.org""","[-0.178219,51.500505]"
"""Imperial_College_London""","""Realising transition pathways for a more electric, low-carbon energy system in the United Kingdom: Challenges, insights and opportunitiesProceedings of the Institution of Mechanical Engineers, Part A: Journal of Power and Energy - Jason Chilvers, Timothy J Foxon, Stuart Galloway, Geoffrey P Hammond, David Infield, Matthew Leach, Peter JG Pearson, Neil Strachan, Goran Strbac, Murray Thomson, 2017""","""Figure 5. The dynamic relationship between energy security, framing of energy and governance logics.\nSource: Johnson et al. 30\nShifting views about how security affected the framing of energy emerged between WWI and WWII; leading to the prevalence again of hybrid governance. A relational approach was used by Johnson et al. 30 to explore the emergence of policy support for fuels and their final withdrawal. That showed how and why emerging technological substitutes can founder and transitions fail in times of economic instability. It led to shifting hybrid state and market governance between incumbents (i.e. the oil majors) and newcomers (e.g. DCL and ICI). These studies consequently reflect a partial historical analogue for the hybrid roles of the state and the market in energy governance (e.g. UK Electricity Market Reform (EMR)), as well as the changing priorities within the energy policy trilemma between climate change mitigation and the provision of secure and affordable energy services. The case studies also provide insights about technological substitutes and new infrastructures (electrifying transport and heat), as well as concerns about the influence of incumbent actors and institutions influence to either advance or constrain low-carbon transitions.\nA further supply-side study of the development of the integrated UK natural gas system over the period 1960–2010 by Arapostathis et al. 31 has illustrated the way in which such integration was closely linked to governance patterns. This explored the development of the gas system in two transitions: (i) from town to natural gas with state governance logic (under the management of the nationalised British Gas Corporation); and (ii) then privatisation and liberalisation after 1987. The latter major structural change is regulated by Ofgem, with a Uniform Network Code (UNC) overseen by the Joint Office of Gas Transporters. Vertical integration has been aided by new control and communication technologies, together with internationalisation via gas interconnectors. That reduced uncertainties, but increased the system’s complexity. This case study 31 provided an analogue for the challenges of integrating large, infrastructural technical systems for a sustainability transition. It is inscribed within the MLP approach yet concentrates on system integration as a complex and uncertain socio-technical process. It indicates how quite dramatic changes in the UK natural gas structure are mirrored in regime formation (see Figure 1 ).\nLittle historical work has been undertaken on energy demand reduction. A study of electric heating in early post-war Britain 32 when electric fires were used at peak times and were therefore particularly problematic in terms of energy end-use, offers insights into the challenges often associated with demand reduction. The Electricity Development Association (EDA), originally established as a public relations arm of the UK electricity industry, tried simultaneously to reduce undesirable peak demand, whilst encouraging increased demand more generally. In the late 1940s, it recommended that electric fires should not be used to meet peak demand. However, in the 1950s and 1960s it concentrated on promoting off-peak heating appliances. It first sought to do this in the United Kingdom via under-floor heating, and then block storage heaters typically composed of clay bricks or other ceramic material. The study under the auspices of the transition pathways consortium by Carlsson-Hyslop 32 analysed the way in which the London County Council (LCC) and its tenants adopted and adapted electric underfloor heating. It concluded that attempts by the electricity industry during the period 1945–1964 had only a limited effect on the trend towards rising energy end-use demand. This was, in part, due to EDA promotional efforts. This analysis is consistent with that on households’ engagement with customer-facing elements of a smarter grid, such as smart meters or energy monitors (see, e.g. a predecessor consortium study by Hargreaves et al. 33 ). Social variables like daily routines, individual preferences and social relations in a household were found by Hargreaves et al. 33 to be important for energy demand reduction. This may reflect a co-evolution of technology with social practices, changing routines, and behaviour. It illustrates the kinds of processes, practices, interactions and modes of governance that need to be considered if demand management/energy efficiency are to succeed in containing energy use and GHGs, whilst enhancing the quality of people’s lives.\nPolicy makers tend to have little institutional memory of what has worked or has not worked in terms of energy sector interventions, because job changes are used to enable UK civil servants to gain experience and avoid accumulating positional or departmental loyalty, and because ministers often serve for short periods (from 2008 to 2015 of the four Secretaries of State for Energy and Climate Change, one served for less than 2 years and another for just over 1 year). Historical analyses/stories of past transitions therefore help them (and other stakeholders) to understand how and why transitions have previously succeeded or failed. They also indicate how long they can take to implement and the reasons why. Overall insights and lessons from such studies can be summarised as:\nThe historical studies have shown that rapid change is possible, but not necessarily frequent. It may require a recognition of the need to change, openness to experiment and a high degree of co-ordination (e.g. the natural gas transition). These studies illustrate how co-evolutionary and co-constructed are the material or physical aspects with the social, political and institutional aspects. For example, the 1966–1977 conversion from town gas to natural gas required both technical changes, including building the national gas grid and installing new burners in millions of gas appliances, along with major institutional reorganisation, new workforce training and political support. 31\nHistorical studies of two alternatives to petrol in the inter-war period 30 show how and why emerging technological substitutes can founder and potential transitions fail in times of economic instability, shifting governance and competition between incumbents and newcomers.\nA further supply-side study of the development of the integrated UK natural gas system over the period 1960–201031 suggests that such integration was closely linked to governance patterns. It indicated how quite dramatic changes in the UK natural gas structure are largely reflected in regime formation and change.\nThere is little historical work on demand reduction. However, the recent study of the EDA and domestic electric heating in post-war Britain 32 suggests that their attempts had limited impacts on the trend of rising demand, and thereby illustrates the challenges facing demand reduction today.\nHorizon scanning and technology assessment of energy systems\nSection:\nTechnological choices in the UK power sector are likely to vary significantly out to 2050. For example, over the last few years the outlook for both coal-fired power stations with CCS and nuclear power has changed dramatically. The UK Government indicated (in November 2015) their wish to phase out unabated coal-fired power stations by 2025, and giving new gas-fired power stations priority. Likewise, the prospects of new nuclear build has been hit by both concerns following the 2011 Fukushima disaster in Japan and a reassessment of the economics of nuclear power by some of the big players, such as the investment decision by the French utility eDF Energy in regard to the construction of the Hinkley Point C nuclear power plant (in Somerset). These short-term changes in attitudes to low-carbon technologies mean that the technology choices implicit in each of the existing pathways need to be kept under continuous review. Horizon scanning involves a portfolio of methods that enable energy researchers and other power sector stakeholders to increase their awareness of important emerging influences on the UK energy system and its environment. It provides a major strand in proactive risk management 11 and strategic thinking as the UK energy sector moves forward. Parker et al., 34 for example, used a modified Delphi technique for horizon scanning in order to identify some 30 emergent policy issues, which strongly featured science and technology, and which would necessitate public engagement as the policies were being developed. This was driven, in part, by concerns over the use of hydraulic fracturing (or fracking) by fossil fuel companies for shale gas extraction in the United Kingdom. A disparate group of people with interests over the science and policy interface (e.g. policy makers and advisers, academics and the private sector) initially elicited a long list of issues. These were then refined into a shorter list that were viewed as being of top priority for policy makers. They included challenges related to energy and environment, such as policies concerning interdisciplinary whole energy systems science (incorporated by a partner in the Realising Transition Pathways Consortium (Jason Chilvers) 34 ). A variety of alternative techniques are available for use in identifying emerging issues in the UK energy sector. Arup Foresight (part of the independent firm of designers, planners, engineers and consultants) have, for example, employed STEEP (social, technological, economic, environmental, political) analysis to examine drivers for change in both the energy and climate change fields. The Realising Transition Pathways Consortium have used a similar approach, in conjunction with more formal methods of Technology Assessment 35 , 36 to evaluate a number of the main disruptive energy technologies. These studies have sought to identify the components of a balance sheet of technological credits and debits in order to evaluate their societal impacts, and to determine whether they are compatible with Britain’s move towards a low-carbon future in 2050 and beyond.\nIndicative energy technology assessments (ETAs) have been carried out for a variety of energy technologies, e.g. UK shale gas extraction, 37 carbon capture and storage (CCS), 38 , 39 advanced rechargeable batteries, 40 rare earth elements (REE) as a constraint on clean energy technologies, 41 nuclear power plants 42 and tidal power barrages. 43 These ETAs were all indicative in the sense of being a simplified evaluation and illustration of the performance of state-of-the-art devices. Nevertheless, such assessments provide a valuable evidence base for developers, policy makers and other stakeholders. Each technology was evaluated using a combination of quantitative and qualitative methods within the spirit of the STEEP approach. The most controversial of these studies was arguably that concerning the benefits and ‘costs’ of shale gas fracking in Britain. 34 , 37 Exploratory drilling in the United Kingdom is at an early stage, with great uncertainty over the scale of the potential shale gas resource. 37 However, such activities are already meeting fierce community resistance. Like all energy technologies, it exhibits unwanted side-effects that simply differ in their level of severity compared to other options. Successful extraction might contribute positively in terms of fuel security and independence, as well as jobs and growth. 37 Shale gas may also make a contribution to attaining the UK’s statutory GHG emissions targets, although potentially harmful environmental impacts need to be satisfactorily resolved via appropriate monitoring and robust regulation. It is unlikely that gas bills for UK household and industrial consumers would fall dramatically as they have done in North America, because Britain is linked to the wider European gas market. Anything produced in the United Kingdom would be a ‘drop in the ocean’ compared to imports via either pipelines or by way of liquefied natural gas (LNG) tankers. Finally, the socio-economic advantages and disadvantages of shale gas fracking are not evenly distributed between various communities and demographic groups. 37 Community engagement in a genuinely participative process – where the government is prepared to change course in response to the evidence and public opinion – will consequently be critically important for the adoption of any new energy option.\nCCS facilities coupled to fossil fuelled power plants or industrial sites provide a key climate change mitigation strategy that potentially permits the continued use of fossil fuel resources, whilst reducing the CO2 emissions. Hammond and Spargo 39 highlight the potential design routes for the capture, transport, clustering and storage of CO2 from UK power plants. Both currently available and novel CCS technologies were evaluated. Due to lower operating efficiencies, the CCS plants showed a longer energy payback period and a lower energy gain ratio than conventional plant. There are also several technical and financial obstacles that need to be overcome, 38 including the adoption of an appropriate legislative framework and the need for full CCS chain risk assessments. There are uncertainties over the full-scale power plant CCS technical performance and costs, which may only become clearer when the first demonstrators are operational. Unfortunately, the UK Government cancelled (on 25 November 2015) their £1 bn CCS competition shortly before the winning consortium was due to be announced. Inevitably, the bidding companies were dismayed by this outcome and the prospects for CCS in Britain in the short term now looks rather bleak. Prior to this, the Government had established a CCS Cost Reduction Task Force 44 as an industry-led joint venture to assist with the challenge of making CCS a commercially viable operation by the early 2020s. The main cost-reduction opportunities were seen as being 44 : (i) transport and storage scale and utilisation, (ii) improved financeability for the CCS chain, and finally (iii) improved engineering designs and performance. Greater financial incentives for carbon abatement could, in principal, be secured through a higher carbon price from the European Union Emissions Trading Scheme (EU ETS), although that has been a significant disappointment in terms of the carbon price level. A collaborative study between the Energy Technologies Institute (ETI), a public-private partnership of key industrial companies and UK funders of energy RD&D, and the Ecofin Research Foundation (ERF) 45 has recently examined the conditions required for mobilising private sector financing of CCS in the United Kingdom. They argue that this technology would be a ‘huge prize’ that could cut the annual costs of meeting the 2050 carbon target by up to 1% of gross domestic product (GDP). 38 , 39 , 45 But they noted that the prevailing financial market conditions are demanding. In order to meet this challenge, they suggest that the United Kingdom needs to build confidence in long-term policy, develop attractive pricing for CCS contracts with suitable risk sharing, put in place an appropriate regulatory and market framework, and devise new ways to offset North Sea storage liability risks. 45 Many believe that the UK Government will need to return to CCS deployment in order to meet its 2050 GHG emissions reduction target in a cost-effective way. 46\nTwo other large-scale power generators that could be available to help secure a low-carbon future for the United Kingdom are nuclear power plants 42 and tidal barrages. 43 The lives of existing nuclear plant has typically been extended to around 40 years (e.g. Hunterston B was financed for 25 years with an expectation of 35 years, and subsequently extended by 7 years). Nevertheless Britain, as with other nuclear-powered European countries, will be progressively decommissioning its older nuclear power stations during the next decade or so. This will leave only the Sizewell B pressurised water reactor (PWR) station in the United Kingdom, with nuclear power holding a considerably reduced share of electricity generation (perhaps as low as 3% by 2020 from around 20% in the winter of 2013–2014). A new generation of nuclear power stations may therefore need to be part of the power generation mix in order to decarbonise the electricity sector by around 2030–2050. In Europe these plants are likely to be variants of the third-generation European pressurised reactor (EPR) design. Emerging (novel) nuclear reactor designs are thought to be inherently safer and less costly 42 ; perhaps having a 25% lower generating cost than present systems. However, the research by the former UK Sustainable Development Commission 47 suggests that a doubling of Britain’s existing nuclear capacity would only yield an 8% cut on CO2 emissions by 2035. Over the longer term, it is likely that the European governments will want to keep a watching brief on advanced nuclear reactors (including modular designs) that are currently being developed in France/Germany, South Africa and the United States. Nevertheless, they will no doubt want to be reassured that such new technologies will be commercially viable. 42 The adoption of either short- or medium-term technologies would obviously be critically dependent on public attitudes to nuclear power in Britain and elsewhere. 1 , 11 , 42 Both the Cardiff-Weston and the smaller Shoots barrages on the River Severn between Somerset and south Wales have been evaluated by Hammond et al. 43 using various ETA techniques to determine their net energy output, carbon footprint and financial investment criteria, alongside various critical technical and environmental issues. These tidal power schemes were assessed over their foreseen lifespan of 120 years in terms of its cradle-to-site, operation and maintenance requirements. The proposed Cardiff-Weston Barrage would yield relatively attractive figures of merit in terms of its net energy and carbon emissions, although its financial performance is poorer than alternative power generators. Comparisons were made with the much smaller, Shoots Barrage scheme that would be located up-river of the Severn road crossings, and which is favoured by environmental groups, because of its more benign ecological and environmental impacts. 43\nThe suitability of advanced rechargeable battery technologies (ARBT) for different applications, such as electric vehicles (EV), consumer electronics, load levelling and stationary power storage, has been the subject of another ETA. 40 These energy storage devices were compared to more mature nickel–cadmium (Ni–Cd) batteries in order to gain a sense of perspective regarding the performance of the ARBT. Lithium (Li)-ion batteries (LIB) currently dominate the rechargeable battery market and are likely to continue to do so in the short term in view of their excellent all-round performance, 40 and firm grip on consumer electronics. However, in view of the competition from Li-Ion Polymer (LIP) batteries their long-term future is uncertain. Although, if safety concerns are overcome and costs fall significantly, there may be growth in the EV sector and to a lesser extent load-levelling, where LIB can exploit their relatively high cycle life. 40 Rare earth batteries and magnets are key elements of hybrid vehicles and gearless wind turbines, and phosphors are critical in energy saving lighting. Hammond and Mitchell 41 argued that ‘rare earth elements' (REE) may place a significant constraint on the development of some low-carbon (or clean) energy technologies. These materials are not actually rare in terms of their abundance, but the number and location of mines are restricted due, in part, to economic considerations. Current REE reserves stand at about 110 million tonnes with around half in the People’s Republic of China (PRC), although other countries like the United States, Commonwealth of Independent States (CIS) (the former Soviet Republics) and Australia hold substantial reserves. Production in China dominates the market, with ∼97% of the global total, and this will remain so until new mines are developed. The PRC has limited its export of REE in order to give preference to the export of manufactured products. Diversity of the global supply chain is therefore a crucial issue moving forward (see Figure 6 ). It is likely that supply constraints will become less critical in the medium to long term as more mines come into operation, and thus further reserves become available. 41 Such constraints could be eased by reducing the amount of material required per application, or changing the technology altogether. LIB, 40 for example, are already a viable replacement for nickel-metal-hydride units in hybrid vehicles. Their costs have fallen from >£1680/kWh in 1990 to <£140/kWh today. REE are not currently recycled, either pre or post-use. There are processes available that could be utilised for this purpose, although they do not currently appear to be economically viable options. 41\nDownload in PowerPoint\nFigure 6. Diversity of global ‘rare earth elements’ (REE) supply over the medium term. Note: ‘Current’ reflects the 2011 baseline. 41\nIn order to round-off these ETA-like studies, an evaluation of the energy densities and spatial footprints of both conventional and renewable generators was undertaken by Cheng and Hammond 48 on a life-cycle (or cradle-to-gate) basis. It was stimulated by a desire to test an assertion by Fells 49 that renewable energy technologies for electricity generation (such as bioenergy plants, solar PV cell arrays, wind turbines and the like) have a low energy density in comparison with fossil fuel or nuclear power stations. He suggested, for example, that if all the wind farms operating in the world in about the year 2000 were to be concentrated on the South Downs of England, then only 10% of UK electricity demand would be met. On a similar basis, he argued 49 that in order to replace Scotland’s two nuclear power stations a total of 10,000 250 kW LIMPET-type wave power generators (i.e. shoreline oscillating water column devices) would be required of the type installed on the island of Islay (one of the Hebridean islands; off the north west coast of Scotland). In the case of biomass energy, Fells 49 postulated that an area the size of the county of Kent would have to be covered in coppiced willow in order to replace half of the output from Dungeness B nuclear power station (a 1040 MW plant consisting of two AGRs, and located in the same county). The nuclear fuel cycle (both with diffusion and centrifuge enrichment) was found by Cheng and Hammond 48 to have the highest energy density of the technologies they examined, with bioenergy plants having the lowest. Their results are summarised in Table 2 , where they are compared with those of Gagnon et al. 50 and of the US Environmental Working Group (EWG). 51 Onshore wind power exhibited a relatively promising energy density and is greater than that of its offshore counterpart, the energy density of the latter fell below that of solar PV arrays. Thus, renewables were found to produce dilute electricity overall with a spatial footprint that is orders-of-magnitude higher than for conventional sources. That was in line with the views of Fells, 49 although there are many other sustainability criteria that will determine their usefulness in the transition towards a low carbon future. 48\nTable 2. A comparison of the spatial footprints per unit of output from various power generators.\nTable 2. A comparison of the spatial footprints per unit of output from various power generators.\nSource: Adapted from Cheng and Hammond. 48\nView larger version\nThe horizon scanning and technology assessment of the energy options 34 – 36 that will influence the three UK transition pathways contributes to an understanding the future interplay of the energy policy trilemma, i.e. achieving deep GHG emission cuts, whilst maintaining a secure and affordable energy system, and addressing how resulting tensions might be resolved. Overall insights and lessons from such studies can be summarised, for example, as:\nShale gas extraction has potential unwanted side-effects, and is already meeting community resistance and controversy. A balance sheet approach has been used to determine the benefits and disbenefits of shale gas fracking. 37 It may contribute to energy security, jobs and growth, as well as attaining national GHG targets over the medium term. Thus, it might form the basis of a transitional energy strategy for the United Kingdom, although the wider environmental impacts will require appropriate and robust regulations to be enforced.\nCarbon capture and storage (CCS) from fossil-fuel power stations is likely to be a key technology in achieving a low carbon future in the United Kingdom at a reasonable cost. 38 Energy and carbon analyses have been undertaken, along with indicative cost estimates, for fossil-fuelled power stations with and without CCS. 39 It could significantly cut GHG emissions, provided technological and financial obstacles can be overcome.\nLarge-scale nuclear power plants and tidal power barrages both exhibit attractive figures of merit in terms of their overall energy performance and near-zero carbon emissions, but have very long financial payback periods. 40 , 43 The latter makes them difficult to undertake with the support of only private sector investors. Nuclear power also gives rise to ongoing problems with high and intermediate-level waste disposal, 40 although a deep underground repository is the preferred option. The siting of such a facility has yet to be resolved in the United Kingdom. A tidal barrage built across the Severn Estuary would inevitably give rise to significant ecological modifications to the aquatic environment. 43\nThe suitability of ARBT have been evaluated for different applications. 40 While LIBs are likely to continue to dominate the rechargeable battery market in the short term, their long-term future is uncertain, because of competition from LIP batteries. There may be some LIBs growth in the electric vehicle sector, if safety concerns are overcome and costs fall significantly, and somewhat less in load-levelling, through their relatively high cycle life.\nRare earth batteries and magnets are key elements in the hybrid vehicles and gearless wind turbines, as are phosphors in energy-saving lighting, but short-term economic mining constraints on REE may limit their development. 41 Such concerns could also be eased by using less material per application, recycling REE, either pre- or post-use, or changing the technology altogether.\nThe energy densities and spatial footprints of various power generators were evaluated on a life-cycle basis. 48 The nuclear fuel cycle was found to have the highest energy density, with bioenergy plants having the lowest. Onshore wind power exhibited a relatively promising energy density; being greater than that for its offshore counterpart. The energy density of the latter fell below that of solar PV arrays.\nElectricity system and network modelling and evaluation\nSection:\nBackground\nA number of reputable studies have been undertaken over recent years that support low or zero carbon energy scenarios for the United Kingdom. These include those produced by the British Government’s Department of Energy and Climate Change (the DECC 2050 Calculator 52 ), the UK Energy Research Centre (the UKERC Energy 2050 Project 53 ), and the Tyndall Centre for Climate Change Research. 54 They all enable insights to be drawn regarding the realism of each scenario set, and reflect a range of aspirations from those wishing to achieve 2050 carbon reduction targets: 80% in the case of DECC 52 and UKERC 53 projections. However, the five Tyndall decarbonisation scenarios 54 focused on an earlier 60% carbon reduction target for 2050, although they employ a distinctive backcasting approach generated and reviewed with the aid of stakeholders. On the other hand, the DECC 2050 Calculator is basically an engineering-based, Excel spreadsheet model that is open source and arguably transparent. The tool permits users to select their own combination of technologies to achieve an 80% reduction in GHG emissions by 2050, whilst ensuring that energy supply and demand are balanced. The UKERC Energy 2050 Project 53 employed a core four-scenario core set that was underpinned by a single cost-optimisation model (UK MARKAL). It took ‘an eclectic approach to scenario building’ 53 with a backcasting dimension to achieve a combination of UK energy resilience and climate change mitigation. In contrast, the quantification of the three pathways developed by the Realising Transition Pathways Consortium was underpinned by a suite of multiple models.\nFrom narrative descriptions of the transition pathways to model formulation\nA range of models were developed to elaborate/explore demand, supply and infrastructure aspects 26 and feed into revising the pathways, both quantitatively and qualitatively in the second iteration for version 2.1 of the transition pathways. Qualitatively this has involved building narrative stories out to 2050, whilst quantitatively it has necessitated the construction of matching, consistent spreadsheets of demand, supply, technologies and (implicit) infrastructure. This was a challenging and time-consuming process, but one that yielded a valuable learning experience. Electricity models were used to variously address hourly, annual and seasonal balancing on regional, national and international scales. An informative multi-modelling comparison of the pathways was then undertaken to innovatively link and embed narrative storylines to technological, economic, social and institutional drivers and constraints. The framework of eight models and appraisal tools (see Figure 7 for the suite of individual models as of April 2013) were iteratively linked and checked for consistency between the various tools and the narrative descriptions of the pathways. This exercise was undertaken by the postgraduate researchers functioning as what was known in the Realising Transition Pathways Consortium as the Engine Room 55 the researchers working independently of the consortium leadership (the academic co-investigators).\nFigure 7. The framework of quantitative models utilised within the Realising Transition Pathways project.\nSource: The Transition Pathways Consortium. 55\nThis cross-scale study was based on the storyline or narrative description of the CC pathway, 8 , 24 which was then evaluated via six power system models and two appraisal techniques. It was used to iteratively link the CC narrative with the models/appraisal tools. Harmonised assumptions on power system inputs and system output targets for each model or tool were initially extracted from the CC pathway storyline. 8 , 24 The framework of models (see again Figure 7 ) was then employed to map the key features of each model/appraisal tool in terms of their temporal, spatial and disciplinary perspectives. Clearly, the narrative description of the CC pathway 8 , 24 was found to be critical for transmitting information about governance logic and the choices of key actors. Nevertheless, many of these parameters were found to be inconsistent. Typically, the CC storyline resulted in an overestimate of demand reduction levels, the uptake of CCS and marine renewables. This is because the narrative storyline tends to underestimate the technical and economic challenges associated with these levels of demand reduction and uptake of CCS and marine renewables. These were subsequently highlighted through the quantitative modelling analysis. Likewise, the narrative description led to an underestimate of the supply-demand balancing requirement, the need for back-up capacity, and the role of nuclear power and interconnectors with Europe, compared to the challenges identified through the modelling in achieving these outcomes.\nThe eight models and appraisal tools (in the order of their breadth of power system boundaries, and in line with the sequence indicated in Figure 7 ) were:\nDemand: This energy demand model (for full details see Barton et al. 28 ) is a highly disaggregated simulation model of UK energy demand for both the domestic and non-domestic sectors. Its primary inputs are a range of characteristics, 26 , 52 including energy service levels, user practices, choices of appliances, building fabric, fuels, deployment of distributed generation, and other parameters, with its main output being final energy demand across the UK building stock.\nFESA: The future energy scenario analysis (FESA) model (for full details see Barnacle et al. 27 ) is a single-year UK power generation and demand simulation model, incorporating 1-hour time steps for dispatch modelling. The overall structure of this model is depicted in Figure 8 . It utilises 2001 UK Met Office weather data on temperature, wind speeds, solar radiation and wave height. The FESA model incorporates technical feasibility constraints on the power network, and enables hourly grid-balancing.\nD-EXPANSE: This model (dynamic version ofexploration ofpatterns innear-optimal energyscenarios; for full details see Trutnevyte 56 ) is a power system optimisation model. D-EXPANSE systematically explores the various near-cost-optimal pathways, as well as the structural uncertainty, based on key inputs of demand, technology costs and characteristics, fuel prices and power system transmission topology. Its main output in terms of UK power systems configuration and costs has been validated by comparing its outputs with that for a variety of existing, well-established whole system models and their cost estimates for the UK. 55\nEconA: The economic appraisal (EconA) appraisal technique (for full details see Trutnevyte et al. 55 ), is an accounting model that systematically calculate and compare investment and total system costs for power generation, transmission and distribution under the three UK transition pathways. The key inputs are the ranges of component technology costs, efficiencies and other technical characteristics. The quantitative output is disaggregated into shares of different power generation technologies, thereby allowing the assessment of economic feasibility of any given pathway (such as the CC pathway in the contribution of Trutnevyte et al. 55 ).\nBLUE-MLP: This model (behaviourlifestyles anduncertaintyenergy model withmulti-levelperspective on transitions) is a probabilistic systems dynamics simulation model (for full details see Trutnevyte et al. 55 ). Its key inputs derive from sector- and actor-specific behavioural elements 55 that arise from the MLP transitions approach 17 , 20 (see again the schema depicted in Figure 1 ), and include the macro-landscape pressures landscape (including government decisions or developments in the international context), the social-technical regime (e.g. the current UK power system structure and its regulation), and niche innovations (e.g. lifestyle-influenced changes in demand). Its key outputs are technology and demand change uncertainty ranges for future energy and emissions pathways.\nEEA: The tool designated as energy and environmental appraisal (EEA) is an accounting framework based on the environmental life-cycle assessment (LCA) of the UK power system (for full details see Hammond et al. 57 and see section ‘Whole systems energy and environmental appraisal of the different energy mixes’ below). Based on a broad inputs set of technology-specific emissions factors, 26 , 58 the key outputs are 18 environmental impact categories 57 that are evaluated from cradle-to-gate, accounting for both upstream and operational (or stack) emissions. The categories included climate change (via GHG emissions), fossil fuel depletion, human toxicity, particulate matter formation and agricultural land use change.\nHESA/UK+: This optimisation model is an enhanced version of the hybrid energy system analysis (HESA) tool (for full details see Barnacle et al. 27 ). The model cost-optimises the UK electricity network, based on the energy hub concept, using key inputs of national power demand and generation mixes as input assumptions/parameters. The principal output is spatial disaggregation of generation, storage, transmission and distribution in terms of 17 onshore nodes, five offshore zones and 39 connections.\nHAPSO: The holistic approach to power system optimisation (HAPSO) model is a bottom-up, cost-minimisation power system model (for full details see Strbac et al. 59 ), with key inputs of technology costs and characteristics as well as electricity system topology. The model’s key output is the optimal power generation, storage, transmission, and distribution network infrastructure requirements, as well as their associated cost. The model then simultaneously estimates long-term investment requirements and short-term operational decisions, including in regard to hourly dispatch, demand side response (DSR; whereby customers are financially incentivised to lower, or shift, their electricity use in order to reduce demand at peak times), storage cycles and power interconnection.\nDownload in PowerPoint\nFigure 8. A schematic representation of the Future Energy Scenario Analysis (FESA) model. Source: Updated from Barton et al. 28\nThese models and appraisals yield a broad spectrum of cross-scales insights 55 covering system boundaries, time, space, and disciplines (see Figure 7 ). They were found to reveal a rather fragile nature of the transition pathway narrative descriptions or storylines. 55 The CC pathway storyline was found, for example, to imply an overestimation of the potential for power demand reduction and for the uptake of marine renewables. The necessity for CCS to meet the 2050 UK GHG emissions target was likewise overestimated. However, they were found to downplay the challenge of supply-demand balancing and the need to use gas power plants as a back-up capacity, as well as the role of nuclear power and electricity interconnectors with Europe.\nThese and other findings have benefited from a whole systems and collaborative working aimed at elaborating and examining pathways for realising a transition to a low carbon, secure and affordable UK energy system by 2050. Thus,\nA critical review of quantitative models for exploring socio-technical transitions has aided interdisciplinary learning between the different developers and users of the storylines, models and appraisal tools. 8 , 24 , 26 – 28 , 55 – 58\nThe iterative improvement of the qualitative narrative descriptions for the pathways, combined with that for a diverse range of models and appraisal techniques, is likely to be a key element in the robust development of future transition pathways and energy scenarios. 55\nAnnual demand modelling\nThe Demand model 28 , 55 assembles trends for the overall annual demand for electricity and fuels to 2050. The model builds from bottom-up representations of the energy service demands in the major sectors, the performance of existing buildings and end-use equipment, and the prospects for technological improvements and behaviour changes. Heating technologies in the domestic, service and commercial sectors are modelled in detail; industrial process heat is represented through underlying sub-sector demands and expected trends. Data were drawn initially from the Energy Consumption in the United Kingdom (ECUK) 60 database with further disaggregation by end-use and service employing assumptions about future technical change developed based on multiple sources. 28 The trends for electrification of transport are modelled, linked to work within the project. 61 Assumptions were compared to those in the DECC 2050 Calculator. 52\nIntroducing the spatial dimension to demand, the HESA model 26 , 27 utilises network theory to calculate flows, the energy hub concept to represent the conversion of energy between carriers (i.e. generation, including renewable energy sources), and deterministic least-cost optimisation (of fuel, generation, transport). The UK+ model includes physical descriptors of all generators, energy demands and storage requirements. It contains the 17 UK onshore nodes, as well as having nodes representing five offshore zones (Norway, Belgium, Netherlands, France and the UK Continental Shelf (UKCS)). The model contains multiple carrier transportation networks to/from international nodes (39 connections facilitate the transportation of electricity, gas, coal, oil, biomass and CO2) with demand and supply capability to represent international nodes (thereby facilitating international trade in energy carriers). HESA and UK+ have been used in combination to model an integrated multi-energy carrier network and applied to local, regional and national scale case studies in the context of the transition pathways, e.g. combined gas and electricity bulk flows with constraints across the United Kingdom.\nThis combination of models 55 indicates a temporal mismatch between low-carbon supply and demand may lead to very low utilisation factors of dispatchable generation, i.e. power plants that can be turned on, off, or have their output varied in a relatively short time at the request of the network operator or plant owner. This affects financing of gas-fired power stations, as well as hampering the prospects for CCS. Supply-demand balancing leads to increasing curtailment of renewables and additional fossil fuel use, illustrates the potential for electricity storage, but suggests that innovation would be required for longer term storage. This combination of models has also been employed for stress testing, optimisation and uncertainty analysis of the pathways. Different technology mixes were found to drive different regional patterns of investment as displayed in Figure 9 . Consistently high investment is required in the South East, South West, East of England and in Scotland. Other regions, such as the North East of England, were found to be exposed to large swings in potential investment under different pathways. Thus, the lessons learned from annual demand modelling were:\nAn increase in capacity of the electrical North-South corridor is essential for the success of all three pathways. A decrease in use of the national natural gas transmission system as a result of decarbonisation means an under-utilisation of the network. Total transmission and generation costs are likely to increase out to 2050 across all three of the UK transition pathways.\nEven in a system with greater localised energy sources (such as under the TF pathway) there is still a need for national energy infrastructures for electricity and gas.\nNote: Estimated via the FESA model. 27 , 28 , 55\nThe temporal mismatch between low-carbon generation and demand profiles may lead to very low utilisation factors of dispatchable generation. This is likely to affect financing of gas-fired power stations, and hampers prospects for CCS, which will need to be fitted to fossil-fired generation to achieve long-term carbon budgets. The supply-demand balancing issues will lead to increasing curtailment of renewables and additional consumption of fossil fuel. This leads to significant potential for electricity storage, although innovation will be needed to bring forward options for longer term storage. Thus, overall insights and lessons from hourly grid-balancing can therefore be summarised as:\nOne year, hourly modelling of Great Britain (GB) – the UK less Northern Ireland – grid balancing using the FESA model indicates a temporal mismatch of low-carbon generation against conventional demand profiles. This presents a much greater challenge to grid balancing than often assumed, e.g. in the DECC 2050 Calculator. 52\nAmbitious low-carbon pathways can lead to very low utilisation factors of dispatchable generation, including that with CCS, which could undermine the economic viability of this innovative, disruptive technology.\nA future system operator (in 2050 or beyond) will need to bear in mind a number of factors in order to secure grid-balancing 27 : the size of the interconnector compared to the peak surplus power requirements; the economic value of exported electricity (which may be quite low) compared to the value of fuel saved by using more resistive heating; and the necessity of maintaining a stable electricity grid (in the frequency and voltage domains) in the absence of conventional, thermal electricity generators.\nIn the absence of very large-scale long-term energy storage, significant curtailment of renewables and additional consumption of fossil fuel may arise at times.\nThe role and value of demand side response\nDemand response is a key option for supply-demand balancing 28 , 59 , 61 – 65 (see Figure 11 ), which offers benefits to all parts of the energy system that have been estimated to amount to some £4 bn per year. Electrification of heating and transport services may provide new opportunities for DSR. For example, research into social practices and service expectations combined with technical modelling (see the subsequent section) indicate that, if householders would tolerate a drop in indoor temperature of 1 ℃ for up to ten days a year, between 3 and 9 GW of peak supply capacity could be avoided. The key aim of DSR is therefore to explore the technical performance of various demand response concepts via time-step modelling techniques, but recognising the critical sensitivity to input assumptions regarding the level of expectations of the users. In order to model the potential demand response characteristics of individual load types, data was initially collected on multiple building loads for incorporation into the HESA/UK+ model combination. The data were then exchanged with the Demand and FESA models. An integrated scheduling algorithm was devised as an extension and redevelopment of the FESA model 26 – 28 (see again Figure 8 ) to allow demand response to compete on a level field against storage and controllable generation. The main calculations were translated into the VBA (i.e. visual basic for applications) code for greater visibility and future flexibility. It has been recognised that changes in the supplier/consumer relationship and in service expectations of consumers will inevitably impact on energy demand out to 2050 and beyond. Consequently, it is important to at least qualitatively ‘model’ consumer practices (see again the subsequent section) and to explore the relationships among customers, suppliers and consumers/prosumers. (Energy prosumers (see Figure 12 ) are those that produce (via distributed energy resources (DERs)), consume, manage or trade energy according to their own requirements and aspirations.) Smart DSP 28 can help to meet the challenges of flexible demand. Thus, water heating has been found to be capable of time-shifting (see again Figure 11 ) by around 50% for up to 7 h, space heating by 100% for up to 1 h, and EVs and plug-in hybrid electric vehicles (PHEVs) charging by 100% for up to 7 h.\nDownload in PowerPoint\nFigure 12. Structural opportunities to control flexible demand, including an illustration of the roles of the transmission network operator (TNO), distribution network operator (DNO), and flexible prosumers.\nThe penetration of renewable generation, particularly onshore and offshore wind turbine arrays, in the UK energy mix may reach as much as 15% by 2020. By that time the number of EVs in use may have reached over one million. Thus, the UK power system will be affected by an increasing imbalance, due to this rise in electricity demand (from EVs) and uncontrolled supply (from wind). Smart EV charging strategies 61 can therefore help the power system cope with high penetrations of local renewable energy sources (RES). Huang and Infield 61 recognised that domestic vehicles are typically parked for around 95% of the time, and hence EVs can be utilised as a ready form of responsive demand. They adopted a Monte Carlo model together with state-of-charge (SOC) information, as part of a whole systems framework, in order to estimate EV charging profiles. Wind farm data was taken from operational sites in Scotland. It was found that the cost over several small EV charging events was essentially free, provided that the surplus wind was greater than 1 MW. Likewise, the impact of the widespread adoption of high-performance heat pumps, alongside the large-scale penetration of wind generators, was recently studied by Cooper et al. 62 They devised a model using dynamic simulations of individual (air-sourced) heat pumps and dwellings, which indicated that increases in peak net-demand is highly sensitive to assumptions regarding the heat pumps themselves, their installation, building fabric (i.e. thermal insulation) performance and grid characteristics. If 80% of dwellings in the United Kingdom were to adopt such heat pumps, for example, then peak net-demand could rise by around 100% (54 GW), although this increase could fall to just 30% (16 GW) under favourable conditions. 62 Smart DSP could reduce this further to 20%, or even 15% with extensive use of thermal storage (as depicted in Figure 11 ). In contrast, should 60% of dwellings take up heat pumps, then the rise in peak net-demand could be as low as 5.5 GW, and consequently the electrification of heating would be more manageable for the network. 62\nAnother study by Teng et al. 63 examined the demand for ancillary services under a future GB electricity system as a result of the high penetration of wind generators with limited inertia capability. Under these circumstances, the network may be required to deal with sudden frequency drops following a loss of generator. An advanced stochastic generation scheduling model was employed to quantify the frequency response requirements and the contribution that could be made by DSR. 63 It suggested that the provision of frequency response from DSR could greatly reduce the system operation cost and wind curtailment. These DSR benefits were found to have significant diurnal and seasonal variation, whereas an even more rapid (near-instant) delivery of frequency response from DSR could yield substantial additional value. Competing technologies to DSR that can provide frequency regulation, such as battery storage 41 or more flexible conventional generation could potentially reduce its value by between 15% and 35%. 63 This would still leave significant room to deploy DSR as a cost-efficient frequency response provider within a future low-carbon electricity system.\nIt is critical to reflect how investors will take decisions to invest in (or to retire) generation plant within a market and policy context. Accounting for the incentives provided to companies through the trading arrangements is hence fundamental for modelling how investors take decisions going forward. As well as power market revenues, renewable and low-carbon generators are also reliant on subsidies to ensure their profitability, which is important for the investment decision-making process. Investors will form ‘rational expectations’ regarding the future when making investment decisions, taking into account power market conditions (e.g. electricity prices, demand growth, demand flexibility, changes in trading and regulatory arrangements, etc.) over the life of the asset based on all the information available to them at the time. Quantitative modelling studies have therefore been conducted in order to evaluate the competitiveness of demand response against other technologies, using a range of GB network case studies related to the transition pathways. A holistic approach (via the whole-electricity system investment model (WeSIM) 64 ; a successor to the HAPSO model 55 ) has been employed to assess the benefits of demand responses on power generation, transmission and distribution systems under each of the three pathways scenarios (see Figure 13 ). WeSIM, employed by Pudjianto et al., 64 is an enhanced model with respect to the modelling of demand and has more functionalities. It was used to provide useful insights on the characteristics of different pathways in terms of the expected increase in future peak demand, driven primarily by electrification of heating and transport sectors, 61 , 62 as well as the consequences for future power system infrastructure requirements. This approach 64 simultaneously optimised investment into new generation, network and storage capacity, while minimising system operation cost, and also considering reserve and security requirements. The analysis distinguished between bulk and distributed storage applications, while also considering the competition against other technologies, such as flexible generation, interconnection and DSR 64 (see again Figure 13 ). The results demonstrated that the DSR savings are potentially significant and that the MR pathway, for example, could save up to £90 bn of investment by 2050. A key issue arising from these studies is that the postulated generation capacity under the pathways may not be sufficient to meet security standards. This highlights the importance of considering the security of supply aspect in the development of future generation portfolios. Analysis of the electricity price characteristics of the three pathways showed that some generators with relatively very low load factors bring into question the feasibility of generation in an energy-only market. There are significant multi-stream savings that arise from DSR (multiple applications, including energy arbitrage, system balancing and capacity) across all pathways (amounting to some £4 bn/year by 2050). The benefits of whole-system based DSR applications are higher than those of the (non-coordinated) transmission network operator (TNO) or distribution network operator (DNO)-centric DSR applications: see again Figure 12 . This highlights the need for such whole system control co-ordination between the TNO and DNO in order to improve the interaction with DSR control.\nDownload in PowerPoint\nFigure 13. Annual versus peak electricity demand under the three UK transition pathways. Note: Estimated via WeSIM 64 ; a successor to the HAPSO model. 55\nEnergy storage (ES) represents one of the key enabling technologies to facilitate an efficient system integration of intermittent RES in conjunction with the electrification of heating and transport demand (see Figure 11 ). A stochastic optimisation method was used to quantify the benefit of distributed energy storage from the owner perspective. 65 A large set of case studies were carried out 65 in order to quantify the commercial and emissions benefits of ES in respect to energy and ancillary service markets, the revenue obtained from feed-in tariffs (FiTs), and the consequent reduction in operational CO2 emissions. ES was found to be able to provide opportunities for temporal arbitrage, because of the volatility of day-ahead and real-time (balancing) energy prices with a value of between £100/kWh and £650/kWh. 65 Its value in terms of anciliary services, such as frequency response, was estimated to be up to about £200/kWh on top of the basic value of ES. The value of ES for FiT revenue maximisation was found to decrease with increasing capacity from £108/kWh to £38/kWh. 65 When ES is charged during low-emission periods and discharged in high-emission ones, then the carbon footprint falls by around 10% even with losses taken into account. Teng et al. 65 observed that current and near-term batteries did not appear to be cost-effective for power generation applications. Thus, they noted that LIBs were most effective (∼£480/kWh) for kW/kWh applications with reasonable charge/discharge cycle lives. 41 (The cost of LIBs are today about ∼£140/kWh (similar to the price in 2012 noted by Hammond and Hazeldine 40 of ∼£135/kWh) having fallen from >£1675/kWh in 1990.) This contrasts with sodium-nickel chloride devices (so-called ZEBRA 41 , 65 batteries) at ∼£329/kWh. Teng et al. 65 expect the costs of lithium ion batteries to halve by 2020, although they expect those for the ZEBRA battery technologies to remain largely unchanged.\nThe technical performance and social acceptability of a range of proposed DSR concepts has been examined via an integrated approach in order to quantify the changes in electricity load profiles of the type represented in Figure 11 . The benefits of DSR options to the various classes of consumers were quantified for a range of scenarios appropriate to the different transition pathways. McKenna and Thomson 66 examined, for example, the way in which domestic consumers with rooftop solar PV arrays could benefit financially from time-shifting. They used an internet discussion forum to determine whether consumers with such PV systems engage in DSR activities so that they benefit further from free, self-produced electricity. Washing machines, dishwashers and electric space and water heaters were the most commonly employed appliances to shift demand. 66 The results suggest that, while price is an effective driver of DSR, there are other factors that generate demand response of the sort depicted in Figure 11 . They indicate that consumers with PV are often willing to be more flexible than is commonly assumed. This behavioural response could possibly be used in future to devise innovative tariffs that might stimulate demand shifting. 68 These value assessments are important elements in assessing the take-up, scale and effectiveness of DSR that can be expected.\nThese and other findings have benefited from a whole systems and collaborative working approach for elaborating and examining the transition pathways for realising a low carbon, secure and affordable UK energy system by 2050. Thus, the insights and lessons learned from studying the role and value of DSR were:\nDemand side participation (DSP) concepts are mainly short term (minutes to hours), whereas flexibility is needed over several days or more. The rigid patterns of modern living and consumer expectations based on life-long experience of fossil-fuelled supplies make such flexibility challenging, but are important to explore. Fully automated DSR concepts, such as ‘smart’ controllers for EV charging and heat-pumps, have been studied in some detail.\nBattery energy storage and controlled EV charging helps cut peak demands, but typically provides only a few hours of storage, doing little to address longer term weather-related variations. A Monte Carlo model of EV movements and home based charging 61 has been used to analyse the impact on a typical low voltage distribution network with typical household loads, suggests voltage impacts to be the most critical: voltages could easily become unacceptable without demand side management. The extension of EV charging to allow workplace charging seems to relieve the distribution network loads and help avoid voltages outside the statutory range.\nDecarbonised electrification of heating could make a useful contribution to the reduction in UK CO2 emissions, but may cause a challenging increase in peak power demand, net of non-dispatchable generation. This can be reduced, although not entirely eliminated by thermal energy storage and DSP. In addition, it has been shown 62 that high-performance (air-sourced) heat pumps, with appropriate installation and better insulated buildings, could make the rise in peak net-demand far more manageable.\nAn integrated market model (developed in WeSIM 64 ) has been used to analyse the evolution in electricity prices in different system backgrounds with different DSR technologies, network development, carbon prices and energy policies (related to market integration with the EU). When viewed in the context of a high share of renewable generation (such as under the TF pathway), the magnitude and volatility of electricity prices tend to increase, particularly driven by higher carbon prices and greater variable generation. The price differential between exporting and importing regions also widens from increased congestion in the national/cross-border transmission system.\nThere are significant multi-stream savings from DSR (via multiple applications, including energy arbitrage, system balancing, capacity) across all pathways; amounting to £4bn/year by 2050. These benefits of whole-system based DSR applications are higher than those of (non-coordinated) transmission system operator (TSO) or distribution system operator (DSO)-centric DSR applications. This highlights the importance of whole system control co-ordination.\nThe transition pathways have been costed under very different governance and institutional arrangements. Economic feasibility of generation in all three pathways will depend on the revenue from secondary markets/sources, such as capacity (ancillary service) market, FiT, tax incentives, etc., although the ratio of the revenue needed from primary and secondary markets is case specific.\nAttending to the social dimensions of realising transition pathways\nSection:\nThere is growing awareness that meeting the challenges of a low-carbon transition will require socio-technical solutions, and that consequently the social sciences have a key role to play in devising them, including working with engineers and physical scientists in an interdisciplinary manner. 66 – 68 A team of social scientists worked work interactively in collaboration with engineers in the present consortium to enhance consideration of the social dimensions of the project. This included work to open up assumptions about actor dynamics and social change as well as roles of the public and civil society in realising the UK transitions pathways. 66 – 68\nBuilding on the concept of the action-space devised in the first phase of the Transition Pathways project 8 , 24 , 30 (see section ‘Insights from historical transitions’ above), a relational co-productionist approach grounded in ideas form science and technology studies (STS) was developed to map relations between social actors across the UK electricity system and the spaces through which they participate in energy system change was developed to described the way in which different patterns of interaction between market, government and civil society actors lead to particular modes and logics of governance. 8 , 24 , 30 An important means of mapping actors and action spaces was through a systematic qualitative analysis of twelve contrasting visions of the low-carbon transition. This analysis showed that while some visions assume a technologically focused transition driven by the energy trilemma and centred on economic growth, alternative visions (particularly those from of civil society actors) place more emphasis on social and cultural change, issues of equity and fairness, and do not assume or depend on existing models of economic growth. Chilvers and Longhurst 67 studied four diverse sites of civil society engagement in low carbon transitions: the DECC Energy 2050 Public Dialogue (DECC 2050), the Camp for Climate Action (CCA; direct action events at various coal-fired power stations over 2006–2011), the Visible Energy Trial 8 , 33 (VET) and the Dyfi Solar Club (DSC; a community energy initiative in Machynlleth, Powys, Wales). They revealed that powerful forms of enrolment, exclusion and the partiality of visions and actions are common to all form of participation in transitions. Such analyses play a valuable role in transition pathways analyses through revealing social dimensions and informing how modelling studies frame the energy problem, bound the study system, and communicate uncertainties. It helped the wider consortium and technical analysts realise that that transitions are never smooth and will always be subject to contestation, negotiation and social change.\nThe other way in which social dimensions of energy transitions were attended to during the second phase of the realising transitions pathways project was through taking forward novel interdisciplinary (ID) experiments to co-produce social science and engineering insights on energy demand response in real time. These studies included a meta-review of social science evidence, leading into the design of small-scale integration experiments. The first of the ID experiments was a Service expectation experiment (see Figure 14 , and the summary in Table 3 ) in which the social science input into existing models was evaluated in order to improve model assumptions about how indoor comfort expectations could change over time. Such service expectations are often held to be stable, but social science literature suggests they vary in different ways. A range of service expectation scenarios were studied based on the outcomes from the review (such as more demanding standards, wider comfort zone and local diversity). The FESA model 26 – 28 ( Figure 8 ) was employed in order to examine various behavioural scenarios with variable service expectations. The work indicated that if householders (consumers or flexible prosumers; see Figure 12 ) were tolerant of a small internal temperature change either side of their desired set-point, and even allowing these for just a few hours per year this could yield large reductions in peak demands (a few GW): see again Figure 11 . This opened up the prospect of new behavioural scenarios for models, new parameters and boundaries. The term framing, used in Table 3 , implies the inevitable process of selective influence over the perception of an individual (involved in the experiment) in such a way as to encourage particular (potentially biased) interpretations and to discourage others. This experiment suggested that new levels of detail are required in existing FESA-like models (e.g. around heating/cooling technologies, housing stock, etc.). 26 – 28\nView larger version\nThe second strain of social science-led, ID experiment (by Higginson et al. 68 ), termed Modelling practices experiment (and again summarised in Table 3 ), was designed to develop new approaches to modelling based on social science understandings of, and data about, social practices. It encouraged the social scientists to communicate their ideas more clearly, whilst allowing engineers to think critically about the embedded assumptions in their models in relation to society and social change. Social practice theory together with network analysis 68 was adopted to provide a network diagram to visualise different practices. ID participants then collaboratively generate mappings of ecologies of practices: see Figure 15 that illustrates various social activities and practices in the home. The elements of practices – represented by circles – are distinguished in terms of images, skills (e.g. washing) and stuff (e.g. dirty clothes). Thus, washing clothes as an energy service is not merely determined by the washing machine, tumble drier and iron, but depends on much else. These other social factors include the meaning of clean, the way the different schedules in the household come together, the organisation of laundry and the way it is done in the household, and so on, i.e. the images and skills that are part of the practice of laundry. Graphs of practice networks such as this can be populated with empirical survey data. Higginson et al. 68 recently used this approach to examine from a survey of different types (or variants) of laundry practice. They gleaned insights into energy intensity, flexibility and the rootedness of practices, i.e. the extent to which they were entrenched or established. It was argued that this permitted the social practices to be represented graphically using a quantitative format ( Figure 15 ) without being overly reductive. This modelling practices experiment opened up new socio-technical discussions about core/periphery elements, variants of practice and so on, but also closes down discussion about the situatedness of practices (see Table 3 ).\nDownload in PowerPoint\nFigure 15. A simplified network representation linking social activities and practices in the home: identifying ‘hubs’, ‘anchors’ and ‘clusters’.\nThrough these ID experiments engineers had become more aware and reflective of the tacit social assumptions and limitation of their models, while social scientists became more aware of the complexity of energy models and the difficulty of making even small changes to their inbuilt assumptions. Importantly, these collaborations produced new findings and insights only possible through interdisciplinary working. Bringing together practice theory with network analysis extended and scaled up understandings of energy-related practices, generating new insights on the constraints and potentials for modelling flexibility and energy demand response. In the service expectation experiment, integrating social science insights into the FESA model showed how even small changes in thermal comfort expectations can lead to significant savings in terms of energy demand, which could prove crucial in realising low carbon transitions.\nKey challenges, insights and opportunities identified in these studies attending to the social dimensions of energy transition pathways include:\nNew evidence that quantitative energy modelling approaches routinely neglect important social aspects of energy transitions and how society will influence future pathways, including changes in how energy problems are framed, service expectations of users, the roles of public engagement and institutional changes.\nSocial science analyses can provide important new evidence about the relations between actors and forms of participation in energy transitions, which is important evidence in its own right and in sensitising models to alternative framings, social futures and uncertainites inherent to scenarios and model projections.\nIf interdisciplinary collaboration is well designed, open, collaborative and based on trust it is possible to integrate engineering and social science expertise, which produces new insights beyond what is possible with single-discipline approaches – for example, showing prospects for energy demand flexibility and responsiveness greater than previously estimated.\nThere is no single best practice approach to interdisciplinary energy research. An effective approach is to develop forms of integration between social science and engineering modeling approaches that are appropriate, diverse and can be evaluated and learned from over time.\nInvolving social scientists in real-time interdisciplinary collaboration with physical scientists can hold the key to producing whole systems energy models that are more responsible, anticipatory and accountable to the social implications and effects of energy transition pathways.\nDistributed energy\nSection:\nThe TF pathway explores a low-carbon transition led by civil society, which focuses on decentralised or distributed solutions to energy problems. Currently, less than 1% of UK electricity demand is met by community- or local authority-owned distributed electricity generation. A major driver for the TF pathway is seen to be a step change in the role of the civic energy sector (communities, co-operatives, local authorities, town and parish councils, social housing providers) through participation in, and ownership of, electricity generation schemes. ESCos are presumed to emerge, with incentives aligned with energy efficiency improvements. Because this pathway deviates most from the current energy market, and has no recent precedent, it has interested bodies including the public-private ETI (e.g. their Patchwork scenario) and the UK energy market regulator (Ofgem). The consortium postgraduate researchers (the Engine Room (see section ‘From narrative descriptions of the transition pathways to model formulation’ above); again working independently of the consortium leadership – the academic co-investigators) were asked to evaluate the implications of this novel pathway, and they produced a Distributing Power report. 69 With strong demand reduction and management, 50% of 2050 final electricity usage could be met via distributed generation with emerging technologies, new infrastructures (including interconnections), and new institutions. Although challenging to the current power system operational norms, a transition to 50% distributed generation by 2050 was found to be technologically feasible. However, it would require the installation and full utilisation of smart grid technology, alongside DSP, demand management, and other techniques and technologies. A more distributed system would clearly need regional energy strategies and local capacity building for city regions, municipalities, communities and citizens. A distributed energy system opens up new avenues for energy transition finance, while challenging incumbent utility business models. (The integrated market simulation model (WeSIM 64 ), described in section ‘Hourly demand profile modelling’ above, can be used to optimise real-time dispatch in a chronological fashion, as well as reflecting entry and exit decisions by investors, using an iterative process.) The model for investment in conventional and renewable generation was used to calculate the electricity prices (including energy and scarcity prices that reflect the scarcity in generation capacity during peak demand), generation and transmission revenues. It highlighted the finding that electricity prices are expected to be more volatile in the future and that the impact of demand response on average electricity price is modest but it reduces significantly the volatility.\nThe Distributing Power report 69 draws on empirical research, engagement with a wide range of stakeholders from the energy sector, and from experience in Germany, Denmark and in the United Kingdom. It offers insights into the barriers and the technological transformation that might be required for a move to a highly distributed energy future. This decentralised generation would be required to satisfy the TF pathway with an increase in regional, national and international interconnection in order to ensure electricity imports from neighbouring countries. 69 Much of the energy value that currently leaks out of the UK economy could then be captured at the local level. Such distributed energy systems have often been equated with increased energy independence. But significant reduction in electricity demand would be necessary, including improved energy efficiency and conservation. Households, for example, would need to more than halve current levels of electricity consumption by 2050. 69 National energy planning with regional and local support for a civic energy sector would be needed. This implies a much greater role for national and local government. The traditional business models of the Big Six incumbent electricity suppliers would inevitably be challenged as they lose market share to local generation and supply businesses. New infrastructure, like smart grids and emerging decentralised technologies (such as in-home fuel cells), would be necessary; requiring a large-scale expansion from 2020 onwards. The impact to consumer bills would only be marginally more expensive out to 2030, 69 although they could be significantly cheaper in the long term (to 2050) compared to the MR and CC pathways. While the Distributing Power report 69 assesses the impact of one distributed generation future, there are others which might see a greater role for solar, onshore wind, or other generation mixes.\nTraditionally, renewable electricity generation capacity in the United Kingdom has been built by large-scale commercial developers and/or utilities, whose finances are globally mobile. The Distributing Power report 69 suggests a possible alternative of a proliferation of distributed energy generators, which are owned fully or in part by municipalities, communities, or small-scale investors. (A companion piece to the Distributing Power report, 69 produced by Johnson and Hall, 70 has examined the distributional implications of the TF pathway.) Citizens would thereby gain more control over their energy use. Centralised generation would still be necessary for base-load and peaking capacity. However, for this to be viable in a distributed generation future, the government would need to provide the right incentives for new large-scale plant and infrastructure. The civic energy sector, defined as energy generation by communities, co-operatives, local authorities, town and parish councils or social housing providers, currently relies on motivated individuals and communities and often, voluntary work. The development of a decentralised future along the lines proposed for the TF pathway would require strong project management and professional expertise to deal with a range of technical, financial, legal and administrative issues. In order to move to a distributed approach, regional energy strategies and local capacity building would be essential to aggregate these local energy schemes into a coherent civic energy generation sector. 69 , 70 This would mean complementing national energy planning with regional and local support for a civic energy sector and implies a much greater role for both national and local government.\nThe launch of the Distributing Power report 69 in February 2015 informed the wider UK energy debate, and is leading to further work with key stakeholders, including an invited submission to the Ofgem non-traditional business models process. The headline messages were: 69\nAll UK energy projections, including a distributed energy future (such as that encapsulated in the TF pathway), require international interconnection. In addition, the TF pathway relies heavily on energy demand reduction, DSP and demand-side management. Households would need to more than halve their current levels of electricity consumption by 2050.\nA distributed energy system opens up new avenues for energy transition finance, while challenging incumbent utility business models. Around 50% of final electricity demand by 2050 could be met via distributed generation, but new infrastructures and emerging technologies would be required: from smart grids at a national level and to the likes of in-home fuel cells locally. A large-scale expansion would need to occur under the TF pathway from 2020 onwards. Thus, national energy planning with regional and local support for a civic energy sector would be needed.\nA high-level of distributed generation would require an increase in regional, national and international interconnection, such as electricity imports from neighbouring countries. Distributed energy systems have often been equated with increased energy independence. Much of the energy value that currently leaks out of the UK economy could be captured at the local level.\nThe traditional business models of the Big Six incumbent electricity suppliers would be challenged as they lose market share to local generation and supply businesses. In order to move towards a more distributed system, regional energy strategies and local capacity building would be essential for city regions, municipalities, communities and citizens.\nThe impact to consumer bills within a highly distributed power system (of the sort proposed for the TF pathway) would only be marginally more expensive in the medium term out to 2030, although it could be significantly cheaper over the long term to 2050 in comparison to those under the alternative MR and CC pathways.\nWhole systems energy and environmental appraisal of the different energy mixes\nSection:\nThe energy and environmental appraisal of the three transition pathways and associated power technologies have been evaluated within the context of a transparent sustainability appraisal framework, i.e. economic, social, environmental and technical benefits. 57 , 58 , 71 This process employed a toolkit of techniques to explore and evaluate the whole systems consequences of the selected transition pathways, such as the (embodied and process) energy and carbon implications of the pathways and technology mixes, their environmental burdens (as indicated by environmental LCA 57 , 58 , 72 – 75 ), and aggregate carbon and environmental footprints. A comprehensive review of the LCA of energy systems 57 included an overview of the historic development of LCA from the early 1990s, and its subsequent codification by the International Standards Organization (ISO). Environmental appraisal of energy systems needs to be conducted on a life-cycle basis, i.e. embracing the full range of extraction, production, distribution, and end-of-life processes or technologies. 57 , 58 , 72 – 75 In a full or detailed LCA, the energy and materials used and pollutants or wastes released into the environment as a consequence of an activity or service are quantified over the whole life-cycle; typically from cradle-to-gate. 57 Such studies are often geographically diverse; i.e. the energy and material inputs associated with the activity may be drawn from any continent or geo-political region of the world. They involve four main LCA stages that follow a logical sequence of goal definition and scoping, inventory analysis, impact assessment, and interpretation. The current strengths and weaknesses of LCA have been identified for the benefit of energy practitioners and policy analysts 57 (see Table 4 ). Comparisons were made with related approaches, such as carbon and environmental footprinting. 71\nTable 4. An outline of the strengths and weaknesses of environmental LCA.\nTable 4. An outline of the strengths and weaknesses of environmental LCA.\nSource: Hammond et al. 57\nView larger version\nAn examination of the whole system environmental burdens of the present transition pathways (version 2.1) was undertaken by Hammond and O’Grady 58 (as an extension of the earlier LCA study by Hammond et al. 75 (of version 1.1 of the pathways)), whereby GHG emissions reflected the sum of both upstream and operational emissions. The latter (‘stack’) emissions are those directly associated with the combustion of fossil fuels within power stations. Thus, the whole system emissions amount to those related to the ‘cradle-to-gate’. The national electricity network (operated by TNOs and DNOs) represents the downstream boundary known as the gate (hence, cradle-to-gate 75 ). In the studies by Hammond et al. 75 and Hammond and O’Grady, 58 they highlighted the significance of upstream emissions and their (technological and policy) implications, in contrast to the emphasis on power plant operational emissions conventionally presented by other analysts. These upstream environmental impacts arise from the energy requirements for extraction, processing/refining, transport and fabrication, as well as methane leakages from coal mining activities – a major contribution – and natural gas pipelines. The total carbon dioxide equivalent (CO2e) emissions associated with various power generators and UK electricity transition pathways towards a low carbon future are depicted in Figure 16 . This illustrates the GHG trajectory under each of the three transition pathways out to 2050. It was also found that CO2e capture facilities coupled to fossil-fuelled plants deliver only a 70% reduction in GHG emissions (including both upstream and operational emissions), in contrast to the normal presumption of a 90% saving.\nFigure 16. ‘Whole systems’ (upstream plus operational (or ‘stack’)) GHG emissions under the three UK transition pathways (1990–2050).\nGHG: greenhouse gas.\nSource: Adapted from Hammond and O’Grady. 58\nThe transition pathways LCA study by Hammond et al. 75 yielded estimates of pollutants or wastes released into the environment as a consequence of the UK ESI in terms of 18 separate impact indicators (together with a tentative single score, aggregate LCA measure). The lower the resulting score for each category (or the single score indicator) the better, although they doesn’t adequately reflect, for example, the impacts associated with nuclear power generation. Nuclear is low carbon, but has a number of other health and environmental impacts associated with the potential release of ionising radiation from nuclear power stations and processing plants. These are generally not effectively accounted for in LCA software tools, 75 because they do not have an underlying basis in ecotoxicology. Statistical weighting of the different LCA categories is normally achieved by the engagement of a panel of experts. It is therefore highly subjective, and this process would not be advisable in many cases. Clearly, it is difficult to manage something like 18 different impact categories, and consequently it is necessary to focus on key categories. Large impacts were found in terms of categories such as Human Toxicity, Freshwater Eutrophication, Marine Ecotoxicity and Natural Land Transformation 75 particularly under the MR pathway. Carbon emissions are the currency of debate in a climate-constrained world, 4 , 58 and consequently GHG emissions are typically given greater emphasis. There is likely to be a significant fall in carbon emissions from the UK power generation sector (see Figure 16 ) of some 31–51% by 2020, 65–86% by 2030 and 78–93% in 2050. 58 The lower figures relate to the MR pathway, whilst the higher ones are associated with the TF pathway. Notwithstanding the emphasis on GHG emissions, some of the other environmental burdens may need to be monitored.\nThe British Government’s independent Committee on Climate Change (CCC) has advocated deep cuts in power sector operational emissions through the 2020s, 46 with UK electricity generation being largely decarbonised by 2030–2040. In contrast, the present transition pathways projections (see again Figure 16 ) 58 indicate that the UK ESI could not be fully decarbonised by 2050 on the whole systems basis employed in the process-LCA studies. 58 , 75 This is because the present estimates take account of upstream, fugitive GHG emissions, whereas the projections by bodies like the CCC and Department of Energy and Climate Change (DECC) generally do not. Nevertheless, the transition pathways suggest that the ESI will be able to bear a significant share of the overall 80% carbon reduction target by 2050. The CCC analysis indicates that average operational emissions from the power generation sector would fall to around 50 gCO2/kWhe by 2030. 46 In contrast, the present MR pathway ( Figure 16 ) indicates that whole system emissions from the UK ESI are likely to only fall, accounting for upstream emissions, to ∼202 gCO2e/kWhe by 2030 and ∼105 gCO2e/kWhe by 2050. 58 The least impactful pathway (TF) suggests 58 that GHG emissions will fall to only ∼108 gCO2e/kWhe by 2030 and ∼53 gCO2e/kWhe by 2050 ( Figure 16 ). If the United Kingdom is to genuinely meet its legally-binding carbon reduction targets, then it will be necessary to account for upstream emissions from power generation. 58 , 75 Otherwise, even if the current UK carbon reduction targets are met, there will remain further emissions upstream.\nAn alternative way of evaluating the environmental impacts of the three UK transition pathways is via carbon and environmental footprinting. 4 , 71 Environmental or ecological footprints have been widely used in recent years as indicators of resource consumption and waste absorption associated transformed on the basis of biologically productive land area (in global hectares (gha)) required per functional unit (such as kWhe). They represent a partial measure of the extent to which an activity is sustainable. 4 , 71 In contrast, carbon footprints are the amount of carbon (or carbon dioxide equivalent) emissions associated with such activities in units of mass or weight (like kilograms per functional unit), although they can be translated into a component of the environmental footprint (on a gha basis). In order to determine the footprints associated with three UK transition pathways, the overall environmental footprint has been disaggregated into various components 71 : bioproductive and built land, carbon emissions, embodied energy, materials and waste, transport, and water consumption (see Figure 17 ). The total environmental footprint in the baseline year of 2010 was found from historic data to be 43 Mgha. In this case, the carbon and embodied energy footprint components were responsible for 80% to the total environmental footprint.\nFigure 17. Environmental footprints of the three UK transition pathways in 2050.\nSource: Adapted from Hammond. 71\nFuture environmental footprints were estimated for each of the three transition pathways. 4 , 71 Electricity demand was projected to decrease significantly under the TF pathway by 2050, but its total environmental footprint was nevertheless greater than either that under the MR or CC pathways (see again Figure 17 ). This is mainly due to the increase in the contribution of the bioproductive and built land component and that of the carbon footprint (rising to 10.9 and 12.5 Mgha respectively by 2050), 71 which are both seen to be higher than in either of the MR and CC cases. Thus increase in these TF pathway components was mainly due to increased usage of solid biofuels for power generation. In order to reduce the overall TF footprint it would therefore be necessary to adopt other renewable power technologies, like offshore wind and solar PV arrays, to satisfy the increase demands caused by electrification of heat and transport. The MR and CC pathways gave rise (see again Figure 17 ) to footprints of 23 and 25 Mgha respectively in 2050, as compared to 43 Mgha in the 2010 base year. 71 Here, the embodied energy component was the largest amongst the various footprint components; rising to 14 and 13 Mgha respectively by 2050. This was due to the large-scale use of fossil-fuelled power plants. There is a large reduction in carbon emissions under the MR pathway (over an 86% reduction compared to 2010 levels), whilst the CC pathway exhibits a slightly smaller fall (albeit nearly an 80% reduction). On the other hand, the TF pathway displays only 42% reduction in carbon emissions by 2050 ( Figure 17 ). Water and waste footprint components made almost negligible contributions under all three transition pathways (only ∼1% footprint share), although this was recognised as probably being an artefact of the footprint methodology and assumptions adopted. 71 Bioenergy and biofuel footprints and land-take (see again Table 2 ) reflect relatively large environmental burdens when compared to other fuels.\nThe carbon and environmental burdens associated with the three UK transition pathways have been assessed via environmental LCA and footprinting methods. Overall insights and lessons from such studies can be summarised as:\nA critical state-of-the-art review of this environmental LCA methodology57 has identified its current strengths and weaknesses for energy practitioners and policy analysts.\nThe extraction and delivery of fuel requires energy and creates GHG emissions. The upstream emissions associated with various power generators and UK electricity transition pathways have been evaluated on a whole systems basis. There will remain further emissions upstream that are unaccounted for by the CCC and DECC. They only account for upstream fugitive GHG emissions beyond UK borders.58,75\nThe carbon and environmental footprints of the three UK transition pathways have also been evaluated.71 The overall environmental footprints were disaggregated into: built land, carbon emissions, embodied energy, materials and waste, transport, and water consumption. This component-based approach has enabled the sustainability challenges to be assessed quite broadly, along with specific issues (e.g. the linkages associated with the so-called energy-land-water nexus).\nEconomic analysis and appraisal\nSection:\nAny transition pathway in the UK energy system will require very large expenditures in the capital intensive energy sector. The costs and potential benefits of such investments, as well as how these investments position key market participants in relation to a range of economic risks, are a critical element to the economic appraisal of such pathways. Economic considerations are the core consideration of market-led actors, while the government – in its social planning role – has a wider consideration of costs under a multi-criteria approach, but one in which a socially optimal transition pathway would reduce costs as far as possible. Many analysis frameworks of possible future energy transitions conduct only a post-calculation of costs (e.g. via the DECC 2050 Calculator or analysis by the UK energy market regulator (Ofgem)), whereas costs are a critical input into the formulation and decision making process in any transition pathway.\nMany existing energy modelling studies have been criticised for their limited treatment of societal actors and associated socio-political dynamics, together with poor representation of the co-evolving nature of society and technology. 76 It has therefore been argued that they consequently find it demanding to analyse socio-technical change. In parallel, it is evident that some of the prominent conceptual frameworks of socio-technical energy transitions (STET) find it difficult to operationalise policy development requirements in quantitative energy analyses. A review and critique of quantitative models for exploring STET was therefore undertaken by Li et al., 76 alongside their application to the energy supply, buildings and transport sectors. They subsequently devised a novel taxonomy for describing STET models 76 for integrating both quantitative modelling and conceptual socio-technical transitions, which incorporated techno-economic detail, explicit actor heterogeneity, and transition pathway dynamics. This study also highlighted a number of the challenges associated with their theoretical and behavioural validation, and proposed future development priorities for STET models. 76\nA stylised probabilistic energy system model (BLUE-MLP) has been constructed with key behavioural parameters on price and non-price drivers. The model has been extended to incorporate alternative actors, spatial and temporal detail. The initial version of the BLUE model was critically reviewed and validated by embedding it in the multi-model comparison exercise (see section ‘From narrative descriptions of the transition pathways to model formulation’ above, and Trutnevyte et al. 55 ). In addition, a literature overview for understanding the state-of-the-art research in behaviour and transition modelling was carried out. Participation in the qualitative-quantitative knowledge integration for demand response (see the above section) helped to collect further ideas on developing BLUE. The initial Excel economic appraisal of the transition pathways covers electricity generation, transmission and distribution. It takes account of the temporal and market participant elements. 77 The Excel economic appraisal (EconA) was embedded in the afore-mentioned multi-model comparison activity (see again section ‘From narrative descriptions of the transition pathways to model formulation’ above 55 ) in order to validate its findings against other realising transition pathway models. The implications of the multi-model comparison activity for the EconA and D-EXPANSE model were summarised by Trutnevyte et al. 55 (see both the sections ‘From narrative descriptions of the transition pathways to model formulation’ and ‘Annual demand modelling’ above). The D-EXPANSE model was used to model the UK power sector transition between 1990 and 2010, in order to get insights about the structural uncertainty of cost optimisation, and to systematically translate the transition pathways narratives into quantitative representations.\nClearly the costs and affordability of energy transitions are one of the most influential drivers in terms of the energy policy trilemma. But so also are the interactions between the power sector and other key economic sectors that drive decarbonisation in line with climate targets. A collaborative study between energy-economic modellers and power systems engineers from the Realising Transition Pathways Consortium therefore undertook a cost appraisal of the UK transition to a low-carbon electricity system under alternate governance logics. 77 This novel approach linked the quantitative electricity system transition pathways and their economic appraisal. Retirement of existing power plant capacity and the installation of new build was based on either DECC planned retirements 77 or estimated lifetimes. Costs of the transmission and distribution network infrastructures (see Figure 12 ) were modelled via the WeSIM 64 model – a successor to the HAPSO model 55 , 77 (see both the sections ‘From narrative descriptions of the transition pathways to model formulation’ and ‘Hourly demand profile modelling’ above). Outside the power system, only the costs of heat-producing devices (such as resistive heaters and gas boilers, community-scale and micro-CHP, and heat pumps) were included in the analysis. It focused on monetary costs and did not account for externalities, associated with the costs of different impacts on the environment 77 (like those considered within an LCA study, such as that described in the above section). The results (see Figure 18 ) contrast the dominant market-led MR transition pathway with alternate pathways that have either stronger governmental control elements (CC pathway), or bottom-up proactive engagement of civil society (TF pathway). The MR pathway exhibited the lowest investment costs out to 2050, whereas the CC pathway had slightly higher total system costs; presuming its implied government policies could be enacted and maintained. The bottom-up, more decentralised (TF) pathway was found to come at the expense of higher investment costs, 77 although it encourages wider participation with civil society. It requires significantly higher investment in renewable electricity generation, electric heating, and particularly EV transport. The spatial distribution of investment requirements under each UK pathway was another issue explored by the partnership of energy-economic modellers and power systems engineers (see Figure 9 ) (and section ‘From narrative descriptions of the transition pathways to model formulation’ above).\nDownload in PowerPoint\nFigure 18. Relative capital investment costs for the three UK transition pathways out to 2050. Source: Updated estimates based on Trutnevyte et al. 77\nEconomic appraisal of the three UK transition pathways 55 , 76 , 77 contributes to an understanding the future interplay of the energy policy trilemma, i.e. achieving deep GHG emission cuts, whilst maintaining a secure and affordable energy system. The insights and lessons from these studies can be summarised as:\nInvestment costing of the three UK transition pathways under very different governance and institutional arrangements was achieved via a novel collaborative study between energy-economic modellers and power systems engineers. 77 It showed that the TF pathway gave rise to the highest investment costs, due to the need for large-scale renewables (such as wind farms), electric heating, and principally EVs and their transport/charging infrastructure.\nFrom this novel STET taxonomy for integrating both quantitative modelling and conceptual socio-technical transitions, 76 methodological improvements in economic analysis of transition pathways were identified as being as important as the analytical insights from any given modelling comparison. For example, firstly understanding the spatial and temporal boundaries of any cost calculation, and secondly assessing if demand reductions are induced by policy instruments (a welfare loss) or attributed to lifestyle evolutions (no welfare loss) are fundamental challenges.\nStimulating investment in low-carbon options\nSection:\nAnalysis of historical energy transitions 30 – 32 (see section ‘Insights from historical transitions’ above) demonstrates that rapid change is possible, but not frequent, and requires a high degree of co-ordination of actions, driven by recognised need to change, e.g. the shift from Town Gas to natural gas. Potential low-carbon investors in the United Kingdom are faced with uncertainty about national policy priorities, and there are structural constraints on low-carbon investment, including immaturity of the sector and mismatches between fund manager and renewable energy investment timescales. 80 The economic feasibility of generation under all three transition pathways will depend on revenues from secondary markets/sources (e.g. the capacity market, FiT and various tax incentives). However, the ratio of the revenue needed from primary and secondary markets is case specific. Comparison with the situation in Germany demonstrates the valuable role that can be played by locally focused institutions, where civic ownership is supported by a local banking sector. 83\nA review of socio-technical systems research by Bolton and Foxon 78 argued that this approach can be operationalised to assess policy and societal challenges of large-scale investments in the low-carbon infrastructure. They observed that the United Kingdom is moving into a new phase of energy governance with significant demand for new investment to meet long-term climate policy objectives, as well as shorter term energy security challenges. The UK Government’s recent EMR aims to promote investment in large-scale low carbon technologies, through incentive schemes such as the contract for difference (CfD) and FiTs. They provide a guaranteed price for low carbon generation and thereby remove one significant uncertainty, although policy and political risks still remain. In further research, Bolton et al. 79 interviewed a range of energy policy and industry stakeholders, revealing different views on governance of energy systems. Those in favour of a liberalised market approach thought that the government should just set the rules, but otherwise not interfere to address price and other risks. In contrast, the mainstream investment community continues to be concerned that other risks could prevent large-scale investment in low-carbon generation. The Levy Control Framework, which was put in place out to 2020 with no clarity as to if it will be extended beyond that, has created an additional policy uncertainty for investors. Capacity markets have been introduced in order to ensure security of energy supply, indicating that this has greater priority than meeting carbon budgets (as reflected in recent UK Government energy policy pronouncements). This again creates uncertainty for investors, as experience indicates that regulatory frameworks and incentives are liable to change over time. In order to bring in new actors, such as mainstream institutional investors, better understanding of how they perceive these risks and uncertainties is required.\nA socio-technical approach has been employed 78 to this important area of policy debate in three specific areas: understanding long-term uncertainty and investment risks; avoiding technological lock-in; and accelerating the diffusion of low carbon finance niches. It explored the dynamics of long-term structural change in capital intensive systems (such as energy, housing and water supply with the aim of seeking to redirect them towards more sustainable long-term trajectories. Bolton and Foxon 78 argue that interventions need to balance the demands of private investors with wider social objectives. A better understanding of investment risk and uncertainty is required. Insights from the MLP of transitions theory suggest that it is necessary to avoid lock-in to current technologies, and the need to support low carbon finance niches.\nIn a follow-up study, Bolton et al. 79 examined the way in which actors in the UK electricity sector are attempting to deliver investment in low-carbon technologies. Such generation capacity is relatively immature and is capital intensive, although they have low operational costs. Empirical research 79 investigating the agency of incumbent regime actors in the face of uncertainty was based on interviews with 36 stakeholders from private and civic energy companies, mainstream and alternative investors, renewables project developers, energy policy makers and civil society. It was found that low-carbon generation does not readily fit into existing electricity markets and investment templates that were designed for a fossil fuel based energy system. The findings of Bolton et al. 79 can inform contemporary debates on the politics and governance of sustainability transitions and offers critical insights on the role of markets and finance in shaping socio-technical change. Key electricity market and infrastructure policies in the United Kingdom were analysed 79 in order to determine ways that low carbon technologies could be made investable. This research argued that this could be achieved by reducing uncertainty, better management of investment risks, and repositioning actors within the electricity socio-technical regime.\nThe role of financial markets in capitalising low-carbon energy systems and long-term change has been explored. 80 Capital requirements for energy system transitions are typically very large, and yet the literature has been curiously quiet on the role of capital markets in financing energy transitions. Stakeholder interviews identified that there are relatively few deals, whilst learning and adaptation are slow. Economic incentives, such as the CfD and FiT strike prices, or renewable obligation certificates (ROCs), are only one type of driver for change. This implies that providing stable incentives may not lead to market penetration of renewables investment. Hall et al. 80 have analysed the UK EMR process and the provision of renewable energy finance, and argued that an adaptive market hypothesis provides a useful framework for understanding the evolution of electricity markets in response to low carbon policy incentives. They demonstrated that the market for renewable energy finance does not conform to the standard efficient markets hypothesis, due to structural and behavioural constraints on investment. However, considering financial markets as being adaptive enables the range of policy responses for the acquisition of low-carbon investment to be much broader. 80\nPrimary data collection was undertaken by Hall and Foxon 81 to characterise the importance of a smart grid infrastructure within a UK energy transition. The UK economy and electricity system have co-evolved, but there remains a mismatch between the distribution of benefits and costs of investing in this infrastructure; leading to a problem of value capture and redeployment. Some benefits of smart grids are less easy to price directly, and are more accurately classified as public goods, such as energy security and decarbonisation. Hall and Foxon 81 drew on semi-structured interviews and focus groups involving UK smart grid stakeholders. This led them to identify municipal-scale developments as potential sources for new business models to deliver smart infrastructure. Municipalities may thus pursue specific economic opportunities with DNOs to make smart grid investments. This supports recent practical interest in an expanded role for municipalities as partners and investors in smart grid infrastructures.\nTransforming energy distribution networks will also play a key enabling role in a low-carbon energy transition in the energy, water and mobility sectors. But Bolton and Foxon 82 have argued that there is relatively little understanding of the social and institutional dimension of these systems, or appropriate institutional challenges to their transformation. This may be because the prevalent model of infrastructure governance in the energy and other sectors has prioritised short-term time horizons and static efficiencies. Bolton and Foxon 82 therefore discuss the appropriate governance strategies for developing flexible and sustainable systems of energy distribution. They draw on ideas from the social shaping of technology in order to develop a broader understanding of infrastructure change as a dynamic socio-technical process. A range of governance challenges to the development of electricity and heat networks are examined along the different phases of the infrastructure life cycle. Lessons are then drawn for the development of governance frameworks for the transformation of energy infrastructure more widely. 82 In the case of electricity distribution in Britain, the regulator (Ofgem) has sought to design suitable incentives to overcome barriers to long-term investment and innovation, although these are at an early stage of implementation. UK local authorities, by contrast, have struggled to finance large-scale infrastructure investments in the area of district heating (so energy-efficient and popular in the Scandinavian countries).\nA comparative analysis of recent energy policy developments in selected European countries (e.g. the German Energiewende) and on the implications of developments at a European level on UK energy policy (e.g. carbon pricing and market unbundling) has been reported by Hall et al. 83 Field research on the German situation drew out the implications for ownership, governance and financing of low carbon energy infrastructure. The German system differs from UK system in at least four ways. It had a much greater degree of decentralisation and municipal ownership, following post-War reconstruction. Their low-carbon transition or Energiewende was seen as a national priority. More decentralised political institutions in the German federal system enable a greater degree of energy policy experimentation. Finally, a more bank-based financial system in Germany, including a well-developed local banking system, contrasts with the centralised and market-based financial system in the United Kingdom. These local German banks have often built on local knowledge and encouraged small-scale renewable investment. They became key promoters of civic and community ownership of electricity generation assets. Such municipal ownership might again enable a similar, more long-term perspective to be taken in the United Kingdom, with a focus on good, safe, reliant energy infrastructure. Further economic and social benefits might then accrue to local municipalities.\nThese roles of actors, governance arrangements and regulations have been analysed in relation to realising market-led, government-led and civil society-led low carbon transition pathways, leading to the following findings:\nEnergy systems can best be understood as socio-technical systems made up of interacting technological and institutional elements, coevolving over time. Governance and regulatory frameworks are critical in managing risks for decision-makers and investors.\nChanges to investment support for low-carbon electricity generation have led to increasing risks and uncertainties, and concerns that long-term governmental commitment to decarbonisation may be undermined if the salience of energy security and cost priorities grows.\nAnalyses of energy finance as an adaptive market 80 help identify the lack of a mature community of investors, mismatches between investment and fund manager timescales, and lack of suitable investment vehicles. Capital markets are likely to change over the long-term to yield more adaptive markets for energy finance.\nThe economic feasibility of generation in all three pathways will depend on the revenue from secondary markets/sources, such as the capacity (ancillary service) market, FiT, and various tax incentives, although the ratio of the revenue needed from primary and secondary markets is case specific.\nA comparative UK–Germany analysis 83 has shown the importance of the local banking sector in facilitating civic ownership structures there.\nThe possibility of a low-carbon, decentralised transition (like that envisaged under the TF pathway) driven by civic energy systems has highlighted the role of local banking systems, and of shared values (including public service and local economic development). 83\nConcluding remarks\nSection:\nThe British Government has set a legally binding target of reducing the nation’s CO2 emissions by 80% by 2050 in comparison to a 1990 baseline. 6 This would ideally require the UK ESI to be decarbonised by around 2030–2050 in order to give more head room for carbon mitigation in other, more challenging sectors (such as industry and transport). 46 A set of three low-carbon transition pathways were developed and analysed via an innovative collaboration between engineers, social scientists and policy analysts. The pathways focus on the power sector, including the potential for increasing use of low-carbon electricity for heating and transport, within the context of critical European Union developments and policies. Their development started from narrative storylines regarding different governance framings, drawing on interviews and workshops with stakeholders and analysis of historical analogies. The quantified UK pathways were named Market Rules (MR), Central Co-ordination (CC) and Thousand Flowers (TF); each representing a dominant logic of governance arrangements – recently described by the Chief Executive Officer of a prominent UK renewable electricity supplier and generator company (unconnected with the project) as reflecting blue, red and green pathways respectively. These pathways have been used to explore what is needed to realise a transition that successfully addresses the so-called energy policy trilemma, i.e. the simultaneous delivery of low carbon, secure and affordable energy services. Such energy transitions are never smooth and always subject to contestation, negotiation and social change. The UK ESI has already undergone quite rapid change over the last few years. 84 Coal power station closures, for example, have amounted to 15 GW between 2010 and 2015; with combined cycle gas turbine plant closures accounting for a further 4 GW. In contrast, there has been a rapid rise in solar PV systems that now stands at around 853,000 installations, for which rooftop solar alone now accounts for >1% of UK electricity supply. 84 The recent British Government energy policy reset, the components of which will only become clear during 2017 (although some senior executives in the UK power sector speculate that it will propose roughly 30% nuclear, 30% renewables, and 30% gas) will lead to additional changes going forward. Thus, if the three transition pathways were being developed today they would no doubt contain rather different energy mixes. The TF pathway might contain more solar PV, but less bioenergy, for instance. Nevertheless, the insights gained from this exercise still provide a valuable evidence base for developers, policy makers and other stakeholders.\nA fundamental requirement for identifying and addressing the multiple challenges and opportunities posed by energy policy and climate change necessitates a combination of academic knowledge with that from industry, commerce, regulatory bodies, political and societal communities. This ambitious goal appears to be more achievable in processes that combine the analytic (the systematic application of expert knowledge) with the ‘deliberative’ (the systematic application of opportunities for face-to-face discussions between experts, stakeholders and citizens). 85 , 86 The ‘Realising Transition Pathways’ Consortium has adopted the practice of the co-production of knowledge to explore and integrate different kinds of expertise in order to provide opportunities for reflection and evaluation. It has attempted to achieve a level of joint working that allows the effective sharing of disciplinary-specific and professional expertise. New evidence and case studies of UK energy transitions provide practical advice on how sustainable energy transitions will depend on science and policy institutions becoming more responsive and adaptive to distributed societal actions. Here the challenges, insights and opportunities that have been gleaned from this research are highlighted (via bullet point summaries at the end of each principal section above).\nAnalytical tools were developed and applied to assess the technical feasibility, social acceptability, and environmental and economic impacts of the pathways. Technological and behavioural developments were examined, alongside appropriate governance structures and regulations for these low-carbon transition pathways, as well as the roles of key energy system actors (both large and small). An assessment of the part that could possibly be played by future demand responses was also undertaken in order to understand the factors that drive energy demand and energy-using behaviour. A set of interacting and complementary engineering and techno-economic models or tools were then employed to analyse electricity network infrastructure investment and operational decisions to assist market design and subsidy mechanisms. This provided a basis for integrating the analysis within a whole systems framework of electricity system development, together with the evaluation of future economic benefits, costs and uncertainties. Likewise, the energy and environmental performance of the different energy mixes were appraised on a life-cycle basis to determine the GHG emissions and other ecological or health burdens associated with each of the three transition pathways. The UK Carbon Budgets 46 are presently on track for an 80% reduction (in production emissions) by 2050, although it has been observed here 58 that the impact of upstream (and consumption) GHG emissions are generally excluded. The impact of such upstream emissions on the carbon performance of technologies (such as combined heat and power (CHP) and CCS) and the transition pathways themselves 58 distinguish the present findings from those of other analysts, such as the CCC and DECC. None of the three pathways yield zero GHG emissions by 2050, which suggests that the UK electricity sector cannot realistically be decarbonised by 2030–2040 as advocated by the CCC. 46\nSocio-technical solutions are required on both the demand and supply-side of any future UK energy system. Reduction in energy demand for heat, power and transport will be a significant element of any energy strategy aimed at limiting global warming to <2 ℃ under whatever pathways actually results out to mid-century. 87 , 88 Improvements in energy efficiency can be obtained from better thermal insulation of the building fabric, smart appliances and controls, alongside the adoption of efficient heating systems, such as heat pumps, community energy schemes and the like. In addition, lifestyle or workplace changes, DSR and DSP may well be needed, but these will be partially offset by so-called rebound effects. Decarbonising the supply-side is likely to see the continued adoption of new nuclear build (although the whole system costs may be prohibitive), offshore wind, and rooftop solar PV. It will inevitably need the take-up of CCS (as well as carbon capture and utilisation (CCU)) for a cost-efficient transition, together with sustainable bioenergy and biofuels, and possibly hydrogen (H2) as a fuel and energy storage media in the long term. Unfortunately, there are constraints over the use of bioenergy resources, including uncertainties over the availability of UK sustainably-sourced biomass, land use challenges, and competition with food supply. Finally, the energy infrastructure in Britain will need renewal in order to make it more resilient (e.g. to climate change impacts) and to potentially accommodate greater decentralised or distributed generation, including greater use of both large and small energy storage devices. Significant generation, transmission and distribution network reinforcements (operating with much lower utilisation factors) will be needed to meet future changes in demand and generation patterns. However, smart power innovations (a combination of interconnectors, storage and demand flexibility (or DSR)) could generate £8 bn per year of savings (according to a report for the recently-established UK National Infrastructure Commission 89 ; for which a member of the Realising Transition Pathways Consortium (Goran Strbac and his team) played a key role 90 ). Indeed, in a risk assessment study of the UK power sector, Hammond and Waldron 11 found that lack of investment in new infrastructure to be ranked the second highest risk to the power sector by different stakeholder groups (academic researchers, civil servants, electricity companies, green groups, power system engineers and various others). The electricity grid was found to be arguably the most vulnerable part of the power system; reinforcing the case for UK network renewal and reconfiguration by the middle of the 21st century. 4 , 11 Innovation, systems integration, and whole systems thinking to identify sustainable energy options (sometimes termed optionality in industry), as examined in the present study, will therefore be critically important in the transition towards a low-carbon future.\nAcknowledgements\nThe authors are particularly grateful for the critical, but supportive, views of members of the project Advisory Board (chaired by James Smith, former chairman of Shell UK and presently chairman of the UK Carbon Trust) made up of industrial representatives, UK Government policy makers and other stakeholders. The authors are also grateful for insights provided by an anonymous reviewer from climate, energy and innovation policy perspectives. However, the views expressed in this paper are the responsibility of the authors alone and not the external collaborators or the funding body.\nThe authors’ names are listed alphabetically.\nDeclaration of Conflicting Interests\nThe author(s) declared no potential conflicts of interest with respect to the research, authorship, and/or publication of this article.\nFunding\nThe author(s) disclosed receipt of the following financial support for the research, authorship, and/or publication of this article: This work draws on research undertaken as part of a major research grant awarded by the UK Engineering and Physical Sciences Research Council (EPSRC) entitled ‘Realising Transition Pathways - Whole Systems Analysis for a UK More Electric Low Carbon Energy Future’ [under Grant EP/K005316/1]. The authors are grateful to this sponsor, as well as for the interchanges with the main UK-based post-doctoral researchers associated with the project (see the project website www.realisingtransitionpathways.org.uk for a full list of those involved).\nReferences\n""","0.25293374","""http://journals.sagepub.com/doi/10.1177/0957650917695448""","[-0.178219,51.500505]"
"""University_of_Exeter""","""A Multi-Objective Optimization for Supply Chain Network Using the Bees AlgorithmInternational Journal of Engineering Business Management - Ernesto Mastrocinque, Baris Yuce, Alfredo Lambiase, Michael S. Packianather, 2013""","""1. Introduction\nSection:\nNowadays, the complexity of the business environment is rapidly increasing [ 1 ]. This is due to several factors such as the expansion of the market, a wide range of suppliers, increased competition and customers demands on the performance of a company, in particular, the waiting time, cost and quality of the product [ 2 ]. Among these factors, if we consider the range of suppliers to the market, it is necessary to design an optimized supply chain model [ 3 ]. The supply chain is a complex network from suppliers to customers, which involves people, technologies, activities, information and resources. Its design and management has the purpose of obtaining the best global performances under unions operating criteria [ 4 ]. A typical supply chain is composed of the following elements: suppliers, manufacturing plants, warehouses, distribution centres (DCs), customers/final markets.\nThe optimization of a supply chain is related to selecting the optimum resource options in order to satisfy the objective function / functions. The single objective-based supply chain models are mostly aimed at finding the minimum total cost [ 5 , 6 ]. However, the modelling of a supply chain requires more than a single-objective such as lead-time minimization, inventory level minimization, service level maximization, environmental impact maximization and so on [ 7 ]. Sometimes these objectives may cause conflicts such as increasing the service level usually causes a growth in costs. Therefore, the aim must be to find trade-off solutions to satisfy the conflicting objectives.\nIn multi-objective optimization problems there is no single optimum solution, but there is a solution set which creates Pareto optimal solutions. Pareto optimal solutions are a set of trade-offs between different objectives and are non-dominated solutions, i.e., there is no other solution which would improve an objective without causing a worsening in at least one of the other objectives [ 8 ].\nIn the literature, several models have been proposed to solve supply chain design problems to get the Pareto optimal solutions. Most of these models are based on genetic algorithms and the fuzzy logic approach. Work has been done on the facility location problem of a four echelons supply chain (suppliers, plants, DCs and customers) [ 9 ]. The objectives of this work are to minimize the total cost, maximize customer services and the capacity utilization balance for DCs using a genetic algorithm-based approach.\nAnother reported work on supply chains is based on the supplier selection, product assembly and distribution system using a modified Pareto genetic algorithm to minimize the total cost and delivery time, and maximize the quality [ 10 ].\nA multi-objective location-inventory problem has been investigated using a multi-objective evolutionary algorithm based on the non-dominated sorting genetic algorithm II (NSGAII) in order to minimize total costs and maximize the volume fill rate and the responsiveness level [ 11 ].\nAn optimum mathematical planning model for green partner selection, which involves four objectives which are cost, time, product quality and green appraisal score, has been developed in [ 12 ]; this model employed two types of genetic algorithms to solve multi-objectives and then to find the set of Pareto optimal solutions. In this study, the weighted sum approach that can generate a greater number of solutions has been proposed.\nIn [ 13 ], the authors have developed a multi-objective fuzzy mathematical programming model for a forward/reverse supply chain minimizing the total cost and the environmental impact. This approach is composed of two parts: in the first phase the method of Jimenez et al. [ 14 ] is applied to convert the proposed multi-objective probability mixed integer programming model into an equivalent auxiliary crisp model, and in the second phase a fuzzy solution method based on the e-constraint method to find the final preferred compromise solution has been proposed.\nA multi-product, multi-stage and multi-period scheduling model is proposed in [ 15 ] to deal with multiple incommensurable goals for a multi-echelon supply chain network with uncertain market demands and product prices; a two-phase fuzzy decision-making method is presented to maximize the participants' expected profits, average safe inventory levels, average customer service levels and robustness of selected objectives to demand uncertainties.\nA bi-objective optimization approach to the designing and planning of a supply chain is proposed in [ 16 ] in order to maximize the annual profit and minimize the environmental impact; profit and environmental impacts are balanced using an optimization approach adapted from symmetric fuzzy linear programming, while the supply chain is modelled as a mixed integer linear programming optimization problem using the resource-task-network methodology.\nIn [ 17 ], a multi-objective evolutionary algorithm called the fuzzy logic non-dominated sorting genetic algorithm II (FL-NSGAII) is used to solve a multi-objective optimization problem of vehicle routing in which multiple depots, multiple customers and multiple products are considered; the travelling distance and the total travelling time are the two objective functions to be minimized.\nA random fuzzy multi-objective mixed-integer non-linear programming model for the supply chain design problem has been proposed in [ 18 ], with a spanning tree-based genetic algorithm in order to minimize the total cost and maximize customers service level.\nThe model in [ 19 ] deals with the planning of a multi-product, multi-period and multi-echelon supply chain network that consists of several existing plants at fixed places, some warehouses and distribution centres at undetermined locations, and a number of given customer zones. The supply chain planning model is constructed as a multi-objective mixed-integer linear program to satisfy several conflicting objectives, such as minimizing the total cost, raising the decision robustness in various product demand scenarios, lifting the local incentives, and reducing the total transport time. A two-phase fuzzy decision-making method has been proposed.\nIn [ 20 ], the proposed method is a bi-objective mathematical programming formulation which minimizes the total costs and the expected transportation costs after failures of facilities of a logistics network; a new hybrid solution methodology is introduced by combining the robust optimization approach, queuing theory and fuzzy multi-objective programming.\nIn addition to the above genetic algorithm and fuzzy logic-based supply chain models, several other models have also been proposed in particular based on the swarm-based optimized models. One of the swarm-based model has been proposed on an inventory model for an assembly supply chain network which has fuzzy demand for single products and a fuzzy reliability of external suppliers effect on determination of inventory policy [ 21 ]. The performance of the supply chain is assessed by two criteria including total cost and fill rate. To solve this bi-criteria model, hybridization of multi-objective particle swarm optimization and simulation optimization is considered. In [ 22 ], an optimization mathematical model integrating cost and time criteria has been solved using a modified particle swarm optimization method (MEDPSO) for solving a multi-echelon unbalanced supply chain planning problem. The results indicated that the MEDPSO method can obtain a better quality solution compared to classical GA and PSO.\nFurthermore, another swarm-based optimization model is proposed for a resource options selection problem in a bulldozer supply chain design in [ 23 ]. The model is based on the ant colony optimization technique to solve the multi-objective problem and to find the Pareto solution set where the aim is to find the best combination of the resource options by minimizing the total cost and the total lead-time.\nIn this work, the optimization of the bulldozer supply chain problem given in [ 23 ] has been selected because of the complexity of the supply chain network and its general combinatorial nature that makes it suitable for various supply chain problems, and the bees algorithm (BA), which is another swarm-based optimization technique, is proposed to solve this problem [ 24 ]. The algorithm is based on the food foraging behaviour of a swarm of bees combining a random search with a neighbourhood search. The BA has been successfully applied to several optimization problems [ 25 – 42 ].\nThere is no single algorithm which can find the best solution for all types of optimization problems according to the no-free lunch theorem [ 43 ]. In previous work, the BA has been shown to have better performance compared to the following optimization algorithms tested for continuous type benchmark functions; simplex method, stochastic simulated annealing, genetic algorithm, ant colony optimization [ 44 ]. Hence, the BA has been selected for the bulldozer supply chain problem. Note that the results found by the ant colony optimization in [ 23 ] were not global optimum. The aim of this study is to improve on the previously reported results using a multi-objective optimization approach based on the BA. The bees algorithm has also been proven to be a valid approach to get the Pareto optimal set for multi-objective problems [ 45 – 47 ]. In [ 45 ], the BA has been tested on the classical environmental/economic dispatch problem (EEDP). The EEDP was amended in conjunction with the bees algorithm to identify the best design in terms of energy performance and carbon emission reduction by adopting zero and low carbon technologies. This computer-based tool supports the decision-making process in the design of a low-carbon city. The algorithm is also tested on a welded beam design problem which involves two non-linear objective functions and seven constraints [ 46 , 47 ]. The BA results have been compared with those obtained with the non-dominated sorting genetic algorithm (NGSA) and the NGSAII, and it has been shown that the bees algorithm is able to find more non-dominated solutions.\nThe bees algorithm-based supply chain optimization model is implemented on a resource options selection problem which has been taken from the literature in order to minimize the total cost and the total lead-time of the supply chain. Several numerical experiments have been conducted in order to show the performance of the algorithm on a Pareto solutions set and later compare them to those achieved by the ant colony optimization.\nThis study is organized as follows: the description of the bees algorithm is given in section 2 , the multi-objective optimization with the bees algorithm is given in section 3 , the supply chain case study model is given in section 4 , the experimental study is given in section 5 , the results are given in section 6 and finally conclusions are given in section 7 .\n2. The bees algorithm optimization\nSection:\n2.1. Bees foraging process in nature\nDuring the harvesting season, a bee colony employs part of its population to scout [ 48 , 49 ] the fields surrounding the hive. Scout bees move randomly looking for food sources. When they return to the hive, scout bees deposit the nectar (or pollen) that they have collected during the search process. Then they start to do a ritual called the “waggle dance” to communicate with other bees and give them information about the food source [ 50 ]. The waggle dance is performed on a particular area of the hive called the “dance floor”, and communicates three basic pieces of information regarding the flower patch: the direction in which it is located, its distance from the hive, and its quality rating [ 49 , 51 ]. After the waggle dance, the dancer bee goes back to the flower patch with its followers, called recruited bees. The number of recruited bees depends on the quality rating of the patch. Flower patches that contain rich and easily available nectar or pollen sources attract the largest number of followers (foragers) [ 50 , 52 ]. Once a recruited forager returns to the hive, it will in turn waggle dance to direct other idle bees towards the food source.\n2.2. The bees algorithm\nThe bees algorithm is an optimization algorithm inspired by the natural foraging behaviour of honey bees to find the optimal solution. The flow chart of the algorithm is shown in Figure 1 .\n""","0.18225986","""http://journals.sagepub.com/doi/10.5772/56754""","[-3.533832,50.735262]"
"""Imperial_College_London""","""Technologies to measure indicators for road user charging | Proceedings of the Institution of Civil Engineers - Transport""","""Proceedings of the Institution of Civil Engineers - Transport\nProceedings of the Institution of Civil Engineers - Transport\nISSN 0965-092X | E-ISSN 1751-7710\nTechnologies to measure indicators for road user charging\nAuthors: \nMSc, PhD, FRIN, FInstCES, MICE, MIHT\nx\nEdward J. Bloustein School of Planning and Public Policy, Rutgers University, New Brunswick, NJ, USA\n, ,\nPublished Online: May 25, 2015\nKey:\nTrial content\nAbstract\nA technically and economically feasible road user charging scheme should be based on quantities that are readily and accurately measurable, as well as being directly variable with the amount of road use and its impact on the environment and society. A key requirement for a pricing scheme is that the charging regime used should be easy for motorists to understand, but at the same time flexible enough for the operator to implement a wide range of policies to meet different aims. A set of variable road user charging indicators is identified herein by considering both the associated costs of a trip and the operational requirements for a feasible road pricing scheme. The study then focused on identifying a set of currently feasible technologies to measure these variables in real-time with high accuracy. Particular attention was paid to the need accurately to track vehicle movements and link these movements to geographical areas and road types, and the key pollutants and particulate matter, all of which have different potential effects that are in some cases dependent on location and time of emissions. Other issues, such as congestion measurement, are also discussed.\nKeywords:\n""","0.4874832","""http://www.icevirtuallibrary.com/doi/10.1680/tran.2010.163.2.63""","[-0.178219,51.500505]"
"""Imperial_College_London""","""Outdoor air pollution and respiratory health in Asia - CHUNG - 2011 - Respirology - Wiley Online Library""","""Outdoor air pollution and respiratory health in Asia\nAuthors\nKIAN FAN CHUNG,\nCorresponding author\nNational Heart and Lung Institute, Imperial College, and NIHR Biomedical Research Unit, Royal Brompton Hospital, London, UK\nCited by (CrossRef): 22 articles Check for updates\nCitation tools\nCiting literature\nThe Authors: Dr Kian Fan Chung is Professor of Respiratory Medicine at the National Heart and Lung Institute, Imperial College London, Senior Investigator of the National Institute for Health Research, UK, and is an expert on the respiratory effects of environmental pollution and their mechanisms. Dr Junfeng (Jim) Zhang is Professor of Environmental and Global Health in Department of Preventive Medicine, Keck School of Medicine at the University of Southern California and has expertise in human exposure assessment to Environmental contaminants and resulting health effects, and gene-environment interactions. Dr Nanshan Zhong is Professor of Respiratory Medicine at the Guangzhou Medical College and Head of Guangzhou State Key Laboratory of Respiratory Disease. He is an expert on prevention and management of COPD in China.\nKian Fan Chung, National Heart and Lung Institute, Imperial College, Dovehouse Street, London SW3 6LY, UK. Email: f.chung@imperial.ac.uk\nABSTRACT\nWith the rapid economic development occurring in the last decade in many countries of Asia, the level of air pollution has increased from both industrial and motor vehicle emissions. Compared with Europe and North America, the potential health effects of this increasing air pollution in Asia remain largely unmeasured. Recent data published by the Health Effects Institute from some major cities in India and China reveal that a 10 µg/m3 increase in PM10 was associated with an increase in mortality of 0.6% in daily all-natural cause mortality, with higher risks being found at extremes of high temperatures and in the lowest economically advantaged population. Other Asian studies have confirmed the link between hospital admissions for the worsening of COPD and the increase in asthma prevalence to levels of outdoor air pollutants. Although potential health effects appear to be similar to already-published Western data, it is important that further studies be carried out in Asia that will inform the public and the authorities of the necessity to curb levels of outdoor air pollutants to acceptable levels.\nAccepted manuscript online:\n15 August 2011\nReceived 7 July 2011; invited to revise 27 July 2011; revised: 2 August 2011; accepted 2 August 2011 (Associate Editor: David Hui).\nRelated content\nArticles related to the one you are viewing\nCiting Literature\n""","0.42113405","""http://onlinelibrary.wiley.com/doi/10.1111/j.1440-1843.2011.02034.x/abstract""","[-0.178219,51.500505]"
"""Brunel_University_London""","""Editorial | Proceedings of the Institution of Civil Engineers - Transport""","""Proceedings of the Institution of Civil Engineers - Transport\nProceedings of the Institution of Civil Engineers - Transport\nISSN 0965-092X | E-ISSN 1751-7710\nPhD, CEng, MCIHT, MICE, PGCHE, FHEA\nx\nDepartment of Mechanical, Aerospace and Civil Engineering, Brunel University, London, UK\nAuthor Affiliations\nPublished Online: July 11, 2016\nKey:\nFree content\nTrial content\nWelcome to the August 2016 issue of Transport. This edition presents six papers covering important theoretical and practical aspects of transportation engineering. On behalf of the editorial board, I thank the authors for their hard work and valuable contributions to the journal. I would also like to extend my appreciation to our esteemed reviewers for their invaluable support.\nTransport networks are one of the most important national assets. Economic prosperity, rapid urbanisation, increasing traffic and ageing infrastructures all have immense impact on safe and efficient operation of this vital asset. Some of these factors are addressed in this issue.\nThe first paper ( Appiah et al., 2016 ) deals with truck characteristics in traffic micro-simulation. The authors present an approach to incorporating the operating characteristics of a local truck fleet in the calibration of micro-simulation models. This approach is different from conventional model calibration where focus is given to adjusting the parameters of driving behaviour logic. The second paper ( Mohapatra et al., 2016 ) reports the influence of conflicting traffic on U-turns at uncontrolled median openings under mixed traffic conditions in an Indian context. With rapid urbanisation and increased traffic volume, most urban roads in India are constructed as multi-lane roads, while many existing two-lane roads are also being widened to multi-lane roads. These multi-lane roads are generally constructed with a raised median, in order to segregate the opposing traffic movements. The authors showed that the impact of conflicting traffic is greater on four-lane roads compared to six-lane roads. In the third paper ( Zong et al., 2016 ), the authors present a model for investigating the feasibility of an integrated transportation demand management (TDM) programme in the Nanhai district of China to mitigate the traffic congestion and reduce exhaust gas emission from motor vehicles. The TDM programme includes a bus priority policy, a motorcycle restriction policy and a congestion pricing policy. The authors demonstrate that all three policies would have a positive effect on Nanhai's transport system. All three papers address key transport issues which traffic engineers and researchers will find very useful.\nIn recent years, railway industries have faced a massive demand for increasing train speeds. However, switch and turnout parts of the track are two critical parts where speed reduction is necessary. In order to develop a more efficient system, the fourth paper ( Sadeghi et al., 2016 ) presents a mathematical model of the impact of railway geometry on the safety of train running and permissible speed. The model is based on the railway vehicle and track parameters such as curve radius, switch initial angle and track gauge with running speed. The model accuracy is verified in field trials. This paper is a good example of how theoretical modelling could help to solve practical issues.\nThe fifth and sixth papers address concrete pavement rehabilitation. The fifth paper ( Lu and Rong, 2016 ), presents the impact of gradation on rubblised Portland cement concrete pavement. Rubblisation is a popular technique for upgrading severely deteriorated concrete pavement. Many previous studies have shown that rubblised concrete with a hot-mix asphalt (HMA) overlay improves pavement performance, especially its cracking resistance. The authors present two studies and demonstrate that if the rubblised gradation matches the requirement for the crushed stone base of the flexible pavement, tensile strains at the HMA overlay bottom develop at a slower pace, indicating an improvement in deterioration resistance (namely cracking) of the overlay system. This article should be a good resource for practitioners and researchers alike. The final paper ( Gao, 2016 ), presents a mathematical model for evaluating the impact of top-down surface cracking in concrete pavement. Surface cracks of concrete pavement not only impact safety and ride quality, but also reduce service life. The author shows that crack length and load position significantly influence the stress intensity factors, and that stress intensity factors are less affected by the elastic modulus of the pavement material than might be expected. Observing that studies on the mechanism of crack propagation in a cement concrete pavement are rather limited, this paper should serve to enhance current knowledge in this field.\nWe trust you find these papers useful and rewarding to read. Comments on this issue or on general journal-related matters will be received with great interest.\nReferences\n""","0.45108706","""http://www.icevirtuallibrary.com/doi/10.1680/jtran.2016.169.4.185""","[-0.472855,51.532848]"
"""Imperial_College_London""","""Fracture analysis of composite co-cured structural joints using decohesion elements - CAMANHO - 2004 - Fatigue & Fracture of Engineering Materials & Structures - Wiley Online Library""","""Fatigue & Fracture of Engineering Materials & Structures\nPrevious article in issue: Current fatigue and fracture research in Portugal\nPrevious article in issue: Current fatigue and fracture research in Portugal\nFracture analysis of composite co-cured structural joints using decohesion elements\nAuthors\nCited by (CrossRef): 38 articles Check for updates\nCitation tools\nCorrespondence: Pedro P. Camanho. E-mail: pcamanho@fe.up.pt\nABSTRACT\nDelamination is one of the predominant forms of failure in laminated composite structures, especially when there is no reinforcement in the thickness direction. To develop composite structures that are more damage tolerant, it is necessary to understand how delamination develops, and how it can affect the residual performance. A number of factors such as residual thermal stresses, matrix-curing shrinkage and manufacturing defects affect how damage will grow in a composite structure. It is important to develop computationally efficient analysis methods that can account for all such factors. The objective of the current work is to apply a newly developed decohesion element to investigate the debond strength of skin-stiffener composite specimens. The process of initiation of delaminations and the propagation of delamination fronts is investigated. The numerical predictions are compared with published experimental results.\nReceived in final form 20 June 2003\nRelated content\nArticles related to the one you are viewing\nCiting Literature\nNumber of times cited: 38\n1\nFarshid Kamareh, Amin Farrokhabadi, Gholamhossein Rahimi, Experimental and numerical investigation of skin/lattice stiffener debonding growth in composite panels under bending loading, Engineering Fracture Mechanics, 2018, 190, 471\nCrossRef\n2\nGuangyan Liu, Hongchen Bao, Kaili Tang, Damage prediction in notched fiber-reinforced composite laminates, Composite Interfaces, 2017, 24, 3, 279\nCrossRef\n3\nH. Saghafi, S.R. Ghaffarian, D. Salimi-Majd, H.A. Saghafi, Investigation of interleaf sequence effects on impact delamination of nano-modified woven composite laminates using cohesive zone model, Composite Structures, 2017, 166, 49\nCrossRef\n4\nS.J. Moreira, S.M.O. Tavares, P.M.S.T. de Castro, Morphing structures and fatigue: The case of an unmanned aerial vehicle wing leading edge, Fatigue & Fracture of Engineering Materials & Structures, 2017, 40, 10, 1601\nWiley Online Library\n5\nMoharram Shameli, Naghdali Choupani, Fracture Criterion of Woven Glass-Epoxy Composite Using a New Modified Mixed-Mode Loading Fixture, International Journal of Applied Mechanics, 2016, 08, 02, 1650015\nCrossRef\n6\nGuangyan Liu, Kaili Tang, Study on stress concentration in notched cross-ply laminates under tensile loading, Journal of Composite Materials, 2016, 50, 3, 283\nCrossRef\n7\nYi Xiao, Wenjing Qiao, Hiroshi Fukuda, Hiroshi Hatta, The effect of embedded devices on structural integrity of composite laminates, Composite Structures, 2016, 153, 21\nCrossRef\n8\nGuillermo Vigueras, Federico Sket, Cristóbal Samaniego, Ling Wu, Ludovic Noels, Denny Tjahjanto, Eva Casoni, Guillaume Houzeaux, Ahmed Makradi, Jon M. Molina-Aldareguia, Mariano Vázquez, Antoine Jérusalem, An XFEM/CZM implementation for massively parallel simulations of composites fracture, Composite Structures, 2015, 125, 542\nCrossRef\n9\nS. Abrate, J. F. Ferrero, P. Navarro, Cohesive zone models and impact damage predictions for composite structures, Meccanica, 2015, 50, 10, 2587\nCrossRef\n10\nR.S. Choudhry, Syed F. Hassan, S. Li, R. Day, Damage in single lap joints of woven fabric reinforced polymeric composites subjected to transverse impact loading, International Journal of Impact Engineering, 2015, 80, 76\nCrossRef\n11\nM.M. Thawre, K.N. Pandey, A. Dubey, K.K. Verma, D.R. Peshwe, R.K. Paretkar, N. Jagannathan, C.M. Manjunatha, Fatigue life of a carbon fiber composite T-joint under a standard fighter aircraft spectrum load sequence, Composite Structures, 2015, 127, 260\nCrossRef\n12\nGergely Czél, Meisam Jalalvand, Michael R. Wisnom, Luis P. Canal, Carlos D. González, Javier LLorca, Novel experimental procedure and determination of full displacement fields of delaminating composite layer interfaces for evaluation of the mode II cohesive law, Engineering Fracture Mechanics, 2015, 149, 326\nCrossRef\n14\nL. Wu, D. Tjahjanto, G. Becker, A. Makradi, A. Jérusalem, L. Noels, A micro–meso-model of intra-laminar fracture in fiber-reinforced composites based on a discontinuous Galerkin/cohesive zone method, Engineering Fracture Mechanics, 2013, 104, 162\nCrossRef\n15\nS. Psarras, S.T. Pinho, B.G. Falzon, Investigating the use of compliant webs in the damage-tolerant design of stiffener run-outs, Composites Part B: Engineering, 2013, 45, 1, 70\nCrossRef\n16\nS.L. Lemanski, J. Wang, M.P.F. Sutcliffe, K.D. Potter, M.R. Wisnom, Modelling failure of composite specimens with defects under compression loading, Composites Part A: Applied Science and Manufacturing, 2013, 48, 26\nCrossRef\n17\nPaul W. Harper, Lu Sun, Stephen R. Hallett, A study on the influence of cohesive zone interface element strength parameters on mixed mode behaviour, Composites Part A: Applied Science and Manufacturing, 2012, 43, 4, 722\nCrossRef\n18\nH. M. Nick, A. Paluszny, M. J. Blunt, S. K. Matthai, Role of geomechanically grown fractures on dispersive transport in heterogeneous geological formations, Physical Review E, 2011, 84, 5\nCrossRef\n19\nJ. CHEN, Simulation of multi-directional crack growth in braided composite T-piece specimens using cohesive models, Fatigue & Fracture of Engineering Materials & Structures, 2011, 34, 2, 123\nWiley Online Library\n20\nMorten G. Ostergaard, Andrew R. Ibbotson, Olivier Le Roux, Alan M. Prior, Virtual testing of aircraft structures, CEAS Aeronautical Journal, 2011, 1, 1-4, 83\n""","0.2946824","""http://onlinelibrary.wiley.com/doi/10.1111/j.1460-2695.2004.00695.x/abstract""","[-0.178219,51.500505]"
"""The_University_of_Edinburgh""","""Representing active travel: a formative evaluation of a computer visualisation tool demonstrating a new walking and cycling route - Edinburgh Research Explorer""","""Representing active travel: a formative evaluation of a computer visualisation tool demonstrating a new walking and cycling route\nResearch output: Contribution to journal › Article\nExport citation\nDownload as Adobe PDF\nRights statement: © Bill, E., Baker, G., Ferguson, N. S., Drinkwater, D., & Mutrie, N. (2015). Representing active travel: a formative evaluation of a computer visualisation tool demonstrating a new walking and cycling route. Environment and Planning B: Planning and Design , 42. 10.1068/b130155p\nAccepted author manuscript, 271 KB, PDF-document\nEnvironment and Planning B: Planning and Design\nVolume\nTransport and public health researchers have a shared interest in the promotion\nof active travel. Walking and cycling are activities that may help to achieve health\nbenefits while also contributing to wider sustainability goals, such as a reduction in carbon emissions from transport, improvements in air quality, and reduced congestion. A variety of interventions have been used to promote travel behaviour change, for example, infrastructure change and personalised travel planning. Some researchers have directed their interest towards the potential of technology and visual representation to motivate and engage individuals to increase their sustainability practices. Computer visualisation tools may be an instrument to prompt behaviour change, leading to a shift towards\nmore active modes of travel. Visualisation technology has been used for many purposes, including raising awareness of global environmental problems, scenario modelling, and the representation of walking and cycling futures. Recently, the availability of large datasets has led to the visualisation of system-usage data from cycle-hire schemes. Elsewhere, various representations of personal journey data have been evaluated in terms of their\ncapabilities to change behaviour. Currently, it is thought that the technical possibilities of visualisations exceed the knowledge of their correct application. Therefore, methods and guidelines for producing and applying visualisations are required. To our knowledge there has been no evaluation of the use of a visualisation that shows infrastructure change to promote active travel. In this study participants were asked to watch a computer visualisation of a new walking and cycling route in Glasgow. This animated visualisation included an existing segregated cycling facility and pedestrian and cyclist bridge. Eleven\nsemistructured interviews and two focus groups considered the potential utility of  visualisation in promoting a new walking and cycling facility and identified any limitations of this approach and potential improvements. The results suggested that visualisation technology has the potential to stimulate debate on in-journey accounts of active travel and the embodied experience of cycling. The built environment and psychosocial factors that culminate in road-user conflicts were discussed. The perception of non motorised modes of transport as risky was not overlooked by participants, who shared their knowledge of cycling road safety and ‘correct’ walking and cycling behaviours. Participants responded\npositively to the appearance of protection from traffic achieved by the new routes. However, many criticised the limited coverage of the visualisation and low traffic volumes. The decision to cycle is often made in the context of real-life constraints that were not replicated fully in this visualisation. Further development of visualisation technology may be needed before it can be used successfully for active travel interventions.\nKeywords: active travel, behaviour change, built environment, infrastructure,\nvisualisation\n""","0.44120026","""http://www.research.ed.ac.uk/portal/en/publications/representing-active-travel-a-formative-evaluation-of-a-computer-visualisation-tool-demonstrating-a-new-walking-and-cycling-route(6fec8a81-9d85-4609-b87a-f0e4a4476548).html""","[-3.187347,55.947691]"
"""UCL""","""Iris Publication""","""http://discovery.ucl.ac.uk/1448976/\nAbstract\nParallelism pervades the Internet, yet efficiently pooling this increasing path diversity has remained elusive. We defend that the inability to progress beyond a single path paradigm is due to an inflexible resource sharing model, rather than a lack of routing solutions. The tussle between networks and hosts over resource sharing has constricted resource pooling into being redefined by stakeholders according to their own needs, often at the expense of others. In this paper we debate existing approaches to resource pooling and present PREFLEX, an architecture where edge networks and hosts both share the burden and reap the rewards of balancing traffic over multiple paths. Using PREF (Path RE-Feedback), networks suggest outbound paths to hosts, who in turn use LEX (Loss Exposure) to signal transport layer semantics such as loss and flow start to the underlying network. By making apparent network preferences and transport expectations, PREFLEX provides a mutualistic framework where congestion control and traffic engineering can both coexist and evolve independently. © 2010 ACM.\nPublication data is maintained in RPS. Visit https://rps.ucl.ac.uk\n› More search options\n""","0.6503426","""http://iris.ucl.ac.uk/iris/publication/885784/7""",
"""Aston_University""","""Solar PV-powered SRM drive for EVs with flexible energy control functions - Research Explorer : Aston University""","""Solar PV-powered SRM drive for EVs with flexible energy control functions\nResearch output: Contribution to journal › Article\nEngineering & Applied Science\nAbstract\nElectric vehicles (EVs) provide a feasible solution to reducing greenhouse gas emissions and thus become a hot topic for research and development. Switched reluctance motors (SRMs) are one of promised motors for EV applications. In order to extend the EVs’ driving miles, the use of photovoltaic (PV) panels on the vehicle helps decrease the reliance on vehicle batteries. Based on phase winding characteristics of SRMs, a tri-port converter is proposed in this paper to control the energy flow between the PV panel, battery and SRM. Six operating modes are presented, four of which are developed for driving and two for standstill on-board charging. In the driving modes, the energy decoupling control for maximum power point tracking (MPPT) of the PV panel and speed control of the SRM are realized. In the standstill charging modes, a grid-connected charging topology is developed without a need for external hardware. When the PV panel directly charges the battery, a multi-section charging control strategy is used to optimize energy utilization. Simulation results based on Matlab/Simulink and experiments prove the effectiveness of the proposed tri-port converter, which has potential economic implications to improve the market acceptance of EVs.\nDocuments\nSolar PV-Powered SRM Drive for EVs with Flexible Energy Control Functions\nRights statement: © 2015 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works.\nAccepted author manuscript, 1005 KB, PDF-document\nDetails\n""","0.5069413","""https://research.aston.ac.uk/portal/en/researchoutput/solar-pvpowered-srm-drive-for-evs-with-flexible-energy-control-functions(4b327948-36d4-46f3-bca5-0a493f55afd5).html""","[-1.888803,52.487018]"
"""Brunel_University_London""","""Editorial | Proceedings of the Institution of Civil Engineers - Transport""","""Proceedings of the Institution of Civil Engineers - Transport\nProceedings of the Institution of Civil Engineers - Transport\nISSN 0965-092X | E-ISSN 1751-7710\nPhD, CEng, MCIHT, MICE, PGCHE, FHEA\nx\nDepartment of Mechanical, Aerospace and Civil Engineering, Brunel University, London, UK\nAuthor Affiliations\nPublished Online: July 11, 2016\nKey:\nFree content\nTrial content\nWelcome to the August 2016 issue of Transport. This edition presents six papers covering important theoretical and practical aspects of transportation engineering. On behalf of the editorial board, I thank the authors for their hard work and valuable contributions to the journal. I would also like to extend my appreciation to our esteemed reviewers for their invaluable support.\nTransport networks are one of the most important national assets. Economic prosperity, rapid urbanisation, increasing traffic and ageing infrastructures all have immense impact on safe and efficient operation of this vital asset. Some of these factors are addressed in this issue.\nThe first paper ( Appiah et al., 2016 ) deals with truck characteristics in traffic micro-simulation. The authors present an approach to incorporating the operating characteristics of a local truck fleet in the calibration of micro-simulation models. This approach is different from conventional model calibration where focus is given to adjusting the parameters of driving behaviour logic. The second paper ( Mohapatra et al., 2016 ) reports the influence of conflicting traffic on U-turns at uncontrolled median openings under mixed traffic conditions in an Indian context. With rapid urbanisation and increased traffic volume, most urban roads in India are constructed as multi-lane roads, while many existing two-lane roads are also being widened to multi-lane roads. These multi-lane roads are generally constructed with a raised median, in order to segregate the opposing traffic movements. The authors showed that the impact of conflicting traffic is greater on four-lane roads compared to six-lane roads. In the third paper ( Zong et al., 2016 ), the authors present a model for investigating the feasibility of an integrated transportation demand management (TDM) programme in the Nanhai district of China to mitigate the traffic congestion and reduce exhaust gas emission from motor vehicles. The TDM programme includes a bus priority policy, a motorcycle restriction policy and a congestion pricing policy. The authors demonstrate that all three policies would have a positive effect on Nanhai's transport system. All three papers address key transport issues which traffic engineers and researchers will find very useful.\nIn recent years, railway industries have faced a massive demand for increasing train speeds. However, switch and turnout parts of the track are two critical parts where speed reduction is necessary. In order to develop a more efficient system, the fourth paper ( Sadeghi et al., 2016 ) presents a mathematical model of the impact of railway geometry on the safety of train running and permissible speed. The model is based on the railway vehicle and track parameters such as curve radius, switch initial angle and track gauge with running speed. The model accuracy is verified in field trials. This paper is a good example of how theoretical modelling could help to solve practical issues.\nThe fifth and sixth papers address concrete pavement rehabilitation. The fifth paper ( Lu and Rong, 2016 ), presents the impact of gradation on rubblised Portland cement concrete pavement. Rubblisation is a popular technique for upgrading severely deteriorated concrete pavement. Many previous studies have shown that rubblised concrete with a hot-mix asphalt (HMA) overlay improves pavement performance, especially its cracking resistance. The authors present two studies and demonstrate that if the rubblised gradation matches the requirement for the crushed stone base of the flexible pavement, tensile strains at the HMA overlay bottom develop at a slower pace, indicating an improvement in deterioration resistance (namely cracking) of the overlay system. This article should be a good resource for practitioners and researchers alike. The final paper ( Gao, 2016 ), presents a mathematical model for evaluating the impact of top-down surface cracking in concrete pavement. Surface cracks of concrete pavement not only impact safety and ride quality, but also reduce service life. The author shows that crack length and load position significantly influence the stress intensity factors, and that stress intensity factors are less affected by the elastic modulus of the pavement material than might be expected. Observing that studies on the mechanism of crack propagation in a cement concrete pavement are rather limited, this paper should serve to enhance current knowledge in this field.\nWe trust you find these papers useful and rewarding to read. Comments on this issue or on general journal-related matters will be received with great interest.\nReferences\n""","0.5146203","""https://www.icevirtuallibrary.com/doi/10.1680/jtran.2016.169.4.185""","[-0.472855,51.532848]"
"""UCL""","""Iris Publication""","""http://discovery.ucl.ac.uk/1527808/\nAbstract\nSocial justice has increasingly been used as a criterion to evaluate urban transport policies. The distribution of levels of accessibility across the city is one of the main issues in this field, as the disadvantages faced by some groups in the access to key services and facilities may contribute to processes of social exclusion. The analysis of this issue has traditionally made use of measures of potential accessibility, often looking at the geographic mismatch between jobs and residences and, more recently, also at inequalities between the levels of public transport provision in different areas of the city. However, the applicability of this kind of analysis in the assessment of public policies is limited by the fact that the measures used may not be reliable indicators of the actual effects of the policies in the wellbeing of the local populations.  This paper addresses this problem by focusing on the social imbalances in the realization of the accessibility potential of each neighbourhood in a metropolitan area. The main hypothesis is that levels of realized accessibility depend not only in the locations of residences, main centres, and transport facilities, but also on the actual daily destinations and travel modes of the population in each neighbourhood.   A series of indicators of potential and realized accessibility is estimated for each neighbourhood, including gravity-based job accessibility measures, the ratio between public and private transport accessibility, actual times to work and commuting distances, and the effect of modal choice and congestion on time to work. These indicators are then compared with variables measuring the socio-economic structure of the population using correlation analysis.  The study incorporates aspects that are often neglected in the estimation of travel times to work. The modelling of trips to work in each area is based on a large set of destinations for the working population in each sector of activity, and considers information on starting time of different jobs, and on the proportion of walking trips. The modelling of public transport trips includes information about the availability and frequency of services and the time of walking, waiting and interchange sections. Car and bus travel times include the effects of road congestion at different times of the day.  The analysis is applied to the case of the Lisbon Metropolitan Area at two moments in time, assessing the distributive effect of a series of policies that gave priority to the expansion of the private transport network, combined with trends such as population ageing and urban fragmentation.  The analysis suggests that while it is possible to identify inequalities in times to work of groups with different socio-economic status, these inequalities are mainly explained by different levels of private transport usage and not by geographic factors such as the mismatch between locations of jobs and people or between levels of transport provision and the mobility needs of the population in each neighbourhood.   These results have implications in the debate regarding the role of spatial planning in addressing equity aspects in urban transport networks. These implications are discussed in the closing section of the paper.\nPublication data is maintained in RPS. Visit https://rps.ucl.ac.uk\n› More search options\n""","0.67991996","""http://iris.ucl.ac.uk/iris/publication/1190374/1""",
"""Imperial_College_London""","""Engineering Compartmentalized Biomimetic Micro- and Nanocontainers - ACS Nano (ACS Publications)""","""Engineering Compartmentalized Biomimetic Micro- and Nanocontainers\n†Department of Chemistry and ‡Institute of Chemical Biology, Imperial College London, Exhibition Road, London SW7 2AZ, United Kingdom\nACS Nano\n, 2017, 11 (7), pp 6549–6565\nDOI: 10.1021/acsnano.7b03245\nPublication Date (Web): June 28, 2017\nCopyright © 2017 American Chemical Society\n*E-mail: t.trantidou@imperial.ac.uk ., *E-mail: o.ces@imperial.ac.uk .\nACS AuthorChoice - This is an open access article published under a Creative Commons Attribution (CC-BY) License , which permits unrestricted use, distribution and reproduction in any medium, provided the author and source are cited.\nReferences\nAbstract\nCompartmentalization of biological content and function is a key architectural feature in biology, where membrane bound micro- and nanocompartments are used for performing a host of highly specialized and tightly regulated biological functions. The benefit of compartmentalization as a design principle is behind its ubiquity in cells and has led to it being a central engineering theme in construction of artificial cell-like systems. In this review, we discuss the attractions of designing compartmentalized membrane-bound constructs and review a range of biomimetic membrane architectures that span length scales, focusing on lipid-based structures but also addressing polymer-based and hybrid approaches. These include nested vesicles, multicompartment vesicles, large-scale vesicle networks, as well as droplet interface bilayers, and double-emulsion multiphase systems (multisomes). We outline key examples of how such structures have been functionalized with biological and synthetic machinery, for example, to manufacture and deliver drugs and metabolic compounds, to replicate intracellular signaling cascades, and to demonstrate collective behaviors as minimal tissue constructs. Particular emphasis is placed on the applications of these architectures and the state-of-the-art microfluidic engineering required to fabricate, functionalize, and precisely assemble them. Finally, we outline the future directions of these technologies and highlight how they could be applied to engineer the next generation of cell models, therapeutic agents, and microreactors, together with the diverse applications in the emerging field of bottom-up synthetic biology.\nKeywords:\nartificial cells ; compartmentalization ; double emulsions ; droplet interface bilayers ; lipid membrane ; microfluidics ; polymersomes ; synthetic biology ; vesicles ;\nCompartmentalization is a universal organizational principal in biology, whereby all living cells are encapsulated by a biological membrane consisting of lipids arranged into a bilayer. This fluid membrane not only serves as a barrier between the external medium and the inner cytosolic compartment but also is a highly dynamic surface that mediates the exchange of molecular components and chemical signals via protein assemblies embedded into the lipid matrix. (1) The theme of compartmentalization, however, is seen in length-scales that are both smaller and larger than cellular ones. Eukaryotic cells contain membrane-bound subcompartments that are specialized to perform specific tasks (organelles), while the pervasiveness and importance of bacterial subcompartments are also increasingly apparent. (2) Chemical species can also be compartmentalized on surfaces, for example, on cytoskeletal filaments, inside invaginations/folds as found inside the inner membrane of mitochondria, or on membranes that exhibit lateral segregation of content in the form of rafts, (3) or colocalized in supramolecular complexes. (4) In the other direction, cells can be brought together to form higher-level structures, namely tissues and organs that exhibit collective properties.\nThe ubiquity of compartmentalization in biology is ultimately derived from the fact that it allows segregation of content and function, enabling multiple processes to occur simultaneously, which has a host of associated advantages; it allows distinct chemical environments (e.g., redox states, pH, chemical potentials) to coexist, the buildup of chemical gradients, the maintenance of nonequilibrium states, and the isolation of components that would otherwise be incompatible with one another. It also enables the principle of division of labor to be employed, increasing process efficiency and productivity.\nThe rise of bottom-up synthetic biology and the potential of cell-like structures across a range of applications, from microreactors and therapeutic delivery vehicles capable of on-board chemical synthesis to artificial cells that perform computing operations and interact with neighboring cells, has led researchers to ask the following question: Can the principle of compartmentalization and its associated advantages be transferred to synthetic cell-like structures? ( Figure 1 ) This review will outline recent progress related to this question, with a focus on the engineering strategies used to manufacture biomimetic micro- and nanocompartments.\nFigure 1. An analogy of a biological and a synthetic cell. The artificial membrane of the cells is engineered according to the end application. Poly(ethylene glycol) (PEG)-ylated lipids to suppress the cell uptake by the immune system, insertion of protein pores to act as gateways, and functionalization of membrane with targeting ligands for stimuli-responsive features. Membrane-bound subcompartments inside the artificial cell can segregate content and perform distinct functions, such as in vitro transcription–translation.\nAt the heart of all these strategies is the self-assembly of amphiphilic molecules, with hydrophilic head groups facing the aqueous environment and the hydrophobic tails facing an oil environment which can either be the membrane core or an external oil solution. This can be achieved using bulk approaches, where molecular design of constituent building blocks influences the final architecture of the supramolecular assembly. (5) This has been supplemented in recent years with microfluidic and nanofluidic methods, (6, 7) where compartmentalized structures are assembled on-chip, one-by-one and often using droplets as precursors, through the handling of fluids in channels of micro- and nanoscale dimensions. This has, in part, been responsible for the upsurge in the number of investigations in this area, due to the high control over the size, content, molecular organization, degree of compartmentalization, and connectivity that it affords. (8)\nIn this review, we deal with structures that have lipid bilayers and related soft-matter assemblies as a fundamental structural motif delineating compartments. The size of the assemblies that we cover spans 6 orders of magnitude, from tens of nanometers to several millimeters, and include lipid vesicles, droplet interface bilayers (DIBs), polymer-based structures, and hybrid architectures. Within these, a range of compartmentalization principles exists, including nested vesicles-in-vesicles, multilayered assemblies, and higher-order networks of interconnected units. In addition, efforts to impart functionality to these systems through the introduction of biological machinery are discussed, as are the attractions and limitations associated with the various engineering strategies for their assembly. This review concludes with perspective applications of these structures as cell-mimics to investigate biological phenomena, in therapeutics, as microreactors and in bottom-up synthetic biology, and outlines a future roadmap for the field.\nReferences\nVesicles and Compartmentalized Vesicle Architectures\nVesicles (or liposomes) are fully enclosed shells of lipid bilayers that have an aqueous interior and exterior. They are the most common type of lipid architecture due to their stability at a range of different lipid compositions and their structural and functional compatibility with biological machinery such as membrane proteins and DNA. Vesicles are classified by their size and number of bilayers (or lamellarity), (9) where unilamellar vesicles are separated into small unilamellar vesicles (SUVs, <100 nm), large unilamellar vesicles (LUVs, 100–1000 nm), and giant unilamellar vesicles (GUVs, >1 μm), while vesicles consisting of multiple lipid bilayers are classed as multilamellar vesicles (MLVs).\nThe different size and lamellarity of vesicles largely underpins their application. The small aqueous volumes contained within SUVs make them particularly useful for performing leakage assays to study the activity of protein pores and channels, making SUVs the preferred platform for a wide range of applications including screening for drug/membrane and protein/membrane interactions, (10, 11) assembling synthetic cells (12) and as vehicles for targeted drug administration. (13) Given their comparable size to intracellular compartments, LUVs are considered as biologically relevant drug carriers and also offer a higher aqueous space-to-lipid ratio. GUVs are usually employed to construct reduced cell analogs in the laboratory, referred to as “minimal cells”, (12) as they are similar in size to a biological cell. MLVs are suitable for the encapsulation of a variety of substances and are the choice for multiple-stage drug delivery.\nThere have been several efforts to introduce compartmentalization into vesicles and segregate materials into distinct, spatially organized compartments. The present work reviews state-of-the-art architectures of multicompartment vesicles and phase-separated vesicles.\nMulticompartment Vesicles (MCVs)\nMCVs are systems that consist of multiple hemifused vesicles which share a single lipid bilayer with each other, thus enabling the insertion of membrane proteins that facilitates the communication between two neighboring compartments ( Figure 2 ). Individual steps are isolated in distinct compartments, and their products traverse into adjacent compartments with the aid of transmembrane protein pores, initiating subsequent steps. Therefore, an engineered multistep enzymatic pathway can be carried out. (14-16) For example, a two-compartment vesicle was employed to demonstrate communication between vesicle compartments and between each compartment with the external environment depending on the spatial location of the small, water-soluble, heptameric β-barrel pore-forming toxin alpha hemolysin (αHL). (14) In the first scenario, one compartment contained CaCl2, while the other compartment contained Fluo-4, a Ca2+ sensitive fluorescent dye. Protein insertion in the internal partitioning bilayer resulted in Ca2+ ions flux between compartments, followed by gradual increase of fluorescent signal. In the second scenario, αHL was inserted at the external bilayers, and CaCl2 was added to the external solution. Fluorescent intensity of both compartments was increased simultaneously, as Ca2+ diffused from the external environment into each vesicle compartment. The same group later demonstrated a three-step enzymatic cascade performed in a three-compartment vesicle. (15) In this application demonstrator, each compartment was loaded with lactase, glucose oxidase, and horseradish peroxidase (HRP) together with Amplex Red, respectively. Lactose was initially hydrolyzed to glucose by lactase, which then translocated through the bilayer pores to the second compartment. There glucose is oxidized using glucose oxidase, yielding H2O2. Finally, H2O2 diffused through the bilayer into the third compartment, where it oxidized Amplex Red in the presence of HRP, yielding a fluorescent molecule resorufin. In a more recent study, a two-compartment vesicle containing an in vitro transcription and translation system was employed to demonstrate spatial segregation of protein synthesis in an artificial cell construct. (16) In this system, one compartment contained a green fluorescent protein (GFP) plasmid, while the other compartment contained a red fluorescent protein (RFP).\nFigure 2. Compartmentalization architecture for lipid-based systems. The building blocks of these systems are amphiphilic lipids which arrange in a monolayer (lipid droplet) or bilayer (lipid vesicle) depending on the oil/water environment. Different compartmentalization architectures involve multicompartment vesicles, phase-separated vesicles, DIB networks, multisomes (or double emulsions), and vesicle-in-vesicle systems such as multivesicular vesicles (MVV) and multilamellar vesicles (MLV). The length-scale of these architectures is indicated at the bottom of the figure.\nPhase-Separated Vesicles\nPhase-separated vesicles are composed of solutions that are capable of phase separating if they contain both poly(ethylene glycol) (PEG) and dextran ( Figure 2 ). (17) Vesicles then “bud”, resulting in distinct compartments. The main limitation of these systems is that its functional use is limited, since there is no bilayer to separate compartments. Moreover, these systems are restricted to solutions that can be phase separated.\nReferences\nTechnologies for Engineering Vesicles and Multicompartment Vesicles\nThere is a wide selection of available methods to generate individual vesicles. These range from bulk techniques, such as electroformation, hydration, and droplet phase-transfer for GUVs, extrusion and sonication for SUVs and LUVs, to more automated and high-throughput technologies, such as droplet microfluidics ( Figure 3 ).\nFigure 3. Engineering strategies for constructing lipid vesicles and multicompartment vesicles. (A) SUVs and LUVs are prepared through extrusion of a polydisperse vesicle population. (B) Electroformation of dry lipid films results in the formation of polydisperse GUVs, MLVs, and MVVs. Note that lipid films can be deposited on one or both ITO slides. (C) Vesicles and multicompartment vesicles are generated via droplet phase transfer through a lipid-stabilized oil–water interface. (D) Microfluidic generation of w/o/w double emulsions and subsequent oil extraction results in the formation of unilamellar vesicles.\nExtrusion\nExtrusion is the most common method to prepare SUVs ( Figure 3 A). (18) A lipid film is hydrated with an aqueous buffer to create a dispersion which is subjected to five freeze–thaw cycles to make the dispersion more homogeneous before it is passed at least 13 times through a polycarbonate filter, resulting in the formation of monodisperse unilamellar vesicles.\nElectroformation\nElectroformation is a particularly simple and widely accessible method for the generation of GUV and multivesicular vesicles (MVV). (19) The process involves the application of an alternating electric current across a hydrated film of lipid deposited between two indium tin oxide (ITO) plates ( Figure 3 B). The alternating electric field causes a periodic electroosmotic movement of water between the individual bilayer lamellae in the film. It has been suggested that these perpendicular to the electrode surface vibrations pull the bilayers off the surface to form a mushroom-like structure which continues to grow until the neck closes and the vesicle detaches from the surface. (20) The main limitations of this method is the lack of control over the vesicle size, asymmetry, and inner compartment content. In addition, this technique is limited to buffers with low ionic strength and is unsuitable to encapsulate large, charged molecules such as DNA and proteins, due to the extremely slow interleaflet movement of these molecules.\nPhase Transfer\nGUVs can also be formed by transferring a lipid monolayer-coated water in oil droplet to an aqueous phase through an interfacial monolayer ( Figure 3 C). (21, 22) As the droplet is transferred, the interfacial monolayer envelopes the droplet, leading to the formation of a vesicle. Phase transfer is primarily driven by gravitational forces where droplets are loaded with a dense internal solution relative to the surrounding oil and aqueous phase, which allows them to sink through the column. This process can also be aided using centrifugal forces (23, 24) or by physically driving droplets through the interface using a micromanipulator. (25) A key advantage of the phase transfer method compared to electroformation is that it allows for asymmetric GUVs to be engineered by incubating droplets in a lipid/oil solution containing one lipid type (inner leaflet) and then adding them to a water-oil column containing another lipid type (outer leaflet). (26) Other advantages of the phase-transfer methodology include control over size distribution and a 100% encapsulation efficiency, since they both depend on the size and number of initial droplets. This is particularly useful when encapsulating large, charged biological macromolecules, which is more difficult to achieve using alternative methods. One of the disadvantages of this technique is the lack of control over the number of compartments of resulted vesicles, which is a stochastic phenomenon dependent on the density of the droplets made during the emulsion formation stage.\nMulticompartment vesicles were showcased by Elani et al. (14-16) using the phase transfer of two or three droplets across a water–oil interface; nanoliter volume aqueous droplets loaded with the appropriate reaction components were initially prepared manually by pipetting. Two or three droplets were subsequently pipetted in the same locality into an oil-water column separated by an interfacial lipid monolayer. This technique facilitates the production of both symmetric and asymmetric lipid bilayers, but the minimum compartment size is 500 μm, below which droplets would not penetrate the interfacial lipid monolayer.\nMicrofluidics\nMonodisperse and asymmetric GUVs in the nanoliter and picoliter regime can be engineered either by using water/oil/water (w/o/w) double emulsions as templates with subsequent extraction of the middle oil phase ( Figure 3 D) (27, 28) or by mediating phase transfer of lipid stabilized w/o droplets by inertial lift force (28-30) or microfabricated posts. (31-33) The efficiency of the latter, however, was extremely low with only ∼1–5% of droplets surviving the phase transfer. Others used an approach where individual monolayers were deposited on droplet templates, enabling asymmetric vesicles of defined lamellarity to be generated depending on how many monolayers were sequentially deposited. (34) Additional efforts have focused on generating vesicles using planar membranes as starting points and then employing a fluidic pulse jet flow to pinch off vesicles. (35) This technique, however, lacks the control and versatility of water in oil methods, while also suffering from a low production rate.\nIn the femtoliter regime, microfluidic hydrodynamic focusing has been demonstrated as a simple technique for nanoscale liposome formation. (36, 37) The mechanism of formation relies on the diffusive mixing at two miscible liquid interfaces at a microfluidic flow focusing junction. The disperse phase contains an alcohol solution with diluted lipids, while the continuous phase is an aqueous solution. Diluting the alcohol concentration below the solubility limit of lipids initiates lipid self-assembly into small unilamellar vesicles.\nReferences\nDroplet Interface Bilayers\nDIBs are model membranes assembled between two lipid-coated water droplets positioned into contact inside a well of oil ( Figure 2 ). The method, pioneered by both the Bayley (38) and the Takeuchi (39) groups, works in two different operating modes depending on how phospholipids are supplied to the system. In the lipid-out approach, the lipids are dissolved directly into the oil, whereas using the lipid-in mode, the lipids are supplied to the water droplets in the form of vesicles, usually prepared by extrusion or sonication. In both approaches, a lipid monolayer assembles at the water–oil interface, and a bilayer is formed when monolayer encased droplets are manipulated into contact.\nAs a lipid bilayer is only present at the interface of the droplets, DIBs typically have a much smaller bilayer area compared to GUVs made from equivalent sized droplets. On the other hand, DIBs are much simpler to assemble, can be connected together to form networks, and, from a compartmentalization perspective, offer the distinct advantage of having one micro compartment positioned either side of the membrane.\nReferences\nTechnologies for Assembling Droplet Interface Bilayers\nDevices for assembling DIBs were initially reported by the Takeuchi group, who showed both the assembly of bilayers from two 15 μL droplets inside overlapping Parylene-coated poly(methyl methacrylate) (PMMA) wells filled with lipid-oil, and at the interface of two continuous aqueous flows inside a microfluidic chip with a lipid-oil cross-flow. (39) A similar microfluidic approach was also reported by the Schmidt group who assembled lipid bilayers inside 100 μm wide microchannels controlled by pneumatic valves, except in this instance the oil was removed in situ by exploiting the absorbent properties of polydimethylsiloxane (PDMS). (40) The material properties of PDMS were also utilized by the Leo group who showed that bilayer size could be controlled by compressing a PDMS device consisting of two overlapping wells. In this elegant approach, an initial compression separates a single 1.2 μL droplet in lipid-oil into two, and the interdroplet interface is controlled by the level of release. (41) Other approaches to assemble DIBs from microliter-scale droplets include the use of micromanipulators to position droplets via electrodes ( Figure 4 A) (38) or by a pin anchor (42) inserted into the droplets, which can also be used as a guide for falling droplets (43) and the use of electric fields to manipulate droplets either by droplet dielectrophoresis (44) or by electro-wetting on dielectric (EWOD) ( Figure 4 B), (45) which can also be used to control bilayer size. (46) The assembly of DIBs from nanoliter-scale droplets has also been shown using microfluidics (which also facilitated droplet exchange), (47) sliding wells, (48) and magnetic beads ( Figure 4 C) (49) and using fluid motion generated either by the thermocapillarity effect or by Marangoni convection. (50) Several of these techniques can also be used to assemble DIB networks, which was demonstrated by the Bayley group using 200 nL droplets dispensed inside Perspex wells (51) and was later shown inside an automated microfluidic platform capable of stacking droplets ranging from 5 nL to 100 nL in volume. (52) Microfluidic approaches have also been used to demonstrate the controlled assembly of alternating 40 pL droplets in branched channels in addition to more complex 3D structures ( Figure 4 D). (53) In other approaches, thousands of 65 pL droplets have also been assembled into 3D DIB networks using 3D printing ( Figure 4 E), (54) while the smallest stable 3D networks reported to-date were assembled from 15 pL droplets using optical tweezers ( Figure 4 F). (55)\nFigure 4. Strategies for assembling DIBs and DIB networks. (A) Micromanipulation of two lipid-coated water-in-oil droplets into contact using Ag/AgCl electrodes. (B) Assembly of DIBs using electric fields to drive droplet motion by electrowetting-on-dielectric (EWOD). (C) DIB network assembly using a magnet to assemble droplets containing magnetic beads. (D) Microfluidic generation of water-in-oil lipid-coated droplets and subsequent assembly of DIB networks. (E) High-throughput production of 3D DIB networks via 3D printing. (F) 3D DIB network construction using optical traps.\nReferences\nFunctionalization of Droplet Interface Bilayers with Membrane Proteins and Pores\nWhile droplets may be supplied with small molecules such as hydrogen peroxide (15) or resorufin (48) which can passively diffuse across DIBs, higher-order activity requires the membrane to be functionalized with membrane proteins or pores supplied to the droplets. This has been reported extensively in the literature using αHL pores, as demonstrated using fluorescence assays (56) and ion channel electrophysiology. (39) Other examples of DIB functionalization using water-soluble species include the linear peptide gramicidin, (44) which forms cation-selective channels, (57) Alamethicin, (41) a 20 amino acid peptide that produces a voltage-dependent conductance in lipid bilayers, (58) and OmpG, (38) which is known to demonstrate pH-dependent gating and voltage-dependent closure.\nIn contrast to most water-soluble peptides, which can be added directly to droplet compartments with minimal preparation, membrane proteins require reconstitution into proteoliposomes before supplying to droplets for membrane insertion. While this has been achieved in DIBs with potassium channels KcsA, (44) hERG, (59) and hBK, (60) the mechano-sensitive channel MscL, (61) the temperature and methanol activated channel TRPM8, (62) and the light-sensitive proton pump bacteriorhodopsin, (51) these proteins are not all commercially available and typically need to be prepared in advance by the investigator. This usually involves overexpression in cells, followed by protein purification and reconstitution which is a laborious, time-consuming, and low-yielding process.\nIn vitro transcription–translation (IVTT) has recently emerged as a “cell-free” alternative method for expressing membrane proteins inside a few hours with minimal molecular biology infrastructure. The method works by incubating a cell-lysate containing all of the necessary ribosomal machinery for assembling proteins with amino acids, nucleotides, a system for metabolic energy generation and an engineered DNA (or RNA) template. (63) While membrane proteins have been successfully expressed using IVTT and purified before supplying to DIBs, (38) electrical measurements of the potassium channels Kcv, (38) KvLm, (64) KcsA, and hERGS5–S6, (65) in addition to optical measurements of the transporter lactose permease, (66) have also been reported directly from droplets of pre-incubated IVTT mixture, without any purification or reconstitution.\nAlthough efforts to couple protein expression and characterization using IVTT in DIBs has been limited by bilayer instability, (65) recent reports have shown that this can be overcome using PEGylated lipids to stabilize the membrane, while fluorescent proteins or αHL are expressed using IVTT in the presence of a DIB or DIB network under an external light trigger. (67) The ability to control protein expression inside microdroplets using external triggers combined with the ability to engineer genetic circuits (68) could set a paradigm shift for functionalizing droplet compartments used to assemble DIBs.\nThe ability to assemble functionalized droplet compartments into bilayer networks with user-defined architectures has enabled microsystems to be engineered with collective properties. Examples of these were demonstrated by the Bayley group who showed the assembly of a light-sensing DIB network and a biobattery from 200 nL droplets functionalized with bacteriorhodopsin and αHL pores. (51) The same group later showed the construction of DIB networks that displayed electrical properties such as full- and half-wave rectification and a current limiting using 7R-αHL, a mutated form of the αHL pore engineered to behave like a diode. (69)\nReferences\nMultisomes\nMultiple emulsions are polydispersed systems where both water-in-oil and oil-in-water emulsions exist simultaneously and are stabilized by hydrophilic and lipophilic surfactants, respectively. There exist two types of multiple emulsions: water-in-oil-in-water (w/o/w) and oil-in-water-in-oil (o/w/o) double emulsions. In the w/o/w, small water droplets are encased in bigger oil droplets, and these oil droplets are dispersed in a continuous aqueous phase. In the o/w/o, oil droplets are dispersed in larger aqueous droplets, and these droplets are again dispersed in a continuous oil phase. In synthetic biology, multiple emulsions have been stabilized by amphiphilic lipids which act as biological surfactants to prevent droplets of the same phase coalescing ( Figure 2 ). These systems, termed multisomes, were introduced by the Bayley group in 2011 (70) in order to overcome the main limitation of DIB architectures, being their inability to work in physiological environments since they are restricted to a bulk oil phase. In this work, water droplet networks were microinjected into a larger oil/water droplet, crucially forming w/o/w-type multisomes. Lipid bilayers formed between the inner water droplets but also connected the inner droplet networks to the external aqueous medium through embedded protein pores. O/w/o-type multisomes were recently demonstrated, (71) which can find applications as carriers for hydrophobic molecules that are insoluble in water, however, these systems natively do not form lipid bilayers and, therefore, communication between distinct compartments is solely based on diffusion through the lipid monolayers. Among w/o/w- and o/w/o-type multisomes, the former has wider areas of applications due to its ability to operate in physiological environments. W/o/w multisomes are also precursors for templating vesicles by removing the intermediate oil phase and zipping the two lipid monolayers together to form a lipid bilayer.\nTechnologies for Engineering Multisomes\nBulk Emulsification Methods\nBulk emulsification methods have traditionally been used to generate double emulsions in the microliter regime and typically involve a two-step procedure. (72) A simple w/o or o/w emulsion is first prepared by adding the internal phase to the external phase and mixing through manual pipetting. The emulsion is then emulsified again with the external (bulk) phase. A pre-emulsification step can be added to this process to achieve proper emulsification. (73) Despite its simplicity this technique fails to precisely control the size distribution of the produced multiple emulsions. The membrane emulsification technique is an alternative method to produce monodispersed emulsions. In this process w/o or o/w emulsions are pressed through the pores of a microporous membrane into the continuous phase. (74)\nMicrofluidics\nRecently, methods for the high-throughput generation of double emulsions and miniaturization to cell-sized volumes have been developed, using traditional microfluidic chips assembled via soft lithography as well as using capillary-based devices. (75) These developments are advantageous, as they allow the generation of picoliter-scale emulsions with greatly narrow size distribution profiles and at rates as high as thousands of emulsions per second. They also allow a greater degree of control over double emulsion architecture to be achieved. In addition, one of the most attractive features of microfluidic techniques is that they enable the fabrication of higher order (double, triple, and quadruple) emulsions to be generated. (76-80)\nThe production of double emulsions in microfluidic devices requires synchronization of the droplet formation frequencies and very specific channel wettability; oil droplet formation can only be realized at a hydrophilic microfluidic junction, whereas the aqueous droplets can only form at a hydrophobic junction. Modification strategies have been leveraged to precisely pattern the surface chemistry within a network of microchannels, enabling the production of oil and water droplets at different parts of the microfluidic chip. One such example is the selective deposition of hydrophilic molecules on plasma-activated PDMS microchannels that are inherently hydrophobic. (27, 73, 78, 81) Nevertheless, while microfluidic generation of surfactant-stabilized systems is well established, lipid-stabilized systems are notoriously more cumbersome to produce, since they require specific surface chemistries and many surface modification techniques are incompatible with lipids. To date, there are few reports detailing the microfluidic generation of lipid-stabilized double emulsions (27, 78) and inverted double emulsions. (71)\nAs a step toward applications in biological settings, there have also been efforts at stabilizing multisomes generated in glass capillary devices by encapsulating the internal nanoliter compartments in gelled alginate, providing them with the robustness needed for eventual academic, industrial, and clinical applications. (82) There have also been efforts to eliminate the intermediate oil phase in multisomes, which might pose problems with respect both to biocompatibility (e.g., if the oil is toxic) and to the encapsulated chemical partitioning into the oil phase. Zhang et al. (83) leveraged a microfluidic device to encapsulate a lipid-stabilized aqueous core with a flexible poly(lactic-co-glycolic acid) shell that was further coated with another lipid monolayer to form “rigid nanovesicles” in the femtoliter regime, although no bilayer was actually present in this system.\nReferences\nApplications of Multisomes\nMultisomes were initially envisaged to act as modular chemical microreactors operating in physiological environments, for applications including smart drug delivery and for in vivo biosensing. Villar et al. explored the potential of w/o/w multisomes for in situ release of chemicals and demonstrated temperature and pH-triggered release of internal droplet content by taking advantage of lipid phase behavior. (70) In this work, multisomes were generated with membranes that would destabilize at temperatures above their phase transition and at high pHs, leading to compartment rupture and exposure of chemical species previously isolated in the internal compartments to one another. The use of picoliter volumes of multisomes as in situ drug synthesis machines was showcased in a study where w/o/w multisomes consisting of two inner droplets were generated using a PDMS microfluidic device. (78) In one droplet, a membrane impermeable fluorogenic pyrylium compound was encapsulated, while the second droplet was loaded with a membrane permeable primary amine. Amine was gradually diffused through the DIB into the adjacent pyrylium-loaded droplet, yielding a fluorescent pyrylium salt.\nW/o/w multisomes have also been employed as templates for the formation of lipid vesicles. Abraham Lee’s group developed a technique for the fabrication of lipid vesicles based on multisomes consisting of oleic acid, a nontoxic derivative of olive oil that rapidly dissolves in ethanol. (27, 84) Water droplets containing the target encapsulated species were first produced in oleic acid in high throughput using a PDMS microfluidic device. The emulsion was then injected into an ethanol/water mixture, where oleic acid was rapidly dissolved in ethanol, leading to removal of the excess solvent and eventually forming lipid vesicles with both ethanol soluble and insoluble phospholipids. The fabricated lipid vesicles were used to encapsulate fluorescent proteins and carcinoma cells. A few years later, this process was entirely transferred “on-chip” by the same group (27) which showcased on-board GFP synthesis. The fabricated multisomes were loaded with a reaction mix consisting of RNA and enzymes, which was mixed “on-chip” with a plasmid solution, and the expression of GFP in the resulted vesicles was monitored over time.\nReferences\nHigher-Order Structures\nAs demonstrated in the preceding sections, compartmentalizing chemical species in space has a host of advantages. These are, however, higher degrees of order which can exist, defined by the organization of a population of compartments in relation to one another. As technologies for compartmentalizing chemistry and biology have continued to progress, there has been an increasing interest in exploring this space for the engineering of materials with emergent and collective features. An analogy with biological systems is instructive: Collections of cells are networked with one another as a collective to yield tissues and organs which are capable of increasingly sophisticated functionalities.\nVesicles in Vesicles\nAn alternative compartmentalization strategy centers upon the construction of hierarchical structures where vesicles are encapsulated in larger vesicles, leading to structures known as vesosomes ( Figure 2 ). These can be classed according to the size regimes of the internal and external compartments. SUVs-in-SUVs have been formed via a spontaneous encapsulation approach, (85, 86) and GUVs-in-GUVs generated via osmotic-induced membrane invagination and budding. (87) LUVs can be encapsulated in GUVs by hydration of lipid films in the presence of LUVs, (88, 89) although this results in low encapsulation efficiencies, as the mechanism of encapsulation largely prohibits the encapsulation of nanoparticles and colloids. Recent development of emulsion-based generation strategies has circumvented these issues. (90) These have also allowed three-tiered vesicle assemblies to be generated, where SUVs in GUVs were put through a third GUV encapsulation step. (91) Once more, precision engineering of structures with respect to the number of encapsulated vesicles, and lipid composition and encapsulated content of each of the vesicles, has only recently been achieved using microfluidic technologies using sequential vesicle generation modules using dewetting of double emulsion templates. (92) Deng et al. used this method to generate a eukaryotic mimic, where the inner vesicles acted as a “nucleus”, in which in vitro transcription of DNA took place. (92)\nOthers have functionalized nested vesicle structures for responsive microreactors for multistep enzymatic reactions. Bolinger et al. encapsulated two populations of SUV in a larger vesicle, each one carrying a different cargo and each composed of distinct lipid compositions, thus possessing different phase transition temperatures. (88) Using phase-transition-mediated leakage, sequential release of reagents by an external stimulus was achieved, and multistep enzymatic reactions could be performed in the vesicle microreactor.\nMultilamellar Vesicles\nMLVs are related structures to vesicles-in-vesicles and are composed of several bilayers layered directly above one another in an onion-like arrangement. These structures are formed simply by hydration of lipid films where submicron particles self-assemble. (93) Multilamellar giant vesicles are generated during electroformation, however, because this process is stochastic, only a small percentage of vesicles possess more than one lamellae. These extra layers can be visualized under fluorescence microscopy (94) and result in distinct vesicle mechanical properties, (95) affecting both their surface tension (96) and bending rigidities. (97) There have been recent efforts in microfluidic technologies for controlled deposition of a number of defined bilayers around a droplet template using a layer-by-layer approach, leading to the demonstration of the controlled construction of multilamellar giant vesicles. (98)\nDirected Assembly of Vesicle Aggregates\nThere have been efforts at designing vesicles capable of aggregation through both specific and global forces, (99) with aggregation being driven by electrostatic forces (85) as well as site-specific biotin–streptavidin interactions. (100, 101) Others have demonstrated aggregation of vesicle-based cells into “colonies” through the addition of polypeptide-induced electrostatic interactions. (102) These aggregates were shown to have enhanced fusion rates and increased permeability to charged biologically relevant molecules including ADP and tRNA due to the stresses resulting from membrane deformation. Second generation technologies have centered on vesicles containing single-stranded DNA on the surface, which are embedded to the membrane through single or double cholesterol anchors (99, 103) or using hydrocarbon anchors. (104) The use of DNA allows specific intervesicle interactions to be made through the formation of Watson–Crick base pairs. These interactions are asymmetric allowing controlled assembly of two different vesicle populations, each possessing complementary DNA strands, unlike biotin–streptavidin interactions where a single population of biotin-containing vesicles are bridged by streptavidin molecules. Such systems were used to construct ordered and amorphous colloidal particles that were coated with a membrane containing surface-mobile DNA linkers. (105) Others have used DNA-coated oil-in-water droplets for sequence-specific self-assembly (91) and to yield assemblies with distinct geometries based on steric considerations, including droplet pairs, chains, and multivalent close-packed structures. (106) There have also been several examples of forming heterogeneous GUV and LUV collections (107-109) and vesicles that clustered through site-specific adhesion between DNA functionalized “Janus vesicles” exhibiting phase separation, where aggregation was limited by steric effects. (110) DNA-tethered vesicles were also engineered to exhibit higher-level properties including negative thermal expansion and tunable porosity through the intervesicle space, (111) with potential sensing and responsive cargo-release applications. Finally, DNA linkers can also be designed to induce vesicle fusion and mixing of internal content through the anchoring geometry of the DNA, a process which has been exploited in a vesicle microreactor context. (104, 112, 113) Although selective communication between vesicles in such assemblies has not been demonstrated, prizing routes to achieve this include the use of protein engineering, reconstitution of cellular machinery, and the design of DNA-origami pores. (114, 115)\nThe primary advantage of using bulk-aggregation methods is that it exploits the principles of self-assembly, meaning aggregates can be generated en masse without external input or human manipulation. As a result, however, the structures are largely amorphous aggregates whose geometries are uncontrolled. Alternative strategies involve constructing vesicle assemblies one-by-one. Orwar and others developed a platform of vesicle networks linked by open nanoethers that enabled flow of encapsulated material between compartments (111, 116, 117) and subsequent chemical reactions that could be controlled by network geometries (118) and shape and volume changes. (119)\nHigher-Order Droplet Interface Bilayer Networks\nThere have been several recent examples of using microfluidic methods to tackle the issue of throughput (53) while still achieving a fine degree of control over network architecture. Villar et al. developed a 3D printer capable of depositing lipid-coated droplets of set compositions in defined locations, using this to construct a “tissue-like” material consisting of tens of thousands of interconnected bilayers. (120) This material exhibited collective properties such as osmosis-induced self-folding from a flat to a spherical architecture, and through selective insertion of protein pores, electrical signals along specific pathways were achieved. By further functionalizing this system with a cell-free expression system and a light-activated DNA promoter, a functional mimic of neuronal transmission that can be controlled in a precise, real-time way was assembled. (121)\nReferences\nPolymer-Based Compartmentalization Architectures\nThere has been increasing interest in using polymers as alternatives to liposomes both in biotechnology (e.g., in drug delivery) and as the construction of cell mimics. Although this review focuses on lipid membrane-based compartmentalized systems, polymer-based structures are briefly discussed here.\nPolymersomes are hollow spherical structures with an aqueous core enclosed by a polymer-based membrane and can thus be considered as synthetic analogues to lipid membranes. Polymers may be composed of a mono- or bilayer of amphiphilic block copolymers, which self-assemble spontaneously in aqueous solution to minimize unfavorable interactions between the hydrophobic regions and the aqueous surroundings ( Figure 5 A). The self-assembly of monomers can result in distinct architectures, such as planar, spherical, or cylindrical shape, depending on the hydrophilic fraction of the block copolymer. (122) Polymer vesicles, therefore, are not composed of bilayers, but instead of a single polymer-thick membrane. Other types of polymers include diblock copolymers which do assemble as bilayers, comb copolymers, and dendrinized copolymers. Polymersomes are physically more robust than liposomes and are capable of withstanding larger stresses and deformations while still mainlining their physical integrity. They are also more resistant to chemical and biochemical degradation. Polymer monomers are easier to synthesize, meaning finely tuning their chemical structure to impart desired properties of the membrane (e.g., thickness, permeability, release rates, stability, and responsiveness). Furthermore, on account of their chemical composition and increased thickness, they are less permeable than lipid membranes, which is advantageous for certain applications. However, polymers also possess several limitations compared to liposomes. They inherently lack the biological relevance of lipids and have a diminished ability for functionalization with biological components, such as transmembrane channels and membrane-associated proteins and antibodies, although there have been some examples of successful reconstitution of several membrane pores (synthosomes). (123) In addition, block copolymers do not possess the rich phase behaviors of lipid membranes, which can give rise to dynamic and responsive behaviors. Due to their diminished biomimetic potential, their use as models of cell membranes to study biological phenomena (e.g., protein–membrane interactions) is limited. Polymersomes can be formed the same way as liposomes, depending on the solubility of the block copolymers; film rehydration, electroformation, extrusion, direct injection, dissolution, and double emulsion production using microfluidics. (124, 125)\nFigure 5. Compartmentalization architecture for polymer-based systems. (A) The building blocks of these systems are amphiphilic block copolymers which assemble to form a polymer membrane encasing an aqueous core. Compartmentalized polymer-based architectures include (B) multicompartment polymersomes and (C) polymersomes-in-polymersomes. (D) Capsosomes as hybrid compartmentalized systems consisting of a polymer membrane which encases small unilamellar liposomes.\nMulticompartment Polymersomes\nMulticompartment polymersomes have been implemented from w/o/w emulsions with block copolymers as the stabilizing agent ( Figure 5 B). (126) A volatile intermediate oil phase consisting of chloroform and hexane was subsequently removed via evaporation. Multicompartment polymersomes, where essentially the polymersome is divided in two by a partitioning membrane, have been formed using a microfluidic device which generates w/o/w double emulsions containing a volatile oil as the intermediate phase, which is then removed, leaving behind polymer membranes. (126)\nPolymersomes-in-Polymersomes\nOther compartmentalized structures, referred as polymersomes-in-polymersomes ( Figure 5 C), are based on the generation of polymersomes and their subsequent encapsulation in larger polymersomes. (127-130) Polymersome-in-polymersomes have been generated both by bulk sequential emulsification strategies (127, 129, 130) and using controlled microfluidic methods. (128)\nReferences\nApplications of Polymersomes and Compartmentalized Polymersome Systems\nDue to their enhanced stability by comparison to liposomes, polymersomes hold great promise as capsules for drugs, cosmetics, and nutrients, facilitating long-term storage and controlled payload release. (122) Polymersome-in-polymersomes systems have been leveraged for the encapsulation and controlled and sequential release of multiple distinct components. (128) In this work, programmable payload release of materials was achieved by selectively rupturing the different membranes (outer, middle, and inner) of multilayer polymersomes based on the presence or absence of (PEG)-b-poly(lactic acid) (PLA) diblock copolymers on the distinct membranes. For example, in a triple polymersome, the absence of PLA homopolymers in all membranes results in sequential rupturing of the membrane from the outermost to the middle and inner membranes, whereas addition of PLA homopolymers in the outer and middle membranes only results in spontaneous degradation of the PLA in water and rupturing of the innermost membrane first. Polymersomes-in-polymersomes have also been used as structural and functional eukaryotic cell mimicry, where smaller polymersomes were loaded with distinct enzymes inside larger polymersomes and served as artificial organelles, facilitating multistep reaction pathways. (127, 129, 130) Multicompartment polymersomes have been used in synthetic biology as cell-like nanocompartments with embedded transmembrane channels, allowing the influx of substrates which are enzymatically acted upon in the interior. (123)\nReferences\nHybrid Architectures\nIn addition to compartmentalized structures that are engineered from either lipids or polymers, there also exists another class of hybrid structure that benefits from the material properties inherited from both systems, capsosomes, together with an additional system based colloidal inclusions of lipid aggregates (coacervates).\nCapsosomes\nCapsosomes are multilayered polymer capsules that contain intact liposomes in engineered subcompartments ( Figure 5 D). Here, the polymer capsule provides structural stability, while the liposomes present biocompatibility. Capsosomes were initially reported by the Caruso group, who showed that 1,2-dioleoyl-sn-glycero-3-phosphocholine (DOPC) liposomes could be embedded in polyelectrolyte multilayers consisting of poly(styrenesulfonate) and poly(allylamine hydrocholoride). In their approach, 3 μm silica particles were used as scaffolds for depositing polyelectrolyte films via layer-by-layer assembly, and capsosome formation was completed by dissolving the silica core. (131) The Caruso group have also shown that liposome adsorption by the polymer film can be improved significantly using a cholesterol-modified poly(l-lysine) precursor layer and a poly(methacrylic acid)-co-(cholesteryl methacrylate) capping layer (132) and presented a detailed study outlining the structural integrity of the capsosomes, the cross-linking of the thiols in the film, the encapsulation efficiency under different conditions, and the long-term stability of the system. (133) A modified, oxidization-free method to stabilize the carrier capsules was also reported (134) in addition to a bespoke liposome-anchoring cholesterol-containing block copolymer that enables the “free-floating” of liposomal subcompartments. (135) To date, capsosomes have been successfully employed to encapsulate biological components such as β-lactamase and luciferase into two spatially separated compartments inside the same structure (133) and show great promise as compartmentalized bioreactors.\nCoacervates\nCoacervates are spherical aggregations of lipid molecules making up a colloidal inclusion which measures 1–100 μm across and is held together by hydrophobic forces. Coacervates possess boundaries that are not as clearly delineated as cellular membranes. Nevertheless, coacervates favor the formation of molecular concentration gradients in their “pseudo-compartments” which were proved to be able to perform catalysis. (136) Coacervates have been suggested by Alexander Oparin as possible precursors of biological cells. (137) Oparin hypothesized that coacervates formed in the prehistoric sea and underwent a selection process, during which they developed microcompartments with chemical reactions taking place in each compartment, which was eventually considered to be a protocell. Recent studies have highlighted the possibility of creating structured microscale entities resembling cells based on coacervates. Multicomponent protocell-like constructs were generated with fatty acid membrane assembly on coacervate microdroplets. (138) The same group later discretely leveraged microfluidic technologies to generate discrete membrane-free coacervate microdroplets (139) and demonstrated the potential of these systems to act as microreactors which are able to perform cell-free gene expression and folding of a fluorescent protein. (140)\nReferences\nNonlamellar Architectures\nRecently, aqueous dispersions of reversed lyotropic nonlamellar liquid crystalline mesophases have also shown promise as therapeutic agents. (141) The most well studied of these lyotropic nanostructured containers are hexosomes and cubosomes, which consist of colloidal nanoparticles with confined internal structures of 2D columnar hexagonal phases (142) or well-ordered 3D bicontinuous cubic phases, (143) respectively. The structural characteristics of these well-defined compartments can potentially facilitate highly efficient encapsulation of medicinal cargo and, by coating the surface with targeting ligands, can be engineered to target specific cells, tissues, or organs. (144)\nAnother type of nonlamellar structures are solid lipid nanoparticles (SLN), which generally consist of a spherical solid lipid core in the nanometer range having a monolayer of phospholipid coating. (145) These dispersions have been proposed as an alternative type of colloidal drug carrier system with their solid core containing the drug dissolved or dispersed in the solid high melting fat matrix. (146) Although these systems are less compatible with biological machinery, they combine advantages of polymeric nanoparticles, fat emulsions, and liposomes, which make them attractive for drug delivery applications; they are biodegradable and stable against coalescence, and their solid core enables drug release over a prolonged period.\nThe second improved generation of SLN was introduced as nanostructured lipid carriers (NLCs). (147) NLCs are produced by using a mixture of solid and liquid lipids. Compared to SLN, NLCs offer the advantage of increased and firmer loading of actives inside the particle matrix due to the presence of many imperfections in the crystalline structure of the particle matrix. (148) The latter has significantly increased their shelf life and facilitated their use in cosmetic and pharmaceutical formulations.\nDiscussion\nComparing and Contrasting Compartmentalized Architectures\nThe selection of the appropriate compartmentalized system from the variety of architectures described above mainly depends on the end application. An important consideration when using these systems as cell mimics for fundamental research or as functional microdevices is how closely they can reconstitute cellular machinery, namely how biomimetic they are. Truly biomimetic systems are also less likely to trigger immune responses. For other applications, the biomimetic feature may not be important. For instance, for drug delivery applications, polymer systems may be more versatile than their liposome counterparts, because they are mechanically more stable, more deformable, and more resistant to their biochemical environment.\nIn this context, vesicle-based systems are far more advantageous, since their basic unit—a unilamellar lipid vesicle—resembles the basic compartment structure of all biological cells, in the sense that the vesicle membrane is a mimic of the self-closed lipid matrix of the plasma membrane. This advantage enables them to incorporate cellular machinery, such as embedded proteins and DNA. This feature is ideal not only for synthetic cell fabrication but also for further studying drug/membrane and protein/membrane interactions. Many vesicle-based compartmentalized systems can be employed as biological systems analogs; for example, nested vesicle structures can be used to mimic a biological cell and its internal compartments/organelles, each of which can act as a responsive microreactor for multistep enzymatic reactions. Vesicle-in-vesicle systems are great candidates for targeted multistaged delivery, where each vesicle compartment is functionalized differently to initiate a specific payload release under distinct stimuli (multiresponsive vesicles). MCVs can be employed to build a cluster of cells that are networked with one another, yielding tissues and organs which are capable of increasingly sophisticated functionalities. The main limitation regarding MCVs arises from how they are engineered; the fabrication of these systems relies on the production of individual water droplets manually through pipetting or microfluidically and their subsequent transformation into lipid vesicles through phase transfer. Thus, compartment volumes are restricted to the nanoliter volume regime, since below this size, droplets are not heavy enough to overcome the water–oil interfacial tension and thus cannot penetrate the oil–water interface. In addition, MCVs lifetimes are limited to a maximum of 1 h due to the large osmotic differences that are required to drive phase transfer.\nDIB networks and w/o/w multisomes can also be functionalized to produce biologically relevant systems. Both architectures are great candidates to act as modular chemical microreactors, although multisomes benefit from the extra advantage of being able to operate in physiological environments, making them suitable for applications such as smart delivery, microreactors for synthetic chemistry, and in vivo biosensing. In addition, the multiphase nature of these systems enables them to act as carriers of both hydrophilic and hydrophobic molecules. An additional advantage of DIB networks and multisomes is that they can be scaled down to the attoliter regime and be produced in high throughput with the aid of droplet microfluidics, something that currently comprises a major technical bottleneck for the manufacturing of vesicle-based compartmentalized systems.\nCritical Discussion on Generation Strategies\nDepending on the application, different engineering strategies or a combination of these are required to assemble multicompartment systems, although the focus nowadays is shifting toward leveraging techniques that facilitate self-assembly and intercompartment communication in an automatic and high-throughput fashion. Electroformation and film hydration are popular and simple methods particularly for engineering higher order structures, however, they lack control over the vesicle size, bilayer asymmetry, and intercompartment content. Phase transfer, on the other hand, addresses the aforementioned issues, however, since it is driven by gravitational forces, it cannot be employed for the production of femtoliter and attoliter systems. The use of optical traps to assemble preprepared droplets and vesicles into DIB networks and VIMs, respectively, can achieve high control over the system’s architecture, however, it is a low-throughput method.\nMicrofluidic approaches allow the design of compartmentalized systems with narrow size distributions and excellent control over the number of compartments and asymmetry of the individual compartments. Recent advances in microfluidic device rapid prototyping, such as 3D printing and acrylic micromachining, have accelerated the use of these platforms in biomembrane engineering. However, with increasing demand not only for high-throughput production but also for minimum compartment size (scaled-out versus scaled-down systems), microfluidic technologies have reached a technical bottleneck. It is indisputably a manufacturing challenge. The state-of-the-art in lipid droplet and vesicle microfluidic generation is almost entirely based on nonscalable technologies such as soft lithography, which restricts applications to microsized carriers (>10 μm). Work on microfluidic nanodroplet and nanovesicle production has recently started to emerge, (36, 149) however, we are still far from exploiting the full potential of microfluidics in assembling compartmentalized systems of these dimensions. Unlocking this technical challenge with the aid of emerging materials and nanofabrication technologies will lead to further applications in artificial organelle manufacturing and therapeutic delivery.\nReferences\nApplications and Future Directions\nA multitude of discipline-spanning applications for compartmentalized systems have been proposed over the years. From modular computers and tissue scaffolds to biosensors and functional materials in soft robotics, and their potential to be used in academia, industry, and the clinic is wide-ranging. Four of the most prominent areas that have been most actively pursued are the use of such structures as cell models for the study of fundamental biology, as microreactors, as therapeutic agents, and as artificial cells in synthetic biology. These are outlined below in more detail.\nCell Models for the Study of Cell Biology\nCompartmentalized soft-matter systems have the potential to be used as models of artificial cells with which to quantitatively investigate biological phenomena in a simplified environment, where variables can be precisely defined for systematic studies, without interference from a living and responsive cell. (150) Cell mimics have already been used to shed light on processes such as cytokinesis (cell division), (151, 152) cell–cell adhesion, (153) and cell motility (154) and the biological effects of molecular crowding, confinement, and compartmentalization. (155, 156) They have also been integral in studying the physical principles behind the membrane’s role in modulating cellular processes, specifically regarding the effects of bilayer asymmetry, (157) curvature, (158) and mechanical properties. (159, 160) Some facets of cell biology are easier to isolate and recapitulate in an artificial system, and it goes without saying that these are better suited for this reductionist approach. This strategy is expected to play an increasingly important role in the study of cell biology going forward. In a general sense, as artificial cells become ever more complex, they will more accurately mimic their biological counterparts, and the more effective this strategy will be.\nMicroreactors\nAnother prospective application is the use of compartmentalized structures as self-assembled reactors for chemical and biochemical synthesis. (15, 16, 161) Their use as reactors is attractive for several reasons: (i) They have ultralow reaction volumes (approaching the femtoliter scale), allowing low-quantity/scarce reagents to be used; (ii) they can be self-assembled, are free of defects, are often self-healing, and do not have to be constructed one-by-one via low-throughput nanofabrication techniques; (iii) they can be directly coupled with biological machineries to impart functionality (e.g., selective diffusion of feedstocks/products through embedded membrane channels); and (iv) they can exist as free-standing units in an aqueous environment, enabling reactor applications in physiologically relevant settings.\nCompartmentalized Reactors\nThese systems hold specific promise in biocatalysis, for the orchestration of spatially and temporally segregated enzyme cascades. (161) Segregating catalytic steps in separate compartments, where each compartment possesses a distinct chemical environment (e.g., different pH, temperatures, redox states, presence of cofactors, etc.), will allow the coupling of enzymatic reaction steps that would otherwise be incompatible with another. Compartmentalization will also facilitate hybrid chemo-enzymatic hybrid cascades, where reaction incompatibilities are especially pronounced, by preventing poisoning of chemical catalysts by enzymatic cofactors and vice versa.\nFuture directions will likely involve the design of tunable reactors, where temporal control of reactions will be controlled by embedded actuators that can modulate activity in response to the external cues (e.g., chemical environment, light, presence of biomolecules, etc.). In addition, a crucial aspect that needs to be addressed is the development of techniques to allow trans-compartment material transfer. When there is a single bilayer separating compartments (e.g., in the case of DIBs), this can be easily achieved through simple protein pores. (38) However, when two bilayers separate compartments from another, this becomes more difficult. Trans-compartment communication will likely rely on DNA origami structures, (115) engineered protein pores, or reconstitution of complex cellular structures that can span double membranes (e.g., connexions, nuclear pore complex and bacterial efflux proteins).\nTherapeutic Applications\nLiposomes have been used as drug delivery vehicles for several decades. (162) They can encapsulate hydrophobic and hydrophilic drugs in the aqueous core or in the membrane itself, can improve the therapeutic index of drugs by influencing drug absorption and metabolism, and can extent drug half-life as well as reduce toxicity. Drug distribution can be controlled by the physicochemical properties of the delivery vehicle itself, and not of the drug, providing crucial extra degrees of freedom in the design of therapeutics.\nThere are several areas in therapeutic delivery where using biomimetic containers can prove advantageous. The first is to increase the robustness and circulation time of the delivery vehicles. This can be achieved by modulating the composition, size, and charge of the compartment, (163, 164) by incorporating molecules such as glycolipids and PEG on the vesicle surface, (165) by mimicking the erythrocyte membranes, (166) and by using cell membrane mimetic polymers. (167)\nThe second concerns targeted delivery, enabling delivery of drugs to the organs, tissues, or cells affected by the disease. Related to this is the need to release the drug at defined rates, according to the diseased state. This can be achieved through a biomimetic approach of attaching moieties to recognize, bind, and induce internalization of the delivery vehicle. They can be decorated with targeting molecules (e.g., antibodies, aptamers, receptor ligands, peptides, and growth factors) (168, 169) and elements incorporated to evade the body’s immune response. (165) There have also been several efforts at using biomimetic surface engineering to coat nanoparticles with material found on the outer surface of cell membranes to mask it from the biological environment and to allow specific targeting. (170) This strategy has been shown to lead to increased uptake by tumors. (171)\nThe third is in the design of liposomes that are smart or responsive, releasing drugs only when the target or diseased site is met. This can be achieved through the incorporation of lipid components that are sensitive to pH (172) or temperature, (173) leading to fusiogenic properties or increased permeability due to phase transitions. Use of stimuli-responsive structures that respond to exogenous triggers (e.g., magnetic fields, light, electric pulses) is also an increasingly explored strategy. (174)\nThe fourth is cell encapsulation in microcapsules (e.g., ones based on hydrogels or polymers). This has the potential for in situ delivery of secreted proteins and for cell-based therapeutics more generally, where living cells treat pathological conditions. Encapsulation in a material that allows outflow of therapeutic material (and waste) and inflow of molecules needed for cell metabolism, while shielding the cell from the larger molecules of the immune system, is a potentially powerful concept in therapeutic delivery. (175)\nThe use of more elaborate compartmentalized structures for such applications is highly attractive for the introduction of smart and responsive functionalities in next generation therapeutic delivery vehicles. These include multicompartment architectures where several drugs can be isolated from one another yet still delivered simultaneously to the target site, in situ synthesis of active therapeutics from isolated drug precursors that are brought together upon encountering a target site, multilayer delivery vehicles with tunable drug release kinetics and staged payload delivery, and implanted tissue-like therapeutic devices. Compartmentalization of content is also valuable in the context of multimodal constructs, such as theranostics, which combine diagnostic and therapeutic capabilities in a single agent.\nThe introduction of biological components to the delivery vehicle surface adds an extra layer of functionality. (15) Addition of responsive elements to the delivery chassis (e.g., functional proteins channels, DNA origami modules, and light-sensitive lipids) raises the possibility for the construction of dormant systems with biovalves that can open/close in the presence/absence of diseased states, and the use of liposome systems as prophylactics that can be administered before a disease is even present.\nOne of the most pressing issues that needs to be addressed for such applications to be realized is the scaling down of the compartmentalized structures to the submicron regime for them to pass through narrow physiological constrictions and the scaling up of generation throughput. Advanced microfluidic and nanofluidic advances are expected to help in this regard.\nBottom-up Synthetic Biology\nBiological systems are highly compartmentalized across several length scales. This includes biomolecule compartmentalization through attachment to membranes and cytoskeleton scaffolds, lateral organization on membrane rafts, compartmentalization in membrane-bound or protein-based organelles, as well as higher-order arrangements of cells in the form of tissues. Therefore, recapitulating such levels of compartmentalization is key in the quest to construct synthetic cell-like systems capable of performing precisely engineered bespoke tasks.\nAs we have seen, efforts at achieving this are accelerating, and synthetic analogues of increasingly intricate biological structures are being developed. The repertoire of cell-like features and components successfully mimicked is expected to expand in the coming years to include, for example, the construction of synthetic exosomes for the transport of cargo between cells, synthetic gap junctions and synapses, and highly specialized analogues of membranous organelles such as the endoplasmic reticulum and the Golgi apparatus through the incorporation on nonbilayer forming lipids. In addition, methods to exert fine control over synthetic cell architecture will lead to the production of diverse cell morphologies such as elongated neutral-like cells.\nRelated to this, the isolation and reconstitution of whole cellular machineries, including flagella, biomolecular motors, cytoskeletons, lipid synthesis machinery, and components needed for membrane fission, will lead to the engineering of emergent behaviors such as self-healing, dynamic morphology changes, directed propulsion, homeostasis, replication, and evolution. For these higher-order behaviors to be mimicked, however, it is also necessary to integrate components that have to date been developed in isolation. Finally, applications utilizing synthetic cells will also be aided by the development of hybrid systems, where synthetic cells are interfaced with biological ones either through the construction of synthetic communication pathways or through hijacking and re-engineering existing biological ones. (176-178)\nReferences\nConclusions\nThere is little doubt that compartmentalizing chemistry and biology in soft-matter assemblies is an active and fast-growing area of research with both the number and scope of investigations increasing year after year. There are several trends which will play important roles in dictating the future direction of the field and help in achieving the diverse proposed applications.\nThe first is increasing synergies with other disciplines, specifically with the micro/nanofluidics community to develop devices needed for the controlled construction of functional structures, and with biochemists whose familiarity with cellular extraction and reconstitution protocols will prove invaluable. Collaboration with chemists to synthesize advanced building-blocks capable of self-assembly is key, as is the involvement of modeling and simulation researchers to better predict system behavior prior to fabrication. Finally, interfacing the soft-matter structures with the external world will require partnerships with engineers, both biological and electronic, and with medics, especially for clinical translation. These will be key in addressing one of the bottlenecks in this area, namely how processes contained inside synthetic cell-like structures can be continually powered by external energy sources, rather than coming to a halt when encapsulated chemical sources of energy are depleted.\nThe emergence of 3D printing and of publically accessible hackspaces in research will also have a part to play. It will serve to democratize the discipline and facilitate multidisciplinary collaborations and will allow biochemists and molecular biologists to exploit microfluidic technologies in their laboratories with limited infrastructure and training.\nOn the other side of the coin, the development of cheap and easy to use cell-free expression kits will enable physical scientists to directly exploit research areas that have previously been the preserve of trained biologists familiar with cell culture and genetic engineering techniques and will prove useful in rapid prototyping of biological parts and devices. This will be aided by the emergence of made-to-order gene synthesis and protein engineering providers, robotic cloud laboratories, and by ever decreasing costs of DNA sequencing (indeed the cost per megabase of DNA sequencing has been outpacing Moore’s law since the mid-2000s).\nIn conclusion, the above trends, in combination with developments in supramolecular chemistry, will allow the fabrication of increasingly complex compartmentalized architectures with useful cell-like functionalities that can serve functional purposes across a range of applications. Although an effort at outlining a roadmap for the field had been made, there will surely be many unpredictable developments that will take this research area to unexpected directions; what these are remains to be seen.\nFunding Information\nThis work was supported by the EPSRC through grants EP/K038648/1 and EP/J017566/1 and through EPSRC fellowship EP/N016998/1 awarded to YE.\nThe authors declare no competing financial interest.\nVocabulary\n""","0.098486036","""http://pubs.acs.org/doi/10.1021/acsnano.7b03245""","[-0.178219,51.500505]"
"""University_of_Surrey""","""An Exploration of Household Response to Personal Travel Carbon-Reduction Targets: International Journal of Sustainable Transportation: Vol 1, No 3""","""An Exploration of Household Response to Personal Travel Carbon-Reduction Targets\nGet access /doi/full/10.1080/15568310601113769?needAccess=true\nABSTRACT\nTransport is currently responsible for around one-quarter of the total anthropogenic CO2 emissions in the United Kingdom, and this proportion is projected to increase. The transport sector will undoubtedly need to play a significant role in achieving carbon reductions if the government is to meet its ambitious long-term goal of a 60% reduction by 2050. This article examines current carbon use by households for personal land-based transport and considers how feasible it would be to change that use over the period up to 2050 in the United Kingdom. It provides a unique insight into how much and in what way households and individuals may be willing to adapt their transport behavior to achieve carbon reductions. A computer-based transport carbon calculator was developed to investigate the CO2 emissions of individual households from various modes based on travel diary information. This formed the focus of a series of interactive interviews in which participants were asked to consider how their future low carbon transport strategy could look. Views of households on various abatement measures were explored, including technological change in vehicle design or fuel source and behavioral change through, for instance, traffic restraint and investment in public transport. Overall, a 40% reduction in carbon emissions was seen to be feasible through a combination of behavioral change measures and a realistically achievable degree of technological improvement, falling well short of the UK government's goal of a 60% reduction. Through changes in behavior alone, the households involved could only achieve around a 20% cut in carbon emissions —seemingly a threshold beyond which further reductions will be difficult and may necessitate significant lifestyle change.\n""","0.7240129","""http://www.tandfonline.com/doi/abs/10.1080/15568310601113769""","[-0.589514,51.242722]"
"""Queen's_University_Belfast""","""An Electric Vehicle Dispatch Module for Demand-Side Energy Participation - Queen's University Belfast Research Portal - Research Directory & Institutional Repository for QUB""","""An Electric Vehicle Dispatch Module for Demand-Side Energy Participation\nResearch output: Contribution to journal › Article\nPublished\nView graph of relations\nThe penetration of the electric vehicle (EV) has increased rapidly in recent years mainly as a consequence of advances in transport technology and power electronics and in response to global pressure to reduce carbon emissions and limit fossil fuel consumption. It is widely acknowledged that inappropriate provision and dispatch of EV charging can lead to negative impacts on power system infrastructure. This paper considers EV requirements and proposes a module which uses owner participation, through mobile phone apps and on-board diagnostics II (OBD-II), for scheduled vehicle charging. A multi-EV reference and single-EV real-time response (MRS2R) online algorithm is proposed to calculate the maximum and minimum adjustable limits of necessary capacity, which forms part of decision-making support in power system dispatch. The proposed EV dispatch module is evaluated in a case study and the influence of the mobile app, EV dispatch trending and commercial impact is explored.\nDocuments\nRights statement: 2016 Elsevier Ltd. All rights reserved. This manuscript version is made available under the CC-BY-NC-ND 4.0 license http://creativecommons.org/licenses/by-nc-nd/4.0/ which permits distribution and reproduction for non-commercial purposes, provided the author and source are cited.\nAccepted author manuscript, 542 KB, PDF-document\nDOI\nElectric vehicle, power system dispatch, real-time dispatch, mobile app, data security\nResearch outputs\n""","0.85899854","""http://pure.qub.ac.uk/portal/en/publications/an-electric-vehicle-dispatch-module-for-demandside-energy-participation(2850e1d6-b146-47dd-b616-e16063d13dc6).html""","[-5.934759,54.583863]"
"""University_of_Surrey""","""Finding effective pathways to sustainable mobility: bridging the science–policy gap: Journal of Sustainable Tourism: Vol 24, No 3""","""关键词: 气候变化 ,  社会技术因素 ,  科技神话 ,  运输禁忌 ,  理想期货\nIntroduction\nDemand is increasing for all transport modes. The transport sector, including tourism and all other transport motivations, is growing more rapidly than most other sectors and is currently responsible for approximately 23% of global energy-related CO2 emissions (Creutzig et al., 2015 Creutzig, F., Jochem, P., Edelenbosch, O.Y., Mattauch, L., van Vuuren, D.P., McCollum, D., & Minx, J. (2015). Transport: A roadblock to climate change mitigation? Science, 350(6263), 911–912. [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] ). Because of the sector's rising contributions to climate change, considerable effort has recently been invested by researchers to try to understand if people are willing to voluntarily change their tourism and transport behaviour (e.g. Becken, 2007 Becken, S. (2007). Tourists' perception of international air travel's impact on the global climate and potential climate change policies. Journal of Sustainable Tourism, 15, 351–368. [Taylor & Francis Online]   [Google Scholar] ; Higham, Cohen, Cavaliere, Reis, & Finkler, 2016 Higham, J.E.S., Cohen, S.A., Cavaliere, C.T., Reis, A.C., & Finkler, W. (2016). Climate change, tourist air travel and radical emissions reduction. Journal of Cleaner Production, 111, 336–347. [Crossref] , [Web of Science ®]   [Google Scholar] ; Kroesen, 2013 Kroesen, M. (2013). Exploring people's viewpoints on air travel and climate change: Understanding inconsistencies. Journal of Sustainable Tourism, 21(2), 271–290. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ; Miller, Rathouse, Scarles, Holmes, & Tribe, 2010 Miller, G., Rathouse, K., Scarles, C., Holmes, K., & Tribe, J. (2010). Public understanding of sustainable tourism. Annals of Tourism Research, 37(3), 627–645. [Crossref] , [Web of Science ®]   [Google Scholar] ). The weight of evidence clearly shows that, while awareness of the impact of mobility on climate change, and particularly that of air travel, is growing, there has been little if any actual behavioural change by tourists to travel less or to change travel modes (Higham, Cohen, Peeters, & Gössling, 2013 Higham, J.E.S., Cohen, S.A., Peeters, P., & Gössling, S. (2013). Psychological and behavioural approaches to understanding and governing sustainable mobility. Journal of Sustainable Tourism, 21(7), 949–967. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ). This realisation has been captured in numerous publications evidencing or attempting to explain an awareness–attitude or attitude–behaviour gap (e.g. Antimova, Nawijn, & Peeters, 2012 Antimova, R., Nawijn, J., & Peeters, P. (2012). The awareness/attitude gap in sustainable tourism: A theoretical perspective. Tourism Review, 67(3), 7–16. [Crossref]   [Google Scholar] ; Cohen, Higham, & Reis, 2013 Cohen, S.A., Higham, J., & Reis, A. (2013). Sociological barriers to sustainable discretionary air travel behaviour. Journal of Sustainable Tourism, 21(7), 982–998. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ; Hares, Dickinson, & Wilkes, 2010 Hares, A., Dickinson, J., & Wilkes, K. (2010). Climate change and the air travel decisions of UK tourists. Journal of Transport Geography, 18(3), 466–473. [Crossref] , [Web of Science ®]   [Google Scholar] ; Juvan & Dolnicar, 2014 Juvan, E., & Dolnicar, S. (2014). The attitude-behaviour gap in sustainable tourism. Annals of Tourism Research, 48, 76–95. [Crossref] , [Web of Science ®]   [Google Scholar] ). Meanwhile, calls were sounding that the very concept of voluntary behaviour change itself was trapped within the constraints of neoliberalism (Barr, Gilg, & Shaw, 2011 Barr, S., Gilg, A., & Shaw, G. (2011). Citizens, consumers and sustainability: (Re)framing environmental practice in an age of climate change. Global Environmental Change, 21, 1224–1233. [Crossref] , [Web of Science ®]   [Google Scholar] ; Schwanen, Banister, & Anable, 2011 Schwanen, T., Banister, D., & Anable, J. (2011). Scientific research about climate change mitigation in transport: A critical review. Transportation Research Part A, 45, 993–1006. [Crossref]   [Google Scholar] ). These calls urged the academy to pay closer attention to the political, social and material systems in which consumption practices are structured, arguing that the “carbon capability” (Whitmarsh, Seyfang, & O'Neill, 2011 Whitmarsh, L., Seyfang, G., & O'Neill, S. (2011). Public engagement with carbon and climate change: To what extent is the public “carbon capable”? Global Environmental Change, 21, 56–65. [Crossref] , [Web of Science ®]   [Google Scholar] ) of the public is limited by the “systems of provision” (Hall, 2013 Hall, C.M. (2013). Framing behavioural approaches to understanding and governing sustainable tourism consumption: Beyond neoliberalism, ‘nudging’ and ‘green growth’? Journal of Sustainable Tourism, 21(7), 1091–1109. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ), which create what Schwanen et al. ( 2011 Schwanen, T., & Lucas, K. (2011). Understanding auto motives. In K. Lucas, E. Blumenberg, & R. Weinberger (Eds.), Auto motives: Understanding car use behaviours. (pp. 3–38). Emerald: Bingley. [Crossref]   [Google Scholar] ) refer to as “path dependencies”.\nA turn towards path dependencies does not suggest that attempts to achieve public behavioural change should be abandoned. Rather it emphasises that devolving the problem of tourism and transport's impacts on climate change to individuals is a limited framing. In addition to social marketing efforts aimed downstream at effecting behavioural change in publics (see Hall, in press Hall, C.M. (in press). Intervening in academic interventions: Using the lens of social marketing to examine the potential for successful sustainable tourism behavioural change. Journal of Sustainable Tourism, DOI: 10.1080/09669582.2015.1088861. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] , this issue), and a continued drive by industry towards marginal efficiency gains available in aviation technologies (Cumpsty et al., 2010 Cumpsty, N., Alonso, J., Eury, S., Maurice, L., Nas, B., Ralph, M., & Sawyer, R. (2010). Report of the independent experts on medium and long term goals for aviation fuel burn reduction from technology. Montreal: ICAO.  [Google Scholar] ; Peeters & Middel, 2007 Peeters, P.M., & Middel, J. (2007). Historical and future development of air transport fuel efficiency. In R. Sausen, A. Blum, D.S. Lee, & C. Brüning (Eds.), Proceedings of an International Conference on Transport, Atmosphere and Climate (TAC), Oxford, United Kingdom, 26–29 June 2006 (pp. 42–47). Oberpfaffenhofen: DLR Institut für Physic der Atmosphäre.  [Google Scholar] ), it is imperative that research focuses on how the radical socio-technical transitions that are necessary to put the tourism and transport sectors on a sustainable emissions path can be achieved. Technical solutions alone will be too little and too late (Chèze, Chevallier, & Gastineau, 2013 Chèze, B., Chevallier, J., & Gastineau, P. (2013). Will technological progress be sufficient to stabilize CO2 emissions from air transport in the mid-term? (No. Les cahiers de l'économie – no. 94). Rueil-Malmaison: Centre Économie et Gestion.  [Google Scholar] ; Peeters, Higham, Kutzner, Cohen, & Gössling, under review Peeters, P., Higham, J.E.S., Kutzner, D., Cohen, S., & Gössling, S. Are technology myths stalling aviation climate policy? Transportation Research Part D: Transport and Environment, under review. [Web of Science ®]   [Google Scholar] ). This includes not only a recognition that the present socio-technical landscape is dominated by neoliberal, techno-centric and ecological modernisation values (Hall, 2013 Hall, C.M. (2013). Framing behavioural approaches to understanding and governing sustainable tourism consumption: Beyond neoliberalism, ‘nudging’ and ‘green growth’? Journal of Sustainable Tourism, 21(7), 1091–1109. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ; Hopkins & Higham, 2012 Hopkins, D., & Higham, J.E.S. (2012). Framework conventions for climate change: An analysis of global framework conventions with reference to resource governance and environmental management approaches in New Zealand. In A. Holden & D. Fennell (Eds.), A handbook of tourism and the environment (pp. 227–240). London: Routledge.  [Google Scholar] ), but also the need for a concerted effort by tourism and transport researchers to become active advocates of pathways to structural change, influence policy learning and provide politicians with tools to simulate policy-making and its effects.\nThe Freiburg 2014 workshop\nThe Freiburg 2014 workshop, held in Freiburg im Breisgau in Germany (1–4 July 2014), sought to address the inability of policy-makers and other stakeholders to change the tourism mobility system towards sustainable development. Its objectives stemmed directly from the Freiburg 2012 workshop, the results of which were disseminated in the Journal of Sustainable Tourism (volume 21, issue 7; see Higham et al., 2013 Higham, J.E.S., Cohen, S.A., Peeters, P., & Gössling, S. (2013). Psychological and behavioural approaches to understanding and governing sustainable mobility. Journal of Sustainable Tourism, 21(7), 949–967. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ) and in an edited book (Cohen, Higham, Peeters, & Gössling, 2014 Cohen, S.A., Higham, J.E.S., Peeters, P., & Gössling, S. (2014). Understanding and governing sustainable tourism mobility: Psychological and behavioural approaches. London: Routledge.  [Google Scholar] ).\nA key outcome from Freiburg 2012 was the conclusion that the public are generally unwilling or unable to change tourism and transport behaviour based on an awareness of environmental impacts, and specifically climate change. It was concluded that “the autonomy of individual pro-environmental response, when set within the systems of provision in late-capitalist consumer society, is fraught with challenge” (Higham et al., 2013 Higham, J.E.S., Cohen, S.A., Peeters, P., & Gössling, S. (2013). Psychological and behavioural approaches to understanding and governing sustainable mobility. Journal of Sustainable Tourism, 21(7), 949–967. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] , p. 14) and that the “low sustainability of the current tourism system is embedded in structures that make it easy and often cheaper to travel unsustainably … raising a wide range of questions regarding transport infrastructures, taxation, management and governance” (Cohen et al. 2014 Cohen, S.A., Higham, J.E.S., Peeters, P., & Gössling, S. (2014). Understanding and governing sustainable tourism mobility: Psychological and behavioural approaches. London: Routledge.  [Google Scholar] , p. 301). This conclusion illustrated the need to move beyond voluntary behavioural change in order to achieve sustainable mobility, and to explore the socio-technical landscapes in which individuals are embedded, through which public behaviour is conditioned and patterned.\nA further crucial conclusion from Freiburg 2012 was that policy-makers had shown limited interest in adopting policy measures that would achieve significant changes in sustainable transport behaviour. This lack of political initiative, wherein it was clear that politicians have far more links to industry than to science, and particularly to the social sciences, suggested that the reasons behind the inaction in transport governance needed to be urgently and critically explored. Overall, it was evident that while a comprehensive understanding of the psychologies of tourism and transport consumption is necessary to inform policy-makers, this alone would not be enough to bring the sectors onto a climatically sustainable pathway, and that radical transitions in the systems of provision and deeper understandings of political psychologies are needed (Cohen et al., 2014 Cohen, S.A., Higham, J.E.S., Peeters, P., & Gössling, S. (2014). Understanding and governing sustainable tourism mobility: Psychological and behavioural approaches. London: Routledge.  [Google Scholar] ; Hall, 2013 Hall, C.M. (2013). Framing behavioural approaches to understanding and governing sustainable tourism consumption: Beyond neoliberalism, ‘nudging’ and ‘green growth’? Journal of Sustainable Tourism, 21(7), 1091–1109. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ; Higham et al., 2013 Higham, J.E.S., Cohen, S.A., Peeters, P., & Gössling, S. (2013). Psychological and behavioural approaches to understanding and governing sustainable mobility. Journal of Sustainable Tourism, 21(7), 949–967. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ).\nThese insights formed the basis for the Freiburg 2014 workshop, which expanded its discussions to focus on public behaviour change, but also on how to change the behaviour of policy-makers, industry stakeholders and researchers themselves, to help achieve changes in tourism and transport systems for environmental reasons. Central to this endeavour was the question of how to bridge the science–policy gap: it was abundantly clear that despite the substantial and expanding body of research on tourism and climate change (Hall et al., 2015 Hall, C.M., Amelung, B., Cohen, S., Eijgelaar, E., Gössling, S., Higham, J., … Scott, D. (2015). On climate change skepticism and denial in tourism. Journal of Sustainable Tourism, 23(1), 4–25. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ), and on transport and climate change (Schwanen, et al., 2011 Schwanen, T., & Lucas, K. (2011). Understanding auto motives. In K. Lucas, E. Blumenberg, & R. Weinberger (Eds.), Auto motives: Understanding car use behaviours. (pp. 3–38). Emerald: Bingley. [Crossref]   [Google Scholar] ), this corpus of knowledge was having little to no effect in practice on governance.\nThe Freiburg 2014 workshop is the basis for this special issue presenting 10 papers, including this overview paper, exploring the dimensions and details of the science–policy gap in sustainable mobility. Having established the context in which the workshop was set, and before introducing the papers in this special issue, we now discuss three essential themes that are vital to understanding why, despite clear scientific evidence as to the growing environmental impacts of tourism transport, and particularly air travel, there is large-scale inertia in structural transitions and a lack of political willpower to enact meaningful policy change: (1) the importance of addressing socio-technical factors, (2) the barriers posed by placing faith in “technology myths” and (3) the need to overcome “transport taboos” in policy-making. The paper concludes by setting a research agenda that forms the basis for the forthcoming Freiburg 2016 workshop (28 June to 1 July 2016).\nSocio-technical factors\nCurrent growth trajectories indicate that transport emissions will double by 2050: the global fleet of light-duty vehicles is expected to double during that time period, and “demand for freight transport (road, rail, shipping, and air) and passenger aviation is projected to surge as well” (Creutzig et al., 2015 Creutzig, F., Jochem, P., Edelenbosch, O.Y., Mattauch, L., van Vuuren, D.P., McCollum, D., & Minx, J. (2015). Transport: A roadblock to climate change mitigation? Science, 350(6263), 911–912. [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] , p. 911). Air travel in particular offers an example of largely intractable public travel behaviours that are entrenched in Europe and North America and being rapidly adopted in the emerging regions of the world (Freire-Medeiros & Name, 2013 Freire-Medeiros, B., & Name, L. (2013). Flying for the very first time: Mobilities, social class and environmental concerns in a Rio de Janeiro favela. Mobilities, 8(2), 167–184. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ; Higham, Cohen, & Cavaliere, 2014 Higham, J., Cohen, S., & Cavaliere, C. (2014). Climate change, discretionary air travel and the ‘flyers’ dilemma'. Journal of Travel Research, 53(4), 462–475. [Crossref] , [Web of Science ®]   [Google Scholar] ). The development of low-cost, high-volume aviation, initially in Europe and North America, and latterly in Brazil, Russia, India and China, is now powering similar air travel growth trajectories in the emerging neoliberal economies of Mexico, South Africa, Indonesia and Turkey (Boeing, 2014 Boeing. (2014). Current market outlook 2014-2033. Seattle, WA: Boeing Commercial Airplanes.  [Google Scholar] ). Growth in air travel over the last two decades has been rapid (Gössling & Upham, 2009 Gössling, S., & Upham, P. (Eds.). (2009). Climate change and aviation: Issues, challenges and solutions. London: Earthscan.  [Google Scholar] ), and the current growth trajectory is projected to continue at a rate of 3.3% per annum to 2030 (Hall, 2013 Hall, C.M. (2013). Framing behavioural approaches to understanding and governing sustainable tourism consumption: Beyond neoliberalism, ‘nudging’ and ‘green growth’? Journal of Sustainable Tourism, 21(7), 1091–1109. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ).\nCalls for tourism to move onto a sustainable emissions path (Becken, 2007 Becken, S. (2007). Tourists' perception of international air travel's impact on the global climate and potential climate change policies. Journal of Sustainable Tourism, 15, 351–368. [Taylor & Francis Online]   [Google Scholar] ) have been especially challenged by growing demand for air travel. This growth has been driven by significant structural changes in the transportation sector (Ryley, Davison, Bristow, & Pridmore, 2010 Ryley, T., Davison, L., Bristow, A., & Pridmore, A. (2010). Public engagement on aviation taxes in the United Kingdom. International Journal of Sustainable Transportation, 4(2), 112–128. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ). Neoliberalism has been embraced by the aviation industry through airline deregulation, the deployment of frequent flyer loyalty programmes and notably by the unrestrained growth of low-cost carriers (LCCs) (Duval, 2013 Duval, D.T. (2013). Critical issues in air transport and tourism. Tourism Geographies, 15(3), 494–510. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ). Network airlines offering full service and traditional routes have been drawn into intense competition with LCCs, transforming the travel market through the uptake of technology to substantially reduce labour costs (Holloway, Humphreys, & Davidson, 2009 Holloway, J.C., Humphreys, C., & Davidson, R. (2009). The business of tourism (8th ed.). Harlow: Pearson Education.  [Google Scholar] ). The LCCs have developed direct sales systems (i.e. internet booking systems), online check-in and product itemisation (e.g. priority boarding, seat allocation, baggage allowances, in-flight food and entertainment services) to de-personalise airport and air travel experiences, while increasing aircraft utilisation and flight loadings, while reducing fares (Boeing, 2014 Boeing. (2014). Current market outlook 2014-2033. Seattle, WA: Boeing Commercial Airplanes.  [Google Scholar] ; Casey, 2010 Casey, M.E. (2010). Low cost air travel: Welcome aboard? Tourist Studies, 10(2), 175–191. [Crossref]   [Google Scholar] ). The LCC business model includes operating with a single aircraft type, providing a single-class product, serving secondary airports and avoiding the costs of frequent flyer programmes (Boeing, 2014 Boeing. (2014). Current market outlook 2014-2033. Seattle, WA: Boeing Commercial Airplanes.  [Google Scholar] ).\nThe consequential growth in demand for low-cost air travel is recognised as “one of the biggest revolutions in tourism and travel since the package holiday's arrival half a century earlier” (Casey, 2010 Casey, M.E. (2010). Low cost air travel: Welcome aboard? Tourist Studies, 10(2), 175–191. [Crossref]   [Google Scholar] , p. 176). The success of the LCCs is reflected in the increasingly ordinary nature of air travel in certain sections of some societies (Randles & Mander, 2009a Randles, S., & Mander, S. (2009a). Practice(s) and ratchet(s): A sociological examination of frequent flying. In S. Gössling & P. Upham (Eds.), Climate change and aviation: Issues, challenges and solutions (pp. 245–271). London: Earthscan.  [Google Scholar] ; Urry, 2010 Urry, J. (2010). Sociology and climate change. The Sociological Review, 57(2), 84–100. [Crossref]   [Google Scholar] ). New structures of air travel provision have created flying as a highly accessible consumer product, shifting leisure travel into the domain of everyday consumer capitalism (Young, Higham, & Reis, 2014 Young, M., Higham, J.E.S., & Reis, A. (2014). Up in the air: A conceptual critique of flying addiction. Annals of Tourism Research, 41, 51–64. [Crossref] , [Web of Science ®]   [Google Scholar] ). Indeed the extent to which these structures have shaped and influenced everyday consumer practices has, in some cases, reached absurd proportions. Ben Schlappig – “the man who flies around the world for free” – is “… one of the biggest stars among an elite group of obsessive flyers whose mission is to outwit the airlines” (Wofford, 2015 Wofford, B. (2015). Up in the air: Meet the man who flies around the world for free. Rolling Stone Magazine, 20 July 2014.  [Google Scholar] , p. 3). Perfecting the art of “travel hacking” – known among its members as “The Hobby” – Schlappig seeks perfection in the art of non-stop air travel and consumer luxury that is paid for by a “… gargantuan cache of frequent flier miles that grows only bigger by the day” (Wofford, 2015 Wofford, B. (2015). Up in the air: Meet the man who flies around the world for free. Rolling Stone Magazine, 20 July 2014.  [Google Scholar] , p. 5). Schlappig's claim is to be “beating the airlines at their own game”; through the gaming of frequent flyer programmes using techniques that he shares with a half million strong following through the “FlyerTalk” website.\nThe gaming of frequent flyer programmes offers an, albeit extreme, insight into consumer air travel behaviour that is anchored in and enabled by the socio-technical system. It forms part of a wider pattern of increasing affordability and uptake of air travel across an expanding range of social classes and societies (Randles & Mander, 2009b Randles, S., & Mander, S. (2009b). Aviation, consumption and the climate change debate: ‘Are you going to tell me off for flying?’ Technology Analysis & Strategic Management, 21(1), 93–113. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ). It is this growth in demand for air travel that contributes significantly to driving up tourism transport emissions (Gössling & Peeters, 2015 Gössling, S., & Peeters, P. (2015). Assessing tourism's global environmental impact 1900–2050. Journal of Sustainable Tourism, 23(5), 639–659. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ). With current and projected growth in aviation emissions has come recognition that the freedom to engage in unrestrained air travel comes with significant environmental costs (IPCC, 2013 IPCC. (2013). Climate change 2013: The physical science basis. Retrieved 28 November 2013 from IPCC web site: http://www.ipcc.ch/report/ar5/wg1/#.Uu70df0p8ds  [Google Scholar] ). While the environmental costs of air travel are now widely understood and accepted by the travelling public, the necessary responses in terms of consumer demand have not followed (Gössling, 2009 Gössling, S., & Upham, P. (Eds.). (2009). Climate change and aviation: Issues, challenges and solutions. London: Earthscan.  [Google Scholar] ; Higham, Cohen, Peeters, & Gössling, 2013 Higham, J.E.S., Cohen, S.A., Peeters, P., & Gössling, S. (2013). Psychological and behavioural approaches to understanding and governing sustainable mobility. Journal of Sustainable Tourism, 21(7), 949–967. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ).\nIt is ironic that the increasingly aeromobile middle classes can be the same people who claim to be environmentally aware and moral consumers (Dolnicar, Juvan, Ring, & Leisch, in press Dolnicar, S., Juvan, E., Ring, A. & Leisch, F. (in press). Tourist segments' justifications for behaving in an environmentally unsustainable way. Journal of Sustainable Tourism, DOI: 10.1080/09669582.2015.10248861 [Crossref] , [Web of Science ®]   [Google Scholar] ; Young et al., 2014 Young, M., Higham, J.E.S., & Reis, A. (2014). Up in the air: A conceptual critique of flying addiction. Annals of Tourism Research, 41, 51–64. [Crossref] , [Web of Science ®]   [Google Scholar] ). Within the context of air travel the “flyers’ dilemma” describes the tension between the self-identity of consumers who feel moral responsibility for their consumer decisions, and the high environmental costs of flying (Higham, Cohen, & Cavaliere, 2014 Higham, J., Cohen, S., & Cavaliere, C. (2014). Climate change, discretionary air travel and the ‘flyers’ dilemma'. Journal of Travel Research, 53(4), 462–475. [Crossref] , [Web of Science ®]   [Google Scholar] ; Rosenthal, 2010 Rosenthal, E. (2010, May 24). Can we kick our addiction to flying? Retrieved 13 September 2010 from The Guardian web site: http://www.guardian.co.uk/environment/2010/may/24/kick-addiction-flying/  [Google Scholar] ). The anxieties arising from the “flyers’ dilemma” have been empirically examined in various European societies (Higham, et al., 2016 Higham, J.E.S., Cohen, S.A., Cavaliere, C.T., Reis, A.C., & Finkler, W. (2016). Climate change, tourist air travel and radical emissions reduction. Journal of Cleaner Production, 111, 336–347. [Crossref] , [Web of Science ®]   [Google Scholar] ). Various studies have highlighted that air travel practices are largely unconstrained because flying is a cheap, convenient and socially desirable form of leisure consumption (Cohen & Higham, 2011 Cohen, S.A., & Higham, J.E.S. (2011). Eyes wide shut? UK consumer perceptions on aviation climate impacts and travel decisions to New Zealand. Current Issues in Tourism, 14(4), 323–335. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ; Higham & Cohen, 2011 Higham, J.E.S., & Cohen, S.A. (2011). Canary in the coalmine: Norwegian attitudes towards climate change and extreme long-haul air travel to Aotearoa/New Zealand. Tourism Management, 32(1), 98–105. [Crossref] , [Web of Science ®]   [Google Scholar] ).\nIt emerges that a focus on the demand-side of travel, in an attempt to address issues of sustainability through behaviour change, should not ignore the fundamental socio-structural factors that underpin the tourism system (Cornelissen, 2005 Cornelissen, S. (2005). The global tourism system. Aldershot: Ashgate.  [Google Scholar] ). Young, Markham, Reis, and Higham ( 2015 Young, M., Markham, F., Reis, A.C., & Higham, J.E.S. (2015). Flights of fantasy: A reformulation of the flyers' dilemma. Annals of Tourism Research, 54, 1–15. [Crossref] , [Web of Science ®]   [Google Scholar] ) argue that the locus of responsibility is critical to debates around sustainable aviation and sustainable mobility more broadly. Hall ( 2013 Hall, C.M. (2013). Framing behavioural approaches to understanding and governing sustainable tourism consumption: Beyond neoliberalism, ‘nudging’ and ‘green growth’? Journal of Sustainable Tourism, 21(7), 1091–1109. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] , p. 1101) observes that “mutual reinforcement between modes of governance and intervention … creates a path dependency in which solutions to sustainable tourism mobility are only identified within ‘green growth’ arguments for greater efficiency and market-based solutions.” Hall ( 2013 Hall, C.M. (2013). Framing behavioural approaches to understanding and governing sustainable tourism consumption: Beyond neoliberalism, ‘nudging’ and ‘green growth’? Journal of Sustainable Tourism, 21(7), 1091–1109. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ) argues that as long as the focus of government tourism policies remains situated in a GDP growth paradigm, the structures of transport provision will remain unchanged and the environment required to empower a consumer-led shift to a sustainable transport emissions path will not exist.\nYoung et al. ( 2015 Young, M., Markham, F., Reis, A.C., & Higham, J.E.S. (2015). Flights of fantasy: A reformulation of the flyers' dilemma. Annals of Tourism Research, 54, 1–15. [Crossref] , [Web of Science ®]   [Google Scholar] ) suggest that appealing to individuals to reduce or otherwise moderate their tourist travel consumption practices is a flawed response. It lacks the necessary government policy response to an industry that is environmentally damaging. Appealing to consumer sacrifice ignores the fundamental socio-structural underpinnings of an unsustainable travel industry. Young et al. ( 2015 Young, M., Markham, F., Reis, A.C., & Higham, J.E.S. (2015). Flights of fantasy: A reformulation of the flyers' dilemma. Annals of Tourism Research, 54, 1–15. [Crossref] , [Web of Science ®]   [Google Scholar] ) critically consider the social, institutional and economic forces that produce excessive and unsustainable travel consumption. They highlight, first and foremost, that within the existing structures of the aviation industry, currently no alternative options are available to avoid the high environmental costs of air travel (Young et al., 2014 Young, M., Higham, J.E.S., & Reis, A. (2014). Up in the air: A conceptual critique of flying addiction. Annals of Tourism Research, 41, 51–64. [Crossref] , [Web of Science ®]   [Google Scholar] ). No low-emission form of aviation exists to serve flyers who are concerned about climate change and aviation emissions (Peeters & Middel, 2007 Peeters, P.M., & Middel, J. (2007). Historical and future development of air transport fuel efficiency. In R. Sausen, A. Blum, D.S. Lee, & C. Brüning (Eds.), Proceedings of an International Conference on Transport, Atmosphere and Climate (TAC), Oxford, United Kingdom, 26–29 June 2006 (pp. 42–47). Oberpfaffenhofen: DLR Institut für Physic der Atmosphäre.  [Google Scholar] ), and neither is there any real prospect of major gains in aviation fuel efficiency in the short–medium term future (Peeters et al., under review) Peeters, P., Higham, J.E.S., Kutzner, D., Cohen, S., & Gössling, S. Are technology myths stalling aviation climate policy? Transportation Research Part D: Transport and Environment, under review. [Web of Science ®]   [Google Scholar] .\nWhile the airline industry has made significant gains in efficiency since the advent of jet aviation (Peeters & Dubois, 2010 Peeters, P., & Dubois, G. (2010). Tourism travel under climate change mitigation constraints. Journal of Transport Geography, 18(3), 447–457. [Crossref] , [Web of Science ®]   [Google Scholar] ), current technologies are locked in for periods of time that reach well beyond the urgent time frame required to achieve radical emission reductions (Higham et al., 2016 Higham, J.E.S., Cohen, S.A., Cavaliere, C.T., Reis, A.C., & Finkler, W. (2016). Climate change, tourist air travel and radical emissions reduction. Journal of Cleaner Production, 111, 336–347. [Crossref] , [Web of Science ®]   [Google Scholar] ). Jet aviation is highly efficient in terms of time/distance/cost thresholds (Howitt, Revol, Smith, & Rodger, 2010 Howitt, O.J.A., Revol, V.G.N., Smith, I.J., & Rodger, C.J. (2010). Carbon emissions from international cruise ship passengers' travel to and from New Zealand. Energy Policy, 38, 2552–2560. [Crossref] , [Web of Science ®]   [Google Scholar] ), but those energy efficiencies have been overwhelmed in real terms by growth in demand (Peeters & Dubois, 2010 Peeters, P., & Dubois, G. (2010). Tourism travel under climate change mitigation constraints. Journal of Transport Geography, 18(3), 447–457. [Crossref] , [Web of Science ®]   [Google Scholar] ), such that the environmental costs of air travel have become unacceptably high (Gössling, Hall, Peeters, and Scott 2010 Scott, D., Peeters, P. & Gössling, S. (2010). Can tourism deliver its aspiration greenhouse gas emission reduction targets? Journal of Sustainable Tourism, 18(3), 393–408. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ; Hall, 2013 Hall, C.M. (2013). Framing behavioural approaches to understanding and governing sustainable tourism consumption: Beyond neoliberalism, ‘nudging’ and ‘green growth’? Journal of Sustainable Tourism, 21(7), 1091–1109. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ). The current structure of the aviation industry and the absence of further substantial technical gains in aircraft efficiency (Scott, Peeters, & Gössling, 2010 Scott, D. (2016). The Paris Climate Change Conference and the tourism industry. Journal of Sustainable Tourism, under review  [Google Scholar] ) are such that aviation emissions are expected to double within a 25–45 year time frame (Gössling & Peeters, 2015 Gössling, S., & Peeters, P. (2015). Assessing tourism's global environmental impact 1900–2050. Journal of Sustainable Tourism, 23(5), 639–659. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ).\nDespite growing sustainability concerns, aviation, like the automobile (Dennis & Urry, 2009 Dennis, K., & Urry, J. (2009). After the car. Cambridge: John Wiley & Sons.  [Google Scholar] ), has become an integral part of contemporary mobility in many societies (Sheller & Urry, 2004 Sheller, M., & Urry, J. (Eds.). (2004). Tourism mobilities: Places to play, places in play. London: Routledge.  [Google Scholar] ; Urry, 2012 Urry, J. (2012). Social networks, mobile lives and social inequalities. Journal of Transport Geography, 21, 24–30. [Crossref] , [Web of Science ®]   [Google Scholar] ). Flying now out-competes other transport modes not only on convenience and time efficiency but – most critically – in terms of cost (Casey, 2010 Casey, M.E. (2010). Low cost air travel: Welcome aboard? Tourist Studies, 10(2), 175–191. [Crossref]   [Google Scholar] ). The time, cost and convenience advantages of air travel are structural factors that explain the deeply embedded nature of air travel practices (Higham, Cohen, & Cavaliere, 2014 Higham, J., Cohen, S., & Cavaliere, C. (2014). Climate change, discretionary air travel and the ‘flyers’ dilemma'. Journal of Travel Research, 53(4), 462–475. [Crossref] , [Web of Science ®]   [Google Scholar] ). The aviation system allows the production of tourism (and other forms of mobility) to be accelerated in terms of fit within the capitalist working day, week and calendar year (Young et al., 2015 Young, M., Markham, F., Reis, A.C., & Higham, J.E.S. (2015). Flights of fantasy: A reformulation of the flyers' dilemma. Annals of Tourism Research, 54, 1–15. [Crossref] , [Web of Science ®]   [Google Scholar] ). Given the fundamentally energy-intensive nature of the tourism system (Becken, 2016 Becken, S. (2016). Peak oil: A hidden issue? Social representations of professional tourism perspectives. Journal of Sustainable Tourism, 24(1), 31–51. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ), mitigating tourism transport emissions has proved a very imposing challenge (Schwanen et al., 2011 Schwanen, T., & Lucas, K. (2011). Understanding auto motives. In K. Lucas, E. Blumenberg, & R. Weinberger (Eds.), Auto motives: Understanding car use behaviours. (pp. 3–38). Emerald: Bingley. [Crossref]   [Google Scholar] ). Not least, neither car nor rail nor even high-speed rail can match the cost, convenience and flexibility of response that air travel can, especially if sea crossings are involved.\nIt is also apparent that travellers, even those who are concerned about their personal leisure travel emissions, are able to disregard their environmental concerns and take advantage of cheap and convenient air travel opportunities (Higham et al., 2016 Higham, J.E.S., Cohen, S.A., Cavaliere, C.T., Reis, A.C., & Finkler, W. (2016). Climate change, tourist air travel and radical emissions reduction. Journal of Cleaner Production, 111, 336–347. [Crossref] , [Web of Science ®]   [Google Scholar] ; Young et al., 2015 Young, M., Markham, F., Reis, A.C., & Higham, J.E.S. (2015). Flights of fantasy: A reformulation of the flyers' dilemma. Annals of Tourism Research, 54, 1–15. [Crossref] , [Web of Science ®]   [Google Scholar] ). Even for those who are deeply concerned about climate change (see Cohen, & Higham, 2011 Cohen, S.A., & Higham, J.E.S. (2011). Eyes wide shut? UK consumer perceptions on aviation climate impacts and travel decisions to New Zealand. Current Issues in Tourism, 14(4), 323–335. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ; Higham & Cohen, 2011 Higham, J.E.S., & Cohen, S.A. (2011). Canary in the coalmine: Norwegian attitudes towards climate change and extreme long-haul air travel to Aotearoa/New Zealand. Tourism Management, 32(1), 98–105. [Crossref] , [Web of Science ®]   [Google Scholar] ), the time and costs advantages of air travel undermine the competitiveness of alternative, more sustainable transport modes (Higham et al., 2014 Higham, J., Cohen, S., & Cavaliere, C. (2014). Climate change, discretionary air travel and the ‘flyers’ dilemma'. Journal of Travel Research, 53(4), 462–475. [Crossref] , [Web of Science ®]   [Google Scholar] ). The time/distance/cost dimensions of air travel have also allowed the consumption of distant tourist destinations to fit within narrow windows of time (e.g. the EasyJet generation of weekend “escape artists”). The act of flying has become integral to significant parts of the contemporary tourism transport system (Young et al., 2015 Young, M., Markham, F., Reis, A.C., & Higham, J.E.S. (2015). Flights of fantasy: A reformulation of the flyers' dilemma. Annals of Tourism Research, 54, 1–15. [Crossref] , [Web of Science ®]   [Google Scholar] ).\nAs Young et al. ( 2014 Young, M., Higham, J.E.S., & Reis, A. (2014). Up in the air: A conceptual critique of flying addiction. Annals of Tourism Research, 41, 51–64. [Crossref] , [Web of Science ®]   [Google Scholar] ) observe, aviation has proven to be resistant to consumer-led change, in contrast to other aspects of consumer behaviour, such as food purchases, recycling, the use of public land transport and the conscious uptake of active transport modes, which are relatively open to modification by individuals (Barr, Shaw, Coles, & Prillwitz, 2010 Barr, S., Shaw, G., Coles, T., & Prillwitz, J. (2010). ‘A holiday is a holiday’: Practicing sustainability, home and away. Journal of Transport Geography, 18(3), 474–481. [Crossref] , [Web of Science ®]   [Google Scholar] ; Lassen, 2010 Lassen, C. (2010). Environmentalist in business class: An analysis of air travel and environmental attitude. Transport Reviews, 30(6), 733–751. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ). The intractability of air travel behaviour change occurs not only because air travel has become a desirable and affordable gateway to tourism in many societies (Casey, 2010 Casey, M.E. (2010). Low cost air travel: Welcome aboard? Tourist Studies, 10(2), 175–191. [Crossref]   [Google Scholar] ), but also because “… the environmental risks associated with air travel are global and systemic, as opposed to specific and individual, and tend not to be prioritised within a flyers' environmental consciousness” (Young et al., 2014 Young, M., Higham, J.E.S., & Reis, A. (2014). Up in the air: A conceptual critique of flying addiction. Annals of Tourism Research, 41, 51–64. [Crossref] , [Web of Science ®]   [Google Scholar] , p. 60). As a result climate concerns may be temporarily suspended with impunity so that consumers can continue to consume leisure travel that involves flying (Watson, 2014 Watson, C. (Ed.). (2014). Beyond flying: Rethinking air travel in a globally connected world. Cambridge: Green Books.  [Google Scholar] ).\nThe current structures of aviation provision foster the willingness of the public to temporarily suspend their climate concerns when engaging in tourism practices (Barr et al., 2010 Barr, S., Shaw, G., Coles, T., & Prillwitz, J. (2010). ‘A holiday is a holiday’: Practicing sustainability, home and away. Journal of Transport Geography, 18(3), 474–481. [Crossref] , [Web of Science ®]   [Google Scholar] ; Cohen, Higham, & Reis, 2013 Cohen, S.A., Higham, J., & Reis, A. (2013). Sociological barriers to sustainable discretionary air travel behaviour. Journal of Sustainable Tourism, 21(7), 982–998. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ). The aviation industry facilitates a range of spatio-temporal fixes (Young et al., 2014 Young, M., Higham, J.E.S., & Reis, A. (2014). Up in the air: A conceptual critique of flying addiction. Annals of Tourism Research, 41, 51–64. [Crossref] , [Web of Science ®]   [Google Scholar] ) that invite the consumer to offset their aviation carbon emissions through various schemes (Barr et al., 2010 Barr, S., Shaw, G., Coles, T., & Prillwitz, J. (2010). ‘A holiday is a holiday’: Practicing sustainability, home and away. Journal of Transport Geography, 18(3), 474–481. [Crossref] , [Web of Science ®]   [Google Scholar] ; Gössling et al., 2007 Gössling, S., Broderick, J., Upham, P., Peeters, P., Strasdas, W., Ceron, J.-P., & Dubois, G. (2007). Voluntary carbon offsetting schemes for aviation: Efficiency and credibility. Journal of Sustainable Tourism, 15(3), 223–248. [Taylor & Francis Online]   [Google Scholar] ). Offset schemes encourage concerned travellers to assume responsibility for a profligate industry, by incurring an additional cost to mitigate the externalities of aviation consumption (Young et al., 2014 Young, M., Higham, J.E.S., & Reis, A. (2014). Up in the air: A conceptual critique of flying addiction. Annals of Tourism Research, 41, 51–64. [Crossref] , [Web of Science ®]   [Google Scholar] ). In doing so offsetting “… actually plays into the hands of an environmentally destructive industry by allowing it to legitimate its practices while simultaneously absolving itself from responsibility for the environmental destruction from which it profits” (Young et al., 2014 Young, M., Higham, J.E.S., & Reis, A. (2014). Up in the air: A conceptual critique of flying addiction. Annals of Tourism Research, 41, 51–64. [Crossref] , [Web of Science ®]   [Google Scholar] , p. 52). This absolution of individual responsibility is an important factor in the accelerating aviation emissions problem (Creutzig et al., 2015 Creutzig, F., Jochem, P., Edelenbosch, O.Y., Mattauch, L., van Vuuren, D.P., McCollum, D., & Minx, J. (2015). Transport: A roadblock to climate change mitigation? Science, 350(6263), 911–912. [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] ). It relates closely to what Hall ( 2013 Hall, C.M. (2013). Framing behavioural approaches to understanding and governing sustainable tourism consumption: Beyond neoliberalism, ‘nudging’ and ‘green growth’? Journal of Sustainable Tourism, 21(7), 1091–1109. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ) refers to as “structures of provision”; the social and institutional structures that underpin unsustainable consumption practices. Expecting the consumer to accept responsibility and respond individually to unsustainable contemporary travel mobilities, in the absence of meaningful industry and policy responses, has proven to be futile (Higham et al., 2016 Higham, J.E.S., Cohen, S.A., Cavaliere, C.T., Reis, A.C., & Finkler, W. (2016). Climate change, tourist air travel and radical emissions reduction. Journal of Cleaner Production, 111, 336–347. [Crossref] , [Web of Science ®]   [Google Scholar] ).\nTechnology myths\nA further vital reason why there is inertia in policy responses to growing aviation emissions is the ongoing industry-led myth, perpetuated by the media and transport policy-makers, that decarbonisation is in progress using radical technological innovation. Gotesky ( 1952 Gotesky, R. (1952). The nature of myth and society. American Anthropologist, 54(4), 523–531. [Crossref] , [Web of Science ®]   [Google Scholar] , p. 530) describes the function of a myth as to “preserve institutions and institutional process”. A “myth” is defined as an idea, story or narrative believed by many people, including decision-makers, even though unfounded or false. As Edelman ( 1998 Edelman, M. (1998). Language, myths and rhetoric. Society, 35(2), 131–139. [Crossref] , [Web of Science ®]   [Google Scholar] , p. 131) reminds us, “[p]olitical language can evoke a set of mythic beliefs in subtle and powerful ways.” Misleading information from the transport and tourism sectors is not new. Gössling and Peeters ( 2007 Gössling, S., Broderick, J., Upham, P., Peeters, P., Strasdas, W., Ceron, J.-P., & Dubois, G. (2007). Voluntary carbon offsetting schemes for aviation: Efficiency and credibility. Journal of Sustainable Tourism, 15(3), 223–248. [Taylor & Francis Online]   [Google Scholar] , p. 402), found four major industry discourses: “air travel is energy efficient; air travel's share of total emissions is negligible; fuel use is constantly minimised and new technology will solve the problem.” All four were deconstructed as being not representative of reality. This section explores the existence and role of “technology myths” in the discourse of sustainable aviation.\nMyths also play a role in other transport modes. Within automobility, for instance, Volkswagen created a green myth around low-emission diesel cars, even though this was largely based on cheating regulations (Franco, Sánchez, German, & Mock, 2014 Franco, V., Sánchez, F.P., German, J., & Mock, P. (2014). Real-world exhaust emissions from modern diesel cars. Berlin: International Council on Clean Transportation Europe.  [Google Scholar] ). So why concentrate on aviation within the domain of sustainable tourism? First because the tourism sector is a central part of passenger aviation, although we cannot be sure exactly how central it is: leisure travel is interlinked with business travel, visiting friends and relatives and other visit motivations. The tourism sector consequently needs to be seen as integral to air transport; the tourism industry cannot be absolved of responsibility for aviation emissions more generally.\nThe second reason is that air transport, though a relatively small part of tourism in terms of total trips (19% in 2010), represents a high share (52% in 2010) of tourism's global emissions, a share that is growing (62% in 2015), which means that aviation's emissions are increasing faster than those of accommodation, car and rail (Gössling & Peeters, 2015 Gössling, S., & Peeters, P. (2015). Assessing tourism's global environmental impact 1900–2050. Journal of Sustainable Tourism, 23(5), 639–659. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ). There is a large body of literature showing that future emissions of aviation are growing fast and that this growth is inevitable given transport volume growth projections (Mayor & Tol, 2010 Mayor, K., & Tol, R.S.J. (2010). Scenarios of carbon dioxide emissions from aviation. Global Environmental Change, 20(1), 65–73. [Crossref] , [Web of Science ®]   [Google Scholar] ; Owen, Lee, & Lim, 2010 Owen, B., Lee, D.S., & Lim, L. (2010). Flying into the future: Aviation emissions scenarios to 2050. Environmental Science & Technology, 44(7), 2255–2260. [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] ; Peeters & Dubois, 2010 Peeters, P., & Dubois, G. (2010). Tourism travel under climate change mitigation constraints. Journal of Transport Geography, 18(3), 447–457. [Crossref] , [Web of Science ®]   [Google Scholar] ; Sgouridis, Bonnefoy, & Hansman, 2010 Sgouridis, S., Bonnefoy, P.A., & Hansman, R.J. (2010). Air transportation in a carbon constrained world: Long-term dynamics of policies and strategies for mitigating the carbon footprint of commercial aviation. Transportation Research Part A: Policy and Practice, 45(10), 1077–1091. [Crossref] , [Web of Science ®]   [Google Scholar] ; Vorster, Ungerer, & Volschenk, 2012 Vorster, S., Ungerer, M., & Volschenk, J. (2012). 2050 scenarios for long-haul tourism in the evolving global climate change regime. Sustainability, 5(1), 1–51. [Crossref] , [Web of Science ®]   [Google Scholar] ).\nFrom a recent study (Peeters et al., under review) Peeters, P., Higham, J.E.S., Kutzner, D., Cohen, S., & Gössling, S. Are technology myths stalling aviation climate policy? Transportation Research Part D: Transport and Environment, under review. [Web of Science ®]   [Google Scholar] it was found that the aviation industry creates “technology myths” that may hamper political initiatives that would enforce mitigation on the aviation sector. Industry commonly wields terms such as “efficiency”, “constantly minimised” or “negligible shares” as discursive devices to perpetuate the myth that technological innovation will neutralise the problem of aviation emissions. Technology myths were identified by Peeters et al. ( under review Peeters, P., Higham, J.E.S., Kutzner, D., Cohen, S., & Gössling, S. Are technology myths stalling aviation climate policy? Transportation Research Part D: Transport and Environment, under review. [Web of Science ®]   [Google Scholar] ) for airframe design (laminar flow, composite structures and blended wing body), engines/propulsion (solar flight, electric flight and propfan) and alternative fuels (Jatropha, animal fats, hydrogen and micro-algae). For these 10 technologies media coverage in newspapers was measured over the past two decades and content analysed.\nLaminar flow and composite structures are widely applied already, with the newest types of planes, like the Boeing B787 and Airbus A350, using, for instance, composites in up to 50% of the construction by weight (Lee, 2010 Lee, J.J. (2010). Can we accelerate the improvement of energy efficiency in aircraft systems? Energy Conversion and Management, 51(1), 189–196. [Crossref] , [Web of Science ®]   [Google Scholar] ). But composite structures allow for weight savings of between 14% and 25% (Raymer et al., 2011 Raymer, D.P., Wilson, J., Perkins, H.D., Rizzi, A., Zhang, M., & Puentes, A.R. (2011). Advanced technology subsonic transport study n+3 technologies and design concepts (No. NASA/TM-2011-217130). Cleveland, OH: Glenn Research Center.  [Google Scholar] ) for the structure to which it is applied. So overall weight reduction of the Boeing B787 would be between 7% and 13%. The impact of this weight savings on fuel efficiency depends on how the designer uses the gains, but it may translate in the end to an approximate 5% fuel efficiency improvement (Peeters, 2000 Peeters, P., & Dubois, G. (2010). Tourism travel under climate change mitigation constraints. Journal of Transport Geography, 18(3), 447–457. [Crossref] , [Web of Science ®]   [Google Scholar] ). This Boeing 787 example clearly shows the strength of myths: the impressive 50% share of new materials is hyped in the media to a lay audience and impressed upon politicians, even though composite structures only offer small and evolutionary efficiency improvements, although coupled with improved engine design and materials, the Boeing 787 and Airbus A350 can offer fuel savings of up to 25% per seat mile over the 15–20 year old aircraft that they are replacing. The latter is an impressive figure, but it also means that fares can be reduced, encouraging more people to travel.\nBlended wing body aircraft have a long history of promises but have never emerged and are unlikely to in the near to mid-term future, or even later. Solar flight has recently attracted much attention. Basic physics tells us that it will never play a serious transport role (Noth, 2008 Noth, A. (2008). Design of solar powered airplanes for continuous flight (Unpublished PhD). ETH Zürich.  [Google Scholar] ), but the ICAO ( 2014 ICAO. (2014). 2013 environmental report. Destination green. Montreal: Author.  [Google Scholar] , p. 12) propagates discourses suggesting that it could solve environmental problems: “the Solar Impulse demonstrated that a solar-powered airplane can fly day and night without fuel.” Public interest in electric flight has followed the same strong rise since the mid-2000s. The main issue with electric flight is the requirement for high performance batteries. Current lithium batteries have a power density that falls short of the requirements for full electric flight by a factor of 100 (Kivits, Charles, & Ryan, 2010 Kivits, R., Charles, M.B., & Ryan, N. (2010). A post-carbon aviation future: Airports and the transition to a cleaner aviation sector. Futures, 42, 199–211. [Crossref] , [Web of Science ®]   [Google Scholar] ). This makes the anticipated 2035 realisation of electric flight (The Australian, 2/11/2012), extremely unlikely.\nOf the four alternative fuels, Jatropha, animal fats and hydrogen were hyped by the media between 2008 and 2011 but are now little mentioned, with significant interest only in micro-algae. Still the sector widely cites alternative fuels as promising future replacements for fossil fuels (Air Transport Action Group [ATAG], 2011 Air Transport Action Group (ATAG). (2011). Powering the future of flight. The six easy steps to growing a viable aviation biofuels industry. Geneva: Author.  [Google Scholar] ; Airbus, 2011 Airbus. (2011). Delivering the future. Global market forecast 2011–2030. Paris: Author.  [Google Scholar] ; Boeing, 2012 Boeing. (2012). Current market outlook 2012-2031. Seattle, WA. Boeing Commercial Airplanes.  [Google Scholar] ; IATA, 2012 IATA. (2012). A global approach to reducing aviation emissions. First stop: Carbon-neutral growth from 2020. Montreal: Author.  [Google Scholar] ; ICAO, 2014 ICAO. (2014). 2013 environmental report. Destination green. Montreal: Author.  [Google Scholar] ; WTTC, 2009 WTTC. (2009). Leading the challenge on climate change. London: Author.  [Google Scholar] ). Jatropha faces issues of high water use (Rosillo-Calle, Thrän, Seiffert, & Teelucksingh, 2012 Rosillo-Calle, F., Thrän, D., Seiffert, M., & Teelucksingh, S. (2012). The potential role of biofuels in commercial air transport – biojetfuel. London: IEA Bioenergy Task 40 Sustainable International Bioenergy Trade.  [Google Scholar] ) and adverse socio-economic impacts (Ariza-Montobbio & Lele, 2010 Ariza-Montobbio, P., & Lele, S. (2010). Jatropha plantations for biodiesel in Tamil Nadu, India: Viability, livelihood trade-offs, and latent conflict. Ecological Economics, 70, 189–195. [Crossref] , [Web of Science ®]   [Google Scholar] ); animal fats face technical problems preventing them from being mixed at higher than 20% shares with kerosene (Vera-Morales & Schäfer, 2009 Vera-Morales, M., & Schäfer, A. (2009). Fuel-cycle assessment of alternative aviation fuels. Cambridge: Omega.  [Google Scholar] ); hydrogen is an old but unresolved idea (Brewer, 1991 Brewer, G.D. (1991). Hydrogen aircraft technology. London: CRC Press.  [Google Scholar] ); micro-algae suffer from land-use issues, at least in the European region (Skarka, 2012 Skarka, J. (2012). Microalgae biomass potential in Europe land availability as a key issue. Technikfolgenabschätzung – Theorie und Praxis, 21, 72–79.  [Google Scholar] ), and water use, low or negative life cycle CO2 emission reductions (Quinn & Davis, 2014 Quinn, J.C., & Davis, R. (2014). The potentials and challenges of algae based biofuels: A review of the techno-economic, life cycle, and resource assessment modeling. Bioresource Technology, 184, 444–452. [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] ), cost and more profitable alternative land uses (Coplin, 2012 Coplin, L.G. (2012). Sustainable development of algal biofuels in the United States. Washington, DC: National Academies Press.  [Google Scholar] ).\nPolicy-makers are required to make decisions that often have long-term effects and are clouded in uncertainties. The quality of such decision-making for the transport sector is significantly degraded by technology myths created by industry and perpetuated through the media (Peeters et al., under review Peeters, P., Higham, J.E.S., Kutzner, D., Cohen, S., & Gössling, S. Are technology myths stalling aviation climate policy? Transportation Research Part D: Transport and Environment, under review. [Web of Science ®]   [Google Scholar] ). Such myths foster political inertia in the development of effective sustainable transport policy measures, discouraging potentially difficult but necessary decisions (Peeters, Gössling, & Lane, 2009 Peeters, P., Gössling, S., & Lane, B. (2009). Moving towards low-carbon tourism. New opportunities for destinations and tour operators. In S. Gössling, C.M. Hall, & D.B. Weaver (Eds.), Sustainable tourism futures. Perspectives on systems, restructuring and innovations (pp. 240–257). New York, NY: Routledge.  [Google Scholar] ).\nTransport taboos\nThe final major theme we discuss in this section of paper is the notion of “taboo” issues in tourism and transport policy-making. The question of why politicians have not acted in more significant ways on climate change mitigation in these sectors, as well as more generally, given that sound evidence of climate change was presented 25 years ago in the Intergovernmental Panel on Climate Change first assessment report (IPCC, 1990 IPCC. (1990). IPCC first assessment report 1990. Cambridge: Cambridge University Press.  [Google Scholar] ), is itself a relatively underexplored area of research. The adverse consequences of climate change for ecosystems and humans have since been confirmed and well documented (IPCC, 2014 IPCC. (2014). Climate change 2014: Synthesis report. Contribution of Working Groups 1, 2, and 3 to the fifth assessment report of the Intergovernmental Panel on Climate Change. Cambridge: Cambridge University Press.  [Google Scholar] ), and climate change is no longer considered a future phenomenon but rather a current and ongoing process, as, for instance, recognised by reinsurers (Munich Re, 2014 Munich Re. (2014). Overall picture of natural catastrophes in 2013 dominated by weather extremes in Europe and Supertyphoon Haiyan. Retrieved 8 January 2015 from http://www.munichre.com/en/media_relations/press_releases/2014/2014_01_07_press_release.aspx   [Google Scholar] ). As an outcome of the IPCC reports, political consensus has been achieved to stabilise greenhouse gas emissions at a level that will prevent global warming from exceeding 2 °C compared to pre-industrial temperatures, an objective confirmed during various Conferences of Parties (UNFCCC, 2014 UNFCCC. (2014). Various documents. Retrieved 17 July 2015 from www.unfccc.int   [Google Scholar] ) and recently recognised at the landmark Paris Agreement (Scott, 2016 Scott, D. (2016). The Paris Climate Change Conference and the tourism industry. Journal of Sustainable Tourism, under review  [Google Scholar] ).\nFor the transport sector, responsible for about 25% of global emissions, the European Commission (EC) has outlined emission reduction goals of -60% by 2050 compared to 1990, with an interim goal of -20% by 2030 compared to 2008 (EC, 2011 European Commission (EC). (2011). White paper: Roadmap to a single European transport area – towards a competitive and resource efficient transport system. COM(2011) 144 final. Brussels: Author.  [Google Scholar] ). These emission reductions are considered in line with the 2 °C guardrail. Yet, while climate policy objectives have been defined for the EU, and while these could also be defined for any country based on national greenhouse gas inventories, there is limited evidence of transport policies that would help to achieve such significant emission reductions, and, controversially, the EC has even outlined that curbing mobility is not considered a viable option (EC, 2011 European Commission (EC). (2011). White paper: Roadmap to a single European transport area – towards a competitive and resource efficient transport system. COM(2011) 144 final. Brussels: Author.  [Google Scholar] ). In countries and regions outside Europe, and specifically for international aviation as a significant sub-sector of tourism, transport-related mitigation policies have thus remained insignificant (Gössling, Scott, & Hall, 2013 Gössling, S., Scott, D., & Hall, C.M. (2013). Challenges of tourism in a low-carbon economy. Wiley Interdisciplinary Reviews: Climate Change, 4(6), 525–538. [Crossref] , [Web of Science ®]   [Google Scholar] ).\nYet, if energy-intense forms of mobility do not decline, it is highly unlikely that absolute reductions in greenhouse gas emissions can be achieved (Anable, Brand, Tran, & Eyre, 2012 Anable, J., Brand, C., Tran, M., & Eyre, N. (2012). Modelling transport energy demand: A socio-technical approach. Energy Policy, 41, 125–138. [Crossref] , [Web of Science ®]   [Google Scholar] ; Banister, 2008 Banister, D. (2008). The sustainable mobility paradigm. Transportation Policy, 15(1), 73–80. [Crossref] , [Web of Science ®]   [Google Scholar] , 2011 Banister, D. (2011). Cities, mobility and climate change. Journal of Transport Geography, 19(6), 1538–1546. [Crossref] , [Web of Science ®]   [Google Scholar] ; Chapman, 2007 Chapman, L. (2007). Transport and climate change: A review. Journal of Transport Geography, 15(5), 354–367. [Crossref] , [Web of Science ®]   [Google Scholar] ; IEA, 2012 IEA. (2012). World energy outlook 2011. Paris: Author.  [Google Scholar] ; Schäfer et al., 2009 Schäfer, A., Heywood, J.B., Jacoby, H.D., & Waitz, I.A., (2009). Transportation in a climate-constrained world. Cambridge, MA: MIT Press.  [Google Scholar] ; UNWTO, UNEP, & WMO, 2008 UNWTO, UNEP, & WMO. (2008). Climate change and tourism: Responding to global challenges. Madrid, Paris & Geneva: UNWTO, UNEP & WMO.  [Google Scholar] ). This has resulted in a situation where there are clear policy goals, and a wide range of market-based, command-and-control and soft policy measures available to achieve these goals (e.g. Friman, Larhult, & Gärling, 2012 Friman, M., Larhult, L., & Gärling, T. (2012). An analysis of soft transport policy measures implemented in Sweden to reduce private car use. Transportation, 40(1), 109–129. [Crossref] , [Web of Science ®]   [Google Scholar] ; OECD & UNEP, 2011 OECD & UNEP. (2011). Climate change and tourism policy in OECD countries. Paris: Author.  [Google Scholar] ; Sterner, 2007 Sterner, T. (2007). Fuel taxes: An important instrument for climate policy. Energy Policy, 35, 3194–3202. [Crossref] , [Web of Science ®]   [Google Scholar] ), but a dearth of implementation, with evidence that only soft policies focusing on voluntary behavioural change appear to be considered politically viable to reduce emissions from transportation. This paradox has been described as an “implementation gap” (Banister & Hickman, 2013 Banister, D., & Hickman, R. (2013). Transport futures: Thinking the unthinkable. Transportation Policy, 29, 283–293. [Crossref] , [Web of Science ®]   [Google Scholar] , p. 292), and led to growing academic interest in barriers to significant climate policy.\nVarious explanations have been provided to explain why governments have been reluctant to implement policies. From a governance viewpoint, Rietveld et al. ( 2005 Rietveld, P., & Stough, R. (Eds.). 2005. Barriers to sustainable transport: Institutions, regulation and sustainability. Abingdon: Spon Press.  [Google Scholar] ) have suggested that institutions rule and structure public and private actions, and that these can be informal, formal, governance-, and resource allocation/employment related. Informal institutions would comprise values, norms, practices, habits and traditions, and are considered conditioners of behaviour (see Schwanen & Lucas, 2011 Schwanen, T., & Lucas, K. (2011). Understanding auto motives. In K. Lucas, E. Blumenberg, & R. Weinberger (Eds.), Auto motives: Understanding car use behaviours. (pp. 3–38). Emerald: Bingley. [Crossref]   [Google Scholar] in the context of automobility). Formal institutions include “codified statutes, constitutions, provisions, laws, regulations, and high level administrative orders” (Rietveld et al., 2005 Rietveld, P., & Stough, R. (Eds.). 2005. Barriers to sustainable transport: Institutions, regulation and sustainability. Abingdon: Spon Press.  [Google Scholar] , p. 3). Governance institutions are a third type of institution focused on rules, including laws, regulations and policy directives, such as planning and zoning issues, or transactions involving actors and agents. Finally, resource allocation refers to government agencies, firms and non-profit associations allocating financial resources. These four categories can be used to identify and address barriers from various viewpoints, including, for instance, the notion that transport planning cannot be questioned, as transportation is important for society and economic growth. This has, for instance, been discussed by Miciukiewicz and Vigar ( 2012 Miciukiewicz, K., & Vigar, G. (2012). Mobility and social cohesion in the splintered city: Challenging technocentric transport research and policy-making practices. Urban Studies, 49(9), 1941–1957. [Crossref] , [Web of Science ®]   [Google Scholar] ) in terms of technological fixation among transport researchers and subsequent technocentric policy-making. In a similar vein, Hutton ( 2013 Hutton, B. (2013). Planning sustainable transport. London: Routledge.  [Google Scholar] ) describes how the turn from meeting predicted transport growth to managing transport demand has only recently been considered in UK transport policy. Ultimately, “barriers” thus often resemble embedded beliefs of ecological modernisation, i.e. the assumption that transport growth can be balanced environmentally, based on technological progress, as also evident in UNEP's ( 2011 UNEP. (2011). Towards a green economy: Pathways to sustainable development and poverty eradication. Retrieved 29 September 2015 from www.unep.org/greeneconomy   [Google Scholar] ) Green Growth focus, which may be seen as another ecological modernisation paradigm without real-world implications for emission growth (Hall, 2009 Hall, C.M. (2009). Degrowing tourism: Décroissance, sustainable consumption and steady-state tourism. Anatolia: An International Journal of Tourism and Hospitality Research, 20(1), 46–61. [Taylor & Francis Online]   [Google Scholar] , 2013 Hall, C.M. (2013). Framing behavioural approaches to understanding and governing sustainable tourism consumption: Beyond neoliberalism, ‘nudging’ and ‘green growth’? Journal of Sustainable Tourism, 21(7), 1091–1109. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] , 2015 Hall, C.M. (2015). Economic greenwash: On the absurdity of tourism and green growth. In M.V. Reddy & K. Wilkes (Eds.), Tourism in the green economy. (pp. 339–358). London: Earthscan by Routledge.  [Google Scholar] ).\nNew understandings of the reasons for inaction on climate change in transport contexts are thus required: “barriers” were discussed with regard to their cognitive and affective dimensions during the Freiburg 2014 workshop, where they were framed as “taboos” (Gössling & Cohen, 2014 Gössling, S., & Cohen, S. (2014). Why sustainable transport policies will fail: European Union climate policy in the light of transport taboos. Journal of Transport Geography, 39, 197–207. [Crossref] , [Web of Science ®]   [Google Scholar] ). Taboos are different from barriers of implementation, because they cannot be addressed politically without considerable (political) danger to the person taking up a given issue. To touch a taboo implies to violate an existing norm, i.e. a situation that is usually in the interest of powerful individuals, (lobby) organisations, or the broader public or community. A “transport taboo” thus describes an issue that cannot be raised without risks, possibly jeopardising the political future of any person raising the taboo. A wide range of transport taboos that politicians are unwilling to touch has been identified, such as the watering down of transport policy by lobbyism, the skewed share of transport emissions contributed by higher income classes and the broader societal glamorisation of high-energy transport consumption (Cohen & Gössling, 2015 Cohen, S.A., & Gössling, S. (2015). A darker side of hypermobility. Environment and Planning A, 47, 1661–1679. [Crossref] , [Web of Science ®]   [Google Scholar] ; for further details on transport taboos see Gössling & Cohen, 2014 Gössling, S., & Cohen, S. (2014). Why sustainable transport policies will fail: European Union climate policy in the light of transport taboos. Journal of Transport Geography, 39, 197–207. [Crossref] , [Web of Science ®]   [Google Scholar] ).\nTransport taboos are consequently issues that would appear obvious, as some solutions are ready at hand, demanding political action; yet, they are characterised by silence. A further example may be the 20 years of OECD reports recommending to remove fossil fuel subsidies, and to introduce carbon pricing ( 1991 OECD. (1991). Energy prices, taxes and carbon dioxide emissions (OECD economic studies 17). Paris: Author.  [Google Scholar] , 1999 OECD. (1999). Project on environmentally sustainable transport (EST) (Report NV/EPOC/PPC/T(99)3/FINAL/REV1). Paris: Author.  [Google Scholar] , 2008, 2015 OECD. (2015). OECD companion to the inventory of support measures for fossil fuels 2015. Retrieved 12 November 2015 from http://www.keepeek.com/Digital-Asset-Management/oecd/energy/oecd-companion-to-the-inventory-of-support-measures-for-fossil-fuels-2015_9789264239616-en#page1   [Google Scholar] ). However, the issue remains politically untouched, because this would lead to outrage by industry associations, who are powerful agents in public discourse. Yet, overcoming taboos is essential if more sustainable tourism and transport policies are to be implemented, specifically regarding climate change. At the very least, this would require political parties to stop using public sentiment to undermine sustainable transport policy initiatives by political opponents in order to gain votes on less popular measures related to climate change mitigation.\nThe papers in this special issue\nThis special issue presents nine further papers that explore avenues for behaviour change by various stakeholders in tourism and transport in order to bridge the science–policy gap in sustainable mobility. The contributions cover a wide spectrum of interests and stakeholders, and connect in various ways to the themes discussed above, notably socio-technical factors and transport taboos.\nThe first three papers investigate the role of researchers in the sustainable mobility debate, and their capacities and shortcomings to contribute to behaviour change. Hall ( in press Hall, C.M. (in press). Intervening in academic interventions: Using the lens of social marketing to examine the potential for successful sustainable tourism behavioural change. Journal of Sustainable Tourism, DOI: 10.1080/09669582.2015.1088861. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ) does this by employing social marketing themes. He questions both the theoretical knowledge base of sustainable tourism and the positioning of sustainability within the wider (tourism) literature, noting that, despite a growing body of research on sustainable tourism and mobilities, concern about these topics in tourism research is still minor, particularly in popular areas such as achieving growth in visitor numbers and expenditure. Substantive change is not evident in most destinations, or among organisations that have adopted sustainable tourism. As a way forward, Hall discusses the need for more advocacy- and participatory-based approaches so that scientists can better communicate with policy-makers and work collaboratively/co-productively with them and other upstream stakeholders. Downstream and (more activist and interventionist) upstream social marketing to the public, taking in the lessons learned from other disciplines and debates (such as that on anti-smoking), may (re)glamorise/make fashionable forms of more sustainable tourism or encourage more conventional but low transport intensity local tourism.\nMelissen and Koens ( in press Melissen, F., & Koens, K. (in press). Adding researchers' behaviour to the research agenda: Bridging the science–policy gap in sustainable tourism mobility. Journal of Sustainable Tourism, DOI: 10.1080/09669582.2015.1071384 [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ) echo Hall, arguing that researchers should not only focus on understanding the structures behind tourist behaviour, but also on how to mobilise policy and business stakeholders to contribute to the sustainable development of tourism. They find several factors or tensions (Jones, Jones, & Walsh, 2008 Jones, N., Jones, H., & Walsh, C. (2008). Political science? Strengthening science-policy dialogue in developing countries. London: Overseas Development Institute.  [Google Scholar] ) hindering researcher behaviour change towards bridging the science–policy gap in sustainable tourism mobility, and make a case for adding researchers' behaviour to the corresponding research agenda. Researchers may need to position themselves closer to the policy arena, without politicising science or moving from engaged to activist research.\nMounting sustainable tourism and transport advocacy will also lead to more attention to the environmental sustainability imperatives of researchers themselves, and the institutions for which they work. Thus the paper by Hopkins, Higham, Tapp, and Duncan ( in press Hopkins, D., Higham, J., Tapp, S., & Duncan, T. (in press). Academic mobility in the Anthropocene era: A comparative study of university policy at three New Zealand institutions. Journal of Sustainable Tourism, DOI: 10.1080/09669582.2015.1071383 [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ) in this issue links to the transport taboo of questioning academic mobility and associated carbon emissions. Set in a New Zealand university context it investigates the perceived lock-in of academic performance being dependent on, or equal to, international mobility. This can be linked back to the pioneering work of the late Karl Georg Høyer (Høyer, 2000 Høyer, K.G. (2000). Sustainable tourism – or sustainable mobility? Journal of Sustainable Tourism, 8(2), 147–161. [Taylor & Francis Online]   [Google Scholar] ; Høyer & Næss, 2001 Høyer, K.G., & Næss, P. (2001). Conference tourism: A problem for the environment as well as for research? Journal of Sustainable Tourism, 9(6), 451–470. [Taylor & Francis Online]   [Google Scholar] ). The authors find academic travel to be embedded in university policy, for example through international partnerships, the need to present research at international conferences and recruitment processes. Acknowledging New Zealand's particular geographical location, they still recommend that academic institutions consider and address the carbon emissions related to academic mobility, and to integrate sustainability more systematically into university (travel) policy.\nAnother highly mobile group possibly caught in a (socio-cultural) lock-in of flight-dependent practices is that of the younger generation in many western countries taking a gap year. Luzecka ( in press Luzecka, P. (in press). “Take a gap year!” A social practice perspective on air travel and potential transitions towards sustainable tourism mobility. Journal of Sustainable Tourism, DOI: 10.1080/09669582.2015.1115513 [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ) explores ways in which conventions related to “appropriate” gap year destinations are developed, sustained and reproduced. Numerous social mechanisms were found to facilitate overseas travel in the context of gap years, including a shared perception of difference and physical distance, which links personal development to the challenges of distant countries. This paper highlights the fact that some long-haul destinations are actually easier or cheaper to travel to than more nearby destinations. Luzecka warns that widening participation in gap year travel may further the normalisation – and psychological lock-in – of long-haul travel. The length of gap years would make them suitable for slow, and potentially more sustainable, travel, but for such a sustainable mobility transition, the socio-cultural forces that shape current gap year practices need to be taken into account.\nThe two following papers acknowledge the reality of consumers not accepting responsibility and responding to unsustainable travel mobilities, and seek ways to influence consumer decision-making through the provision of carbon information with travel products. Araña and León ( in press Araña, J.E., & León, C.J. (in press). Are tourists animal spirits? Evidence from a field experiment exploring the use of non-market based interventions advocating sustainable tourism. Journal of Sustainable Tourism, DOI: 10.1080/09669582.2015.1101128 [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ) experiment with the role of emotions and time pressure in decision-making, hypothesising that many traveller decisions are of an experiential nature. In a Spanish social tourism programme setting, they carried out a field experiment in which they manipulate the choice context of travellers, when deciding where to travel. Travel plans involved different levels of CO2 emissions, contexts about the emotional state, and decision time. Araña and León find that emotional states and the decision context can indeed affect the sustainability of travel choices. These findings have several implications for pro-environmental behaviour policies and campaigns in tourism and the effectiveness of tax incentives. Subjects showing more empathy with future generations are more likely to accept low-carbon travel options.\nEijgelaar, Nawijn, Barten, Okuhn, and Dijkstra ( in press Eijgelaar, E., Nawijn, J., Barten, C., Okuhn, L., & Dijkstra, L. (in press). Consumer attitudes and preferences on holiday carbon footprint information in the Netherlands. Journal of Sustainable Tourism, DOI: 10.1080/09669582.2015.1101129 [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ) investigate carbon labels, as a soft measure towards more sustainable travel choices that is more likely to receive industry acceptance than direct volume-reducing measures. Their case is linked to the desire of Dutch tour operators to offer such a label. Hence, they explore preferences for carbon label design in tourism. The authors tested label designs in a number of consecutive research phases under Dutch consumers. They find a number of preconditions for a tourism carbon label: it should be simple in design and connect to existing well-known EU labels for energy efficiency. But at the same time they note that sustainability is still of low priority during holiday decision-making.\nAn interesting case in science–policy interaction is Antarctica, as the continent is not controlled by a state, but through a 29-party governance regime, the Antarctic Treaty System. As little progress was made on tourism issues through the Treaty's meetings, the International Association of Antarctica Tour Operators filled this gap by self-regulating Antarctic tourism. However, their capability to self-regulate is increasingly questioned. Student, Lamers, and Amelung ( in press Student, J., Lamers, M., & Amelung, B. (in press). Towards a tipping point? Exploring the capacity to self-regulate Antarctic tourism using agent-based modelling. Journal of Sustainable Tourism, DOI: 10.1080/09669582.2015.1107079 [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ) apply agent-based modelling (ABM) to identify the challenges for the self-regulation of this carbon-intensive form of tourism. They find a number of potentially destabilising factors connected to likely future tourism development, whereby optimum group size and membership cost are crucial. More importantly, they stress the strength of ABM as a method to safely experiment with uncertainties in Antarctica, and help to provide insights for an environmentally optimised application in (sustainable Antarctic tourism) policy.\nThe final two papers investigate sustainable transport policy-making and practices at destinations. This local/regional level work reveals key aspects of the realpolitik of policy-making in ways not open to most researchers at national or international levels. Scuttari, Volgger, and Pechlaner ( in press Scuttari, A., Volgger,M., & Pechlaner, H. (in press). Transition management towards sustainable mobility in alpine destinations: Realities and realpolitik in Italy's South Tyrol region. Journal of Sustainable Tourism, DOI: 10.1080/09669582.2015.XXXXXX [Crossref] , [Web of Science ®]   [Google Scholar] ) seek ways for governing the transition towards more sustainable tourism mobility by applying a system approach. Their research in a South Tyrolean context indicates that the transition towards more sustainable transport solutions is complex and requires both public and private sector unpredictability and risk aversion to be taken into account. Scuttari et al. identify three conditions relevant to performing the transition, each one linked to a different sub-system (socio-ecological, socio-technical and governance). The transition to sustainable solutions is a complex task that can only be successful when all sub-systems – tourism, transport, governance and social-ecological – interact in informal or formal partnership. To be successful, three conditions were identified: (1) an improved understanding of what sustainable transport entails, (2) adoption of the best available technology and (3) courage and leadership to take risks with new solutions without knowing what they will bring with absolute certainty. The latter means that science should provide a better understanding of how to mitigate risk aversion or even better, how to shift the focus of risk aversion towards avoiding the risks of unsustainable development and climate change, as opposed to the risks associated with introducing, managing and using novel transport systems.\nFinally, Stanford and Guiver (in press) Stanford, D., & Guiver, J. (in press). Driving pro-environmental change in tourist destinations: Encouraging sustainable travel in national parks via partnership project creation and implementation. Journal of Sustainable Tourism, DOI: 10.1080.09669582.2015.1122018 [Web of Science ®]   [Google Scholar] explore public–private partnership led projects providing alternatives to car travel in three UK national parks as mechanisms of modal shift and pro-environmental change. They identify a number of success factors and provide practical advice on understanding and guiding future multi-partnership pro-environmental change processes in complex networks. As in the previous paper, strong local governance structures, awareness creating, trust and learning are important, and the effective communication of benefits to stakeholders appeared most significant.\nConclusions and research agenda\nThis paper has discussed three areas crucial for understanding why, despite clear scientific evidence about the growing environmental impacts of tourism transport, there is large-scale inertia in structural transitions and a lack of political willpower to enact meaningful policy change. These included the importance of addressing socio-technical factors, the barriers posed by placing faith in “technology myths” and the need to overcome “transport taboos” in policy-making. These areas shed significant light on why a science–policy gap in sustainable mobility exists, and on the issues that must be overcome if this gap is to be bridged. The societal challenge of transitioning the tourism and transport sectors to a sustainable emissions path must not be devolved entirely to the public and the marketplace, as suggested by neoliberal values. It is vital that both governments and the tourism and transport industries take a more cautious approach to the technological optimism that is fostering policy inertia: technological innovation alone will not save the day anytime soon. They must invest more in research, in operational procedures and in encouraging the development of and marketing alternatives to air travel. But most importantly, policy-makers must take a more open approach to implementing sustainable transport policies that affect the structures of provision; they will need to be lobbied to touch issues that may be politically risky, but nonetheless have been shown in other contexts to be successful in fostering desirable sustainable transport outcomes.\nBuilding on these insights, the Freiburg 2016 workshop will consequently focus on desirable transport futures, i.e. visions of desirable sustainable transport systems that have the potential to be actively taken up by wide cross sections of society (c.f. Banister & Hickman, 2013 Banister, D., & Hickman, R. (2013). Transport futures: Thinking the unthinkable. Transportation Policy, 29, 283–293. [Crossref] , [Web of Science ®]   [Google Scholar] ). A starting point for this is the analysis of sustainable transport transitions that are now underway, and the analysis of the structural, political, institutional and social/psychological factors underlying those transitions. The e-bike revolution is one example of societal change involving a low-carbon technological innovation, with uptake and adoption motivated by convenience, speed, health and cost. Many cities in Europe have re-discovered the bicycle as a transport mode with diverse benefits, and there now exists widespread and growing demand for infrastructures that facilitate cycling and other active forms of transport (Gössling & Choi, 2015 Gössling, S., & Choi, A.S. (2015). Transport transitions in Copenhagen: Comparing the cost of cars and bicycles. Ecological Economics, 113, 106–113. [Crossref] , [Web of Science ®]   [Google Scholar] ; Pucher & Buehler, 2012 Pucher, J., & Buehler, R. (2012). City cycling. Cambridge, MA: MIT Press.  [Google Scholar] ). Cycling cities have become a desirable transport future but the health and cost benefits of cycling demand that issues of cyclist safety are addressed in infrastructural provision. The rise of car sharing systems, in place of car ownership, is another timely example of a mobility transition, but is not without rebound effects, as the media suggests that it has cannibalisation effects at the expense of public transport (Schwarz, 2015 Schwarz, K. (2015, December 11). Carsharing: Wie umweltschädlich sind Car2go und Drivenow wirklich? [Carsharing: How environmentally harmful are Car2go and Drivenow actually?]. The Huffington Post (German Edition). Retrieved 1 December 2015 from http://www.huffingtonpost.de/2015/02/13/carsharing-klima-umfrage-wirtschaftswoche_n_6675908.html   [Google Scholar] ).\nIn contrast to desirable futures, while flying is highly desirable for many, continued growth in air travel on a global scale is incompatible with a sustainable transport future, and it is here that the need for urgent transition is now widely accepted. However, before entertaining alternatives to the current unsustainable transport system, it is essential to know what desirable transport futures may look like. The critical analysis of mobility transitions, including barriers confronting the achievement of desirable transport futures, is needed. A concerted research effort in the following key areas is consequently required:\nDesired transport\nFuture visions must be built upon desired transport systems. Critical examination is needed of spontaneous market uptake of desired new transport systems and their rebound effects. How have e-bike, car sharing, high-speed rail and successful public transport systems emerged in certain societies? What factors have acted as facilitators of change and how were barriers overcome? How important are individuals, i.e. specific people, in initiating change? What were the key roles of stakeholders and were low-carbon transitions an objective from the outset or a coincidental outcome? What lessons can be learned from these revolutions and what wider roles may such successes play in developing towards low-carbon transport and tourism?\nThe role of fashion\nMany trends in tourism and travel are fashion driven. Certain destinations can rise and fall substantially in a very short time. In the Netherlands long-haul travel grew rapidly until 2008 when it stabilised and started to decline. What factors influence significant changes in established patterns of consumption? Why has “environmental consciousness”, with the exception of European car purchasing, proved largely ineffective in driving low-carbon transport transitions? What potential do social marketing, celebrity endorsement and role model advocacy offer, and how can the effectiveness of these strategies be maximised? What other strategies may exist to influence and encourage the fashionability of more sustainable forms of tourism (e.g. caravanning, train journeys, “loca-tourism”, slow tourism and staycationing)? How can industry, government, the media and public organisations engage in such processes, and what in particular is the role of science and researchers?\nEconomic issues\nThe economic arguments for growth in aviation are well established, even though many assessments appear to remain partial. But what are the economic arguments that support the development of sustainable transport systems? What economic growth scenarios may be associated with low-carbon transitions to rail and electric vehicle fleets, and the new infrastructures required to facilitate active transport modes? What do economic models predict for the redistribution of travel flows under low-carbon transport scenarios? Contributions to a more complete understanding of the economics of low-carbon transport scenarios are critically important to the shift towards desired transport futures.\nPublic health and well-being\nCritical issues arise when contemplating how the sustainable transportation agenda is coupled with questions of public health and well-being. Policy outcomes driven by a public health and well-being agenda may have the potential for achieving significant environmental benefits. What potential do desirable transport futures offer to overcome personal well-being and public health risks, such as the negative health dimensions of frequent flying (Cohen & Gössling, 2015) Cohen, S.A., & Gössling, S. (2015). A darker side of hypermobility. Environment and Planning A, 47, 1661–1679. [Crossref] , [Web of Science ®]   [Google Scholar] , or the risk of pandemic associated with long-haul flights? And where mobility transitions are already in progress, can, for instance, the rising public health costs of serious injuries and deaths of cyclists be mitigated by dedicated cycle infrastructure?\nIssues of equity and ethics\nThere is a need to move beyond the Eurocentrism (c.f. Cohen & Cohen, 2015 Cohen, E., & Cohen, S.A. (2015). Beyond Eurocentrism in tourism: A paradigm shift to mobilities. Tourism Recreation Research, 40(2), 157–168. [Taylor & Francis Online]   [Google Scholar] ) that has framed debate around these issues. While the West has contributed disproportionately to the environmental crisis, emissions of unsustainable transportation are globally dispersed. Insights that are theoretically, methodologically and practically informed are required to understand sustainable transportation issues as they apply to emerging world regions (e.g. Dillimono & Dickinson, 2015 Dillimono, H.D., & Dickinson, J.E. (2015). Travel, tourism, climate change, and behavioral change: Travelers' perspectives from a developing country, Nigeria. Journal of Sustainable Tourism, 23(3), 437–454. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] on Nigerian perspectives). Growth from the middle classes in parts of Asia, Latin America, South America and Africa is also driving up global transport emissions. What equity issues arise in association with the transition from old to new transport systems? What ethical issues arise with the growth of unsustainable transportation in less developed countries? How will the continuing but declining emission footprint be distributed between countries and sectors globally? What will be the impacts of emission trading, taxation regimes, subsidies and infrastructure planning, and how will they vary between regions in light of the recent Paris Agreement?\nAdvocacy- and participatory-based approaches\nThe need exists for advocacy- and participatory-based approaches (see Bramwell, Higham, Lane, & Miller, 2016 Bramwell, B., Higham, J., Lane, B., & Miller, G. (2016). Advocacy or neutrality? Disseminating research findings and driving change toward sustainable tourism in a fast changing world. Journal of Sustainable Tourism, 24(1), 1–7. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ; Hall, in press Hall, C.M. (in press). Intervening in academic interventions: Using the lens of social marketing to examine the potential for successful sustainable tourism behavioural change. Journal of Sustainable Tourism, DOI: 10.1080/09669582.2015.1088861. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ) to enable more effective communication with policy communities, and to facilitate collaboration and co-production with policy-makers and other upstream stakeholders. What opportunities exist to implement new or underutilised methods such as simulation, serious gaming and in-depth multi-stakeholder approaches? What potential do new approaches offer to communicate the science of climate change, and internalise the challenges inherent in responding to climate change? How can new approaches serve to highlight the contribution of travel in global GHG emissions, the inherent difficulties in responding to unsustainable transportation, and potential pathways to desirable transport futures? These key areas form the basis for a continued research agenda aimed at transitioning the tourism and transport sectors to a sustainable emissions path.\nAcknowledgments\nThe convenors of the Freiburg 2014 workshop (1–4 July 2014) gratefully acknowledge the members of its Scientific Advisory Board, all of whom contributed to the success of the workshop: Dr Stewart Barr (University of Exeter, UK), Dr Jo Guiver (University of Central Lancashire, UK), Professor Michael Hall (University of Canterbury, NZ), Dr Julia Hibbert (Bournemouth University, UK), Professor Daniel Scott (University of Waterloo, Canada) and Professor David Banister (TSI, University of Oxford, UK).\nDisclosure statement\nScott A. Cohen is a reader at the University of Surrey (United Kingdom).\nJames Higham\nJames Higham is a professor at the Department of Tourism, University of Otago (New Zealand).\nStefan Gössling\nStefan Gössling is a professor at Lund University and Linnaeus University (Sweden). He is also research coordinator at the Western Norway Research Institute's Research Centre for Sustainable Tourism.\nPaul Peeters\nPaul Peeters is an associate professor at NHTV Breda University of Applied Sciences (The Netherlands).\nEke Eijgelaar\nEke Eijgelaar is a researcher at the Centre for Sustainable Tourism and Transport at NHTV Breda University for Applied Sciences (The Netherlands).\nArticle Metrics\n""","0.2631879","""http://www.tandfonline.com/doi/full/10.1080/09669582.2015.1136637""","[-0.589514,51.242722]"
"""King's_College_London""","""Efficient macroscopic urban traffic models for reducing congestion - Research Portal, King's College, London""","""Daniele Magazzeni ( Informatics , Planning )\nAbstract\nThe global growth in urbanisation increases the demand for services including road transport infrastructure, presenting challenges in terms of mobility. In this scenario, optimising the exploitation of urban road networks is a pivotal challenge. Existing urban traffic control approaches, based on complex mathematical models, can effectively deal with planned-Ahead events, but are not able to cope with unexpected situations -such as roads blocked due to car accidents or weather-related events- because of their huge computational requirements. Therefore, such unexpected situations are mainly dealt with manually, or by exploiting pre-computed policies. Our goal is to show the feasibility of using mixed discrete-continuous planning to deal with unexpected circumstances in urban traffic control. We present a PDDL+ formulation of urban traffic control, where continuous processes are used to model flows of cars, and show how planning can be used to efficiently reduce congestion of specified roads by controlling traffic light green phases. We present simulation results on two networks (one of them considers Manchester city centre) that demonstrate the effectiveness of the approach, compared with fixed-Time and reactive techniques.\n""","0.98501563","""https://kclpure.kcl.ac.uk/portal/en/publications/efficient-macroscopic-urban-traffic-models-for-reducing-congestion(7abd3cf0-9e53-43c0-8df7-22976e0738dc).html""","[-0.116938,51.510732]"
"""StaffOxfordUniversityPhysics""","""The PanCam Instrument for the ExoMars Rover""","""The PanCam Instrument for the ExoMars Rover\nTo cite this article:\nCoates A.J., Jaumann R., Griffiths A.D., Leff C.E., Schmitz N., Josset J.-L., Paar G., Gunn M., Hauber E., Cousins C.R., Cross R.E., Grindrod P., Bridges J.C., Balme M., Gupta S., Crawford I.A., Irwin P., Stabbins R., Tirsch D., Vago J.L., Theodorou T., Caballo-Perucha M., Osinski G.R., and the PanCam Team. Astrobiology.                           July 2017,                                     17(6-7): 511-541. https://doi.org/10.1089/ast.2016.1548\nPublished in Volume: 17 Issue 6-7: July 1, 2017\nOnline Ahead of Print: May 22, 2017\n1Mullard Space Science Laboratory, University College London, Dorking, UK.\n2Centre for Planetary Science at UCL/Birkbeck, London, UK.\n3Institute of Planetary Research, German Aerospace Centre (DLR), Berlin, Germany.\n4Space Exploration Institute, Neuchâtel, Switzerland.\n5Joanneum Research, Graz, Austria.\n6Department of Physics, Aberystwyth University, Aberystwyth, UK.\n7Department of Earth and Environmental Sciences, University of St Andrews, St Andrews, UK.\n8Department of Earth and Planetary Sciences, Birkbeck, University of London, London, UK.\n9Space Research Centre, University of Leicester, Leicester, UK.\n10Department of Earth Sciences, Open University, Milton Keynes, UK.\n11Department of Earth Science and Engineering, Imperial College London, London, UK.\n12Department of Physics, University of Oxford, Oxford, UK.\n13European Space Agency, Noordwijk, the Netherlands.\n14Centre for Planetary Science and Exploration, University of Western Ontario, London, Canada.\n© A.J. Coates et al., and the PanCam Team, 2017; Published by Mary Ann Liebert, Inc. This Open Access article is distributed under the terms of the Creative Commons License ( http://creativecommons.org/licenses/by/4.0 ), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly credited.\nAddress correspondence to:\nAccepted 1 November 2016\nABSTRACT\nThe scientific objectives of the ExoMars rover are designed to answer several key questions in the search for life on Mars. In particular, the unique subsurface drill will address some of these, such as the possible existence and stability of subsurface organics. PanCam will establish the surface geological and morphological context for the mission, working in collaboration with other context instruments. Here, we describe the PanCam scientific objectives in geology, atmospheric science, and 3-D vision. We discuss the design of PanCam, which includes a stereo pair of Wide Angle Cameras (WACs), each of which has an 11-position filter wheel and a High Resolution Camera (HRC) for high-resolution investigations of rock texture at a distance. The cameras and electronics are housed in an optical bench that provides the mechanical interface to the rover mast and a planetary protection barrier. The electronic interface is via the PanCam Interface Unit (PIU), and power conditioning is via a DC-DC converter. PanCam also includes a calibration target mounted on the rover deck for radiometric calibration, fiducial markers for geometric calibration, and a rover inspection mirror. Key Words: Mars—ExoMars—Instrumentation—Geology—Atmosphere—Exobiology—Context. Astrobiology 17, 511–541.\n1. Introduction\nPanCam is one of the context instruments on the ExoMars rover (Vago et al., 2017 , in this issue) and will provide images in the visible and near infrared (NIR), from which crucial observations of landscape morphology, geology, and atmospheric science may be derived. PanCam will be the prime tool to characterize the morphology and geology of rock outcrops on the martian surface and will be crucial during mission operations for geological target selection and characterization. PanCam data will support the overarching exobiological objective of ExoMars through the characterization of paleoenvironments that involved sustained liquid water at the ExoMars study site. The PanCam spectral range is extended by the Infrared Spectrometer for ExoMars (ISEM) instrument (Korablev et al., 2017 , in this issue), which will add to the mineralogical determination; as shown by Harris et al. ( 2015 ), definitive identification of unique minerals is rarely achievable with the PanCam wavelength range alone. In addition, the Close-UP Imager (CLUPI; Josset et al., 2017 , in this issue) will provide high-resolution images of potential drilling sites and other interesting samples. Subsurface context will be provided by a ground-penetrating radar (Water Ice and Subsurface Deposit Observation On Mars, WISDOM; Ciarletti et al., 2017 , in this issue) and a neutron detector (Autonomous Detector of Radiation Of Neutrons, ADRON; Mitrofanov et al. 2017 , in this issue), as well as a visible-IR spectrometer (Mars Multispectral Imager for Subsurface Studies, Ma_MISS; De Sanctis et al., 2017 , in this issue) in the drill tip to provide in situ mineralogy for the subsurface samples before they are brought to the surface. Sample analysis will be by the Analytical Laboratory Drawer (ALD) instruments, MicrOmega (Bibring et al., 2017 , in this issue), RLS (Raman spectrometer; Rull et al., 2017 , in this issue), and Mars Organic Molecule Analyser (MOMA; Goesmann et al., 2017 , in this issue).\nPanCam will be fundamental in the day-to-day scientific operations of the rover. The images and other data products will be available to the team soon after downlink to assist with scientific decisions on where to drive next, on what targets of interest geological observations should focus on, and where and which rock units ExoMars should drill. The team intends to make images available via ESA in near real time for outreach purposes as appropriate. The central role of PanCam in these activities has been shown to be vital in many field trials already (e.g., Schmitz et al., 2009 ; Steele et al., 2010 ; Gunes-Lasnet et al., 2014 ).\nIn this paper, after presenting the team organization, we discuss the PanCam scientific objectives and instrument design, and the measurement scenario, calibration, and 3-D vision aspects.\n1.1. Team organization\nThe PanCam team organization is illustrated in Fig. 1 . Mullard Space Science Laboratory (MSSL) is the principal investigator (PI) institute with overall responsibility for the instrument, supported by co-PI involvements for major hardware contributions at DLR, Germany (supported by industry, OHB), and Space-X, Switzerland (supported by industry, RUAG). In addition, there are lead-co-I roles in Austria (Joanneum Research—3-D vision team lead) and Wales (Aberystwyth University—Small Items lead). The hardware team is led by a project manager. The international science team is co-chaired by the PI and co-PIs.\nIn addition to the science team, which has association with each of the key components, co-I “swaps” have been initiated with the ISEM, WISDOM, and CLUPI teams, emphasizing and enhancing the collaborative nature of the mission.\n2. Scientific Objectives\n2.1. Contribution to overall rover mission science\nThe overall goals of the ExoMars 2020 rover (Vago et al., 2017 , in this issue) are to search for signs of past and present life on Mars and to characterize the water/geochemical environment as a function of depth in the shallow subsurface. The key new aspect of the mission is the retrieval and analysis of subsurface samples from 0 to 2 m below the oxidized surface of Mars. Rover operations include an integrated set of measurements at multiple scales: beginning with panoramic imaging and analysis of the geological context, progressing to finer-scale investigations of surface rock outcrops, and culminating with the collection of well-selected subsurface (or surface) samples to be studied in the rover's analytical laboratory.\nThe main scientific objectives of PanCam may be summarized as follows:\n(1) Provide 2-D and 3-D geological and mineralogical context information through imaging, including construction of digital terrain models (DTMs) and their visualization;\n(2) Support the selection of rover science and drilling sites by providing geological and mineralogical characterization of target rock outcrops;\n(3) Geologically investigate and map the rover science traverse and drilling sites;\n(4) Locate the landing site, the science sites, and the rover position with respect to local and global references by comparison and data fusion with data from orbiters;\n(5) Support rover traverse planning with geological context of the environment;\n(6) Image and characterize the acquired drill samples;\n(7) Study the properties of the atmosphere and variable phenomena, including water and dust content of the atmosphere.\nPanCam will determine the geological and geomorphological context for the remainder of the rover payload. A pair of Wide Angle Cameras (WACs) and a close-up High Resolution Camera (HRC) located at the top of the mast of the rover, together with geological, atmospheric, and red/green/blue filters, constitute a powerful camera system for planetary science. The WACs and HRC enable complementary imaging at different scales to obtain both wide-angle multispectral stereoscopic panoramic images and high-resolution color images. PanCam can view the lander upper surface and verify mechanism deployments and potentially the interaction of the drill and the rover wheels with the regolith. PanCam is the main ExoMars rover instrument for the remote characterization of the landing site's geological context, to provide detailed 3-D DTMs through stereo imaging and measure the surface Bidirectional Reflectance Distribution Function (BRDF).\nThe two WACs will each generate multispectral stereo images with 38.3° field of view (FOV) (horizontal/vertical), and the HRC will provide monoscopic “zoom” images with 4.88° FOV (horizontal/vertical; see Table 2 ); the combination provides morphological information on the rover surroundings. The WACs use multiple narrow-band filters to constrain the mineral composition of rocks and soils and the concentration of water vapor and the dust optical properties in the atmosphere.\nThe HRC can acquire high-resolution subset images of the wide-angle panoramas, as well as image mosaics, and furthermore enables high-resolution imaging of inaccessible locations, for example, on steep slopes such as crater or valley walls. It also allows observation of retrieved subsurface samples before ingestion into the Sample Preparation and Distribution System (SPDS) of the Pasteur payload. Combined with a Rover Inspection Mirror (RIM), placed at the front end of the rover body, engineering images of the underside of the rover chassis as well as views of the rover wheels for soil mechanics science and wheel wear can be acquired with the HRC. In addition, views of the underside of overhanging rock formations may also be acquired.\nThe wide-angle (WACs) and close-up (HRC) capability thus provides imaging at different scales, from submillimeter resolution (HRC) directly in front of the rover up to millimeter-to-meter resolution to effectively infinite distances. These properties allow the acquisition of information to support rover navigation. PanCam is the only scientific instrument on the rover that can generate detailed 3-D DTMs, slope maps, and similar products. This will be complemented by lower-resolution Navigation Camera (NavCam) data. It should be noted that NavCam has a 65° FOV with a 150 mm stereo baseline and is accommodated on the mast in front of PanCam tilted down by 18° (Silva et al., 2013 ). After a drill site has been selected, using PanCam and other context information, the instrument can also view the drill tailings and thus provide complete geological context for the subsurface samples.\n2.2. Specific scientific goals\nCamera experiments are an indispensable component of the scientific payload of any surface planetary mission, whether it is a stationary lander or a mobile rover (e.g., Bell et al., 2003; Edgett et al., 2012 ; Gunn and Cousins, 2016 ; Maki et al., 2012 ). PanCam will study the geological diversity of individual local areas along the rover traverse and will be a significant contributor to the scientific output of ExoMars, particularly to characterization of surface geology and geomorphology, atmospheric sciences, and cartography/geodesy. Importantly, analysis of PanCam imagery will guide the selection of areas and rock outcrops for more detailed analysis and provide stratigraphic context for these sites. The application of stereo imaging will significantly enhance the ability of the science team to investigate terrain and geology through 3-D vision. DTMs and the corresponding texture maps in a visualization environment will enhance the quantitative analysis of the geomorphology and geology of target areas. In the following sections, we describe in detail the scientific objectives that will be addressed by PanCam.\n2.2.1. Geology and geomorphology\nThe major objective of PanCam imaging with respect to geology and geomorphology is the identification and characterization of rock and unconsolidated surficial units on the basis of their morphology, geometry, distribution, and physical (e.g., cohesion) and spectral properties (the latter will be addressed in the next section on color investigations). Perhaps the single most important contribution of PanCam science to the mission will be to help reconstruct the geological and geomorphological history of the ExoMars study area and in particular to define the stratigraphic context. This is crucial to place sample analysis in a geological spatial and relative temporal framework. The search for biosignatures requires an understanding of the local and regional geological context (e.g., Westall et al., 2015 ), which will be interpreted mainly, but not exclusively, from imaging data. As geological context encompasses the multiscale character of natural systems, context information for planetary rover missions will not only come from in situ data obtained by rover instruments but also from remote sensing data acquired by orbiter instruments. Therefore, it will be essential to link observations at multiple scales by combining rover and orbiter data (e.g., Golombek et al., 2005 , 2008 ; Arvidson et al., 2015 ; Stack et al., 2016 ). An immediate application of such combined data analysis will be the identification of landforms visible in both PanCam and orbiter images, which is key for a precise determination of the landing site location in a global geodetic reference frame (Oberst et al., 1999a , 1999b ; Haase et al., 2012 ). Ideally, such combined analysis will benefit from simultaneous and coordinated observations between PanCam and orbiter instruments enabling cross-calibration for, for example, spectro-photometric investigations (ground truth; e.g., Lichtenberg et al., 2007 ; Hoekzema et al., 2011 ; Fernando et al., 2015 ). Importantly, the need for context information applies to all dimensions and requires 3-D products from PanCam's stereo images (e.g., DTMs) as a spatial reference for other data (e.g., WISDOM, ISEM; Paar et al., 2015 ).\nThe search for biosignatures on Mars is considered to be most promising at sites of ancient geological strata that exhibit morphological, geological, and mineralogical evidence for sustained aqueous activity (e.g., Farmer and Des Marais, 1999 ; Grotzinger et al. 2014 , 2015; Vago et al., 2015 , 2017). The final three candidate landing sites for the ExoMars rover mission (Oxia Planum, Aram Dorsum, Mawrth Vallis) are all characterized by layered deposits suggestive of aqueous activity (depositional and/or alteration) (Bridges et al., 2016a ). Spatially resolved PanCam images and 3-D data products will be essential to study their sedimentary and compositional characteristics. Imaging is necessary to establish the local and regional stratigraphy (e.g., Lewis et al., 2008 ; Edgar et al., 2012 ; Grotzinger et al., 2015 ; Stack et al., 2015 ), for identification of lithologies indicative of aqueous processes (such as the conglomerates in Gale Crater; Williams et al., 2013 ), and for analyzing key sedimentological features such as cross-stratification (Grotzinger et al., 2006 , 2015; Lamb et al., 2012 ) or clinoforms (Grotzinger et al., 2015 ). High-resolution views from the HRC will allow the examination of rock textures (e.g., Herkenhoff et al., 2008 ) and the analysis of particle shape (e.g., Szabó et al., 2015 ; Yingst et al., 2016 ) and grain size distributions (e.g., Grotzinger et al., 2015 ). Smaller grain size measurements, however, require very high image resolution and typically require a microscopic imager (e.g., Jerolmack et al., 2006 ; Edgett et al., 2015 ), and it is likely that PanCam and CLUPI will need to work jointly toward this goal. In theory, PanCam images would also help identify potential morphological biosignatures such as microbially induced sedimentary structures (Noffke, 2009 ). This task, however, will require great care, as distinguishing microbially induced sedimentary structures from abiotic features is challenging (Cady et al., 2003 ; Davies et al., 2016 ) and needs to consider different scales of observation (Ibarra and Corsetti, 2016 ).\nData products derived from PanCam stereo images will permit the quantitative analysis of geological and geomorphic features of interest. A prime example is stratal layer geometry (thickness and attitude, i.e., strike and dip), which can be determined from rover stereo data (e.g., Metz et al., 2009 ; Stack, 2015 ). At larger scales, the geometry of surfaces can be investigated by combining rover images and DTMs derived from orbiter images (e.g., erosional unconformities; Watkins et al., 2016 ). The use of 3-D data is not restricted to sedimentary rock outcrops but will support the study of all surface phenomena. For instance, it also helps to constrain eolian processes (e.g., prevailing paleo-wind directions can be reconstructed from ventifact geometry; Bridges et al., 2014 ) and quantitatively analyze volcanic landforms (Squyres et al., 2007 ; Manga et al., 2012 ). Rock populations have been studied at all previous landing sites (Golombek et al., 2012 ), and PanCam images and 3-D data will be used to characterize their properties and to constrain their provenance (Craddock and Golombek, 2016 ).\nRover images and 3-D data can also support the study of physical properties of rocks (Nahm and Schultz, 2007 ; Okubo, 2007 ) and soils, for example, by viewing the disturbance of the soil by the mechanical interaction with a robotic arm or with rover wheels (e.g., Moore et al., 1987 ; Arvidson et al., 2004 ). Rover telemetry data in combination with rover image data have been used by Arvidson ( 2015 ) and Arvidson et al. ( 2017 ) to analyze the mechanical properties of the soils traversed by the Mars Science Laboratory (MSL) rover, Curiosity.\nIn the case of ExoMars, PanCam will also image the growing accumulation of loose drill material around the borehole to examine its physical properties (e.g., the angle of repose) and mineralogical properties. Indeed, as the MSL rover has shown, the analysis of drill powders provides important information on rock properties below the ubiquitous dust layer and on the weathering profile with depth (e.g., Treiman et al., 2016 ). Importantly, PanCam multi-angle and spectral data (see below) will also enable the study of spectro-photometric properties of the traverse area (Johnson et al., 2008 , 2015 ).\n2.2.2. Rock and soil composition and mineralogy\nOne of the great successes of the Curiosity rover has been the identification of igneous rocks present as clasts from conglomerates of the fluvio-lacustrine system, for example, the Hottah Facies in Gale Crater (Williams et al., 2013 ). For instance, ChemCam compositional analyses together with complementary Mastcam, MAHLI, and ChemCam RMI imagery have shown the presence of feldspar-rich trachybasalts (Sautter et al., 2015 ; Bridges et al., 2016b ), indicating that the Gale catchment contained fractionated igneous rocks in addition to more primitive basalts. PanCam will likewise be able to reveal igneous textures and felsic/mafic mineral proportions, either within clasts in sediments or by imaging of in situ lava flows that have been hypothesized for parts of Oxia Planum (Quantin et al., 2015 ).\nA first-order assessment of the composition of surface materials, including level of oxidation, hydration, and extent of chemical alteration, will be provided by PanCam WAC and HRC color images and selected WAC multispectral data. Analysis of narrowband multispectral images using the “geology” filters ( Table 3 ) will be used to determine spectrally distinct units that can be correlated with structural features identified with WAC DTM data products (e.g., Fig. 2C ), building up a picture of sedimentary or volcanic structure, local stratigraphy, and geochemical evolution. This approach has been used previously to great effect using image data sets from the Mars Exploration Rover (MER) Pancams (e.g., Farrand et al., 2006 , 2014 ; Rice et al., 2010 ). Since the deployment of 12-band “geology” multispectral imaging on NASA Pathfinder (Smith et al., 1997 ), subsequent missions have gradually modified the distribution of their geology filters across the 440–1000 nm wavelength range (Gunn and Cousins, 2016 ). Due to the exobiology focus of the ExoMars mission, the PanCam 12-band geology filter set was redesigned for the specific purpose of detecting minerals that had formed in the presence of liquid water (e.g., clays), while maintaining the ability of PanCam to also detect Fe2+- and Fe3+-bearing mineral phases common to Mars (Cousins et al., 2010 , 2012), for which this wavelength range is most sensitive. While these modified filters cover different center wavelengths, many are within 3–9 nm of those flown on previous missions, including the 432, 535, 601, 673, 904, and 1009 nm filters on board the MSL Mastcam and MER Pancams (Anderson and Bell, 2013 ). This enables spectral observations from previous missions to be correlated with those acquired with ExoMars. Analysis of these spectral bands ( Table 1 ), together with the other data sets produced by PanCam (and IR reflectance spectra from ISEM—see Korablev et al., 2017 , in this issue), will enable the identification of evidence of the paleoenvironment's habitability (see Harris et al., 2015 ), forming a major step in deciding where to drill. The ability of PanCam multispectral data products to characterize and distinguish between different mineralogical units produced by argillic alteration of basalt was demonstrated during a field deployment of a PanCam emulator on Mars analog terrains in Iceland (Harris et al., 2015 ).\nView larger version                                     (97K)\nFIG. 2.\nPanCam data products. (A–B) Color panorama and close-up color WAC image from the SAFER campaign in Chile (Gunes-Lasnet et al., 2014 ). (C) DTM of Shaler outcrop on Mars constructed from MSL Mastcam images using the prototype 3-D vision software for PanCam. (D–E) False-color multispectral image of pillow basalt outcrop in Iceland with diagenetic mineral veins and associated HRC image (Harris et al., 2015 ).\nInformation about Downloading\nTable 1. Spectral Parameters for ExoMars PanCam\nContext information is essential for the successful interpretation of multispectral data, and other rover missions have used spatially highly resolved imaging data as context for multispectral spot observations. For example, the main camera on the MERs, Pancam (Bell et al., 2003), provided such context for observations made by the Miniature Thermal Emission Spectrometer (Mini-TES; e.g., Christensen et al., 2004 ). More recently, the ChemCam instrument on the MSL rover Curiosity was equipped with a Remote Microscopic Imager (RMI) to provide geological context for the Laser-Induced Breakdown Spectrometer (LIBS) measurements (Maurice et al., 2012 ; Le Mouélic et al., 2015 ). In the same way, PanCam's HRC will not only provide context for PanCam's WAC color images but also for the ISEM spectrometer (Korablev et al., 2017 , in this issue). To ensure a common imaging direction and accurate positioning, the optical axes of the HRC and ISEM are coaligned.\n2.2.3. Landing site investigations\nFor the 2020 ExoMars launch, the landing site will be selected from Oxia Planum and one of either Aram Dorsum or Mawrth Vallis (Bridges et al., 2016a ). There are a number of hypotheses for each of the landing sites that will be investigated with PanCam and the other instruments. The final landing ellipse dimensions and azimuths have not been firmly determined for a 2021 landing, but current planning uses a semimajor axis of 50–60 km (Bridges et al., 2016a ).\n2.2.3.1. Oxia Planum (18.14°N, 335.76°E)\nOxia Planum is thought to be a layered, clay-rich Noachian terrain at the southeastern margin of the Chryse region. A long-lived aqueous system is suggested to have existed in Oxia Planum, including the distal deposits of an early Hesperian sedimentary fan that may represent an ancient deltaic sedimentary body (Quantin et al., 2015 ). Several valley systems converge at Oxia Planum, with the proposed delta being at the outlet of Coogoon Valles (Quantin et al., 2016 ).\nIn addition, Oxia Planum has an ancient, finely layered clay-bearing unit with surfaces that have been exposed as recently as 100 Ma (Quantin et al., 2015 ). That region, in the middle and western part of the ellipse, is thought to be part of a 200 m thick phyllosilicate unit, providing primary scientific targets throughout the landing ellipse (Quantin et al., 2014 ). These deposits have similarities with other phyllosilicate deposits, such as those at Mawrth Vallis, that occur throughout the wider western Arabia Terra and Meridiani region (Noe Dobrea et al., 2010 ), suggesting that alteration processes could have been intense over this entire region (Poulet et al., 2005 ).\nThe region also includes a 20 m thick Amazonian capping unit of uncertain, but possible volcanic, origin (Quantin et al., 2014 ). The regions of the phyllosilicate unit that are closest to the capping unit have the strongest CRISM (Compact Reconnaissance Imaging Spectrometer for Mars) signatures for Fe/Mg phyllosilicates (Quantin et al., 2014 , 2015).\n2.2.3.2. Aram Dorsum (7.869°N, 348.8°E)\nAram Dorsum is part of an exhumed inverted fluvial channel system in a regional ancient alluvial landscape (Di Achille and Hynek, 2010 ; Balme et al., 2015 ; Sefton-Nash et al., 2015 ). There are Noachian-aged sedimentary rocks throughout the ellipse, providing scientific imaging targets for PanCam. The system has been exhumed from beneath mid/late Noachian-aged “etched terrains” (e.g., Hynek and Phillips, 2008 ), so the region has been protected from the martian environment for what could have been several billion years.\nAram Dorsum comprises a central inverted “trunk” fluvial channel system with smaller subsidiary channels feeding into it. Traces of buried channels can be seen at various stratigraphic levels, suggestive of a long duration of sediment aggradation (Balme et al., 2015 ; Sefton-Nash et al., 2015 ). The main trunk channel is surrounded by what are interpreted to be floodplain sedimentary deposits (Balme et al., 2014 ). The exposed region of the system is of the order of 10 km wide and 100 km long (Balme et al., 2014 ). The working hypothesis for this site is that it represents a relict aggradational alluvial system that was long-lived and involved migrating fluvial channels (Balme et al., 2014 ). Thus, it hosted a variety of alluvial depositional environments and likely comprised sedimentary rocks displaying a variety of grain sizes. The predicted long-duration nature of the system, and the potential for fine-grained alluvial sediments, makes Aram Dorsum a potentially good location for preserved biosignatures.\nAt the time of writing, there are very few CRISM images available for Aram Dorsum, with dust coverage obscuring the images that are available. However, at nearby Miyamoto Crater, Fe/Mg phyllosilicates were found on both sides of the channel (Marzo et al., 2009 ; Balme et al., 2015 ). The similarity in setting has been taken as an indication that Aram Dorsum could also contain similar phyllosilicates (Balme et al., 2015 )—again adding to the potential for biosignature preservation.\n2.2.3.3. Mawrth Vallis (22.16°N, 342.05°E)\nMawrth Vallis has abundant Fe/Mg phyllosilicates and associated layered terrains (Loizeau et al., 2010 , 2015 ). It is a well studied, mineralogically diverse site (Bishop et al., 2008 ), which together with its stratigraphy has been taken to suggest aqueous systems and a rich aqueous history (e.g., Michalski et al., 2010 ). It is predicted that biosignatures could be retained in the phyllosilicate and hydrated silica deposits, especially as there is no evidence for mixed-layer clays that would degrade the biosignatures (Poulet et al., 2014 ). In addition, the high clay content in Mawrth Vallis might allow organic preservation in paleosol paleoenvironments (Poulet et al., 2015 ). Reduced paleosols are thought to be excellent scientific targets, as reducing soils cause immediate preservation and therefore can concentrate organics (Poulet et al., 2014 ; Gross et al., 2016 ). There are clay transitions within the landing ellipse, transitioning from Fe-smectite to overlying Al-clays (kaolinite), as can be seen in CRISM images (Poulet et al., 2015 ).\nThe landing site at Mawrth Vallis is part of a large area with widespread layered deposits and evidence for draping relationships between some of them (Poulet et al., 2014 ). Erosional landforms superposed on the clay-rich succession are also present, such as channels and small capped buttes and mesas. Furthermore, as there are few “boulder-forming” units and the thermal inertia is low, it is assumed that the region is formed at least in part from fine-grained sedimentary rocks (Poulet et al., 2014 ). There is also a capping unit in Mawrth Vallis, which is thought to have buried the exobiology regions of interest. Like Aram Dorsum, these have been exhumed in geologically recent times (Poulet et al., 2015 ), which improves the biosignature preservation potential.\nGiven the three potential landing sites, the identification and measurement of sedimentary structures and determination of the sedimentary facies and stratigraphy will be an essential part of the ExoMars rover mission. Working hypotheses for the geological context will be developed—and here, PanCam's capabilities will be central—and used to interpret the paleoenvironments that the sedimentary rocks formed in. From here, the ExoMars science team will choose which locales to target and sample using the other instruments.\nThe key hypotheses and questions that PanCam will be deployed to help test and address at whichever of the landing sites is chosen are as follows:\n(I) If Oxia Planum is the site, (i) What is the nature and depositional environment of the clay-bearing units? (ii) Are the Oxia clays truly the lower members of the more varied clay sequence observed at Mawrth? Is this a major regional alteration landscape? (iii) If the rover can reach the geographically constrained fan-shaped landform, is it a delta? (iv) Is the capping unit in Oxia Planum volcanic?\n(II) (i) Is Aram Dorsum an exhumed, alluvial depositional system? (ii) If so, are fine-grained floodplain and local lacustrine deposits present? (iii) Are phyllosilicates present in the Aram Dorsum region?\n(III) (i) What are the depositional or diagenetic environments for the various clay mineral–hosting strata documented at Mawrth Vallis? (ii) Does Mawrth Vallis contain evidence for paleosols? (iii) What is the significance and nature of the transition from Fe-smectite to Al-clays?\n2.2.4. Support of exobiology\nPanCam data will support the overarching exobiological objective of ExoMars through the characterization of paleoenvironments that involved sustained liquid water at the ExoMars study site. While water alone does not ensure habitability (e.g., Knoll and Grotzinger, 2006 ; Grotzinger et al. 2014 ; Fox-Powell et al., 2016 ), it provides the basis for current exobiological exploration of Mars (Rummel et al., 2014 ). Since 2012, MSL Curiosity MastCam data have revealed evidence of fluvio-lacustrine sedimentary deposits (Grotzinger et al., 2014 , 2015) and diagenetic veins and related mineralogy (McLennan et al., 2014 ; Nachon et al., 2014 ; Bridges et al., 2015 ; Schwenzer et al., 2016 ). Critical information for construction of the stratigraphic framework of sedimentary rocks along the rover traverse and their sedimentological and paleoenvironmental interpretation has been provided by MastCam, including images of fluvial conglomerates (Williams et al., 2013 ), a variety of cross-stratification structures, fine-scale lamination indicative of lacustrine sedimentation, and sulfate and Mg-rich veins cutting though the sediments (Grotzinger et al., 2014 , 2015).\nMastCam observations have also demonstrated how large-scale stratigraphic relationships between geological units along the rover traverse can be understood within the context of CRISM mineralogical data (Seelos et al., 2014 ; Grotzinger et al., 2015 ). The role of PanCam on ExoMars will be much the same, and its combination of wide-angle, high-resolution, 3-D, and multispectral visualization ( Fig. 2 ) will enable a thorough evaluation of the geological context for both drill-site selection and subsequent interpretation of sample analyses. Specific to ExoMars is the necessity to identify those lithologies most likely to harbor evidence for organic biosignatures (Farmer and Des Marais, 1999 ; Parnell et al., 2007 ), and the degree and type of post-depositional processes that have affected them. To this end, identification of reduced, phyllosilicate-bearing sediments will be a particular priority due to the hypothesis of preferential preservation of organic matter by clay minerals (Ehlmann et al., 2008 ). PanCam (HRC and WAC) will be an important tool in this, but this will be augmented by the use of a relevant suite of spectrometers (e.g., ISEM and the Raman spectrometer). The three potential landing sites satisfy this criterion, having either spectral evidence for abundant clays (Oxia Planum, Mawrth Vallis) or geological features that suggest environments where fine-grained sediment is likely to have accumulated (Aram Dorsum).\nDetermination of the subsurface stratigraphic extent of candidate sampling strata through combining PanCam DTMs of rock outcrops with WISDOM data (Ciarletti et al., 2017 , in this issue) will also be a key input into deciding where to drill. The three landing sites are all hypothesized to contain fine-grained sedimentary rocks. Burial of such deposits is likely to have been associated with diagenesis, for example, the formation of clay and iron oxide through the dissolution of olivine, and the creation of secondary mineral veins (Léveillé et al., 2014 ; Bridges et al., 2015 ). The role of post-emplacement diagenetic processes is of particular importance given the ability of diagenetic processes either to mineralize (preserve) or destroy/displace organic biosignatures, in addition to UV and oxidative degradation of organic material (ten Kate, 2010 ). A key finding from the MSL Curiosity mission has been the prevalence of diagenetic hydrated calcium sulfate fracture-fill veins, which formed from circumneutral fluids at relatively low temperatures (<50°C) and pressures (Nachon et al., 2014 ; Schwenzer et al., 2016 ). Remote detection of deposits such as these with PanCam will be achieved through a combination of WAC multispectral (color, hydration band identification) and HRC (mineral vein morphology and crystal habits) data. Likewise, combined HRC and WAC multispectral data will also be used to detect other low-temperature secondary mineralization features that have the potential to trap organic matter during precipitation, including evaporitic salt phases, zeolite mineralization, and carbonates, which can then be corroborated with ISEM spectral data to identify and spatially extrapolate their mineralogy across a PanCam scene.\n2.2.5. Atmospheric science\nThe major changes on the martian surface that can be detected by PanCam are caused by eolian processes and condensation of volatiles, which directly reflect variations in the prevailing near-surface wind regime, and the diurnal and seasonal volatile and dust cycles. Atmospheric studies will concentrate on the detection of clouds, measurements of the aerosol contents, and the water vapor absorption at 936 nm (Titov et al., 1999 ). Although currently present at only ∼30 ppm near the surface, the atmospheric water vapor distribution is vital to understanding the water exchange with the regolith and its loss to space. It may also be affected at high altitudes by any nearby crustal magnetic fields. The abundance of water vapor in the instrument line of sight will be inferred by measuring the 936 nm absorption feature, utilizing the 925 nm (continuum) and 935 nm solar filters ( Table 3 ). By direct imaging of the setting Sun, this feature will be measured as a function of zenith angle, to probe vertical distribution in the near-surface layers. These properties of abundance and vertical profile will be retrieved with the radiative transfer and retrieval tool NEMESIS (Non-linear optimal Estimator for MultivariatE Spectral analysIS) (Irwin et al., 2008 ). NEMESIS is a versatile tool designed for application to any planet and has retrieved vertical water vapor distributions at Mars (Lolachi et al., 2007 ) as well as atmospheric properties of Titan (Teanby et al., 2007 ), Saturn (Fletcher et al., 2007 ), Jupiter (Irwin et al., 2004 ), and Venus (De Kok et al., 2011 ), for a range of viewing geometries.\nScattering by dust particles (aerosols) controls the quantity of light in the sky and its spectral distribution (Thomas et al., 1999 ). Dust particles stripped from dust layers on the ground and ice, nucleated together, are important components of the aerosol load in the atmosphere. The vertical optical depth of aerosols in the atmosphere of Mars varies strongly, depending on meteorological conditions such as temperature and atmospheric pressure. The results obtained at the MER and MSL landing sites concerning atmospheric conditions were discussed by Smith et al. ( 2006 ), Moores et al. ( 2013 ), and Webster et al. ( 2013 ). PanCam will use images of the sky observed near sunset to determine scattering properties of the dust particles via simulation with NEMESIS (Kleinböhl et al., 2011 ), in conjunction with observations from meteorology packages on the ExoMars landing platform. The coordination of multiple instrument observations of optical depth has been successful in constraining aerosol properties over previous missions (Lemmon et al., 2004 ; Wolff et al., 2006 ). The variation of scattering properties with altitude may be inferred by observing the sky after sunset, when increasingly higher levels in the atmosphere are illuminated by sunlight (Markiewicz et al., 1999 ).\nIn addition to studies of dust particles and other aerosols, lander- and rover-based cameras have been used successfully to study and monitor cloud activity on Mars (e.g., Moores et al., 2010 , 2015 ), and PanCam will continue this endeavor, including using automated techniques (e.g., Francis et al., 2014 ).\nThe observations of these atmospheric properties across the mission duration will provide temporal data, contributing to the optical depth record accumulated and reviewed by Lemmon et al. ( 2015 ). The collected observations made by the ExoMars rover, landing platform instruments, and Trace Gas Orbiter (TGO) will provide further insights into the characteristics and evolution of the martian atmosphere.\n2.3. Operational planning\nThe planning of all rover operations relies heavily on visual information provided by various camera systems (e.g., Bell et al., 2003). The ExoMars rover will have a nominal lifetime of 218 sols (approximately 7 Earth months). During this period, a total drive distance of several kilometers is expected (Vago et al., 2017 , in this issue). To plan drives and analytical campaigns, a daily process of localization and navigation planning will be necessary. This will make use of the High Resolution Imaging Science Experiment (HiRISE) on Mars Reconnaissance Orbiter in particular, and to some extent imagery from the High Resolution Stereo Camera (HRSC) on Mars Express and the Colour and Stereo Surface Imaging System (CaSSIS) on the ExoMars 2016 TGO, together with the ExoMars rover navigation and localization cameras. Complementary to the onboard guidance navigation and control (GNC, Winter et al., 2015 ), which performs relative localization in reaction to a predefined local path, absolute localization [both for strategic (daily) and tactical (longer-term) planning] will be performed in the Rover Operations and Control Center (ROCC) at the ALTEC premises in Turin. The PanCam 3-D vision workflow PRoViP (Paar et al., 2009 ; see also Section 5.3 in this paper) will be able to interpret PanCam, NavCam, and Localization Camera (LocCam) data and generate 3-D vision products (panoramas and DTMs). These data are expected to be available on a daily basis to be used for scientific planning for that sol.\nFor absolute localization, given that high-resolution satellite DTMs/ortho images in the range of 0.5 m resolution or better are available, rover DTMs are projected into an orthorectified mosaic, which uses the XYZ location of each pixel to create a true overhead view. These mosaics are then compared with orbital (e.g., HiRISE) views of the terrain to pinpoint exactly where the rover is in terms of latitude and longitude on the martian surface (Tao et al., 2016 ). A Path Planning module based on the local DTM will facilitate the long-term route planning. A traverse-monitoring map will show areas within which the rover is allowed to enter or not.\nPanCam single images, mosaics, and stereo products will provide essential higher-resolution views of potential scientific targets, sometimes with geology filters. It is envisaged that some PanCam imagery and stereo DTMs will be available in the daily cycle of downloads, with the number of PanCam products varying according to scientific priorities and data downlink rates. A key strength of ExoMars science is expected to be the rapid integration of PanCam stereo imagery with additional 3-D information into the science and drive planning process.\n2.4. Synergies with other instruments\nAn important scientific property of the Pasteur payload instruments is their ability to contribute to the successive chain of observations aiming to collect the best possible samples for analysis. PanCam is the first link in this chain.\nThe PanCam WACs will obtain panoramic scale information needed to characterize the rover's surroundings. Without the need to move the rover, PanCam HRC, in combination with the IR spectrometer ISEM, can secure detailed, high-resolution visual and spectral data on faraway candidate targets. Armed with these results, the science team can make an informed decision regarding which geological targets to inspect at close range.\nOnce the rover has reached a scientifically interesting objective, for example, a sedimentary rock outcrop that could have been deposited in an aqueous environment, PanCam WAC, PanCam HRC, and ISEM can work in a concerted manner to study the target. This characterization can be used to determine which portion of the outcrop to investigate at very high resolution with CLUPI, the close-up imager accommodated on the ExoMars drill.\nPanCam can also support rover operations when performing subsurface scanning maneuvers. These are predefined trajectories executed by the rover in order to construct 2-D and 3-D models using the WISDOM Ground Penetrating Radar (GPR) and the ADRON neutron detector. They allow the determination of, respectively, the subsurface stratigraphy under the rover (including the existence of potential obstacles) and the subsoil's level of hydration—both important for deciding where to drill.\nPanCam and CLUPI can work in tandem to visually examine outcrops and rocks at progressively higher resolution, that is, overall views with the WACs, imaging at millimeter scale with the HRC, and detailed textural studies at tens-of-microns scale with CLUPI.\nPanCam and CLUPI can also monitor drilling operations. As the drill penetrates into the ground, a mound of fines will be collected at its base. CLUPI can obtain very detailed images of these fines at 39 and 13 (drill lowered) μm/pixel (Josset et al., 2017, in this issue). However, via the RIM, or once the rover has backed away, it is the PanCam HRC that can inspect the entire collection of fines, revealing any heterogeneity in the grains. This information can be compared with the borehole wall data obtained by the Ma_MISS IR spectrometer integrated in the drill tip.\nFinally, the PanCam HRC and CLUPI are tasked with imaging the sample deposited by the drill on the Core Sample Transport Mechanism (CSTM)—a small drawer emerging through a port on the front of the rover to receive the sample. Once again, CLUPI can obtain high-resolution images (∼20 μm/pixel) of portions of the sample, but the PanCam HRC will achieve a top view of the complete sample prior to its delivery to the analytical laboratory for further processing and analysis.\nIn summary, the use of PanCam in synergy with all the rover's external instruments constitutes a major requirement for achieving the mission's scientific objectives.\nAlthough not strictly an instrument, the rover locomotion system itself (Poulakis et al., 2015 ) will provide PanCam with numerous scientific opportunities, for example, wheel-soil interaction studies based on mechanical properties of the terrain material that the rover will traverse, which can be assessed with PanCam and CLUPI. The results of these investigations will help improve predictions for tractive performance of flexible wheels on different terrains and slopes (the rover includes wheel slip sensors and is able to assess effective traverse progress optically). The wheels of the rover can also be used to conduct trenching observations (planned or otherwise) where PanCam and CLUPI can directly inspect (shallow) excavated material deemed interesting.\n3. Instrument Design\n3.1. Instrument overview\nThe PanCam design (total mass 2.13 kg with margin) includes the following major items:\n(a) Wide Angle Camera (WAC) pair, for multispectral stereoscopic panoramic imaging, using a miniaturized filter wheel. The WAC units themselves are provided by RUAG and Space-X, Switzerland, and the filter wheels and drives are produced by Mullard Space Science Laboratory (MSSL), University College London (UCL).\n(b) High Resolution Camera (HRC) for high-resolution color images. The HRC hardware is produced by OHB, Oberfaffenhofen, and DLR Institute for Planetary Research, Berlin, Germany.\n(c) PanCam Interface Unit and DC-DC converter (PIU and DCDC) to provide a single electronic interface. The PIU and DCDC are provided by MSSL-UCL.\n(d) PanCam Optical Bench (OB) to house PanCam and provide planetary and dust protection. The OB is provided by MSSL-UCL.\nThe PanCam mechanical design is illustrated in Fig. 3 . The OB is located on a rover-supplied pan-tilt mechanism at the top of the rover mast, at a height of ∼2 m above the surface (Silva et al., 2013 ).\nA summary of the main characteristics of PanCam is shown in Table 2 .\nTable 2. Main PanCam Characteristics and Resources\nEach of the WACs includes 11 filters comprising R, G, and B color bands, a geological filter set [optimized for use on Mars by Cousins et al. ( 2010 , 2012 )], and atmospheric filters to analyze the water and dust content in the martian atmosphere. The filter wheel and WAC system are illustrated in Fig. 4 .\nView larger version                                     (51K)\nFIG. 4.\nFront and rear CAD views of the right WAC assembly, showing the filter wheel and stepper motor. The left WAC and right WAC filter sets are not identical; they include RGB, narrow-band geology, and solar.\nInformation about Downloading\nThe HRC includes R, G, and B filters bonded to the detector chips to provide color information. The optical path is housed within the OB structure and comprises a baffle and mirror arrangement, a focus mechanism, and a detector with associated readout electronics (see Fig. 5 ).\nInformation about Downloading\nThe PIU is the main interface between the ExoMars rover and the PanCam subsystems, and uses an FPGA implementation. The final system component is the OB, which provides a planetary protection barrier to the external environment (including HEPA filters), as well as mechanical positioning of the PanCam components. A view of the structural-thermal model (STM) OB is shown in Fig. 6 .\nInformation about Downloading\nIn addition to the four major PanCam OB-mounted components outlined above, three additional “Small Items” hardware components are part of the PanCam design to improve the scientific return and provide useful engineering data. These are the calibration target (shared with ISEM), fiducial markers, and a rover inspection mirror (see Section 3.5). We note that data formatting and compression are performed within the rover electronics system.\n3.2. Wide angle cameras (WACs) and filter wheel\nEach WAC contains a STAR1000 APS-based camera with wide-angle optics and a filter wheel containing 11 filters ( Figs. 4 and 7 ).\nView larger version                                     (27K)\nFIG. 7.\nWAC block diagram showing the STAR1000 CMOS sensor with temperature sensor, the FPGA and image memory, connector, and LVDS drivers.\nInformation about Downloading\nThe 1 megapixel (1024 × 1024) STAR1000 detector is digitized to 10 bits with the onboard ADC. This CMOS active pixel sensor (APS) detector was selected to reduce the number of voltage lines required and the complexity of the support circuitry (compared to a traditional CCD sensor), thus allowing lighter, more compact camera heads to be designed. The STAR1000 was developed to be extremely radiation resistant (∼100 Krad, Cos et al., 2006 ) for long-duration geostationary missions and has flown previously as a star tracker detector (Schmidt et al., 2015 ). It was selected at a phase in the ExoMars mission evolution when a 1.5–2 year interplanetary cruise phase near solar maximum was foreseen. The sensor is currently in flight on the Mascot lander aboard the Hyabusa 2 spacecraft (Jaumann et al., 2016 ) and will be further qualified, for the demanding ∼200 thermal cycles it will see on the surface of Mars, as part of a life test model as part of the PanCam Assembly, Integration, and Test (AIT) phase. The product of quantum efficiency and fill factor of the STAR1000 is above 20% for most of the visible (i.e., 470–710 nm) but falls monotonically to 7% at 400 nm and only 3% at 1000 nm. To compensate for these quantum efficiency limitations, the WAC filter band passes systematically increase at both long and short wavelengths ( Table 3 ), maintaining relatively constant integration times by increasing the light energy reaching the sensor [as described in the filter selection paper by Cousins et al. ( 2012 )].\nTable 3. WAC Filter Properties for the Left Filter Wheel (Top Half) and the Right Filter Wheel (Bottom Half)\nThe fixed-focus, f = 21.85 mm optics provide in-focus images from approximately 0.85 m to infinity (optimized for 1.9 m). PSF modeling indicates >80% of a point source's energy is contained within the central 15-micron square pixel. This figure is a worst-case value for the edge of the field with performance improving toward the optical axis. The data from the detector are digitized to 10 bits. Stereo images are acquired with a 500 mm baseline and 2.8° toe-in (per “eye”), optimized for stereo vision at 5 m from the rover. The broadband red color filters in both WACs are used for stereo imaging, while in the same sequence images are taken through the green and blue broadband filters from one WAC (known as “RRGB”) to produce an RGB color texture to “drape” over the 3-D terrain model recovered from the stereo data. PanCam is mounted on top of the rover deployable mast array (DMA) some 2 m above the martian surface. From this position it can be panned (around the vertical axis) ±180° and tilted (around the horizontal axis) ±90°, from the straight-ahead position. This allows the WACs to image the PanCam Calibration Target (PCT) and Fiducial Markers (FidMs) on the rover deck and science targets on the (unobscured) martian surface and in the sky above the rover.\nEach WAC is composed of a gold-colored cube containing the power, memory, and sensor PCBs embedded in a protective epoxy attached to the 53° (diagonal) FOV lens. Unlike the HRC, the WAC design [incorporating over 20 years of development heritage—e.g., Beauvivre et al. ( 1999 ), Josset et al. ( 2006 ), Griffiths et al. ( 2005 )] calls for standalone modules containing 512 Mbits of memory storage for up to 50 images. The WAC is mounted to the OB just behind an 11-position filter wheel, turned by a stepper motor via a 64:1 gearbox (0.28° of filter wheel rotation per motor step). A Hall effect sensor detects magnets located along the periphery of the wheel (and also at the home position) to allow the PIU to determine the current filter location.\nThe 22 (total) filters are divided into three functional groups: 2 × R, G & B broadband color imaging filters (6), narrow-band geology filters in the 400–1000 nm wavelength range (12), and ultra-narrow-band solar filters (4) for dust optical density and water vapor absorption studies. The solar filters include a factor of ∼10−5 band pass attenuation to allow solar imaging without the detector saturating at even the minimum integration time. The filter center wavelength, pass band, and other properties are shown in Table 3 . Since data bandwidth limits will rarely allow the use of all 12 geology filters on extended targets, ratios of certain filters (shown with bold IDs in Table 3 )—for example, G03 and G05; G02, G06, and G01; and G07, G10, G11, and G12—will be used to identify diagnostic slopes, knees, or bands expected from hydrated clays, salts, or other minerals of exobiological interest (Harris et al., 2015 ).\n3.3. High Resolution Camera (HRC)\nThe PanCam HRC will be one of the few landscape-viewing cameras on Mars to be equipped with active focus capability, enabling it to reveal details near or far with about 8-fold better resolution than the WACs (and comparable to the 100 mm focal length, MastCam100 on the Curiosity rover).\nIn particular, HRC images will allow for high-resolution views of “Regions of Interest” within WAC wide-angle panoramas, as well as high-resolution imaging of rover-inaccessible locations on, for example, crater walls or in valleys. Combined with the RIM, placed at the front end of the rover body, high-resolution engineering images of the rover underside as well as views of the rover wheels for soil mechanics science or views of the underside of overhanging rock formations can be acquired.\nThe HRC is physically located inside the PanCam OB. The position of the viewing port next to the right WAC has been optimized to provide a top view of retrieved subsurface samples deposited by the drill on the CSTM.\nThe optical design is centered on a STAR1000 1024 × 1024 pixel CMOS detector, with 15 μm pixel size. Illuminated by a 180 mm EFL, f/16 lens (Cooke triplet), the detector enables detailed images of near and distant objects: the 4.88° square FOV takes images with a scale of ∼0.17 mm per pixel at 2 m distance and 8.5 cm per pixel at 1 km distance. PSF modeling indicates >70% of a point source's energy is contained within the central 15-micron square pixel. This figure is a worst-case value for the edge of the field with performance improving toward the optical axis. Physically, the HRC consists of the focal plane and control electronics PCBs, the focus drive stage with the lens barrel on top, the folding mirror assembly, and the entrance window (see Figs. 8 and 9 ). A major difference from the WAC is that the HRC lacks local image storage memory; instead, to simplify the design, the image data are transmitted directly to the PIU and buffered there. From the entrance window, the light is directed through an external and internal stray light baffle onto a 45° folding mirror. Inside the OB, an internal short wall carries a second internal baffle that directs the light onto the Cooke-triplet lens.\nView larger version                                     (32K)\nFIG. 9.\nHRC block diagram showing the STAR1000 CMOS sensor with temperature sensor, the FPGA (center), connectors, power conditioning, and LVDS drivers (right) and finally the focus motor control circuitry (left).\nInformation about Downloading\nTo enable active focusing, the lens group sits on a focus drive stage, which is mechanically actuated by a stepper motor for obtaining well-focused images between ∼1 m (distance to the sample on the CSTM) and infinity. Through a second short wall and third internal baffle, the light finally reaches the focal plane with the image sensor.\nThe HRC uses the same monochrome APS as the two WACs. However, instead of a filter wheel, an affixed red-green-blue filter strip over the CMOS detector is used. 1 Covering the spectral range from 440 to 654 nm (at FWHM), the three filter bands (covering, respectively, 342, 341, and 341 pixels horizontally) are blue (475 ± 35 nm), green (542.5 ± 22.5 nm), and red (635 ± 19 nm)—see Fig. 10 . For color image acquisition, using the three stripe filters on the detector, the camera head has to be panned over the full FOV to mosaic each color swath across the detector FOV. We note that optical testing of the HRC elegant breadboard revealed stray light issues relating to the filter; these have been mitigated by adding a black coating to the filter edges.\nView larger version                                     (32K)\nFIG. 10.\n(Left) RGB strip filter, directly glued onto the active area of the STAR1000 detector. (Right) Filter transmission curve of the RGB filter strips.\nInformation about Downloading\nConnected to the focal plane via a flex layer is the control electronics PCB, which houses all HRC electronics, including camera control, autofocus and autofocus motor control, and interface control.\nTo satisfy the stringent alignment requirements, the focal plane is placed on an isostatically mounted bracket. Shims between the focal plane bracket and the OB, as well as shims between the folding mirror bracket and OB, can be used to further adjust height and angular alignment during integration.\nThe autofocus algorithm is newly developed by the HRC team. An adapted global search strategy is used to search for the sharpest image within the focus range. The sharpness of an image is determined within a 32 × 32, 64 × 64, 128 × 128, or 256 × 256 window by Sobel filtering and calculation of the mean of the root-squared image gradients in x and y direction. The sharpness at the initial motor position is calculated by moving the motor either forward or backward depending on the current focus position, with a step length of 3 mm. Again, the image sharpness is calculated, and the motor movement direction is changed if the sharpness is lower than the initial sharpness. Then, steps of 1 mm are executed, and the image sharpness is calculated iteratively until a coarse global maximum sharpness is found. At the final stage, the step size is reduced to find the global maximum image sharpness. Although range estimation is not required for the HRC autofocus, the drive stage can be set by command at a position calculated based on range-to-target information from the WAC stereo products.\n3.4. Optical bench (OB)\nPanCam's internal components are contained in an OB. An OB was selected to provide the instrument with protection from the martian environment (e.g., dust) and to provide the martian environment protection from any contaminants brought from Earth by the instrument. The OB is vented with a HEPA filter to equalize pressure but maintain cleanliness. In addition, the rigidity of the OB helps maintain a stable structure from which to acquire stereo imaging.\nThe OB is of aluminum construction with dimensions of 562 × 70 × 113 mm (L × H × D). The walls are machined from a single aluminum block, and afterward the interior is cut out by using electrical discharge machining wire cutting. Wire cutting allows the OB to have thinner walls than could be machined from a solid block, resulting in a lightweight rigid structure.\nThe base is electron-beam welded to the wall structure, and the lid is secured to the top of the bench by a series of fasteners once the internal components are mounted. In this configuration, the box makes a very stiff, extremely light monocoque structure. The mass of the OB itself, including 12% margin, is just under 780 g.\nThe interior of the OB is painted with a black paint (Z306) to cut down on stray light. Aeroglaze Z-306 has a reflectance of ∼8% BoL in the visible (Gilmore, 2002 ) and a few percent in the NIR (Ames, 1990 ). The exterior of the OB is coated with A276, a space-qualified white paint that aids PanCam thermal control. Equally importantly, A276 is compatible with ExoMars planetary protection guidelines; it is glossy and smooth, so it is less likely to harbor spores and other bioburden. It can also withstand dry heat microbial reduction sterilization.\n3.5. Supporting electronics—PanCam Interface Unit (PIU) + DC-DC converter (DCDC)\nThe function of the PIU is to provide a single interface for all three cameras to the rover and this is achieved by using the SpaceWire RMAP interface protocol. The PIU receives the SpaceWire RMAP packets and executes them as required and forwarding the command to the cameras. Due to power constraints, only a single camera can be powered at any one time. The active camera is selected by the PIU using power switches.\nSingle alternating WAC operation (e.g., during stereo image acquisition) is not expected to present problems maintaining operating temperature. This is because thermal modeling indicates that the low thermal conductance to the OB means that one camera is unlikely to cool significantly in the few minutes it is switched off (while the other is acquiring the matching image in the stereo pair). Alternating camera use during a sequence of stereo pairs allows heat loss from each camera to be minimized.\nThe PIU is responsible for control of the filter wheels. The PIU maintains locally the Rover Elapsed Time (RET) in order to allow time-stamping of HK packets and image data. In addition to time stamps, images can be identified by a unique image ID that is embedded in the image metadata and contains parameters such as the sol date and task ID. Owing to PanCam's position on the end of the mast and again to power limitations, the instrument does not have any survival heaters and follows the martian surface temperature.\nTherefore, the cameras will generally be operated during the day when surface temperatures are above −40°C (to reduce power required for heating). An exception may be the solar observations just prior to sunset (sunrise observations likely being precluded by power and thermal restrictions). However, since the rover is solar powered, it is similarly limited to daytime operations when the dust opacity is low enough to enable (and any seasonal constraints allow) a suitable operating power margin to be maintained (Vago, 2012 ).\nGiven this, the PIU provides autonomous camera unit temperature control and monitoring with secondary power for the heaters. Moreover, the PIU is responsible for the control of the filter wheels. The performance and state of PanCam is monitored though the Housekeeping packets generated by the PIU. These Housekeeping packets are also used by the rover to detect any off-nominal behavior and take the appropriate actions.\nA single DC-DC converter, which is housed in a dedicated compartment of the OB, provides the galvanically isolated secondary rails as required by the rest of the instrument. The DC-DC converter converts the 28 V primary power bus to three different voltages:\n• 12 V, used to drive the filter wheels and the HRC focus actuator;\n• 6 V, which powers the various digital components (switched to power the cameras as needed);\n• 1.5 V, used by the PanCam FPGA.\nThe DC-DC converter incorporates a number of features such as current limiting designed to safeguard the rest of the instrument in the event of a component failure or upset.\n3.6. Small Items\nThe PanCam “Small Items” consist of additional passive hardware to aid the surface operations of PanCam and allow in situ calibration. These items include the PCT, the FidMs, and the RIM. The PCT and FidMs are mounted on the rover deck and the RIM on the left-hand suspension bogie bracket as shown in Fig. 11 .\nInformation about Downloading\n3.6.1. PanCam Calibration Target (PCT)\nThe PCT provides an in situ calibration target for the radiometric calibration of PanCam on the martian surface. The PCT has a mass of 36.2 g excluding mounting screws and consists of an aluminum structure with a surface area of 67 × 76 mm, which mechanically retains eight colored glass and ceramic calibration patches. Six of the calibration patches (red, yellow, green/blue, blue, and two gray) have an exposed diameter of 18 mm and will be used only for PanCam calibration. Colored glass was selected for the calibration patches, as the color has excellent resistance to UV-induced fading and damage from the moderate doses of ionizing radiation it will encounter during the mission. The surfaces of the calibration patches are processed to obtain a diffuse reflection, and the back surface is aluminized to increase the total reflectance. The glass for the six small calibration patches is standard Schott colored and neutral-density filter glass.\nThe white and multiband calibration patches have an exposed diameter of 30 mm and will be used for the radiometric and spectral calibration of ISEM (Korablev et al., 2017 , in this issue) in addition to PanCam. WCT-2065 (a rare earth doped glass developed by NIST and manufactured by Schott) is used to provide well-defined bands for spectral calibration applications in the visible and NIR. The white calibration patch is Pyroceram manufactured by the Vavilov State Optical Institute in St. Petersburg.\nThe calibration patches will be calibrated for absolute reflectance in total hemispherical/8° geometry and BRDF so that the angle of incident solar illumination can be compensated for. The PCT includes two shadow posts to allow the level of indirect (scattered) skylight to be assessed and aid in the determination of the illumination direction and angle.\nThe PCT is mounted on the front of the rover deck in a region as clear as possible from sources of shadowing and stray light and will be viewed by PanCam from an angle of ∼23° from the vertical. Measurements of the light scattered by the PCT will allow the level of incident illumination to be determined over the PanCam and ISEM spectral range. In combination with preflight calibration data, these measurements will allow PanCam images to be processed to obtain calibrated data products such as spectral parameter images and relative reflectance spectra of objects in the FOV.\nDust deposition on the PCT during the ExoMars mission will be accounted for in the data processing by developing a radiative transfer model of the PCT/dust system, building on the results of previous missions (Johnson et al., 2002 ; Bell et al., 2006; Kinch et al., 2007 , 2015 ). This will use laboratory measurements of Mars analog dust (JSC Mars-1; Allen et al., 1997 ) on the PCT prototype as with the MER calibration target (Johnson et al., 2006 ) and measurements of settling rates derived from the rover solar array power output (Stella et al., 2005 ).\n3.6.2. Fiducial Markers (FidMs)\nTogether with the PCT, the three FidMs form two right-angle triangles on the rover deck to allow in situ geometric calibration of the PTU/PanCam system. Each FidM consists of a single piece of aluminum, anodized black and with the center section ground back to aluminum to provide high contrast. The center hole in each FidM provides a mounting point for geometric reference targets for preflight calibration activities. The FidMs have dimensions of 32 × 16 × 6.5 mm and a mass of 1.2 g excluding mounting screws.\n3.6.3. Rover Inspection Mirror (RIM)\nThe RIM is a 50 mm diameter convex spherical mirror machined and polished from aluminum, with a radius of curvature of 30 mm mounted on an aluminum bracket. The RIM assembly has a mass of 21.8 g excluding mounting screws. The RIM will be imaged by the HRC and will allow the drill spoil heap to be observed while drilling is taking place. It will also allow the underside of the rover to be observed for diagnosis in the event of problems with uneven surfaces, the drivetrain, and so on. The RIM will also allow the PanCam instrument to take “selfies” of the rover for publicity and outreach purposes.\n4. Measurement Scenario\n4.1. Usage of PanCam\nThe ExoMars mission plan is to explore the martian terrain near the landing site using a series of six experiment cycles and two vertical surveys (Vago et al., 2015 , 2017). The rover will target outcrops as indicators of buried rock masses that may extend below the radiation-altered and oxidized layers to depths of >1.5 m where molecular fossils may have survived for billions of years.\nA “reference surface mission,” involving experiment cycles, has been designed to provide the necessary requirements for sizing the rover. The discussion in this section is based on that existing plan, which also provides a rough template for achieving the main scientific goals during the nominal surface mission. We fully appreciate that the detailed planning for Mars operations will vary significantly from this scenario. Inputs from the science and engineering teams for PanCam and other instruments will be generated on a daily basis as the mission progresses, in reaction to the martian terrain and environment and to the state of the rover.\nIn an experiment cycle (EC), the rover uses the Pasteur payload (over a period of 14 sols, with another 4 sols reserved for traveling between EC sites) to home in on a suitable outcrop from which to acquire samples (Vago, 2012 ). For particularly promising EC sites, a vertical survey can be conducted where samples are returned every 50 cm from the surface to the maximum drilling depth of 2 m.\nThe EC can be divided into an approach phase (3–4 sols) and a sampling phase (10–11 sols). At the beginning of the approach phase, the rover can be up to 20 m distant from a possible drill target, so a PanCam WAC panorama of up to 10 RRGB color/stereo images of the area ahead of the rover is acquired on the first sol. At the same time, HRC RGB color images and co-registered ISEM spectra (Korablev et al., 2017 , in this issue) of promising rocks (seen during the ∼100 m drive from the previous EC location) are acquired. From these data, an outcrop target will be chosen for the rover to approach to ∼3 m on the second sol. ADRON (Mitrofanov et al., 2017 , in this issue) and WISDOM (Ciarletti et al., 2017 , in this issue) surveys are conducted during the approach phase. A WAC image using either all 12 geology filters or selected groups (as discussed in Section 3.1) is taken of the outcrop along with a mosaic of eight HRC color images (and again eight co-registered ISEM spectra). Then on the third sol, a HRC color context image is taken of the potential drill target area to be imaged in greater detail by CLUPI. Subsequently, CLUPI will acquire up to six images (with depth from focus position information) to characterize rock microtexture and select a location to drill. Finally, on the forth sol of the approach phase, a surface sample is acquired and imaged by the HRC and CLUPI before ingestion into the ALD by the HRC and CLUPI. In this way, PanCam forms part of the “remote sensing” part of the Pasteur payload (along with WISDOM, ADRON, ISEM, and CLUPI) used to determine where to drill and acquire a sample.\nDuring the EC sampling phase, the “remote sensing” instruments are used less frequently, with the ALD instruments taking center stage. However, assuming the surface sample results are promising, on the sixth sol a 6-position WAC RRGB mosaic is acquired to help plan a WISDOM pattern search for a location to drill deeper for unaltered samples. The WAC is used again on the seventh sol to acquire 12 RRGB images to increase the accuracy of the knowledge of rover positioning at the corners of the WISDOM pattern.\nNext, on the eighth sol while drilling to at least 1.5 m depth is proceeding, the WAC is used to acquire a further 10 RRGB images for strategic planning (e.g., to help determine the drive direction for the following EC). The final use of PanCam during the sampling phase is on the 10th sol to image the retrieved subsurface sample with the HRC (along with CLUPI) before ingestion into the ALD.\nBetween the 11th and 13th sols, PanCam rests while the ALD instruments analyze the subsurface sample. Then, from the 14th to 18th sol, the rover drives to the next EC location, while conducting WISDOM and ADRON soundings. The only PanCam activity on these sols is the possible acquisition of WAC broadband red filter stereo pairs (or mosaics of stereo pairs) to provide higher-resolution views (than available with the NavCams) to help plan the rovers' course to the next EC location.\nDuring the mission's two vertical surveys, the PanCam is mostly inactive while the rover drills at a single location. HRC images of the samples prior to ingestion can again be envisaged.\n4.2. Instrument performance examples\nThe instrument performance will be determined from the integrated PanCam instrument and from calibration when the instrument has been assembled (see Section 5.1–5.2). At present, representative examples have been produced by using PanCam emulators such as the AUPE-2 Aberystwyth University PanCam Emulator 2 (e.g., Pugh et al., 2012 ; Harris et al., 2015 ) and breadboard models, but the actual instrument performance examples are not available as yet.\nA number of ExoMars-related field trials and tests have been performed in the last few years (see Fig. 12 ), including participation in recent Arctic Mars Analogue Svalbard Expeditions (AMASE) 2008–2015 (see Schmitz et al., 2009 ; Steele et al., 2010 ), the SAFER campaign in the Atacama Desert in 2013 (Gunes-Lasnet et al., 2014 ), and field trials in Iceland in 2013 (Harris et al., 2015 ). For these tests, a representative PanCam simulator was used, which was provided by Aberystwyth University. This simulator includes representative (though not the final) filter wavelengths from which spectral information may be used to study mineralogy. These campaigns have been used, in combination with teams from other ExoMars instruments, to develop working procedures representative of a mission to Mars, as well as to test instrument performance, develop calibration techniques, and pursue scientific investigations of particular areas. These included, for example, the Bockfjord Volcanic Complex and the Nordaustlandet/Palander Icecap. Scientific data from these trials are discussed elsewhere (Schmitz et al., unpublished data).\nView larger version                                     (74K)\nFIG. 12.\nViews of AUPE PanCam simulator at tests in a Hertfordshire, UK, quarry (bottom left) and at the AMASE campaign, Svalbard.\nInformation about Downloading\nOther PanCam ground tests have included “blind” geological identifications performed in the AU Mars analog facility, tests in a quarry in Hertfordshire with the Astrium UK “Bridget” prototype rover, a field trial in Shropshire in 2015, and deployment in Boulby mine (Payler et al., 2017 ).\n5. Calibration and 3-D Vision\n5.1. Radiometric calibration plan\nRaw PanCam images will be processed to remove image artifacts caused by the camera system and convert digital numbers into calibrated radiometric values. These processing activities will be implemented in the PanCam data processing pipeline at the ROCC. To correct camera-induced image artifacts and obtain a true representation of the scene viewed by PanCam, radiometric calibration measurements to fully characterize the camera properties will be necessary.\nThe radiometric calibration of the PanCam instrument will comprise a combination of component- and system-level measurements to characterize the properties of various parts of the instrument. Component-level calibrations will measure camera properties including the following: detector dark current and bias, detector linearity, detector hot/cold pixels, filter absolute transmission, PCT reflectance, and so on. System level calibrations will characterize properties of the complete system and include the following: flat-field measurements to determine the non-uniformity in the response of the optical system, measurements of system radiometric response, measurements of system spectral response and the response of the system to stray light. Dark current and flat fields will also be acquired periodically in flight to determine the effects of thermal cycling and radiation exposure on the detector response.\nMany of the camera properties will be temperature-dependent, so calibration will be carried out as a function of temperature. The PanCam instrument together with calibration hardware, including an integrating sphere, will be mounted in a thermal vacuum chamber (TVC) at MSSL (see Fig. 13b ) so that measurements can be carried out over the full operating temperature range of the system: −50°C to 35°C. These measurements will be interpolated to the sensor temperature recorded for the in-flight images to allow the modeled sensor response to be subtracted and estimates of remaining errors to be derived (following the methods of Bell et al., 2006).\nView larger version                                     (56K)\nFIG. 13.\n(a) PanCam embedded in the Geometric transformations chain of the ExoMars rover. The main element is the rover frame with various elements attached such as Drill or WISDOM (bottom). The cascade relevant for PanCam is the transform between rover and PTU, followed by the transform between PTU and WACL—depending on the pan-tilt values. WACL, HRC, and WACR are described in the PanCam coordinate system. In addition, for fusion purposes PanCam (WACL) will be cross-calibrated with NavCam and ISEM. (b) MSSL TVC to be used for WACs/HRC calibration in open state. (c) PanCam geometric calibration target design with random dot pattern for WACs (large dots) and HRC (small dots).\nInformation about Downloading\nThe integrating sphere will be mounted on a linear translation stage so that it can be placed in front of each of the PanCam cameras without breaking vacuum. Light sources for the integrating sphere will include white light for flat-field and linearity measurements and a tunable light source incorporating a monochromator for spectral calibrations. The light sources and a calibrated monitor spectrometer will be located outside the TVC and coupled via optical fibers. PanCam calibration measurements will be traceable to national standards laboratories (NIST) via appropriate calibration standards. These will include a calibrated light source to achieve absolute radiometric calibration and reflectance standards to determine the absolute reflectance of the PCT.\n5.2. Geometric calibration plan\nThe geometric calibration of the PanCam involves all the steps required to define its components in a common coordinate system. This coordinate system will allow local reconstruction of the information collected by the PanCam components at each rover position on Mars.\nTo perform calibration, first each PanCam camera must be calibrated individually, second relative to each other, and then to the rest of the PanCam components. This last step is called cross-calibration.\nThe individual calibration of the WACs and HRC will compute the coordinates of the principal point, the focal length, and the lens distortion coefficients for each camera that is called intrinsic orientation (IO)—various representations are available. PanCam will use a derivative of the TSAI model (Tsai, 1987 ) with the option to convert to other well-known schemes such as CAHVOR (Di and Li, 2004 ). The IO of the WACs will be obtained by using one representative filter (e.g., the red RGB component); distortion of other filters is measured in comparison to it by measuring the relative distortion. For HRC IO, the calibration using two different focal lengths is needed. The cross-calibration determines the geometric relationship between all PanCam components, which are mathematically expressed as 3-D-Helmert transformations, as displayed in Fig. 13a .\nChanges in the IOs of the WACs and HRC will be observed by executing several temperature transitions in vacuum. Further exhaustive tests will be conducted in ambient conditions outside the TVC to assess the dependency of the filter wavelengths on the WAC IOs and the stability of the WAC and HRC IO and relative orientation after rotating the cameras around the Pan and Tilt Unit (PTU).\nThe original plan to bring a full setup of 3-D target points, measured by an optical coordinate metrology system (e.g., Vicon), into the calibration clean room was abandoned due to planetary protection and laboratory space reasons. Instead, a flat calibration target that fulfils the planetary protection requirements, that is, appropriate for dry heat microbial reduction, will be used. It consists of an aluminum target containing a set of randomly distributed points in different scales to fit the WAC and HRC needs simultaneously, as displayed in Fig. 13c . Furthermore, in contrast to up-to-date approaches of targets with regular patterns (Bell et al., 2003; Edgett et al., 2015 ), the target can cover the full image, and the points can still be automatically detected and correctly assigned to perform a fully automatic calibration using hundreds of images.\nThe final AIT task requires measurements of the relative calibration between the rover and OB, PTU, FidMs, and Mast. The current plan is to accomplish this by cross-calibration with NavCam and additional adjustment of the WACs versus the PTU axes by multiple overlapping image observations under varying PTU angles and overlapping observations of the rover deck and fiducial markers under varying PTU angles.\nCross-calibration with ISEM and CLUPI will be obtained by multiple simultaneous viewing of the same target (e.g., the PCT), followed by an adjustment procedure. Cross-calibration to WISDOM will be done only indirectly based on the PanCam and WISDOM individual alignment in the rover coordinate system.\nVerification and possible correction of the calibration on Mars will be obtained by bundle adjustment of single stereo pairs and overlapping patches of stereo panoramas.\n5.3. 3-D vision\nThree-dimensional scene reconstruction from PanCam stereo imagery is established by the processing framework PRoViP (Planetary Robotics Vision Processing). Starting with images from the instrument available via the ESA Planetary Science Archive or NASA Planetary Data System (during the mission the data will be directly from downlink sources in the ROCC), stereo matching is performed, followed by 3-D reconstruction into DTMs in various geometries, generation of an intermediate data set (“GPC”: Generic Point Cloud), combination of the DTMs into unique consistent mosaicked products, and finally the export into products to be exploited by scientists and operations personnel.\nExamples of processing products and capabilities are as follows:\n(a) Digital Elevation Models in spherical, cylindrical, and Cartesian coordinate space;\n(b) Ortho images;\n(c) 3-D meshes;\n(d) Derived thematic maps of the surroundings, describing reconstruction accuracy, occlusions, solar illumination, slopes, roughness, hazards, and so on;\n(e) Fusion of rover- and orbiter-based images;\n(f) Fusion between WAC and HRC 3-D vision data products (e.g., overlay of WAC DTM/ortho images with HRC texture).\nPRoViP has been extensively tested with various Mars mission data sets from sensors similar to PanCam, including MSL Mastcam (Barnes et al., 2015a , Paar et al., 2016a , 2016b ) (see Fig. 14 ).\nView larger version                                     (55K)\nFIG. 14.\n(Left) Result of MSL Mastcam processing of Garden City outcrop area taken at MSL Sol 926 and 929 (DTM, rendered by PRo3D) making use of ExoMars PanCam 3-D vision processing workflow scheme PRoViP. (Right) 3-D rendered MSL Mastcam stereo processing results at subcentimeter resolution, as appearing in PRo3D Graphical User Interface.\nInformation about Downloading\nFor immersive 3-D presentation of the PanCam 3-D vision products, we will use an interactive 3-D viewing tool called “PRo3D” (Planetary Robotics 3D Viewer, Barnes et al., 2015b ), which allows one to virtually explore reconstructed martian terrain and perform geological analysis ( Fig. 15 ). PRo3D builds upon the ideas of existing rendering tools used for tactical and strategic planning such as combining the rover CAD model with the 3-D reconstructed environment (Poulakis et al., 2008 ; Cooper et al., 2013 ; Proton, 2015 ) or the exploitation of image poses to generate virtual views (Howard, 2015 ). In addition, it goes beyond the approach of transition between panoramas and 3-D environment followed in Google Mars but gives simultaneous real-time access to different resolutions from planetary to microscopic level and therefore allows an interactive fusion of rover image products and orbiter DTMs (Paar et al., 2015 ), closing the loop between 3-D vision processing and immersive 3-D geology. Various measurement and annotation tools are provided to\n(a) Delineate geological boundaries,\n(b) Obtain the true dimension of geological features,\n(c) Obtain linear and projected distances between surface points,\n(d) Calculate dip and strike values of stratigraphic layers.\nView larger version                                     (85K)\nFIG. 15.\nScreenshot of PRo3D showing a geological interpretation session in the Shaler area (Gale Crater, MSL mission), based on PRoViP 3-D reconstruction from a set of 99 MSL Mastcam stereo images. This detailed interpretation of the stratigraphy shows the main stratigraphic boundaries as gray lines, bedset boundaries as thick white lines, and laminations within those bedsets as thin white lines (note that the original image is in color). The dip and strike values are available directly in PRo3D in color coded by dip value and generally dip 15–20° to the southeast (validation forthcoming). The findings are consistent with those in the works of Anderson et al. ( 2015 ) and Edgar et al. ( 2014 ) in that the outcrop represents a changing fluvial environment, with recessive, fine-grained units interlayered with coarse, pebbly units. Data courtesy of NASA/JPL, image courtesy of Imperial College London, Robert Barnes/Sanjeev Gupta; www.provide-space.eu\nInformation about Downloading\n6. Conclusions\nWe have described the scientific objectives of PanCam, its design, and how it will be used, as well as calibration methods and 3-D vision capabilities. PanCam has several powerful novel capabilities in terms of Mars camera deployment:\n• The WAC spacing, 50 cm, gives excellent stereo reconstruction\n• The WAC-HRC combination allows rock texture to be superimposed on the excellent DTMs\n• The WAC filters have been specifically designed to reduce uncertainty in the identification of water-rich minerals\n• WAC will perform atmospheric science measurements, that is, water vapor and dust determination, cloud monitoring\n• The HRC will provide rock texture information and will be able to view drill tailings, samples, and underneath the rover\n• PanCam will perform synergistic work with other context instruments (ISEM CLUPI, WISDOM, ADRON, and Ma_MISS)\nIn summary, PanCam will be a highly capable scientific camera system for the martian surface with an excellent anticipated scientific performance for geology, using filters selected for accurate identification of water-rich minerals and for atmospheric science and exobiology.\nAcknowledgments\nWe thank the ExoMars project team and Industry for their hard work on the ExoMars rover. We acknowledge support from the UK Space Agency (lead funding agency for PanCam) and STFC, DLR agency, Swiss Space Office (via PRODEX), Austrian agency. We thank the PanCam science team for help over the years. PanCam would not be possible without vital engineering support at MSSL (T. Hunt, J. Jones, C. Theobald, B. Winter, B. Hancock, G. Davison, A. Spencer, A. Rousseau, V. Botelho, P. Yuen, P. Janicki), DLR, OHB, RUAG and Joanneum Research/VRVIS.\nReferences\nC.C. Allen, R.V. Morris, D.J. Lindstrom, M.M. Lindstrom, and J.P. Lockwood (1997) JSC Mars-1: martian regolith simulant [abstract 1797]. In 28th Lunar and Planetary Science Conference, Lunar and Planetary Institute, Houston.\nA.J. Ames (1990) Z306 black paint measurements. Proc SPIE 1331:299–304.\nR. Anderson, J.C. Bridges, A. Williams, L. Edgar, A. Ollila, J. Williams, M. Nachon, N. Mangold, M. Fisk, J. Schieber, S. Gupta, G. Dromart, R. Wiens, S. Le Mouélic, O. Forni, N. Lanza, A. Mezzacappa, V. Sautter, D. Blaney, B. Clark, S. Clegg, O. Gasnault, J. Lasue, R. Léveillé, E. Lewin, K.W. Lewis, S. Maurice, H. Newsom, S.P. Schwenzer, and D. Vaniman (2015) ChemCam results from the Shaler outcrop in Gale Crater, Mars. Icarus 249:2–21.\nR.B. Anderson and J.F. Bell (2013) Correlating multispectral imaging and compositional data from the Mars Exploration Rovers and implications for Mars Science Laboratory. Icarus 223:157–180.\nR.E. Arvidson (2015) Roving on Mars with Opportunity and Curiosity: terramechanics and terrain properties. In Earth and Space 2014: Engineering for Extreme Environments,\nProceedings of the 14th Biennial ASCE Conference on Engineering, Science, Construction, and Operations in Challenging Environments\n, edited by L.S. Gertsch and R.B. Malla, American Society of Civil Engineers, Reston, VA, pp 165–173.\nR.E. Arvidson, R.C. Anderson, P. Bartlett, J.F. Bell, P.R. Christensen, P. Chu, K. Davis, B.L. Ehlmann, M.P. Golombek, S. Gorevan, E.A. Guinness, A.F.C. Haldemann, K.E. Herkenhoff, G. Landis, R. Li, R. Lindemann, D.W. Ming, T. Myrick, T. Parker, L. Richter, F.P. Seelos, L.A. Soderblom, S.W. Squyres, R.J. Sullivan, and J. Wilson (2004) Localization and physical property experiments conducted by Opportunity at Meridiani Planum. Science 306:1730–1733.\nR.E. Arvidson, J.F. Bell, J.G. Catalano, B.C. Clark, V.K. Fox, R. Gellert, J.P. Grotzinger, E.A. Guinness, K.E. Herkenhoff, A.H. Knoll, M.G.A. Lapotre, S.M. McLennan, D.W. Ming, R.V. Morris, S.L. Murchie, K.E. Powell, M.D. Smith, S.W. Squyres, M.J. Wolff, and J.J. Wray (2015) Mars Reconnaissance Orbiter and Opportunity observations of the Burns Formation: crater hopping at Meridiani Planum. J Geophys Res: Planets 120:429–451.\nR.E. Arvidson, K.D. Iagnemma, M. Maimone, A.A. Fraeman, F. Zhou, M.C. Heverly, P. Bellutta, D. Rubin, N.T. Stein, J.P. Grotzinger, and A.R. Vasavada (2017) Mars Science Laboratory Curiosity rover megaripple crossings up to Sol 710 in Gale Crater. Journal of Field Robotics 34:495–518.\nM. Balme, P. Fawdon, P. Grindrod, S. Gupta, J. Michalski, J. Carter, J.-P. Muller, and P. Sidiropoulos (2014) Inverted, exhumed channel system in Oxia Palus. In First ExoMars Landing Site Selection Workshop, 26–28 March 2014, ESAC, Villanueva de la Cañada, Madrid, Spain.\nM. Balme, P. Grindrod, J. Davis, P. Fawdon, E. Sefton-Nash, S. Gupta, F. Butcher, J. Carter, J.-P. Muller, P. Sidiropoulos, and V. Yershov (2015) Aram Dorsum. In Third ExoMars Landing Site Selection Workshop, 20–21 October 2015, ESTEC, Noordwijk, the Netherlands.\nR. Barnes, G. Paar, C. Traxler, J.-P. Muller, Y. Tao, K. Sander, S. Gupta, T. Ortner and L. Fritz (2015a) PRo3D: interactive geologic assessment of planetary 3D vision data products. In International Congress on Stratigraphy (STRATI 2015). Available online at http://www.vrvis.at/publications/pdfs/PB-VRVis-2015-028.pdf\nR. Barnes, T. Ortner, B. Huber, G. Paar, J.-P. Muller, M. Giordano, and K. Willner (2015b) PRo3D®: a tool for high resolution rendering and geological analysis of martian rover-derived digital outcrop models [paper no. 35-17]. In Geological Society of America Abstracts with Programs, 47:111. Available online at https://gsa.confex.com/gsa/2015AM/webprogram/Paper265784.html\nS. Beauvivre, P. Lamy, T. Nguyen-Trong, and J.L. Reynaud (1999) The panoramic camera of the ROSETTA mission: performances of prototype 3D microcameras. Adv Space Res 24:1105–1114.\nJ.F. Bell, S.W. Squyres, K.E. Herkenhoff, J.N. Maki, H.M. Arneson, D. Brown, S.A. Collins, A. Dingizian, S.T. Elliot, E.C. Hagerott, A.G. Hayes, M.J. Johnson, J.R. Johnson, J. Joseph, K. Kinch, M.T. Lemmon, R.V. Morris, L. Scherr, M. Schwochert, M.K. Shepard, G.H. Smith, J.N. Sohl-Dickstein, R.J. Sullivan, W.T. Sullivan, and M. Wadsworth (2003) Mars Exploration Rover Athena Panoramic Camera (Pancam) investigation. J Geophys Res 108, doi:\n10.1029/2003JE002070\n.\nJ.F. Bell, J. Joseph, J.N. Sohl-Dickstein, H.M. Arneson, M.J. Johnson, M.T. Lemmon, and D. Savransky (2006) In-flight calibration and performance of the Mars Exploration Rover Panoramic Camera (Pancam) instruments. J Geophys Res 111, doi:\n10.1029/2005JE002444\n.\nJ.-P. Bibring, V. Hamm, C. Pilorget, J.L. Vago, and the MicrOmega Team. (2017) The MicrOmega investigation onboard ExoMars. Astrobiology 17, 621–626.\nJ.L. Bishop, E.Z. Noe Dobrea, N.K. McKeown, M. Parente, B.L. Ehlmann, J.R. Michalski, R.E. Milliken, F. Poulet, G.A. Swayze, J.F. Mustard, S.L. Murchie, and J.P. Bibring (2008) Phyllosilicate diversity and past aqueous activity revealed at Mawrth Vallis, Mars. Science 321:830–833.\nJ.C. Bridges, S.P. Schwenzer, R. Leveille, F. Westall, R. Wiens, N. Mangold, T. Bristow, P. Edwards, and G. Berger (2015) Diagenesis and clay formation at Gale Crater, Mars. J Geophys Res 120, doi:\n10.1002/2014JE004757\n.\nJ.C. Bridges, R.A. Henson, J.L. Vago, D. Loizeau, R.M.E. Williams, E. Hauber, and E. Sefton-Nash (2016a) ExoMars landing site characterisation and selection [abstract 2170]. In 47th Lunar and Planetary Science Conference, Lunar and Planetary Institute, Houston.\nJ.C. Bridges, P.H. Edwards, R. Anderson, M.D. Dyar, M. Fisk, L. Thompson, P. Gasda, S.P. Schwenzer, W. Goetz, D. Blaney, J. Filiberto, and R.C. Wiens (2016b) Igneous differentiation on Mars: trachybasalts in Gale Crater [abstract 2160]. In 47th Lunar and Planetary Science Conference, Lunar and Planetary Institute, Houston.\nN.T. Bridges, F.J. Calef, B. Hallet, K.E. Herkenhoff, N.L. Lanza, S. Le Mouélic, C.E. Newman, D.L. Blaney, M.A. Pablo, G.A. Kocurek, Y. Langevin, K.W. Lewis, N. Mangold, S. Maurice, P.-Y. Meslin, P. Pinet, N.O. Renno, M.S. Rice, M.E. Richardson, V. Sautter, R.S. Sletten, R.C. Wiens, and R.A. Yingst (2014) The rock abrasion record at Gale Crater: Mars Science Laboratory results from Bradbury Landing to Rocknest. J Geophys Res: Planets 119:1374–1389.\nS.L. Cady, J.D. Farmer, J.P. Grotzinger, J.W. Schopf, and A. Steele (2003) Morphological biosignatures and the search for life on Mars. Astrobiology 3:351–368.\nP.R. Christensen, M.B. Wyatt, T.D. Glotch, A.D. Rogers, S. Anwar, R.E. Arvidson, J.L. Bandfield, D.L. Blaney, C. Budney, W.M. Calvin, A. Fallacaro, R.L. Fergason, N. Gorelick, T.G. Graff, V.E. Hamilton, A.G. Hayes, J.R. Johnson, A.T. Knudson, H.Y. McSween Jr., G.L. Mehall, L.K. Mehall, J.E. Moersch, R.V. Morris, M.D. Smith, S.W. Squyres, S.W. Ruff, and M.J. Wolff (2004) Mineralogy at Meridiani Planum from the Mini-TES experiment on the Opportunity Rover. Science 306:1733–1739.\nV. Ciarletti, S. Clifford, D. Plettemeier, Gall Le, A., Y. Hervé, S. Dorizon, C. Quantin-Nataf, W.-F. Benedix, S. Schwenzer, E. Pettinelli, E. Heggy, A. Herique, J.-J. Berthelier, W. Kofman, J.L. Vago, S.-E. Hamran, and the WISDOM Team. (2017) The WISDOM radar: unveiling the subsurface beneath the ExoMars Rover and identifying the best locations for drilling. Astrobiology 17, 565–584.\nB.K. Cooper, S.A. Maxwell, F.R. Hartman, J.R. Wright, J. Yen, N.T. Toole, Z. Gorjian, and J.C. Morrison (2013, September) Robot sequencing and visualization program (RSVP). NASA Tech Briefs. Available online at http://ntrs.NASA.gov/search.jsp?R=20140001459\nS. Cos, D. Uwaerts, J. Bogaerts, and W. Ogiers (2006) Active Pixels for Star Trackers: Final Report, Doc. Nr: APS-FF-SC-05-023, Dated 24-03-2006, Issue: 1, Cypress Semiconductor Corp. BVBA, Mechelen, Belgium.\nC.R. Cousins, A.D. Griffiths, I.A. Crawford, B.J. Prosser, M.C. Storrie-Lombardi, L.E. Davis, M. Gunn, A.J. Coates, A.P. Jones, and J.M. Ward (2010) Astrobiological considerations for the selection of the geological filters on the ExoMars PanCam instrument. Astrobiology 10:933–951.\nC.R. Cousins, M. Gunn, B.J. Prosser, D.P. Barnes, I.A. Crawford, A.D. Griffiths, L.E. Davis, and A.J. Coates (2012) Selecting the geology filter wavelengths for the ExoMars Panoramic Camera instrument. Planet Space Sci 71:80–100.\nR.A. Craddock and M.P. Golombek (2016) Characteristics of terrestrial basaltic rock populations: implications for Mars lander and rover science and safety. Icarus 274:50–72.\nN.S. Davies, A.G. Liu, M.R. Gibling, and R.F. Miller (2016) Resolving MISS conceptions and misconceptions: a geological approach to sedimentary surface textures generated by microbial and abiotic processes. Earth-Science Reviews 154:210–246.\nR. De Kok, P.G.J. Irwin, C.C.C. Tsang, G. Piccioni, and P. Drossart (2011) Scattering particles in nightside limb observations of Venus' upper atmosphere by Venus Express VIRTIS. Icarus 211:51–57.\nM.C. De Sanctis, F. Altieri, E. Ammannito, D. Biondi, Angelis De, S., M. Meini, G. Mondello, S. Novi, R. Paolinetti, M. Soldani, R. Mugnuolo, S. Pirrotta, J.L. Vago, and the Ma_MISS team. (2017) Ma_MISS on ExoMars: mineralogical characterization of the martian subsurface. Astrobiology 17:612–620.\nK. Di and R. Li (2004) CAHVOR camera model and its photogrammetric conversion for planetary applications. J Geophys Res: Planets 109, doi:\n10.1029/2003JE002199\n.\nG. Di Achille, and B.M. Hynek (2010) Ancient ocean on Mars supported by global distribution of deltas and valleys. Nat Geosci 3:459–463.\nL.A. Edgar, J.P. Grotzinger, A.G. Hayes, D.M. Rubin, S.W. Squyres, J.F. Bell, and K.E. Herkenhoff (2012) Stratigraphic architecture of bedrock reference section, Victoria Crater, Meridiani Planum, Mars. In Sedimentary Geology of Mars, SEPM Special Publication No. 102, edited by J. Grotzinger and R. Milliken, Society for Sedimentary Geology, Tulsa, OK, pp 195–209.\nL.A. Edgar, S. Gupta, D.M. Rubin, K.W. Lewis, G.A. Kocurek, R.B. Anderson, J.F. Bell, G. Dromart, K.S. Edgett, J.P. Grotzinger, C. Hardgrove, L.C. Kah, R. Leveille, M.C. Malin, N. Mangold, R.E. Milliken, M. Minitti, M. Palucis, M. Rice, S.K. Rowland, J. Schieber, K.M. Stack, D.Y. Sumner, A.J. Williams, J. Williams, and R.M.E. Williams (2014) A fluvial sandbody on Mars: reconstruction of the Shaler outcrop, Gale Crater, Mars [abstract 1648]. In 45th Lunar and Planetary Science Conference, Lunar and Planetary Institute, Houston.\nK.S. Edgett, R.A. Yingst, M.A. Ravine, M.A. Caplinger, J.N. Maki, F.T. Ghaemi, J.A. Schaffner, J.F. Bell III, L.J. Edwards, K.E. Herkenhoff, E. Heydari, L.C. Kah, M.T. Lemmon, M.E. Minitti, and T.S. Olsonshow (2012) Curiosity's Mars Hand Lens Imager (MAHLI) investigation. Space Sci Rev 170:259–317.\nK.S. Edgett, M.A. Caplinger, J.N. Maki, M.A. Ravine, F.T. Ghaemi, S. McNair, K.E. Herkenhoff, B.M. Duston, R.G. Willson, R.A. Yingst, M.R. Kennedy, M.E. Minitti, A.J. Sengstacken, K.D. Supulver, L.J. Lipkaman, G.M. Krezoski, M.J. McBride, T.L. Jones, B.E. Nixon, J.K. Van Beek, D.J. Krysak, and R.L. Kirk (2015) Curiosity's Robotic Arm-Mounted Mars Hand Lens Imager (MAHLI): Characterization and Calibration Status, MSL MAHLI Technical Report 0001 (version 1: 19 June 2015; version 2: 05 October 2015), doi:\n10.13140/RG.2.1.3798.5447\n.\nB.L. Ehlmann, J.F. Mustard, C.I. Fassett, S.C. Schon, J.W. Head, D.J. Des Marais, J.A. Grant,and S.L. Murchie (2008) Clay minerals in delta deposits and organic preservation potential on Mars. Nat Geosci 1:355–358.\nJ.D. Farmer and D.J. Des Marais (1999) Exploring for a record of ancient martian life. J Geophys Res 104:26977–26995.\nW.H. Farrand, J.F. Bell, J.R. Johnson, S.W. Squyres, J. Soderblom, and D.W. Ming (2006) Spectral variability among rocks in visible and near-infrared multispectral Pancam data collected at Gusev Crater: examinations using spectral mixture analysis and related techniques. J Geophys Res 111, doi:\n10.1029/2005JE002495\n.\nW.H. Farrand, J.F. Bell, J.R. Johnson, M.S. Rice, B.L. Jolliff, and R.E. Arvidson (2014) Observations of rock spectral classes by the Opportunity rover's Pancam on northern Cape York and on Matijevic Hill, Endeavour Crater, Mars. J Geophys Res 119:2349–2369.\nJ. Fernando, F. Schmidt, C. Pilorget, P. Pinet, X. Ceamanos, S. Douté, Y. Daydou, and F. Costard (2015) Characterization and mapping of surface physical properties of Mars from CRISM multi-angular data: application to Gusev Crater and Meridiani Planum. Icarus 253:271–295.\nL.N. Fletcher, P.G.J. Irwin, N.A. Teanby, G.S. Orton, P.D. Parrish, R. de Kok, C. Howett, S.B. Calcutt, N. Bowles, and F.W. Taylor (2007) Characterising Saturn's vertical temperature structure from Cassini/CIRS. Icarus 189:457–478.\nM.G Fox-Powell, J.E Hallsworth, C.R. Cousins, and C.S. Cockell (2016) Ionic strength is a barrier to the habitability of Mars. Astrobiology 16:427–442.\nR. Francis, J. Moores, K. McIsaac, D. Choi, and G. Osinski (2014) Observations of wind direction by automated analysis of images from Mars and the MSL rover. Acta Astronaut 94:776–783.\nD.G. Gilmore (2002) Spacecraft Thermal Control Handbook: Fundamental Technologies, 2nd ed., Aerospace Press, El Segundo, CA.\nF. Goesmann, W.B. Brinckerhoff, F. Raulin, W. Goetz, R. Danell, S. Getty, S. Siljeström, H. Mißbach, H. Steininger, Jr. Arevalo, R.D., A. Buch, C. Freissinet, A. Grubisic, U. Meierhenrich, V.T. Pinnick, F. Stalport, C. Szopa, J.L. Vago, R. Lindner, M.D. Schulte, J.R. Brucato, D.P. Glavin, N. Grand, X. Li, F.H.W. van Amerom, and the MOMA Science Team. (2017) The Mars Organic Molecule Analyzer (MOMA) instrument: characterization of organic material in martian sediments. Astrobiology 17:655–685.\nM. Golombek, A. Huertas, D. Kipp, and F. Calef (2012) Detection and characterization of rocks and rock size-frequency distributions at the final four Mars Science Laboratory landing sites. International Journal of Mars Science and Exploration 7, doi:\n10.1555/mars.2012.0001\n.\nM.P. Golombek, R.E. Arvidson, J.F. Bell, P.R. Christensen, J.A. Crisp, L.S. Crumpler, B.L. Ehlmann, R.L. Fergason, J.A. Grant, R. Greeley, A.F. Haldemann, D.M. Kass, T.J. Parker, J.T. Schofield, S.W. Squyres, and R.W. Zurek (2005) Assessment of Mars Exploration Rover landing site predictions. Nature 436:44–48.\nM.P. Golombek, A.F.C. Haldemann, R.A. Simpson, R.L. Fergason, N.E. Putzig, R.E. Arvidson, J.F. Bell, and M.T. Mellon (2008) Martian surface properties from joint analysis of orbital, Earth-based, and surface observations. In The Martian Surface: Composition, Mineralogy, and Physical Properties, edited by J. Bell, Cambridge University Press, New York, pp 468–497.\nA.D. Griffiths, A.J. Coates, J.-L. Josset, G. Paar, B. Hofmann, D. Pullan, P. Rüffer, M.R. Sims, and C.T. Pillinger (2005) The Beagle 2 stereo camera system. Planet Space Sci 53:1466–1482.\nC. Gross, F. Poulet, J. Michalski, B. Horgan, and J.L. Bishop (2016) Mawrth Vallis—proposed landing site for ExoMars 2018/2020 [abstract 1421]. In 47th Lunar and Planetary Science Conference, Lunar and Planetary Science Institute, Houston.\nJ. Grotzinger, J. Bell, III, K. Herkenhoff, J. Johnson, A. Knoll, E. McCartney, S. McLennan, J. Metz, J. Moore, S. Squyres, R. Sullivan, O. Ahronson, R. Arvidson, B. Joliff, M. Golombek, K. Lewis, T. Parker, and J. Soderblom (2006) Sedimentary textures formed by aqueous processes, Erebus Crater, Meridiani Planum, Mars. Geology 34:1085–1088.\nJ.P. Grotzinger, D.Y. Sumner, L.C. Kah, K. Stack, S. Gupta, L. Edgar, D. Rubin, K. Lewis, J. Schieber, N. Mangold, R. Milliken, P.G. Conrad, D. Des Marais, J. Farmer, K. Siebach, F. Calef III, J. Hurowitz, S.M. McLennan, D. Ming, D. Vaniman, J. Crisp, A. Vasavada, K.S. Edgett, M. Malin, D. Blake, R. Gellert, P. Mahaffy, R.C. Wiens, S. Maurice, J.A. Grant, S. Wilson, R.C. Anderson, L. Beegle, R. Arvidson, B. Hallet, R.S. Sletten, M. Rice, J. Bell III, J. Griffes, B. Ehlmann, R.B. Anderson, T.F. Bristow, W.E. Dietrich, G. Dromart, J. Eigenbrode, A. Fraeman, C. Hardgrove, K. Herkenhoff, L. Jandura, G. Kocurek, S. Lee, L.A. Leshin, R. Leveille, D. Limonadi, J. Maki, S. McCloskey, M. Meyer, M. Minitti, H. Newsom, D. Oehler, A. Okon, M. Palucis, T. Parker, S. Rowland, M. Schmidt, S. Squyres, A. Steele, E. Stolper, R. Summons, A. Treiman, R. Williams, Yingst, A.; Team. MSL Science (2014) A habitable fluvio-lacustrine environment at Yellowknife Bay, Gale Crater, Mars. Science 343, doi:\n10.1126/science.1242777\n.\nJ.P. Grotzinger, S. Gupta, M.C. Malin, D.M. Rubin, J. Schieber, K. Siebach, D.Y. Sumner, K.M. Stack, A.R. Vasavada, R.E. Arvidson, S. Gupta, M.C. Malin, D.M. Rubin, J. Schieber, K. Siebach, D.Y. Sumner, K.M. Stack, A.R. Vasavada, R.E. Arvidson, F. Calef, L. Edgar, W.F. Fischer, J.A. Grant, J. Griffes, L.C. Kah, M.P. Lamb, K.W. Lewis, N. Mangold, M.E. Minitti, M. Palucis, M. Rice, R.M.E. Williams, R.A. Yingst, D. Blake, D. Blaney, P. Conrad, J. Crisp, W.E. Dietrich, G. Dromart, K.S. Edgett, R.C. Ewing, R. Gellert, J.A. Hurowitz, G. Kocurek, P. Mahaffy, M.J. McBride, S.M. McLennan, M. Mischna, D. Ming, R. Milliken, H. Newsom, D. Oehler, T.J. Parker, D. Vaniman, R.C. Wiens, and S.A. Wilson (2015) Deposition, exhumation, and paleoclimate of an ancient lake deposit, Gale Crater, Mars. Science 350, doi:\n10.1126/science.aac7575\n.\nS. Gunes-Lasnet, A. Kisidi, M. van Winnendael, J.-L. Josset, V. Ciarletti, D. Barnes, A. Griffiths, G. Paar, S. Schwenzer, D. Pullan, E. Allouis, L. Waugh, M. Woods, A. Shaw, and G. Chong Diaz (2014) SAFER: the promising results of the Mars mission simulation in Atacama, Chile. In i-SAIRAS 2014: 12th International Symposium on Artificial Intelligence, Robotics and Automation in Space, 17–19 June 2014, Montreal, Canada.\nM.D. Gunn and C.R. Cousins (2016) Mars surface context cameras past, present and future. Earth Space Sci 3:144–162.\nI. Haase, J. Oberst, F. Scholten, M. Wählisch, P. Gläser, I. Karachevtseva, and M.S. Robinson (2012) Mapping the Apollo 17 landing site area based on Lunar Reconnaissance Orbiter camera images and Apollo surface photography. J Geophys Res 117, doi:\n10.1029/2011JE003908\n.\nJ.K Harris, C.R. Cousins, M. Gunn, P.M. Grindrod, D. Barnes, I.A. Crawford, R.E. Cross, and A.J. Coates (2015) Remote detection of past habitability at Mars-analogue hydrothermal alteration terrains using an ExoMars Panoramic Camera emulator. Icarus 252:284–300.\nK.E. Herkenhoff, M.P. Golombek, E.A. Guinness, J.B. Johnson, A. Kusack, L. Richter, R.J. Sullivan, and S. Gorevan (2008) In situ observations of the physical properties of the martian surface. In The Martian Surface: Composition, Mineralogy, and Physical Properties, edited by J. Bell, Cambridge University Press, New York, pp 451–467.\nN.M. Hoekzema, M. Garcia-Comas, O.J. Stenzel, E.V. Petrova, N. Thomas, W.J. Markiewicz, K. Gwinner, H.U. Keller, and W.A. Delamere (2011) Retrieving optical depth from shadows in orbiter images of Mars. Icarus 214:447–461.\nM. Howard (2015) Midnight Planets. Available online at http://www.midnightplanets.com\nB.M. Hynek and R.J. Phillips (2008) The stratigraphy of Meridiani Planum, Mars, and implications for the layered deposits' origin. Earth Planet Sci Lett 274:214–220.\nY. Ibarra and F.A. Corsetti (2016) Lateral comparative investigation of stromatolites: astrobiological implications and assessment of scales of control. Astrobiology 16:271–281.\nP.G.J. Irwin, P. Parrish, T. Fouchet, S.B. Calcutt, F.W. Taylor, A.A. Simon-Miller, and C.A. Nixon (2004) Retrievals of jovian tropospheric phosphine from Cassini/CIRS. Icarus 172:37–49.\nP.G.J. Irwin, N.A. Teanby, Kok de, R., L.N. Fletcher, C.J.A. Howett, C.C.C. Tsang, C.F. Wilson, S.B. Calcutt, C.A. Nixon, and P.D. Parrish (2008) The NEMESIS planetary atmosphere radiative transfer and retrieval tool. J Quant Spectrosc Radiat Transf 109:1136–1150.\nR. Jaumann, N. Schmitz, A. Koncz, H. Michaelis, S.E. Schroeder, S. Mottola, F. Trauthan, H. Hoffmann, T. Roatsch, D. Jobs, J. Kachlicki, B. Pforte, R. Terzer, M. Tschentscher, S. Weisse, U. Mueller, L. Perez-Prieto, B. Broll, A. Kruselburger, T.-M. Ho, J. Biele, S. Ulamec, C. Krause, M. Grott, J.-P. Bibring, S. Watanabe, S. Sugita, T. Okada, M. Yoshikawa, and H. Yabuta (2016) The camera of the MASCOT asteroid lander on board Hayabusa 2. Space Sci Rev doi:\n10.1007/s11214-016-0263-2\n.\nD.J. Jerolmack, D. Mohrig, J.P. Grotzinger, D.A. Fike, and W.A. Watters (2006) Spatial grain size sorting in eolian ripples and estimation of wind conditions on planetary surfaces: application to Meridiani Planum, Mars. J Geophys Res 111, doi:\n10.1029/2005JE002544\n.\nJ.R. Johnson, M.T. Lemmon, W.M. Grundy, and K.E. Herkenhoff (2002) Dust mineralogy and deposition rates on Mars from observations of Mars Pathfinder calibration targets [abstract 1392]. In 33rd Lunar and Planetary Science Conference, Lunar and Planetary Institute, Houston.\nJ.R. Johnson, J. Sohl-Dickstein, W.M. Grundy, R.E. Arvidson, J. Bell, P. Christensen, T. Graff, E.A. Guinness, K. Kinch, R. Morris, and M.K. Shepard (2006) Radiative transfer modeling of dust-coated Pancam calibration target materials: laboratory visible/near-infrared spectrogoniometry. J Geophys Res: Planets 111, doi:\n10.1029/2005JE002658\n.\nJ.R. Johnson, J.F. Bell, P. Geissler, W.M. Grundy, E.A. Guinness, P.C. Pinet, and J. Soderblom (2008) Physical properties of the martian surface from spectrophotometric observations. In The Martian Surface: Composition, Mineralogy, and Physical Properties, edited by J. Bell, Cambridge University Press, New York, pp 428–450.\nJ.R. Johnson, W.M. Grundy, M.T. Lemmon, J.F. Bell, and R.G. Deen (2015) Spectrophotometric properties of materials observed by Pancam on the Mars Exploration Rovers: 3. Sols 500–1525. Icarus 248:25–71.\nJ.-L. Josset, S. Beauvivre, P. Cerroni, M.C. De Sanctis, P. Pinet, S. Chevrel, Y. Langevin, M.A. Barucci, P. Plancke, D. Koschny, M. Almeida, Z. Sodnik, S. Mancuso, B.A. Hofmann, K. Muinonen, V. Shevchenko, Shkuratov, Yu., P. Ehrenfreund, and B.H. Foing (2006) Science objectives and first results from the SMART-1/AMIE multicolour micro-camera. Adv Space Res 37:14–20.\nJ.-L. Josset, F. Westall, B.A. Hofmann, J. Spray, C. Cockell, S. Kempe, A.D. Griffiths, M.C. De Sanctis, L. Colangeli, D. Koschny, K. Föllmi, E. Verrecchia, L. Diamond, M. Josset, E.J. Javaux, F. Esposito, M. Gunn, A.L. Souchon-Leitner, T.R.R. Bontognali, O. Korablev, S. Erkman, G. Paar, S. Ulamec, F. Foucher, P. Martin, A. Verhaeghe, M. Tanevski, and J.L. Vago (2017) The Close-Up Imager onboard the ESA ExoMars Rover: objectives, description, operations, and science validation activities. Astrobiology 17:595–611.\nK.M. Kinch, J. Sohl-Dickstein, J.F. Bell, J.R. Johnson, W. Goetz, and G.A. Landis (2007) Dust deposition on the Mars Exploration Rover Panoramic Camera (Pancam) calibration targets. J Geophys Res: Planets 112, doi:\n10.1029/2006JE002807\n.\nK.M. Kinch, J.F. Bell, W. Goetz, J.R. Johnson, J. Joseph, M.B. Madsen, and J. Sohl-Dickstein (2015) Dust deposition on the decks of the Mars Exploration Rovers: 10 years of dust dynamics on the Panoramic Camera calibration targets. Earth Space Sci 2:144–172.\nA. Kleinböhl, J.T. Schofield, W.A. Abdou, P.G. Irwin, and R.J. de Kok (2011) A single-scattering approximation for infrared radiative transfer in limb geometry in the martian atmosphere. J Quant Spectrosc Radiat Transf 112:1568–1580.\nA.H. Knoll and J.P. Grotzinger (2006) Water on Mars and the prospect of martian life. Elements 2:171–175.\nO.I. Korablev, Y. Dobrolensky, N. Evdokimova, A.A. Fedorova, R.O. Kuzmin, S.N. Mantsevich, E.A. Cloutis, J. Carter, F. Poulet, J. Flahaut, A. Griffiths, M. Gunn, N. Schmitz, J. Martín-Torres, M.-P. Zorzano, D.S. Rodionov, J.L. Vago, A.V. Stepanov, A.Y Titovu., N.A. Vyazovetsky, A.Y Trokhimovskiyu., A.G. Sapgir, Y.K. Kalinnikov, Y.S. Ivanov, A.A. Shapkin, and A.Yu Ivanov. (2017) Infrared spectrometer for ExoMars: a mast-mounted instrument for the Rover. Astrobiology 17:542–564.\nM.P. Lamb, J.P. Grotzinger, J.B. Southard, and N.J. Tosca (2012) Were aqueous ripples on Mars formed by flowing brines? In Sedimentary Geology of Mars, SEPM Special Publication No. 102, edited by J. Grotzinger and R. Milliken, Society for Sedimentary Geology, Tulsa, OK, pp 139–150.\nS. Le Mouélic, O. Gasnault, K.E. Herkenhoff, N.T. Bridges, Y. Langevin, N. Mangold, S. Maurice, R.C. Wiens, P. Pinet, H.E. Newsom, R.G. Deen, J.F. Bell, J.R. Johnson, W. Rapin, B. Barraclough, D.L. Blaney, L. Deflores, J. Maki, M.C. Malin, R. Pérez, and M. Saccoccio (2015) The ChemCam Remote Micro-Imager at Gale Crater: review of the first year of operations on Mars. Icarus 249:93–107.\nM.T. Lemmon, M.J. Wolff, M.D. Smith, R.T. Clancy, D. Banfield, G.A. Landis, A. Ghosh, P.H. Smith, N. Spanovich, B. Whitney, and P. Whelley (2004) Atmospheric imaging results from the Mars Exploration Rovers: Spirit and Opportunity. Science 306:1753–1756.\nM.T. Lemmon, M.J. Wolff, J.F. Bell, M.D. Smith, B.A. Cantor, and P.H. Smith (2015) Dust aerosol, clouds, and the atmospheric optical depth record over 5 Mars years of the Mars Exploration Rover mission. Icarus 251:96–111.\nR.J. Léveillé, J. Bridges, R.C. Wiens, N. Mangold, A. Cousin, N. Lanza, O. Forni, A. Ollila, J. Grotzinger, S. Clegg, K. Siebach, G. Berger, B. Clarck, C. Fabre, R. Anderson, O. Gasnault, D. Blaney, L. Deflores, L. Leshin, M. Sylvestre, and H. Newsom (2014) Chemistry of fracture-filling raised ridges in Yellowknife Bay, Gale Crater: window into past aqueous activity and habitability on Mars. J Geophys Res 119:2398–2415.\nK.W. Lewis, O. Aharonson, J.P. Grotzinger, S.W. Squyres, J.F. Bell, L.S. Crumpler, and M.E. Schmidt (2008) Structure and stratigraphy of Home Plate from the Spirit Mars Exploration Rover. J Geophys Res 113, doi:\n10.1029/2007JE003025\n.\nK.A. Lichtenberg, R.E. Arvidson, F. Poulet, R.V. Morris, A. Knudson, J.F. Bell, G. Bellucci, J.-P. Bibring, W.H. Farrand, J.R. Johnson, D.W. Ming, P.C. Pinet, A.D. Rogers, and S.W. Squyres (2007) Coordinated analyses of orbital and Spirit Rover data to characterize surface materials on the cratered plains of Gusev Crater, Mars. J Geophys Res 112, doi:\n10.1029/2006JE002850\n.\nD. Loizeau, N. Mangold, F. Poulet, V. Ansan, E. Hauber, J.-P. Bibring, B. Gondet, Y. Langevin, P. Masson, and G. Neukum (2010) Stratigraphy in the Mawrth Vallis region through OMEGA, HRSC color imagery and DTM. Icarus 205:396–418.\nD. Loizeau, N. Mangold, F. Poulet, J.-P. Bibring, J.L. Bishop, J. Michalski, and C. Quantin (2015) History of the clay-rich unit at Mawrth Vallis, Mars: high-resolution mapping of a candidate landing site. J Geophys Res: Planets 120:1820–1846.\nR. Lolachi, P.G.J. Irwin, N. Teanby, S. Calcutt, C.J.A. Howett, N.E. Bowles, F.W. Taylor, J.T. Schofield, A. Kleinboehl, and D.J. McCleese (2007) Preliminary martian atmospheric water vapour column abundances with Mars climate sounder. Bulletin of the American Astronomical Society 39:458.\nJ. Maki, D. Thiessen, A. Pourangi, P. Kobzeff, T. Litwin, L. Scherr, S. Elliott, A. Dingizian, and M. Maimone (2012) The Mars Science Laboratory engineering cameras. Space Sci Rev 170:77–93.\nM. Manga, A. Patel, J. Dufek, and E.S. Kite (2012) Wet surface and dense atmosphere on early Mars suggested by the bomb sag at Home Plate, Mars. Geophys Res Lett 39, doi:\n10.1029/2011GL050192\n.\nW.J. Markiewicz, R.M. Sablotny, H.-U. Keller, N. Thomas, D. Titov, and P.H. Smith (1999) Optical properties of the martian aerosols as derived from imager for Mars Pathfinder midday sky brightness data. J Geophys Res 104:9009–9018.\nG.A. Marzo, T.L. Roush, N.L. Lanza, P.C. McGuire, H.E. Newsom, A.M. Ollila, and S.M. Wiseman (2009) Association of phyllosilicates and the inverted channel in Miyamoto Crater, Mars. Geophys Res Lett 36, doi:\n10.1029/2009GL038703\n.\nS. Maurice, R.C. Wiens, M. Saccoccio, B. Barraclough, O. Gasnault, O. Forni, N. Mangold, D. Baratoux, S. Bender, G. Berger, J. Bernardin, M. Berthé, N. Bridges, D. Blaney, M. Bouyé, P. Caïs, B. Clark, S. Clegg, A. Cousin, D. Cremers, A. Cros, L. DeFlores, C. Derycke, B. Dingler, G. Dromart, B. Dubois, M. Dupieux, E. Durand, L. d'Uston, C. Fabre, B. Faure, A. Gaboriaud, T. Gharsa, K. Herkenhoff, E. Kan, L. Kirkland, D. Kouach, J.-L. Lacour, Y. Langevin, J. Lasue, Mouélic Le, S., M. Lescure, E. Lewin, D. Limonadi, G. Manhès, P. Mauchien, C. McKay, P.-Y. Meslin, Y. Michel, E. Miller, H.E. Newsom, G. Orttner, A. Paillet, L. Parès, Y. Parot, R. Pérez, P. Pinet, F. Poitrasson, B. Quertier, B. Sallé, C. Sotin, V. Sautter, H. Séran, J.J. Simmonds, J.-B. Sirven, R. Stiglich, N. Striebig, J.-J. Thocaven, M.J. Toplis, and D. Vaniman (2012) The ChemCam instrument suite on the Mars Science Laboratory (MSL) rover: science objectives and mast unit description. Space Sci Rev 170:95–166.\nS.M. McLennan, R.B. Anderson, J.F. Bell, III, J.C. Bridges, F. Calef III, J.L. Campbell, B.C. Clark, S. Clegg, P. Conrad, A. Cousin, D.J. Des Marais, G. Dromart, M.D. Dyar, L.A. Edgar, B.L. Ehlmann, C. Fabre, O. Forni, O. Gasnault, R. Gellert, S. Gordon, J.A. Grant, J.P. Grotzinger, S. Gupta, K.E. Herkenhoff, J.A. Hurowitz, P.L. King, S. Le Mouélic, L.A. Leshin, R. Léveillé, K.W. Lewis, N. Mangold, S. Maurice, D.W. Ming, R.V. Morris, M. Nachon, H.E. Newsom, A.M. Ollila, G.M. Perrett, M.S. Rice, M.E. Schmidt, S.P. Schwenzer, K. Stack, E.M. Stolper, D.Y. Sumner, A.H. Treiman, S. VanBommel, D.T. Vaniman, A. Vasavada, R.C. Wiens, R.A. Yingst; Team. MSL Science (2014) Elemental geochemistry of sedimentary rocks in Yellowknife Bay, Gale Crater, Mars. Science 343, doi:\n10.1126/science.1244734\n.\nJ.M. Metz, J.P. Grotzinger, D.M. Rubin, K.W. Lewis, S.W. Squyres, and J.F. Bell (2009) Sulfate-rich eolian and wet interdune deposits, Erebus Crater, Meridiani Planum, Mars. Journal of Sedimentary Research 79:247–264.\nJ.R. Michalski, J.-P. Bibring, F. Poulet, D. Loizeau, N. Mangold, E. Noe Dobrea, J.L. Bishop, J.J. Wray, N.K. McKeown, M. Parente, E. Hauber, F. Altieri, F.G. Carrozzo, and P.B. Niles (2010) The Mawrth Vallis Region of Mars: a potential landing site for the Mars Science Laboratory (MSL) mission. Astrobiology 10:687–703.\nI.G. Mitrofanov, M.L. Litvak, S.Yu. Nikiforov, I. Jun, Bobrovnitsky, Yu.I., D.V. Golovin, A.S. Grebennikov, F.S. Fedosov, A.S. Kozyrev, D.I. Lisov, A.V. Malakhov, M.I. Mokrousov, A.B. Sanin, V.N. Shvetsov, G.N. Timoshenko, T.M. Tomilina, V.I. Tret'yakov, and A.A. Vostrukhin (2017) The ADRON-RM instrument onboard the ExoMars Rover. Astrobiology 17:585–594.\nH.J. Moore, R.E. Hutton, G.D. Clow, and C.R. Spitzer (1987) Physical Properties of the Surface Materials at the Viking Landing Sites on Mars, USGS professional paper 1389, United States Government Printing Office, Washington, DC.\nJ.E. Moores, M.T. Lemmon, P.H. Smith, L. Komguem, and J.A. Whiteway (2010) Atmospheric dynamics at the Phoenix landing site as seen by the Surface Stereo Imager. J Geophys Res: Planets 115, doi:\n10.1029/2009JE003409\n.\nJ.E. Moores, R. Haberle, M. Lemmon, K.M. Bean, M. Mischna, M. de la Torre Juárez, C. Newman, F. Calef, B. Cantor, A.R. Vasavada, J. Maki, J. Martin-Torres, M.-P. Zorzano, R. Francis, E. McCullough, EC MSL Science TeamTeam. AM (2013) Constraints on atmospheric water vapor and circulation at Gale Crater from the MSL atmospheric monitoring campaign [abstract 1548]. In 44th Lunar and Planetary Science Conference, Lunar and Planetary Institute, Houston.\nJ.E. Moores, M.T. Lemmon, H. Kahanpää, S.C.R. Rafkin, R. Francis, J. Pla-Garcia, K. Bean, R. Haberle, C. Newman, M. Mischna, A.R. Vasavada, M. de la Torre Juárez, N. Rennó, J. Bell, F. Calef, B. Cantor, T.H. Mcconnochie, A.-M. Harri, M. Genzer, M.H. Wong, M.D. Smith, F.J. Martín-Torres, M.-P. Zorzano, O. Kemppinen, and E. McCullough (2015) Observational evidence of a suppressed planetary boundary layer in northern Gale Crater, Mars as seen by the Navcam instrument onboard the Mars Science Laboratory rover. Icarus 249:129–142.\nM. Nachon, S.M. Clegg, N. Mangold, S. Schröder, L.C. Kah, G. Dromart, A. Ollila, J.R. Johnson, D.Z. Oehler, J.C. Bridges, S. Le Mouélic, O. Forni, R.C. Wiens, R.B. Anderson, D.L. Blaney, J.F. Bell III, B. Clark, A. Cousin, M.D. Dyar, B. Ehlmann, C. Fabre, O. Gasnault, J. Grotzinger, J. Lasue, E. Lewin, S. McLennan, S. Maurice, P.-Y. Meslin, W. Rapin, M. Rice, S.W. Squyres, K. Stack, D.Y. Sumner, D. Vaniman, and D. Wellington (2014) Calcium sulfate veins characterized by ChemCam/Curiosity at Gale Crater, Mars. J Geophys Res: Planets 119, doi:\n10.1002/2013JE004588\n.\nA.L. Nahm and R.A. Schultz (2007) Outcrop-scale physical properties of Burns Formation at Meridiani Planum, Mars. Geophys Res Lett 34, doi:\n10.1029/2007GL031005\n.\nE.Z. Noe Dobrea, J.L. Bishop, N.K. McKeown, R. Fu, C.M. Rossi, J.R. Michalski, C. Heinlein, V. Hanus, F. Poulet, R.J.F. Mustard, S. Murchie, A.S. McEwen, G. Swayze, J.-P. Bibring, E. Malaret, and C. Hash (2010) Mineralogy and stratigraphy of phyllosilicate-bearing and dark mantling units in the greater Mawrth Vallis/west Arabia Terra area: constraints on geological origin. J Geophys Res 115, doi:\n10.1029/2009JE003351\n.\nN. Noffke (2009) The criteria for the biogeneicity of microbially induced sedimentary structures (MISS) in Archean and younger, sandy deposits. Earth-Science Reviews 96:173–180.\nJ. Oberst, W. Zeitler, and T. Parker (1999a) Revised Viking landing site yields accurate maps for Mars. Eos 80:549–553.\nJ. Oberst, R. Jaumann, W. Zeitler, E. Hauber, M. Kuschel, T. Parker, M. Golombek, M. Malin, and L. Soderblom (1999b) Photogrammetric analysis of horizon panoramas: the Pathfinder landing site in Viking orbiter images. J Geophys Res 104:8927–8934.\nC.H. Okubo (2007) Strength and deformability of light-toned layered deposits observed by MER Opportunity: Eagle to Erebus Craters, Mars. Geophys Res Lett 34, doi:\n10.1029/2007GL031327\n.\nG. Paar, A. Griffiths, A. Bauer, T. Nunner, N. Schmitz, D. Barnes, and E. Riegler (2009) 3D vision ground processing workflow for the Panoramic Camera on ESA's EXOMARS mission 2016. In 9th Conference on Optical 3-D Measurement Techniques, July 2009, Vienna, Austria.\nG. Paar, G. Hesina, C. Traxler, V. Ciarletti, D. Plettemeier, C. Statz, K. Sander, and B. Nauschnegg (2015) Embedding sensor visualization in martian terrain reconstructions. In ASTRA, May 2015, ESA, ESTEC, Noordwijk, theNetherlands. Available online at http://robotics.estec.esa.int/ASTRA/Astra2015/Papers/Session%209B/95433_Paar.pdf\nG. Paar, et al. (2016a) PRoViDE: Planetary Robotics Vision Data Processing and Fusion [id. EPSC2015-345]. In European Planetary Science Congress 2015, 27 September–2 October 2015, Nantes, France.\nG. Paar, C. Koeberl, G. Hesina, B. Huber, and C. Traxler (2016b) 3D Vision for Mars 2020 Mastcam-Z: pre-assessment of processing techniques and geologic use cases [abstract 2810]. In 47th Lunar and Planetary Science Conference, Lunar and Planetary Institute, Houston.\nJ. Parnell, D. Cullen, M.R. Sims, S. Bowden, C.S. Cockell, R. Court, P. Ehrenfreund, F. Gaubert, W. Grant, V. Parro, M. Rohmer, M. Sephton, H. Stan-Lotter, A. Steele, J. Toporski, and J. Vago (2007) Searching for life on Mars: selection of molecular targets for ESA's Aurora ExoMars mission. Astrobiology 7:578–604.\nS.J. Payler, J.F. Biddle, A.J. Coates, C.R. Cousins, R.E. Cross, D.C. Cullen, M.T. Downs, S.O.L. Direito, T. Edwards, A.L. Gray, J. Genis, M. Gunn, G.M. Hansford, P. Harkness, J. Holt, J.-L. Josset, X. Li, D.S. Lees, D.S.S. Lim, M. McHugh, D. McLuckie, E. Meehan, S.M. Paling, A. Souchon, L. Yeoman, and C.S. Cockell (2017) Planetary science and exploration in the deep subsurface: results from the MINAR Program, Boulby Mine, UK. International Journal of Astrobiology 16:114–129.\nP. Poulakis, L. Joudrier, S. Wailliez, and K. Kapellos (2008) 3DROV: a planetary rover system design, simulation and verification tool. Available online at http://robotics.estec.esa.int/i-SAIRAS/isairas2008/Proceedings/SESSION%2012/m105-Poulakis.pdf\nP. Poulakis, J.L. Vago, D. Loizeau, C. Vicente-Arevalo, A. Hutton, R. McCoubrey, J. Arnedo-Rodriguez, J. Smith, B. Boyes, S. Jessen, A. Otero-Rubio, S. Durrant, G. Gould, L. Joudrier, Y. Yushtein, C. Alary, E. Zekri, P. Baglioni, A. Cernusco, F. Maggioni, R. Yague, and F. Ravera (2015) Overview and development status of the ExoMars rover mobility system. In ASTRA, May 2015, ESA, ESTEC, Noordwijk, the Netherlands. Available online at http://robotics.estec.esa.int/ASTRA/Astra2015/Papers/Session 1A/96038_Poulakis.pdf\nF. Poulet, J.-P. Bibring, J.F. Mustard, A. Gendrin, N. Mangold, Y. Langevin, R.E. Arvidson, B. Gondet, and C. Gomez (2005) Phyllosilicates on Mars and implications for early martian climate. Nature 438:623–627.\nF. Poulet, J. Michalski, J. Carter, M. Balme, J.L. Bishop, C. Gross, P. McGuire, A. Dumke, N. Mangold, J.E. Moersch, C. Beck, P.M. Grindrod, S. Gupta, P. Fawdon, A. Ody, and J. Audouard (2014) Mawrth Vallis. In First ExoMars Landing Site Selection Workshop, 26–28 March 2014, ESAC, Villanueva de la Cañada, Madrid.\nF. Poulet, J. Michalski, C. Gross, J. Carter, B. Horgan, M. Balme, J.L. Bishop, A. Dumke, N. Mangold, P. Fawdon, and P.M. Grindrod (2015) Mawrth rocks! (probing the early Mars habitability, climate and origin of life). In Third ExoMars Landing Site Selection Workshop, 20–21 October 2015, ESTEC, Noordwijk, the Netherlands.\nJ. Proton (2015) Viewpoint. Available online at http://www.planetarysciencecommand.com\nS. Pugh, D. Barnes, L. Tyler, M. Gunn, N. Schmitz, G. Paar, A. Bauer, C. Cousins, D. Pullan, A. Coates, A. Griffiths, and Team. the PanCam (2012) AUPE—a PanCam emulator for the ExoMars 2018 mission. In i-SAIRAS 2012: 11th International Symposium on Artificial Intelligence, Robotics and Automation in Space, 4–7 September, Turin, Italy.\nC. Quantin, J. Carter, P. Thollot, A. Ody, L. Lozach, P. Allemand, and B. Bultet (2014) Oxia Planum. In First ExoMars Landing Site Selection Workshop, 26–28 March, ESAC, Villanueva de la Cañada, Madrid.\nC. Quantin, J. Carter, P. Thollot, J. Broyer, L. Lozach, J. Davis, P. Grindrod, M. Pajola, E. Baratti, S. Rossato, P. Allemand, B. Bultel, C. Leyrat, J. Fernando, and A. Ody (2015) Oxia Planum: a suitable landing site for ExoMars 2018 Rover. EPSC Abstracts 10:EPSC2015-704.\nC. Quantin, J. Carter, P. Thollot, J. Broyer, J. Davis, P. Gringrod, M. Pajola, E. Barrati, S. Rossato, P. Allemand, B. Bultel, C. Leyrat, J. Fernando, and A. Ody (2016) Oxia Planum—the landing site for ExoMars 2018 [abstract 2863]. In 47th Lunar and Planetary Science Conference, Lunar and Planetary Institute, Houston.\nM.S. Rice, J.F. Bell, E.A. Cloutis, A. Wang, S.W. Ruff, M.A. Craig, D.T. Bailey, J.R. Johnson, P.A. de Souza, and W.H. Farrand (2010) Silica-rich deposits and hydrated minerals at Gusev Crater, Mars: vis-NIR spectral characterization and regional mapping. Icarus 205:375–395.\nF. Rull, S. Maurice, I. Hutchinson, A. Moral, C. Perez, C. Diaz, M. Colombo, T. Belenguer, G. Lopez-Reyes, A. Sansano, O. Forni, Y. Parot, N. Striebig, S. Woodward, C. Howe, N. Tarcea, P. Rodriguez, L. Seoane, A. Santiago, J.A. Rodriguez-Prieto, J. Medina, P. Gallego, R. Canchal, P. Santamaría, G. Ramos, and J.L. Vago, on behalf of the RLS team. (2017) The Raman Laser Spectrometer for the ExoMars Rover Mission to Mars. Astrobiology 17:627–654.\nJ.D. Rummel, D.W. Beaty, M.A. Jones, C. Bakermans, N.G. Barlow, P. Boston, V.F. Chevrier, B.C. Clark, J.P. de Vera, R.V. Gough, J.E. Hallsworth, J.W. Head, V.J. Hipkin, T.L. Kieft, A.S. McEwen, M.T. Mellon, J.A. Mikucki, W.L. Nicholson, C.R. Omelon, R. Peterson, E.E. Roden, B. Sherwood Lollar, K.L. Tanaka, D. Viola, and J.J. Wray (2014) A new analysis of Mars “Special Regions”: findings of the second MEPAG Special Regions Science Analysis Group (SR-SAG2). Astrobiology 14:887–968.\nV. Sautter, M.J. Toplis, R.C. Wiens, A. Cousin, C. Fabre, O. Gasnault, S. Maurice, O. Forni, J. Lasue, A. Ollila, J.C. Bridges, N. Mangold, S. Le Mouélic, M. Fisk, P.-Y. Meslin, P. Beck, P. Pinet, Deit Le, L., W. Rapin, E.M. Stolper, H. Newsom, D. Dyar, N. Lanza, D. Vaniman, S. Clegg, and J.J. Wray (2015) In situ evidence for continental crust on early Mars. Nat Geosci 8:605–609.\nU. Schmidt, T. Fiksel, A. Kwiatkowski, I. Steinbach, B. Pradarutti, K. Michel, and E. Benzi (2015) Autonomous star sensor ASTRO APS: flight experience on Alphasat. CEAS Space Journal 7:237–246.\nN. Schmitz, D. Barnes, A. Coates, A. Griffiths, E. Hauber, R. Jaumann, H. Michaelis, H. Mosebach, G. Paar, P. Reissaus, and F. Trauthan (2009) Field test of the ExoMars Panoramic Camera in the High Arctic—first results and lessons learned. In EGU General Assembly 2009, 19–24 April, Vienna, Austria, p 1062.\nS.P. Schwenzer, J.C. Bridges, R.C. Wiens, P.G. Conrad, S.P. Kelley, R. Léveillé, N. Mangold, J. Martín-Torres, A. McAdam, H. Newsom, M.P. Zorzano, W. Rapin, J. Spray, A.H. Treiman, F. Westall, A.G. Fairen, and P.-Y. Meslin (2016) Fluids during diagenesis in sediment alteration and sulfate vein formation in sediments at Gale Crater, Mars. Meteorit Planet Sci 51:2175–2202.\nK.D. Seelos, F.P. Seelos, C.E. Viviano-Beck, S.L. Murchie, R.E. Arvidson, B.L. Ehlmann, and A.A. Fraeman (2014) Mineralogy of the MSL Curiosity landing site in Gale Crater as observed by MRO/CRISM. Geophys Res Lett 41:4880–4887.\nE. Sefton-Nash, S. Gupta, M. Balme, P. Grindrod, P. Fawdon, J. Davis, P. Sidiropoulos, V. Yershov, and J.-P. Muller (2015) ExoMars 2018 rover candidate landing sites: Aram Dorsum and the Hypanis Vallis Delta. EPSC Abstracts 10:EPSC2015-684.\nN. Silva, R. Lancaster, and J. Clemmett (2013) ExoMars rover vehicle mobility functional architecture and key design drivers. In 12th Symposium on Advanced Space Technologies in Automation and Robotics (ASTRA-2013), ESA, ESTEC, Noordwijk, the Netherlands. Available online at robotics.estec.esa.int/ASTRA/Astra2013/Papers/silva_2811301.pdf\nM.D. Smith, M.J. Wolff, N. Spanovich, A. Ghosh, D. Banfield, P.R. Christensen, G.A. Landis, and S.W. Squyres (2006) One martian year of atmospheric observations using MER Mini-TES. J Geophys Res: Planets 111, doi:\n10.1029/2006JE002770\n.\nP.H. Smith, M.G. Tomasko, D. Britt, D.G. Crowe, R. Reid, H.U. Keller, N. Thomas, F. Gliem, P. Rueffer, R. Sullivan, R. Greeley, J.M. Knudsen, M.B. Madsen, H.P. Gunnlaugsson, S.F. Hviid, W. Goetz, L.A. Soderblom, L. Gaddis, and R. Kirk (1997) The imager for Mars Pathfinder experiment. J Geophys Res 102, doi:\n10.1029/96JE03568\n.\nS.W. Squyres, O. Aharonson, B.C. Clark, B.A. Cohen, L. Crumpler, P.A. de Souza, W.H. Farrand, R. Gellert, J. Grant, J.P. Grotzinger, A.F.C. Haldemann, J.R. Johnson, G. Klingelhöfer, K.W. Lewis, R. Li, T. McCoy, A.S. McEwen, H.Y. McSween, D.W. Ming, J.M. Moore, R.V. Morris, T.J. Parker, J.W. Rice, S. Ruff, M. Schmidt, C. Schröder, L.A. Soderblom, and A. Yen (2007) Pyroclastic activity at Home Plate in Gusev Crater, Mars. Science 316:738–742.\nK.M. Stack (2015) Reconstructing past depositional and diagenetic processes through quantitative stratigraphic analysis of the martian sedimentary rock record. PhD thesis, Caltech, Pasadena, CA.\nK.M. Stack, J.P. Grotzinger, S. Gupta, L.C. Kah, K.W. Lewis, M.J. McBride, M.E. Minitti, D.M. Rubin, J. Schieber, D.Y. Sumner, L.M. Thompson, J. Van Beek, A.R. Vasavada, and R.A. Yingst (2015) Sedimentology and stratigraphy of the Pahrump Hills Outcrop, Lower Mount Sharp, Gale Crater, Mars [abstract 1994]. In 46th Lunar and Planetary Science Conference, Lunar and Planetary Institute, Houston.\nK.M. Stack, C.S. Edwards, J.P. Grotzinger, S. Gupta, D.Y. Sumner, F.J. Calef, L.A. Edgar, K.S. Edgett, A.A. Fraeman, S.R. Jacob, Deit Le, L., K.W. Lewis, M.S. Rice, D.M. Rubin, R.M.E. Williams, and K.H. Williford (2016) Comparing orbiter and rover image-based mapping of an ancient sedimentary environment, Aeolis Palus, Gale Crater, Mars. Icarus 280:3–21.\nA. Steele, H.E.F. Amundsen, P. Conrad, L. Benning, and the AMASE 2009 team. (2010) Arctic Mars Analogue Svalbard Expedition (AMASE) 2009 [abstract 2398]. In 46th Lunar and Planetary Science Conference, Lunar and Planetary Institute, Houston.\nP.M. Stella, R.C. Ewell, and J.J. Hoskin (2005) Design and performance of the MER (Mars Exploration Rovers) solar arrays. In Conference Record of the Thirty-First IEEE Photovoltaic Specialists Conference, IEEE, Piscataway, NJ, pp 626–630.\nT. Szabó, G. Domokos, J.P. Grotzinger, and D.J. Jerolmack (2015) Reconstructing the transport history of pebbles on Mars. Nat Commun 6, doi:\n10.1038/ncomms9366\n.\nY. Tao, J.-P. Muller, and W. Poole (2016) Automated localisation of Mars rovers using co-registered HiRISE-CTX-HRSC orthorectified images and wide baseline Navcam orthorectified mosaics. Icarus 280:139–157.\nN.A. Teanby, P.G.J. Irwin, Kok De, R., S. Vinatier, B. Bézard, C.A. Nixon, F.M. Flasar, S.B. Calcutt, N.E. Bowles, L. Fletcher, and C. Howett (2007) Vertical profiles of HCN, HC3N, and C2H2 in Titan's atmosphere derived from Cassini/CIRS data. Icarus 186:364–384.\nI.L. ten Kate (2010) Organics on Mars? Astrobiology 10:589–603.\nN. Thomas, W.J. Markiewicz, R.M. Sablotny, M.W. Wuttke, H.U. Keller, J.R. Johnson, R.J. Reid, and P.H. Smith (1999) The color of the martian sky and its influence on the illumination of the martian surface. J Geophys Res 104:8795–8808.\nD.V. Titov, W.J. Markiewicz, N. Thomas, H.U. Keller, R.M. Sablotny, M.G. Tomasko, M.T. Lemmon, and P.H. Smith (1999) Measurements of the atmospheric water vapor on Mars by the imager for Mars Pathfinder. J Geophys Res 104, doi:\n10.1029/1998JE900046\n.\nA.H. Treiman, D.L. Bish, D.T. Vaniman, S.J. Chipera, D.F. Blake, D.W. Ming, R.V Morris, T.F. Bristow, S.M. Morrison, M.B. Baker, E.B. Rampe, R.T. Downs, J. Filiberto, A.F. Glazner, R. Gellert, L.M. Thompson, M.E. Schmidt, Deit Le, L., R.C. Wiens, A.C. McAdam, C.N. Achilles, K.S. Edgett, J.D. Farmer, K.V Fendrich, J.P. Grotzinger, S. Gupta, J.M. Morookian, M.E. Newcombe, M.S. Rice, J.G. Spray, E.M. Stolper, D.Y. Sumner, A.R. Vasavada, and A.S. Yen (2016) Mineralogy, provenance, and diagenesis of a potassic basaltic sandstone on Mars: CheMin X-ray diffraction of the Windjana sample (Kimberley area, Gale Crater). J Geophys Res: Planets 121, doi:\n10.1002/2015JE004932\n.\nR. Tsai (1987) A versatile camera calibration technique for high-accuracy 3D machine vision metrology using off-the-shelf TV cameras and lenses. IEEE Journal on Robotics and Automation 3.4:323–344.\nJ. Vago (2012, October 11) Rover Reference Surface Mission Table. Issue 7.0.\nJ.L. Vago, L. Lorenzoni, F. Calantropio, and A.M. Zashchirinskiy (2015) Selecting a landing site for the ExoMars 2018 mission. Solar System Research 49:538–542.\nJ.L. Vago, F. Westall, Pasteur Instrument Teams (A.J. Coates, R. Jaumann, O. Korablev, V. Ciarletti, I. Mitrofanov, J.-L. Josset, M.C. De Sanctis, J.-P. Bibring, F. Rull, F. Goesmann, H. Steininger, W. Goetz, W. Brinckerhoff, C. Szopa, and F Raulin.); Landing Site Selection Working Group (F. Westall, H.G.M. Edwards, L.G. Whyte, A.G. Fairén, J.-P. Bibring, J. Bridges, E. Hauber, G.G. Ori, S. Werner, D. Loizeau, R.O. Kuzmin, R.M.E. Williams, J. Flahaut, F. Forget, J.L. Vago, D. Rodionov, O. Korablev, H. Svedhem, E. Sefton-Nash, G. Kminek, L. Lorenzoni, L. Joudrier, V. Mikhailov, A. Zashchirinskiy, F. Calantropio, A. Merlo, P. Poulakis, O. Witasse, O. Bayle, and S Bayón.); other contributors (U. Meierhenrich, J. Carter, J.M. García-Ruiz, P. Baglioni, A. Haldemann, A.J. Ball, A. Debus, R. Lindner, F. Haessig, D. Monteiro, R. Trautner, C. Voland, P. Rebeyre, D. Goulty, F. Didot, S. Durrant, E. Zekri, G. Visentin, M. Azkarate, M. Zwick, C Carreau. and the ExoMars Project Team). (2017) Habitability on early Mars and the search for biosignatures with the ExoMars rover. Astrobiology 17:471–510.\nJ.A. Watkins, J. Grotzinger, N. Stein, S.G. Banham, S. Gupta, D. Rubin, K.M. Stack, and K.S. Edgett (2016) Paleotopography of erosional unconformity, base of Stimson Formation, Gale Crater, Mars [abstract 2939]. In 47th Lunar and Planetary Science Conference, Lunar and Planetary Institute, Houston.\nC.R. Webster, P.R. Mahaffy, G.J. Flesch, P.B. Niles, J.H. Jones, L.A. Leshin, S.K. Atreya, J.C. Stern, L.E. Christensen, T. Owen, H. Franz, R.O. Pepin, Steele, A.; Team. the MSL Science (2013) Isotope ratios of H, C, and O in CO2 and H2O of the martian atmosphere. Science 341:260–263.\nF. Westall, F. Foucher, N. Bost, M. Bertrand, D. Loizeau, J.L. Vago, G. Kminek, F. Gaboyer, K.A. Campbell, J.-G. Bréhéret, P. Gautret, and C.S. Cockell (2015) Biosignatures on Mars: what, where, and how? Implications for the search for martian life. Astrobiology 15:998–1029.\nR.M.E. Williams, J.P. Grotzinger, W.E. Dietrich, S. Gupta, D.Y. Sumner, R.C. Wiens, N. Mangold, M.C. Malin, K.S. Edgett, S. Maurice, O. Forni, O. Gasnault, A. Ollila, H.E. Newsom, G. Dromart, M.C. Palucis, R.A. Yingst, R.B. Anderson, K.E. Herkenhoff, Mouélic Le, S., W. Goetz, M.B. Madsen, A. Koefoed, J.K. Jensen, J.C. Bridges, S.P. Schwenzer, K.W. Lewis, K.M. Stack, D. Rubin, L.C. Kah, J.F. Bell, III, J.D. Farmer, R. Sullivan, T. Van Beek, D.L. Blaney, O. Pariser, R.G. Deen; Team. MSL Science (2013) Martian fluvial conglomerates at Gale Crater. Science 340:1068–1072.\nM. Winter, C. Barcaly, V. Pereira, R. Lancaster, M. Caceres, N.B. McManamon, N. Silva, D. Lachat, and M. Campana (2015) ExoMars Rover vehicle: detailed description of the GNC system. In ASTRA, May 2015, ESA, ESTEC, Noordwijk, the Netherlands.\nM.J. Wolff, M.D. Smith, R.T. Clancy, N. Spanovich, B.A. Whitney, M.T. Lemmon, J.L. Bandfield, D. Banfield, A. Ghosh, G. Landis, and P.R. Christensen (2006) Constraints on dust aerosols from the Mars Exploration Rovers using MGS overflights and Mini-TES. J Geophys Res 111, doi:\n10.1029/2006JE002786\n.\nR.A. Yingst, K. Cropper, S. Gupta, L.C. Kah, R.M.E. Williams, J. Blank, F. Calef, V.E. Hamilton, K. Lewis, J. Shechet, M. McBride, N. Bridges, J. Martinez Frias, and H. Newsom (2016) Characteristics of pebble and cobble-sized clasts along the Curiosity rover traverse from sol 100 to 750: terrain types, potential sources, and transport mechanisms. Icarus 280:72–92.\nAbbreviations Used\nUsers who read this article also read\n \nHabitability on Early Mars and the Search for Biosignatures with the ExoMars Rover\nJorge L. Vago , Frances Westall , Pasteur Instrument Teams, Landing Site Selection Working Group, and Other Contributors , Andrew J. Coates , Ralf Jaumann , Oleg Korablev , Valérie Ciarletti , Igor Mitrofanov , Jean-Luc Josset , Maria Cristina De Sanctis , Jean-Pierre Bibring , Fernando Rull , Fred Goesmann , Harald Steininger , Walter Goetz , William Brinckerhoff , Cyril Szopa , François Raulin , Frances Westall , Howell G. M. Edwards , Lyle G. Whyte , Alberto G. Fairén , Jean-Pierre Bibring , John Bridges , Ernst Hauber , Gian Gabriele Ori , Stephanie Werner , Damien Loizeau , Ruslan O. Kuzmin , Rebecca M. E. Williams , Jessica Flahaut , François Forget , Jorge L. Vago , Daniel Rodionov , Oleg Korablev , Håkan Svedhem , Elliot Sefton-Nash , Gerhard Kminek , Leila Lorenzoni , Luc Joudrier , Viktor Mikhailov , Alexander Zashchirinskiy , Sergei Alexashkin , Fabio Calantropio , Andrea Merlo , Pantelis Poulakis , Olivier Witasse , Olivier Bayle , Silvia Bayón , Uwe Meierhenrich , John Carter , Juan Manuel García-Ruiz , Pietro Baglioni , Albert Haldemann , Andrew J. Ball , André Debus , Robert Lindner , Frédéric Haessig , David Monteiro , Roland Trautner , Christoph Voland , Pierre Rebeyre , Duncan Goulty , Frédéric Didot , Stephen Durrant , Eric Zekri , Detlef Koschny , Andrea Toni , Gianfranco Visentin , Martin Zwick , Michel van Winnendael , Martín Azkarate , Christophe Carreau , the ExoMars Project Team\nAstrobiology. Jul 2017: 471-510.\n""","0.086770475","""http://online.liebertpub.com/doi/10.1089/ast.2016.1548""",
"""University_of_Liverpool""","""Speed Sensorless Induction Motor Drive Control for Electric Vehicles  - The University of Liverpool Repository""","""The University of Liverpool Repository\nSpeed Sensorless Induction Motor Drive Control for Electric Vehicles\nRind, SJ (2017) Speed Sensorless Induction Motor Drive Control for Electric Vehicles. PhD thesis, University of Liverpool.\nText\nDownload (6MB)\nAbstract\nFast diminishing fossil fuel resources, deterioration in air quality and concerns for environmental protection, continuously promote the interest in the research and development of Alternative Energy Vehicles (AEVs). Traction motor drive is an integral part and common electric propulsion system in all kinds of AEVs. It plays an utmost significant role in the development of electrified transport industry. Application of Induction Motor (IM) drive is not only limited to the domestic and industrial applications but also has an ubiquitous influence in the modern electrified transport sector. IM is characterized by a simple and rugged structure, operational reliability, low maintenance, low cost, ability to operate in a hostile environment and high dynamic performance. However, IM is one of the widely accepted choices by Electric Vehicles (EVs) manufacturer. At present, Variable speed IM drive is almost replacing the traditional DC motor drive in a wide range of applications including EVs where a fast dynamic response is required. It became possible after the technological advancement and development in the field of power switching devices, digital signal processing and recently intelligent control systems have led to great improvements in the dynamic performance of traction drives. Speed Sensorless control strategies offer better system’s reliability and robustness and reduce the drive cost, size and maintenance requirements. Sensorless IM drives have been applied on medium and high speed applications successfully. However, instability at low speed and under different load disturbance conditions are still a critical problem in this research field and has not been robustly achieved. Some application such as traction drives and cranes are required to maintain the desired level of torque down to low speed levels with uncertain load torque disturbance conditions. Speed and torque control is more important particularly in motor-in-wheel traction drive train configuration EVs where vehicle wheel rim is directly connected to the motor shaft to control the speed and torque. The main purpose of this research is to improve the dynamic performance of conventional proportional-integral controller based model reference adaptive system (PI-MRAS) speed observer by using several speed profiles under different load torque disturbance conditions, which is uncertain during the whole vehicle operation apart from the vehicle own load. Since, vehicle has to face different road conditions and aerodynamic effects which continuously change the net load torque effect on the traction drive. This thesis proposes different novel methods based on the fuzzy logic control (FLC) and sliding mode control (SMC) with rotor flux MRAS. Numerous simulations and experimental tests designed with respect to the EV operation are carried out to investigate the speed estimation performance of the proposed schemes and compared with the PI-MRAS speed observer. For simulation and experimental purpose, Matlab-Simulink environment and dSPACE DS-1104 controller board are used respectively. The results presented in this thesis show great performance improvements of the proposed schemes in speed estimation & load disturbance rejection capability and provide a suitable choice of speed sensoless IM drive control for EVs with cost effectiveness.\nItem Type:\n""","0.62840366","""https://livrepository.liverpool.ac.uk/3008062/""","[-2.96826,53.408471]"
"""StaffCambridgeUniversityEngineering""","""A new, fast response CO2 sensor - CUED Publications database""","""CUED Publications database\nA new, fast response CO2 sensor\nSutela, C and Hands, T and Collings, N (2000) A new, fast response CO2 sensor. 312-.\nFull text not available from this repository.\nAbstract\nThe inability of emissions reduction methods to meet upcoming legislation without an unacceptable increase in vehicle cost is a major problem of automobile manufacturer. This work aims to develop a cost-effective reduction of automobile emissions. A prototype CO 2 sensor with 5 msec response time was built and bench tested, then used on an engine. The sensor design was based on standard emissions measurement technology using non-dispersive IR absorption. An improved sensor has now been completed with significant improvements in terms of signal to noise ratio and long-term stability. The improved sensor will be used to measure CO 2 concentrations on three different engines. The results will then be used to validate engine and catalyst models and to propose control strategies aimed at reducing overall emissions. A brief description of the sensor itself was presented. Original is an abstract.\nItem Type:\n""","0.8308315","""http://publications.eng.cam.ac.uk/345176/""",
"""Queen's_University_Belfast""","""A Conventional Internal Combustion Engine Versus a Range Extended Electric Vehicle Under the Current Regulatory Regime in the United Kingdom - Queen's University Belfast Research Portal - Research Directory & Institutional Repository for QUB""","""A Conventional Internal Combustion Engine Versus a Range Extended Electric Vehicle Under the Current Regulatory Regime in the United Kingdom\nResearch output: Contribution to conference › Paper\nPublished\nView graph of relations\nTransport accounts for 22% of greenhouse gas emissions in the United Kingdom and cars are expected tomore than double by 2050. Car manufacturers are continually aiming for a substantially reduced carbonfootprint through improved fuel efficiency and better powertrain performance due to the strict EuropeanUnion emissions standards. However, road tax, not just fuel efficiency, is a key consideration of consumerswhen purchasing a car. While measures have been taken to reduce emissions through stricter standards, infuture, alternative technologies will be used. Electric vehicles, hybrid vehicles and range extended electricvehicles have been identified as some of these future technologies. In this research a virtual test bed of aconventional internal combustion engine and a range extended electric vehicle family saloon car were builtin AVL’s vehicle and powertrain system level simulation tool, CRUISE, to simulate the New EuropeanDrive Cycle and the results were then soft-linked to a techno-economic model to compare the effectivenessof current support mechanisms over the full life cycle of both cars. The key finding indicates that althoughcarbon emissions are substantially reduced, switching is still not financially the best option for either theconsumer or the government in the long run.\nOriginal language\n""","0.80789256","""http://pure.qub.ac.uk/portal/en/publications/a-conventional-internal-combustion-engine-versus-a-range-extended-electric-vehicle-under-the-current-regulatory-regime-in-the-united-kingdom(03198126-2cdf-4adc-9de1-c6ca0ec29aa2).html""","[-5.934759,54.583863]"
"""UCL""","""Iris Publication""","""http://discovery.ucl.ac.uk/1458907/\nAbstract\n© 2013 John Wiley & Sons, Ltd. This paper presents an empirical assessment of urban traffic congestion in Central London, UK. Compared with freeways or motorways, urban networks are relatively less studied because of its complexity and availability of required traffic data. This paper introduces the use of automatic number plate recognition technology to analyze the characteristic of urban traffic congestion in Central London. We also present the use of linear regression to diagnose the observed congestion and attribute them to different causes. In particular, we distinguish the observed congestion into two main components: one due to recurrent factors and the other due to nonrecurrent factors. The methodologies are illustrated through a case study of Central London Area. It is found that about 15% of the observed congestion in the region is due to nonrecurrent factors such as accidents, roadwork, special events, and strikes. Given the significance of London, the study will be valuable for transport policy evaluation and appraisal in other global cities.\nPublication data is maintained in RPS. Visit https://rps.ucl.ac.uk\n› More search options\n""","1.1258848","""http://iris.ucl.ac.uk/iris/publication/1000161/7""",
"""University_of_Bristol""","""Evolving Spiking Networks with Variable Resistive Memories | Evolutionary Computation | MIT Press Journals""","""Evolving Spiking Networks with Variable Resistive Memories\nArticle navigation\nAltmetric\nabout article usage data:\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean euismod bibendum laoreet. Proin gravida dolor sit amet lacus accumsan et viverra justo commodo. Proin sodales pulvinar tempor. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus.\nEvolving Spiking Networks with Variable Resistive Memories\nVolume 22 |           Issue 1 |          Spring 2014\np.79-103\nAbstract\nSection:\nNeuromorphic computing is a brainlike information processing paradigm that requires adaptive learning mechanisms. A spiking neuro-evolutionary system is used for this purpose; plastic resistive memories are implemented as synapses in spiking neural networks. The evolutionary design process exploits parameter self-adaptation and allows the topology and synaptic weights to be evolved for each network in an autonomous manner. Variable resistive memories are the focus of this research; each synapse has its own conductance profile which modifies the plastic behaviour of the device and may be altered during evolution. These variable resistive networks are evaluated on a noisy robotic dynamic-reward scenario against two static resistive memories and a system containing standard connections only. The results indicate that the extra behavioural degrees of freedom available to the networks incorporating variable resistive memories enable them to outperform the comparative synapse types.\n© 2014 Massachusetts Institute of Technology\n1  Introduction\nSection:\nNeuromorphic computing (NC; Mead, 1990 ) is a bio-inspired paradigm concerned with emulating brainlike functionality within artificial systems. Typical NC involves the use of a physical network composed of neurons (e.g., CMOS; Rabaey, 1996 ) that are interconnected by a dense web of nanoscale synapses. Resistive memories (RMs; Waser and Aono, 2007 ) are synapse-candidate devices—typically metal-insulator-metal—that can be induced to switch to one of several resistances through application of an appropriate voltage. They can be manufactured at the nanoscale and provide a nonvolatile memory whereby the state (resistance) of the device can vary depending on its activity. Nonvolatile memory faciliates low-heat, low-power storage (Ho et al., 2009 ), alleviating typical nanoscale concerns such as power usage and heat dissipation. A context-sensitive dynamic internal state allows synapse-like information processing. We categorise RMs as either resistive switching memories (RSMs; Waser and Aono, 2007 ) or memristors (memory-resistors; Chua, 1971 ) depending upon their characteristic behaviour. RSMs allow switching between (usually two) discrete resistance states, whereas memristors permit gradual traversal of a nonlinear resistance profile.\nNC requires some form of in-trial learning to harness the computational power of the network—typically a form of Hebbian learning (Hebb, 1949 ) is used to realise spike time dependent plasticity (STDP; Kistler, 2002 ). RM synapses alter their efficacy during the lifetime of the network, depending on the activity of the neurons they are connected to. The Hebbian mechanism is coupled with a neuro-evolutionary model that allows network topologies to be modified during the application of a genetic algorithm (GA; Holland, 1975 ). Self-adaptive search parameters are shown to provide a flexible learning architecture which may be especially beneficial given the autonomous nature of NC.\nA variable RM, the focus of this study, is an RM whose STDP response can be tuned by evolution, potentially imparting a variety of adaptive behaviours to the networks. Previous studies (Howard et al., 2012 ) have indicated that fixed STDP profiles can be exploited by evolution and cast into specific roles, such as facilitating or depressing synapses, with synaptic role based on STDP response—it follows that more varied responses may permit more finely-tuned behaviours within the networks.\nThe computational properties of two types of variable RM—memristor and RSM—are analysed when cast as synapses in evolutionary spiking neural networks (SNNs; Gerstner and Kistler, 2002 ). Our hypothesis is that the additional degrees of functional freedom afforded to the variable RM networks can be harnessed by the evolutionary process. To test this hypothesis, the variable memristor and variable RSM networks are compared to networks composed of (1) PEO-PANI memristors (Erokhin and Fontana, 2008 ), (2) HP memristors (Strukov et al., 2008 ), and (3) constant, non-plastic connections. A dynamic simulated robotics navigation task is selected for this purpose. To our knowledge, this is the first approach that allows for the self-adaptation of the characteristic performance of the RMs alongside neuroevolution of both neurons and connection structure.\n2  Background\nSection:\n2.1  Spiking Networks\nSNNs present a phenomenological model of neural activity in the brain. In an SNN, neurons are linked via unidirectional, weighted connections. Each neuron has a measure of excitation, or membrane potential, and communicates via the voltage spike, or action potential. A neuron spikes when its membrane potential exceeds some threshold, which typically requires a cluster of incoming spikes arriving within a short time period. A spike emitted from a neuron is received by all connected postsynaptic neurons.\nAs the membrane potential may be considered a form of memory, such networks are able to produce temporally dynamic activation patterns, which potentially allows for increased computing power (Maass, 1996 ; Saggie-Wexler et al., 2006 ) when considering temporal problems (e.g., robotics, time series analysis), compared to “stateless” network models such as the multi layer perceptron (Rumelhart and McClelland, 1986 ; although continuous time recurrent neural networks can use internal dynamics to the same effect, e.g., Blynel and Floreano, 2003 ). SNNs are preferred because the voltage spike is an efficient medium of communication when compared to traditional schemes where voltage is constantly applied to a connection. The benefits of such a scheme—low-heat, low-power communication—are heightened when coupled with nonvolatile synapses (such as the RMs used herein), as sparse pulse-based encoding schemes may be envisioned.\nTwo well-known formal SNN implementations are the leaky integrate and fire (LIF) model and the spike response model (SRM; Gerstner and Kistler, 2002 ). Neuro-evolution applies evolutionary techniques to alter the topology/weights of neural networks. Floreano et al. ( 2008 ) survey various methods for evolving both weights and architectures. Nolfi and Floreano ( 2000 ) describe the evolution of networks for robotics tasks.\n2.2  Resistive Memories\nNumerous RMs have been previously manufactured from a plethora of materials—Akinaga and Shima ( 2010 ) provide a summary. RSMs are predominantly metal oxides (HfO2, Cu2O, ZnO, ZrO2, TiO2). Memristor materials are more varied, and include conductive polymers (Erokhin and Fontana, 2008 ), metal silicides (Jo et al., 2010 ), and crystalline oxides (Doolittle et al., 2009 ) in addition to certain metal oxides.\nOne popular theory, espoused by Waser and Aono ( 2007 ), states that the resistance profiles of both types of RM are considered to be the result of the appearance of filaments in the substrate, which may arise due to material defects or conditions during synthesis. Filaments are conductive pathways through the material that allow electrons to flow through them. In our taxonomy, memristors, as shown in Figure 1 (a), do not form complete filaments, giving rise to the characteristic nonlinear I-V curves of these devices as other mechanisms (such as ionic conductivity) play a more prominent role in electron transport, as shown in Figure 1 (b). Complete filament formation occurs in the case of RSMs, as shown in Figure 1 (c), which results in ohmic I-V profiles, as shown in Figure 1 (d). This distinction is not universal (e.g., under specific conditions an RSM may act like memristor, and vice versa).\nFigure 1: (a) Incomplete filament formation (memristor)—as there are no complete filaments, ionic conductivity gives rise to (b) generalised HP memristor I-V curve, (c) complete filament formation (RSM); dark lines show complete filaments, (d) generalised RSM I-V curve, dashed line showing a possible current compliance. The steeper gradient is the LRS, the shallower is the HRS.\n2.2.1  Memristors\nThe memristor, a class of RM theoretically characterized by Chua ( 1971 ), has recently enjoyed a resurgence of interest after being manufactured from titanium oxide by HP labs (Strukov et al., 2008 ). Memristors are the fourth fundamental circuit element, joining the capacitor, inductor, and resistor. Like RSMs, memristors can be operated as binary switches; we forgo this method of operation and use the memristor as an analogue device capable of incremental resistance alteration.\nAs filaments are not formed, some other conductivity mechanism is used instead; in this case ionic conductivity gives rise to the nonlinear I-V curve seen in Figure 1 (d). An explanatory model of the titanium dioxide device can be seen in Figure 2 . Here, the memristor is modeled as two variable resistors Ron and Roff. The instantaneous resistance of the device can be attributed to the position of the boundary between Ron (which is doped with oxygen vacancies, on charge carriers, and therefore has low resistance) and Roff (which displays higher resistance). Charge flowing through the memristor in a given direction causes the oxygen vacancies to migrate in that direction, moving the boundary between Ron and Roff and altering the resistance of the device. Nonvolatility arises due to the chemical nature of the mechanism; Strukov et al. ( 2008 ) provide more details.\nFigure 2: Generalised memristor model shown as two resistors whose boundary, and hence final resistance, varies depending on the polarity of the input charge. Resistor Ron contains oxygen vacancies (black dots), which act as charge carriers, and possesses low resistance; resistor Roff has no vacancies and a high resistance. From an initial boundary position (Centre), charge flowing from the positive terminal to negative terminal causes the vacancies to percolate towards the negative terminal (Right), increasing the size of Ron which decreases the resistance of the device. The opposite is true for charge flowing from the negative to the positive port (Left).\nFormally, a memristor is a passive two-terminal electronic device that is described by the relation between the device terminal voltage v, terminal current i (which is related to the charge q transferred onto the device), and magnetic flux\n, as Equation ( 1 ) shows. Resistance can be made to increase or decrease depending on the polarity of the voltage. The nonvolatile resistance, M, is a nonlinear function of the charge as shown in Equation ( 2 ).\n(1)\n(2)\nPrevious applications of memristors within neural paradigms are ubiquitous: Titanium dioxide memristors (Strukov et al., 2008 ) have been used in the manufacture of nanoscale neural crossbars (Snider, 2005 ), and silver silicide memristors have been shown to function in neural architectures (Jo et al., 2010 ). Other successful applications include the modelling of learning in amoeba (Pershin et al., 2009 ), as well as pattern recognition by crossbar circuits for robotic control (Mouttet, 2009 ). In particular, Mouttet ( 2009 ) highlights the attractive prospect of applying evolutionary computation techniques directly to memristive hardware, as memristors can simultaneously perform the functions of both processor and memory.\n2.2.2  Resistive Switching Memories\nAs their nomenclature implies, RSMs are typically used as a bistable resistive switch; pulsing with a voltage over some threshold transfers the device from an initial low-resistance state (LRS) to a high-resistance state (HRS). Successive voltage pulses can then be used to switch between these states; the amount of voltage required depends on the physical properties of the device. RSMs are typically metal-insulator-metal devices that are composed of an ion-conducting semiconductor sandwiched between two layers of metal. Electroforming creates complete filaments, which provide ohmic conductance in the LRS. Driving over a threshold voltage breaks these filaments and transfers the device to the HRS. A further voltage spike (usually in conjuction with a current compliance to protect the device) reforms these filaments and reinstates the LRS—see Figure 1 (c)–(d). RSMs follow Equations ( 1 ) and ( 2 ), under the proviso that M is now a linear function of charge. RSMs are not sensitive to the polarity of voltage used. Examples of RSMs are confined to binary operation, for example, as resistive random access memory (Akinaga and Shima, 2010 ; Hosoi et al., 2006 ), although neural implementations exist (Xia et al., 2005 ).\n2.3  Synaptic Plasticity\nHebbian learning (Hebb, 1949 ) is thought to account for adaptation and learning in the brain. Briefly, Hebbian learning states that “neurons that fire together, wire together”—in other words, in the event that a presynaptic neuron causes a postsynaptic neuron to fire, the synaptic strength between those two neurons increases so that such an event is more likely to happen in the future. Such a mechanism allows for self-organising, correlated activation patterns.\nSpike time dependent plasticity (STDP; Kistler, 2002 ) was originally formulated as a way of implementing Hebbian learning within computer-based neural networks. Interestingly, the STDP equation has been found to have distinct similarities to the reality of Hebbian learning in biological synapses (Bi and Poo, 1998 ). It has recently been postulated that a memristance-like mechanism affects synaptic efficacy in biological neural networks (Linares-Barranco and Serrano-Gotarredona, 2009 ), based on similarities between memristive equations and their neural counterparts. Querlioz et al. ( 2011 ) have recently shown that memristive STDP can be made to mitigate device variations that are currently intrinsic to hardware memristor realisation.\nTypically when implementing STDP with RMs of both kinds, a bidirectional voltage spike is emitted by a neuron whose membrane potential exceeds some threshold. Bidirectional spikes are a necessity as they allow the temporal coincidence of spikes across a synapse to be tracked. The spike can be approximated by either a continuous (Afifi et al., 2009 ; Linares-Barranco and Serrano-Gotarredona, 2009 ) or discrete (Jo et al., 2010 ; Snider, 2008 ) waveform through time, which is transmitted to all synapses that the neuron is connected to (presynaptic or postsynaptic). In the case of memristors, if the instantaneous voltage across a synapse surpasses some threshold—typically when the waveforms sufficiently overlap—the conductance of the synapse changes. For RSMs, multiple consecutive voltage spikes of a given polarity within a short time frame are required to switch the device from one state to the other. Note that this removes the element of biological realism from RSM STDP while providing a fast-switching binary behaviour.\nThe notion that varied plastic behaviours could be combined in a single network is an attractive one from a computing perspective, as more functional degrees of freedom may be afforded to the synapses. Additionally, certain synaptic behaviours may be more beneficial than others in certain positions within the network. Integration of neuroevolution with heterogeneous neuromoduation rules is investigated by Soltoggio ( 2008 ), and has been extended to robot controllers (Durr et al., 2008 ). Increased behavioural diversity (and high-quality pathfinding in the latter case) is reported. Probabilistic spike emission, which is governed by modulatory Hebbian rules, has also been investigated (Maass and Zador, 1999 ). The authors show a biologically-plausible mechanism capable of computing with short spike trains where the population of synapses display heterogeneous probabilities of transmitting/blocking a spike. Urzelai and Floreano ( 2001 ) present a nodes-only encoding scheme where synapses are affected by four versions of the Hebb rule, which generates pathfinding behaviour online from initially random actions. Synaptic weights are not evolved; instead, evolution is performed on the rules which govern how synapses react to STDP. High adaptability to new environments is evidenced. Since synaptic strength is not directly modelled and all synapses at a given node display homogenous STDP behaviour, it is unclear how to transition such a scheme to memristive/hardware implementations. Howard et al. ( 2012 ) used memristive STDP to vary the behaviour of a synapse (and therefore the network) during a trial. In this study, we extend this concept to allow for variable RMs of both types, whereby the STDP response of the synapse can be tailored by evolution to suit its role within the network.\n2.4  Viability of a Variable Resistive Memory\nConceptually, a variable RM can be seen as a nonvolatile, low power, and behaviourally diverse synapse candidate for neuromorphic hardware. A lingering question is then: How do we know that variable RMs are physically realisable? Although the field is very much in its infancy, there are a number of reasons to believe that the networks produced will have a physical analog.\nThe STDP response of the memristors can be encapsulated in a “physical properties” parameter, where changing this parameter varies the behaviour of the synapse. The memristor physical properties parameter\n(first used by Howard et al., 2012 ; derived from the original equations by Strukov et al., 2008 ) is given as\n, where\nis the mobility of oxygen vacancies and D is the device thickness in nanometres. Gale ( 2012 ) presents a more detailed model, which indicates that varying the electrode size also affects memristance, and has some experimental verification (Gale, de Lacy Costello, et al., 2012 ). Due to the relationship between\nand D, it can be inferred that a smaller D will generate a larger memristive effect: as memristiance is more pronounced at smaller scales, many memristive devices are therefore likely to be manufactured at compatible (nano) scales. As\nwas originally derived from modelling of physical devices,\nvalues in the range of those proposed in this article are potentially viable. Variations of a small D can also create a greater potential variance in\nfor a given\n, meaning that the amount of synaptic variance available to any newly-found memristor is predicted to increase with increasing miniturisation. Finally, the sizes of D given for current memristor models predict a scale that is small enough to permit sufficient synaptic density for neuromorphic hardware implementations—equivalent to that found in the human brain.\nAnother possible method of varying the STDP response of a memristor requires irradiation by an ion beam, as described by Vujisic et al. ( 2010 ). Simulations of irradiated titanium dioxide memristors were found to possess a lower oxygen vacancy mobility (\n) and reduced resistance in the doped region (Ron). Additionally, selective bombardment of specific synapses could alter synaptic behaviour in an online manner, although the precise method of targeted radiation delivery would depend upon the physical structure of the network. Advantages of this approach include online behaviour modification, the ability to elicit varied STDP responses from a homogenous group of memristors postfabrication, and potentially including this mechanism as part of a feedback loop during evolution.\nRSMs could be adapted in a similar manner to\n, where varying the device would in this case change its switching sensitivity. As RSMs can be made from titanium dioxide, they are also candidates for control via irradiation (Vujisic et al., 2010 ). A benefit of the physical properties parameter is that, as it is implicitly grounded in reality, the dimensions of the RM corresponding to a given parameter value can be calculated and used as a best fit for reconstructing simulated networks with available hardware devices. This is especially pertinent as our research group is capable of creating and profiling both types of RM (Gale, Pearson et al., 2012 ).\nIn summary, (1) RMs are suitable synapse candidates, (2) STDP is a popular means to achieving learning within RM spiking networks, and (3) motivation for researching a variable RM has been given.\n3  The System\nSection:\nThe system consists of 100 SNNs which are evaluated on a robotics test problem, and altered via a steady-state GA. Each experiment lasts for 1,000 evolutionary generations; two new networks are created and trialled on the test problem per generation. Each trial consists of 8,000 time steps, which begin with the reading of sensory information and calculation of action, and end with the agent performing that action. Every time step comprises 21 steps of SNN processing, at the end of which the action is calculated. The state of the system was sampled every 20 generations and used to create the results. Results were averaged over 30 experimental repeats.\n3.1  Control Architecture\nSpiking network implementation is based on the LIF model. Neurons are arranged into a three-layer (input, hidden, output) network without recurrency but with hidden-hidden neuron connectivity. Each neuron has a membrane potential y>0 which slowly degrades over time, and can be modified either by an external current or by spikes received from presynaptic neurons. As spikes are received by the neuron, the value of y is increased in the case of an excitatory spike, or decreased if the spike is inhibitory. If y surpasses a positive threshold\nthe neuron spikes and transmits an action potential to every neuron to which it is presynaptic, with strength relative to the synaptic weight between those two neurons. The neuron then resets its membrane potential to prevent oversaturation; for a given neuron, y at time t is given as in Equation ( 3 )\n(3)\n(4)\nEquation ( 4 ) shows the reset formula. Here, y(t) is the membrane potential at time t, I is the input current to the neuron, a is a positive constant, b is the degradation (leak) constant and c is the reset membrane potential of the neuron. A model of temporal delays is used so that, in the single hidden layer only, a spike sent to a neuron not immediately neighbouring the sending neuron is received x steps after it is sent, where x is the number of neurons between the sending neuron and receiving neuron. Each output neuron has an activation window that records the number of spikes produced by that neuron at each time step.\nSNN parameters are initial hidden layer nodes =9, a=0.3, b=0.05, c=0.0, cini=0.5,\n, output window size =21. Previous experimentation has shown that these parameters, specifically the initial hidden-layer nodes and output window size, have relatively little effect on network performance. Fewer initial hidden-layer neurons can restrict possible topologies (and therefore possible output responses) during early generations, resulting in a slightly longer learning process. Output window size is experimentally set to allow a reasonable amount of STDP activity per agent movement. Parameters are chosen to strike a balance between system performance and evaluation time. A typical SNN is shown in Figure  3 (a).\nFigure 3: (a) A typical SNN architecture. In the hidden layer, white neurons denote excitatory neurons and black neurons signify inhibitory neurons. (b) Khepera sensory arrangement. Three light sensors and three IR sensors share positions 0, 2, and 5 and form the network input. Two bump sensors, B1 and B2, are shown attached at\nangles to the front-left and front-right of the robot.\nThe SNNs were used to control a simulated Khepera II robot with eight light sensors and eight distance sensors. At each time step (64 ms in simulation time), the agent sampled its light sensors, whose values ranged from eight (fully illuminated) to 500 (no light); and IR distance sensors, whose response values ranged from 0 (no object detected) to 1,023 (object very close). All sensor readings were scaled to the range [0,1] (0 being unactivated, 1 being highly activated) before being input to the SNN. Six sensors comprised the input state for the SNN, three IR and three light sensors at positions 0, 2, and 5 as shown in Figure  3 (b). Additionally, two bump sensors were added to the front-left and front-right of the agent to prevent it from becoming stuck against an object. If either bump sensor were activated, an interrupt was sent, causing the agent to reverse 10 cm and the agent to be penalised by 10 time steps. Movement values and sensory update delays were constrained by accurate modelling of physical Khepera agent. Sensory noise was added based on Webots Khepera data;\n2% noise for IR sensors and\n10% noise for light sensors, all randomly sampled from a uniform distribution. Wheel slippage was also included (10% chance). The spike trains of the output neurons were discretised into high or low activated (high activation if more than half of the 21 SNN processing steps generated a spike at the neuron, low otherwise). Three actions were possible: forward (maximum movement on both left and right wheels, high activation of both output neurons), and continuous turns to both the left (high activation on the first output neuron, low on the second) and right (low activation on the first output neuron, high on the second)—caused by halving the left/right motor outputs, respectively. Three discrete actions are used to encourage more distinct changes in network activity when generating and transitioning between these actions, allowing a detailed analysis of such disparities to be performed.\n3.1.1  Benchmark Synapse Types\nFrom the description of SNNs in Section 2.1 and that of RMs in Section 2.2 , the strength of a connection weight in a neural network can be intuitively seen as the inverse resistance of that connection. The impact of a synapse on the functionality of the network depends on the modelling equations and parameters used. In this section, the equations governing the two comparative memristors (HP and PEO-PANI) and the constant connection are described. The HP memristor was chosen for study as it is well understood. The PEO-PANI memristor is also well-understood, but more importantly has a strongly different STDP profile (see Figure  1 (d)), which allows for contrasting behaviour. Importantly, when considering future hardware endeavours, both of these memristors are more likely than comparable devices to be available in sufficient quantities.\nThese synapse types have been previously compared (Howard et al., 2012 ); the main findings of the study were (1) memristive STDP was used to generate highly fit solutions, (2) the evolutionary algorithm assigned roles to the synapses based on their STDP behaviours (HP memristors were statistically more frequently connected to an inhibitory neuron, PEO-PANI were more frequently attached to an excitatory neuron), and (3) self-adaptive search parameters were found to be context-sensitive and beneficial to the evolution of the networks. In this study, these synapses serve as a means of comparison to the new variable devices.\n3.1.1.1 HP Memristor\nThe HP memristor is comprised of thin-film titanium dioxide (TiO2) and titanium dioxide with oxygen vacancies (TiO(2-x)), which have different resistances. The boundary between the two compounds moves in response to the charge on the memristor, which in turn alters the resistance of the device as delineated in Figure  2 . To allow for a future transition into variable synapses, memristance equations are rearranged based on the originals provided by Strukov et al. ( 2008 ).\nIn the following equations, W is the scaled weight (conductance) of the connection, G is the unscaled weight of the connection, M is the memristance, sf1 and sf2 are scale factors, Roff is the resistance of the TiO2, Ron is the resistance of the oxygen-depleted TiO(2-x), q is the charge on the device, and qmin is the minimum allowed charge.\nencompasses the physical properties of the device. The original profiles, used for the benchmark memristors, are recreated using a rescaled\n, Ron=0.01, Roff=1, qmin=0.0098.\n(5)\nFigure  4 (a) shows that HP and PEO-PANI memristors display increased sensitivity (larger\nper STDP event) when\nis a low number and either W>0.1 for HP-governed synapses, or W<0.9 for PEO-PANI-governed profiles.\nFigure 5: Showing a positive STDP event for a memristor. A presynaptic voltage spike is received at time t−1, with a postsynaptic voltage spike at time t. Combined, the voltage surpasses\n, increasing the conductivity of the device. (b) In the case of the RSM, consecutive voltage spikes (l.h.s. Sn=3, r.h.s. Sn=4) serve to push the voltage past a threshold, causing a switch. Dotted lines show the derived voltage threshold. Voltage spike values are decremented by one per subsequent time step.\nRSM STDP parameters are Sn, which encapulates the sensitivity of the device to voltage buildup (in the form of repeated STDP spikes), and Sc, which tracks the number of consecutive STDP events the synapse has experienced. All synapses are initially in the low resistance state (W=0.9). At each step, every synapse is checked as before, incrementing Sc if an STDP event occurs at the synapse and decrementing Sc if no STDP event occurs at that step. If Sn=Sc, the RSM switches to the high resistance state (W=0.1) and Sc is reset to 0. The RSM can switch back and forth between the LRS and HRS during a trial. Note that the polarity of the voltage spike in RSM networks is always the same, regardless of the coincidence of presynaptic and postsynaptic spikes across the device.\nFigure  5 (b) shows how this mechanism compares to regular STDP. Due to the requirement of consecutive STDP events, the actual frequency of synapse alteration is lower than that seen in the memristive networks. The number of consecutive spikes required can be seen as an analogue to a higher voltage threshold which is required to switch. Note that q is no longer instrumental to the functioning of the device; that is, RSMs are related to voltage-threshold rather than being charge-controlled. Because of this, the network architectures required to handle the two RMs (memristive and RSM) are assumed to be incompatible with each other.\nWe note that LS may be discussed in the context of RSMs and must be set equal to Sn to allow the device to surpass this threshold in the face of voltage dissipation, which acts to lower the value of the waveform through time.\nmay also be derived and varies according to Sn, although its value is not necessarily required to model the device. After an RM network is trialled, all synapses are reset to their original weights (0.5 for memristors, 0.9 for RSMs).\n3.2  Evolutionary Algorithm\nHaving described the component parts of our networks, we now detail the implementation of the GA that acts on them. Per generation, two parents are selected fitness-proportionately, mutated, and used to create two offspring. We use only mutation to explore weight space; crossover is omitted as sufficient solution space exploration can be obtained via a combination of self-adaptive weight and topology mutations; a view that is reinforced in the literature (e.g., Rocha et al., 2003 ). The offspring are inserted into the population and two networks with the lowest fitness are deleted.\nEach network is respresented by two variable-length vectors, one containing neurons and the other connections. A neuron is defined by its type (excitatory or inhibitory), membrane potential, and last spike value LS. A connection is defined by its type (e.g., HP memistor), weight, charge,\n, and the neurons it connects. These two vectors are augmented by self-adaptive parameters that control various rates of mutation. Mutatable network parameters are neuron type, synaptic weight (in non-RM networks),\n(in variable memristor networks), Sn (in variable RSM networks), and associated self-adaptive parameters. Neurons and connections may be added/removed from their respective vectors by the GA.\nThe use of a self-adaptive framework is justified when the application area of neuromorphic computing is considered—that is, when brainlike systems must be able to autonomously adapt to a changing environment and adjust their learning accordingly. This potentially allows increased structural stability in highly fit networks while enabling less useful networks to vary more strongly per GA application. Mechanistically, self-adaptation also permits the use of self-repair/self-modification, wherein the GA is able to (1) in a stable environment, lower mutation rates to enable homeostasis or provide incremental, gradual improvements or (2) when the environment rapidly changes, or part of the network fails, increase learning rates to more quickly adapt to these new conditions. When coupled with neuroevolution, the effect is to tailor the evolution of the network to the complexity of the environment explicitly, that is, each network controls its own architecture autonomously in terms of (1) amount of mutation that takes place in a given network at a given time (2) adapting the hidden-layer topology of the neural networks to reflect the complexity of the problem considered by the network, as shown by Hurst and Bull ( 2006 ). This mechanism was first used with SNNs by Howard ( 2010 ). We note that the benefits of this approach will be more pronounced in hardware implementations, which will be the topic of future research.\n3.2.1  Self-Adaptive Mutation\nWe use self-adaptive mutation rates as in evolutionary strategies (ESs; Rechenberg, 1973 ), to dynamically control the frequency and magnitude of mutation events taking place in each network. Here, the rate of mutation per allele\nof each network is initialized uniformly randomly in the range [0, 0.25]. During a GA cycle, a parent's\nis modified as in Equation ( 19 ) (where N denotes a normal distribution); the offspring then adopts this new\nand mutates itself by this value, before being inserted into the population.\n(19)\nOnly non-RM networks can alter their connection weights via the GA. Connection weights in this case are initially set during network creation, node addition, and connection addition randomly uniformly in the range [0, 1]. Memristive network connections are always set to 0.5, and cannot be mutated from this value. The aim of setting this value is to force the memristive networks to harness the plasticity of their connections during a trial to successfully solve the problem.\n3.2.2  Control of Variable Synapses\nThe STDP responses of the variable synapses are governed by the self-adaptive parameter\n, which is initialised and self-adapted as with\n. In the case of the variable memristor, mutation changes a synapse's\nby\n. Offspring networks have their parents’\nand\nvalues modified using Equation ( 19 ) as with\n, with neuron addition/removal occurring after mutation. Added nodes are initially excitatory with 50% probability, otherwise they are inhibitory.\nAutomatic feature selection is a method of reducing the dimensionality of the data input to a process by using computational techniques to select and operate exclusively on a subset of inputs taken from the entire set. In the context of neural networks, feature selection can disable synaptic (traditionally input) connections. In this study we allow each connection to be individually enabled/disabled, a mechanism termed connection selection. During a GA cycle, a connection can be added or removed from the connection vector based on a new self-adaptive parameter\n(which is initialised and self-adapted in the same manner as\nand\n). If a connection is added for a nonmemristive network, its connection weight is randomly initialised uniformly in the range [0, 1], memristive connections are always set to 0.5. During a node addition event, new connections are set probabilistically, with P=0.5 of each possible neural connection being added. Connection selection is particularly important to the memristive networks. As they cannot alter connection weights via the GA, variance induced in network connectivity patterns plays a large role in the generation of STDP in the networks. Likewise, RSM networks rely on connection selection to generate synchronised synaptic excitations/inhibitions, which allow the network to generate appropriate output actions.\n3.3  Task\nThe main advantage of STDP is the ability to vary during a trial in response to a dynamically-changing environment. To demonstrate the ability of variable RM synapses to handle dynamic reward scenarios, an experiment was simulated in a T-maze (e.g., Blynel and Floreano, 2003 ) scenario, as used by Soltoggio et al. ( 2008 ) to investigate the adaptivity of plastic networks. In particular, the variable memristor (MEM) and RSM (RSM) elements were compared to the static HP (HP) and PEO-PANI (PEO) memristors, and the constant connection or nonswitching RSM (CONST). The popular robotics simulator Webots (Michel, 2004 ) was chosen; alternatives are summarised by Craighead et al. ( 2007 ).\nThe environment was an enclosed arena with coordinates ranging from [−1, 1] in both x and y directions, and is shown in Figure  6 to represent a T. The agent is initialised facing north in a zone at the bottom of the T (delineated in Figure  6 with a checkered pattern). Reward zones R1 and R2 were situated at the end of the left and right arms, respectively. A light source, modelled on a 15 W lightbulb, was placed at the top-centre of the arena (x=0.5, y=1) and was used by the network for action calculation.\nFigure 6: The T-maze. The agent (white circle) begins in the checkered box and must travel to R1 or R2. The light source is shown (top-centre).\nDuring a trial, the agent initially learned to navigate to R1. Once stable pathfinding to R1 was attained, the reward zone was switched to R2 and the agent reinitialised in the start zone. To give the agent memory of the first part of the trial, the membrane potentials and synaptic weights of the controlling network were not reset during this process. This task is dynamic as the reward zone changes so the agent must forget its previously-learned behaviour after a time and adapt to a newly-positioned goal state. A network that located R2 following location of R1 was said to have solved the trial. The measure of fitness used, f, was simply the total number of steps required to solve the trial. Each network was permitted 4,000 steps to locate R1, plus an additional 4,000 steps to locate R2.\n4  Results\nSection:\nIn the following discussion, best fitness refers to the lowest-fitness network in each experimental repeat (lower fitness denoted higher solution quality). Average fitness was the mean fitness of the population of networks. Neurons listed the average final number of connected neurons in the population, and connectivity was the average percentage of enabled connections in the population. All of the above measurements were averaged over the 30 experimental repeats. Two-tailed t-tests were used to assess statistical significance.\nFigures  7 (a) and 7 (b) show that both variable network types generate solutions with better average fitness and best fitness than their static counterparts (for best fitness, MEM and RSM were both p<.05 vs. HP, PEO, and CONST; for average fitness MEM was p<.05 vs. HP and PEO, RSM was p<.05 vs. HP, PEO, and CONST). This is an encouraging result, as in addition to outperforming the majority of the nonvariable synapses, the variable RM synapses induce no significant performance overhead that may have arisen due to the increased search/behaviour space that the GA has to deal with. The average fitness of HP networks is due to much of the population not being able to perform both parts of the trial; best fitness is still comparable to the other nonvariable network types. When comparing the two variable RM networks, we note that the average fitness of RSM networks is significantly (p<.05) lower than that of MEM networks.\nFigure 7: Box plots showing average (a) best fitness, (b) mean fitness, (c) connected hidden layer nodes, (d) enabled connections, (e)\n, (f)\n, and (h)\nfor the T-maze experiment.\nThe best single network of each type had the following fitness values: MEM=839, RSM=879, PEO=956, CONST=915, HP=901. MEM networks generated the highest quality (single) solution, 2.56 s faster than the best-evolved RSM network. As the pathfinding function is better-approximated, GA-tuned STDP behaviour of the MEM synapses is said to be capable of the most complex responses to environmental stimuli.\nVariable RMs are also found to be easier to evolve for this task—both MEM and RSM networks take statistically (p<.05) fewer generations to generate a solution that successfully solves the task compared to all other synapse types, indicating that a greater rate of adaptation is possible when using variable synapses. The average number of generations to create a network that solves the problem are RSM=19.3, MEM=27.7, PEO=46.2, HP=890.5, and GA=66.3. Compared to RSM networks, MEM networks appear to require more GA tuning of\nto generate functional solutions, due to the larger and more fine-grained search space of\ncompared to Sn.\nRSM networks possess the fewest average neurons per network. MEM networks contain more excitatory neurons (average 13.9) than they do inhibitory (average 3.2, p<.05), the most likely explanation being that a given level of network activity is required to generate all required behaviours given an arbitrary input state. RSM networks possess an approximately equal distribution of neuron types because the neurons are ambivalent to the polarity of the incoming voltage spikes (average 6.7 excitatory neurons, 5.9 inhibitory neurons).\nMEM networks were more densely connected (average 53.6%) than their RSM counterparts (average 50.9%, p<.05). Denser synaptic topologies were required for MEM networks as more of the computational power of the network is embodied in the synapse itself (a notion echoed in recent literature, Abbott and Regehr, 2004 ). When a single MEM synapse is compared to a single RSM synapse, it is evidenced that the MEM device is capable of temporal behaviour that is more complex and granular; however, the RSM network as a whole overcomes a lack of synaptic complexity via arrangements of simpler devices and synchronised LRS/HRS switching to generate useful spike patterns. HP networks are also more densely connected than RSM (average 53.3%, p<.05), although this is likely due to the requirement for additional synapses to percolate sufficient activity through the network given the tendency of the HP memristor to either become stuck in a low-conductivity region of its STDP profile or be used as a depressing synapse, for example, with a presynaptic inhibitory neuron (Howard et al., 2012 , provide in-depth analysis).\nIn terms of computational complexity, we observe that MEM and RSM networks possess more complex temporal dynamics than the other STDP-enabled network types. Complexity in MEM networks is evidenced through a heterogeneous collaboration of myriad STDP responses. In contrast, complexity in RSM networks is mainly due to the creation of synchronised weight oscillators within the network which are required for high-fitness behaviour generation. In either case, synaptic activity (as opposed to neuron activity) is seen to be the main driver of action generation—the computational onus is seen to be taken from neuron and reattributed to the synapse.\nConnection selection approximately halves the amount of connections used by the networks (Figure  7 (d) shows connectivity varying between 50.9–53.7%). Considering possible NC applications, the integration of mechanisms such as synaptic redundancy, self-repair, and self-modification could be eased by the sparse connectivity of the generated solutions. In eventual hardware implementations, more synapses will be available to implement these mechanisms when compared to solutions that do not use this technique.\nFigures  7 (e)–(h) show that all parameters decline from their original values. MEM networks are seen to possess higher average\n(rate of connection selection, 0.043) than both RSM (0.029), HP (0.03), and CONST (0.033) networks (p<.05). While proving the context-sensitivity of self-adaptation, this result also relates to the idea that MEM synapses are more computationally powerful, and therefore the networks (1) require more connections, and (2) need to experiment more with synaptic configurations via connection selection to generate highly fit solutions. Iota, which controls the frequency of variable synapse alteration events, varies between MEM and RSM with p=.481.\nWhen self-adaptive parameters from the same network type are compared, all are observed to be significantly (p<.05) different from each other—compare Figure  7 (e)–(h). Self-adaptation is shown to be context-sensitive, with the GA automatically discovering preferential values for each parameter based on its role in the generation of fit solutions.\n4.1  Analysis of Synapse Variability\n4.1.1  Variable Memristor Networks\nin the range 1–100. A PEO-PANI-governed profile with\nwould therefore have a recalculated value of 101+50=151.\nVariation appears in the distribution of profile types in MEM networks, shown in Figure  8 (a). Synapses are more frequently governed by HP profiles (average 41.4 synapses per network) than PEO-PANI-governed synapses (average 36.9 synapses per network, p<.05). More prolific use of HP-governed profiles, which provide lower average efficacy, can be seen as a way to balance network activity given the increased connectivity of MEM networks in general. Figure  8 (b) shows the distribution of profile types per layer over time. It was observed that HP-governed profiles were more frequently found connecting two hidden-layer neurons (20.6 vs. 17.8 average PEO-PANI-governed connections, p<.05), but were less frequent than PEO-PANI profiles when connecting sensors (input layer) to the hidden layer. This shows that values of\nare selected to permit swifter weight change per STDP event when connecting sensors into the network, enabling a more expedient network response to changing environmental conditions (mainly to allow for different actions to be more quickly calculated from similar environmental conditions when R1 changes to R2).\nFigure 8: Number of connections belonging to (a) each profile type overall in MEM networks, (b) each profile type per layer in MEM networks. M = mean of all networks, B = numbers from best network of each experimental repeat.\n4.1.2  Variable RSM Networks\nNo differences were found with respect to the type (inhibitory/excitatory) of neuron that synapses of each Sn connect, with p-values ranging from 0.59 to 0.99. We note that lower Sn (Sn=2–3) synapses are found connecting input neurons to the hidden layer, with Sn=4–6 synapses more prevalent when connecting two hidden-layer neurons, suggesting that fast-switching synapses are required to immediately generate activity within the network. IR sensors have lower Sn than light sensors as they trigger only when near obstacles and so must be able to quickly switch to peturb network output and avoid the obstacle.\nNo significant results were observed with respect to the type of neuron (excitatory or inhibitory) that the synapses were presynaptic/postsynaptic to in RSM networks (all p>.05), reinforcing the notion that the timing of weight switches within the networks requires subnetworks of synapses with varying temporal behaviour. This is opposed to MEM networks which assign distinct roles to individual synapses based on their behaviour under STDP.\n4.1.3  STDP\nThe ability of a network to generate high-quality overall solutions despite the in-trial movement of the goal state is implicitly linked to its ability to alter its internal dynamics during runtime using STDP. The need to search this additional space during GA application is offset by the increased power of the synapses (for MEM networks) or the increased power of the possible internal network dynamics (for RSM networks). For MEM and RSM networks, the ability of a variable synapse to tailor its behaviour more accurately than the other synapse types is recognised and harnessed by the evolutionary process, resulting in the observed differences in best fitness and average fitness.\nUse of STDP by the best MEM network is shown in Figure  9 , and to give an example of the network's in-trial variance, the network itself is provided in Figure  10 . HP-governed profiles were found to quickly reduce synaptic efficacy to the left (right) motor, causing peturbation of calculated action during turn by bringing that motor below the high activated threshold. PEO-PANI-governed MEM profiles to the same motor were used to swiftly increase the level of spiking activity (usually in response to a light sensor surpassing/coming under some threshold) until a forward action was calculated after the turn was completed. HP profiles were statistically (p<.05) more likely to be found reducing a synapse's efficacy. In contrast, PEO-PANI-governed profiles were statistically (p<.05) more likely to be found increasing a synapse's efficacy. PEO-PANI-governed profiles experience statistically (p<.05) more positive STDP and statistically (p<.05) fewer negative STDP events than HP-governed profiles. These findings seem to concur with previous work by Howard et al. ( 2012 ), in which static PEO memristors were found to be better suited to conducting weight through the network (with the opposite being true for HP memristors). The evolutionary process harnessed the differing profiles by placing PEO memristors where they would receive the most positive STDP.\nFigure 9: (a) Average synaptic weight, (b) average positive STDP, (c) average negative STDP per profile type for the MEM networks in the T-maze.\nFigure 10: Synapse strengths (a) after the first 50 time steps, (b) after finding the first reward zone, and (c) after adapting to find the second reward zone for the best MEM network in the T-maze.\nRSM networks generated highly fit behaviour via the ability to rapidly vary the network dynamics in three main ways: (1) to perform additional connection selection in-trial, for example, to switch a synapse to a given state and leave it there; (2) as (1) but varying the connectivity map of the network multiple times based on the sensory input; and (3) in the creation of weight oscillators in the network, whereby the firing on the neurons and switching of the synapses synchronised through time to generate appropriate output actions from a subgroup of neurons. In the third case, the input state was found to perturb both the firing pattern of the neurons and the weight-switching pattern of the synapses to generate, for example, turning actions when required. All other network types using STDP relied on numerous repeated events of a particular polarity to provide large increases in efficacy, whereas the RSM could switch back and forth multiple times in a short number of time steps—more expedient binary switching allows for output to be more quickly altered for a given input configuration. RSM networks experience a gradual increase in STDP throughout the lifetime of the network. Figures  11 (a) and 11 (b) show the behaviour of the best RSM network from each run through the first 500 time steps. The switching profile itself shows two peaks of activity, at time steps 90 and 400, which correspond to the approximate turning times to reach R1 and R2, respectively. The contribution to switching frequency per Sn is shown in Figure  11 (b)—we observe significant disparity between all Sn types in this regard (all p<.05). Lower Sn synapses represent more variable STDP profiles, as they have higher maximum switching frequencies.\nFigure 11: (a) Average switch frequency (left axis)/average synaptic weight (right axis), (b) average switch frequency per Sn for the RSM networks in the T-maze.\nFewer overall STDP events occur in RSM networks than in MEM networks, presumably because (1) consecutive STDP events are more difficult to attain, and (2) each switch can have a more dramatic effect on the activity of the network. These results suggest that the casting of synapses into roles is only possible when using memristors as synapses, as RSM synapses do not display these relative disparities between Sn types, or a sensitivity to incoming voltage polarity.\n5  Conclusions\nSection:\nIn this study, we have introduced the notion of a variable RM and analysed its synaptic performance when compared to static RMs and benchmark connections in a dynamic robotics scenario. Our hypothesis was that the additional degrees of functional freedom afforded to the variable RMs allowed them to outperform these other synapses in key areas. Experimental findings supported this hypothesis, as variable RMs of both kinds generated higher quality solutions than the other synapse types.\nThe results suggest that self-adapation of the characteristic resistance profile of both variable RMs is harnessed by the evolutionary process to provide variable plastic networks with more implicit degrees of freedom than the other network types. Importantly, the need to explore additional search space (especially in the case of\n) was found to be nondisruptive (and in most cases beneficial) with respect to network performance, while providing a more flexible synaptic representation.\nThe inclusion of self-adaptive mutation parameters with a neuro-evolutionary approach is likely to be necessary for the autonomous emergence of neuromorphic processing units. This study presents a candidate implementation that allows for the formation of such task-specific neural groupings. Futhermore, our results enforce the view that this kind of approach may be used to guide the synthesis requirements of functional memristor/RSM hardware systems. Trials on different task types may provide insight into the optimal composition of such systems on a per-task basis.\nThe main benefit of RM STDP over other STDP implementations lies in hardware realisation, as the efficacy (and, in the case of the memristor, activity) of the synapse is stored in the nonvolatile physical state of the device and thus does not require simulation. Possible future research directions include hardware and mixed-media implementations, provided the two RM types can be integrated into the same circuit architecture. It is postulated that RSMs would be easier to implement in hardware due to their mechanically simpler discrete switching behaviours, which would require less finely-tuned manufacturing and be more tolerant of errors during this process. For synapses implementing approximately the same behaviour, it is likely that the same materials could be used, with finely controlled variations during synthesis required to achieve the desired behaviours. Where synapses require radically different functionality, mixing of heterogeneous materials may be required—considering the recent discovery of myriad memristors with varied behaviour at similar scales, it is likely that any evolved network will have a compatible behavioural hardware equivalent. We note that titanium dioxide additionally allows for memristive behaviour and binary switching to be elicited from the same material. As well as providing more functional degrees of freedom to the synapse, evolution could potentially control switching between the behaviours to autonomously create task-optimal neuromorphic subarchitectures, as well as online synaptic transformations via targeted irradiation for self-repair or self-modification.\nReferences\nSection:\nAbbott, L., and Regehr, W. (2004). Synaptic computation. Nature, 431(7010):796–803. Crossref\nAfifi, A., Ayatollahi, A., and Raissi, F. (2009). STDP implementation using memristive nanodevice in CMOS-nano neuromorphic networks. IEICE Electronics Express, 6(3):148–153. Crossref\nAkinaga, B. H., and Shima, H. (2010). Resistive random access memory (RERAM) based on metal oxides. Proceedings of the IEEE, 98(12):2237–2251. Crossref\nBi, G.-Q., and Poo, M.-M. (1998). Synaptic modifications in cultured hippocampal neurons: Dependence on spike timing, synaptic strength, and postsynaptic cell type. The Journal of Neuroscience, 18(24):10464–10472.\nBlynel, J., and Floreano, D. (2003). Exploring the T-maze: Evolving learning-like robot behaviors using CTRNNS. In S. Cagnoni, C. Johnson, J. Cardalda, E. Marchiori, D. Corne, J.-A. Meyer, J. Gottlieb, M. Middendorf, A. Guillot, G. Raidl, and E. Hart (Eds.), Applications of evolutionary computing. Lecture notes in computer science, vol. 2611 (pp. 173–176). Berlin: Springer-Verlag. Crossref\nChua, L. (1971). Memristor—the missing circuit element. IEEE Transactions on Circuit Theory, 18(5):507–519. Crossref\nCraighead, J., Murphy, R., Burke, J., and Goldiez, B. (2007). A survey of commercial open source unmanned vehicle simulators. In Proceedings of the 2007 IEEE International Conference on Robotics and Automation, pp. 852–857. Crossref\nDoolittle, W., Calley, W., and Henderson, W. (2009). Complementary oxide memristor technology facilitating both inhibitory and excitatory synapses for potential neuromorphic computing applications. In Proceedings of the International Semiconductor Device Research Symposium, 2009, ISDRS ’09, pp. 1–2. Crossref\nDurr, P., Mattiussi, C., Soltoggio, A., and Floreano, D. (2008). Evolvability of neuromodulated learning for robots. In Proceedings of the 2008 ECSIS Symposium on Learning and Adaptive Behavior in Robotic Systems, pp. 41–46. Crossref\nErokhin, V., and Fontana, M. P. (2008). Electrochemically controlled polymeric device: A memristor (and more) found two years ago. Retrieved from http://arxiv.org/abs/arXiv:0807.0333\nFloreano, D., Dürr, P., and Mattiussi, C. (2008). Neuroevolution: From architectures to learning. Evolutionary Intelligence, 1:47–62. Crossref\nGale, E. (2012). The memory-conservation model of memristance. In J. Heber, D. Schlom, Y. Tokura, R. Waser, and M. Wutting (Eds.), Technical Digest of Frontiers in Electronic Materials (pp. 538–539). Nature Conferences & Wiley VCH.\nGale, E., de Lacy Costello, B., and Adamatzky, A. (2012). The effect of electrode size on memristor properties: An experimental and theoretical study. In International Conference in Electronics Design, Systems and Applications, ICEDSA 2012, pp. 80–85. Crossref\nGale, E., Pearson, D., Kitson, S., Adamatzky, A., and de Lacy Costello, B. (2012). Different behaviour seen in flexible titanium dioxide sol-gel memristors dependent on the choice of electrode material. In J. Heber, D. Schlom, Y. Tokura, R. Waser, and M. Wutting (Eds.), Technical Digest of Frontiers in Electronic Materials (pp. 577–578). Nature Conferences & Wiley VCH.\nGerstner, W., and Kistler, W. (2002). Spiking neuron models—Single neurons, populations, plasticity. Cambridge, UK: Cambridge University Press. Crossref\nHebb, D. O. (1949). The organisation of behavior. New York: Wiley.\nHo, Y., Huang, G. M., and Li, P. (2009). Nonvolatile memristor memory: Device characteristics and design implications. In ICCAD, pp. 485–490. Crossref\nHolland, J. H. (1975). Adaptation in natural and artificial systems. Ann Arbor, MI: University of Michigan Press.\nHosoi, Y., Tamai, Y., Ohnishi, T., Ishihara, K., Shibuya, T., Inoue, Y., Yamazaki, S., Nakano, T., Ohnishi, S., Awaya, N., et al. (2006). High speed unipolar switching resistance ram (rram) technology. 2006 International Electron Devices Meeting, pp. 1–4. Crossref\nHoward, G. D. (2010). Constructivist and spiking neural learning classifier systems. Ph.D. thesis, University of the West of England.\nHoward, G. D., Gale, E., Bull, L., de Lacy Costello, B., and Adamatzky, A. (2012). Evolution of plastic learning in spiking networks via memristive connections. IEEE Transactions on Evolutionary Computing, 16:711–729. Crossref\nHurst, J., and Bull, L. (2006). A neural learning classifier system with self-adaptive constructivism for mobile robot control. Artificial Life, 12(3):353–380. Link\nJo, S. H., Chang, T., Ebong, I., Bhadviya, B. B., Mazumder, P., and Lu, W. (2010). Nanoscale memristor device as synapse in neuromorphic systems. Nano Letters, 10(4):1297–1301. PMID: 20192230. Crossref\nJung, J.-Y., and Reggia, J. (2006). Evolutionary design of neural network architectures using a descriptive encoding language. IEEE Transactions on Evolutionary Computation, 10(6):676–688. Crossref\nKistler, W. M. (2002). Spike-timing dependent synaptic plasticity: A phenomenological framework. Biological Cybernetics, 87(5–6):416–427. Crossref\nLinares-Barranco, B., and Serrano-Gotarredona, T. (2009). Memristance can explain spike-time-dependent-plasticity in neural synapses. Retrieved from http://hdl.handle.net/10101/npre.2009.3010.1\nMaass, W. (1996). Networks of spiking neurons: The third generation of neural network models. Neural Networks, 10:1659–1671. Crossref\nMaass, W., and Zador, A. M. (1999). Dynamic stochastic synapses as computational units. Neural Computation, 11(4):903–917. Link\nMattiussi, C., and Floreano, D. (2007). Analog genetic encoding for the evolution of circuits and networks. IEEE Transactions on Evolutionary Computation, 11(5):596–607. Crossref\nMead, C. (1990). Neuromorphic electronic systems. Proceedings of the IEEE, 78(10):1629–1636. Crossref\nMichel, O. (2004). WebotsTM: Professional mobile robot simulation. International Journal of Advanced Robotic Systems, 1(1):39–42.\nMouttet, B. (2009). Memristor pattern recognition circuit architecture for robotics. In Proceedings of the 2nd International Multi-Conference on Engineering and Technological Innovation II, pp. 65–70.\nNolfi, S., and Floreano, D. (2000). Evolutionary robotics. Cambridge, MA: MIT Press.\nPershin, Y. V., La Fontaine, S., and Di Ventra, M. (2009). Memristive model of amoeba learning. Phys. Rev. E, 80(2):021926. Crossref\nQuerlioz, D., Bichler, O., and Gamrat, C. (2011). Simulation of a memristor-based spiking neural network immune to device variations. In Proceedings of the 2011 International Joint Conference on Neural Networks (IJCNN), pp. 1775–1781. Crossref\nRabaey, J. M. (1996). Digital integrated circuits: A design perspective. Upper Saddle River, NJ: Prentice-Hall.\nRechenberg, I. (1973). Evolutionsstrategie: Optimierung technischer systeme nach prinzipien der biologischen evolution. Frommann-Holzboog.\nRocha, M., Cortez, P., and Neves, J. (2003). Evolutionary neural network learning. In Progress in artificial intelligence. Lecture notes in computer science, Vol. 2902 (pp. 24–28). Berlin: Springer. Crossref\nRumelhart, D., and McClelland, J. (1986). Parallel distributed processing, Vols. 1–2. Cambridge, MA: MIT Press.\nSaggie-Wexler, K., Keinan, A., and Ruppin, E. (2006). Neural processing of counting in evolved spiking and McCulloch-Pitts agents. Artificial Life, 12(1):1–16. Link\nSnider, G. (2005). Computing with hysteretic resistor crossbars. Appl. Phys. A., 80:1165–1172. Crossref\nSnider, G. (2008). Spike-timing-dependent learning in memristive nanodevices. In IEEE International Symposium on Nanoscale Architectures, NANOARCH 2008, pp. 85–92. Crossref\nSoltoggio, A. (2008). Neural plasticity and minimal topologies for reward-based learning. In Proceedings of the 8th International Conference on Hybrid Intelligent Systems, pp. 637–642. Crossref\nSoltoggio, A., Bullinaria, J. A., Mattiussi, C., Dürr, P., and Floreano, D. (2008). Evolutionary advantages of neuromodulated plasticity in dynamic, reward-based scenarios. In S. Bullock, J. Noble, R. Watson, and M. A. Bedau (Eds.), Proceedings of the 11th International Conference on Artificial Life, Alife XI, pp. 569–576.\nStanley, K., Bryant, B., and Miikkulainen, R. (2005). Real-time neuroevolution in the Nero video game. IEEE Transactions on Evolutionary Computation, 9(6):653–668. Crossref\nStanley, K. O., and Miikkulainen, R. (2002). Evolving neural networks through augmenting topologies. Evolutionary Computation, 10(2):99–127. Link\nStrukov, D. B., Snider, G. S., Stewart, D. R., and Williams, R. S. (2008). The missing memristor found. Nature, 453:80–83. Crossref\nUrzelai, J., and Floreano, D. (2001). Evolution of adaptive synapses: Robots with fast adaptive behavior in new environments. Evolutionary Computation, 9(4):495–524. Link\nVujisic, M., Stankovic, K., Marianovic, N., and Osmokrovic, P. (2010). Simulated effects of proton and ion beam irradiation on titanium dioxide memristors. IEEE Transactions on Nuclear Science, 57(4):1798–1804. Crossref\nWaser, R., and Aono, M. (2007). Nanoionics-based resistive switching memories. Nature Materials, 6(11):833–840. Crossref\nXia, G., Tang, Z., Li, Y., and Wang, J. (2005). A binary hopfield neural network with hysteresis for large crossbar packet-switches. Neurocomputing, 67(0):417–425. Crossref\nGerard Howard\nDepartment of Computer Science, University of the West of England, Bristol, BS16 1QY, UK david4.howard@uwe.ac.uk\nLarry Bull\nDepartment of Computer Science, University of the West of England, Bristol, BS16 1QY, UK larry.bull@uwe.ac.uk\nBen de Lacy Costello\nDepartment of Applied Sciences, University of the West of England, Bristol, BS16 1QY, UK ben.delacycostello@uwe.ac.uk\nElla Gale\nDepartment of Applied Sciences, University of the West of England, Bristol, BS16 1QY, UK ella.gale@uwe.ac.uk\nAndrew Adamatzky\n""","0.11517951","""http://www.mitpressjournals.org/doi/10.1162/EVCO_a_00103""","[-2.60329,51.459066]"
"""University_of_Aberdeen""","""Multivariate Simulation and Multimodal Dependence Modeling of Vehicle Axle Weights with Copulas | Journal of Transportation Engineering | Vol 132, No 12""","""Journal of Transportation Engineering\nShare\nAbstract\nSafety assessment and rational design of bridge structures requires the uncertainty associated with vehicle loads to be modeled as accurately as possible. This modeling is rendered difficult by the presence of vehicle axle weights that involve different combinations of unimodal and multimodal probability distributions with different dependence structures. In this paper, a transformation invariant approach using copula functions is proposed for the multivariate simulation of dependent axle weights of different vehicle classes. Copula based dependence modeling, which is widely used in the financial risk analysis, is applied to model and simulate three different vehicle cases with different combinations of marginal probability distributions for axle weights. The database of observed vehicle weights is based on the data collected at five locations on national highways in India. The dependence between multimodal distributions of axle weights is accurately considered and simulations are carried out. The simulated axle weights are found to be in very good agreement with the observed data. This type of simulation is useful in carrying out simulation-based reliability analysis of bridges and pavements.\n""","1.2676355","""http://ascelibrary.org/doi/10.1061/%28ASCE%290733-947X%282006%29132%3A12%28945%29""","[-2.099122,57.165019]"
"""Imperial_College_London""","""Modeling Joint Charging and Parking Choices of Electric Vehicle Drivers | Decentralized Control Approach for Charging Service Providers""","""Modeling Joint Charging and Parking Choices of Electric Vehicle Drivers\nDecentralized Control Approach for Charging Service Providers\nPDF\nAbstract\nElectric vehicles (EVs) offer significant opportunities to improve sustainability of the road transport sector. But simultaneously, widespread adoption of EVs would create new challenges. For example, spatiotemporal concentration of charging events in high-density residential or commercial areas would place extreme demands on the power network, causing bottlenecks and grid instability. A novel approach to the typical decentralized control methods for EV charging service providers (CSPs) is presented. First, static price signals based on anticipated demand define a set of charging offers, targeted to segments of EV users. Prices are differentiated either only by time or both by time and place and allow comparison and evaluation of both scenarios. A choice-based revenue management method is employed to optimize allocation of generated charging offers, with respect to revenue outcome for the CSP. The charging coordination techniques are demonstrated through simulation. Data come from the London Travel Demand Survey and particularly trips around Westfield, one of Europe’s largest urban shopping malls, representing out-of-home charging behavior for short intervals in a high-demand area. Findings suggest that in a first-come, first-served system, locational pricing might create opportunities both for increased revenue and for relocation of charging events to less-congested facilities. In the revenue management system, locational pricing significantly favors total revenue outcome but without discharging vulnerable areas. However, because agents with conflicting interests participate in the process (infrastructure owners, power system operators, EV drivers), opportunity exists for the CSP to adapt constraints according to the priority of its objectives.\n< >\nTransportation Research Record: Journal of the Transportation Research Board\nTransportation Research Record: Journal of the Transportation Research Board\nPrint ISSN: 0361-1981\n""","1.0084107","""http://trrjournalonline.trb.org/doi/10.3141/2502-15""","[-0.178219,51.500505]"
"""Imperial_College_London""","""Environmental Health Perspectives – Air Pollution and Respiratory Infections during Early Childhood: An Analysis of 10 European Birth Cohorts within the ESCAPE          Project""","""Supplemental Material (1.2 MB) PDF\nIntroduction\nRespiratory infections are a leading reason for outpatient physician visits and hospitalizations among children ( Williams et al. 2002 ). Most infections resolve with minimal use of health care resources; however, episodes of severe or recurrent infection may require hospitalization or surgery, and the resultant burden on resources is substantial ( Black et al. 2010 ).\nYoung children are particularly susceptible to respiratory pathogens and also to air pollution ( Bateson and Schwartz 2008 ; Heinrich and Slama 2007 ). There is strong evidence that indoor air pollution, such as secondhand smoke and the use of biomass, is a risk factor for respiratory infections in children ( da Costa et al. 2004 ). Evidence is growing to support an association with outdoor air pollution as well ( Brauer et al. 2006 ; Leonardi et al. 2000 ; MacIntyre et al. 2011 ).\nThe European Study of Cohorts for Air Pollution Effects ( ESCAPE 2009 ) is a project aimed at investigating the impacts of long-term exposure to air pollution through the development of harmonized exposure data assigned to previously established cohorts that have collected information on specific health outcomes of interest for air pollution research. We analyzed data from 10 European birth cohorts and completed a meta-analysis of air pollution and respiratory infection (pneumonia, croup, and otitis media) during early childhood.\nMethods\nStudy population. We included 10 ESCAPE birth cohorts. The inclusion criteria for each birth cohort were that data on at least one outcome of interest were available during early childhood, and that the ESCAPE exposure assignment was complete.\nBAMSE (Children, Allergy, Milieu, Stockholm, Epidemiological Survey) is a population-based prospective birth cohort of children born during 1994–1996 in Stockholm County, Sweden ( Wickman et al. 2002 ). GASPII (Gene and Environment: Prospective Study on Infancy in Italy) is a prospective birth cohort of children born during 2003–2004 in Rome, Italy ( Porta et al. 2007 ). GINIplus (German Infant Nutrition Intervention Study Plus environmental and genetic influences on allergy development) is a population-based prospective birth cohort, with a nutritional intervention, of children born during 1995–1998 in Wesel and Munich, Germany ( Zirngibl et al. 2002 ). LISAplus (Influence of Life-style Factors on the Development of the Immune System and Allergies in Childhood Plus the influence of traffic emissions and genetics) is a population-based prospective birth cohort study of children born during 1997–1999 in Wesel, Munich, Leipzig, and Bad Honnef, Germany ( Heinrich et al. 2002 ). INMA (INfancia y Medio Ambiente; Environment and Childhood) is a network of Spanish birth cohorts. The four INMA cohorts in the present analysis comprise children born during 2004–2008 in both major cities and rural towns—Asturias, Gipuzkoa, Sabadell, and Valencia ( Guxens et al. 2012 ). MAAS (Manchester Asthma and Allergy Study) is an unselected, prospective population-based birth cohort study (with a small nested allergen control intervention) of children born during 1995–1997 in the Greater Manchester conurbation in the United Kingdom ( Custovic et al. 2002 ). Finally, the PIAMA (Prevention and Incidence of Asthma and Mite Allergy) study is a population based prospective birth cohort, with an intervention component, of children born during 1996–1997 in cities and small towns across the Netherlands ( Brunekreef et al. 2002 ). Each cohort obtained parental consent and protocols were approved by all relevant ethical review boards.\nExposure to outdoor air pollution was estimated using land use regression (LUR) models, and methods were harmonized across each cohort ( Beelen et al. 2013 ; Cyrys et al. 2012 ; Eeftens et al. 2012a , 2012b ; ESCAPE 2013 ). Briefly, sampling sites for particulate matter (n = 20–40) and nitrogen oxides (n = 40–80) were strategically chosen for each study area to represent the spatial distribution of concentrations at the residential address of each child at birth, with some overrepresentation of locations with heavy traffic where the largest heterogeneity was expected. Three 2-week sampling campaigns were spread out over 1 year and used to estimate an annual average. Measurement data used to develop the LUR models were collected during 2008–2009 (BAMSE, GINIplus/LISAplus, PIAMA), 2009 (INMA), 2009–2010 (MAAS), and 2010–2011 (GASPII). The annual average was temporally adjusted using continuous measurement data from a fixed monitor that was used to capture background levels in each study area. Models based on GIS (geographic information system) variables related to traffic, land use, population density, altitude, and regional background pollution were developed using common ESCAPE protocols to predict measured air pollution concentrations.\nSeparate models were developed for nitrogen dioxide (NO2), nitrogen oxides [NOx (NO2 + NO)], PM2.5 (particulate matter ≤ 2.5 μm in diameter), PM2.5 absorbance, PM10 (≤ 10 μm in diameter), and coarse PM (PM10–PM2.5). In addition, two variables were created to describe traffic intensity at the residential address: traffic intensity on the nearest street, and traffic load on all major roads within a 100-m buffer. Annual average air pollution concentrations and traffic intensity variables were assigned to children for the first year of life based on their residential address reported at birth. The LISAplus study centers of Leipzig and Bad Honnef were not included in the ESCAPE exposure assessment, so children from these cities could not be included in the meta-analysis.\nThe air pollution data used to derive the ESCAPE exposure models were measured in 2008–2011, whereas children included in the study cohorts were born as early as 1994. Therefore, we conducted sensitivity analyses using routine monitoring data to back-extrapolate exposure estimates based on LUR to each child’s year of birth. We used two approaches for the back-extrapolation: The first used the ratio of the average concentration measured from the date of birth through the second birthday to the average concentration measured during the ESCAPE monitoring year; the second used the absolute difference between the average concentrations at each time period ( ESCAPE 2013 ). Both methods altered the spatial contrast derived from the current LUR models without affecting the spatial patterns of air pollutants in the study areas.\nFor each cohort, parents reported (yes/no) physician-diagnosed pneumonia, otitis media, and croup during early childhood (see Supplemental Material, p. 2, for the specific questions used for each cohort). Outcomes were assessed at 6 months (GASPII, LISAplus), 1 year (BAMSE, GINIplus, INMA Valencia, LISAplus, PIAMA), 14 months (INMA Gipuzkoa, INMA Sabadell), 15 months (GASPII), 18 months (LISAplus, INMA Asturias), 2 years (BAMSE, GINIplus, LISAplus, PIAMA), and 3 years (MAAS). It was not possible to evaluate respiratory infections restricted to the first 2 years of life for the MAAS birth cohort because these outcomes were not assessed in the full cohort until 3 years of age. Pneumonia data were available for all cohorts; otitis media data were available for all except GINIplus and MAAS; and croup data were available for all except GASPII, the four INMA cohorts, and PIAMA. Cumulative incidence was modeled in each analysis, unless otherwise specified.\nWe used logistic binomial regression in all individual cohort analyses, and statistical significance was defined by p-values < 0.05. Air pollution was entered as a continuous variable and was not transformed. Models were assessed using the Hosmer–Lemeshow goodness-of-fit test and the Pearson’s chi-square test. Potential confounders were identified from previous literature and selected a priori. Individual cohort models were adjusted for municipality/city (BAMSE only), sex, older siblings (any/none), partial or exclusive breastfeeding at 6 months, atopy of either parent, child-care attendance reported at any time during follow-up, maternal smoking during pregnancy, secondhand smoke in the home reported at any time during follow-up (not available for INMA), visible mold or dampness in the home, use of gas stove, birth season (winter: January–March; spring: April–June; summer: July–September; fall: October–December), parental socioeconomic status [highest education attained by either parent (BAMSE, GINIplus, LISAplus, PIAMA, INMA: low, medium, high); highest occupational level by either parent (GASPII: low, medium, high); or household income (MAAS: < £10,000; £10,000–20,000; £20,000–30,000; > £30,000)], and intervention (GINIplus, MAAS, and PIAMA only). Models for traffic intensity and traffic load were additionally adjusted for background NO2 concentrations. Children with missing data for any covariate were excluded from individual analyses. Based on the ESCAPE protocol, we calculated estimates for the following increments in exposure: 10 μg/m3 for NO2, 20 μg/m3 for NOx, 1 unit for PM2.5 absorbance, 5 μg/m3 for PM2.5, 10 μg/m3 for PM10, 5 μg/m3 for coarse PM, 5,000 vehicles/day for traffic intensity on the nearest street; and 4,000 vehicle-km/day for traffic load on major roads within a 100-m buffer. We assessed heterogeneity of effect estimates between studies using the I2 statistic ( Huedo-Medina et al. 2006 ). We used random-effects meta-analysis models to calculate combined estimates ( DerSimonian and Laird 1986 ).\nWe used sensitivity analyses to test the robustness of effect estimates to the inclusion of additional potential confounders: birth weight, maternal age at birth, and area-level socioeconomic indicators. In addition, we stratified associations for outcomes that were diagnosed during the first year of life and outcomes diagnosed during the second year of life for cohorts that completed follow-ups at 1 and 2 years of age (BAMSE, GINIplus, LISAplus, PIAMA). Additional analyses were stratified by sex, parental socioeconomic status (low, middle, or high), and residential mobility (moved from the birth address at any time during the follow-up period) to examine potential effect modification. As noted above, we also performed sensitivity analyses using exposure estimates that were recalculated for selected pollutants using back-extrapolation techniques to assess the consistency of associations. In addition, we performed a sensitivity analysis of the influence of neighborhood clustering by including an area-level variable (BAMSE: neighborhood; GINIplus: ZIP code; LISAplus: ZIP code; INMA: rural indicator; PIAMA: neighborhood) as a random effect in adjusted models. Area-level data were not available for GASPII or MAAS. Finally, we used two-pollutant models to estimate the independent effects of NO2 and PM.\nAll individual and combined analyses were completed using identical protocols. Individual estimates are presented by cohort except for the German birth cohorts (LISAplus and GINIplus), which had almost identical study designs and parental questionnaires, and are presented as GINI/LISA North (Wesel) and GINI/LISA South (Munich) because separate air pollution models were developed for each area as part of ESCAPE. Statistical analyses were completed using SPSS version 20 (IBM SPSS, Armonk, NY, USA) and SAS version 9.1 (SAS Institute Inc., Cary NC, USA).\nResults\nThere was complete outcome (at least one), exposure (a minimum of NO2 and NOx) and potential confounder information for 16,059 children across all 10 cohorts (79.6% of the total recruited population). Children excluded due to missing data were more likely to have parents of lower socioeconomic status (BAMSE, GINI/LISA South, GINI/LISA North, MAAS, PIAMA), mothers who smoked during pregnancy (BAMSE, GASPII, GINI/LISA South, GINI/LISA North, PIAMA); and were less likely to be breastfed for at least 6 months (GASPII, GINI/LISA South, GINI/LISA North, MAAS, PIAMA) or to have atopic parents (GINI/LISA South, INMA Sabadell). Table 1 shows the cumulative incidence of parent-reported physician-diagnosed respiratory infection, by cohort. The cumulative incidence of pneumonia during early childhood ranged from 1.5% in INMA Sabadell to 7.9% in BAMSE (0.7–3.6% during the first year only). Otitis media ranged from 21.8% in GASPII to 50.0% in BAMSE (6.8–26.6% for the first year), and croup ranged from 10.6% in MAAS to 12.9% in GINI/LISA North (4.2–5.6% for the first year). There were differences in breastfeeding, child-care attendance, parental atopy, and secondhand smoke exposure among the cohorts (see Supplemental Material, Table S1). Air pollution concentrations were highest in GASPII and lowest in BAMSE; GINI/LISA South, GINI/LISA North and PIAMA had similar mean concentrations ( Table 1 ). Additional statistics on air pollutant concentrations by cohort are available in Supplemental Material, Table S2. Air pollutant concentrations were moderately to highly correlated (see Supplemental Material, Table S3; e.g., correlation between PM2.5 and NO2 ranged between 0.42 and 0.80, and correlations between PM2.5 absorbance and NO2 ranged between 0.40 and 0.93).\nTable 1 – The cumulative incidence of respiratory infections and distribution of air pollution for each ESCAPE birth cohort.\nView larger image (TIF File)\nAssociations between air pollution and respiratory infection during early childhood are presented in Figure 1 for a) individual and b) combined effect estimates. Table 2 presents combined effect estimates for crude (adjusted for sex and municipality) and adjusted (adjusted for all potential confounders) models and p-values for heterogeneity. The heterogeneity between studies varied and the largest I2 statistics were for models of pneumonia and NO2, PM2.5, and PM10. Effect estimates were robust to adjustment for older siblings, breastfeeding, parental atopy, child care, maternal smoking during pregnancy, environmental tobacco smoke, visible mold or dampness, use of gas stove, birth season, and parental socioeconomic status. For pneumonia, elevated odds ratios (ORs) were found in almost all analyses, and the combined estimates were statistically significant for all measures of air pollution except PM2.5 (OR = 2.58; 95% CI: 0.91, 7.27 for a 5-μg/m3 increase). For otitis media and croup, results were generally null across all analyses except for NO2 and otitis media, for which the adjusted OR was 1.09 (95% CI: 1.02, 1.16 for a 10-μg/m3 increase).\nFigure 1 – Forest plots of individual cohort and combined effect estimates (ORs) by outcome for (A) NO2, (B) NOx, (C) PM2.5, (D) PM2.5 absorbance, (E) PM10, (F) coarse PM, (G) traffic intensity on nearest street, and (H) traffic load on all major roads. Weight indicates relative weight (%) assigned using random-effects meta-analysis. The lifetime cumulative incidence of respiratory infection (pneumonia, otitis media, croup) was assessed at 12 months (INMA Valencia), 14 months (INMA Gipuzkoa, INMA Sabadell), 15 months (GASPII), 18 months (INMA Asturias), 24 months (BAMSE, GINI/LISA North, GINI/LISA South, PIAMA), and 36 months (MAAS) of age. Individual cohort models were adjusted for municipality (BAMSE), sex, older siblings, breastfeeding at 6 months, atopy of either parent, any child-care reported during follow-up, maternal smoking during pregnancy, any environmental tobacco smoke in the child’s home reported during follow-up, visible mold or dampness in the home, use of gas stove, birth season, parental socioeconomic status (low, medium, high), and intervention (GINIplus, MAAS, PIAMA). Associations are presented for the following increments in exposure: 10 μg/m3 for NO2, 20 μg/m3 for NOx, 5 μg/m3 for PM2.5, 1 unit for PM2.5 absorbance, 10 μg/m3 for PM10, 5 μg/m3 for coarse PM, 5,000 vehicles/day for traffic intensity on the nearest street; and 4,000 vehicle-km/day for traffic load on major roads within a 100-m buffer.\nView larger image (TIF File)\nEffect estimates in two-pollutant models that included NO2 plus one of the PM exposures were closer to the null (vs. estimates from single-pollutant models), and the only statistically significant finding was for NO2 and otitis media (OR = 1.13; 95% CI: 1.01, 1.26 for a 10-μg/m3 increase in NO2) when adjusted for coarse PM (see Supplemental Material, Table S4). Confidence intervals increased substantially in two-pollutant models, reflecting the high correlation between pollutants (see Supplemental Material, Table S3).\nAll measures of air pollution were associated with pneumonia (p < 0.05) in analyses restricted to the first year of life (e.g., OR = 4.06; 95% CI: 1.93, 8.57 for a 5-μg/m3 increase in PM2.5) ( Table 3 ). Further, the combined effect estimate for all associations (pneumonia, otitis media, and croup) increased when analyses were restricted to outcomes in the first year of life.\nTable 3 – Adjusted combined estimates for air pollution exposure at the birth address and respiratory infection by year of life [OR (95% CI)].\nView larger image (TIF File)\nStratified meta-analyses suggested slightly stronger effects in females and in those from middle socioeconomic groups (see Supplemental Material, Tables S5 and S6). In analyses stratified by residential mobility during follow-up, the associations between air pollution and respiratory infection were not consistent by strata: Pneumonia effects were greater for movers (OR = 1.62; 95% CI: 1.20, 2.18 vs. 1.21; 95% CI: 0.88, 1.67 for NO2), whereas otitis media effects were greater for nonmovers (OR = 1.08; 95% CI: 1.01, 1.16 vs. 1.03; 95% CI: 0.71, 1.48 for NO2; see Supplemental Material, Table S7). Inclusion of additional covariates into the individual cohort models (birth weight, maternal age and area level socioeconomic indicators) did not change air pollution effect estimates or improve model fit (data not shown). There was no consistent evidence for spatial clustering when area-level variables were included as a random effect in models (data not shown). Finally, analyses using back-extrapolated monitoring data were generally consistent with the main findings (see Supplemental Material, Table S8).\nDiscussion\nAs part of the ESCAPE project we had the unprecedented opportunity to examine outdoor air pollution as a risk factor for respiratory infection during early childhood in an analysis combining 10 European birth cohorts (NTotal = 16,059) with data on parent-reported physician-diagnosed pneumonia, otitis media, and croup; we also examined individual air pollution exposure estimates based on common ESCAPE protocols. We found consistent evidence for an association between air pollution and pneumonia, and some evidence for otitis media, during the first two years of life.\nSimilar to secondhand smoke ( U.S. Department of Health and Human Services 2006 ), air pollution is thought to increase susceptibility to respiratory infections primarily via an inflammatory response ( Li et al. 2008 ). Urban air pollution may impair defense mechanisms ( Clarke et al. 2000 ; Leonardi et al. 2000 ), and oxidant pollutants, in particular, may exacerbate virus-induced inflammation of the respiratory system ( Lambert et al. 2003 ; Spannhake et al. 2002 ).\nAnalyses were restricted to the first years of life to include the period of greatest age-specific incidence of respiratory infections ( Schnabel et al. 2009 ; Walker et al. 2013 ). Our findings suggested that air pollution effects may be slightly stronger during the first year ( Table 3 ). This finding could highlight a unique period of susceptibility when children are at increased risk of respiratory infections due to air pollution ( Gehring et al. 2002 ; Gouveia and Fletcher 2000 ; Heinrich and Slama 2007 ). It is also possible that the null findings for infections during the second year of life are due to increased exposure misclassification as older children may spend less time at their home address due to increased child-care enrollment.\nA unique strength of LUR models is their ability to capture small-scale spatial variability in exposure; however, the measurements used to create the ESCAPE exposure models were taken after the birth year ( Eeftens et al. 2012a ; Cyrys et al. 2012 ), and this may have introduced exposure misclassification. Although it is possible that overall levels of air pollution changed during this period, previous findings suggest that the spatial distribution of air pollutants within each area remained consistent ( Cesaroni et al. 2012 ; Eeftens et al. 2011 ; Wang et al. 2013 ). Further, our sensitivity analyses using monitoring data to back-extrapolate exposure estimates to the actual first year of life were consistent with our main findings (see Supplemental Material, Table S8).\nThe wording of parental questionnaires was similar across each cohort, and previous research has shown good agreement between maternal recall and medical records during early childhood ( D’Souza-Vazirani et al. 2005 ; Vernacchio et al. 2007 ). Geographic differences in the prevalence of outcomes across the cohorts were most pronounced for otitis media and may point to potential diagnostic biases or disease misclassification between countries. It was not possible to adjust for epidemics, the impact of vaccinations, or the frequency of infections because data were not available across all cohorts. Furthermore, defining upper respiratory tract infections (otitis media, croup) by physician diagnosis is complicated by the fact that not all infections present with acute symptoms severe enough to warrant a physician visit, in contrast with pneumonia, which routinely presents with a high fever and/or difficulty breathing ( Edmond et al. 2012 ).\nConclusion\nOur meta-analysis of 10 European birth cohorts found consistent evidence for an association between traffic-related air pollution and pneumonia, and some evidence to suggest an association with otitis media. Policies aimed at reducing air pollution may be successful in reducing the overall burden of pneumonia in early childhood.\nCorrection\nThe value for “Traffic load on major streets within 100-m buffer” for GINI/LISA South in Table 1 was incorrect in the manuscript originally published online. It has been corrected here.\nReferences\nAguilera I, Pedersen M, Garcia-Esteban R, Ballester F, Basterrechea M, Esplugues A, et al. 2013. Early-life exposure to outdoor air pollution and respiratory health, ear infections, and eczema in infants from the INMA study. Environ Health Perspect 121:387–392; doi: 10.1289/ehp.1205281 .\nBateson TF, Schwartz J. 2008. Children’s response to air pollutants. J Toxicol Environ Health A 71(3):238–243.\nBeelen R, Hoek G, Vienneau D, Eeftens M, Dimakopoulou M, Pedeli X, et al. 2013. Development of NO2 and NOx land use regression models for estimating air pollution exposure in 36 study areas in Europe—the ESCAPE project. Atmos Environ 72:10–23.\nBlack RE, Cousens S, Johnson HL, Lawn JE, Rudan I, Bassani DG, et al. 2010. Global, regional, and national causes of child mortality in 2008: a systematic analysis. Lancet 375:1969–1987.\nBrauer M, Gehring U, Brunekreef B, de Jongste J, Gerritsen J, Rovers M, et al. 2006. Traffic-related air pollution and otitis media. Environ Health Perspect 114:1414–1418; doi: 10.1289/ehp.9089 .\nBrunekreef B, Smit J, de Jongste J, Neijens H, Gerritsen J, Postma D, et al. 2002. The Prevention and Incidence of Asthma and Mite Allergy (PIAMA) birth cohort study: design and first results. Pediatr Allergy Immunol 13:55–60.\nCesaroni G, Porta D, Badaloni C, Stafoggia M, Eeftens M, Meliefste K, et al. 2012. Nitrogen dioxide levels estimated from land use regression models several years apart and association with mortality in a large cohort study. Environ Health 11:48; doi: 10.1186/1476-069X-11-48 .\nClarke RW, Antonini JM, Hemenway DR, Frank R, Kleeberger SR, Jakab GJ. 2000. Inhaled particle-bound sulfate: effects on pulmonary inflammatory responses and alveolar macrophage function. Inhal Toxicol 12(3):169–186.\nCustovic A, Simpson BM, Murray CS, Lowe L, Woodcock A; NAC Manchester Asthma and Allergy Study Group. 2002. The National Asthma Campaign Manchester Asthma and Allergy Study. Pediatr Allergy Immunol 13(suppl 15):32–37.\nCyrys J, Eeftens M, Heinrich J, Ampe C, Armengaud A, Beelen R, et al. 2012. Variation of NO2 and NOx concentrations between and within 36 European study areas: results from the ESCAPE study. Atmos Environ 62:374–390.\nda Costa JL, Navarro A, Neves JB, Martin M. 2004. Household wood and charcoal smoke increases risk of otitis media in childhood in Maputo. Int J Epidemiol 33(3):573–578.\nDerSimonian R, Laird N. 1986. Meta-analysis in clinical trials. Control Clin Trials 7(3):177–188.\nD’Souza-Vazirani D, Minkovitz CS, Strobino DM. 2005. Validity of maternal report of acute health care use for children younger than 3 years. Arch Pediatr Adolesc Med 159(2):167–172.\nEdmond K, Scott S, Korczak V, Ward C, Sanderson C, Theodoratou E, et al. 2012. Long term sequelae from childhood pneumonia; systematic review and meta-analysis. PLoS One 7(2):e31239; doi: 10.1371/journal.pone.0031239 .\nEeftens M, Beelen R, de Hoogh K, Bellander T, Cesaroni G, Cirach M, et al. 2012a. Development of land use regression models for PM2.5, PM2.5 absorbance, PM10 and PMcoarse in 20 European study areas; results of the ESCAPE project. Environ Sci Technol 46(20):11195–11205.\nEeftens M, Beelen R, Fischer P, Brunekreef B, Meliefste K, Hoek G. 2011. Stability of measured and modelled spatial contrasts in NO2 over time. Occup Environ Med 68(10):765–770.\nEeftens M, Tsai M-Y, Ampe C, Anwander B, Beelen R, Bellander T, et al. 2012b. Spatial variation of PM2.5, PM10, PM2.5 absorbance and PMcoarse concentrations between and within 20 European study areas and the relationship with NO2—Results of the ESCAPE project. Atmos Environ 62(0):303–317.\nESCAPE (European Study of Cohorts for Air Pollution Effects). 2009. Home page. Available: http://www.escapeproject.eu/ [accessed 22 November 2013].\nESCAPE (European Study of Cohorts for Air Pollution Effects). 2013. Manuals. Available: http://www.escapeproject.eu/manuals/ [accessed 22 November 2013].\nEsplugues A, Ballester F, Estarlich M, Llop S, Fuentes-Leonarte V, Mantilla E, et al. 2011. Outdoor, but not indoor, nitrogen dioxide exposure is associated with persistent cough during the first year of life. Sci Total Environ 409(22):4667–4673.\nGehring U, Cyrys J, Sedlmeir G, Brunekreef B, Bellander T, Fischer P, et al. 2002. Traffic-related air pollution and respiratory health during the first 2 yrs of life. Eur Respir J 19(4):690–698.\nGouveia N, Fletcher T. 2000. Respiratory diseases in children and outdoor air pollution in São Paulo, Brazil: a time series analysis. Occup Environ Med 57(7):477–483.\nGuxens M, Aguilera I, Ballester F, Estarlich M, Fernández-Somoano A, Lertxundi A, et al. 2012. Prenatal exposure to residential air pollution and infant mental development: modulation by antioxidants and detoxification factors. Environ Health Perspect 120:144–149; doi: 10.1289/ehp.1103469 .\nHeinrich J, Bolte G, Hölscher B, Douwes J, Lehmann I, Fahlbusch B, et al. 2002. Allergens and endotoxin on mothers’ mattresses and total immunoglobulin E in cord blood of neonates. Eur Respir J 20(3):617–623.\nHeinrich J, Slama R. 2007. Fine particles, a major threat to children. Int J Hyg Environ Health 210(5):617–22.\nHuedo-Medina TB, Sánchez-Meca J, Marín-Martínez F, Botella J. 2006. Assessing heterogeneity in meta-analysis: Q statistic or I2 index? Psychol Methods 11(2):193–206.\nJedrychowski WA, Perera FP, Spengler JD, Mroz E, Stigter L, Flak E, et al. 2013. Intrauterine exposure to fine particulate matter as a risk factor for increased susceptibility to acute broncho-pulmonary infections in early childhood. Int J Hyg Environ Health 216(4): 395–401.\nLambert AL, Mangum JB, DeLorme MP, Everitt JI. 2003. Ultrafine carbon black particles enhance respiratory syncytial virus-induced airway reactivity, pulmonary inflammation, and chemokine expression. Toxicol Sci 72(2):339–346.\nLeonardi GS, Houthuijs D, Steerenberg PA, Fletcher T, Armstrong B, Antova T, et al. 2000. Immune biomarkers in relation to exposure to particulate matter: a cross-sectional survey in 17 cities of Central Europe. Inhal Toxicol 12(suppl 4):1–14.\nLi N, Xia T, Nel AE. 2008. The role of oxidative stress in ambient particulate matter-induced lung diseases and its implications in the toxicity of engineered nanoparticles. Free Radic Biol Med 44(9):1689–1699.\nLin M, Stieb DM, Chen Y. 2005. Coarse particulate matter and hospitalization for respiratory infections in children younger than 15 years in Toronto: a case-crossover analysis. Pediatrics 116(2):e235–e240.\nMacIntyre EA, Karr CJ, Koehoorn M, Demers PA, Tamburic L, Lencar C, et al. 2011. Residential air pollution and otitis media during the first two years of life. Epidemiology 22(1):81–89.\nMahalanabis D, Gupta S, Paul D, Gupta A, Lahiri M, Khaled MA. 2002. Risk factors for pneumonia in infants and young children and the role of solid fuel for cooking: a case-control study. Epidemiol Infect 129(1):65–71.\nMehta S, Shin H, Burnett R, North T, Cohen AJ. 2013. Ambient particulate air pollution and acute lower respiratory infections: a systematic review and implications for estimating the global burden of disease. Air Qual Atmos Health 6(1):69–83.\nPorta D, Forastiere F, Di Lallo D, Perucci CA, Grupo Collaborativo GASPII. 2007. Enrolment and follow-up of a birth cohort in Rome. Epidemiol Prev 31(6):303–308.\nSchnabel E, Sausenthaler S, Brockow I, Liese J, Herbarth O, Michael B, et al. 2009. Burden of otitis media and pneumonia in children up to 6 years of age: results of the LISA birth cohort. Eur J Pediatr 168(10):1251–1257.\nSchwartz J, Spix C, Wichmann HE, Malin E. 1991. Air pollution and acute respiratory illness in five German communities. Environ Res 56:1–14.\nSpannhake EW, Reddy SP, Jacoby DB, Yu XY, Saatian B, Tian J. 2002. Synergism between rhinovirus infection and oxidant pollutant exposure enhances airway epithelial cell cytokine production. Environ Health Perspect 110:665–670.\nU.S. Department of Health and Human Services. 2006. The Health Consequences of Involuntary Exposure to Tobacco Smoke: A Report of the Surgeon General. Washington, DC:U.S. Department of Health and Human Services.\nVernacchio L, Vezina RM, Ozonoff A, Mitchell AA. 2007. Validity of parental reporting of recent episodes of acute otitis media: a Slone Center Office-Based Research (SCOR) Network study. J Am Board Fam Med 20(2):160–163.\nWalker CLF, Rudan I, Liu L, Nair H, Theodoratou E, Bhutta ZA, et al. 2013. Global burden of childhood pneumonia and diarrhoea. Lancet 381:1405–1416.\nWang R, Henderson SB, Sbihi H, Allen RW, Brauer M. 2013. Temporal stability of land use regression models for traffic-related air pollution. Atmos Environ 64:312–319.\nWickman M, Kull I, Pershagen G, Nordvall SL. 2002. The BAMSE project: presentation of a prospective longitudinal birth cohort study. Pediatr Allergy Immunol 13(suppl 15):11–13.\nWilliams BG, Gouws E, Boschi-Pinto C, Bryce J, Dye C. 2002. Estimates of world-wide distribution of child deaths from acute respiratory infections. Lancet Infect Dis 2:25–32.\nZirngibl A, Franke K, Gehring U, von Berg A, Berdel D, Bauer CP, et al. 2002. Exposure to pets and atopic dermatitis during the first two years of life. A cohort study. Pediatr Allergy Immunol 13(6):394–401.\nHighlighted Sections\n""","0.14785789","""https://ehp.niehs.nih.gov/1306755/""","[-0.178219,51.500505]"
"""The_University_of_Edinburgh""","""Inherent Tracers for Carbon Capture and Storage in Sedimentary Formations: Composition and Applications - Environmental Science & Technology (ACS Publications)""","""Inherent Tracers for Carbon Capture and Storage in Sedimentary Formations: Composition and Applications\n† School of Geosciences, The University of Edinburgh, Grant Institute, King’s Buildings, James Hutton Road, Edinburgh EH9 3FE, U.K.\n‡ Isotope Geosciences Unit, Scottish Universities Environmental Research Centre, Rankine Avenue, East Kilbride G75 0QF, U.K.\nEnviron. Sci. Technol.\n, 2016, 50 (15), pp 7939–7955\nDOI: 10.1021/acs.est.6b01548\nPublication Date (Web): July 5, 2016\nCopyright © 2016 American Chemical Society\n*Phone: +44 (0)131 6507010; fax: +44(0)131 6507340; email: sflude@gmail.com .\nACS AuthorChoice - This is an open access article published under a Creative Commons Non-Commercial No Derivative Works (CC-BY-NC-ND) Attribution License , which permits copying and redistribution of the article, and creation of adaptations, all for non-commercial purposes.\nReferences\nAbstract\nInherent tracers—the “natural” isotopic and trace gas composition of captured CO2 streams—are potentially powerful tracers for use in CCS technology. This review outlines for the first time the expected carbon isotope and noble gas compositions of captured CO2 streams from a range of feedstocks, CO2-generating processes, and carbon capture techniques. The C-isotope composition of captured CO2 will be most strongly controlled by the feedstock, but significant isotope fractionation is possible during capture; noble gas concentrations will be controlled by the capture technique employed. Comparison with likely baseline data suggests that CO2 generated from fossil fuel feedstocks will often have δ13C distinguishable from storage reservoir CO2. Noble gases in amine-captured CO2 streams are likely to be low concentration, with isotopic ratios dependent on the feedstock, but CO2 captured from oxyfuel plants may be strongly enriched in Kr and Xe which are potentially valuable subsurface tracers. CO2 streams derived from fossil fuels will have noble gas isotope ratios reflecting a radiogenic component that will be difficult to distinguish in the storage reservoir, but inheritance of radiogenic components will provide an easily recognizable signature in the case of any unplanned migration into shallow aquifers or to the surface.\n1 Introduction\n1.1Need for CCS\nThe link between atmospheric concentrations of anthropogenically produced CO2 and global warming is unequivocal, (1-4) and CO2 emissions must be drastically reduced, and eventually stopped, if we are to avoid catastrophic, irreversible climate change. Carbon capture and storage (CCS) features prominently in all scenarios that consider timely and feasible reductions in CO2 emissions. (1, 5) Importantly, CCS is the only technology that can substantially reduce carbon emissions from industrial processes such as chemical synthesis and steel production. Climate models are increasingly relying on the use of negative emissions to limit global average temperature rise to 2 °C and include large amounts of bioenergy combined with CCS (BECCS), as this is the only feasible, industrial-scale negative emissions technology currently available. (6)\nCarbon capture in the context of this review involves removal of CO2 from the flue gases of point-source emitters, such as power stations and industrial plants, to produce a stream of high concentration CO2. Current well-developed capture techniques are often classified into one of three categories. (1) “Amine capture”, also referred to as “post-combustion capture” because it was originally envisaged to be applied most often to fossil fuel or biomass combustion-fired power stations, removes CO2 from a gas stream by chemical reaction of the CO2 with an amine solvent (with or without the use of membranes) and is already widely used by the hydrocarbon industry to remove CO2 from produced natural gas. (7) (2) “Oxycombustion” or “oxyfuel combustion” produces a high CO2 purity flue gas by burning fuel in an oxygen-rich atmosphere, rather than air, and recycling the flue gas into the combustion chamber. (3) “Pre-combustion capture” collects the CO2 produced during gasification processes and is so named for the potential to generate hydrogen fuel, which can be combusted without producing CO2 to produce electricity. These general carbon capture terms were developed in the context of CCS being most readily applied to electricity generation (hence the focus on pre- or post-combustion). In reality, these capture techniques are already applied to a much wider range of industrial activities, such as natural gas processing, synfuel production, and chemical/fertilizer manufacture (see Section 3 ), so classification according to the stage of electricity generation is no longer appropriate. As such, we use the terms “amine capture”, “oxyfuel” and “gasification” when discussing these three different types of capture technique. Additional pressure-based adsorption techniques onto solid adsorbents (e.g., pressure-swing adsorption) or organic solvents are also used during gas purification, especially as part of the gasification processes.\nThe efficiency of CO2 capture and the purity of the captured CO2 stream vary between ∼95% and 99.9% (2, 8) depending on the capture method, post-capture cleanup, and specific conditions employed. Industrial specifications require a CO2 purity of >95% for transport and storage, to maximize density and avoid problematic phase changes, so end-product CO2 streams tend to contain 90–99% CO2, with minor to trace amounts of N2, hydrocarbons, H2S, NOX, SOX, O2, H2O, and noble gases (especially Ar). (7-9)\n1.2Need for CO2 Tracers\nCommercial-scale carbon-storage projects will be required by governmental regulatory bodies to monitor CO2 injected for storage and mitigate any unplanned behavior, such as migration out of the storage reservoir (leakage) or to the surface (seepage), in the storage complex. (10) Furthermore, being able to trace the migration and reactions of injected CO2 in the subsurface is fundamental to the continual assessment of injectivity, identification of CO2 trapping mechanisms, and quantification of storage capacity, all of which need to be well-understood and characterized to ensure storage security. Geophysical techniques, while useful monitoring tools, remain limited in their ability to quantify CO2 pore space saturation and dissolution at high spatial resolution. (11-13) Seepage rates of 0.001–0.01% per year are generally considered acceptable on a climate accounting basis, amounting to a loss of ∼1% of the injected CO2 over 100 years, a target adopted by the U.S. Department of Energy. (14, 15) Conclusive detection of such seepage rates by measurement of CO2 concentrations remains problematic due to natural background CO2 fluctuations. A potential solution to this problem is the use of geochemical tracers, detectable at low concentrations due to their low background level in the atmosphere or storage complex. Addition of geochemical tracers for environmental monitoring and interpretation of reservoir dynamics is a long-standing practice in the hydrocarbon industry, with perfluorocarbon tracer compounds (PFTs), (16) tritiated and perdeuterated CH4 and H2O, freons, sulfur hexafluoride (SF6) (17) and noble gases such as Kr and Xe (18) proving to be particularly useful tracers.\nTracers can be classified in terms of their relationship to the injected CO2 as (1) added tracers (substances added to the CO2 stream prior to injection, e.g., SF6), (2) inherent or natural tracers (substances already present in the CO2 stream or the isotopic composition of the CO2 itself), or (3) indirect tracers (changes to baseline values resulting from interaction of the CO2 with the natural environment, e.g., pH or cation content due to mineral dissolution). (19) Adding geochemical tracers to injected CO2 can facilitate detailed monitoring and modeling of CO2 storage, but concerns remain regarding the economic cost of tracers in commercial-scale storage sites, the possibility of increased background (lower sensitivity)/site contamination, and the environmental impact of such compounds. (17, 20-22) PFTs and SF6, in particular, are potent greenhouse gases with atmospheric residence times of 1000s of years. (17, 22)\nUsing the isotopic and trace element geochemistry of the injected CO2 itself as a tracer has the potential to facilitate in-reservoir tracing and leakage monitoring with minimal economic and environmental impact compared with added tracers. Furthermore, Article 12.1 of the EU directive on CCS states that “no waste or other matter may be added for the purpose of disposing of [the CO2]”; (10) while provision has been made in the directive for allowing the addition of tracers, these require consideration on a case-by-case basis, so use of inherent CO2 tracers may help to simplify applications for CO2-storage permits.\nHere, we describe the inherent tracers which will be most useful for fingerprinting and monitoring CO2 during storage, summarize the currently available information regarding inherent tracer signatures in both captured CO2 and potential storage reservoirs, and highlight the further research necessary to facilitate the application of inherent tracer geochemistry to CCS. As we will show, the feasibility of using inherent tracers for measuring, monitoring, and verification (MMV) depends on a number of variables, including the baseline composition of reservoirs and overburden of interest and the inherent tracer composition of the captured CO2 stream. These will vary extensively depending on a number of factors, and hence specific discussion of detection limits of the inherent tracers we describe is out of the scope of this review.\nReferences\n2 Inherent Tracers\nFor tracers to be effective, their compositions must be distinct from that of the storage site, including the host reservoir, overburden, and local atmosphere. In this section we provide a brief background to and highlight further information on the isotope and trace gas systems that may be used as inherent tracers.\n2.1CO2 Isotopic Composition\nThe stable isotopes of C and O of injected CO2 are an obvious potential tracer and have been successfully used in a number of projects to identify CO2 migration and quantify pore space saturation and dissolution of CO2 (see section 6 ). Much of this work and background theory relevant to CCS have recently been summarized in a number of review papers. (12, 19, 23-26) However, the isotopic composition of the captured CO2 itself has received less attention, which we address in section 3 . For this review, we concentrate on using C-isotopes as a means of fingerprinting the injected CO2. While O-isotopes of captured CO2 may be a useful, quantitative monitoring tool, (11) rapid equilibration of O-isotopes between CO2 and water (27) means that the O-isotope composition of CO2 will be controlled by any volumentrically significant water it interacts with; as a result the O-isotope composition of CO2 is expected to change significantly after injection into the storage reservoir and so not provide a diagnostic tracer of the CO2 itself. Hence O-isotopes are not discussed in detail in this review.\nFor context, the range of isotopic compositions occurring in nature are shown in Figure 1 with details provided in Supporting Information Table S1. C-isotope values are presented in δ13C relative to Vienna Pee Dee Belemnite (V-PDB), where\nFigure 1. C-isotope values for a range of naturally occurring materials. Black boxes indicate CO2. White boxes are other substances. Arrows represent values off the scale of the diagram. See Supporting Information Table S1 for references. Note that a wide range of δ13C values are covered by naturally occurring CO2 sources.\nIsotope fractionation, enrichment factors (ε), and conversion between isotopic values relative to different standards are covered in detail in recent review papers which we refer interested readers to. (12, 19, 23-26)\n2.2Noble Gases\nNoble gases (He, Ne, Ar, Kr, and Xe) are particularly useful for tracing interaction of gases with fluids due to their unreactive nature and Henry’s Law controlled solubility; in general, solubility increases with elemental mass and decreases with increasing temperature. Noble gases will preferentially partition into gas > oil > fresh water > saline water, so mixing and migration of different fluids and gases in the subsurface may lead to multiple re-equilibration events that result in elemental fractionation of the noble gases. (28, 29) Hence, noble gases are being increasingly used to identify and quantify hydrocarbon migration pathways from modeling the elemental fractionation that occurs during partitioning between water, oil, and gas. (30, 32) Noble gases in the subsurface can be considered a mixture of three components: (33) (1) atmospheric derived noble gases, introduced to the subsurface by equilibration with meteoric water and recharge; (2) radiogenic noble gases produced in situ by decay of radioactive elements; (3) terrigenic fluids originating from defined geochemical reservoirs. Two common terrigenic components in sedimentary formations are crust and mantle. Mantle noble gases are enriched in 3He, with 3He/4He as high as 70 RA (RA being 3He/4He of atmosphere, 1.339 × 10–6) while crustal noble gases are enriched in radiogenic noble gases (4He and 40Ar) and have 3He/4He < 0.7 RA32. In subsurface fluids a distinction exists between radiogenic and crustal components; the terrigenic crustal component is derived from radioactive decay, but represents the cumulative accumulation in the host rock, and is thus controlled by the age and chemistry of the geological formation hosting the fluid and the openness of the system, while the radiogenic component is added to the fluid by in situ radioactive decay and is thus a function of the host formation chemistry and fluid residence time. (33) Summaries of noble gas data relevant to CCS are shown in Table 1 .\nTable 1. Summary of Noble Gas Concentrations and Solubilities\n \nReferences\n3 Geochemistry of the Captured CO2 Stream\nTwo sources of information are available to assess the likely composition of the captured CO2 stream: (1) a limited number of direct measurements on captured CO2 and (2) hypothetical considerations of the feedstocks and processes involved in CO2 generation. We analyze this information to draw conclusions about the range of CO2 compositions that can be expected for different feedstocks and processes, which are summarized in Table 2 . Further information regarding δ13C and noble gas content of a range of relevant feedstocks are provided in the Supporting Information .\nTable 2. Expected Carbon Isotope and Noble Gas Compositions of the CO2 Stream Generated by a Variety of Industrial and Energy-Generating Technologies, Relative to Their Source Components (Feedstock, Combustion Atmosphere, etc.) and with Likely Fractionations Where Relevant a\nTable a\nSubsequent amine capture or physical absorption are not included. For processes that will be followed with amine capture (* in “process” column), add δ13C enrichment of −20 to +2.5‰ and depletion of noble gas concentrations (especially light noble gases). For physical absorption in organic solvents (may or may not be used with all other processes), add a small positive C-isotopic enrichment, dependent on the relative efficiencies of the absorption and desorption processes, and depletion of noble gas concentrations (especially light noble gases). References for the C-isotope composition of feedstock and other components are given in the text and in the Supporting Information tables, and values are summarised in Figure 1 .\n3.1Direct Measurement of the Captured CO2 Stream\nCCS projects have reported captured CO2 stream data from two oxycombustion plants, three synfuel/hydrogen production plants, two fertilizer manufacturers, one natural gas processing plant, and one unknown combustion source. δ13C has been the most widely analyzed tracer in captured CO2 to date, giving a wide range of values from −51 to −4.7‰. Limited noble gas data are available for CO2 streams from fertilizer and oxyfuel plants. The limited available data is consistent with theoretical considerations discussed below, but the uncertainties involved (most often relating to the precise feedstock composition) hinder robust predictions of captured CO2 stream chemistry, and more studies are needed to clarify the δ13C of captured CO2.\n3.2Fuel Combustion for Energy Production\nPower stations are some of the largest point sources of CO2 emissions in the developed world, making them obvious targets for CCS. In most cases, power is generated by combustion of material, often fossil fuels but with an increasing use of biomass, to drive a turbine and generate electricity. Capture of combustion-produced CO2 will be either via amine capture or oxyfuel methods.\n3.2.1Carbon Isotopes\nFor CO2 derived from fossil fuel combustion, Widory (34) identified 13C depletion in the CO2 relative to the fuel, amounting to δ13C ∼ −1.3‰ for a range of fossil fuel types (solid, liquid, and gas). More recent work has measured δ13C during coal combustion and found that resulting CO2 has δ13C between −2.39 and +2.33‰ relative to the coal feedstock. (35) δ13CCO2 of −46.2‰ (36) has been reported for CO2 derived from combustion of natural gas, which is consistent with (the admittedly wide range of) expected values ( Figure 1 ), but the capture method was not reported.\nFor biomass, complete combustion of C3 and C4 plants produces CO2 with the same C-isotope composition of the bulk plant, but partial combustion of C4 plants may result in 13C enrichment of the CO2 (up to +4‰ at 3% combustion). (37) The C-isotope signature of CO2 produced by burning biomass will therefore depend on the specific feedstock and the efficiency of the combustion process. Given the higher temperatures associated with oxycombustion, we might expect a higher efficiency of biomass combustion compared to normal combustion, so no isotopic fractionation would be expected. Reported δ13C of CO2 from oxycombustion of natural gas (−40‰, Rousse CCS project (38) ) and lignite (−26‰, Ketzin CCS project; see Supporting Information Table S2) are consistent with expected values (−61 to −21.3‰ and −31.3 to −21.3‰, respectively; Table 2 ).\n3.2.2Noble Gases\nTo the best of our knowledge, very little data are available on the noble gas content of combustion gases. Noble gases in combustion flue gases will be derived from the material being combusted and from the combustion atmosphere (air for normal combustion; cryogenic oxygen for oxyfuel). Concentrations of most noble gases in hydrocarbons are generally 2–3 orders of magnitude lower than in air ( Table 1 ), so atmospheric noble gases are expected to dominate. A radiogenic or terrigenic isotopic component might be resolvable in hydrocarbon derived CO2 due to elevated 4He in fossil fuels.\nFor oxyfuel, additional heavy noble gases (Ar, Kr, and Xe) may be introduced with the cryogenically purified O2. CO2 injected at the Rousse CCS project was derived from oxycombustion of natural gas. (38) The source natural gas fuel was enriched in 4He and depleted in 20Ne, 36Ar, 40Ar, and 84Kr relative to air; (38) the resulting CO2 remained enriched in 4He and depleted in 20Ne relative to air, but Ar isotopes had concentrations similar to air and 84Kr was enriched by an order of magnitude compared to air. (38) Enrichments of Ar (up to 2%) in oxyfuel-captured CO2 have also been observed during oxyfuel pilot experiments, (8) despite distillation procedures designed to remove inert gases. (7)\n3.3Gasification Processes/Synfuel Production/Pre-combustion CO2 Capture\nHere we use the term “gasification processes” to refer to the range of reactions used to generate Syngas (H2 and CO) from a variety of fuel stocks. Syngas can be further processed by Fischer–Tropsch reactions to create a range of chemicals and synthetic fuels (synfuels), including synthetic natural gas (SNG) and Fischer–Tropsch liquid fuels. These chemical reactions are described in the Supporting Information .\nSyngas is generated by a two stage chemical reaction. At the first stage, carbon monoxide (CO) and H2 are produced from the feedstock, via either steam reforming or partial oxidation, followed by addition of steam to stimulate a “shift reaction” that converts CO to CO2, generating more H2. (7) For synfuel production the syngas stream is passed through a synthesis reactor where CO and H2 are catalytically converted to the desired chemical. (7) CO2 from the entire process is captured both upstream and downstream of the synthesis reactor and the captured CO2 will be a combination of CO2 generated from different gasification stages, with a decreased input from the shift reaction as CO is used in Fischer–Tropsch reactions. The resulting CO2 is removed from the gas stream by either chemical solvents (e.g., amine capture) or physical solvents (e.g., cold methanol). (7)\n3.3.1Carbon Isotopes\nFractionation of C-isotopes during gasification is likely due to increased bond strength of 13C–12C compared to 12C–12C, resulting in 13C depletion in low molecular weight gases and 13C enrichment in heavy residues such as tar and vacuum bottoms. (39) C-isotope ratios will be δ13CCO < δ13CCH4 < δ13Chydrocarbons < δ13Ccoal < δ13Cchar < δ13CCO2 at typical gasification temperatures (>1000 °C). (40-42) This suggests that any CO2 produced by incomplete reactions in the first stage of gasification is likely to be enriched in 13C compared to the original feedstock, while the resulting CO will be depleted in 13C. This agrees with experimental results from underground coal gasification plants, (39, 41, 43) and natural gas generation via pyrolysis of coal and lignite, (44, 45) which produced CO2 enriched in 13C by 2–10‰ relative to the feedstock. Conversely, CO2 generated from CO via the shift reaction will be depleted in 13C. In a simplistic scenario, all CO2 resulting from gasification will be derived from the shift reaction, so we could expect CO2 captured from Syngas plants to be the same as or isotopically lighter than the feedstock, depending on the efficiency of the gasification reactions and proportion of feedstock not converted to Syngas. For synfuel and F-T plants, the 13C-depleted CO will be used in chemical synthesis, so early generated, CO2 slightly enriched in 13C will dominate. In reality, gasification of solid fuels is likely to produce CO2 and CH4 in addition to CO and H2, so the isotopic composition of resulting CO2 will depend on the proportions of 13C-enriched, early produced CO2 and 13C-depleted, shift-reaction CO2. It is thus difficult to precisely predict the C-isotopic composition of CO2 captured from syngas and synfuel plants. However, it is likely that the various fractionation and mixing processes will average out, giving CO2 with an isotopic composition similar to or slightly more 13C-depleted than the feedstock for syngas plants, and similar to or slightly more 13C-enriched than the feedstock for chemical and synfuel plants.\nOne of the sources of CO2 injected at the Ketzin project was reportedly a byproduct of hydrogen production (46) at an oil refinery. (47) This CO2 has δ13C ∼ −30.5‰ (47) ( Table S2 ) which is indistinguishable from the range of δ13C values expected for oil (−18 to −36 ‰, Table 2 ). CO2 injected in the Frio project was derived from a refinery in Bay City, TX, USA, and the Donaldsonville fertilizer plant, Louisiana. (48) Reported δ13C of the injected CO2 was −51 to −35‰. (49) While the end-member δ13C compositions were not reported, the values are consistent with those for natural gas (fertilizer plant) and oil (refinery) (see Table 2 and Figure 1 ). CO2 captured from the Scotford Bitumen Upgrader, Canada, was derived from hydrogen production and purified using amine capture; (50) most hydrogen production in the region is produced using steam methane reforming. (51) The captured CO2 has δ13C of −37‰, (52) which is within the range of δ13C values for natural gas. While the range of possible feedstock compositions is too wide to be conclusive, these data are consistent with our above predictions. The CO2 injected at Weyburn is generated via coal gasification at the Great Plains Synfuel Plant, Beulah, ND, USA, and has a δ13C of −20 to −21‰. (53) This is indistinguishable from the (wide) range of δ13C for coal of −30 to −20‰ ( Table 2 ). Data are not available for the coal and lignite used in the Synfuel plant, but coals and lignite from North Dakota have δ13C between −25 and −23‰ with a minority of coal beds reaching −20‰. (54) The captured CO2 from the Synfuel plant is thus at the 13C-enriched end of the range of likely feedstock isotope values, consistent with our prior discussion.\n3.3.2Noble Gases\nThe noble gas composition of the captured CO2 stream generated by gasification processes is likely to be controlled by the noble gas content of the feedstock and the steam and oxygen used in the gasification processes. Steam is likely to introduce noble gases that are a mixture of atmosphere and air saturated water (ASW) for the source water. Gasifiers that use partial oxidation rather than steam reforming will likely produce CO2 enriched in heavy noble gases (Ar, Kr, and Xe) from added O2.\n3.4Fermentation\nFermentation of biomass to produce ethanol as a sustainable fuel source is a well-developed industry in the USA and Brazil; while the total anthropogenic CO2 emissions from bioethanol fermentation make up less than 1% of global CO2 emissions, the CO2 gas stream is of high purity and thus a suitable target for early adoption of CCS. (7) The two main crops used for bioethanol production are currently corn/maize (USA) and sugar cane (Brazil), both of which are C4 photosynthetic pathway plants. (55) Various other C4 crops, such as miscanthus switchgrass, and C3 plants, such as poplar, (56) are under investigation as suitable bioethanol feedstocks due to their ability to grow in relatively arid climates and their lack of economic competition as a food crop. (55) Ethanol is produced from the feedstock by fermentation of the sugars and starches in the biomass, generating a pure stream of CO2 via (57)\n(1)\n3.4.1Carbon Isotopes\nThe carbon isotopic composition of plant sugars generally reflects the bulk plant composition; δ13C of glucose from sugar beet (C3) is ∼−25.1‰ (58) (cf. −30 to −24‰, Table 2 ) and from maize (C4) is δ13C ∼ −10.5‰ (58) (cf. −15 to −10‰, Table 2 ). Carbon isotopes are not evenly distributed within the glucose molecules and this results in fractionation of C-isotopes during fermentation; (58, 59) the third and fourth carbon atoms in the glucose chain are enriched in 13C relative to the bulk sugar, and these form the resulting CO2. (59) Different degrees of 13C enrichment of third and fourth position C atoms occur between C3 and C4 photosynthetic pathway plants, resulting in hypothetical 13C enrichment of fermentation-produced CO2 over glucose of ∼+8.2‰ for C3 plants and +4.5‰ for C4 plants. (59) Measured CO2–glucose isotope fractionation factors range from +7.4 to +4.6‰ for C3 plants and +5.1‰ for C4 plants. (59-61) Apples are C3 plants and CO2 produced during fermentation of cider has been measured with δ13C of −25 to −21‰, which is enriched by at least 3‰ relative to C3 plants. (62)\nAssuming that bioethanol feedstock will be dominated by C4 biomass and that CO2 produced by fermentation is enriched in 13C by 4–6‰ relative to the original sugars, we can expect CO2 captured from fermentation plants to have δ13C of ∼−11 to −4‰.\n3.4.2Noble Gases\nThe main source of noble gases during fermentation will be air saturated water (ASW) in the fermenting solution. Noble gases are more soluble in organic solvents, so we would expect solubility to increase as fermentation proceeds, resulting in noble gas depletion in the CO2 stream.\n3.5Cement Industry\nCement production (including energy to drive the process and indirect emissions) contributes ∼6% of global anthropogenic CO2 emissions, ∼50% of which is from calcination of limestone to produce lime and CO2: (63, 64)\n(2)\nThe remaining emissions are from the energy required to fire the kiln; coal is commonly used but other fuels, such as natural gas, may be used. Likely carbon capture solutions for the cement industry include oxyfuel combustion to heat the kiln or amine capture for both kiln combustion and calcination gases. (63)\n3.5.1Carbon Isotopes\nCalcination reactions are assumed to not cause isotopic fractionation, so the resulting CO2 has the same isotopic composition as the initial carbonate (65, 66) —i.e., δ13C ∼ 0. Assuming a 50:50 mixture of CO2 derived from calcination and from coal combustion, we would expect CO2 emitted from cement factories to have δ13C between ∼−11 and −16‰.\n3.5.2Noble Gases\nSince the noble gas content of limestone is low (see Supporting Information section S.1.5), calcination of limestone is unlikely to significantly contribute noble gases to the CO2 stream, which will be dominated by noble gases from fossil fuel combustion from firing the kiln.\n3.6Iron and Steel Industry\nThe steel industry generates 1.9 tonnes of CO2 per tonne of steel (67) contributing 4–7% of global anthropogenic CO2 emissions. CO2 is generated from two processes: energy for steel production by burning of fuel and the use of reducing agents for steel production from iron ore, the most readily available reducing agent being coal. (67) Integrated steel plants (ISP) use mostly coal, with minor natural gas and oil, as both the fuel and reducing agent, while mini-mill plants use electric furnaces to heat and melt scrap or direct-reduced iron (DRI); (7) while mini-mill plants may not directly produce CO2 emissions, DRI is produced by reacting iron ore with H2 and CO to form iron + H2O + CO2. (7)\n3.6.1Carbon Isotopes\nAccording to our investigations, there are no published data for carbon isotope fractionation between steel and CO2; hence estimating δ13C of CO2 produced by integrated steel plants is difficult, but likely to be dominated by combustion CO2 (so δ13C of −31 to −21‰). In the case of DRI production an obvious source of H2 and CO for the reduction process is Syngas. In this case, the δ13C of CO2 resulting from iron reduction would likely mirror that of the CO, as discussed for Syngas production (i.e., slightly depleted in 13C relative to the gasification feedstock— section 3.3 ).\n3.6.2Noble Gases\nThe overall noble gas budget of CO2 emitted from steel plants will be dominated by atmospheric noble gases incorporated during combustion, for integrated steel plants, and noble gases introduced during syngas production, for mini-mill plants. However, given the low concentration of He in air, enrichment of iron ore derived radiogenic 4He may be significant.\n3.7CO2 Separation\n3.7.1Chemical Absorption\nChemical absorption involves passing flue gases through a solvent with a high affinity for CO2 (most commonly an amine solvent). In a typical amine capture process a CO2-bearing flue gas is reacted with the amine solvent at ∼40 to 60 °C and the remaining flue gas (which will contain some residual CO2) cleaned and vented; the CO2-bearing solvent is transferred to a desorber vessel and heated to 100–140 °C to reverse the CO2-binding chemical reaction and release a stream of pure (>99%) CO2 gas. (7, 68) Typical CO2 recoveries are 80–95% of the CO2 in the flue gas. (7) Such techniques are commonly employed to remove CO2 from natural gas, before it is piped to national gas grids. (7) Various capture plants and aqueous amine solvents are being developed for chemical absorption of CO2. The effects on inherent tracer composition will likely depend on the relative efficiencies of the absorption/desorption processes used by the capture process, the specific chemical reaction pathways that occur and the temperature and pH of the reactions. Two reaction pathways are common for amine solvents: bicarbonate (HCO3–) and carbamate (NH2CO2–) formation. (68)\nCarbon Isotopes\nNo data are yet available for C-isotope fractionation in the amine solutions commonly used in CO2 capture. For water, C-isotope fractionation between CO2 gas and bicarbonate is greater at lower temperatures. (27) In terms of carbon capture, this suggests that greater isotopic fractionation will take place during the absorption stage than the desorption stage. Below, we use Rayleigh Fractionation (27) to calculate expected δ13C values for absorbed and desorbed CO2.\nIn water at typical amine absorption temperatures (40–60 °C), the bicarbonate–CO2 enrichment factor will be between +4 and +7‰. (27, 69) If 85–99% of the CO2 dissolves to form bicarbonate in the amine solution, the resulting bicarbonate will be enriched in 13C by 0 to +2.34 ‰ relative to the original CO2 flue gas. At desorption temperatures (100–140 °C), the HCO3––CO2 enrichment factor will be ±1‰, (69) and if 99% of the bicarbonate is desorbed, the resulting CO2 will have a δ13C value between −0.06 and +0.06‰ compared to that of the saturated bicarbonate. The net enrichment of captured CO2 relative to original flue CO2 will therefore be between −0.06 and +2.4 ‰, depending on the absorption and desorption temperatures.\nAn isotope fractionation factor of +1.011 (equivalent to an enrichment factor of ∼ +11‰) has been determined for carbamate relative to aqueous CO2. (70) 13C enrichment between gaseous and aqueous CO2 in fresh water at typical amine absorption temperatures (40–60 °C) is −0.9 to −1.0‰, (27) so the net isotope enrichment factor of carbamate relative to the original CO2 flue gas will be ∼+10‰. If 85–99% of the CO2 dissolves to form carbamate in the amine solution, the resulting carbamate will be enriched in 13C by +0.5 to +3‰ relative to the original flue gas CO2. If 99% of the carbamate is desorbed, the resulting CO2 will have δ13C ∼ 0.5‰ lower than the saturated carbamate, resulting in a net enrichment of 13C in the captured CO2 of 0 to +2.5‰ relative to the original flue gas.\nThe anticipated 13C enrichment in CO2 from amine capture, relative to the original flue gas CO2, will be between −0.06 and +2.5‰, with the exact enrichment value dependent on absorption and desorption temperature, and the relative proportions of bicarbonate and carbamate species in the amine solution.\nHowever, work investigating C-isotope fractionation during absorption of CO2 by NH3–NH4Cl solutions at room temperature suggests that, in alkaline solutions, dissolved carbon (bicarbonate and carbamate ions) may be depleted in 13C relative to the CO2 gas by more than −50‰. (71) In the context of the above discussion regarding absorption/desorption efficiency, this may result in significant 13C depletion in the captured CO2 relative to the source gas, the opposite effect of what would be expected from dissolution in water.\nThe CO2 injected at the Pembina CCS project was derived from the Ferus natural gas processing plant, (72) which presumably used a form of chemical absorption to strip CO2 from natural gas. It had δ13C ∼ −4.7‰, (11) which falls well within the range of values for CO2 coexisting with natural gas (−13.9 to +13.5, (73) Figure 1 ). Similarly, CO2 captured using amine solvents from steam reforming of methane (see gasification, above) has δ13C of −37‰, (50, 52) well within the isotopic range of natural gas (−20 to −52‰). Given the breadth of possible δ13C values for the source CO2, these data do not help to constrain which of the above hypotheses is true, but suggest that 13C enrichment of the captured CO2 relative to the original CO2 is less than ±20‰. More work to experimentally determine C-isotope fractionation during CO2 capture would be beneficial. In the meantime, we tentatively conclude that fractionation of C-isotopes during amine capture is likely between −20 and +2.5‰ relative to the source CO2, based on the available data for captured CO2 relative to feedstocks, and the likely maximum enrichment calculated for CO2 dissolution in fresh water.\nNoble Gases\nFew data are available for the noble gas content of the CO2 stream produced by chemical absorption. In a summary of the CO2 product stream specifications from a number of post-combustion capture technologies, (74) Ar was present at concentrations of 10–25 ppmv, much lower than the atmospheric concentration of 9340 ppmv ( Table 1 ). This is likely due to the unreactive noble gases remaining in the gas phase during absorption and subsequently being vented, rather than being absorbed with the CO2. A small proportion of the noble gases will dissolve into the amine solution. As noble gas solubility decreases with increasing temperature, these will be efficiently exsolved when the solvent is heated to release the CO2. Noble gas solubility is controlled by Henry’s Law with the heavy noble gases having greater solubilities than lighter noble gases. As a result we might expect noble gas element ratios to show heavy element enrichment relative to atmosphere.\n3.7.2Physical Absorption\nPhysical absorption of CO2 requires a high partial pressure of CO2 and is often used to separate CO2 from other gases in CO2-rich gas streams, such as the products of gasification processes. CO2 absorption or dissolution into the solvent is according to Henry’s Law. (75) No chemical reaction takes place, and the absorbed gas is released from the solvent by pressure reduction. Physical absorption using cold methanol is used to capture CO2 produced at the Great Plains Synfuel plant, for use in the Weyburn enhanced oil recovery (EOR) and CCS site. (7)\nCarbon Isotopes\nTo the best of our knowledge there are no data available to assess the effect of physical absorption on δ13C–CO2. However, we would expect an enrichment of 13C in the dense phase (27) (i.e., dissolved in the solvent) and the isotopic composition of the resulting captured CO2 will depend on the relative efficiencies of the absorption and desorption mechanisms. If desorption is more efficient than absorption, then a small degree of 13C enrichment is likely.\nNoble Gases\nIn general, noble gases have a much higher solubility in organic solutions than in water (76, 77) and follow Henry’s Law, with the heavier noble gases having higher solubility. However, as is the case with noble gas dissolution in amine solvents, the noble gases will be preferentially retained in the gas phase and become decoupled from the CO2. The small proportion of noble gases that are absorbed into the solvent will likely be enriched in the heavier noble gases relative to atmosphere due to the enhanced solubility of the heavier noble gases. Assuming efficient desorbing of gases from the physical solvent, CO2 captured via physical absorption is likely to contain low concentrations of noble gases with element ratios enriched in heavy noble gases relative to the noble gas composition of the original flue gas. Isotopic ratios, however, are unlikely to change.\nReferences\n4 Geochemistry of Fluids and Gases in Actual and Potential CCS Storage Sites\nThe two types of storage sites currently considered to have the most potential for CCS in the short term are depleted oil and gas fields and deep, saline formations. In geological terms, these two types of storage are very similar, comprising reservoir rocks filled with saline fluid. In the case of depleted hydrocarbon fields, a wealth of information is available from hydrocarbon exploration and the fields are proven to have stored buoyant fluids or gas over geological time scales. On the other hand, many wells may have been drilled in such fields, resulting in potential leakage pathways, and many hydrocarbon fields are too small to provide large-scale CO2 storage. Conversely, saline aquifers are much larger but are poorly studied due to lack of hydrocarbon accumulation, and it is not conclusively known whether a given aquifer is leak-tight with respect to buoyant fluids. Porous basalt formations pose another promising storage option, (78) but the chemical and transport processes involved in these cases have significant differences compared to storage in sedimentary formations and are beyond the scope of this review.\nTo trace CO2 injected into a storage reservoir, the baseline conditions of the reservoir and the likely in-reservoir processes need to be known. Hydrodynamically closed reservoirs will tend to have more stable baseline conditions and predictable behavior, while hydrodynamically open reservoirs, and depleted hydrocarbon reservoirs that, at best will be contaminated with drilling fluids and at worst may have been flushed with water to aid hydrocarbon recovery, may have spatially and temporally variable baselines, and thus exhibit less predictable behavior. Below we summarize the measured and expected geochemical baselines for potential storage reservoirs. While a reasonable amount of data is available for hydrocarbon reservoirs, less information is available for the baseline evolution after production ceases. Data for non-hydrocarbon-bearing saline aquifers are uncommon.\n4.1Carbon Isotopes\nThe δ13C of CO2 in storage formations generally varies between ∼−23 and +1‰ ( Figure 2 and Supporting Information Table S3). Formations that experience rapid flow of formation water or mixing of water reservoirs may exhibit a large range in δ13CCO2 values at a single site (e.g., −23 to −16‰ at Weyburn (79) ). δ13C for DIC are more constrained, based on the available data, and fall between −9 and +3‰ (see Supporting Information Table S3), regardless of whether the host rock is carbonate or siliciclastic, or whether the storage formation has experienced previous hydrocarbon exploitation, but this may reflect a limited data set. For storage reservoirs in depleted hydrocarbon fields or associated with EOR, the baseline isotope values may fluctuate strongly depending on industrial activities, such as water flushing (80) or contamination with organic matter resulting in enhanced bacterial action. (81)\nFigure 2. Baseline storage reservoir CO2, DIC, and carbonate minerals, compared to injected CO2 in existing CCS projects. Gray boxes show the δ13C of injected CO2; Frio and Ketzin show two boxes each to reflect the two anthropogenic CO2 sources used in these projects. Reservoir baseline values for CO2, DIC, and carbonate minerals are shown by horizontal crosshair lines. Where the baseline data are variable, the full range in values is shown by gray lines while the majority of reservoir data are represented by black lines. See Tables S2–S4 for references.\n4.2Noble Gases\nThe most comprehensive noble gas measurements from a CCS reservoir are from the Weyburn EOR project, (82) although these do not represent baseline data. 4He concentrations were 2 orders of magnitude greater than for air saturated water (ASW) while other noble gas isotopes (Ne – Kr) had concentrations 1–2 orders of magnitude lower. The isotopic composition of the noble gases is consistent with a depletion in atmospheric noble gases, as would be expected for a hydrocarbon-rich formation where the noble gases partition into the hydrocarbon phase, rather than the pore-water phase, and an enrichment in radiogenic isotopes, consistent with a deep origin of the fluid. Similarly at the Cranfield CO2-EOR site, noble gas data from produced gases indicate high levels of terrigenic/radiogenic 4He in the reservoir. (83) Other noble gas data are available for fluids from the Rousse and Frio storage reservoirs. The Frio data are restricted to He and Ar concentrations (80,000 ppb (≫air) and 400,000 ppb (≈ ASW) respectively (49) ). Air-normalized concentrations for 4He, 20Ne, 36Ar, 40Ar and 84Kr, from Rousse show that, while the concentration of 4He was ∼10 times greater than air, the remaining noble gases were all 100–1000 times lower than air, with a positive correlation between concentration and elemental mass. (38)\nThese observations are consistent with the formation waters having interacted with hydrocarbons, causing depletion in atmospheric noble gases (originally derived via hydrologic recharge) relative to expected air saturated water (ASW), due to preferential partitioning into the hydrocarbon phase ( section 2.2 ). Repeated dissolution and exsolution of noble gases will produce greater degrees of elemental fractionation, with an enrichment of heavy relative to light noble gases, compared to air. (84) While these processes facilitate precise quantitative modeling when all of the relevant conditions are well-characterized, it is difficult to place more quantitative constraints on the range of noble gas concentrations that could be expected in deep aquifers.\nThe isotopic composition of subsurface noble gas elements, however, does not fractionate during dissolution and exsolution and is instead controlled by mixing between different sources of noble gases. In very simplistic terms, the formations likely to be of most interest for CCS are those that have at least some degree of hydrodynamic isolation. In such cases, the fluids in the reservoir will be relatively old, residing in the subsurface for a considerable amount of time, perhaps approaching geological time scales. This will give a much stronger radiogenic and terrigenic noble gas signature than would be observed for shallow, freshwater aquifers that undergo regular recharge (see section 7 ). Noble gases in hydrocarbon systems often have a resolvable mantle component identified by elevated 3He, and a high proportion of radiogenic isotopes that are often correlated with reservoir depth (4He*, 21Ne*, and 40Ar*, with “*” denoting a radiogenic origin). (30, 85-87) Some hydrocarbon fields have elevated, isotopically atmospheric Kr and Xe that cannot be explained by elemental fractionation in a water–oil–gas system. This is attributed to adsorption of atmospheric Kr and Xe onto the carbon-rich sediments that are the source of hydrocarbons. (30, 88) Such sediment derived Kr and Xe enrichments may occur in hydrocarbon fields, but would partition into the hydrocarbon phases, rather than water and so are unlikely to be observed in saline aquifers or depleted hydrocarbon fields where the Kr- and Xe-enriched phase was either never present or has been removed.\nIn the case of depleted oil and gas fields an additional source of noble gases may be introduced during water stimulation to maintain reservoir pressure. The extent of this contamination will depend on the relative volumes of water added, amount of original formation water remaining, and the noble gas composition of the injected water. If seawater is injected, as is likely in offshore hydrocarbon fields, the added noble gases will be those of atmosphere equilibrated seawater (similar order of magnitude concentrations to those quoted for fresh water in Table 1 ). If produced fluids from the field are simply reinjected, then the noble gas composition is unlikely to change.\nMany factors control the noble gas composition of potential storage reservoirs, so good noble gas baseline data will be beneficial if noble gases are to be used as tracers. Many reservoirs are likely to have elevated He concentrations relative to air or ASW and be depleted in other noble gases, while isotopic ratios will show strong radiogenic and terrigenic components. Saline aquifers will likely have more stable and consistent baselines than depleted hydrocarbon fields where contamination from production processes is likely.\nReferences\n5 Geochemical Evolution of the CO2 Stream on Injection and Migration in the Subsurface\nOnce injected into a geological storage formation, the fingerprint of the CO2 stream will change depending on the processes and reactions that take place and the time scale and rate of those reactions. This section describes the changes that are likely to take place as the CO2 plume migrates through the subsurface. Dominant processes will be mixing of the injected CO2 with pre-existing materials, dissolution of the injected CO2 into formation waters, fluid–rock reactions, such as dissolution of carbonate minerals, and migration. Precipitation of secondary carbonate and clay minerals will also change the stable isotope composition of the carbon-bearing gases and fluids in the subsurface, but there is currently limited evidence that these processes will occur on site-monitoring time scales, and, given the current uncertainties regarding mineral precipitation during CO2 storage in sedimentary formations, these will not be considered here. Transport of CO2 through the subsurface can be considered in terms of diffusive and advective transport, both of which may affect the composition of the CO2 plume in different ways.\n5.1Carbon Isotopes\nδ13C evolution of injected CO2 has been covered by a number of recent review papers (11, 12, 19, 23-26) so is only qualitatively described here. Injected CO2 will first mix with any free-phase CO2 in the reservoir, resulting in a CO2 plume with a δ13C value resulting from mixing between injected and baseline values. Identification of the injected CO2 plume is thus dependent on the difference between the injected and baseline δ13CCO2, the relative volumes of injected and baseline CO2, and relevant enrichment factors (which in turn are dependent on temperature and salinity) between gases and dissolved C-species\nCO2 will begin to dissolve into the formation water to form dissolved inorganic carbon (DIC), with isotopic fractionation between CO2 and DIC related to temperature, pH, and the DIC species formed. At reservoir conditions, DIC derived from the injected CO2 is calculated to be enriched in 13C by −1 to +7‰ relative to the coexisting CO2. (27) This DIC will subsequently mix with baseline DIC.\nCarbonic acid formation may cause dissolution of any carbonate minerals present, adding another source of C to the DIC; the stable isotope composition of these carbonate minerals, and thus resulting δ13CDIC, depends on the origin of the carbonate ( Figure 1 ).\nDiffusive transport through rock or soil pore networks may cause C-isotope fractionation at the migration front, resulting in sequential 13C depletion and then enrichment at a given location as the migration front passes. (12, 89) For dry systems, if reactive mineral surfaces such as illite are present, 44[CO2](12C16O2) may be preferentially adsorbed onto the surfaces, resulting in an initial 13C enrichment of the free-phase CO2, that can change the δ13CCO2 by up to hundreds of permil, followed by 12C enrichment relative to the bulk CO2 as the 12CO2 is desorbed, resulting in lower δ13C values, before returning to the bulk composition. (90) Further work is needed to investigate the presence of this effect in fluid saturated systems. While these processes are unlikely to affect the bulk of CO2 injected for storage, they may affect the migration front of the injection plume and any CO2 that leaks from the storage site. Early measurements of δ13CDIC at the Ketzin observation well Ktzi 200 gave δ13C values lower than expected for mixing of CO2 sources and calculated C-isotope fractionation during dissolution; diffusive fractionation was a speculated cause of this depletion. (81)\n5.2Noble Gases\nThe processes affecting noble gases in the subsurface are described in a number of recent summary papers and text books. (28-30, 91, 92) As with stable isotopes, the noble gas signature of the injected CO2 stream will first be modified by mixing with any atmospheric, terrigenic, and radiogenic noble gas components in the reservoir gas phase. Exchange of noble gases between different reservoir phases (gas, water, oil, and solid particles) may take place according to the differences in solubility described in section 2.2 . Note from Table 1 that Xe will partition preferentially into oil rather than gas at temperatures less than 50 °C so interaction of the injected CO2 with any oil in the subsurface will cause Xe depletion in the gas phase. Recent work (93) experimentally determined noble gas partitioning between supercritical CO2 and water and found deviations relative to ideal gas–water partitioning behavior that became greater with increasing CO2 density. Ar, Kr, and Xe all show an increasing affinity for the CO2 phase with increasing CO2 density, due to enhanced molecular interactions of denser-phase CO2 with the larger, more polarizable noble gases, while He shows decreasing affinity. (93)\nPhysical adsorption of noble gases onto solid particles, while difficult to quantify due to a lack of experimental data on adsorption properties, may significantly fractionate heavy from light noble gas elements, and a number of studies indicate enrichment of Kr and Xe in organic-rich shales and coal. (29, 94, 95)\nMigration of the plume front may chromatographically fractionate the noble gas elements and CO2 due to differences in molecular diffusion rate and solubility, although the specific manifestation of this fractionation depends on the rock matrix, the gas transportation mechanism, and relative solubility of the gas species. Less soluble species will migrate faster than more soluble species, (96) meaning that noble gases, which will preferentially partition into the gas phase, should travel faster through the subsurface than CO2, which will begin to dissolve on contact with water. If gas transport takes place via molecular diffusion through pore space, the lighter, faster diffusing species will travel more quickly through the subsurface than the heavier, slower diffusing species. In the case of arrival of the migration front at a monitoring well, we would expect to detect gases in the following order, with the delay between gas arrival dependent on the distance traveled: He, Ne, Ar, CO2, Kr, and Xe. (97) However, the opposite may be true when gas transport is via advection along fractures, with faster diffusing species, which are more able to enter the rock pore space, traveling less rapidly than slower diffusing species, which are confined to fractures and more open, faster flow pathways. (98) The isotopic composition of the noble gases, however, is not expected to be altered by migration, so characterization of baseline and injected noble gas isotope compositions will allow mass-balance modeling and fingerprinting of any subsurface samples produced from monitoring wells.\nReferences\n6 Past and Present Use and Future Potential of Inherent Tracers for In-Reservoir Processes in CCS Projects\nA number of projects have successfully used inherent stable isotopes to monitor CO2 behavior in the subsurface, while added noble gases have also proven useful. Supporting Information Table S4 summarizes the ways that these tracers have been used in different CCS projects and identifies the key papers describing these applications. Many of these projects and applications have been summarized in recent review papers. (12, 17, 26)\nUsing C-isotopes as a CO2 or DIC fingerprint to detect breakthrough and monitor migration of the injected CO2 is the most common application of inherent tracers in existing CCS projects. In most of these projects the injected CO2 was isotopically distinct from baseline CO2 and DIC. However, C-isotopes were still a useful tool for monitoring migration and breakthrough at Weyburn, where the injected and baseline δ13CCO2 overlap (due to the wide range of baseline values), and at Pembina, where the injected δ13CCO2 overlapped with baseline δ13CDIC ( Figure 2 ). In these cases, C-isotope fractionation during dissolution of injected CO2 to form bicarbonate (∼5‰ at 50–60 °C) increases the separation in δ13C values between baseline DIC and injection derived HCO3–. In many cases (see Supporting Information Table S4), C-isotopes were the most sensitive tracer, indicating arrival of injected CO2 at a monitoring well earlier than significant changes in fluid pH or CO2 concentration. When the baseline conditions are well-characterized, C-isotopes have proven to be useful for quantifying the proportion of CO2 or DIC derived from the injected CO2 and from in-reservoir mineral dissolution (Weyburn, (12, 99-101) Cranfield, (31) and Ketzin (81) ). C-isotopes have also proven useful at identifying contamination from drilling fluids. (81)\nHence, δ13C of CO2 and DIC has the potential to be a powerful in-reservoir tracer, as long as the injected CO2 has a δ13C value that is easily distinguishable from background CO2 and, if it dissolves, will produce DIC with δ13C distinguishable from baseline DIC. Figure 3 compares the expected δ13C of captured CO2 from a number of processes and feedstocks, to the range of likely baseline storage formation values. From this, we can see that C3 biomass and fossil fuel derived CO2 will be easiest to distinguish from reservoir baseline conditions, using δ13C, although coal and C3 biomass derived CO2 have a greater chance of overlap.\nFigure 3. Comparison of the range of inherent tracer values for storage and leakage reservoirs ( Table S1 and Tables S2–S6 ), and the expected captured CO2 composition for various CO2 sources ( Table 2 ). Boxes represent the range of δ13C (V-PDB) and noble gas concentration (relative to air and ASW) in baseline conditions for atmosphere, soil, shallow aquifers, and storage reservoirs, compared to the range of values expected for different sources of captured CO2. C-isotopes are given in δ notation relative to V-PDB. Noble gases shown for absolute concentrations relative to air and ASW, with dominant components resolvable by isotopic analysis: “L” = light noble gases; “H” = heavy noble gases; “R/T” = radiogenic and/or terrigenic component; “M” = mantle component; “ASW” = air saturated water. ff = fossil fuels; bm = biomass; ISP = integrated steel plant; DRI = directly reduced iron.\nWhile no studies have taken place using noble gases inherent to captured CO2 as a tracer, use of noble gases coexisting with natural CO2 injected for EOR operations (32) and as added tracers for both tracing CO2 migration (Frio and Ketzin) and quantifying residual saturation (Otway) suggest that noble gases could prove very useful, if their injected composition is different from those of the reservoir baseline. In addition to experimental CCS sites, natural tracers have been used to study reservoir processes in natural CO2 accumulations with combined noble gas and C-isotope measurements identifying CO2 dissolution into the formation waters. (102)\nReferences\n7 Baseline Fingerprint of Leakage Pathway Reservoirs (Atmosphere, Soil, and Groundwater Aquifers)\nThe aim of CCS is to prevent CO2 from entering the atmosphere, so being able to detect seepage of geologically stored CO2 to the atmosphere is a high priority. However, this remains difficult due to problems associated with identification of leakage sites, leakage plume dilution, and difficulties in establishing a precise local atmospheric baseline. In this section we will briefly review the probable range of baseline conditions for C-isotopes and noble gases in the reservoirs most likely to be influenced by CO2 leakage and how these may or may not contrast with CO2 leakage signatures.\n7.1Atmosphere\nCarbon Isotopes\nAtmospheric CO2 has δ13C of between −6 and −8‰ V-PDB (27) ( Figure 1 ), but may vary spatially and temporally with local conditions, weather, and anthropogenic activity; e.g., atmospheric measurements in Dallas, TX, USA, ranged from δ13CCO2 of −12 to −8‰ over ∼1.5 years due to varying photosynthetic uptake, respiration, and anthropogenic sources (vehicle emissions). (103) C-isotopes can be a sensitive tracer, despite large background fluctuations, by using Keeling plots, which correlate δ13CCO2 with inverse CO2 concentration to determine the isotopic composition of local CO2 (ecosystem respired and anthropogenic sources) mixing with regional atmospheric CO2. (104) If injected CO2 were to leak to the atmosphere from the subsurface, it should be identifiable using Keeling plots as long as its δ13C is different from that of the (previously established) baseline end members. Keeling plots from North and South America suggest that ecosystem respired CO2 has δ13C between −33 and −19‰, (104) which is similar to the anticipated δ13C of CO2 captured from burning C3 biomass and some fossil fuels; δ13C of captured CO2 may thus be especially difficult to distinguish from surface CO2. Captured CO2 derived from natural gas combustion may be depleted enough in 13C and CO2 captured from natural gas processing plants may be sufficiently enriched in 13C to be distinguishable from local and regional atmospheric sources of δ13C.\nNoble Gases\nThe concentration of noble gases in the atmosphere is given in Table 1 . Atmospheric values for commonly used noble gas isotopic ratios include the following: 3He/4He = 1 R/RA; (105) 20Ne/22Ne = 9.8; (105) 40Ar/36Ar = 298.56. (106) Regardless of the inherent noble gas composition of the injected CO2 stream, if CO2 leaks from deep geological storage, it will most likely be accompanied by baseline reservoir noble gases, which will be enriched in radiogenic and terrigenic isotopes (e.g., 3He/4He ≪ 1 R/RA; 40Ar/36Ar > 298.56).\n7.2Soil\nCarbon Isotopes\nAs with atmosphere, the stable isotope composition of soil CO2 can vary spatially and temporally with local conditions. It is governed by a combination of CO2 produced by soil respiration, fractionation during diffusion, mixing with atmospheric CO2, and isotopic exchange with soil water. (89, 107) This can result in highly variable δ13C values for soil that vary on a daily basis. δ13C data are available for soil from a number of CCS sites ( Supporting Information Table S5), all of which show more than 10‰ variation (between −27 and −7‰) with no evidence of being contaminated by injected CO2. There is considerable overlap between the δ13C of soil CO2 and the expected range of δ13C values of captured CO2 ( Figure 3 ). CO2 derived from combustion or gasification of natural gas may produce CO2 significantly more depleted in 13C than soil CO2, while CO2 captured from natural gas processing may be significantly enriched. Given the wide variation in baseline soil δ13C values at any given site, C-isotopes in isolation will only be a useful leakage tracer if the leaking CO2 has a distinctive δ13C (i.e., derived from natural gas or natural gas processing), and if CO2 concentration is also measured and Keeling plots are used. Use of δ13CCO2 in conjunction with concentrations of oxygen and nitrogen can be a useful tool to identify mixing between atmospheric CO2 and CO2 produced in the soil from biological respiration or methane oxidation. (108)\nNoble Gases\nIn simplistic terms, noble gases in soil are derived from the atmosphere and partition between gas and water phases; soil gas should have an atmospheric noble gas composition, while fluids have concentrations consistent with air saturated water for the local soil temperature. (109) However, this ideal theoretical behavior is not always observed. Changes to the local combined partial pressure of CO2 and O2 (due to the greater solubility of CO2 over O2) can cause corresponding changes to noble gas concentrations and elemental ratios, with heavier noble gases more affected than lighter noble gases, likely due to differences in diffusion rate, (91) though isotopic ratios remain atmospheric. Three soil-gas monitoring projects associated with CCS sites provide limited noble gas concentration data ( Supporting Information Table S5). At Weyburn, Ar concentrations (110) are atmospheric (∼0.9%), and at Rousse, He concentrations from four separate campaigns were consistent at ∼5 ppm, (111) again consistent with atmospheric concentrations. At Otway, baseline He concentrations in the soil ranged from 3 to 103 ppm, (112, 113) i.e., ranging between enriched and slightly depleted compared to atmosphere. The reasons for these elevated He concentrations were unknown, but not thought to represent leakage of a deep gas source.\nIn terms of using noble gases to detect leaking CO2, isotopic ratios will be the most useful tool. The isotopic ratios of noble gases in baseline soil will be atmospheric (see above), while noble gases in CO2 leaking from depth will most likely have 3He/4He below atmospheric values, and 40Ar/36Ar greater than atmosphere, irrespective of the noble gas composition of the injected CO2, due to enrichment of radiogenic 4He* and 40Ar* in the subsurface (see sections 2.2 and 4 ). Concentrations of noble gas elements or isotopes may provide additional information, depending on the noble gas content of the injected CO2, and as long as variations in baseline soil noble gas partial pressure and elemental fractionation due to changing CO2 + O2 content are taken into account.\n7.3Shallow Aquifers\nShallow aquifers are often sources of potable water and hence CO2 leakage into such reservoirs is undesirable. Such reservoirs are recharged by meteoric water and are thus hydrodynamically connected to the surface, so leakage of CO2 into a shallow aquifer will likely result in escape of some of that CO2 to the atmosphere. For these reasons, identification and mitigation of any CO2 leakage into shallow aquifers will be a high priority.\nCompared to the atmosphere or soil, baseline geochemical conditions in aquifers are likely to be much more stable, thus providing a higher sensitivity for leak detection. Furthermore, if the hydrodynamic gradient of an aquifer is well-characterized, monitoring wells can be placed downstream of any potential leakage structures, allowing efficient monitoring of a relatively large area without the need to identify and monitor every single potential leakage point. (114)\nCarbon Isotopes\nThe δ13C value of CO2 and DIC in fresh spring and groundwaters is generally derived during recharge from the soil, followed by dissolution, associated isotope fractionation (see section 5 ) and weathering of carbonate material. (27) Bacterial action can isotopically enrich DIC in 13C (up to +30‰), via reduction of CO2 to methane ( Figure 1 ), or fermentation of acetate to produce CH4 and CO2. (115-118)\nSupporting Information Table S5 lists δ13C for CO2 and DIC in selected freshwater springs and aquifers. Data for Ketzin, Altmark, Otway, and Hontomín were collected as part of the CCS monitoring programs. δ13C values of both CO2 and DIC range from −24 to −9‰, consistent with derivation from soil CO2 ( Figure 1 ). Data from other aquifers extend the range to higher values, indicating bacterial action. δ13C of CO2 in shallow aquifers may be difficult to distinguish from δ13CCO2 of captured and injected CO2, especially that derived from coal and biomass feedstocks and cement manufacture.\nNoble Gases\nNoble gases enter subsurface aquifers via recharge of meteoric water in the vadose zone of soils, and baseline compositions reflect ASW, with or without excess air, for the local soil temperature. (109) While deviations from this ideal behavior have been noted, these are most likely explained by changes to noble gas partial pressure in soil, described above. (91) In general, the processes that result in noble gas elemental fractionation in meteoric and groundwater are controlled by well-understood physical mechanisms, are related to the residence time of water in the subsurface, and can be modeled. (33) Groundwater may thus provide a well-constrained, predictable baseline for leakage monitoring using noble gases. Furthermore, as noble gases are sparingly soluble in water, the concentration of noble gases in ASW is significantly lower than that of the atmosphere, resulting in a signal-to-noise ratio that is 100 times more sensitive. (119) While the processes controlling the noble gas content of groundwater are well-understood and their behavior predictable, they are dependent on specific local recharge conditions, so establishing a precise baseline is essential. As with atmospheric and soil reservoirs, the baseline of recently recharged aquifers is likely to differ from leaking CO2 by a lack of radiogenic and terrigenic noble gases. However, old (hundreds of thousands of years) groundwaters may exist in aquifers used as domestic and agricultural water sources, and such aquifers may have significant radiogenic and terrigenic components. One such example is the Milk River aquifer in Alberta, Canada, which has groundwater residence times of up to 500 ka. (120) The majority of noble gases have concentrations between 0.2 and 4 times the expected values for ASW, but radiogenic and terrigenic derived 4He is enriched in some wells by more than 2000 times the expected ASW value and 40Ar/36Ar values are all greater than atmosphere. (121)\nReferences\n8 Past and Present Use and Future Potential of Inherent Tracers for Leak Detection in CCS Projects\nUse of tracers for monitoring leakage of CO2 into overlying reservoirs (aquifers, soil, and atmosphere) follows the same principles as for in-reservoir monitoring, but with the added complication that the released volumes are likely to be much smaller so sensitivity and detection become a critical issue.\nGeochemical analysis is a common monitoring technique for CCS sites, many of which employ surface, soil, and/or groundwater analysis to monitor for leakage or contamination and a recent review (19) provides more details on the theory and practice of using tracers to detect CO2 leakage into freshwater aquifers. However, in the vast majority of CCS field tests, no leakage has been observed and these projects are thus of limited value in assessing the viability of using inherent tracers as leakage detection. An exception is the Frio CCS project, where added tracers, elevated dissolved CO2 gas contents, slight increases in HCO3– concentrations, and substantial depletion in 13C of DIC were found in strata above a primary seal (but remaining below the main structural trap for the storage reservoir), indicating that CO2 had leaked within the subsurface. (49) These indicators returned to background levels within 9 months of injection, suggesting that the leak was short-lived and occurred early in the injection process. Given that the injection well was 50 years old, leakage from the well itself was considered to be the most likely source of the CO2, rather than migration between strata. (49) While it was not possible to calculate the volumes of leaked CO2 at Frio, it seems that C-isotopes of DIC may provide a potentially powerful tracer of CO2 leakage when volumes are so low that there is no significant rise in HCO3– concentration.\nAt the Rangely-Weber CO2-EOR site, Colorado, USA, CO2 and CH4 gas fluxes were used to quantify microseepage from the reservoir. (122) Statistical analysis showed that gas flux and isotopic composition were different between the area overlying the reservoir and a nearby control site, but it was not possible to conclusively attribute these differences to gas seepage from the reservoir. Assuming that the differences were due to gas seepage, maximum seepage rates of 170 tonnes per year CO2 and 400 tonnes per year CH4 were calculated. (122)\nAllegations of CO2 leakage from the Weyburn EOR site into farmland (the Kerr Property) were shown to be unfounded, (123) but this case study provides useful insights of how natural tracers can help to determine the origin of CO2, even when robust baseline data are not available. A number of incidents and CO2 measurements led the owners of the farmland to believe that CO2 injected into the Weyburn site was leaking into their property. One of the reasons for this belief highlights a potential downfall of using stable isotope data for tracing CO2 migration; high concentrations of CO2 measured in the soil had the same δ13CCO2 as the CO2 being injected as part of the Weyburn project. This δ13CCO2 value (∼−21‰) was, however, comparable to typical soil-gas CO2 compositions (124) (cf. Figure 1 ). An independent investigation was commissioned to determine the origin of CO2 on the site, the results of which showed without doubt that the CO2 was natural and did not derive from injection of CO2 for storage or EOR at Weyburn. (124) For soil gas, correlations of CO2 with O2 and N2 were consistent with a CO2 origin by soil respiration, rather than addition of an extra CO2 component, and correlating CO2 concentration with δ13CCO2 showed that the soil-gas isotope composition was easily explained by mixing between atmospheric CO2 and soil-gas CO2 with a δ13CCO2 of −25‰. (124) Noble gas and C-isotope analyses on groundwater well samples, injected CO2 and water, and fluids produced from deep in the Weyburn formation confirmed that gas from the reservoir was not present. (82) Noble gas concentrations in the shallow groundwaters were consistent with ASW, as would be expected for the local groundwater system, while the fluids produced from the Weyburn field were very different; most noble gas concentrations (Ne, Ar, Kr, and Xe) in the Weyburn fluids were much lower than would be expected for ASW, while 4He concentrations were much higher, consistent with enrichment of radiogenic 4He in the crust. (82) Furthermore, 3He/4He ratios in groundwater samples were indistinguishable from air, while Weyburn fluids had 3He/4He values an order of magnitude lower, due to addition of crustal radiogenic 4He. (82) Importantly, Weyburn reservoir water and shallow groundwater samples showed no correlation on a plot of HCO3– vs 3He/4He, which would be expected if mixing occurred between deep, Weyburn fluids and ASW groundwater. (82)\nIn the absence of real CO2 leaks from storage sites, information on tracer behavior during leakage can only be gleaned from controlled release experiments (i.e., injecting CO2 into a unit that will leak) and studying natural CO2 or natural gas seeps. Experiments releasing CO2 into soil at a rate comparable to 0.001% leakage from a 200 Mt CO2-storage site have been successful at identifying CO2 leakage using δ13C with Keeling plots in both atmosphere and soil, although in these cases the injected CO2 had a particularly light isotopic signature (δ13C ←45‰). (36, 125-127) An experimental CO2 leak (δ13CCO2 of −26.6‰) into sediments in the North Sea (QICS project) showed that δ13CDIC of pore water registered the leak earlier than significant increases in HCO3– concentration were detected. (128) In these examples the difference in δ13C between baseline and injected CO2 was 15–25‰. In these leakage experiments the migration distance for the injected CO2 is small (maximum 11 m – QICS), and it is possible that the isotopic composition of the CO2 could change during migration over the larger distances associated with geological storage (kilometres deep). However, detailed modeling of potential leakage at the QUEST CCS project, Edmonton, Canada, from the Basal Cambrian Sandstone (BCS) storage reservoir into overlying aquifers indicated that the δ13CCO2 of the leaking CO2 would differ from the injected CO2 by less than 1‰. (52)\nAnother experiment released CO2 with He and Kr tracers into the vadose zone of limestone and showed that molecular diffusivity was not an adequate model for coupled CO2–tracer behavior; while He and Kr behaved according to predictive models, the CO2 took significantly longer to travel through the substrate. (97) This experiment gives weight to the hypothesis that noble gases may provide an early warning of CO2 leakage. Further evidence suggesting that noble gases may be useful tracers of CO2 migration comes from studies on natural CO2 and gas seeps. At St John’s, Arizona/New Mexico, USA, δ13C was inconclusive in establishing the origin of elevated HCO3– in spring water, but He and Ne isotopes identified both mantle and crustal components and thus a deep origin for the CO2. (129) He and Ne isotopes were similarly used to confirm that elevated levels of soil-gas CO2 and CH4 were due to microseepage of gas from deep, hydrocarbon-bearing formations at Teapot Dome, Wyoming. (119) Importantly, this study established that total He concentrations of approximately just 10 ppm in soil gas and 0.1 ppm in groundwater aquifers would be sufficient to identify deep-sourced He. (119)\nIn summary, C-isotopes may be useful for detection of leakage and seepage if the baseline and injected CO2 are significantly different. When isotopic compositions are not distinctive, combining δ13C with CO2, O2, and N2 concentrations can help to constrain the CO2 origin. Of the noble gases, He is a particularly sensitive leak and seep tracer due to its low background concentrations at the surface and likely high concentration in the storage reservoir, regardless of the He content of the injected CO2.\nReferences\n9 Summary, Implications, and Conclusions\nThe inherent stable isotope and noble gas composition of captured CO2 has the potential to provide powerful monitoring tools for carbon capture and storage projects, both for in-reservoir processes and for identifying leakage and seepage from the storage unit. This application requires significant compositional differences between the injected CO2 and the reservoir (for in-reservoir monitoring) and between the reservoir plus injected CO2 and overlying shallow aquifers, soil, and atmosphere (for seepage monitoring).\nIn simplistic terms, captured CO2 is generated in two stages: (1) initial reaction of a feedstock to produce a CO2-bearing flue gas and (2) separation of the CO2 from the other flue gases. When considering the likely isotopic and noble gas composition of the captured CO2 stream, we found that the C-isotope composition and noble gas isotope ratios will be dominated by the initial feedstock, and noble gas concentrations will be controlled by the use of CO2 purification technology.\nFor fossil fuel and C3 biomass feedstocks a δ13C fractionation of −1.3‰ from the feedstock can be expected while the combustion of C4 biomass may result in greater isotope fractionation. There is a notable lack of information regarding the effect of CO2 separation technologies (e.g., amine capture) on the stable isotope composition of captured CO2, but 13C depletion by tens of permil is hypothetically possible. Combining hypothetical considerations with the small amount of available data suggests that C-isotope fractionation during amine capture will be between −20 and +3‰. This amounts to a total fractionation between the feedstock and the captured CO2 of between −21 and +2‰. A lack of solubility data for noble gases in amine solvents and a lack of detailed noble gas measurements on captured CO2 makes it difficult to predict the noble gas content. Fossil fuel feedstocks are likely to be enriched in radiogenic or terrigenic noble gases (especially 4He), and this isotopic component will be transferred to the CO2, although any CO2-purification processes are likely to cause noble gas depletion. However, there is a growing body of evidence to suggest that oxyfuel CO2 (and other processes that use cryogenic oxygen, such as Syngas plants) may be enriched in heavy noble gases Kr and Xe. While fossil fuels remain the dominant feedstock, CO2 captured from power plants will likely have a high 4He content (at least before amine capture), but this will change over time if fossil fuels are increasingly replaced with biomass to provide renewable energy with potentially negative CO2 emissions.\nLikely baseline compositions for storage reservoirs and overlying aquifers, soil, and atmosphere were reviewed to assess the likelihood that injected CO2 will be isotopically different, and this is summarized in Figure 3 . Use of fossil fuels and C3 biomass feedstocks are most likely to produce captured CO2 with δ13C distinctive from baseline conditions, although δ13C of the CO2 in some storage reservoirs may be difficult to distinguish from coal or C3 biomass derived CO2. CO2 generated from C4 biomass, fermentation, cement manufacture, and natural gas processing will be more difficult to distinguish. Elevated 4He concentrations that are expected to occur in various sources of captured CO2 are unlikely to contrast with storage reservoir baseline conditions due to the presence of radiogenic and terrigenic 4He, but may provide a highly sensitive tracer for detecting leakage and seepage. Elevated Kr and Xe in CO2 captured from processes that use cryogenic oxygen may be useful, but there is not yet enough data to assess how ubiquitous this enrichment is and whether the concentrations involved are sufficient to allow detection in the reservoir. We note, however, that the wide range of noble gas element and isotope ratios that can be measured means that detailed baseline characterization of reservoir and injected CO2 is likely to yield some combination of noble gas ratios that provide a suitable in-reservoir tracer.\nA number of fundamental questions remain unanswered due to a lack of empirical data. While we have tried to address these questions hypothetically, more research is necessary to test these hypotheses. Specifically, (1) will carbon capture technologies result in low noble gas concentrations with preferential loss of light noble gases, and how much C-isotope fractionation will take place during carbon capture? (2) Will CO2 captured from oxyfuel plants have a higher noble gas content than amine-captured CO2, especially for heavy noble gases? (3) Will migration of the CO2 plume over geological distances result in significant fractionation of stable isotopes or noble gases, over what time scales and distance will this fractionation be observed, and how might this affect our ability to identify CO2 leakage or seepage?\n""","0.16671845","""http://pubs.acs.org/doi/10.1021/acs.est.6b01548""","[-3.187347,55.947691]"
"""Imperial_College_London""","""Modeling Joint Charging and Parking Choices of Electric Vehicle Drivers | Decentralized Control Approach for Charging Service Providers""","""Modeling Joint Charging and Parking Choices of Electric Vehicle Drivers\nDecentralized Control Approach for Charging Service Providers\nPDF\nAbstract\nElectric vehicles (EVs) offer significant opportunities to improve sustainability of the road transport sector. But simultaneously, widespread adoption of EVs would create new challenges. For example, spatiotemporal concentration of charging events in high-density residential or commercial areas would place extreme demands on the power network, causing bottlenecks and grid instability. A novel approach to the typical decentralized control methods for EV charging service providers (CSPs) is presented. First, static price signals based on anticipated demand define a set of charging offers, targeted to segments of EV users. Prices are differentiated either only by time or both by time and place and allow comparison and evaluation of both scenarios. A choice-based revenue management method is employed to optimize allocation of generated charging offers, with respect to revenue outcome for the CSP. The charging coordination techniques are demonstrated through simulation. Data come from the London Travel Demand Survey and particularly trips around Westfield, one of Europe’s largest urban shopping malls, representing out-of-home charging behavior for short intervals in a high-demand area. Findings suggest that in a first-come, first-served system, locational pricing might create opportunities both for increased revenue and for relocation of charging events to less-congested facilities. In the revenue management system, locational pricing significantly favors total revenue outcome but without discharging vulnerable areas. However, because agents with conflicting interests participate in the process (infrastructure owners, power system operators, EV drivers), opportunity exists for the CSP to adapt constraints according to the priority of its objectives.\n< >\nTransportation Research Record: Journal of the Transportation Research Board\nTransportation Research Record: Journal of the Transportation Research Board\nPrint ISSN: 0361-1981\n""","0.7462486","""http://trrjournalonline.trb.org/doi/10.3141/2502-15""","[-0.178219,51.500505]"
"""StaffCambridgeUniversityEngineering""","""Exhaust gas ignition (EGI)-a new concept for rapid light-off of automotive exhaust catalyst - CUED Publications database""","""Login\nExhaust gas ignition (EGI)-a new concept for rapid light-off of automotive exhaust catalyst\nMa, T and Collings, N and Hands, T (1992) Exhaust gas ignition (EGI)-a new concept for rapid light-off of automotive exhaust catalyst. SAE Technical Papers.\nFull text not available from this repository.\nAbstract\nIncreasing pressure on lowering vehicle exhaust emissions to meet stringent California and Federal 1993/1994 TLEV emission standards of 0.125 gpm NMOG, 3.4 gpm CO and 0.4 gpm NOx and future ULEV emission standards of 0.04 gpm NMOG, 1.7 gpm CO and 0.2 gpm NOx has focused specific attention on the cold start characteristics of the vehicle's emission system, especially the catalytic converter. From test data it is evident that the major portion of the total HC and CO emissions occur within the first two minutes of the driving cycle while the catalyst is heating up to operating temperature. The use of an electrically heated catalyst (EHC) has been proposed to alleviate this problem but the cost and weight penalties are high and the durability has yet to be fully demonstrated (1)*. This paper describes a method of reducing the light-off time of the catalytic converter to less than 20 seconds by means of an afterburner. The system uses exhaust gases from the engine calibrated to run rich and additional air injected into the exhaust gas stream to form a combustible mixture. The key feature concerns the method of making this combustible mixture ignitable within 2 seconds from starting the engine when the exhaust gases arriving at the afterburner are cold and essentially non-reacting. © Copyright 1992 Society of Automotive Engineers, Inc.\nItem Type:\n""","0.5884305","""http://publications.eng.cam.ac.uk/573576/""",
"""Queen's_University_Belfast""","""Limitations of Global Kinetic Parameters for Automotive Application - Queen's University Belfast Research Portal - Research Directory & Institutional Repository for QUB""","""Limitations of Global Kinetic Parameters for Automotive Application\nResearch output: Contribution to conference › Paper\nPublished\nView graph of relations\nWith emission legislation becoming ever more stringent, automotive companies are forced to invest heavily into solutions to meet the targets set. To date the most effective way of treating emissions is through the use of catalytic converters. Current testing methods of catalytic converters whether being tested on a vehicle or in a lab reactor can be expensive and offer little information about what is occurring within the catalyst. It is for this reason and the increased price of precious metal that kinetic modelling has become a popular alternative to experimental testing.\nDOI\n""","0.56548566","""http://pure.qub.ac.uk/portal/en/publications/limitations-of-global-kinetic-parameters-for-automotive-application(787a255d-e247-4564-8179-34ad9d3b3688).html""","[-5.934759,54.583863]"
"""Cranfield_University""","""Reactive Atom Plasma for Rapid Figure Correction of Optical Surfaces""","""Reactive Atom Plasma for Rapid Figure Correction of Optical Surfaces\nReactive Atom Plasma for Rapid Figure Correction...\nReactive Atom Plasma for Rapid Figure Correction of Optical Surfaces\nAbstract:\nArticle Preview\nNanometre-scale figuring technique at atmospheric pressure for large optical surfaces is a high profile research topic which attracts numerous competing state-of-the-art technologies. In this context, a dry chemical process, called Reactive Atom Plasma (RAP), was developed as a prospectively ideal alternative to CNC polishing or Ion Beam Figuring. The RAP process combines high material removal rates, nanometre level repeatability and absence of subsurface damage. A RAP figuring facility with metre-scale processing capability, Helios 1200, was then established in the Precision Engineering Centre at Cranfield University. The work presented in this paper is carried out using Helios 1200 and demonstrates the rapid figuring capability of the RAP process. First experimental tests of figure correction are performed on fused silica substrates over 100 mm diameter areas. A 500 nm deep spherical hollow shape is etched onto the central region of 200x200 mm polished surfaces. The test is carried out twice for reproducibility purposes. After two iterative steps, a residual figure error of ~16 nm rms is achieved. Subsequently, the process is scaled up to 140 mm diameter areas and two tests are carried out. First, the developed algorithm for 500 nm deep spherical hollow test is confirmed. Residual deviation over processed area is ~18 nm rms after three iterations. Finally, a surface characterised by random topography (79 nm rms initial figure error) is smoothed down to ~ 16 nm rms within three iteration steps. All results presented in this paper are achieved by means of an in-house developed tool-path algorithm. This can be described as a staggered meander-type tool motion path specifically designed to reduce heat transfer and consequently temperature gradient on the surface. Contiguously, classical de-convolution methods are adapted to non-linear etching rates for the derivation of the surface scanning speed maps. The figuring procedure is carried out iteratively. It is noteworthy that iteration steps never exceed ~7 minutes mean processing time.\nInfo:\nMichael N. Morgan, Andrew Shaw and Otar Mgaloblishvili\nPages:\n10.4028/www.scientific.net/KEM.496.182\nCitation:\nM. Castelli et al., \""Reactive Atom Plasma for Rapid Figure Correction of Optical Surfaces\"", Key Engineering Materials, Vol. 496, pp. 182-187, 2012\nOnline since:\nDOI: 10.1002/adem.200600028\n[2] Allen LN, Roming HW, (1990) Demonstration of an ion figuring process. Advanced Optical Manufacturing and Testing – Proceeding of SPIE 1333 (1990) 22–33.\n[3] Castelli M, Jourdain R, McMeeking G, Morantz P, Shore P, Proscia D, Subrahmanyan P, Initial Strategies for 3D RAP Processing of Optical Surfaces Based on a Temperature Adaptation Approach, 36th MATADOR Conference, Manchester, 18 (2010) 569-572.\nThe Computer-Controlled Chemical Polishing Techniques for Precision Optics\nAuthors: Qiao Xu, Jian Wang, Jing Hou\nAbstract: The computer-controlled chemical polishing (CCCP) techniques based on the Marangoni effect have been developed to manufacture precision optics on polished fused silica surface. In this study, we present the Marangoni confined chemical-etching process in which the material removal on optical surfaces can be accomplished by etching with buffered HF solution. The process shows stable characteristics and good repeatability while the etching depth can be controlled in the order of ten nanometers. We also present the experimental results of this technology for fabrication of phase corrector and continuous phase plate. Results show that the CCCP’s deterministic sub-aperture-polishing characteristics make it possible to correct the surface error and imprint complex phase structure with spatial scale-length of several millimeters onto optical surface.\n217\nProposal for Machining Optical Free Form Surfaces Using Atmospheric Pressure Plasma Jet\nAuthors: Yan Fu Zhang, Bo Wang, Shen Dong\nAbstract: Optics with free form surface can be achieve special imaging effects and reduce component amounts in optical systems. However, it is difficulty to fabricate high accuracy, damage-free optical surface with free form surfaces by conventional method. Atmospheric plasma machining is a non-contact chemical processing method which can fabricate optics without damaged layer. Numerical controlled atmospheric pressure plasma machining (NC-APPM) method is proposed to machine optical free form surfaces. A new atmospheric pressure plasma jet generator was designed to get Gaussian rotational symmetry removal spot and the spot maximum diameter is 1.5mm. Base on dwelling time algorithm, a sinusoidal wave structure, the pitch 2mm and the amplitude 500 nm, is fabricated on a pre-polished flat silica quartz surface using three-axis numerically controlled machine made by ourselves. The result shows that the amplitude error is 59 nm compare to the expectation value surfaces using numerical controlled atmospheric plasma machining method.\n2995\nControl of Thermal Effect in Ion Beam Figuring Process Based on Low-Pass Filtering\nAuthors: Zheng Yuan, Yi Fan Dai, Hao Yu, Xu Hui Xie, Lin Zhou\nAbstract: During ion beam figuring process, most heat energy is absorbed by optics surface, heating the workpiece surface un-uniformly, called thermal effect. Thermal effect leads to distortion even cracking of the optical figure due to high temperature and temperature gradients, especially for the temperature sensible materials such as BK7, KDP and CaF2. One of the methods on decreasing thermal effect is decreasing total dwelling time and dwelling time gradients. According to the ability of ion beam correction, It is proposed that a new surface error distribution is obtained by filtered by a low pass filter from the initial surface error distribution measured by interferometer, and then it is used to calculate the dwelling time function. It is indicated by simulation that this measured decreases the total dwelling time and dwelling time gradients, reduces the temperature peak and heat stress. At last, a flat surface with the surface accuracy of 0.002λ rms is obtained from the initial surface error of 0.006λ rms, proving that high precision surface can be achieved with the surface after low pass filtering. So it is of great signification for actual application on ion beam figure temperature sensible materials.\n360\nThree-Dimensional Surface Error Reconstruction and Ion Beam Figuring of Optical Hemisphere\nAuthors: Wen Lin Liao, Yi Fan Dai, Xu Hui Xie, Lin Zhou, Zi Wen Zheng, Chao Xie\nAbstract: This research is aiming at exploring a feasible machining method for ultra-high slope surface with deterministic figuring technology. We first successfully realize the nanometer-precision machining of optical hemispherical surface by using ion beam figuring (IBF) under the guidance of the reconstructed three-dimensional (3D) surface error. For figuring such a high-slope surface, we proposed some technical details, the modified algorithm for dwell time, the nonlinear developing method of surface error and the stitching machining technology, to address some important problems in process. Simultaneity a fused silica hemispherical surface is figured with our proposed method on the experimental installation IBF700-5V developed by ourselves. The root-mean-square (RMS) surface error of this sample is reduced from 19.6 nm to 9.6 nm after four iterations and about 37.8min. The experimental results indicate that IBF is a technique of high efficiency for the nanometer-precision machining of high-slope surface.\n210\nIon Beam Figuring System for Ultra-Precise Optics\nAuthors: Zheng Yuan, Yi Fan Dai, Xu Hui Xie, Lin Zhou\nAbstract: Ion beam figuring (IBF) is a novel technology for Ultra-precise optics. Material is removed from optic surface in atomic or molecular form by physical sputtering. Due to non-contact between the tool and the work piece, the problems involved in the conventional process are avoided, such as edge-effect and tool-wear. The ion beam figuring process is of high determinacy and high efficiency. All these properties make ion beam figuring one of the promising methods for producing mirrors of high precision with nm-rms accuracy. In this article, a new ion beam figuring system which contains doubled vacuum chambers is set up. Optics can be exchanged by a transport vehicle shuttling between the two vacuum chambers without opening the primary vacuum chamber and waiting for the ion source to cool completely, which means the efficiency can be increased greatly. A high performance processing robot contains three linear axes and two angular axes of motion, providing 5-axis ion source positioning capability with high accuracy. The angle can be up to 50° to figure very steep spherical and aspherical surfaces. Then, the beam removal function of Gaussian shape is obtained by an experimental method and it is extremely stable for a long time. Finally, two sample mirrors are figured by the ion beam figuring system: one is a fused silica flat mirror with a 100 mm diameter (90% effective aperture) and an ultra-precise flat mirror with a surface error of 0.89 nm rms, 14.7 nm PV is obtained; the other fused silica concave spherical mirror with a 100 mm aperture (90% effective aperture) and 420 mm radius of curvature is figured and a concave spherical mirror with 1 nm rms, 16.9 nm PV is obtained, which prove that the ion beam figuring system is favourable for the figuring process.\n19\n""","0.21830732","""https://www.scientific.net/KEM.496.182""","[-0.629225,52.074389]"
"""Brunel_University_London""","""Effect of Gas-to-Liquid Diesel Fuels on Combustion Characteristics, Engine Emissions, and Exhaust Gas Fuel Reforming. Comparative Study - Energy & Fuels (ACS Publications)""","""Effect of Gas-to-Liquid Diesel Fuels on Combustion Characteristics, Engine Emissions, and Exhaust Gas Fuel Reforming. Comparative Study\nA. Abu-Jrai , † A. Tsolakis , * † K. Theinnoi , † R. Cracknell , ‡ A. Megaritis , § M. L. Wyszynski , † and S. E. Golunski ‖\nSchool of Engineering, Mechanical and Manufacturing Engineering, University of Birmingham, Birmingham B15 2TT, U.K., Shell Global Solutions, Cheshire Innovation Park, Chester CH1 3SH, U.K., Mechanical Engineering, School of Engineering and Design, Brunel University, West London, Uxbridge UB8 3PH, U.K., and Johnson Matthey Technology Centre, Blount's Court, Sonning Common, Reading RG4 9NH, U.K.\nEnergy Fuels\n, 2006, 20 (6), pp 2377–2384\nDOI: 10.1021/ef060332a\nPublication Date (Web): October 18, 2006\nCopyright © 2006 American Chemical Society\nAbstract\nNew diesel-type fuels such as biodiesels and gas-to-liquid (GTL) fuel have been developed in order to aid vehicle manufacturers in achieving forthcoming emission regulations, by improving engine out emissions and exhaust gas after-treatment performance. Furthermore, synthetic fuels are virtually free of sulfur and aromatic hydrocarbons and can improve the performance and durability of the catalytic fuel reformers that are designed to provide H2 to fuel cells, internal combustion (IC) engines, and after-treatments. Combustion and exhaust-gas reforming experiments with GTL and ultralow sulfur diesel (ULSD) were run under several engine and reformer operating regimes. Using a single cylinder bench engine, the combustion of GTL fuel (and blends with conventional diesel fuel) was found to reduce NOx emissions substantially and improve engine thermal efficiency but led to an increase in smoke for the default injection timing in the experiment. However, by optimizing the injection timing in a GTL-fueled engine, the harmful emissions of NOx and smoke were both reduced simultaneously while still giving improvements in engine thermal efficiency. In general, it was found that the NOx/particulates tradeoff curve shifted to lower emissions for GTL fuel and GTL fuel blends. During exhaust-gas reforming, the use of GTL fuel was found to increase fuel conversion, while producing more hydrogen and less methane.\n""","0.71420383","""http://pubs.acs.org/doi/abs/10.1021/ef060332a""","[-0.472855,51.532848]"
"""Queen's_University_Belfast""","""Impact of electric vehicles on a carbon constrained power system—a post 2020 case study - Queen's University Belfast Research Portal - Research Directory & Institutional Repository for QUB""","""Impact of electric vehicles on a carbon constrained power system—a post 2020 case study\nResearch output: Contribution to journal › Article\nPublished\nView graph of relations\nElectric vehicles (EVs) offer great potential to move from fossil fuel dependency in transport once some of the technical barriers related to battery reliability and grid integration are resolved. The European Union has set a target to achieve a 10% reduction in greenhouse gas emissions by 2020 relative to 2005 levels. This target is binding in all the European Union member states. If electric vehicle issues are overcome then the challenge is to use as much renewable energy as possible to achieve this target. In this paper, the impacts of electric vehicle charged in the all-Ireland single wholesale electricity market after the 2020 deadline passes is investigated using a power system dispatch model. For the purpose of this work it is assumed that a 10% electric vehicle target in the Republic of Ireland is not achieved, but instead 8% is reached by 2025 considering the slow market uptake of electric vehicles. Our experimental study shows that the increasing penetration of EVs could contribute to approach the target of the EU and Ireland government on emissions reduction, regardless of different charging scenarios. Furthermore, among various charging scenarios, the off-peak charging is the best approach, contributing 2.07% to the target of 10% reduction of Greenhouse gas emissions by 2025.\nDocuments\nRights statement: Copyright 2015 The Author  This is an open access article published under a Creative Commons Attribution License (https://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution and reproduction in any medium, provided the author and source are cited.\nFinal published version, 309 KB, PDF-document\nLinks\n""","0.7283162","""http://pure.qub.ac.uk/portal/en/publications/impact-of-electric-vehicles-on-a-carbon-constrained-power-systema-post-2020-case-study(4492d015-b884-49c5-aba2-f1d7c29b3367).html""","[-5.934759,54.583863]"
"""StaffCambridgeUniversityEngineering""","""Innovation, the diesel engine and vehicle markets: Evidence from OECD engine patents - CUED Publications database""","""CUED Publications database\nLogin\nInnovation, the diesel engine and vehicle markets: Evidence from OECD engine patents\nBonilla, D and Bishop, JDK and Axon, CJ and Banister, D (2014) Innovation, the diesel engine and vehicle markets: Evidence from OECD engine patents. Transportation Research Part D: Transport and Environment, 27. pp. 51-58. ISSN 1361-9209\nFull text not available from this repository.\nAbstract\nThis paper uses a patent data set to identify factors fostering innovation of diesel engines between 1974 and 2010 in the OECD region. The propensity of engine producers to innovate grew by 1.9 standard deviations after the expansion of the car market, by 0.7 standard deviations following a shift in the EU fuel economy standard, and by 0.23 standard deviations. The propensity to develop emissions control techniques was positively influenced by pollution control laws introduced in Japan, in the US, and in the EU, but not with the expansion of the car market. Furthermore, a decline in loan rates stimulated the propensity to develop emissions control techniques, which were simultaneously crowded out by increases in publicly-funded transport research and development. Innovation activities in engine efficiency are explained by market size, loan rates and by (Organisation for Economic Cooperation and Development) diesel prices, inclusive of taxes. Price effects on innovation, outweigh that of the US corporate average fuel economy standards. Innovation is also positively influenced by past transport research and development. © 2014 Elsevier Ltd.\nItem Type:\n""","0.77428937","""http://publications.eng.cam.ac.uk/624083/""",
"""Imperial_College_London""","""Lung Development and Aging | Annals of the American Thoracic Society""","""Annals of the American Thoracic Society\nDepartment of Paediatrics, Imperial College, London, United Kingdom; and Royal Brompton Harefield National Health Service Foundation Trust, London, United Kingdom\nCorresponding Author: Andrew Bush\nAbstract\nSection:\nThe onset of chronic obstructive pulmonary disease (COPD) can arise either from failure to attain the normal spirometric plateau or from an accelerated decline in lung function. Despite reports from numerous big cohorts, no single adult life factor, including smoking, accounts for this accelerated decline. By contrast, five childhood risk factors (maternal and paternal asthma, maternal smoking, childhood asthma and respiratory infections) are strongly associated with an accelerated rate of lung function decline and COPD. Among adverse effects on lung development are transgenerational (grandmaternal smoking), antenatal (exposure to tobacco and pollution), and early childhood (exposure to tobacco and pollution including pesticides) factors. Antenatal adverse events can operate by causing structural changes in the developing lung, causing low birth weight and prematurity and altered immunological responses. Also important are mode of delivery, early microbiological exposures, and multiple early atopic sensitizations. Early bronchial hyperresponsiveness, before any evidence of airway inflammation, is associated with adverse respiratory outcomes. Overlapping cohort studies established that spirometry tracks from the preschool years to late middle age, and those with COPD in the sixth decade already had the worst spirometry at age 10 years. Alveolar development is now believed to continue throughout somatic growth and is adversely impacted by early tobacco smoke exposure. Genetic factors are also important, with genes important in lung development and early wheezing also being implicated in COPD. The inescapable conclusion is that the roots of COPD are in early life, and COPD is a disease of childhood adverse factors interacting with genetic factors.\nKeywords:\nKeywords: atopy ; asthma ; nicotine ; chronic obstructive pulmonary disease ; microbiome\nIn 1977, in a classic report, Fletcher and Peto ( 1 ) proposed a model (their Figure 1 ) in which all comers attained a normal FEV1 at age 25 years, and progression to respiratory disability was solely determined by rate of decline of spirometry thereafter. Smoking history was seen as the chief determinant of rate of decline, and events before age 25 years were irrelevant. In their far less well known, but far more accurate Figure 2, they incorporated different starting levels of FEV1 at age 25 years, as well as different rates of decline, into their model. These findings have been taken forward and have had to be substantially modified by a recent study combining three cohorts. This confirmed two trajectories to chronic obstructive pulmonary disease (COPD) or, strictly speaking, to an FEV1/FVC ratio of less than 70%. There were approximately equal numbers in each trajectory. Of those who failed to attain an FEV1 of 80% before age 40 years, 26% had developed COPD during the 22 years of observation, whereas 7% with a normal FEV1 aged 40 years developed COPD within the same time period due to an accelerated rate of decline in FEV1 ( 2 ). Critically, the rate of decline was unrelated to smoking, nor could the authors identify any current feature associated with rapid decline in spirometry. The only logical conclusion is that all COPD risk is determined before the age of 40 years, either genetically or by environmental adverse influences or their interactions ( Figure 1 ).\nFigure 1. Why adults get premature airway disease. Note that all the factors have origins in childhood; there is no consistent adult-onset feature identified in the literature.\n[More] [Minimize]\nThis conclusion is supported by a European study that identified five adverse childhood influences that were associated with a lower FEV1 and a more rapid rate of decline of spirometry (and, hence, a greater COPD risk in adult life) ( 3 ). These were maternal and paternal asthma, maternal smoking, and childhood asthma and severe respiratory infections. Childhood disadvantage was at least as important as heavy smoking. The focus is therefore on any adverse event increasing the likelihood of one or more of these disadvantages. The first lesson from normal lung growth for pediatricians is that by asking five simple questions (antenatally, asking the mother three simple questions) ( Table 1 ) ( 4 ), a population of children at high risk for later premature airflow obstruction can be identified. Second, any factor increasing the likelihood of the development of childhood asthma or an increased propensity to respiratory infection will contribute to accelerated lung aging. Gene polymorphisms, for example in a disintegrin and metalloproteinase domain 33 (ADAM33), have also been associated with accelerated decline in lung function ( 5 ) (see below). Finally, no adult life influence, including smoking, has consistently been associated with accelerated decline in spirometry. The conclusion is inescapable: both the two recently described trajectories to COPD ( 2 ) are determined before adult life, and, if COPD is to be prevented, measures starting in adult life are too late.\nTable 1. Simple key questions to identify children at high risk for chronic obstructive pulmonary disease\nAntenatally and postnatally\nDoes the child have asthma?\nHas the child had severe respiratory infections?\nThe best description of the normal evolution of spirometry is from the Global Lung Initiative ( 6 ). The group used 97,759 measurements in healthy nonsmokers from 72 centers in 33 countries aged between 2.5 and 95 years to construct predictive equations for spirometry. From their smooth curves, three key stages emerge: for normal lung health, spirometry needs to be normal at first measurement (now best described by the raised volume, rapid thoracic compression technique at birth [ 7 ], or preschool standard spirometry [ 8 ], stage 1), needs to grow normally in childhood to attain a normal plateau at age 20 to 25 years (stage 2), and declines with aging at a normal rate (stage 3). Key influences on these stages are discussed in turn. Finally, new data challenging the concepts of normal alveolar growth are presented. Space allows only a summary of many factors leading to childhood asthma and respiratory infections.\nKey Stage 1: Before Birth\nSection:\nThe morphological phases of lung development in utero have been well described; airway caliber is determined largely in the second half of pregnancy. Recently, the gene expression studies of normal lung development have been determined ( 9 ) and have broadly confirmed the utility of the morphological stages. The complexities of the pathways of branching morphogenesis have been reviewed ( 10 , 11 ) and will not be discussed further, except insofar as they lead to important genetic clues into lung aging.\nPreconception adverse events may impact the fetus. Grandmaternal smoking has a double-hit effect; it increases the risk of maternal asthma and, even if the mother herself does not smoke, increases the risk of her offspring having asthma ( 12 , 13 ).\nAntenatal adverse effects can be mediated through reducing airway caliber, altering fetal immune responses, inducing either or both prematurity and low birth weight, and influencing the mode of delivery. Many different antenatal adverse effects on lung growth have been described ( 14 ), including the effects of maternal stress on fetal immune responses ( 15 ), but most information is available for nicotine and tobacco smoke. These are worsened if mother or fetus have non-null GSTT1, highlighting the importance of gene–environment interactions ( 16 ). Recently, the adverse effects on early childhood spirometry of maternal exposure to environmental pollution have come to the fore ( 17 , 18 ), and, although the mechanisms are speculative, it is clear that early airflow obstruction is the result ( 19 ).\nMaternal hypertension of pregnancy has been described as causing airflow obstruction in the baby ( 20 ), but this has been disputed recently, with attention focusing on prepregnancy hypertension as being important ( 21 ). More studies are needed to confirm or otherwise the developmental role of maternal blood pressure on the baby.\nStructural Changes\nMost of the data have come from animal models of nicotine exposure of the pregnant dam. Antenatal changes described include increased collagen deposition ( 22 ), increased MUC5AC expression ( 23 ), and airway lengthening and reduction in caliber ( 24 ). The readout in the fetus is airway obstruction and airway hyperresponsiveness (AHR) at birth. Note that AHR occurs in the absence of allergen exposure (mice) and any evidence of airway inflammation (mice, infants [ 24 , 25 ]). The anatomical changes are likely also exacerbated by loss of alveolar tethering points ( 26 ) and increased airway smooth muscle thickness ( 27 )\nImmunological Changes\nThere are a large number of studies looking at the effects of pregnancy exposures on cord blood mononuclear cell function. Maternal smoking and previous pregnancies affect cord blood mononuclear cell proliferation to allergens ( 28 ). Abnormal cytokine responses at birth predict wheeze with viral infections in early life ( 29 ), including rhinovirus-induced wheeze, which is strongly associated with subsequent asthma ( 30 ). Maternal smoking is also associated with abnormal toll-like receptor function ( 31 ).\nBirth Weight, Low Birth Weight, and Prematurity\nA recent metaanalysis has shown that any cause of low birth weight is associated with subsequent childhood and adult asthma ( 32 ). The Aberdeen Birth cohort demonstrated a linear relationship between birth weight (adjusted for relevant maternal factors) and spirometry at age 45 to 50 years ( 33 ). Tobacco smoking is a well-known cause of preterm delivery, the risk of which is reduced by tobacco legislation ( 34 ). Very preterm infants are well known to be left with fixed and variable airflow obstruction, and, although outcomes are improving ( 35 ), even those preterm babies requiring no treatment in the newborn period have airflow limitation ( 36 ), so improvements in neonatal intensive care are unlikely to abolish the problem. The decrements in spirometry in bronchopulmonary dysplasia survivors are greater than those of healthy preterm infants ( 37 ). Furthermore, even modest degrees of prematurity (up to 37 weeks’ gestation) are associated with impaired spirometry in the late teenage years ( 38 ) and increased use of asthma medications in childhood ( 39 – 41 ). Low birth weight of itself is a risk factor for subsequent asthma ( 32 ). There may be a differential effect of low birth weight in babies who are small (SGA), as opposed to appropriate (AGA), weight for gestation age; at age 20 to 22 years, spirometry was strongly predicted by birth weight in the SGA but not the AGA group ( 42 ). It should be noted that, as protocols for resuscitation of the newborn ( 43 ) and subsequent ventilation ( 44 ) have changed, so have the different contributions of airway and parenchymal disease in “new” and “old” bronchopulmonary dysplasia ( 45 )\nMode of Delivery\nDelivery by caesarean section is associated with an increased risk of atopic disorders ( 46 , 47 ), probably mediated via an effect on the fetal microbiome ( 48 ). Especially if at least one parent is allergic, children delivered by caesarean section have a higher prevalence of asthma at age 8 years, and children of nonallergic parents were more likely to be sensitized ( 49 ). Because there are no randomized controlled trials of caesarean section delivery, it is not possible to disentangle the effects of caesarean delivery from the causes leading to the need for caesarean delivery.\nKey Stage 2: Childhood Lung Growth\nSection:\nLessons from the Birth Cohorts\nThe ideal study would have recruited babies antenatally and followed them through with repeated measurements until death; such a study has not been done, and so we have to rely on a series of overlapping cohorts ( 50 – 53 ), reviewed in Reference 54 . Although there are some discrepancies, the general message is that lung function at age 4 to 6 years is determined by lung function and bronchial hyperresponsiveness soon after birth, and thereafter tracks; hence, decrements at age 4 to 6 years are reflected in adult lung function, at least to age 50 years. There may be further deterioration at school age and beyond, but no improvements.\nThis view has recently been challenged, at least in the context of preterm survivors. A group of preterm babies at age 7 to 9 years had evidence of airflow obstruction, the degree of which related to the intensity of neonatal treatment, but this had normalized by age 20 to 22 years ( 42 ); interestingly, birth weight was a strong determinant of airflow obstruction in the SGA but not the AGA low birth weight babies. However, this difference was not found in another study ( 55 ). The differences might relate to the proportions of SGA and AGA babies in the different studies or the relative insensitivity of spirometry to distal airway disease. Overall, however, it is clear that the preschool years represent a critical window for long-term lung health.\nThe presence of AHR is important in long-term lung function and requires a developmental perspective. Three groups have measured neonatal AHR, and all showed significant relationships with long-term outcomes, albeit with slightly different results ( 56 – 60 ). The COPSAC (Copenhagen Prospective Studies on Asthma in Childhood) data ( 59 ) suggested that 40% of airway obstruction at age 7 years was determined antenatally and 60% postnatally; neonatal AHR was more strongly associated with asthma at age 7 years than neonatal lung function. It should be noted that neonatal AHR is not related to airway inflammation ( 25 ) and is presumably determined by anatomical factors (see above); thus, small airways increase resistance more for a given proportionate radius change because resistance is inversely related to the fourth power of the radius. Although AHR and lung function at birth were described as independent risk factors for childhood lung function ( 61 ), in reality abnormal anatomy is likely to underlie both. Finally, the longest-running study of AHR from birth to adult life showed that the adult relationship between AHR and asthma was established before age 6 years ( 62 ).\nTobacco and Nicotine\nThe effects of passive smoking were described in a series of metaanalyses ( 63 – 69 ), which have been recently updated ( 70 ); they are sufficiently well known that, in the interest of space, they will not be further discussed. Of interest, recent data showed that maternal smoking and the child taking up smoking have additive effects on the child’s lung function ( 71 ).\nPollution\nThe association of exposure to outdoor pollution postnatally with poorer lung function, asthma, respiratory infections, and a lower rate of growth of spirometry has been well described ( 72 – 74 ), but it may be difficult to disentangle the confounding effects of socioeconomic status. Recently, the beneficial effects of legislation leading to improved air quality on the growth of children’s lungs have been described ( 2 ). Globally, indoor exposure to burning biomass fuels may be most important, and measures to improve indoor air quality improve children’s lung function ( 75 ). Organophosphorus pesticides have recently been implicated as affecting child lung development ( 76 ).\nAsthma and Atopy\nEarly impairment of lung function is associated with objectively diagnosed asthma at age 10 years ( 77 ). It has long been known that early sensitization to aeroallergens is associated with persistent wheeze, loss of lung function, and the development of AHR ( 78 ). Understanding has advanced with the realization that atopy is not an all-or-none phenomenon but can be quantified ( 79 ) and has a developmental perspective. The Manchester group used machine learning approaches to analyze data on patterns of wheeze and atopic sensitization and showed that only multiple early sensitizations were important ( 80 ). In a subsequent study, they showed that persistent wheeze, early multiple atopic sensitizations, and asthma attacks are associated with reduced growth in lung function ( 81 ). Asthma itself is associated with poorer lung growth. As yet unexplained, in the CAMP (Childhood Asthma Management Program) study, approximately one-third of subjects lost percent predicted lung function over the study period, independent of prescribed treatment ( 82 ).\nEarly Viral Infections\nThat acute viral infections are important causes of early respiratory morbidity due to bronchiolitis and wheeze is indisputable. However, whether they cause asthma to develop in an infant who would otherwise not go on to the disease, or are a marker for an asthma propensity, or both, is controversial. It is clear from cord blood studies (see above) that there is antenatal programming favoring viral wheeze; a study from Perth showed that respiratory function was impaired before the development of bronchiolitis, and this decrement tracked into mid-childhood ( 83 ). Respiratory syncytial virus bronchiolitis is a devastating illness, but studies as to whether it is causally associated with asthma are controversial ( 84 , 85 ). Recently, attention has focused on rhinovirus as being more associated with later asthma ( 30 ). The balance of evidence is that allergic sensitization precedes viral wheezing ( 86 ), and it is likely that sensitization rather than viral infections drive the march to asthma. However, this conclusion must still be considered tentative.\nMicrobiome\nThe role of bacteria in normal and abnormal immune development, as well as exacerbations of airway disease ( 87 ), has recently come to the fore. The lower airway is now known not to be sterile as was once believed ( 88 ). Early nasopharyngeal bacterial colonization is associated with altered immune responses ( 89 ), a greater likelihood of wheezing ( 90 ), and worse respiratory infective outcomes ( 91 )—therefore, a double hit at least hypothetically in accelerating lung aging subsequently. It is likely that the fundamental abnormality is an underlying mucosal immune defect, but this is still contentious. By contrast, environmental bacterial and fungal diversity is associated with a reduced risk of asthma ( 92 ). Animal studies have shown that the microbiome is essential for normal immune development ( 93 ), and interactions between allergens and the microbiome influence the body’s immune responses ( 94 , 95 ). The long-term effects of an abnormal microbiome on lung aging are currently unknown, but their influences on asthma risk mean that they are likely significant (see above).\nNutrition\nThere is evidence that an early and rapid gain in weight may be associated with poorer lung growth, in addition to the effects of low birth weight and SGA ( 96 ). However, paradoxically, greater weight gain in later childhood may be associated with better spirometry ( 97 ).\nKey Stage 3: The Aging Lung\nSection:\nThere has been much recent information that has increased our understanding of lung aging since Fletcher and Peto’s manuscript ( 2 , 98 – 101 ). In summary, it is clear that many patients with COPD have a normal rate of lung aging, and, indeed, those who fail to attain the normal plateau in early adult life are at the highest risk of COPD. Asthma and bronchial hyperresponsiveness are risk factors for accelerated decline, but no other environmental factor, including smoking, has consistently been implicated as a cause. The Framingham study reported traffic pollution as being important ( 102 ), but the caveats about socioeconomic status (see above) remain.\nThe role of asthma and AHR in accelerated decline in airway function is multifactorial. The combination of a preexisting low FEV1 and airway inflammation (as shown by elevation in fractional exhaled nitric oxide) is associated with accelerated decline ( 103 ), as are asthma attacks ( 104 ). The Groningen group showed that patients with asthma who stopped smoking and used inhaled corticosteroids had a slower rate of decline; AHR predicted decline independent of baseline FEV1 ( 105 ). However, the two are interrelated; they also showed that low childhood FEV1 and less increase over time was associated with adult AHR ( 106 )\nGenes, Lung Growth, and Lung Aging\nSection:\nGenetic factors, including gene-by-environment interactions via a variety of epigenetic mechanisms, are clearly important in lung development and aging. It is likely that a rich harvest of COPD genes will be found in normal lung development ( 107 ). There are substantial commonalities between genes causing reduced lung function in both smokers and nonsmokers ( 108 ). The conventional approaches have recently been taken forward by using systems genetic approaches ( 109 ).\nAntenatally Important Genes\nADAM33 is an exemplar gene with different roles at different developmental stages. It is important antenatally during airway branching morphogenesis ( 110 ). Levels in the fetus depend on maternal atopy, via an IL-13 pathway ( 111 ). There is an adverse interaction between antenatal tobacco exposure and ADAM33 polymorphisms and lung function at age 8 years ( 112 ). ADAM33 polymorphisms are associated with increased airway resistance in the preschool years ( 113 ), are associated with asthma and bronchial hyperresponsiveness in adults ( 114 ), and those known to convey susceptibility to COPD were associated with an accelerated rate of decline in spirometry in a Dutch general population ( 5 ).\nGenes Important in Early Postnatal Life\nThe β-receptor gene links early lung function, asthma, and COPD. Much is known about β-receptor function in asthma, but very little is known about any possible role in infancy. Maximal flow at functional residual capacity and bronchial hyperresponsiveness (BHR) were measured soon after birth in infants; having any Glyn 27 or Arg 16 allele was associated with reduced maximal flow at functional residual capacity ( 1 ), independent of maternal smoking or atopic status, but BHR was independent of genotype. The patients were restudied at age 11 years, and β-receptor genotype had no association with either spirometry or BHR, possibly because of low statistical power. More than 80% of the children had at least one parent with asthma, so caution should be exercised before extrapolating to low-risk populations. In another study ( 115 ) there was an association between arg16 gln27 and a positive BHR at age 6 years. The gly16 gln27 haplotype was associated with better spirometry at 6 and 11 years of age and less likelihood of an asthma diagnosis at the later time point, but at age 11 years, arg16 gln27 was associated with worse spirometry. A further study found associations with β-receptor haplotypes in adults with COPD, asthma, and other respiratory problems ( 116 ). β-receptor polymorphisms also predicted symptoms of asthma continuing into adult life ( 117 ), but like other genetic studies, the association was weak. One study examined the genetics of preschool wheeze phenotypes and related them to COPD genes ( 118 ). They found that at least three COPD genes were involved in lung growth and development and were involved in antenatal and early life responses to tobacco smoke exposure. More recently, low circulating concentrations of the antiinflammatory protein CC16, which are known to be associated with an accelerated decline in FEV1 in patients with COPD ( 98 , 119 ), have also been found to be associated with accelerated decline in a general adult population and impaired childhood lung function ( 120 ).\nGenome-Wide Association Studies of Spirometry: Developmental Genes\nThere have been a large number of recent important genome-wide association studies both of normal lung function ( 121 – 123 ) and of COPD, many but not all of the latter focusing on lung function ( 122 – 126 ). A recent genome-wide association study implicated the CHRNA5/3 region and in particular HTR4 in airflow obstruction ( 127 ). At least some of the genes identified are also active in important in utero developmental pathways (e.g., wnt/β-catenin [ 128 ]). However, other genes important in premature onset of adult COPD ( 129 ), such as alpha-1 antitrypsin, appear not to have a developmental role, although interestingly those heterozygous for mutations in this gene appear to have increased respiratory reserve ( 130 )\nAlveolar Growth\nSection:\nConventional wisdom was that alveolar growth was largely a postnatal phenomenon, with an initial rapid phase in the first 2 years of life and a much slower phase until age 8 years, whereupon alveoli increased in size but not in number. A series of recent papers have challenged this concept. In nonhuman primates, where alveolar counts can be made at different ages, alveolar numbers increase until adult maturity. In humans, inhalation of hyperpolarized helium (He3) can be used to calculate alveolar size using a number of mathematical modeling techniques and has demonstrated that alveolar size does not change between the ages of 7 and 21 years ( 131 ).\nAdverse effects on alveolar growth have really only been studied in the context of prematurity and its treatment. In animal models, hyperoxia, systemic steroids, and nicotine all impair secondary septation and neoalveolarization ( 132 – 134 ). He3 data in humans ( 135 ) suggest that maternal smoking in pregnancy may increase alveolar size and reduce numbers. The fact that nicotine itself is implicated in both impaired airway and alveolar development calls into question the safety of e-cigarettes ( 136 ). There is also some evidence of catch-up growth, although this is based on cross-sectional studies, not longitudinal data; there are no neonatal data with corresponding studies in childhood and adult life. One group used carbon monoxide transfer as a surrogate for the size of the alveolar–capillary membrane and showed this was normal at rest and on exercise in adult life ( 137 ). He3 data in preterm survivors in adolescence showed that alveolar size was normal ( 138 ). Nitrogen washout can be used to partition gas mixing abnormalities into airway (Scond) and alveolar (Sacin) ( 139 , 140 ). Compared with normal infants, preterm survivors in childhood had, as expected, an abnormal Scond, but Sacin was normal, implying normal alveolarization ( 141 ). However, it should be said that if many alveoli were completely destroyed, Sacin would still be normal, because they would give no signal. Also, all these studies assumed that alveolarization had been abnormal in the newborn period, but they could not measure it, so that there had been true catch-up growth remains conjectural. However, taken together, the evidence is that alveolarization continues for longer, and there is greater potential for catch-up growth, than was previously believed. Certainly, lungs apparently destroyed by necrotizing pneumonias usually recover completely ( 142 ), so at least the potential for catch-up is certainly present. Intriguingly, being brought up at altitude in hypoxic conditions appears to stimulate alveolarization while having no effect on airway function ( 143 ); this raises the intriguing question as to whether keeping the preterm survivors very well oxygenated is as wise as we believed.\nCOPD: Relevance of Developmental Aspects of Lung Function\nSection:\nThere is one final lesson to be learned from developmental aspects of lung growth. The Global Initiative for Chronic Obstructive Lung Disease defines COPD as an FEV1/FVC ratio less than 70%. However, this ratio changes with age ( 144 ); the lungs of young children empty so efficiently that the forced expiratory volume in 0.5 second (FEV0.5)/FVC ratio has to be used ( 7 ), because FEV1/FVC is 100%. Conversely, after age 50 years, increasing numbers of normal people will have FEV1/FVC ratio less than 70%, and after age 70 years, more than 15% of normal people will have FEV1/FVC ratio less than 70%. This use of a fixed ratio without considering the developmental background has two important consequences. The first is that many more normal elderly people will be diagnosed as having COPD ( 145 ). The second is that the severity of the premature airflow obstruction in young adults and even children will not be appreciated; an FEV1/FVC ratio of 75% will be very abnormal at this age. This underscores the fact that premature airflow obstruction is primarily a pediatric disease; this is being overlooked, and intervention delayed, by relying on a ratio that is falsely reassuring at a young age.\nSummary and Conclusions: What Does This Mean for the Future of Lung Health?\nSection:\nIt is clear that if we are to prevent COPD from becoming an ever more important cause of death in adults, we must optimize lung health from before birth and in early childhood. We have much to learn about detailed mechanisms, but there is much we can do now while these studies are going on. We must focus on three preventive measures that have been shown to work. As a matter of urgency, we need to tighten our grip on all forms of tobacco and nicotine exposure, including e-cigarettes. We must legislate to reduce exposure to outdoor pollution, in particular ensuring that very tight controls on vehicle emissions in residential areas are enforced. We need to acknowledge that healthy aging starts in childhood, and unhealthy aging does as well. If fundamental research in the prevention of COPD is to be done, it will be done in early life. Finally, in particular in low- and middle-income country settings, we must ensure that indoor biomass fuel exposure is minimized. The message needs to be gotten across that COPD is not all about a disease that smokers bring on themselves but is in fact just disease of childhood disadvantage and genetics, which must be addressed in childhood if death rates are to drop.\nReferences\n""","0.123699985","""https://www.atsjournals.org/doi/10.1513/AnnalsATS.201602-112AW""","[-0.178219,51.500505]"
"""Cranfield_University""","""Pilot-model-in-the-loop simulation environment to study large aircraft dynamicsProceedings of the Institution of Mechanical Engineers, Part G: Journal of Aerospace Engineering - Mohammad M Lone, Alastair K Cooke, 2013""","""Section:\n1.\nWeltz G, Shweyk K. Application of new and standard pilot-induced oscillation (PIO) analysis methods to flight test data of the C-17 transport aircraft. 2007. In: AIAA atmospheric flight mechanics conference and exhibit, Hilton Head, SC, 20–23 August 2007, AIAA-2007-6387.\n2.\nNorton W.J. Aeroelastic pilot-in-the-loop oscillations. In: Flight vehicle integration panel workshop on pilot induced oscillations, North Atlantic Treaty Organization, February 1995, AGARD-AR-335, pp.10-1–10-14.\n3.\nMcRuer D, Jex H. A review of quasi-linear pilot models. IEEE Trans Human Factors in Electronics HFE-8 1967; 3: 231–249. Crossref\n4.\nThompson PM, Klyde DH, Brenner MJ. Wavelet-based time-varying human operator models. 2001. In: AIAA atmospheric flight mechanics, conference and exhibit, Montreal, Canada, 6–9 August 2001, AIAA-2001-4009.\n5.\nTustin A. An investigation of the operator's response in manual control of a power driven gun. C.S. Memorandum 169 Metropolitan-Vickers Electrical Co, August 1944.\n6.\nMcRuer D, Krendel E. Mathematical models of human pilot behaviour AGARDograph AGARD-AG-188, Advisory Group for Aerospace Research & Development, 1974.\n7.\nHess R. A unified theory for aircraft handling qualities and adverse aircraft-pilot coupling. Technical Report AIAA 97-0454, AIAA, Reno, NV, 1997.\n8.\nKleinman D. Optimal control of linear systems with time-delay and observation noise. IEEE Trans Automatic Control 1969; 14: 524–527. Crossref\n9.\nDoman D. Projection methods for order reduction of optimal human operator models. Ph.D. Thesis Virginia Polytechnic Institute and State University, VA, 1998.\n10.\nAnderson M, Doman D. Fixed order optimal pilot models. 1996. In: AIAA guidance, navigation and control conference, San Diego, CA, 29–31 July 1996, AIAA-96-3871.\n11.\nKleinman D, Baron S. The human as an optimal controller and information processor NASA CR-1151, NASA, 1968.\n12.\nHess R. Prediction of pilot opinion ratings using an optimal pilot model. Human Factors 1977; 19: 459–475. Link\n13.\nDavidson J, Schmidt D. Modified optimal control pilot model for computer-aided design and analysis. Technical Memorandum 4384, NASA, Langley Research Center, October 1992.\n14.\nAndrews S, Cooke A. An aeroelastic flexible wing model for aircraft simulation. In: 48th AIAA aerospace sciences meeting including the new horizons forum and aerospace exposition, Orlando, FL, 4–7 January 2010, AIAA-2010-35.\n15.\nZaal P, Pool D, de Bruin J, . Use of pitch and heave motion cues in a pitch control task. J Guidance, Control and Dynamics 2009; 32: 366–377. Crossref\n16.\n""","0.40322384","""http://journals.sagepub.com/doi/10.1177/0954410011434342""","[-0.629225,52.074389]"
"""Imperial_College_London""","""A pricing and investment strategy for national roads | Proceedings of the Institution of Civil Engineers - Transport""","""Proceedings of the Institution of Civil Engineers - Transport\nProceedings of the Institution of Civil Engineers - Transport\nISSN 0965-092X | E-ISSN 1751-7710\nA pricing and investment strategy for national roads\nAuthors: \nOBE, CEng, FICE, FIHT, FRTPI, FREng\nx\nPublished Online: May 25, 2015\nKey:\nTrial content\nAbstract\nMain road traffic has doubled in the last quarter-century and its growth continues. During this time the length of the trunk road network has been reduced by almost a fifth and motorway construction has all but halted. Combinations of additional strategic road capacity and national road pricing are examined to explore what mix of these would provide a package of measures which would ease future congestion whilst maintaining adequate levels of mobility. A combination of ‘efficient pricing’—which would replace the existing road taxation regime—and the provision of an additional 600 lane km of strategic road space a year would reduce congestion and carbon emissions whilst providing the mobility needed for a growing and successful economy. The net revenues from pricing would be more than sufficient to pay for the additional capacity and the higher charges to road users would be more than offset by improved strategic road travel conditions.\nKeywords:\n""","0.8936618","""http://www.icevirtuallibrary.com/doi/10.1680/tran.2008.161.3.103""","[-0.178219,51.500505]"
"""Imperial_College_London""","""Engine Operational Benefits with Cylinder Deactivation in Malaysian Urban Driving Conditions""","""Engine Operational Benefits with Cylinder Deactivation in Malaysian Urban Driving Conditions\nPaper #:\nhttps://doi.org/10.4271/2015-01-0983\nCitation:\nAbas, M. and Martinez-Botas, R., \""Engine Operational Benefits with Cylinder Deactivation in Malaysian Urban Driving Conditions,\"" SAE Technical Paper 2015-01-0983, 2015, https://doi.org/10.4271/2015-01-0983 .\n8\nAbstract:\nCylinder deactivation has been utilized by vehicle manufacturers since the 80's to improve fuel consumption and exhaust emissions. Cylinder deactivation is achieved by cutting off fuel supply and ignition in some of the engine cylinders, while their inlet and outlet valves are fully closed. The vehicle demand during cylinder deactivation is sustained by only the firing cylinders, hence increasing their indicated power. Conventionally, half the number of cylinders are shut at certain driving conditions, which normally at the lower demand regime. An optimal strategy will ensure cylinder deactivation contributes to the fuel saving without compromising the vehicle drivability.Cylinder deactivation has been documented to generally improve fuel consumption between 6 to 25 %, depending on the type-approval test drive cycle. However, type-approval test has been reported to differ from the “real-world” fuel consumption values. Therefore the documented fuel consumption might not be representable for consumers in their actual driving. The Malaysian authorities have been using the NEDC test to measure the emission and fuel consumption for declaration purposes, which may be misleading. This paper presents the measurement and analysis of an engine operating with cylinder deactivation, tested on a dynamometer in accordance to the actual driving conditions rather than the NEDC. This is to understand the actual benefits of cylinder deactivation in the real world. The regular Malaysian urban driving conditions were previously identified and applied in this analysis.To understand the engine operational behaviour, a piezoelectric sensor was instrumented on the engine to acquire the in-cylinder pressure traces. Test results from this study have shown that cylinder deactivation improves fuel consumption and thermodynamic efficiencies for the actual Malaysian driving conditions. The fuel consumption benefit also correlates well with the improvements on the mean effective pressures. Engine pumping mean effective pressure reduced as much as 19.4% and the thermal efficiency was consistently improved up to 5% during the cylinder deactivated operation. These improvements were achieved while maintaining similar brake mean effective pressures as if when all cylinders are firing. Most importantly, these improvements fall within the regular actual urban driving conditions, thus will be most beneficial for Malaysian drivers. Furthermore, the recorded engine operating characteristics will be the key in determining the correct strategy towards maximizing the benefits of cylinder deactivation for the Malaysian urban driving conditions.\nEvent:\n""","0.48871857","""http://papers.sae.org/2015-01-0983/""","[-0.178219,51.500505]"
"""Brunel_University_London""","""Robust solutions and risk measures for a supply chain planning problem under uncertainty | SpringerLink""",""", Volume 59, Issue 1 , pp 2–12 | Cite as\nRobust solutions and risk measures for a supply chain planning problem under uncertainty\nAuthors\nC A Poojari Email author\nC Lucas\n22 Citations\nAbstract\nWe consider a strategic supply chain planning problem formulated as a two-stage stochastic integer programming (SIP) model. The strategic decisions include site locations, choices of production, packing and distribution lines, and the capacity increment or decrement policies. The SIP model provides a practical representation of real-world discrete resource allocation problems in the presence of future uncertainties which arise due to changes in the business and economic environment. Such models that consider the future scenarios (along with their respective probabilities) not only identify optimal plans for each scenario, but also determine a hedged strategy for all the scenarios. We\n1)\nexploit the natural decomposable structure of the SIP problem through Benders’ decomposition,\n \napproximate the probability distribution of the random variables using the generalized lambda distribution, and\n \n3)\nthrough simulations, calculate the performance statistics and the risk measures for the two models, namely the expected-value and the here-and-now.\n \nsupply chain planning stochastic integer programming Benders’ decomposition generalized lambda distribution simulation genetic algorithm \nReferences\nArntzen B, Brown G, Harrison TP and Trafton L (1995). Global supply chain management at digital equipment corporation. Interfaces 1(25): 69–93. CrossRef Google Scholar\nBaricelli P (1996). An investigation into a manufacturing and supply chain planning problem under uncertainty. Master's thesis, Department of Mathematics and Statistics, Brunel University, West London. Google Scholar\nBerman O and Ganz Z (1994). The capacity expansion problem in the service industry. Comput Opns Res 21: 557–572. CrossRef Google Scholar\nBerman O, Ganz Z and Wagner J (1994). A stochastic optimization model for planning capacity expansion in a service industry under uncertain demand. Naval Res Logist 41: 545–564. CrossRef Google Scholar\nBerman O and Hood S (1999). Capacity optimization planning system (caps). Interfaces 29: 31–50. CrossRef Google Scholar\nBienstock D and Shapiro J (1988). Optimizing resource acquisition decisions by stochastic programming. Mngt Sci 34: 215–229. CrossRef Google Scholar\nBirge J (1985). Decomposition and partitioning methods for multi-stage stochastic linear programs. Opns Res 33: 989–1007. CrossRef Google Scholar\nBirge J and Louveaux F (1997). Introduction to Stochastic Programming. Springer Series in Operations Research. Springer-Verlag: New York. Google Scholar\nBitran G and Tirupati D (1993). Hierarchial production planning. Handbooks in Operations Research and Management Science: Logistics of Production and Inventory. North-Holland: Amsterdam. Google Scholar\nBradley J and Arntzen B (1999). The simultaneous planning of production, capacity, and inventory in seasonal demand environments. Opns Res 47: 795–806. CrossRef Google Scholar\nBrindley C and Ritchie R (2001). The information-risk conundrum. Market Intell Plann 1(19): 29–37. Google Scholar\nCarino D, Kent R, Myers D, Stacy C, Sylvanus M, Turner A, Watababe K and Ziemba W (1994) . Russell–Vasuda kasai model: an asset liability model for Japanese insurance company using multi-stage stochastic programming. Interfaces, 24(1): 29–49. Google Scholar\nChang S-G and Gavish B (1993). Telecommunications network topological design and capacity expansion. Telecommun Syst 1: 99–131. CrossRef Google Scholar\nCheung R and Powell W (1996). Models and algorithms for distribution problems with uncertain demands. Transport Sci 30: 43–59. CrossRef Google Scholar\nChristopher M (1992). Logistics and Supply Chain Management. Pitman Publishing: London. Google Scholar\nChristopher M and Lee H (2004). Mitigating supply chain risk through improved confidence. Int J Phys Distrib Logist Mngt 4: 388–396. CrossRef Google Scholar\nDempster M and Consigli G (1998). The calm stochastic programming model for dynamic asset-liability management. In: Mulvey JM and Ziemba WT (eds). World Wide Asset and Liability Modelling. Cambridge University Press: Cambridge, pp 464–500. Google Scholar\nDempster M, Fisher M, Jansen L, Lageweg B, Lenstra J and Kan A (1983). Analysis of heuristics for stochastic programming—results for heirarchical scheduling problems. Math Opns Res 8: 525–537. CrossRef Google Scholar\nDempster M, Pedrón NH, Medova E, Scott J and Sembos A (2000). Planning logistic operations in the oil industry. J Opl Res Soc 51: 1271–1288. CrossRef Google Scholar\nEppen G, Martin R and Schrage L (1989). A scenario approach to capacity planning. Opl Res 37: 517–525. CrossRef Google Scholar\nEscudero L, Kamesam P, King A and Wets R-J (1993). Production planning via scenario modelling. Ann Opns Res 43: 311–335. Google Scholar\nFantauzzi F, Gaivornski A and Messina E (1996). Lecture notes on economics and mathematical systems: Network optimization. In: Pardalos M., Hearn D and Hager WW, editors. Decomposition Methods for Network Optimization Problems in the Presence of Uncertainty, Vol. 450. Springer: Berlin, pp 234–248. Google Scholar\nFedergruen A and Zipkin P (1984). A combined vehicle routing and inventory allocation problem. Opns Res 32: 1019–1037. CrossRef Google Scholar\nFragniere E, Gondzio J and Vial J-P (2000). Building and solving large-scale stochastic programs on an affordable distributed computing system. Ann Opns Res 99: 167–187. CrossRef Google Scholar\nFreimer M, Mudholkar G, Kollia G and Lin C (1988). A study of the generalized Tukey lambda family. Commun Statist—Theory Methods 17: 3547–3567. Google Scholar\nGeoffrion A and Graves G (1974). Multicommodity distribution system design by bender's decomposition. Mngt Sci 20: 822–844. CrossRef Google Scholar\nGeoffrion A and Powers R (1995). Twenty years of strategic distribution systems design: An evolutionary perspective. Interfaces 25(5): 105–128. Google Scholar\nHaksoz C and Seshadri S (2007). Supply Chain operations in the presence of a spot market: a review with discussion. J Opl Res Soc 58: 1412–1429. Google Scholar\nHastings C, Mosteller F, Tukey JW and Winsor CP (1947). Low moments for small samples: A comparative study of order statistics. Ann Math Statist 18: 413–426. CrossRef Google Scholar\nHoyland K and Wallace S (1996). Generating scenario trees for multi-stage decision problems. Mngt Sci 26: 1–13. Google Scholar\nHuchzermeier A and Cohen M (1996). Valuing operational flexibility under exchange rate risk. Opns Res 44: 100–113. CrossRef Google Scholar\nKarian Z and Dudewicz E (2000). Fitting Statistical Distributions: The Generalized Lambda Distribution and Generalized Bootstrap Methods. CRC Press: Boca Raton, FL. CrossRef Google Scholar\nKeeney R and Raiffa H (1976). Decisions with Multiple Objectives: Preferences and Value Trade-offs. Wiley: New York. Google Scholar\nKing RAR and MacGillivray HL (1999). A starship estimation method for the generalized lambda distributions. Austral New Zealand J Statist 41: 353–374. CrossRef Google Scholar\nLaguna M (1998). Applying robust optimization to capacity expansion of one location in telecommunications with demand uncertainty. Mngt Sci 44: 101–110. CrossRef Google Scholar\nLaporte G, Louveaux F and Hamme LV (1994). Exact solution to a location problem with stochastic demands. Transport Sci 28: 95–103. CrossRef Google Scholar\nManne A (ed). Investments for Capacity Expansion. The MIT Press: Cambridge. Google Scholar\nModiano E (1987). Derived demand and capacity planning under uncertainty. Opns Res 35: 185–197. CrossRef Google Scholar\nMulvey J (1996). Generating scenario for the towers perrin investment system. Interfaces 26: 1–13. CrossRef Google Scholar\nMurphy F and Weiss HJ (1990). An approach to modeling electric utility capacity expansion planning. Naval Res Logist 37: 827–845. CrossRef Google Scholar\nMurphy F, Sen S and Soyster A (1987). Electric utility expansion planning in the presence of existing capacity: A nondifferentiable, convex programming approach. Comput Opns Res 14: 19–31. CrossRef Google Scholar\nNelder JA and Mead R (1965). A simplex method for function minimization. Comput J 7: 308–313. CrossRef Google Scholar\nNembhard H, Shi L and Park C (2000). Real option models for managing manufacturing system changes in the new economy. Eng Econom 45: 232–258. CrossRef Google Scholar\nOzturk A and Dale R (1985). Least squares estimation of the parameters of the generalized lambda distribution. Technometrics 27: 81–85. CrossRef Google Scholar\nPoojari CA and Varghese B (2007). Genetic algorithm based technique for solving chance constrained problems. Eur J Opl Res, doi:10.1016/j.ejor.2006.06.045. Google Scholar\nPowell M (1962). An iterative method for finding stationary values of a function of several variables. Comput J 5: 147–151. CrossRef Google Scholar\nRajagopalan S, Singh M and Morton T (1998). Capacity expansion and replacement in growing markets with uncertain technological breakthroughs. Mngt Sci 44: 12–30. CrossRef Google Scholar\nRamberg J and Schmeiser B (1974). An approximate method for generating asymmetric random variables. Commun ACM 17: 78–82. CrossRef Google Scholar\nRamberg J, Dudewicz E, Tadikamalla P and Mykytka E (1979). A probability distribution and its uses in fitting data. Technometrics 21: 201–214. Google Scholar\nRitchie B and Brindley C (2007). An emergent framework for supply chain UK management and performance measurment. J Opl Res Soc 58: 1398–1411. Google Scholar\nRobinson JB (1988). Loaded questions: New approaches to utility forecasting. Energy Pol 16: 58–68. CrossRef Google Scholar\nShapiro J (2000). Modeling the Supply Chain. Brooks/Cole-Thomson Learning: Pacific Grove, CA. Google Scholar\nStougie R (1987). Design and analysis of algorithms for stochastic integer programming. CWI Tract 37: 48–62. Google Scholar\nSwaminathan J (2000). Tool capacity planning for semiconductor fabrication facilities under demand uncertainty. Eur J Opl Res 120: 545–558. CrossRef Google Scholar\nVan Slyke RM and Wets RJ-B (1969). L-shaped linear programs with application to optimal control and stochastic programming. SIAM J Appl Math 17: 638–663. CrossRef Google Scholar\nVerter V and Dasci A (2002). The plant location and flexible technology acquisition problem. Eur J Opl Res 136: 366–382. CrossRef Google Scholar\nVidal C and Goetschalckx M (1997). Strategic production—distribution models: A critical review with emphasis on global supply chain models. Eur J Opl Res (98), 1–18. Google Scholar\nWagner J and Berman O (1995). Models for planning capacity expansion of convenience stores under uncertain demand and the value of information. Ann Opns Res 59: 19–44. CrossRef Google Scholar\nWets RJ-B (1974). Stochastic programs with fixed recourse: The equivalent deterministic program. SIAM Rev 16: 309–339. CrossRef Google Scholar\nCopyright information\nPoojari, C., Lucas, C. & Mitra, G. J Oper Res Soc (2008) 59: 2. https://doi.org/10.1057/palgrave.jors.2602381\nDOI https://doi.org/10.1057/palgrave.jors.2602381\nPublisher Name Palgrave Macmillan UK\nPrint ISSN 0160-5682\n""","0.24289322","""https://link.springer.com/article/10.1057%2Fpalgrave.jors.2602381""","[-0.472855,51.532848]"
"""Imperial_College_London""","""Environmental Health Perspectives – A Study of the Combined Effects of Physical Activity and Air Pollution on Mortality in Elderly Urban Residents: The Danish         Diet, Cancer, and Health Cohort""","""Research Volume 123 | 2015\nEnviron Health Perspect; DOI:10.1289/ehp.1408698\nA Study of the Combined Effects of Physical Activity and Air Pollution on Mortality in Elderly Urban Residents: The Danish         Diet, Cancer, and Health Cohort\nZorana Jovanovic Andersen,1,2 Audrey de Nazelle,3 Michelle Ann Mendez,4 Judith Garcia-Aymerich,5,6,7 Ole Hertel,8 Anne Tjønneland,2 Kim Overvad,9,10 Ole Raaschou-Nielsen,2 and Mark J. Nieuwenhuijsen5,6,7\nAuthor Affiliations open\n1Center for Epidemiology and Screening, Department of Public Health, University of Copenhagen, Copenhagen, Denmark; 2Danish Cancer Research Center, Danish Cancer Society, Copenhagen, Denmark; 3Centre for Environmental Policy, Imperial College London, London, United Kingdom; 4Department of Nutrition, University of North Carolina at Chapel Hill, Chapel Hill, North Carolina, USA; 5Center for Research in Environmental Epidemiology (CREAL), Barcelona, Spain; 6Universitat Pompeu Fabra, Barcelona, Spain; 7CIBER Epidemiología y Salud Pública (CIBERESP), Barcelona, Spain; 8Department of Environmental Science, Aarhus University, Roskilde, Denmark; 9Section for Epidemiology, Department of Public Health, Aarhus University, Aarhus, Denmark; 10Department of Cardiology, Aalborg University Hospital, Aalborg, Denmark\nSupplemental Material PDF (334 KB)\nIntroduction\nRegular physical activity has many health benefits including reduced all-cause mortality along with a reduced risk of cardiovascular disease, cancer, and diabetes ( Johnsen et al. 2013 ; Samitz et al. 2011 ; Schnohr et al. 2006 ; Woodcock et al. 2011 ). Exposure to air pollution may adversely affect human health by triggering or exacerbating respiratory and cardiovascular conditions, certain cancers, and possibly diabetes, leading to premature mortality ( Beelen et al. 2014a ; Hoek et al. 2013 ; Raaschou-Nielsen et al. 2012 , 2013 ).\nDeclining rates of physical activity ( Brownson et al. 2005 ) have given rise to population-level health initiatives including promotion of active transport in cities, encouraging a shift from car use to cycling and walking ( de Nazelle et al. 2011 ). These initiatives are also highly relevant as a solution to other urban challenges such as traffic congestion, air pollution, and greenhouse-gas emission problems in major cities. One of the major challenges to active transport initiatives and other efforts to promote exercise is the trade-off between the health benefits of increased physical activity and potential harms due to amplified exposure to air pollution during outdoor physical activity in urban areas ( Rojas-Rueda et al. 2011 , 2012 , 2013 ; Woodcock et al. 2014 ). Increased respiratory uptake and deposition of air pollutants in the lung due to higher minute ventilation during physical exercise may amplify harmful effects of air pollution, even in young and healthy individuals ( Giles and Koehle 2014 ; Strak et al. 2010 ). In controlled, real-life exposure studies, reduced lung function has been reported in association with walking on a busy street in London ( McCreanor et al. 2007 ; Zhang et al. 2009 ), running near heavy traffic close to major highway ( Rundell et al. 2008 ), cycling during rush hour on a heavy-traffic route ( Strak et al. 2010 ), or hiking on high air pollution days ( Korrick et al. 1998 ). Similarly, exposure to air pollution and exercise in a controlled setting was reported to alter markers of vascular impairment, arterial stiffness, and vascular reactivity and to reduce exercise performance ( Cutrufello et al. 2012 ; Lundbäck et al. 2009 ; Rundell and Caviston 2008 ; Shah et al. 2008 ) and alter immune function ( Chimenti et al. 2009 ). These studies documented evidence of acute adverse health effects of short-duration exposures to high levels of air pollution during exercise, which seem to be transient and reversible after exercise, at least in young healthy individuals.\nOne study examined whether exercise modified associations of acute (same-day) exposure to air pollution with mortality in Hong Kong, and reported that regular exercise may reduce premature death attributable to air pollution in elderly subjects ( Wong et al. 2007 ). A cohort study in children reported that participating in sports was associated with development of asthma in children residing in areas with high ozone, but not in areas with low ozone levels ( McConnell et al. 2002 ). These studies implied that there is a potential interaction between physical activity and air pollution, yet no cohort study in adults has explored whether long-term exposure to air pollution modifies beneficial health effects of physical activity on mortality.\nIn a large prospective urban cohort, we studied whether reductions in mortality linked to regular outdoor leisure-time and transport-related physical activity in terms of doing sports, cycling, gardening, and walking ( Johnsen et al. 2013 ) were modified by long-term exposure to high levels of air pollution at residence.\nMaterials and Methods\nDesign and study population. This study was based on the Danish Diet, Cancer, and Health cohort, described in detail elsewhere ( Tjønneland et al. 2007 ). In brief, the cohort consists of 57,053 men (48%) and women (52%) born in Denmark, 50–64 years of age, living in Copenhagen or Aarhus, with no previous cancer diagnosis at the time of enrollment (1993–1997). The participants completed an extensive questionnaire on diet, smoking, alcohol consumption, education, occupation, physical activity, history of diseases and medication, and other health-related items, and provided blood samples, blood pressure, and height and weight measurements at enrollment. Relevant Danish ethical committees and data protection agencies approved the study, and written informed consent was provided by all participants.\nMortality definition. Each cohort member was followed up in the Danish Register of Causes of Death ( Helweg-Larsen 2011 ) until 31 December 2009, using a unique personal identification number. On the basis of the underlying cause of death, we defined total mortality as all mortality from natural causes [International Classification of Diseases, 10th Revision (ICD-10) codes A00–R99], cancer mortality (C00–C97), cardiovascular mortality (I00–I99), respiratory mortality (J00–J99), and diabetes mortality (E10–E14). We extracted the date of emigration or disappearance and the addresses of all cohort members from the Central Population Registry ( Pedersen 2011 ) using their personal identification numbers.\nPhysical activity. Physical activity was assessed by a self-administered, interviewer-checked questionnaire in which leisure time and transport-related (e.g., to and from work, shopping) physical activity was reported as hours per week spent on sports, cycling, gardening, walking, housework (cleaning, shopping), and “do-it-yourself” activities (e.g., house repair). Data were collected separately for winter and summer of the previous year, and the two values were averaged, so that being active implies at least half an hour spent on a specific activity per week. The physical activity questions have been validated in two studies that found high correlation between self-reported physical activity estimates with the accelerometer measurements of total metabolic equivalent in 182 subjects ( Cust et al. 2008 ) and with combined heart rate and movement sensing measurements in 1,941 subjects ( InterAct Consortium et al. 2012 ). We focused in this study on sports, cycling, and gardening, which were previously associated with lower mortality in the same cohort ( Johnsen et al. 2013 ), and additionally walking at least half an hour per week, which is relevant as an outdoor physical activity pertinent to exposure to air pollution. A previous analysis of data from the cohort indicated that accounting for the amount of physical activity did not substantially alter associations with mortality when activity was dichotomized as any participation versus none ( Johnsen et al. 2013 ). Therefore, our main analyses focused on the estimated effect of participation (yes/no) in sports, cycling, gardening, and walking on mortality, whereas associations with the amount of cycling (categorized as does not cycle, 0.5–4 hr/week, or > 4 hr/week) were estimated in sensitivity analyses.\nAir pollution exposure. The outdoor concentration of nitrogen dioxide (NO2) was calculated at the residential addresses of each cohort member with the Danish AirGIS dispersion modeling system ( http://www.dmu.dk/en/air/models/airgis/ ). AirGIS is based on a geographical information system (GIS) and provides estimates of traffic-related air pollution with high temporal (1-year averages) and spatial (address-level) resolution. AirGIS is a validated model: High correlation was found between AirGIS estimated and measured NO2 values ( Raaschou-Nielsen et al. 2000 ), which has been used in a number of studies ( Andersen et al. 2012b , 2012c ; Raaschou-Nielsen et al. 2011 , 2012 , 2013 ) and is described in more detail in the Supplemental Material, “AirGIS Human Exposure Modelling System.” We used the mean of annual concentrations of NO2 at residential addresses of each cohort participant since 1971 until the end of follow-up as a proxy of average exposure to traffic-related air pollution during exercise. We defined an indicator variable of high versus moderate/low NO2 exposure separated by the 75th percentile of exposure range in the cohort (≥ vs. < 19.0 μg/m3).\nStatistical methods. We used Cox proportional hazards regression with age as the underlying time scale to simultaneously estimate associations between mortality and participation in sports, cycling, gardening, and walking, with separate models used to estimate associations of the four activities with total, cancer, cardiovascular, respiratory, and diabetes mortality, respectively. The follow-up started on the date of enrollment into the cohort (1993–1997) until the date of death, emigration, or 31 December 2009, whichever came first. We fit a crude model adjusted for age (underlying time scale), each of the four domains of physical activity, NO2, sex, and year of enrollment into cohort. In addition we fit a fully adjusted model that also included occupational physical activity (sedentary work, standing work, manual work, heavy manual work, or no occupation), smoking status (never, previous, current), lifetime smoking intensity (spline), smoking duration (years), environmental tobacco smoke (indicator of exposure to smoke in the home and/or at work for at least 4 hr/day), alcohol intake (indicator and spline for intensity, grams/day), educational level (< 8, 8–10, or > 10 years of education), fruit and vegetable intake (grams/day), fat intake (grams/day), occupational risk (indicator of a year or longer in an occupation with potential exposure to smoke, particles, fumes or chemicals: mining, rubber industry, tannery, chemical industry, wood-processing industry, metal processing, foundry, steel-rolling mill, shipyard, glass industry, graphics industry, building industry, truck, bus, or taxi driver, manufacture of asbestos or asbestos cement, asbestos insulation, cement article industry, china and pottery industry, painter, welder, hairdresser, auto mechanic), and mean income in the municipality of residence at enrollment (spline), We checked the proportional hazards assumption for all categorical variables by testing for a non-zero slope in a generalized linear regression of the scaled Schoenfeld residuals on functions of time [estat phtest command in Stata (StataCorp, College Station, TX, USA)]. We detected violation of proportional hazards assumption by marital status (single, married, divorced, widow/widower) and therefore stratified the model by this variable. Significance level < 0.05 was considered as statistically significant result in all analyses. An additional model was fit in which potentially mediating variables [body mass index (BMI; continuous, kilograms per meter squared), self-reported diagnosis or medication for hypertension and hypercholesterolemia] were added to the full model. Effect modification of associations between the four physical activities (yes/no) and mortality from different causes by exposure to NO2 (moderate/high or low) was evaluated by introducing an interaction term into the model, and tested using likelihood ratio tests. Additionally, for cycling, we tested whether there was an interaction between intensity of cycling (> 4 hr/week, 0.5–4 hr/week, does not cycle) and NO2 levels, to examine whether there is a dose–response relationship with different levels of NO2 [very high, ≥ 23.9 μg/m3 (90th percentile of exposure range); moderate, 15.1–23.9 μg/m3; low, < 15.1 μg/m3 (50th percentile of exposure range)]. We also conducted sensitivity analyses using 1-year mean of NO2 at the residential address at enrollment (1993–1997, corresponding to the time period for the self-reported physical activity data) as an alternative proxy of exposure to air pollution. Finally, we conducted two sensitivity analyses on total and respiratory mortality: a) with high exposure to air pollution defined as NO2 levels above the 90th percentile (23.9 μg/m3) of exposure range; and b) in a cohort subset consisting of 13,948 subjects living in inner Copenhagen (municipalities of Copenhagen and Frederiksberg)—the most urban part of the cohort, with the highest levels of cycling and air pollution (75th percentile of NO2 distribution = 24 μg/m3). Results are presented as hazard ratios (HRs) with 95% confidence intervals (CIs), estimated with stcox in Stata 11.2.\nResults\nOf 57,053 cohort members, 571 were excluded due to cancer diagnosis before baseline, 2 due to uncertain date of cancer diagnosis, 960 for whom an address history was not available for at least 80% of the time between 1971 and recruitment date in the Central Population Registry or their address at baseline could not be geocoded, 948 due to missing air pollution exposure (due to missing traffic counts or other air pollution model input data), and 2,511 due to missing information for a potential confounder or effect modifier, leaving 52,061 cohort members for the study. Excluded subjects did not differ significantly from the rest of the cohort with respect to age, physical activity levels, and education (results not shown).\nStudy participants were followed for a mean of 13 years, resulting in 677,760 person-years, during which 5,534 (10.6%) died. Of these, 2,864 (50.6%) died from cancer, 1,285 (23.2%) from cardiovascular disease, 354 (6.4%) from respiratory disease, and 122 (2.2%) from diabetes as the underlying cause of death.\nMean age at recruitment was 56.6 years ( Table 1 ). Most of the study subjects participated in physical activity: 54.3% participated in sports, 68.0% cycled, 73.5% gardened, and 93.0% walked. Participation in all physical activities was lower among those who died during follow-up than in the entire cohort ( Table 1 ), with the lowest participation among those who died from respiratory disease and diabetes ( Table 2 ). The mean concentration of NO2 at residence was 16.9 ± 5.2 μg/m3 for the cohort and 17.9 ± 5.7 μg/m3 for the subjects who died during follow-up ( Table 1 ).\nTable 1 – Characteristics of 52,061 participants in the Danish Diet, Cancer, and Health cohort.\nView larger image (TIF File)\nStatistically significant inverse associations were observed between participation in sports (vs. non participation) and all mortality ( Table 3 ), with fully adjusted HRs of 0.78 (95% CI: 0.73, 0.82) for total mortality, 0.82 (95% CI: 0.76, 0.89), 0.78 (95% CI: 0.69, 0.88), 0.60 (95% CI: 0.47, 0.77), and 0.34 (95% CI: 0.21, 0.55) for cancer, cardiovascular, respiratory, and diabetes mortality, respectively. Statistically significant inverse associations, somewhat weaker than those for participation in sports, were estimated for cycling (vs. not cycling) and gardening (vs. not gardening) with all but cancer mortality: 0.83 (95% CI: 0.78, 0.88) and 0.84 (95% CI: 0.79, 0.89) for total mortality, 0.78 (95% CI: 0.69, 0.88) and 0.82 (95% CI: 0.72, 0.93) for cardiovascular mortality, 0.62 (95% CI: 0.50, 0.77) and 0.63 (95% CI: 0.50, 0.79) for respiratory mortality, and 0.61 (95% CI: 0.42, 0.89) and 0.42 (95% CI: 0.28, 0.62) for diabetes mortality, respectively. Walking (vs. not walking) was statistically significantly inversely associated with respiratory mortality only (HR = 0.71; 95% CI: 0.51, 0.97). All estimates were robust (remained unchanged or were only slightly attenuated) to additional adjustment for BMI, blood pressure, and hypercholesterolemia (data not shown).\nTable 3 – Association [HR (95% CI)] of total and cause-specific mortality with participation (yes/no) in physical activities among 52,061 participants in the Diet, Cancer, and Health cohort.\nView larger image (TIF File)\nThere was no statistically significant effect modification of inverse associations between any of the four physical activities and mortality by NO2, except for gardening (p = 0.02), and borderline significant associations for cycling (p-value for interaction 0.09) on respiratory mortality ( Table 3 ). The inverse associations of cycling and gardening with respiratory mortality were stronger among subjects with moderate/low NO2 exposure (HR = 0.55; 95% CI: 0.42, 0.72 and HR = 0.55; 95% CI: 0.41, 0.73, respectively) than among those with high NO2 exposure (HR = 0.77; 95% CI: 0.54, 1.11 and HR = 0.81; 95% CI: 0.55, 1.18, respectively). Comparable and slightly attenuated effect estimates were observed for all physical activities with a 1-year mean level of NO2 at the cohort baseline (data not shown). There was no significant interaction between cycling intensity and NO2 when considering the dose–response relationship between increasing levels of cycling intensity and NO2 levels, categorized as low, moderate, or high (see Supplemental Material, Table S1). Furthermore, sensitivity analyses showed no effect modification of associations between total and respiratory mortality with any physical activity when exposure to NO2 was dichotomized at the 90th percentile (23.9 μg/m3) (see Supplemental Material, Table S2), or in the subset of cohort living in inner Copenhagen (see Supplemental Material, Table S3).\nDiscussion\nEstimates suggesting that leisure-time participation in sports, cycling, and gardening was associated with lower mortality were not significantly modified by exposure to NO2 in an urban setting, for total, cancer, cardiovascular, and diabetes mortality. Estimated benefits of cycling and gardening on respiratory mortality were moderately attenuated among those with high levels of NO2 exposure compared with moderate or low exposure.\nOur finding of significant reductions in total natural and cause-specific mortality related to physical activity confirm existing evidence ( Samitz et al. 2011 ; Woodcock et al. 2011 ) including Danish data ( Johnsen et al. 2013 ; Schnohr et al. 2006 ). Estimated benefits of cycling, including cycling to and from work and shopping, were weaker than estimated effects of participating in sports, but were significant, and comparable to the limited evidence. Benefits of cycling estimated in the present analysis were slightly weaker than those earlier reported for cycling to work on all-cause mortality in another cohort in Denmark (relative risk = 0.72; 95% CI: 0.57, 0.91) ( Andersen et al. 2000 ) and comparable to cycling to work in Chinese women on overall mortality [HR = 0.79; 95% CI: 0.61, 1.01 and HR = 0.66; 95% CI: 0.40, 1.07, for 0.1–3.4 and ≥ 3.5 MET (metabolic equivalent)-hr/day, respectively, compared with no cycling] ( Matthews et al. 2007 ). Estimated inverse effects of gardening on mortality were noteworthy, because they are similar in magnitude to those of cycling, whereas weak inverse associations were detected between walking and respiratory mortality only.\nAdverse effects of chronic exposure to air pollution on total natural and cardiovascular mortality are well supported ( Hoek et al. 2013 ), and positive associations were also evident in this Danish cohort, where air pollution levels are relatively low ( Beelen et al. 2014a , 2014b ; Raaschou-Nielsen et al. 2012 , 2013 ). Long-term exposure to air pollution was also associated with diabetes mortality in this cohort ( Raaschou-Nielsen et al. 2013 ), but not with respiratory mortality, in agreement with the recent meta-analyses of 16 European cohorts, including a subset of the cohort in the present analyses ( Dimakopoulou et al. 2014 ). On the other hand, associations of air pollution with incidence of chronic respiratory disease—asthma and COPD (chronic obstructive pulmonary disease)—have been also found in this cohort ( Andersen et al. 2011 , 2012a ).\nOur results—that long-term benefits of physical activity on all major types of mortality were not moderated by exposure to high levels of NO2—are novel. This may imply that acute stress and damage to the cardiovascular system induced by short-term exposure to air pollution during exercise, in terms of vascular impairment, arterial stiffness, and reduced blood flow, as shown in earlier studies ( Lundbäck et al. 2009 ; Rundell and Caviston 2008 ; Shah et al. 2008 ), seem to be transient and reversible and do not abate long-term benefits of physical activity on mortality. Our results may furthermore be explained by the short duration of the physical activities, with mean of 2–3 hr/week for most activities ( Table 1 ); this implies that extra inhaled dose of air pollution during physical activity, which is a function of increased inhalation and duration, is only a small fraction of total inhaled dose of air pollution ( Rojas-Rueda et al. 2011 ), and is therefore not sufficient to increase the risk of premature mortality. Our results are furthermore in line with a study finding significantly lower levels of physical activity on days with poor air quality among respiratory disease patients, but not in cardiovascular patients, who do not seem immediately enough bothered by air pollution to change their outdoor physical activity habits ( Balluz et al. 2008 ; Wells et al. 2012 ). Our study thus may imply that effects of long-term exposure to NO2 and physical activity on overall and cardiovascular mortality are independent of each other, with benefits of outdoor physical activity not being reduced by exposure to NO2.\nInverse associations of cycling and gardening with respiratory mortality were closer to the null among subjects with high NO2 exposure (0.77; 95% CI: 0.54, 1.11 and 0.81; 95% CI: 0.55, 1.18, respectively) than among those with moderate/low NO2 (0.55; 95% CI: 0.42, 0.72 and 0.55; 95% CI: 0.41, 0.73, respectively). Only one similar study exists in a cohort of children, which, consistent with our findings, showed asthma development only in children living in areas with high ozone concentrations, and not in those living in areas with low ozone ( McConnell et al. 2002 ). It is plausible that amplification of lung damage due to greater inhaled doses of air pollution through physical activity in urban areas with high air pollution may moderate the benefits of physical activity, which improves some of the same physiological mechanisms. Earlier studies have shown that hikers with a history of asthma had significantly greater air pollution–related acute reductions in pulmonary functions than did asthma-free hikers ( Korrick et al. 1998 ), and that subjects with moderate asthma had greater acute lung function reductions after walking on a busy street in London than did those with mild asthma ( McCreanor et al. 2007 ; Zhang et al. 2009 ). However, reduced physical activity was observed on days with poor air quality among respiratory disease patients ( Balluz et al. 2008 ; Wells et al. 2012 ), but not among cardiovascular disease patients, as noted earlier. This implies an alternative explanation to our findings that reduced benefit from physical activity in subjects residing in areas with high air pollution may be attributable to abstaining from physical activity on days with high air pollution, and not from enhanced negative effects of greater exposure to air pollution during physical activity. Our findings were weakened by the fact that there was no dose–response relationship in reductions of respiratory mortality related to cycling by number of hours spent cycling and by increasing levels of air pollution (see Supplemental Material, Table S1). Although numbers are small in the interaction analyses, the lack of effect of duration of cycling may imply that the cyclists themselves differ from the noncyclists, and that in general, the effects of air pollution are minimal in healthy people. Finally, significant interactions of cycling and gardening with air pollution observed for respiratory mortality ( Table 3 ) could not be reproduced when considering levels of NO2 > 24.9 μg/m3 (the 90th percentile) as high exposure, or when considering the subset of subjects living in inner Copenhagen, where levels of air pollution and number of people cycling are at the highest in Denmark (see Supplemental Material, Tables S2 and S3). However, these analyses need to be interpreted with caution because in both sensitivity analyses, exposure levels were also increased in the “low” exposure category, possibly obscuring differences in associations between the lower and higher levels of exposure.\nIn summary, our findings suggest that outdoor physical activity in areas with high air pollution may moderate, but not reverse, the benefits of physical activity on respiratory mortality: Adverse effects of the additional pollutants inhaled over time do not outweigh the benefits of physical activity. Our results, however, need to be reproduced, because of both the small number of people dying from respiratory causes and the sensitivity of these results to the definition of NO2 and subcohort. Furthermore, because of the relatively small number of people dying from respiratory causes (6% in this cohort), and assuming that our results are true, reductions in health benefits related to physical activity in areas with high air pollution are rather marginal.\nStrengths of our study include a large prospective cohort, with well-defined and validated information on physical activity and air pollution exposure, both of which have been linked to mortality ( Johnsen et al. 2013 ; Raaschou-Nielsen et al. 2012 , 2013 ). We furthermore benefited from the state-of-the art information on individual exposure to NO2 with high spatial (address-specific) and temporal (annual mean) resolution, assessed over 35 years. Another strength of this cohort is the very high prevalence of cycling (68%), both leisure and utilitarian (e.g., to work, shopping); this provided the data for evaluation of an interaction of air pollution with this type of physical activity, in contrast to existing studies on cycling to work ( Andersen et al. 2000 ; Matthews et al. 2007 ; Rojas-Rueda et al. 2011 , 2012 ). Furthermore, this is the first cohort study to evaluate individual-level benefits of physical activity in an urban cohort while also considering individual exposure to air pollution. A study of short-term effects of air pollution on mortality in Hong Kong, which has several-fold higher levels of air pollution than in Copenhagen, found that those who exercised regularly had reduced susceptibility to acute effects of air pollution and lower mortality than those who did not exercise ( Wong et al. 2007 ). Our study provides a novel approach in contrast to existing health impact assessment studies. Our study estimated benefits versus risks of increased physical activity, typically by evaluating active travel policies targeted to shift commuters from car use to cycling, on a population level, based on derivation of risk estimates from different studies and hypothetical scenarios ( Andersen et al. 2000 ; de Hartog et al. 2010 ; Rojas-Rueda et al. 2011 , 2012 , 2013 ).\nA weakness of our study is the use of NO2 levels at residence as a proxy of average air pollution levels encountered during physical activity. This assumption works well for gardening, which typically occurs at the residence (the exact location of air pollution modeling) but less well for cycling and walking. Given that this cohort consists of older subjects 50–65 years of age at baseline, many of whom retired before study recruitment or during study follow-up, it is reasonable to assume that most of their time walking and cycling had taken place in close proximity to their residence, which may be well represented by air pollution levels at residence. The higher exposure misclassification is expected for cycling than for gardening. Cycling levels were the same for subjects residing in areas with low/moderate and high air pollution levels, 68%. Gardening was more common in subjects living in areas with low/moderate air pollution (79%) than in those living in areas with high air pollution (58%), because rates of house ownership are higher in the suburbs than in the inner city, where pollution is highest. Furthermore, we did not have information on cycling, walking, and exercising habits of cohort participants, and possible behavioral adjustment by those living in areas of high air pollution levels to avoid the most polluted areas, which may bias results. Similarly, participating in sports is a poor proxy of outdoor activity because we do not have information on the type of sports activity or whether it took place outdoors (running), or indoors (e.g., gym, badminton, swimming). Thus, lack of findings of interaction with air pollution and participation in sports may be attributable to exposure misclassification. Many cohort members retired during the study follow-up, implying the possibility of misclassification of exposure over time, if retirement led to considerable changes in cycling after enrollment. Most biking trips (over 65%) in Denmark are undertaken for leisure activities, shopping, and doing errands, with a minority for transport to and back from work ( Danish Technical University 2013 ). Cycling decreases with age in Denmark, but only marginally, by about 10–15% from 50–59 to 60–69 years, due to retirement/decrease in share of cycling trips to work ( Vithen 2013 ).\nAnother weakness is a lack of data on particulate matter (PM), which was available for only half of the cohort participants living in Copenhagen ( Beelen et al. 2014a ) and only for 2010, and was therefore not used here. However, NO2 and nitrogen oxides were found to correlate strongly with PM in Denmark, with Spearman correlation coefficient of 0.70 for PM10 (PM with diameter ≤ 10 μm) and 0.93 for ultrafine fraction of PM ( Hertel et al. 2001 ; Ketzel et al. 2003 ), implying that similar results for PM would be expected. Furthermore, we have shown earlier that PM10 originates largely from long-range transport in Denmark, resulting in smaller spatial variation than ultrafine PM and NO2 ( Andersen et al. 2007 ), which originate mainly from traffic. Traffic is the main focus of this study, reflecting air pollution exposures during exercise or commute. Still, NO2 serves as a proxy for all traffic-related pollutants, including elemental carbon, nitric oxide, carbon monoxide, ultrafine PM, noise, and possibly road dust.\nAnother weakness is that DCH cohort participants are likely healthier than the general Danish population, because they are better educated and had higher income than nonparticipants ( Tjønneland et al. 2007 ). Finally, air pollution levels are relatively low in Copenhagen and Aarhus, and these findings need to be reproduced in sites with higher air pollution levels.\nOur results are in agreement with a growing number of health impact assessment studies that evaluate the net effects of an increase in cycling at the population level, typically as a shift from car use, and conclude that health benefits due to increased physical activity levels generally outweigh the risks related to increase inhaled air pollution doses during cycling ( de Hartog et al. 2010 ; Rojas-Rueda et al. 2011 , 2012 ; Woodcock et al. 2014 ).\nConclusions\nPhysical activity plays a key role in improving the physiologic mechanisms and health outcomes that exposure to air pollution may exacerbate. This presents a challenge in understanding and balancing the beneficial effects of physical activity in the urban environment with the detrimental effects of air pollution on human health. Our findings suggest that beneficial effects of physical activity on mortality in an urban area with relatively low levels of air pollution are not moderated in subjects residing in areas with the highest levels of air pollution. Estimated benefits of cycling and gardening on respiratory mortality were marginally reduced, but not annulled, for those living in areas with high NO2 levels, but these novel results need confirmation. Overall, the long-term benefits of physical activity in terms of reduced mortality outweigh the risk associated with enhanced exposure to air pollution during physical activity.\nReferences\nAndersen LB, Schnohr P, Schroll M, Hein HO. 2000. All-cause mortality associated with physical activity during leisure time, work, sports, and cycling to work. Arch Intern Med 160:1621–1628.\nAndersen ZJ, Bønnelykke K, Hvidberg M, Jensen SS, Ketzel M, Loft S, et al. 2012a. Long-term exposure to air pollution and asthma hospitalisations in older adults: a cohort study. Thorax 67:6–11.\nAndersen ZJ, Hvidberg M, Jensen SS, Ketzel M, Loft S, Sørensen M, et al. 2011. Chronic obstructive pulmonary disease and long-term exposure to traffic-related air pollution: a cohort study. Am J Respir Crit Care Med 183:455–461.\nAndersen ZJ, Kristiansen LC, Andersen KK, Olsen TS, Hvidberg M, Jensen SS, et al. 2012b. Stroke and long-term exposure to outdoor air pollution from nitrogen dioxide: a cohort study. Stroke 43:320–325.\nAndersen ZJ, Raaschou-Nielsen O, Ketzel M, Jensen SS, Hvidberg M, Loft S, et al. 2012c. Diabetes incidence and long-term exposure to air pollution: a cohort study. Diabetes Care 35:92–98.\nAndersen ZJ, Wahlin P, Raaschou-Nielsen O, Scheike T, Loft S. 2007. Ambient particle source apportionment and daily hospital admissions among children and elderly in Copenhagen. J Expo Sci Environ Epidemiol 17:625–636.\nBalluz LS, Okoro CA, Mokdad A. 2008. Association between selected unhealthy lifestyle factors, body mass index, and chronic health conditions among individuals 50 years of age or older, by race/ethnicity. Ethn Dis 18:450–457.\nBeelen R, Raaschou-Nielsen O, Stafoggia M, Andersen ZJ, Weinmayr G, Hoffmann B, et al. 2014a. Effects of long-term exposure to air pollution on natural-cause mortality: an analysis of 22 European cohorts within the multicentre ESCAPE project. Lancet 383:785–795.\nBeelen R, Stafoggia M, Raaschou-Nielsen O, Andersen ZJ, Xun WW, Katsouyanni Ketal. 2014b. Long-term exposure to air pollution and cardiovascular mortality: an analysis of 22 European cohorts. Epidemiology 25:368–378.\nBrownson RC, Boehmer TK, Luke DA. 2005. Declining rates of physical activity in the United States: what are the contributors? Annu Rev Public Health 26:421–443.\nChimenti L, Morici G, Paterno A, Bonanno A, Vultaggio M, Bellia V, et al. 2009. Environmental conditions, air pollutants, and airway cells in runners: a longitudinal field study. J Sports Sci 27:925–935.\nCust AE, Smith BJ, Chau J, van der Ploeg HP, Friedenreich CM, Armstrong BK, et al. 2008. Validity and repeatability of the EPIC physical activity questionnaire: a validation study using accelerometers as an objective measure. Int J Behav Nutr Phys Act 5:33; doi: 10.1186/1479-5868-5-33 .\nCutrufello PT, Smoliga JM, Rundell KW. 2012. Small things make a big difference: particulate matter and exercise. Sports Med 42:1041–1058.\nDanish Technical University. 2013. Faktaark om cykeltrafik i Danmark 2013 [in Danish]. Available: http://www.modelcenter.transport.www6.si​tecore.dtu.dk/Transportvaneundersoegelse​n/TU-udgivelser/Faktaark-om-cykeltrafik-​i-Danmark-2013 [accessed 20 January 2015].\nde Hartog J, Boogaard H, Nijland H, Hoek G. 2010. Do the health benefits of cycling outweigh the risks? Environ Health Perspect 118:1109–1116; doi: 10.1289/ehp.0901747 .\nde Nazelle A, Nieuwenhuijsen MJ, Antó JM, Brauer M, Briggs D, Braun-Fahrlander C, et al. 2011. Improving health through policies that promote active travel: a review of evidence to support integrated health impact assessment. Environ Int 37:766–777.\nDimakopoulou K, Samoli E, Beelen R, Stafoggia M, Jovanovic AZ, Hoffmann B, et al. 2014. Air pollution and non-malignant respiratory mortality in 16 cohorts within the ESCAPE project. Am J Respir Crit Care Med 189:684–696.\nGiles LV, Koehle MS. 2014. The health effects of exercising in air pollution. Sports Med 44:223–249.\nHelweg-Larsen K. 2011. The Danish register of causes of death. Scand J Public Health 39(7 suppl):26–29.\nHertel O, Jensen SS, Andersen HV, Palmgren F, Wåhlin P, Skov H, et al. 2001. Human exposure to traffic pollution. Experience from Danish studies. Pure Appl Chem 73:137–145.\nHoek G, Krishnan RM, Beelen R, Peters A, Ostro B, Brunekreef B, et al. 2013. Long-term air pollution exposure and cardio- respiratory mortality: a review. Environ Health 12:43; doi: 10.1186/1476-069X-12-43 .\nInterAct Consortium, Peters T, Brage S, Westgate K, Franks PW, Gradmark A, et al. 2012. Validity of a short questionnaire to assess physical activity in 10 European countries. Eur J Epidemiol 27:15–25.\nJohnsen NF, Ekblond A, Thomsen BL, Overvad K, Tjønneland A. 2013. Leisure time physical activity and mortality. Epidemiology 24:717–725.\nKetzel M, Wahlin P, Berkowicz R, Palmgren F. 2003. Particle and trace gas emission factors under urban driving conditions in Copenhagen based on street and roof level observations. Atmos Environ 37:2735–2749.\nKorrick SA, Neas LM, Dockery DW, Gold DR, Allen GA, Hill LB, et al. 1998. Effects of ozone and other pollutants on the pulmonary function of adult hikers. Environ Health Perspect 106:93–99.\nLundbäck M, Mills NL, Lucking A, Barath S, Donaldson K, Newby DE, et al. 2009. Experimental exposure to diesel exhaust increases arterial stiffness in man. Part Fibre Toxicol 6:7; doi: 10.1186/1743-8977-6-7 .\nMatthews CE, Jurj AL, Shu XO, Li HL, Yang G, Li Q, et al. 2007. Influence of exercise, walking, cycling, and overall nonexercise physical activity on mortality in Chinese women. Am J Epidemiol 165:1343–1350.\nMcConnell R, Berhane K, Gilliland F, London SJ, Islam T, Gauderman WJ, et al. 2002. Asthma in exercising children exposed to ozone: a cohort study. Lancet 359:386–391.\nMcCreanor J, Cullinan P, Nieuwenhuijsen MJ, Stewart-Evans J, Malliarou E, Jarup L, et al. 2007. Respiratory effects of exposure to diesel traffic in persons with asthma. N Engl J Med 357:2348–2358.\nPedersen CB. 2011. The Danish Civil Registration System. Scand J Public Health 39(7 suppl):22–25.\nRaaschou-Nielsen O, Andersen ZJ, Hvidberg M, Jensen SS, Ketzel M, Sørensen M, et al. 2011. Air pollution from traffic and cancer incidence: a Danish cohort study. Environ Health 10:67; doi: 10.1186/1476-069X-10-67 .\nRaaschou-Nielsen O, Andersen ZJ, Jensen SS, Ketzel M, Sørensen M, Hansen J, et al. 2012. Traffic air pollution and mortality from cardiovascular disease and all causes: a Danish cohort study. Environ Health 11:60; doi: 10.1186/1476-069X-11-60 .\nRaaschou-Nielsen O, Hertel O, Vignati E, Berkowicz R, Jensen SS, Larsen VB, et al. 2000. An air pollution model for use in epidemiological studies: evaluation with measured levels of nitrogen dioxide and benzene. J Expo Anal Environ Epidemiol 10:4–14.\nRaaschou-Nielsen O, Sørensen M, Ketzel M, Hertel O, Loft S, Tjønneland A, et al. 2013. Long-term exposure to traffic-related air pollution and diabetes-associated mortality: a cohort study. Diabetologia 56:36–46.\nRojas-Rueda D, de Nazelle A, Tainio M, Nieuwenhuijsen MJ. 2011. The health risks and benefits of cycling in urban environments compared with car use: health impact assessment study. BMJ 343:d4521; doi: 10.1136/bmj.d4521 .\nRojas-Rueda D, de Nazelle A, Teixidó O, Nieuwenhuijsen MJ. 2012. Replacing car trips by increasing bike and public transport in the greater Barcelona metropolitan area: a health impact assessment study. Environ Int 49:100–109.\nRojas-Rueda D, de Nazelle A, Teixidó O, Nieuwenhuijsen MJ. 2013. Health impact assessment of increasing public transport and cycling use in Barcelona: a morbidity and burden of disease approach. Prev Med 57:573–579.\nRundell KW, Caviston R. 2008. Ultrafine and fine particulate matter inhalation decreases exercise performance in healthy subjects. J Strength Cond Res 22:2–5.\nRundell KW, Slee JB, Caviston R, Hollenbach AM. 2008. Decreased lung function after inhalation of ultrafine and fine particulate matter during exercise is related to decreased total nitrate in exhaled breath condensate. Inhal Toxicol 20:1–9.\nSamitz G, Egger M, Zwahlen M. 2011. Domains of physical activity and all-cause mortality: systematic review and dose–response meta-analysis of cohort studies. Int J Epidemiol 40:1382–1400.\nSchnohr P, Lange P, Scharling H, Jensen JS. 2006. Long-term physical activity in leisure time and mortality from coronary heart disease, stroke, respiratory diseases, and cancer. The Copenhagen City Heart Study. Eur J Cardiovasc Prev Rehabil 13:173–179.\nShah AP, Pietropaoli AP, Frasier LM, Speers DM, Chalupa DC, Delehanty JM, et al. 2008. Effect of inhaled carbon ultrafine particles on reactive hyperemia in healthy human subjects. Environ Health Perspect 116:375–380; doi: 10.1289/ehp.10323 .\nStrak M, Boogaard H, Meliefste K, Oldenwening M, Zuurbier M, Brunekreef B, et al. 2010. Respiratory health effects of ultrafine and fine particle exposure in cyclists. Occup Environ Med 67:118–124.\nTjønneland A, Olsen A, Boll K, Stripp C, Christensen J, Engholm G, et al. 2007. Study design, exposure variables, and socioeconomic determinants of participation in Diet, Cancer and Health: a population-based prospective cohort study of 57,053 men and women in Denmark. Scand J Public Health 35:432–441.\nVithen C. 2013. Cykling i Danmark—hvor står vi? Tal og statistik [in Danish]. Vejdirektoratet. Available: http://www.trm.dk/~/media/Files/Publicat​ion/2013/Cykelstrategi%202013/Charlotte%​20Vithen.pdf [accessed 20 January 2015].\nWells EM, Dearborn DG, Jackson LW. 2012. Activity change in response to bad air quality, National Health and Nutrition Examination Survey, 2007–2010. PLoS One 7:e50526; doi: 10.1371/journal.pone.0050526 .\nWong CM, Ou CQ, Thach TQ, Chau YK, Chan KP, Ho SY, et al. 2007. Does regular exercise protect against air pollution-associated mortality? Prev Med 44:386–392.\nWoodcock J, Franco OH, Orsini N, Roberts I. 2011. Non-vigorous physical activity and all-cause mortality: systematic review and meta-analysis of cohort studies. Int J Epidemiol 40:121–138.\nWoodcock J, Tainio M, Cheshire J, O’Brien O, Goodman A. 2014. Health effects of the London bicycle sharing system: health impact modelling study. BMJ 348:g425; doi: 10.1136/bmj.g425 .\nZhang JJ, McCreanor JE, Cullinan P, Chung KF, Ohman-Strickland P, Han IK, et al. 2009. Health effects of real-world exposure to diesel exhaust in persons with asthma. Res Rep Health Eff Inst 138:5–109.\nHighlighted Sections\n""","0.16335776","""https://ehp.niehs.nih.gov/1408698/""","[-0.178219,51.500505]"
"""Brunel_University_London""","""Explicit dynamic formulation to demonstrate compliance against quasi-static aircraft seat certification loads (CS25.561) – Part I: influence of time and mass scalingProceedings of the Institution of Mechanical Engineers, Part G: Journal of Aerospace Engineering - Omkar Gulavani, Kevin Hughes, Rade Vignjevic, 2014""","""Official webpage for EASA (European Aviation Safety Agency), https://www.easa.europa.eu/what-we-do.php (accessed 18 September 2013). Google Scholar\n2.\nEASA CS-25. European Aviation Safety Agency Certification Specifications and Acceptable Means of Compliance for Large Aeroplanes CS-25. Amendment 12, 13 July 2012, http://www.easa.europa.eu/agency-measures/docs/certification-specifications/CS-25/CS-25%20Amdt%2012.pdf (2012, accessed 18 September 2013). Google Scholar\n3.\nARP5526 Revision C. Aircraft Seat Design Guidance and Clarifications, 24 May 2011. Google Scholar\n4.\nAdvisory Circular AC 25.562-1B. Dynamic evaluation of seat restraint systems and occupant protection on transport airplanes by federal aviation administration, 10 January 2006, https://www.faa.gov/regulations_policies/advisory_circulars/index.cfm/go/document.information/documentID/22657 (2006, accessed 18 September 2013). Google Scholar\n5.\nAbaqus 6.9.3 Online documentation, http://abaqus.civil.uwa.edu.au:2080/v6.9/books/usb/default.htm (2009, accessed 6 April 2009). Google Scholar\n6.\nLSDYNA. Keyword’s user manual. Volume I, version 971. May 2007. Google Scholar\n7.\nMattiasson, K, Bernspång, L, Samuelsson, A. Solution of quasi-static, force-driven problems by means of a dynamic-explicit approach and an adaptive loading procedure. Eng Comput 1996; 13(2--4): 172–189. Google Scholar , Crossref\n8.\nReddy, R, Reddy, M, Prasad, R. A review on finite element simulations in metal forming. Int J Mod Eng Res 2012; 2(4): 2326–2330. Google Scholar\n9.\nXu F, Chowdhury P, Sambamoorthy B, et al. Correlation of the federal motor vehicle safety standard 225 (FMVSS225) requirement of an automotive seat system using LS-DYNA. In: 7th international LS-DYNA users conference, Dearborn, MI, USA, 19--21 May 2002, pp.9--1--9--8. Google Scholar\n10.\nKlaus-Jurgen Bathe. Finite element procedures in engineering analysis, Prentice-Hall civil engineering and engineering mechanics series. Englewood Cliffs, NJ: Prentice-Hall, 1982. Google Scholar\n11.\nCook, RD, Malkus, DS, Plesha, ME. Concepts and applications of finite element analysis, 4th ed. New York: John Wiley and Sons, 2001. Google Scholar\n12.\nPatwardhan V, Halder T, Xu F, et al. Simulation and validation of FMVSS 207/210 using LS-DYNA. In: 7th international LS-DYNA users conference, Dearborn, MI, USA, 19--21 May 2002, pp.9--9--9--16. Google Scholar\n13.\nPrior, AM. Applications of implicit and explicit finite element techniques to metal forming. J Mater Process Technol 1994; 45(1--4): 649–656. Google Scholar , Crossref\nVol 228, Issue 11, 2014\nDesign novelties of seat under development\nReview of static certification regulations\nEvolution of methodology to overcome explicit challenges\nApplication of methodology: a case study ‘Downward 8.6g’\nValidation of FE methodology\n""","0.368353","""http://journals.sagepub.com/doi/10.1177/0954410013506333""","[-0.472855,51.532848]"
"""UCL""","""Iris Publication""","""Log In\nPlease report any queries concerning the funding data grouped in the sections named \""Externally Awarded\"" or \""Internally Disbursed\"" (shown on the profile page) to           your Research Finance Administrator. Your can find your Research Finance Administrator at https://www.ucl.ac.uk/finance/research/rs-contacts.php by entering your department\nPlease report any queries concerning the student data shown on the profile page to:\nGlobal vehicle emissions: Commercial Opportunities from Emissions Regulation for Vehicle Manufacturers and Component Suppliers\nPublication Type:\n""","1.1911471","""http://iris.ucl.ac.uk/iris/publication/1064143/1""",
"""City_University_London""","""Organization Science | INFORMS""","""Organization Science\nDriving Performance via Exploration in Changing Environments: Evidence from Formula One Racing\nArticle Tools\n(full-text views and PDF downloads over the previous year)\nDownloaded 1,151 times\nDepartment of Business and Management, LUISS University, 00197 Rome, Italy\nDepartment of Business and Management, LUISS University, 00197 Rome, Italy\nCass Business School, City University London, London EC1Y 8TZ, United Kingdom\nCass Business School, City University London, London EC1Y 8TZ, United Kingdom\nW. P. Carey School of Business, Arizona State University, Tempe, Arizona 85287\nW. P. Carey School of Business, Arizona State University, Tempe, Arizona 85287\nFisher School of Business, The Ohio State University, Columbus, Ohio 43210\nFisher School of Business, The Ohio State University, Columbus, Ohio 43210\nPermalink: https://doi.org/10.1287/orsc.2015.0984\nPublished Online: May 25, 2015\nThis work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License. You are free to download this work and share with others, but cannot change in any way or use commercially without permission, and you must attribute this work as “Organization Science. Copyright 2015 INFORMS. http://dx.doi.org/10.1287/orsc.2015.0984 , used under a Creative Commons Attribution License: http://creativecommons.org/licenses/by-nc-nd/4.0/ .”\nPage Range:         1079 - 1100\nAbstract\nSection:\nUntil recently, scholars have customarily lumped multiple dimensions of environmental change into single constructs, and usually ascertained that the more the context changes, the more value firms derive from higher levels of exploration. In sync with more recent studies focusing on specific dimensions of change, in this paper we borrow theoretical elements from systems theory to examine the possibility that the reward to developing innovative product components may itself be eroded by implicit and yet burgeoning costs to fit the new component technology into existing architectures, thereby dampening system performance. Specifically, we theoretically assess how varying magnitudes of industry regulatory changes affect the optimum level of firm exploration, and propose—counterintuitively vis-à-vis past literature—that the more radical (i.e., competence destroying), as opposed to incremental (i.e., competence enhancing), these changes are, the more the optimum intensity of firm exploration recedes. Based on quantitative as well as qualitative empirical analyses from the Formula One racing industry, we precisely trace the observed performance outcomes back to the underlying logic of our theory, stressing that impaired capabilities to integrate the new component in the architecture redesign and time-based cognitive limitations both operate to inhibit the otherwise positive relationship between firm exploration and performance. In the end, we offer new insights to theory and practice.\nIntroduction\nSection:\nFirms’ responses to environmental changes in terms of exploration efforts are an important but still open issue in the study of strategy and organizations ( Gupta et al. 2006 , March 1991 , Posen and Levinthal 2012 , Sørensen and Stuart 2000 , Tushman and Romanelli 1985 ). Although enhancing their exploration efforts under conditions of environmental change can allow firms to adjust to new environments more effectively (e.g., Blundell et al. 1999 ; Teece et al. 1997 ; Tushman and Anderson 1986, p. 446 ), it can also entail increased costs, risks, and challenges of its own that may reduce or even outweigh the benefits it brings. As an example of a typical managerial dilemma, should an industrial equipment manufacturer respond to the so called “3D printing revolution” by engineering a 3D printer system based on the most consolidated technology available, or by developing a more advanced prototype that is new to the industry? In this paper, we investigate this aspect by examining levels of optimal exploration under different magnitudes of environmental change.\nExtant literature on the subject of organizational responses to environmental change has provided mixed results and a multitude of perspectives. For example, earlier studies suggest that enhanced exploration in changing environments may yield neutral (e.g., Kim and Rhee 2009 ), net positive (e.g., Aghion et al. 2005 , Blundell et al. 1999 , Geroski 1995 , Jansen et al. 2006 ), or even negative (e.g., Posen and Levinthal 2012 ) effects. Tushman and Anderson ( 1986, p. 445 ) argue that as environmental changes develop from incremental to radical, firms can no longer rely on improving efficiencies by refining what they already do, but rather may have more to gain from exploring new competencies and expertise. On the other hand, Posen and Levinthal ( 2012 ) warn that this may not always be the case. They suggest instead that as environments change ever more frequently, the best value a firm can derive from exploration can actually recede, because novel know-how either fails to materialize or decays much more quickly in concert with the more frequent changes in the environment.\nWe develop such arguments further in this paper. Specifically, we consider the relationship between the magnitude of environmental change and the optimal exploration by the firm. Our goal is to identify the best firm strategy, under the relatively steady periods with recurrent changes of minor degree as well as the sporadic radical jolts of radical magnitude. The variation in such magnitude of environmental change is an important issue and is a common occurrence, for example, during political change, when regulatory agencies implement new industrial policies designed to shape new competitive dynamics ( Stewart 2011 ), or when the industry is subject to more major technological shifts, which tend to be less frequent than more incremental changes ( Klepper 1997 ). Therefore, whether the value of exploration increases in this environment—as has broadly been suggested in prior literature—or decreases, due to other as yet ill understood mechanisms, remains an open question.\nIn contrast to earlier literature, we focus exclusively on a specific organizational mechanism and theorize that when environmental conditions undergo shifts of increasing magnitude, greater exploration is likely to constitute a suboptimal strategy. We argue that as the magnitude of environmental changes increases from incremental toward radical ( Henderson and Clark 1990 ), greater exploration causes more challenges in the management of interdependencies across parts of complex systems ( Simon 1962 ) and stretches the organization’s integration capabilities ( Brusoni et al. 2001 , Prencipe 1997 ). For this reason, under radical environmental changes, increasing exploration rapidly amplifies the costs of reintegrating and managing the architecture of the very system that embeds the innovation, and in the process outweighs the conventionally anticipated benefits. Alternatively, when environmental changes are smaller, more aggressive exploration generates superior performance because the integration costs of complex systems are more likely to be manageable, and thus the net gains of exploration positive. Our analyses reveal decreasing returns to exploration due to reasons that are unrelated to the well-known exploration–exploitation trade-off ( March 1991 ). In fact, we observe that the performance outcomes of greater exploration involving complex systems decrease on their own, regardless of the relative level of exploitation. Hence, by theoretically and empirically assessing the costs of greater exploration in terms of architectural fit, we propose and find that more radical changes cause the optimal rate of exploration to occur at ever lower, and not higher, levels of exploration.\nTo isolate the causal mechanisms that relate complexity and integration into an existing architecture, we use an unconventional approach by combining quantitative and qualitative empirical analyses of Formula One (F1) racing. F1 is an innovation-intensive industry where firms—teams of engineers and drivers, backed by deep-pocketed organizations and sponsors—try to beat opponents with superior car design, safety, and performance ( Castellucci and Ertug 2010 , Jenkins 2010 ). The independent governing authority FIA (Fédération Internationale de l’Automobile) imposes environmental changes by releasing, once a year, a new set of rules that define basic guidelines for technology advances in the sport, thus influencing teams’ exploration strategies and F1’s overall competitive dynamics in each racing season. In this sense, the changes in industry regulations operate exogenously to the process of firm exploration. Our 30-year panel data set, which includes detailed codifications of all F1 car blueprints (over 300 vehicles), all FIA regulations, and all racing results, permits a robust long-term quantitative analysis of the exploration–performance association, as moderated by the FIA’s regulatory changes. In turn, our qualitative assessment of technical reports provides opportunities to not only compare exploratory strategies across F1 teams, but, more importantly, also help us ascertain, through unambiguous interpretations, the underlying logics of architectural misfits between winning and losing cars and teams (for a similar example of mixed method application, see Canales 2013 ). Because our empirical environment involves changes that vary greatly in magnitude (despite the predictability of their frequency), it suits the specificities of our theory well, and helps redress possible confusions between conceptual domains of environmental change ( McCarthy et al. 2010 ).\nIn what follows, we first provide a detailed account of the scope of our research and develop our hypotheses. We then present the setup and results of our quantitative and qualitative analyses. In the final section, we further specify the confusions noted above and identify other implications for theory and practice.\nThe Magnitude of Exogenous Environmental Change\nSection:\nStudies of firms’ responses to environmental change are neither new nor uncommon (see Bourgeois and Eisenhardt 1988 , Jansen et al. 2006 , Kim and Rhee 2009 , among others). But our cumulative understanding is bounded by the lack of precision in the use of constructs in extant research, which limits our ability to synthesize an empirical consensus, generalize patterns across studies, or understand the causal mechanisms that drive different empirical results. McCarthy et al. ( 2010 ) warn that the multidimensional constructs representing environmental change—e.g., dynamism ( Baum and Wally 2003 , Davis et al. 2009 , Jansen et al. 2006 ), turbulence ( Dess and Beard 1984 ), clock speed ( Nadkarni and Narayanan 2007a , b ), and velocity ( Bourgeois and Eisenhardt 1988 )—inhibit our ability to comprehend its fundamental antecedents and consequences.\nIn line with McCarthy et al. ( 2010, p. 604 ), we tackle this issue by stressing that underlying such different terms are two conceptually distinct constructs: the rate (e.g., Child 1972 , Wholey and Brittain 1989 ) and the magnitude (e.g., Abernathy and Clark 1985 , Tushman and Anderson 1986 ) of change. The former represents the frequency of changes in the environment, and reflects time lags between successive shifts, whereas the latter represents the size of the discontinuity of a new (technological) paradigm ( Hannan and Freeman 1977 , Levins 1968 ). Although studies on magnitude are less common in the current literature, partly due to the difficulties of quantifying it ( McCarthy et al. 2010, p. 608 ), there have been several insightful studies involving frequency.\nPosen and Levinthal ( 2012 ) recently used a simulation model to show that when the frequency of change is extreme, firms are better off avoiding having to chase fast-moving targets; that is, more exploration does not pay off, because the more rapid decay of generated know-how decreases its expected net returns. However, frequency and magnitude represent distinct and complementary dimensions of change, so the theoretical logic serving the former does not automatically transfer to the latter. Specifically, when the frequency of change is constant (or even decreasing), the swift obsolescence of innovations—which, according to Posen and Levinthal ( 2012 ), limits the expected value of exploration—is not an issue, so that intense exploration may turn out to be the best strategic approach in such environments.\nHowever, we posit that other distinct issues may arise, which are linked to different levels of magnitude of environmental change. In fact, although environmental changes may take place occasionally (or only once), they can still be intense enough to reshape technological standards. This distinction between frequency and magnitude matters, because as technological leadership can quickly crumble, firms may tend to continuously explore newer solutions ( Tushman and Anderson 1986 ), but in doing so they encounter problematic misfits with the overarching platform where these new solutions should be integrated. Consider the recent evolution in data storage technologies, for instance. The Blue-ray format, since it involves a shorter laser wavelength, permits the storage of vastly greater quantities of data on a disk, promising major gains for film and video-game consumers. But concerns regarding the integration of this format with existing consoles and display sets, the availability of content, and the production tooling and systems required significantly curtailed its widely anticipated success ( Yoffie and Rossano 2012 ).\nWe conceptualize the magnitude of environmental change to be either incremental or radical ( Tushman and Anderson 1986 , Henderson and Clark 1990 ) and consider how this variation affects the value of firm exploration. Tushman and Anderson ( 1986, p. 439 ) explain that when environmental changes demand incremental innovation, they are likely to be “competence enhancing,” because firms can react by exploiting the potential of their existing designs and technologies. Such incremental adaptation by firms does not draw from any dramatically new science, but rather involves firms tinkering, perhaps rather marginally, with their existing products and processes. In contrast, when changes demand radical innovation, they are likely to be “competence destroying,” because they may compel firms to rethink their entire sets of scientific, engineering, and design principles and skills (see also Henderson and Clark 1990, p. 9 ). Basically, the distinction between the two is one of degree, in terms of whether their adaptation to the new environment fundamentally alters the set of firm competencies and skills associated with the new technologies ( Tushman and Anderson 1986, p. 442 ). Consequently, this variance induces important effects on an industry’s competitive dynamics; that is, whereas the former reinforces the dominance of established technologies, and so increases the competitive advantage of incumbents, the latter destroys the know-how superiority of market leaders, so decreasing their competitive advantages and opening up opportunities for new entrants ( Abernathy and Clark 1985 , Anand et al. 2010 , Dess and Beard 1984 , Ettlie et al. 1984 , Henderson and Clark 1990 , Tushman and Anderson 1986 ).\nAnother issue in the study of firm responses to their environments relates to the sources of environmental change, which can be diverse, ranging from institutional, technological, political, market demand, and even legal domains ( March 1991, p. 71 ; McCarthy et al. 2010, p. 609 ; Tushman and Anderson 1986, p. 440 ). Generally speaking, the more an environmental change is exogenous (i.e., external) to the industry players, the more uncertain and unpredictable this will be to the incumbents ( March 1991 ). Thus, radical innovations based on established proprietary know-how (e.g., the launch of the iPhone) represent industry shocks that are endogenously defined by specific organizations (i.e., Apple), whereas the emergence of new technologies with cross-industry application potentials (e.g., digital imaging during the 1990s, or 3D printing currently), or new industry regulations (e.g., policies that curb the use of refrigerant gases for air conditioning devices), represent examples of change stemming from exogenous sources.\nIn our model, we focus on the latter type of situation. Specifically, we examine the effects of environment changes as those triggered by a regulatory agency that, although fundamentally involved in the industry, is independent of any of its competitive actors. Conceptually, regulatory changes reflect “the change in laws and regulations that affect an industry” ( McCarthy et al. 2010, p. 609 ) and are deemed to be “of great importance to organization scholars” ( Hambrick and Abrahamson 1995, p. 1434 ). Regulations can involve a range of business activities, such as pricing, production methods, and technological specifications ( Ashford et al. 1985 ), and are usually imposed by an impartial external agency, such as the state, institutions, or other industry controlling bodies ( Stewart 2011 ). In heavily regulated industries such as pharmaceuticals, aerospace, defense, and healthcare ( Ashford et al. 1985 , Stewart 2011 ), although the regulations may reflect some general industry needs, ultimately they are enacted by authorities that are exogenous to its firms and aim broadly at matters of collective utility, such as better consumer welfare, faster competitive dynamics, greater producer safety, unified technological standards, and even enhanced ecological preservation. In the process—and the point of central relevance to our study—these policies influence firm choices about how much and in which directions they should explore and innovate ( Ashford and Hall 2011 , Porter 1996 ) so that they can comply with regulatory changes and so compete in the new environment. So our focus on regulatory changes enables us to study the optimal exploration strategies that firms engage in to respond to these environmental changes.\nExploration-Based Strategies and Firm Performance\nSection:\nPrior research has shown that exploration is relevant for firm performance ( March 1991 ) because it enables firms to discover new knowledge—via learning by searching—that better fits the new environment in which they operate. Some researchers have considered exploration and exploitation as orthogonal and thus achievable simultaneously ( Baum et al. 2000 , Beckman 2006 , Koza and Lewin 1998 , Rothaermel 2001 ). In contrast, other studies have emphasized firms’ inability to conduct both concurrently at intensive levels due to scarcity of resources ( March 1996 , 2006 ), instead suggesting inverted-U-shaped relationships between exploration (or exploitation) and performance. 1\nWe start from this latter notion that exploration brings benefits in a curvilinear manner (i.e., benefits first rise, then fall), but offer a distinct rationale relative to this previous literature. We stress that overexploration is linked with issues of its own, unrelated to the well-known exploration–exploitation trade-off ( March 1991 ), and which are instead related to the challenges of fitting new components into existing and already well-integrated system architectures. Our inverted-U relationship thus reflects the logic that as firms explore increasingly more, they may not be able to benefit fully from the value and novelty of what they discover. Exploration examined at the component level overlooks cognitive complications at the system level, which firms handling complex products—e.g., those composed of various interdependent parts—must grapple with, even when their explorations yields new components that are indeed superior. Hence, we argue that, even assuming a firm can strike the right level of exploratory efforts vis-à-vis the novelty value of the components it discovers (as in the Blu-ray example), it must still grapple with the challenge of integrating those components into its complex product architecture, and this challenge varies with the extent of its exploratory efforts.\nThe notion of product or system architecture reflects the fact that multiple components must fit together satisfactorily to make a coherent system ( Brusoni and Prencipe 2001 ). The distinction between the product as a whole (i.e., the system) and its parts (i.e., components) has a long history in the literature (see, among others, Alexander 1964 ; Henderson and Clark 1990, p. 11 ; Marples 1961 ; Simon 1962 ). Simon ( 1999, p. 16 ) explains that because such multiple parts can interact in nontrivial ways, the whole system takes a value that is more than the sum of the individual parts. Given the hierarchy of relations, the performance of each component element not only depends on its own inherent qualities, but also becomes a function of the output of others it connects to, such that increasing the adjustments at the component level can multiply the risk of system misfit. Thus, systems that are highly complex, i.e., where individual parts interact with multiple others, 2 take significantly longer to emerge efficient through an evolutionary process ( Simon 1962 , 1999 ).\nOur first hypothesis builds on the underlying logic of an inverted-U-shaped relationship as being more attuned to the problems of balancing the architecture of a system as novel component-level upgrades are introduced ( Henderson and Clark 1990 , Simon 1962 ). Conceptually, when individual components are innovated to fit a new environment more aptly, they yield performance improvements vis-à-vis the old ones. But the logic of system decomposability suggests that the concomitant risk of system misfit increases the more the new component relies on technologies far from the original design ( Brusoni et al. 2001 ). The more distinct and specialized the novel components become, the more likely they are to distort the established homeostasis of the system as a whole, and throw the entire architecture out of balance ( Simon 1962, p. 6 ). For example, new emissions standards may compel automakers such as Ford and General Motors (GM) to respond to new regulatory demands by developing engines with lower emissions. But, because such firms are likely to hold stronger engineering competencies associated with traditional engine designs, they may struggle to retrofit such new components to existing powertrain, axle, and wheel subsystems and so deliver consumers acceptable vehicle performance and safety. Hence, as exploration increases, it first enhances performance, but the farther from its existing know-how base a firm explores new component knowledge, the more it must rethink a complex set of component interdependencies involving the whole product system’s architectural fit, so that, beyond an optimum level, the marginal benefits of exploration will begin to decrease. We therefore propose the following:\nHypothesis 1 (H1)\nCeteris paribus, the performance of firms relying on complex products first increases and then decreases as exploration at the component level rises.\nA subsequent question that arises is how the inverted-U relationship noted above behaves when subject to environmental change of varying magnitudes. At a base level, several prior research strands suggest that the more the environment changes, the more firms gain from further exploration ( Brusoni et al. 2007 , Jansen et al. 2006 ). However, March ( 1991 ) argues that a firm’s knowledge only creates value insofar as the environment in which it operates remains the same. Received empirical wisdom about competitive dynamics also suggests that radical change can reduce the gap between leaders and followers, making the playing field more equal, so boosting followers’ impetus to innovate ( Aghion et al. 2005 , Blundell et al. 1999 , Geroski 1995 ). 3 As environmental changes erode the competitive gap between players, rivalry intensifies, thus affecting rents asymmetrically—reducing preinnovation rents by more than it reduces postinnovation ones—and leading firms to innovate to escape current competition. Similarly, Tushman and Anderson ( 1986 ) argue that “incremental changes” are “competence enhancing” because they “permit firms to exploit their existing competence and expertise”; whereas “radical changes” are “competence destroying” because they “break the existing know-how base for the product class,” hence lowering barriers “for new technologies to emerge” ( Abernathy and Clark 1985, pp. 445–446 ). Thus, incremental changes drive “orderliness and consolidation,” whereas radical ones can “alter a product class.” As a result, the former reinforces existing advantages and decreases incentives to explore, whereas the latter destroys existing advantages, and so encourages exploration ( Tushman and Anderson 1986, p. 446 ).\nIn our research, we argue that most prior studies have overlooked the organizational challenges of greater exploration, particularly when it comes to issues of integrating novel components into complex systems. As changes of increasing magnitude may trigger issues that, at the margin, grow more rapidly than the benefits of exploration, it may be easy to overestimate the net gains if these issues are ignored. We consider the genesis of such organizational issues in terms of the firm’s capacity to integrate novel components into the system, given the limits on time and its cognitive capacity.\nNovel components generated in response to radical environmental changes can impose exacting demands on the architecture of product systems ( Henderson and Clark 1990 , Brusoni et al. 2001 ). At a base level, environment shifts spawn crises in the internal fit between system components since they all fit the environment at distinct levels of specialization. But the system performance problem can quickly grow much more severe, depending on a firm’s capacity (or lack thereof) to integrate the system’s interrelated parts ( Brusoni and Prencipe 2006 ). Even where interdependencies between elements are minor, once a firm extends its component technologies searches, it is likely to have to devote exponentially more time and resources to synchronize all its systems’ parts properly ( Simon 1962 ), as the know-how needed to solve such architectural problems is often implicit and hidden across various organizational fields ( Henderson and Clark 1990 , Simon 1962 ). So when regulatory changes increase to significant levels, the costs of the information processing associated with architectural fit tend to grow considerably. This implies that beyond the skills needed to invent new components, the system integration capabilities of firms—which Prencipe ( 1997, p. 1261 ) identifies as those needed to manage their entire system’s dynamics—come to bear additional burdens. Thus, when responding to environmental changes of greater magnitude, firms that enhance their exploration levels may be challenged by the risk of system failure, even if the novel components they seek to integrate are themselves technologically superior. For this reason, we suggest that as regulatory changes impose more radical technology upgrades, the optimum level of exploration beyond what is needed for minimum compliance will tend to recede.\nThe constraints on time and firm’s cognitive capacity play an important role in this argument. Simon ( 1976 ) suggests that once a complex system is exposed to environmental change, the information required to coordinating and fitting the multiple parts together increases exponentially. Organizations often rely on cognitive as well as experiential frameworks ( Gavetti and Levinthal 2000, p. 113 ) to coordinate the changing parts of complex systems. Given the radical nature of the changes in the environment, as well as in the novelty of the components, their cognitive frameworks are less likely to prove adequate to the challenge of designing a new architecture, ex ante. At the same time, in terms of their experiential frameworks, the demands on information and computation will necessitate ever more experiments if the system is to evolve more integrated, and these can subject the organization to greater risk of failure ( Simon 1976 ). Because the integration of the system rests on the interdependencies of its parts, greater magnitudes of change make it harder to predict the net gains from component-level upgrades ( Brusoni et al. 2001 ). At a base level, organizations tend to use simple heuristics of system architectures, which are effective tools to reduce search costs. But when regulatory changes grow in magnitude, the complexity of system architecture can increase beyond the organization’s cognitive limits, making the process of trial-and-error learning both costly and risky. In this case, the firm may become unable to foretell how well new arrangements of components will fit into a cohesive architecture. Hence, we reason that when environmental changes are increasingly more radical, the inflection point at which exploration levels are at their optimum ( H1 ) will recede:\nHypothesis 2 (H2)\nCeteris paribus, the magnitude of environmental change negatively moderates the curvilinear relationship between firm exploration and performance; that is, the greater the magnitude of such change, the lower the level of exploration at which firm performance will be maximized.\nQuantitative Analysis Methods\n,\n(2)\nwhere t = 1,…, m years (or F1 seasons), k = 1,…, n organizations (or F1 teams), Y denotes Performance, CTR denotes Change in Technical Regulations, EXP denotes Extent of Firm Exploration, DR denotes Change Drivers, CE denotes Change Engineers, and Γ denotes organization fixed effects.\nWe ran these two models with a generalized method of moments (GMM) estimator ( Arellano and Bond 1991 , 1998 ). 6 This option offers several attractive properties compared to canonical panel data estimation via the ordinary least squares (OLS) method. First, it allows us to account for performance trend effects ( Roodman 2009b ). Both the lagged value of the dependent variable and the lagged value of the fixed effects can give rise to dynamic panel biases, so OLS coefficient estimates risk being biased and inconsistent ( Nickell 1981 ). Second, the GMM method provides a suitable set of tools to account for any endogeneity, predetermination, and reverse causality that may arise because the independent variables Change in Technical Regulations and Extent of Firm Exploration may correlate with error terms in future time periods. In fact, this estimator runs the model as a system of equations in which the variables can be instrumented with lagged variables. Thus, by adopting the conventional approach in Stata Module xtabond2 ( Roodman 2009b ), we modeled fixed effects and controls as exogenous, the independent variables as predetermined, and the lagged dependent variable as endogenous. Because of the large number of panels, the high resulting number of available moment conditions was a potential source of overfitting bias ( Baltagi 2009 ), so, as Roodman ( 2009a , b ) suggests, the number of instruments we used was consistently fewer than the number of groups.\nTable 2 reports the coefficients, significance levels, and number of instruments, as well as the results of Wald, Arellano–Bond Type 1 and 2, and Sargan–Hansen tests ( Roodman 2009b ). 7 Model 1 includes the controls. We find a positive trend in performance that is captured by the positive and significant coefficient in the lagged dependent variable, confirming the benefits of our choice of GMM estimation. In Model 2 (Equation ( 1 )), with only the main effects, there is a positive and significant coefficient for Extent of Firm Exploration and a negative and significant one for its quadratic term (EXP)2, suggesting an inverted-U relationship, as predicted in H1 . To provide stronger evidence of the inverted-U curvilinear relationship, as suggested by Lind and Mehlum ( 2010 ), we also examined whether the positions of the extremum point fall within the range of the observed data. Specifically, we first estimated the position of the extremum point (B = 1.665, p < 0.01) on EXP and its related confidence interval (CI) by using the delta method (CI, [0.989, 2.341]). Then, we verified that the confidence interval is indeed inside the data range of EXP (i.e., CI, [0.989, 2.341] ⊂ [0, 2.833]). 8\nTable 2: Results of Two-Way System GMM Blundell and Bond ( 1998 ) Model Estimation\nTable 2: Results of Two-Way System GMM Blundell and Bond ( 1998 ) Model Estimation\n \nNotes. N = 346. Robust standard errors are in parentheses.\n∗p < 0.05; ∗∗p < 0.01; ∗∗∗p < 0.001.\nIn Model 3 (Equation ( 2 )), the coefficient of the two-way interaction term between Extent of Firm Exploration and Change in Technical Regulations is negative and significant (B = −0.127, p < 0.05), suggesting support for H2 . To gain further insight into the moderation effect of the curvilinear relationship in Model 3, we further conducted a graphical analysis using conventional approaches ( Aiken and West 1991 , Bauer and Curran 2005 , Cohen et al. 1983 ). Figure 1 reports the fitted values (based on Model 3) of the relationship between the Extent of Firm Exploration and Performance at three representative levels of the moderator (Change in Technical Regulations)—at the mean, and at minus and at plus one standard deviation ( Aiken and West 1991 ). The graphical analysis fully supports the effects predicted in H2 . In fact, the level of performance peaks around an exploration level of about 2.1, when regulatory changes are low. In contrast, when the moderator is set one standard deviation above the mean, the value of exploration at which performance peaks is about 1; beyond this value, exploration becomes increasingly dysfunctional. 9\nFigure 1 Interaction Effect Among Change in Technical Regulations, Exploration, and Firm Performance\nTo supplement the evidence from the above graphical analysis, we proceeded as follows. We first verified that each curve in Figure 1 has indeed an inverted-U shape by applying the same test that we used to test H1 ( Lind and Mehlum 2010 ). The results of the tests confirm that in each curve the extremum point falls within the range of EXP. We then compared the exact estimations of the extremum point positions in the curves obtained by plugging in values of Change in Technical Regulations equal to the mean minus and plus one standard deviation. The analyses confirmed and specified the insights of the graphical analysis as the former estimate (CTRmean−SD: B = 2.106, p < 0.01) resulted to be greater than the latter (CTRmean+SD: B = 1.089, p < 0.01). Finally, we performed a statistical test that rejected the hypothesis that the difference between CTRmean−SD and CTRmean+SD is null (B = 1.144, p < 0.05), thus providing full support for H2 .\nEssentially, our statistical results indicate that although the Extent of Firm Exploration has an inverted-U relationship with Performance, the value of exploration at which performance peaks decreases as environmental (i.e., regulatory) changes increase in magnitude (i.e., become more radical). 10\nQualitative Analysis Methods\nSection:\nOur quantitative model above relies on precise metrics of the Magnitude of Regulatory Changes and firm strategic choices regarding the Extent of Firm Exploration and Performance, thus enabling a faithful test of the alternate logic put forth in this paper—i.e., that environment changes of high magnitude disturb the fit of system architecture, thus causing the optimum trade-off point between exploration and performance to recede. In this section, we take further steps to articulate the precise nature of this underlying logic by grounding an in-depth qualitative analysis on historical archival data that helps reveal the logical threads behind the empirical effects shown earlier. Our methodological approach is consistent with other well-known studies of organizational capabilities involving complex processes (e.g., Gavetti 2005 ). Following accepted practices (e.g., Eisenhardt 1989 , Siggelkow 2007 , Yin 2008 ), we select a representative season, i.e., one with a radical regulation change, and contrast its effects across multiple teams following diverse strategies (i.e., engaging in more or less extensive exploration). In this study, our specific focus is the 2009 season, and the particular radical component involved is a new energy-efficient technology known as the kinetic energy recovery system—or simply, KERS.\nIndustry experts agree that this season gave an acute demonstration of the different teams’ approaches to innovation vis-à-vis the changes promoted by the FIA ( Aversa 2013 ). In the words of Sebastian Vettel, a Red Bull team driver, 2009 saw “the biggest change in history of F1,” one that he felt would “spice up the race” (AutomotiveTV.com 2009). Furthermore, the relative recentness of this season and the enormous interest it excited in the media, industry, and fans afford us access to a vast selection of secondary data. We used online (e.g., Web crawlers) and off-line (e.g., libraries, archives) search mechanisms to scan multiple sources (e.g., videos, articles, industry reports, interviews, books, audio files, pictures, and blueprints) to examine all the managerial, strategic, and competitive aspects that characterized the season, consulting over 300 documents (readily available from the authors on request), the vast majority of which are used by F1 insiders themselves (e.g., Formula1.com , BBC Sport archives, Autosport.com , FIA official regulations, Racecar Engineering, the F1 special report in the Financial Times online, etc.). Three scholars intimately familiar with F1 examined all these files independently multiple times, identifying keywords and critical interpretations, and afterward discussed the archival data together and sought a fit between their collective interpretations and information from these external sources. To strengthen the reliability of our triangulation, we followed the suggestion of Gioia et al. ( 2013 ) that one rater should act as a “devil’s advocate,” openly challenging the validity of the ideas presented by the others.\nThis thorough archival search helped us build a broad map of events that tracked race performance back to the challenges of fitting new technologies to the cars’ architectures, and further back to managerial choices about the extent of their teams’ explorations of the external environment. For instance, when cars failed, we searched for technical reports that provided interpretations of the causes. Thus, we were able to trace car performance and championship results against technological changes and identify the core mechanisms affecting vehicle architecture and component choices, which in turn correspond to teams’ choices about their exploration levels in that season. Because official sources often report quotes and interviews from experts and F1 professionals (e.g., drivers, managers, directors, suppliers), we were able to ground our interpretations on direct comments from the very people who lived those events. And their retrospective bias was minimized because of the temporal proximity of the circumstances—for example, the articles consulted yielded quotes from postrace press conferences, where team managers and drivers provided their immediate and impromptu interpretations of the situation. We selected a set of the most significant quotes from these protagonists, and use them to enrich our descriptive narrative of the events in the section below. We then aggregated the first-order data into broader second-order constructs that represent the central building blocks of our conceptual model on the performance effects of exploration in changing environments (see Table 3 ). Following accepted practices (e.g., Locke 2001 , Maitlis and Lawrence 2007 , Stigliani and Ravasi 2012 ), we summarized both first- and second-order categories and connected them to the basic interaction model that informs our quantitative analysis presented earlier.\nTable 3: Qualitative Codification of the Model’s Variables, Mechanisms, and Effects on Performance\nTable 3: Qualitative Codification of the Model’s Variables, Mechanisms, and Effects on Performance\nModel\n \nPositive performance for the teams who opted for low exploration\n—Constructors’ Championship: Two relatively inexperienced teams (Brawn GP and Red Bull) get the first two positions in the ranking by winning 14 out of 17 races\n—Drivers’ Championship: Brawn GP and Red Bull’s drivers get the first four positions in the ranking, despite their limited experience and mediocre past results\nFinally, in collecting qualitative data from our panel, we interviewed external informants from very different fields (e.g., academia, F1 racing, expert media, motorsport historians, and F1 fans) to assess the face validity of the causal interpretations we offer in our theoretical model. This work involved 35 hours of interaction with a total of nine external informants, who overwhelmingly corroborated our interpretations, giving us confidence about the robustness and external validity of the theoretical inferences we present. We review the regulatory changes that affected car design in 2009, analyze how teams reacted in terms of their strategic exploration choices, and finally identify the mechanisms underlying the interactions between environmental changes and exploration as it affected team performance in the F1 championship in that season.\nQualitative Analysis Results\nSection:\nFollowing some years of relative technological stability, the FIA introduced several new rules in 2009 that affected all components of F1 race cars: engine, chassis, aerodynamics, mechanics, tires, and electronics. These diverse parts have such a symbiotic codependence that even minute changes in one (e.g., aerodynamics, engine) could affect multiple other parts (e.g., brake mechanics, weight) and have subsequent effects elsewhere (e.g., tire efficiencies), so the challenges of architectural fit are quite immense, reflecting the complex nature of the race car as a system. In addition to the challenges resulting from these mandatory technological changes, the teams had to cope with major limitations on their research and development (R&D) resources in 2009: specifically, FIA banned all in-season testing, put a strict cap on wind-tunnel simulation time, and allowed only a maximum of eight engines per driver over the season. These resource restrictions were meant to equalize the playing field and boost rivalry, but they gave F1 teams less time to study engineering specifics for the season, and so curtailed their ability to understand fully the consequences of the technological advancements outlined in the new season regulations and achieve a well-balanced car. Many teams worked around these limits by using official races to test innovations, although this approach increased their risks of failure and hit the more innovative teams especially hard.\nAs noted above, in addition to these requirements, the FIA’s 2009 guidelines also allowed for optional technological advancements, such as the KERS, a device that stores the kinetic energy from the waste heat created by the car’s brakes. Once converted into electrical power and stored in a dedicated battery, this energy is then made available for acceleration. Although there was an overall push in F1 toward the development of such fuel-efficient ecologically friendly technologies, this initiative also promised to increase viewer excitement as the KERS facilitates overtaking. But the FIA established very strict rules regarding its output and use, for instance, the system could only deliver a maximum of 80 extra horsepower (about 10% over current output), and was only allowed to be turned on for 6.6 seconds per lap, either in a single or in multiple short bursts. No energy recovery system had ever been adopted in F1 racing before, such that not even the FIA had been able to provide base engineering guidelines. The core concept was based on a prototypical hybrid technology, the mechanical and electric principles of which were still largely unknown in the industry; so KERS was new in absolute terms, even to the most experienced teams. The FIA allowed teams significant creative room around the KERS design and mechanics:\nUnlike the engine, there is full development freedom on KERS. And like any new technology it’s only natural to expect the system to develop as you learn more about it. Every team will be updating their systems during the season.\n(Paddy Lowe, McLaren Engineering Director; Formula1.com 2008)\nThese qualities—that it was not a requirement, that it was entirely new, and that teams were free to explore it—make the KERS a suitable illustration for studying our underlying logic. In fact, the extensive exploration of the KERS core technology and design that teams undertook in the 2009 season, along with the dramatic reduction in their analytical and R&D assets (that stressed their engineers’ cognitive limits) significantly increased the complexity of fitting and rebalancing the delicate architecture of F1 cars. In the words of industry insiders:\nKERS requires a lot of fine-tuning to the car. It has to recharge itself—so when you press the brakes, it generates an extra resistance that you have to somehow compensate for to balance it out. That means interacting with the engine braking and the brake balance. You just have to find the best compromise; it’s not just installing the KERS and going quicker, you have to balance it into the whole system.\n(Pedro De La Rosa, McLaren test driver; Formula1.com 2008)\nKERS does require a little extra attention from the driver. And it certainly harms your weight distribution. You have less weight to play with, so set-up work becomes a little trickier.\n(Christian Klien, BMW test driver; Formula1.com 2009)\nIn line with their continuous enthusiasm for groundbreaking innovations, all the major teams—Ferrari, BMW, Renault, Toyota, Williams, and McLaren—responded with great interest to the FIA’s suggestions about introducing the KERS, and invested considerable preseason R&D resources into testing the device (i.e., they opted for higher exploration). With the exception of Toyota and Williams, they all deployed KERS-equipped cars at the first 2009 Grand Prix, a few months later. But the FIA cap on R&D activities increased the uncertainty around the system, and turned teams’ initial enthusiasm into concerns; they actually began to wonder whether the efforts, costs, and risks involved would be sufficiently repaid by the potential benefits.\nIn contrast, the less explorative teams avoided the KERS altogether, explaining their decisions by pointing to the poor results from preseason tests and budget limits. Ross Brawn, the celebrated former Ferrari technical director and (from 2009) Brawn GP team principal foresaw some of the critical issues the KERS would bring in terms of its value, and the many challenges involved in debugging the car’s architectural fit:\nThe theoretical advantage of having KERS is perhaps 2 or 3 tenths of a second per lap (…) but you lose in terms of weight, packaging, and torsional moment at the back. In any case, there is no clear decision on KERS. I think it will take a while before we can eliminate the disadvantages. There will be a number of KERS versions, and perhaps…more versions that we haven’t thought of so far. For us the system only starts to work when we overcome the disadvantages.\n(Ross Brawn, Brawn GP Technical Director; F1 Technical 2009)\nFollowing an alternative exploration strategy, the teams that decided to forgo developing KERS (including Brawn GP and Red Bull, both new upstart teams at that time) undertook instead significant efforts to optimize existing components (i.e., they opted for less extensive exploration). For example, they both introduced aerodynamic undersides, known as double diffusers, and improved their sidepods and exhaust systems. In contrast to the KERS, these changes were considered more incremental in nature and represented relatively marginal improvements of existing components based on established field-specific knowledge, to comply with the 2009 FIA rules. Ross Brawn affirmed that the double diffuser was “an innovative approach to an existing idea,” and, despite various complaints from rival teams, the FIA declared it a “legal adaptation” ( Aversa 2013, p. 16 ). Adrian Newey, Red Bull’s chief technical director, also opted for a moderately conservative exploration approach, as his team expressed concerns over the architectural fit costs of the KERS and suggested it was unadvisable to push exploration far beyond what the regulation required:\nWe have taken a clean sheet, blue-sky approach, looking at the implications of the rules and how to interpret them,…not changing things simply for the sake of it.\n(Adrian Newey; Formula1.com 2009)\nAnd indeed, Ross Brawn’s concerns materialized in the exploration-prone teams’ experiences. Even in the pretesting season, the adoption of the KERS revealed problems across interfaces with various other components. What complicated things was not merely the fact that the KERS itself was still being developed, but that the testing of its effective integration during the first (i.e., premanufacture) stages of vehicle design was limited to simple simulations. In the words of an industry insider:\nThe KERS is a complex system, not only technologically regarding the battery and the control system, but also regarding the logistical management of the parts, which is very complex.\n(Luca Marmorini, Ferrari Powertrain Chief Engineer; Formula1.com 2011)\nBecause of the tightly embedded nature of the car’s multiple components, the KERS also imposed technical limitations on the evolution of the general car architecture. For example, FIA imposes minimum-weight rules for safety reasons, which in 2009 was 1,333 lbs, driver included. By locating ballast units around the car, teams could optimize the car balance taking the cars’ actual weight up to the minimum required. But the KERS added around 66 lbs of nonadjustable weight, thus raising balancing and torsional problems:\nIn practice, constructors build their racing cars much lighter than the regulations require, and then bring them up to the mandatory minimum by adding ballast as low down as possible, and where it will best improve the vehicle’s handling and reduce its tyre wear. That depends on the driver and the circuit. With less ballast to distribute optimally around the car, a heavier driver is already at a competitive disadvantage. Include KERS and the car could be out of the running altogether, despite having a peak power 10% more than normal. The extra weight could also rob the car of its full fuel load, forcing it to make extra pit stops during a race.\n( The Economist 2009 )\nIn subsequent phases, when drivers began testing the F1 cars, other system misfit issues arose. Because the KERS boost could only be activated in certain circumstances, it required mental as well as visual agility from drivers to track panel indicators and nuances of the racetrack itself, which did not fit every driving style, and in fact negatively impacted performance for some of them:\nIt’s how much I take my eyes off the track, that’s the worry. …I had headaches the first time…because you’re trying to read what the steering wheel says.\n(Rubens Barrichello, Brawn GP driver; Spurgeon 2011b )\nCompounding the ballast distribution problem, the KERS was hard to implement in cars with heavy drivers. Some teams that mounted the KERS forced their drivers to undergo rigid diets to address the problem of nonadjustable weight in the car architecture. But these diets impacted their physical abilities, and several of them struggled to perform during races:\nF1 drivers found themselves not always in the best of health thanks to their weight loss. During the extreme heat and physical strain of some of the Formula 1 races, driver[s] can lose up to 5 kilos of weight. At the hottest early race of the season in 2009, Alonso also found himself in another very difficult situation: His water bottle broke and he had nothing to drink throughout the race. Having lost 5 kilos over the winter, then a further 5 kilos or so during the race, and without anything to drink, the Spanish driver collapsed after the race in a state of dehydration.\n( Spurgeon 2011a )\nWith the added limitations on testing resources, teams struggled to balance their vehicles even as the season progressed. The fit difficulties also led to vehicle reliability issues that continued throughout the season, in the form of electrical shocks, batteries overheating, and even fires. In fact, the 2009 season brought an increased number of car breakdowns, especially in teams that adopted the KERS:\nAnd as it was in an early stage of development as the season began, it was also unreliable for many teams. The Ferrari team suffered KERS breakdowns on race weekends in what became its worst season start in decades when it failed to score any points in the first three races.\n( Spurgeon 2010 )\nGiven these mounting problems, some teams took the radical step of cancelling their adoption of the KERS:\nWe’re keeping working on our KERS. I’m not saying we won’t run it this year but it will be difficult to run it on the car and have the car set in its optimum performance window.\n(Patrick Head, Williams technical director; Formula1.com 2008)\nIt was not until the 2011 season that teams finally figured that an adjustable flap—the drag reduction system (DRS)—would prove to be the only way to get the best out of the KERS.\nEssentially, qualitative evidence suggests that organizations are likely to find radical regulatory changes challenging, in that they magnify the need to redefine and reshape product system architecture throughout the entire product development process. For this reason, in this environment, strategies of greater exploration are likely to prove suboptimal. Based on our analysis of the qualitative evidence above, Figure 2 highlights the causal logic in this process by isolating two mechanisms that make system rebalancing a complex task: (a) novel components drastically complicate the problems of architectural design (Mechanism 1), particularly in the design and prototyping phases, and (b) organizations’ time-based cognitive limitations (Mechanism 2) can damage their ability to overcome such challenges promptly, particularly during the product’s actual life.\nFigure 2 Problems in Architectural Redesign and Time-Based Cognitive Limitation Throughout the Product Development Process\nThe performance implications arising from different exploration-based strategies corroborate our logic above. To highlight broader nuances, we consider both the Constructors’ and the Drivers’ Championships. The especially turbulent regulatory environment of the 2009 season challenged all teams and led to general decreases in car speeds compared to the previous year. And it is clear that the teams that explored farther afield (i.e., experimented with the KERS) had an even rougher year and suffered significant performance handicaps. F1 teams spent a total of US$64 million experimenting with the KERS technology in 2009, but the innovation turned out to be less effective than teams had initially hoped. In their best laps, KERS-equipped cars, although super charged with some 10% additional horsepower, gained only two- or three-tenths of a second, and saved only 0.021 liters of fuel.\nBut more telling are the overall performance results, when these gains are taken together with the difficulties of balancing the car architecture (brakes, ballast weight, driver fit, etc.). Published reports highlight that the teams officially regretted their decision to explore the KERS in the 2009 season. The teams who ended up with the best championship results were those who opted for standard, reliable, no-frills cars that, whereas they complied strictly with the new FIA regulations, stuck to a strategy of more moderate exploration based on technology optimization of well-established components, such as Brawn GP’s double diffuser and Red Bull’s improved sidepod and exhaust. The season ended up with a rare result in F1 history, with two young and relatively inexperienced teams winning first (Brawn GP) and second places (Red Bull) in the Constructor’s Championship, recording substantial point leads over the budget-rich and more highly innovative Ferrari, McLaren, Williams, Renault, and BMW teams. Interestingly, Ferrari (third place) and McLaren (fourth place) scored less than half of the points of the two top-ranked teams, whereas BMW (fifth place) only began earning more points toward the end of the season, when it decided to suspend the KERS project. As “rookies,” Brawn GP and Red Bull could hardly have been predicted to do so well. Brawn GP was created in 2009, from a “last-minute” management buyout of the failing Honda Racing F1 team, 11 whereas Red Bull in turn emerged from the ashes of Jaguar GP, which is remembered as one of the least successful F1 ventures. In line with the constructor’s ranked results, the Driver Championship went to Jenson Button (Brawn GP), who had been a comparatively unsuccessful driver since his debut in 2000, had not won a championship before, and had only achieved mediocre results in the two previous seasons (15th in 2007 and 18th in 2008). The young and inexperienced Sebastian Vettel of Red Bull came second, whereas Rubens Barrichello (Brawn GP) and Mark Webber (Red Bull) finished third and fourth. The first top-team driver was Lewis Hamilton (fifth), who only amassed half as many points as Button. Analysts observed that the exploration of the KERS correlated negatively with race performance:\nAfter years of domination by McLaren, Mercedes and Scuderia Ferrari, this season saw an underdog driver win a Grand Prix. It was even more surprising as it was the teams without KERS that were doing well in the championship.\n(TheSportsCampus.com 2010)\nThe negative effects of adopting the KERS were particularly visible given the qualities of teams who lost out, but could normally have expect better results: higher budgets, better drivers, longer experience, and greater visibility, among others. In sum, we believe the KERS case offers useful theoretical insights that pinpoint the precise logical thread underlying the findings from our quantitative empirical model. When environmental changes are radical, firms are likely to have to cope with perhaps substantial problems of product architectural fit and significant cognitive limits inherent in a fiercely competitive and technologically dynamic environment involving complex systems. We find that dynamic environments can erode the rewards of intense exploratory efforts aimed at advancing technological frontiers, which suggests that careful analyses are required of how and when exploration will or will not pay off.\nAlthough we have largely focused on illustrating a context of radical change, as our empirical model suggests, our qualitative data support the evidence that the issues that KERS adopters faced in 2009 failed to materialize in a context of limited change of the technical regulations. Take as a representative example the case of Williams’ car in 1993—a quite stable season in terms of regulations changes.\nDesigned by Patrick Head and Adrian Newey, Williams’ FW15C car introduced some radically innovative solutions in the 1993 F1 season, such as antilock brakes, traction control, and active suspension, together with an improved Renault engine. Official sources agree the FW15C was the most technologically sophisticated Formula One car of all time. Williams’ driver Alain Prost won the driver’s title and with 10 victories in 16 attempts, and Williams convincingly grabbed the Constructor’s Championship. The car had its debut in a year of minor regulatory changes, which did not create particular challenges in fitting the new solutions within the car architecture, which proved to be fast and reliable from the very beginning. Official sources claim the following:\nAdapted to minor regulations changes, the FW15 did eventually make its competition debut at the start of the 1993 season as the FW15C. Unlike the FW14, it was designed for the latest electronic devices like the fully active suspension, so it was a much tidier package. One of the biggest tricks up the FW15C’s sleeve was the hugely sophisticated active suspension system that was developed in-house at Williams. This allowed the suspension to be continuously optimised for each section of the track. Another feature was a “push-to-pass” button, which would raise the rear ride-height and as a result reduce the drag created by the diffuser. In addition to the active suspension the 1993 Williams also featured traction control, ABS and fly-by-wire controls. …In the next years the teams tried to reintroduce many of the driver aids but the Formula 1 cars were never so comprehensively equipped as the FW15C. This makes the Renault-engined machine perhaps the most advanced Grand Prix car ever built.\n2 Simon ( 1962 ) refers to this as the system’s degree of decomposability (cf. Nickerson and Zenger 2004 ).\n3 Assuming a rather stable environment (or one that only changes incrementally), firms with context-specific capabilities will earn a competitive advantage over those that possess context-generic capabilities ( Porter 1985 ). But as the environment changes more radically, the Context specificity of the resource (and hence, its value superiority) decreases quickly, so eroding this advantage. For example, the use of pesticides in farming is known to boost crop yields, and sellers of patented formulas have an edge over rivals that sell generics. However, should the patented formula suffer from new regulatory bans, this competitive advantage would end. As the literature argues, this “equalization” would drive firms into new explorative endeavors.\n4 Regulations may be aimed at introducing or restricting the use of new technologies, but qualitative evidence (available from the authors on request) reveals that in both cases they produce similar effects on firms’ behaviors. In fact, the evidence we examine shows that regulatory changes end up enhancing technological heterogeneity at the firm level, as players always strive to find ways to work around the regulations. Thus, a regulation may forbid a specific solution, but often does not concomitantly ban all the alternative devices/solutions that could be used as functional alternatives. Another key aspect regarding the distinct types of technical regulations is that the changes in the rules may, in theory, have contrasting effects in different organizations. However, the qualitative data coded during our study show little evidence in support of this argument.\n5 Cars that failed to finish a race were automatically assigned to the last position in that race.\n6 Since the persistence of the dependent variable could cause weak instrument problems, we opted to use the system-GMM estimation rather than the difference-GMM technique ( Arellano and Bond 1991 , 1998 ).\n7 The robust standard errors were computed conventionally by applying the Windmeijer ( 2005 ) correction. The Sargan–Hansen test did not report significant coefficients for either model, indicating that our instruments were suitable; similarly, the results of the Arellano–Bond tests indicate the absence of second-order autocorrelation.\n8 Note that Lind and Mehlum ( 2010 ) observe that determining whether the (1 − 2α) confidence interval for the extremum is within the range of the x variable is equivalent to running the Sasabuchi ( 1980 ) test at the α level of significance.\n9 As the environment changes more radically, the level of performance registered at the peak of the inverted-U shape (unsurprisingly) decreases. In fact, because environmental shocks generally render existing products and technologies less valuable, it is plausible that immediately after such shocks occur, even top performers can only achieve suboptimal product configurations.\n10 Our framing assumes environmental changes to be exogenous to the activities of firms, that is, as resulting from impositions by an external agency, rather than from a Schumpeterian process triggered by the firms themselves. But one can still suspect regulatory changes in F1 may be endogenous—for example, that they may involve favoritism, or some other superordinate interest by a team with undue influence on the FIA—and so question the validity of the analysis. To examine this possibility, we inspected the reasoning the FIA gave for each proposed regulatory change closely, and in each case found that they aimed to decrease team dominance and improve public welfare (e.g., rules to reduce negligent behavior and improve driver safety, technical standards to improve the chances of vehicle overtaking and thus increase fan entertainment, budget limitations to reduce costs and balance the chances of cash-rich against cash-poor teams, and rules regarding sponsorship display in cars to improve revenue). We also verified whether the issuance of new rules coincided with the dominance of particular teams. Indeed, we found that the 2009 regulatory shock was partly deliberately intended to break a rapidly increasing concentration in performance and team dominance. To check for the robustness of the results, we repeated the regression analysis excluding that year, but found no relevant variations in the findings for either the estimates of the coefficients or their statistical significance.\n11 Nick Fry and Ross Brawn (former general manager and technical director at Honda F1, respectively) took over the company and re-founded it as Brawn GP, after several failed attempts to find an alternative buyer.\nReferences\nSection:\nAbernathy WJ , Clark KB (1985) Innovation: Mapping the winds of creative destruction. Res. Policy 14(1):3–22. Crossref\n""","0.16292752","""http://pubsonline.informs.org/doi/10.1287/orsc.2015.0984""","[-0.102322,51.52779]"
"""University_of_Surrey""","""Finding effective pathways to sustainable mobility: bridging the science–policy gap: Journal of Sustainable Tourism: Vol 24, No 3""","""关键词: 气候变化 ,  社会技术因素 ,  科技神话 ,  运输禁忌 ,  理想期货\nIntroduction\nDemand is increasing for all transport modes. The transport sector, including tourism and all other transport motivations, is growing more rapidly than most other sectors and is currently responsible for approximately 23% of global energy-related CO2 emissions (Creutzig et al., 2015 Creutzig, F., Jochem, P., Edelenbosch, O.Y., Mattauch, L., van Vuuren, D.P., McCollum, D., & Minx, J. (2015). Transport: A roadblock to climate change mitigation? Science, 350(6263), 911–912. [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] ). Because of the sector's rising contributions to climate change, considerable effort has recently been invested by researchers to try to understand if people are willing to voluntarily change their tourism and transport behaviour (e.g. Becken, 2007 Becken, S. (2007). Tourists' perception of international air travel's impact on the global climate and potential climate change policies. Journal of Sustainable Tourism, 15, 351–368. [Taylor & Francis Online]   [Google Scholar] ; Higham, Cohen, Cavaliere, Reis, & Finkler, 2016 Higham, J.E.S., Cohen, S.A., Cavaliere, C.T., Reis, A.C., & Finkler, W. (2016). Climate change, tourist air travel and radical emissions reduction. Journal of Cleaner Production, 111, 336–347. [Crossref] , [Web of Science ®]   [Google Scholar] ; Kroesen, 2013 Kroesen, M. (2013). Exploring people's viewpoints on air travel and climate change: Understanding inconsistencies. Journal of Sustainable Tourism, 21(2), 271–290. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ; Miller, Rathouse, Scarles, Holmes, & Tribe, 2010 Miller, G., Rathouse, K., Scarles, C., Holmes, K., & Tribe, J. (2010). Public understanding of sustainable tourism. Annals of Tourism Research, 37(3), 627–645. [Crossref] , [Web of Science ®]   [Google Scholar] ). The weight of evidence clearly shows that, while awareness of the impact of mobility on climate change, and particularly that of air travel, is growing, there has been little if any actual behavioural change by tourists to travel less or to change travel modes (Higham, Cohen, Peeters, & Gössling, 2013 Higham, J.E.S., Cohen, S.A., Peeters, P., & Gössling, S. (2013). Psychological and behavioural approaches to understanding and governing sustainable mobility. Journal of Sustainable Tourism, 21(7), 949–967. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ). This realisation has been captured in numerous publications evidencing or attempting to explain an awareness–attitude or attitude–behaviour gap (e.g. Antimova, Nawijn, & Peeters, 2012 Antimova, R., Nawijn, J., & Peeters, P. (2012). The awareness/attitude gap in sustainable tourism: A theoretical perspective. Tourism Review, 67(3), 7–16. [Crossref]   [Google Scholar] ; Cohen, Higham, & Reis, 2013 Cohen, S.A., Higham, J., & Reis, A. (2013). Sociological barriers to sustainable discretionary air travel behaviour. Journal of Sustainable Tourism, 21(7), 982–998. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ; Hares, Dickinson, & Wilkes, 2010 Hares, A., Dickinson, J., & Wilkes, K. (2010). Climate change and the air travel decisions of UK tourists. Journal of Transport Geography, 18(3), 466–473. [Crossref] , [Web of Science ®]   [Google Scholar] ; Juvan & Dolnicar, 2014 Juvan, E., & Dolnicar, S. (2014). The attitude-behaviour gap in sustainable tourism. Annals of Tourism Research, 48, 76–95. [Crossref] , [Web of Science ®]   [Google Scholar] ). Meanwhile, calls were sounding that the very concept of voluntary behaviour change itself was trapped within the constraints of neoliberalism (Barr, Gilg, & Shaw, 2011 Barr, S., Gilg, A., & Shaw, G. (2011). Citizens, consumers and sustainability: (Re)framing environmental practice in an age of climate change. Global Environmental Change, 21, 1224–1233. [Crossref] , [Web of Science ®]   [Google Scholar] ; Schwanen, Banister, & Anable, 2011 Schwanen, T., Banister, D., & Anable, J. (2011). Scientific research about climate change mitigation in transport: A critical review. Transportation Research Part A, 45, 993–1006. [Crossref]   [Google Scholar] ). These calls urged the academy to pay closer attention to the political, social and material systems in which consumption practices are structured, arguing that the “carbon capability” (Whitmarsh, Seyfang, & O'Neill, 2011 Whitmarsh, L., Seyfang, G., & O'Neill, S. (2011). Public engagement with carbon and climate change: To what extent is the public “carbon capable”? Global Environmental Change, 21, 56–65. [Crossref] , [Web of Science ®]   [Google Scholar] ) of the public is limited by the “systems of provision” (Hall, 2013 Hall, C.M. (2013). Framing behavioural approaches to understanding and governing sustainable tourism consumption: Beyond neoliberalism, ‘nudging’ and ‘green growth’? Journal of Sustainable Tourism, 21(7), 1091–1109. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ), which create what Schwanen et al. ( 2011 Schwanen, T., & Lucas, K. (2011). Understanding auto motives. In K. Lucas, E. Blumenberg, & R. Weinberger (Eds.), Auto motives: Understanding car use behaviours. (pp. 3–38). Emerald: Bingley. [Crossref]   [Google Scholar] ) refer to as “path dependencies”.\nA turn towards path dependencies does not suggest that attempts to achieve public behavioural change should be abandoned. Rather it emphasises that devolving the problem of tourism and transport's impacts on climate change to individuals is a limited framing. In addition to social marketing efforts aimed downstream at effecting behavioural change in publics (see Hall, in press Hall, C.M. (in press). Intervening in academic interventions: Using the lens of social marketing to examine the potential for successful sustainable tourism behavioural change. Journal of Sustainable Tourism, DOI: 10.1080/09669582.2015.1088861. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] , this issue), and a continued drive by industry towards marginal efficiency gains available in aviation technologies (Cumpsty et al., 2010 Cumpsty, N., Alonso, J., Eury, S., Maurice, L., Nas, B., Ralph, M., & Sawyer, R. (2010). Report of the independent experts on medium and long term goals for aviation fuel burn reduction from technology. Montreal: ICAO.  [Google Scholar] ; Peeters & Middel, 2007 Peeters, P.M., & Middel, J. (2007). Historical and future development of air transport fuel efficiency. In R. Sausen, A. Blum, D.S. Lee, & C. Brüning (Eds.), Proceedings of an International Conference on Transport, Atmosphere and Climate (TAC), Oxford, United Kingdom, 26–29 June 2006 (pp. 42–47). Oberpfaffenhofen: DLR Institut für Physic der Atmosphäre.  [Google Scholar] ), it is imperative that research focuses on how the radical socio-technical transitions that are necessary to put the tourism and transport sectors on a sustainable emissions path can be achieved. Technical solutions alone will be too little and too late (Chèze, Chevallier, & Gastineau, 2013 Chèze, B., Chevallier, J., & Gastineau, P. (2013). Will technological progress be sufficient to stabilize CO2 emissions from air transport in the mid-term? (No. Les cahiers de l'économie – no. 94). Rueil-Malmaison: Centre Économie et Gestion.  [Google Scholar] ; Peeters, Higham, Kutzner, Cohen, & Gössling, under review Peeters, P., Higham, J.E.S., Kutzner, D., Cohen, S., & Gössling, S. Are technology myths stalling aviation climate policy? Transportation Research Part D: Transport and Environment, under review. [Web of Science ®]   [Google Scholar] ). This includes not only a recognition that the present socio-technical landscape is dominated by neoliberal, techno-centric and ecological modernisation values (Hall, 2013 Hall, C.M. (2013). Framing behavioural approaches to understanding and governing sustainable tourism consumption: Beyond neoliberalism, ‘nudging’ and ‘green growth’? Journal of Sustainable Tourism, 21(7), 1091–1109. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ; Hopkins & Higham, 2012 Hopkins, D., & Higham, J.E.S. (2012). Framework conventions for climate change: An analysis of global framework conventions with reference to resource governance and environmental management approaches in New Zealand. In A. Holden & D. Fennell (Eds.), A handbook of tourism and the environment (pp. 227–240). London: Routledge.  [Google Scholar] ), but also the need for a concerted effort by tourism and transport researchers to become active advocates of pathways to structural change, influence policy learning and provide politicians with tools to simulate policy-making and its effects.\nThe Freiburg 2014 workshop\nThe Freiburg 2014 workshop, held in Freiburg im Breisgau in Germany (1–4 July 2014), sought to address the inability of policy-makers and other stakeholders to change the tourism mobility system towards sustainable development. Its objectives stemmed directly from the Freiburg 2012 workshop, the results of which were disseminated in the Journal of Sustainable Tourism (volume 21, issue 7; see Higham et al., 2013 Higham, J.E.S., Cohen, S.A., Peeters, P., & Gössling, S. (2013). Psychological and behavioural approaches to understanding and governing sustainable mobility. Journal of Sustainable Tourism, 21(7), 949–967. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ) and in an edited book (Cohen, Higham, Peeters, & Gössling, 2014 Cohen, S.A., Higham, J.E.S., Peeters, P., & Gössling, S. (2014). Understanding and governing sustainable tourism mobility: Psychological and behavioural approaches. London: Routledge.  [Google Scholar] ).\nA key outcome from Freiburg 2012 was the conclusion that the public are generally unwilling or unable to change tourism and transport behaviour based on an awareness of environmental impacts, and specifically climate change. It was concluded that “the autonomy of individual pro-environmental response, when set within the systems of provision in late-capitalist consumer society, is fraught with challenge” (Higham et al., 2013 Higham, J.E.S., Cohen, S.A., Peeters, P., & Gössling, S. (2013). Psychological and behavioural approaches to understanding and governing sustainable mobility. Journal of Sustainable Tourism, 21(7), 949–967. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] , p. 14) and that the “low sustainability of the current tourism system is embedded in structures that make it easy and often cheaper to travel unsustainably … raising a wide range of questions regarding transport infrastructures, taxation, management and governance” (Cohen et al. 2014 Cohen, S.A., Higham, J.E.S., Peeters, P., & Gössling, S. (2014). Understanding and governing sustainable tourism mobility: Psychological and behavioural approaches. London: Routledge.  [Google Scholar] , p. 301). This conclusion illustrated the need to move beyond voluntary behavioural change in order to achieve sustainable mobility, and to explore the socio-technical landscapes in which individuals are embedded, through which public behaviour is conditioned and patterned.\nA further crucial conclusion from Freiburg 2012 was that policy-makers had shown limited interest in adopting policy measures that would achieve significant changes in sustainable transport behaviour. This lack of political initiative, wherein it was clear that politicians have far more links to industry than to science, and particularly to the social sciences, suggested that the reasons behind the inaction in transport governance needed to be urgently and critically explored. Overall, it was evident that while a comprehensive understanding of the psychologies of tourism and transport consumption is necessary to inform policy-makers, this alone would not be enough to bring the sectors onto a climatically sustainable pathway, and that radical transitions in the systems of provision and deeper understandings of political psychologies are needed (Cohen et al., 2014 Cohen, S.A., Higham, J.E.S., Peeters, P., & Gössling, S. (2014). Understanding and governing sustainable tourism mobility: Psychological and behavioural approaches. London: Routledge.  [Google Scholar] ; Hall, 2013 Hall, C.M. (2013). Framing behavioural approaches to understanding and governing sustainable tourism consumption: Beyond neoliberalism, ‘nudging’ and ‘green growth’? Journal of Sustainable Tourism, 21(7), 1091–1109. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ; Higham et al., 2013 Higham, J.E.S., Cohen, S.A., Peeters, P., & Gössling, S. (2013). Psychological and behavioural approaches to understanding and governing sustainable mobility. Journal of Sustainable Tourism, 21(7), 949–967. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ).\nThese insights formed the basis for the Freiburg 2014 workshop, which expanded its discussions to focus on public behaviour change, but also on how to change the behaviour of policy-makers, industry stakeholders and researchers themselves, to help achieve changes in tourism and transport systems for environmental reasons. Central to this endeavour was the question of how to bridge the science–policy gap: it was abundantly clear that despite the substantial and expanding body of research on tourism and climate change (Hall et al., 2015 Hall, C.M., Amelung, B., Cohen, S., Eijgelaar, E., Gössling, S., Higham, J., … Scott, D. (2015). On climate change skepticism and denial in tourism. Journal of Sustainable Tourism, 23(1), 4–25. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ), and on transport and climate change (Schwanen, et al., 2011 Schwanen, T., & Lucas, K. (2011). Understanding auto motives. In K. Lucas, E. Blumenberg, & R. Weinberger (Eds.), Auto motives: Understanding car use behaviours. (pp. 3–38). Emerald: Bingley. [Crossref]   [Google Scholar] ), this corpus of knowledge was having little to no effect in practice on governance.\nThe Freiburg 2014 workshop is the basis for this special issue presenting 10 papers, including this overview paper, exploring the dimensions and details of the science–policy gap in sustainable mobility. Having established the context in which the workshop was set, and before introducing the papers in this special issue, we now discuss three essential themes that are vital to understanding why, despite clear scientific evidence as to the growing environmental impacts of tourism transport, and particularly air travel, there is large-scale inertia in structural transitions and a lack of political willpower to enact meaningful policy change: (1) the importance of addressing socio-technical factors, (2) the barriers posed by placing faith in “technology myths” and (3) the need to overcome “transport taboos” in policy-making. The paper concludes by setting a research agenda that forms the basis for the forthcoming Freiburg 2016 workshop (28 June to 1 July 2016).\nSocio-technical factors\nCurrent growth trajectories indicate that transport emissions will double by 2050: the global fleet of light-duty vehicles is expected to double during that time period, and “demand for freight transport (road, rail, shipping, and air) and passenger aviation is projected to surge as well” (Creutzig et al., 2015 Creutzig, F., Jochem, P., Edelenbosch, O.Y., Mattauch, L., van Vuuren, D.P., McCollum, D., & Minx, J. (2015). Transport: A roadblock to climate change mitigation? Science, 350(6263), 911–912. [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] , p. 911). Air travel in particular offers an example of largely intractable public travel behaviours that are entrenched in Europe and North America and being rapidly adopted in the emerging regions of the world (Freire-Medeiros & Name, 2013 Freire-Medeiros, B., & Name, L. (2013). Flying for the very first time: Mobilities, social class and environmental concerns in a Rio de Janeiro favela. Mobilities, 8(2), 167–184. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ; Higham, Cohen, & Cavaliere, 2014 Higham, J., Cohen, S., & Cavaliere, C. (2014). Climate change, discretionary air travel and the ‘flyers’ dilemma'. Journal of Travel Research, 53(4), 462–475. [Crossref] , [Web of Science ®]   [Google Scholar] ). The development of low-cost, high-volume aviation, initially in Europe and North America, and latterly in Brazil, Russia, India and China, is now powering similar air travel growth trajectories in the emerging neoliberal economies of Mexico, South Africa, Indonesia and Turkey (Boeing, 2014 Boeing. (2014). Current market outlook 2014-2033. Seattle, WA: Boeing Commercial Airplanes.  [Google Scholar] ). Growth in air travel over the last two decades has been rapid (Gössling & Upham, 2009 Gössling, S., & Upham, P. (Eds.). (2009). Climate change and aviation: Issues, challenges and solutions. London: Earthscan.  [Google Scholar] ), and the current growth trajectory is projected to continue at a rate of 3.3% per annum to 2030 (Hall, 2013 Hall, C.M. (2013). Framing behavioural approaches to understanding and governing sustainable tourism consumption: Beyond neoliberalism, ‘nudging’ and ‘green growth’? Journal of Sustainable Tourism, 21(7), 1091–1109. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ).\nCalls for tourism to move onto a sustainable emissions path (Becken, 2007 Becken, S. (2007). Tourists' perception of international air travel's impact on the global climate and potential climate change policies. Journal of Sustainable Tourism, 15, 351–368. [Taylor & Francis Online]   [Google Scholar] ) have been especially challenged by growing demand for air travel. This growth has been driven by significant structural changes in the transportation sector (Ryley, Davison, Bristow, & Pridmore, 2010 Ryley, T., Davison, L., Bristow, A., & Pridmore, A. (2010). Public engagement on aviation taxes in the United Kingdom. International Journal of Sustainable Transportation, 4(2), 112–128. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ). Neoliberalism has been embraced by the aviation industry through airline deregulation, the deployment of frequent flyer loyalty programmes and notably by the unrestrained growth of low-cost carriers (LCCs) (Duval, 2013 Duval, D.T. (2013). Critical issues in air transport and tourism. Tourism Geographies, 15(3), 494–510. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ). Network airlines offering full service and traditional routes have been drawn into intense competition with LCCs, transforming the travel market through the uptake of technology to substantially reduce labour costs (Holloway, Humphreys, & Davidson, 2009 Holloway, J.C., Humphreys, C., & Davidson, R. (2009). The business of tourism (8th ed.). Harlow: Pearson Education.  [Google Scholar] ). The LCCs have developed direct sales systems (i.e. internet booking systems), online check-in and product itemisation (e.g. priority boarding, seat allocation, baggage allowances, in-flight food and entertainment services) to de-personalise airport and air travel experiences, while increasing aircraft utilisation and flight loadings, while reducing fares (Boeing, 2014 Boeing. (2014). Current market outlook 2014-2033. Seattle, WA: Boeing Commercial Airplanes.  [Google Scholar] ; Casey, 2010 Casey, M.E. (2010). Low cost air travel: Welcome aboard? Tourist Studies, 10(2), 175–191. [Crossref]   [Google Scholar] ). The LCC business model includes operating with a single aircraft type, providing a single-class product, serving secondary airports and avoiding the costs of frequent flyer programmes (Boeing, 2014 Boeing. (2014). Current market outlook 2014-2033. Seattle, WA: Boeing Commercial Airplanes.  [Google Scholar] ).\nThe consequential growth in demand for low-cost air travel is recognised as “one of the biggest revolutions in tourism and travel since the package holiday's arrival half a century earlier” (Casey, 2010 Casey, M.E. (2010). Low cost air travel: Welcome aboard? Tourist Studies, 10(2), 175–191. [Crossref]   [Google Scholar] , p. 176). The success of the LCCs is reflected in the increasingly ordinary nature of air travel in certain sections of some societies (Randles & Mander, 2009a Randles, S., & Mander, S. (2009a). Practice(s) and ratchet(s): A sociological examination of frequent flying. In S. Gössling & P. Upham (Eds.), Climate change and aviation: Issues, challenges and solutions (pp. 245–271). London: Earthscan.  [Google Scholar] ; Urry, 2010 Urry, J. (2010). Sociology and climate change. The Sociological Review, 57(2), 84–100. [Crossref]   [Google Scholar] ). New structures of air travel provision have created flying as a highly accessible consumer product, shifting leisure travel into the domain of everyday consumer capitalism (Young, Higham, & Reis, 2014 Young, M., Higham, J.E.S., & Reis, A. (2014). Up in the air: A conceptual critique of flying addiction. Annals of Tourism Research, 41, 51–64. [Crossref] , [Web of Science ®]   [Google Scholar] ). Indeed the extent to which these structures have shaped and influenced everyday consumer practices has, in some cases, reached absurd proportions. Ben Schlappig – “the man who flies around the world for free” – is “… one of the biggest stars among an elite group of obsessive flyers whose mission is to outwit the airlines” (Wofford, 2015 Wofford, B. (2015). Up in the air: Meet the man who flies around the world for free. Rolling Stone Magazine, 20 July 2014.  [Google Scholar] , p. 3). Perfecting the art of “travel hacking” – known among its members as “The Hobby” – Schlappig seeks perfection in the art of non-stop air travel and consumer luxury that is paid for by a “… gargantuan cache of frequent flier miles that grows only bigger by the day” (Wofford, 2015 Wofford, B. (2015). Up in the air: Meet the man who flies around the world for free. Rolling Stone Magazine, 20 July 2014.  [Google Scholar] , p. 5). Schlappig's claim is to be “beating the airlines at their own game”; through the gaming of frequent flyer programmes using techniques that he shares with a half million strong following through the “FlyerTalk” website.\nThe gaming of frequent flyer programmes offers an, albeit extreme, insight into consumer air travel behaviour that is anchored in and enabled by the socio-technical system. It forms part of a wider pattern of increasing affordability and uptake of air travel across an expanding range of social classes and societies (Randles & Mander, 2009b Randles, S., & Mander, S. (2009b). Aviation, consumption and the climate change debate: ‘Are you going to tell me off for flying?’ Technology Analysis & Strategic Management, 21(1), 93–113. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ). It is this growth in demand for air travel that contributes significantly to driving up tourism transport emissions (Gössling & Peeters, 2015 Gössling, S., & Peeters, P. (2015). Assessing tourism's global environmental impact 1900–2050. Journal of Sustainable Tourism, 23(5), 639–659. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ). With current and projected growth in aviation emissions has come recognition that the freedom to engage in unrestrained air travel comes with significant environmental costs (IPCC, 2013 IPCC. (2013). Climate change 2013: The physical science basis. Retrieved 28 November 2013 from IPCC web site: http://www.ipcc.ch/report/ar5/wg1/#.Uu70df0p8ds  [Google Scholar] ). While the environmental costs of air travel are now widely understood and accepted by the travelling public, the necessary responses in terms of consumer demand have not followed (Gössling, 2009 Gössling, S., & Upham, P. (Eds.). (2009). Climate change and aviation: Issues, challenges and solutions. London: Earthscan.  [Google Scholar] ; Higham, Cohen, Peeters, & Gössling, 2013 Higham, J.E.S., Cohen, S.A., Peeters, P., & Gössling, S. (2013). Psychological and behavioural approaches to understanding and governing sustainable mobility. Journal of Sustainable Tourism, 21(7), 949–967. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ).\nIt is ironic that the increasingly aeromobile middle classes can be the same people who claim to be environmentally aware and moral consumers (Dolnicar, Juvan, Ring, & Leisch, in press Dolnicar, S., Juvan, E., Ring, A. & Leisch, F. (in press). Tourist segments' justifications for behaving in an environmentally unsustainable way. Journal of Sustainable Tourism, DOI: 10.1080/09669582.2015.10248861 [Crossref] , [Web of Science ®]   [Google Scholar] ; Young et al., 2014 Young, M., Higham, J.E.S., & Reis, A. (2014). Up in the air: A conceptual critique of flying addiction. Annals of Tourism Research, 41, 51–64. [Crossref] , [Web of Science ®]   [Google Scholar] ). Within the context of air travel the “flyers’ dilemma” describes the tension between the self-identity of consumers who feel moral responsibility for their consumer decisions, and the high environmental costs of flying (Higham, Cohen, & Cavaliere, 2014 Higham, J., Cohen, S., & Cavaliere, C. (2014). Climate change, discretionary air travel and the ‘flyers’ dilemma'. Journal of Travel Research, 53(4), 462–475. [Crossref] , [Web of Science ®]   [Google Scholar] ; Rosenthal, 2010 Rosenthal, E. (2010, May 24). Can we kick our addiction to flying? Retrieved 13 September 2010 from The Guardian web site: http://www.guardian.co.uk/environment/2010/may/24/kick-addiction-flying/  [Google Scholar] ). The anxieties arising from the “flyers’ dilemma” have been empirically examined in various European societies (Higham, et al., 2016 Higham, J.E.S., Cohen, S.A., Cavaliere, C.T., Reis, A.C., & Finkler, W. (2016). Climate change, tourist air travel and radical emissions reduction. Journal of Cleaner Production, 111, 336–347. [Crossref] , [Web of Science ®]   [Google Scholar] ). Various studies have highlighted that air travel practices are largely unconstrained because flying is a cheap, convenient and socially desirable form of leisure consumption (Cohen & Higham, 2011 Cohen, S.A., & Higham, J.E.S. (2011). Eyes wide shut? UK consumer perceptions on aviation climate impacts and travel decisions to New Zealand. Current Issues in Tourism, 14(4), 323–335. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ; Higham & Cohen, 2011 Higham, J.E.S., & Cohen, S.A. (2011). Canary in the coalmine: Norwegian attitudes towards climate change and extreme long-haul air travel to Aotearoa/New Zealand. Tourism Management, 32(1), 98–105. [Crossref] , [Web of Science ®]   [Google Scholar] ).\nIt emerges that a focus on the demand-side of travel, in an attempt to address issues of sustainability through behaviour change, should not ignore the fundamental socio-structural factors that underpin the tourism system (Cornelissen, 2005 Cornelissen, S. (2005). The global tourism system. Aldershot: Ashgate.  [Google Scholar] ). Young, Markham, Reis, and Higham ( 2015 Young, M., Markham, F., Reis, A.C., & Higham, J.E.S. (2015). Flights of fantasy: A reformulation of the flyers' dilemma. Annals of Tourism Research, 54, 1–15. [Crossref] , [Web of Science ®]   [Google Scholar] ) argue that the locus of responsibility is critical to debates around sustainable aviation and sustainable mobility more broadly. Hall ( 2013 Hall, C.M. (2013). Framing behavioural approaches to understanding and governing sustainable tourism consumption: Beyond neoliberalism, ‘nudging’ and ‘green growth’? Journal of Sustainable Tourism, 21(7), 1091–1109. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] , p. 1101) observes that “mutual reinforcement between modes of governance and intervention … creates a path dependency in which solutions to sustainable tourism mobility are only identified within ‘green growth’ arguments for greater efficiency and market-based solutions.” Hall ( 2013 Hall, C.M. (2013). Framing behavioural approaches to understanding and governing sustainable tourism consumption: Beyond neoliberalism, ‘nudging’ and ‘green growth’? Journal of Sustainable Tourism, 21(7), 1091–1109. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ) argues that as long as the focus of government tourism policies remains situated in a GDP growth paradigm, the structures of transport provision will remain unchanged and the environment required to empower a consumer-led shift to a sustainable transport emissions path will not exist.\nYoung et al. ( 2015 Young, M., Markham, F., Reis, A.C., & Higham, J.E.S. (2015). Flights of fantasy: A reformulation of the flyers' dilemma. Annals of Tourism Research, 54, 1–15. [Crossref] , [Web of Science ®]   [Google Scholar] ) suggest that appealing to individuals to reduce or otherwise moderate their tourist travel consumption practices is a flawed response. It lacks the necessary government policy response to an industry that is environmentally damaging. Appealing to consumer sacrifice ignores the fundamental socio-structural underpinnings of an unsustainable travel industry. Young et al. ( 2015 Young, M., Markham, F., Reis, A.C., & Higham, J.E.S. (2015). Flights of fantasy: A reformulation of the flyers' dilemma. Annals of Tourism Research, 54, 1–15. [Crossref] , [Web of Science ®]   [Google Scholar] ) critically consider the social, institutional and economic forces that produce excessive and unsustainable travel consumption. They highlight, first and foremost, that within the existing structures of the aviation industry, currently no alternative options are available to avoid the high environmental costs of air travel (Young et al., 2014 Young, M., Higham, J.E.S., & Reis, A. (2014). Up in the air: A conceptual critique of flying addiction. Annals of Tourism Research, 41, 51–64. [Crossref] , [Web of Science ®]   [Google Scholar] ). No low-emission form of aviation exists to serve flyers who are concerned about climate change and aviation emissions (Peeters & Middel, 2007 Peeters, P.M., & Middel, J. (2007). Historical and future development of air transport fuel efficiency. In R. Sausen, A. Blum, D.S. Lee, & C. Brüning (Eds.), Proceedings of an International Conference on Transport, Atmosphere and Climate (TAC), Oxford, United Kingdom, 26–29 June 2006 (pp. 42–47). Oberpfaffenhofen: DLR Institut für Physic der Atmosphäre.  [Google Scholar] ), and neither is there any real prospect of major gains in aviation fuel efficiency in the short–medium term future (Peeters et al., under review) Peeters, P., Higham, J.E.S., Kutzner, D., Cohen, S., & Gössling, S. Are technology myths stalling aviation climate policy? Transportation Research Part D: Transport and Environment, under review. [Web of Science ®]   [Google Scholar] .\nWhile the airline industry has made significant gains in efficiency since the advent of jet aviation (Peeters & Dubois, 2010 Peeters, P., & Dubois, G. (2010). Tourism travel under climate change mitigation constraints. Journal of Transport Geography, 18(3), 447–457. [Crossref] , [Web of Science ®]   [Google Scholar] ), current technologies are locked in for periods of time that reach well beyond the urgent time frame required to achieve radical emission reductions (Higham et al., 2016 Higham, J.E.S., Cohen, S.A., Cavaliere, C.T., Reis, A.C., & Finkler, W. (2016). Climate change, tourist air travel and radical emissions reduction. Journal of Cleaner Production, 111, 336–347. [Crossref] , [Web of Science ®]   [Google Scholar] ). Jet aviation is highly efficient in terms of time/distance/cost thresholds (Howitt, Revol, Smith, & Rodger, 2010 Howitt, O.J.A., Revol, V.G.N., Smith, I.J., & Rodger, C.J. (2010). Carbon emissions from international cruise ship passengers' travel to and from New Zealand. Energy Policy, 38, 2552–2560. [Crossref] , [Web of Science ®]   [Google Scholar] ), but those energy efficiencies have been overwhelmed in real terms by growth in demand (Peeters & Dubois, 2010 Peeters, P., & Dubois, G. (2010). Tourism travel under climate change mitigation constraints. Journal of Transport Geography, 18(3), 447–457. [Crossref] , [Web of Science ®]   [Google Scholar] ), such that the environmental costs of air travel have become unacceptably high (Gössling, Hall, Peeters, and Scott 2010 Scott, D., Peeters, P. & Gössling, S. (2010). Can tourism deliver its aspiration greenhouse gas emission reduction targets? Journal of Sustainable Tourism, 18(3), 393–408. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ; Hall, 2013 Hall, C.M. (2013). Framing behavioural approaches to understanding and governing sustainable tourism consumption: Beyond neoliberalism, ‘nudging’ and ‘green growth’? Journal of Sustainable Tourism, 21(7), 1091–1109. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ). The current structure of the aviation industry and the absence of further substantial technical gains in aircraft efficiency (Scott, Peeters, & Gössling, 2010 Scott, D. (2016). The Paris Climate Change Conference and the tourism industry. Journal of Sustainable Tourism, under review  [Google Scholar] ) are such that aviation emissions are expected to double within a 25–45 year time frame (Gössling & Peeters, 2015 Gössling, S., & Peeters, P. (2015). Assessing tourism's global environmental impact 1900–2050. Journal of Sustainable Tourism, 23(5), 639–659. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ).\nDespite growing sustainability concerns, aviation, like the automobile (Dennis & Urry, 2009 Dennis, K., & Urry, J. (2009). After the car. Cambridge: John Wiley & Sons.  [Google Scholar] ), has become an integral part of contemporary mobility in many societies (Sheller & Urry, 2004 Sheller, M., & Urry, J. (Eds.). (2004). Tourism mobilities: Places to play, places in play. London: Routledge.  [Google Scholar] ; Urry, 2012 Urry, J. (2012). Social networks, mobile lives and social inequalities. Journal of Transport Geography, 21, 24–30. [Crossref] , [Web of Science ®]   [Google Scholar] ). Flying now out-competes other transport modes not only on convenience and time efficiency but – most critically – in terms of cost (Casey, 2010 Casey, M.E. (2010). Low cost air travel: Welcome aboard? Tourist Studies, 10(2), 175–191. [Crossref]   [Google Scholar] ). The time, cost and convenience advantages of air travel are structural factors that explain the deeply embedded nature of air travel practices (Higham, Cohen, & Cavaliere, 2014 Higham, J., Cohen, S., & Cavaliere, C. (2014). Climate change, discretionary air travel and the ‘flyers’ dilemma'. Journal of Travel Research, 53(4), 462–475. [Crossref] , [Web of Science ®]   [Google Scholar] ). The aviation system allows the production of tourism (and other forms of mobility) to be accelerated in terms of fit within the capitalist working day, week and calendar year (Young et al., 2015 Young, M., Markham, F., Reis, A.C., & Higham, J.E.S. (2015). Flights of fantasy: A reformulation of the flyers' dilemma. Annals of Tourism Research, 54, 1–15. [Crossref] , [Web of Science ®]   [Google Scholar] ). Given the fundamentally energy-intensive nature of the tourism system (Becken, 2016 Becken, S. (2016). Peak oil: A hidden issue? Social representations of professional tourism perspectives. Journal of Sustainable Tourism, 24(1), 31–51. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ), mitigating tourism transport emissions has proved a very imposing challenge (Schwanen et al., 2011 Schwanen, T., & Lucas, K. (2011). Understanding auto motives. In K. Lucas, E. Blumenberg, & R. Weinberger (Eds.), Auto motives: Understanding car use behaviours. (pp. 3–38). Emerald: Bingley. [Crossref]   [Google Scholar] ). Not least, neither car nor rail nor even high-speed rail can match the cost, convenience and flexibility of response that air travel can, especially if sea crossings are involved.\nIt is also apparent that travellers, even those who are concerned about their personal leisure travel emissions, are able to disregard their environmental concerns and take advantage of cheap and convenient air travel opportunities (Higham et al., 2016 Higham, J.E.S., Cohen, S.A., Cavaliere, C.T., Reis, A.C., & Finkler, W. (2016). Climate change, tourist air travel and radical emissions reduction. Journal of Cleaner Production, 111, 336–347. [Crossref] , [Web of Science ®]   [Google Scholar] ; Young et al., 2015 Young, M., Markham, F., Reis, A.C., & Higham, J.E.S. (2015). Flights of fantasy: A reformulation of the flyers' dilemma. Annals of Tourism Research, 54, 1–15. [Crossref] , [Web of Science ®]   [Google Scholar] ). Even for those who are deeply concerned about climate change (see Cohen, & Higham, 2011 Cohen, S.A., & Higham, J.E.S. (2011). Eyes wide shut? UK consumer perceptions on aviation climate impacts and travel decisions to New Zealand. Current Issues in Tourism, 14(4), 323–335. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ; Higham & Cohen, 2011 Higham, J.E.S., & Cohen, S.A. (2011). Canary in the coalmine: Norwegian attitudes towards climate change and extreme long-haul air travel to Aotearoa/New Zealand. Tourism Management, 32(1), 98–105. [Crossref] , [Web of Science ®]   [Google Scholar] ), the time and costs advantages of air travel undermine the competitiveness of alternative, more sustainable transport modes (Higham et al., 2014 Higham, J., Cohen, S., & Cavaliere, C. (2014). Climate change, discretionary air travel and the ‘flyers’ dilemma'. Journal of Travel Research, 53(4), 462–475. [Crossref] , [Web of Science ®]   [Google Scholar] ). The time/distance/cost dimensions of air travel have also allowed the consumption of distant tourist destinations to fit within narrow windows of time (e.g. the EasyJet generation of weekend “escape artists”). The act of flying has become integral to significant parts of the contemporary tourism transport system (Young et al., 2015 Young, M., Markham, F., Reis, A.C., & Higham, J.E.S. (2015). Flights of fantasy: A reformulation of the flyers' dilemma. Annals of Tourism Research, 54, 1–15. [Crossref] , [Web of Science ®]   [Google Scholar] ).\nAs Young et al. ( 2014 Young, M., Higham, J.E.S., & Reis, A. (2014). Up in the air: A conceptual critique of flying addiction. Annals of Tourism Research, 41, 51–64. [Crossref] , [Web of Science ®]   [Google Scholar] ) observe, aviation has proven to be resistant to consumer-led change, in contrast to other aspects of consumer behaviour, such as food purchases, recycling, the use of public land transport and the conscious uptake of active transport modes, which are relatively open to modification by individuals (Barr, Shaw, Coles, & Prillwitz, 2010 Barr, S., Shaw, G., Coles, T., & Prillwitz, J. (2010). ‘A holiday is a holiday’: Practicing sustainability, home and away. Journal of Transport Geography, 18(3), 474–481. [Crossref] , [Web of Science ®]   [Google Scholar] ; Lassen, 2010 Lassen, C. (2010). Environmentalist in business class: An analysis of air travel and environmental attitude. Transport Reviews, 30(6), 733–751. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ). The intractability of air travel behaviour change occurs not only because air travel has become a desirable and affordable gateway to tourism in many societies (Casey, 2010 Casey, M.E. (2010). Low cost air travel: Welcome aboard? Tourist Studies, 10(2), 175–191. [Crossref]   [Google Scholar] ), but also because “… the environmental risks associated with air travel are global and systemic, as opposed to specific and individual, and tend not to be prioritised within a flyers' environmental consciousness” (Young et al., 2014 Young, M., Higham, J.E.S., & Reis, A. (2014). Up in the air: A conceptual critique of flying addiction. Annals of Tourism Research, 41, 51–64. [Crossref] , [Web of Science ®]   [Google Scholar] , p. 60). As a result climate concerns may be temporarily suspended with impunity so that consumers can continue to consume leisure travel that involves flying (Watson, 2014 Watson, C. (Ed.). (2014). Beyond flying: Rethinking air travel in a globally connected world. Cambridge: Green Books.  [Google Scholar] ).\nThe current structures of aviation provision foster the willingness of the public to temporarily suspend their climate concerns when engaging in tourism practices (Barr et al., 2010 Barr, S., Shaw, G., Coles, T., & Prillwitz, J. (2010). ‘A holiday is a holiday’: Practicing sustainability, home and away. Journal of Transport Geography, 18(3), 474–481. [Crossref] , [Web of Science ®]   [Google Scholar] ; Cohen, Higham, & Reis, 2013 Cohen, S.A., Higham, J., & Reis, A. (2013). Sociological barriers to sustainable discretionary air travel behaviour. Journal of Sustainable Tourism, 21(7), 982–998. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ). The aviation industry facilitates a range of spatio-temporal fixes (Young et al., 2014 Young, M., Higham, J.E.S., & Reis, A. (2014). Up in the air: A conceptual critique of flying addiction. Annals of Tourism Research, 41, 51–64. [Crossref] , [Web of Science ®]   [Google Scholar] ) that invite the consumer to offset their aviation carbon emissions through various schemes (Barr et al., 2010 Barr, S., Shaw, G., Coles, T., & Prillwitz, J. (2010). ‘A holiday is a holiday’: Practicing sustainability, home and away. Journal of Transport Geography, 18(3), 474–481. [Crossref] , [Web of Science ®]   [Google Scholar] ; Gössling et al., 2007 Gössling, S., Broderick, J., Upham, P., Peeters, P., Strasdas, W., Ceron, J.-P., & Dubois, G. (2007). Voluntary carbon offsetting schemes for aviation: Efficiency and credibility. Journal of Sustainable Tourism, 15(3), 223–248. [Taylor & Francis Online]   [Google Scholar] ). Offset schemes encourage concerned travellers to assume responsibility for a profligate industry, by incurring an additional cost to mitigate the externalities of aviation consumption (Young et al., 2014 Young, M., Higham, J.E.S., & Reis, A. (2014). Up in the air: A conceptual critique of flying addiction. Annals of Tourism Research, 41, 51–64. [Crossref] , [Web of Science ®]   [Google Scholar] ). In doing so offsetting “… actually plays into the hands of an environmentally destructive industry by allowing it to legitimate its practices while simultaneously absolving itself from responsibility for the environmental destruction from which it profits” (Young et al., 2014 Young, M., Higham, J.E.S., & Reis, A. (2014). Up in the air: A conceptual critique of flying addiction. Annals of Tourism Research, 41, 51–64. [Crossref] , [Web of Science ®]   [Google Scholar] , p. 52). This absolution of individual responsibility is an important factor in the accelerating aviation emissions problem (Creutzig et al., 2015 Creutzig, F., Jochem, P., Edelenbosch, O.Y., Mattauch, L., van Vuuren, D.P., McCollum, D., & Minx, J. (2015). Transport: A roadblock to climate change mitigation? Science, 350(6263), 911–912. [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] ). It relates closely to what Hall ( 2013 Hall, C.M. (2013). Framing behavioural approaches to understanding and governing sustainable tourism consumption: Beyond neoliberalism, ‘nudging’ and ‘green growth’? Journal of Sustainable Tourism, 21(7), 1091–1109. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ) refers to as “structures of provision”; the social and institutional structures that underpin unsustainable consumption practices. Expecting the consumer to accept responsibility and respond individually to unsustainable contemporary travel mobilities, in the absence of meaningful industry and policy responses, has proven to be futile (Higham et al., 2016 Higham, J.E.S., Cohen, S.A., Cavaliere, C.T., Reis, A.C., & Finkler, W. (2016). Climate change, tourist air travel and radical emissions reduction. Journal of Cleaner Production, 111, 336–347. [Crossref] , [Web of Science ®]   [Google Scholar] ).\nTechnology myths\nA further vital reason why there is inertia in policy responses to growing aviation emissions is the ongoing industry-led myth, perpetuated by the media and transport policy-makers, that decarbonisation is in progress using radical technological innovation. Gotesky ( 1952 Gotesky, R. (1952). The nature of myth and society. American Anthropologist, 54(4), 523–531. [Crossref] , [Web of Science ®]   [Google Scholar] , p. 530) describes the function of a myth as to “preserve institutions and institutional process”. A “myth” is defined as an idea, story or narrative believed by many people, including decision-makers, even though unfounded or false. As Edelman ( 1998 Edelman, M. (1998). Language, myths and rhetoric. Society, 35(2), 131–139. [Crossref] , [Web of Science ®]   [Google Scholar] , p. 131) reminds us, “[p]olitical language can evoke a set of mythic beliefs in subtle and powerful ways.” Misleading information from the transport and tourism sectors is not new. Gössling and Peeters ( 2007 Gössling, S., Broderick, J., Upham, P., Peeters, P., Strasdas, W., Ceron, J.-P., & Dubois, G. (2007). Voluntary carbon offsetting schemes for aviation: Efficiency and credibility. Journal of Sustainable Tourism, 15(3), 223–248. [Taylor & Francis Online]   [Google Scholar] , p. 402), found four major industry discourses: “air travel is energy efficient; air travel's share of total emissions is negligible; fuel use is constantly minimised and new technology will solve the problem.” All four were deconstructed as being not representative of reality. This section explores the existence and role of “technology myths” in the discourse of sustainable aviation.\nMyths also play a role in other transport modes. Within automobility, for instance, Volkswagen created a green myth around low-emission diesel cars, even though this was largely based on cheating regulations (Franco, Sánchez, German, & Mock, 2014 Franco, V., Sánchez, F.P., German, J., & Mock, P. (2014). Real-world exhaust emissions from modern diesel cars. Berlin: International Council on Clean Transportation Europe.  [Google Scholar] ). So why concentrate on aviation within the domain of sustainable tourism? First because the tourism sector is a central part of passenger aviation, although we cannot be sure exactly how central it is: leisure travel is interlinked with business travel, visiting friends and relatives and other visit motivations. The tourism sector consequently needs to be seen as integral to air transport; the tourism industry cannot be absolved of responsibility for aviation emissions more generally.\nThe second reason is that air transport, though a relatively small part of tourism in terms of total trips (19% in 2010), represents a high share (52% in 2010) of tourism's global emissions, a share that is growing (62% in 2015), which means that aviation's emissions are increasing faster than those of accommodation, car and rail (Gössling & Peeters, 2015 Gössling, S., & Peeters, P. (2015). Assessing tourism's global environmental impact 1900–2050. Journal of Sustainable Tourism, 23(5), 639–659. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ). There is a large body of literature showing that future emissions of aviation are growing fast and that this growth is inevitable given transport volume growth projections (Mayor & Tol, 2010 Mayor, K., & Tol, R.S.J. (2010). Scenarios of carbon dioxide emissions from aviation. Global Environmental Change, 20(1), 65–73. [Crossref] , [Web of Science ®]   [Google Scholar] ; Owen, Lee, & Lim, 2010 Owen, B., Lee, D.S., & Lim, L. (2010). Flying into the future: Aviation emissions scenarios to 2050. Environmental Science & Technology, 44(7), 2255–2260. [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] ; Peeters & Dubois, 2010 Peeters, P., & Dubois, G. (2010). Tourism travel under climate change mitigation constraints. Journal of Transport Geography, 18(3), 447–457. [Crossref] , [Web of Science ®]   [Google Scholar] ; Sgouridis, Bonnefoy, & Hansman, 2010 Sgouridis, S., Bonnefoy, P.A., & Hansman, R.J. (2010). Air transportation in a carbon constrained world: Long-term dynamics of policies and strategies for mitigating the carbon footprint of commercial aviation. Transportation Research Part A: Policy and Practice, 45(10), 1077–1091. [Crossref] , [Web of Science ®]   [Google Scholar] ; Vorster, Ungerer, & Volschenk, 2012 Vorster, S., Ungerer, M., & Volschenk, J. (2012). 2050 scenarios for long-haul tourism in the evolving global climate change regime. Sustainability, 5(1), 1–51. [Crossref] , [Web of Science ®]   [Google Scholar] ).\nFrom a recent study (Peeters et al., under review) Peeters, P., Higham, J.E.S., Kutzner, D., Cohen, S., & Gössling, S. Are technology myths stalling aviation climate policy? Transportation Research Part D: Transport and Environment, under review. [Web of Science ®]   [Google Scholar] it was found that the aviation industry creates “technology myths” that may hamper political initiatives that would enforce mitigation on the aviation sector. Industry commonly wields terms such as “efficiency”, “constantly minimised” or “negligible shares” as discursive devices to perpetuate the myth that technological innovation will neutralise the problem of aviation emissions. Technology myths were identified by Peeters et al. ( under review Peeters, P., Higham, J.E.S., Kutzner, D., Cohen, S., & Gössling, S. Are technology myths stalling aviation climate policy? Transportation Research Part D: Transport and Environment, under review. [Web of Science ®]   [Google Scholar] ) for airframe design (laminar flow, composite structures and blended wing body), engines/propulsion (solar flight, electric flight and propfan) and alternative fuels (Jatropha, animal fats, hydrogen and micro-algae). For these 10 technologies media coverage in newspapers was measured over the past two decades and content analysed.\nLaminar flow and composite structures are widely applied already, with the newest types of planes, like the Boeing B787 and Airbus A350, using, for instance, composites in up to 50% of the construction by weight (Lee, 2010 Lee, J.J. (2010). Can we accelerate the improvement of energy efficiency in aircraft systems? Energy Conversion and Management, 51(1), 189–196. [Crossref] , [Web of Science ®]   [Google Scholar] ). But composite structures allow for weight savings of between 14% and 25% (Raymer et al., 2011 Raymer, D.P., Wilson, J., Perkins, H.D., Rizzi, A., Zhang, M., & Puentes, A.R. (2011). Advanced technology subsonic transport study n+3 technologies and design concepts (No. NASA/TM-2011-217130). Cleveland, OH: Glenn Research Center.  [Google Scholar] ) for the structure to which it is applied. So overall weight reduction of the Boeing B787 would be between 7% and 13%. The impact of this weight savings on fuel efficiency depends on how the designer uses the gains, but it may translate in the end to an approximate 5% fuel efficiency improvement (Peeters, 2000 Peeters, P., & Dubois, G. (2010). Tourism travel under climate change mitigation constraints. Journal of Transport Geography, 18(3), 447–457. [Crossref] , [Web of Science ®]   [Google Scholar] ). This Boeing 787 example clearly shows the strength of myths: the impressive 50% share of new materials is hyped in the media to a lay audience and impressed upon politicians, even though composite structures only offer small and evolutionary efficiency improvements, although coupled with improved engine design and materials, the Boeing 787 and Airbus A350 can offer fuel savings of up to 25% per seat mile over the 15–20 year old aircraft that they are replacing. The latter is an impressive figure, but it also means that fares can be reduced, encouraging more people to travel.\nBlended wing body aircraft have a long history of promises but have never emerged and are unlikely to in the near to mid-term future, or even later. Solar flight has recently attracted much attention. Basic physics tells us that it will never play a serious transport role (Noth, 2008 Noth, A. (2008). Design of solar powered airplanes for continuous flight (Unpublished PhD). ETH Zürich.  [Google Scholar] ), but the ICAO ( 2014 ICAO. (2014). 2013 environmental report. Destination green. Montreal: Author.  [Google Scholar] , p. 12) propagates discourses suggesting that it could solve environmental problems: “the Solar Impulse demonstrated that a solar-powered airplane can fly day and night without fuel.” Public interest in electric flight has followed the same strong rise since the mid-2000s. The main issue with electric flight is the requirement for high performance batteries. Current lithium batteries have a power density that falls short of the requirements for full electric flight by a factor of 100 (Kivits, Charles, & Ryan, 2010 Kivits, R., Charles, M.B., & Ryan, N. (2010). A post-carbon aviation future: Airports and the transition to a cleaner aviation sector. Futures, 42, 199–211. [Crossref] , [Web of Science ®]   [Google Scholar] ). This makes the anticipated 2035 realisation of electric flight (The Australian, 2/11/2012), extremely unlikely.\nOf the four alternative fuels, Jatropha, animal fats and hydrogen were hyped by the media between 2008 and 2011 but are now little mentioned, with significant interest only in micro-algae. Still the sector widely cites alternative fuels as promising future replacements for fossil fuels (Air Transport Action Group [ATAG], 2011 Air Transport Action Group (ATAG). (2011). Powering the future of flight. The six easy steps to growing a viable aviation biofuels industry. Geneva: Author.  [Google Scholar] ; Airbus, 2011 Airbus. (2011). Delivering the future. Global market forecast 2011–2030. Paris: Author.  [Google Scholar] ; Boeing, 2012 Boeing. (2012). Current market outlook 2012-2031. Seattle, WA. Boeing Commercial Airplanes.  [Google Scholar] ; IATA, 2012 IATA. (2012). A global approach to reducing aviation emissions. First stop: Carbon-neutral growth from 2020. Montreal: Author.  [Google Scholar] ; ICAO, 2014 ICAO. (2014). 2013 environmental report. Destination green. Montreal: Author.  [Google Scholar] ; WTTC, 2009 WTTC. (2009). Leading the challenge on climate change. London: Author.  [Google Scholar] ). Jatropha faces issues of high water use (Rosillo-Calle, Thrän, Seiffert, & Teelucksingh, 2012 Rosillo-Calle, F., Thrän, D., Seiffert, M., & Teelucksingh, S. (2012). The potential role of biofuels in commercial air transport – biojetfuel. London: IEA Bioenergy Task 40 Sustainable International Bioenergy Trade.  [Google Scholar] ) and adverse socio-economic impacts (Ariza-Montobbio & Lele, 2010 Ariza-Montobbio, P., & Lele, S. (2010). Jatropha plantations for biodiesel in Tamil Nadu, India: Viability, livelihood trade-offs, and latent conflict. Ecological Economics, 70, 189–195. [Crossref] , [Web of Science ®]   [Google Scholar] ); animal fats face technical problems preventing them from being mixed at higher than 20% shares with kerosene (Vera-Morales & Schäfer, 2009 Vera-Morales, M., & Schäfer, A. (2009). Fuel-cycle assessment of alternative aviation fuels. Cambridge: Omega.  [Google Scholar] ); hydrogen is an old but unresolved idea (Brewer, 1991 Brewer, G.D. (1991). Hydrogen aircraft technology. London: CRC Press.  [Google Scholar] ); micro-algae suffer from land-use issues, at least in the European region (Skarka, 2012 Skarka, J. (2012). Microalgae biomass potential in Europe land availability as a key issue. Technikfolgenabschätzung – Theorie und Praxis, 21, 72–79.  [Google Scholar] ), and water use, low or negative life cycle CO2 emission reductions (Quinn & Davis, 2014 Quinn, J.C., & Davis, R. (2014). The potentials and challenges of algae based biofuels: A review of the techno-economic, life cycle, and resource assessment modeling. Bioresource Technology, 184, 444–452. [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] ), cost and more profitable alternative land uses (Coplin, 2012 Coplin, L.G. (2012). Sustainable development of algal biofuels in the United States. Washington, DC: National Academies Press.  [Google Scholar] ).\nPolicy-makers are required to make decisions that often have long-term effects and are clouded in uncertainties. The quality of such decision-making for the transport sector is significantly degraded by technology myths created by industry and perpetuated through the media (Peeters et al., under review Peeters, P., Higham, J.E.S., Kutzner, D., Cohen, S., & Gössling, S. Are technology myths stalling aviation climate policy? Transportation Research Part D: Transport and Environment, under review. [Web of Science ®]   [Google Scholar] ). Such myths foster political inertia in the development of effective sustainable transport policy measures, discouraging potentially difficult but necessary decisions (Peeters, Gössling, & Lane, 2009 Peeters, P., Gössling, S., & Lane, B. (2009). Moving towards low-carbon tourism. New opportunities for destinations and tour operators. In S. Gössling, C.M. Hall, & D.B. Weaver (Eds.), Sustainable tourism futures. Perspectives on systems, restructuring and innovations (pp. 240–257). New York, NY: Routledge.  [Google Scholar] ).\nTransport taboos\nThe final major theme we discuss in this section of paper is the notion of “taboo” issues in tourism and transport policy-making. The question of why politicians have not acted in more significant ways on climate change mitigation in these sectors, as well as more generally, given that sound evidence of climate change was presented 25 years ago in the Intergovernmental Panel on Climate Change first assessment report (IPCC, 1990 IPCC. (1990). IPCC first assessment report 1990. Cambridge: Cambridge University Press.  [Google Scholar] ), is itself a relatively underexplored area of research. The adverse consequences of climate change for ecosystems and humans have since been confirmed and well documented (IPCC, 2014 IPCC. (2014). Climate change 2014: Synthesis report. Contribution of Working Groups 1, 2, and 3 to the fifth assessment report of the Intergovernmental Panel on Climate Change. Cambridge: Cambridge University Press.  [Google Scholar] ), and climate change is no longer considered a future phenomenon but rather a current and ongoing process, as, for instance, recognised by reinsurers (Munich Re, 2014 Munich Re. (2014). Overall picture of natural catastrophes in 2013 dominated by weather extremes in Europe and Supertyphoon Haiyan. Retrieved 8 January 2015 from http://www.munichre.com/en/media_relations/press_releases/2014/2014_01_07_press_release.aspx   [Google Scholar] ). As an outcome of the IPCC reports, political consensus has been achieved to stabilise greenhouse gas emissions at a level that will prevent global warming from exceeding 2 °C compared to pre-industrial temperatures, an objective confirmed during various Conferences of Parties (UNFCCC, 2014 UNFCCC. (2014). Various documents. Retrieved 17 July 2015 from www.unfccc.int   [Google Scholar] ) and recently recognised at the landmark Paris Agreement (Scott, 2016 Scott, D. (2016). The Paris Climate Change Conference and the tourism industry. Journal of Sustainable Tourism, under review  [Google Scholar] ).\nFor the transport sector, responsible for about 25% of global emissions, the European Commission (EC) has outlined emission reduction goals of -60% by 2050 compared to 1990, with an interim goal of -20% by 2030 compared to 2008 (EC, 2011 European Commission (EC). (2011). White paper: Roadmap to a single European transport area – towards a competitive and resource efficient transport system. COM(2011) 144 final. Brussels: Author.  [Google Scholar] ). These emission reductions are considered in line with the 2 °C guardrail. Yet, while climate policy objectives have been defined for the EU, and while these could also be defined for any country based on national greenhouse gas inventories, there is limited evidence of transport policies that would help to achieve such significant emission reductions, and, controversially, the EC has even outlined that curbing mobility is not considered a viable option (EC, 2011 European Commission (EC). (2011). White paper: Roadmap to a single European transport area – towards a competitive and resource efficient transport system. COM(2011) 144 final. Brussels: Author.  [Google Scholar] ). In countries and regions outside Europe, and specifically for international aviation as a significant sub-sector of tourism, transport-related mitigation policies have thus remained insignificant (Gössling, Scott, & Hall, 2013 Gössling, S., Scott, D., & Hall, C.M. (2013). Challenges of tourism in a low-carbon economy. Wiley Interdisciplinary Reviews: Climate Change, 4(6), 525–538. [Crossref] , [Web of Science ®]   [Google Scholar] ).\nYet, if energy-intense forms of mobility do not decline, it is highly unlikely that absolute reductions in greenhouse gas emissions can be achieved (Anable, Brand, Tran, & Eyre, 2012 Anable, J., Brand, C., Tran, M., & Eyre, N. (2012). Modelling transport energy demand: A socio-technical approach. Energy Policy, 41, 125–138. [Crossref] , [Web of Science ®]   [Google Scholar] ; Banister, 2008 Banister, D. (2008). The sustainable mobility paradigm. Transportation Policy, 15(1), 73–80. [Crossref] , [Web of Science ®]   [Google Scholar] , 2011 Banister, D. (2011). Cities, mobility and climate change. Journal of Transport Geography, 19(6), 1538–1546. [Crossref] , [Web of Science ®]   [Google Scholar] ; Chapman, 2007 Chapman, L. (2007). Transport and climate change: A review. Journal of Transport Geography, 15(5), 354–367. [Crossref] , [Web of Science ®]   [Google Scholar] ; IEA, 2012 IEA. (2012). World energy outlook 2011. Paris: Author.  [Google Scholar] ; Schäfer et al., 2009 Schäfer, A., Heywood, J.B., Jacoby, H.D., & Waitz, I.A., (2009). Transportation in a climate-constrained world. Cambridge, MA: MIT Press.  [Google Scholar] ; UNWTO, UNEP, & WMO, 2008 UNWTO, UNEP, & WMO. (2008). Climate change and tourism: Responding to global challenges. Madrid, Paris & Geneva: UNWTO, UNEP & WMO.  [Google Scholar] ). This has resulted in a situation where there are clear policy goals, and a wide range of market-based, command-and-control and soft policy measures available to achieve these goals (e.g. Friman, Larhult, & Gärling, 2012 Friman, M., Larhult, L., & Gärling, T. (2012). An analysis of soft transport policy measures implemented in Sweden to reduce private car use. Transportation, 40(1), 109–129. [Crossref] , [Web of Science ®]   [Google Scholar] ; OECD & UNEP, 2011 OECD & UNEP. (2011). Climate change and tourism policy in OECD countries. Paris: Author.  [Google Scholar] ; Sterner, 2007 Sterner, T. (2007). Fuel taxes: An important instrument for climate policy. Energy Policy, 35, 3194–3202. [Crossref] , [Web of Science ®]   [Google Scholar] ), but a dearth of implementation, with evidence that only soft policies focusing on voluntary behavioural change appear to be considered politically viable to reduce emissions from transportation. This paradox has been described as an “implementation gap” (Banister & Hickman, 2013 Banister, D., & Hickman, R. (2013). Transport futures: Thinking the unthinkable. Transportation Policy, 29, 283–293. [Crossref] , [Web of Science ®]   [Google Scholar] , p. 292), and led to growing academic interest in barriers to significant climate policy.\nVarious explanations have been provided to explain why governments have been reluctant to implement policies. From a governance viewpoint, Rietveld et al. ( 2005 Rietveld, P., & Stough, R. (Eds.). 2005. Barriers to sustainable transport: Institutions, regulation and sustainability. Abingdon: Spon Press.  [Google Scholar] ) have suggested that institutions rule and structure public and private actions, and that these can be informal, formal, governance-, and resource allocation/employment related. Informal institutions would comprise values, norms, practices, habits and traditions, and are considered conditioners of behaviour (see Schwanen & Lucas, 2011 Schwanen, T., & Lucas, K. (2011). Understanding auto motives. In K. Lucas, E. Blumenberg, & R. Weinberger (Eds.), Auto motives: Understanding car use behaviours. (pp. 3–38). Emerald: Bingley. [Crossref]   [Google Scholar] in the context of automobility). Formal institutions include “codified statutes, constitutions, provisions, laws, regulations, and high level administrative orders” (Rietveld et al., 2005 Rietveld, P., & Stough, R. (Eds.). 2005. Barriers to sustainable transport: Institutions, regulation and sustainability. Abingdon: Spon Press.  [Google Scholar] , p. 3). Governance institutions are a third type of institution focused on rules, including laws, regulations and policy directives, such as planning and zoning issues, or transactions involving actors and agents. Finally, resource allocation refers to government agencies, firms and non-profit associations allocating financial resources. These four categories can be used to identify and address barriers from various viewpoints, including, for instance, the notion that transport planning cannot be questioned, as transportation is important for society and economic growth. This has, for instance, been discussed by Miciukiewicz and Vigar ( 2012 Miciukiewicz, K., & Vigar, G. (2012). Mobility and social cohesion in the splintered city: Challenging technocentric transport research and policy-making practices. Urban Studies, 49(9), 1941–1957. [Crossref] , [Web of Science ®]   [Google Scholar] ) in terms of technological fixation among transport researchers and subsequent technocentric policy-making. In a similar vein, Hutton ( 2013 Hutton, B. (2013). Planning sustainable transport. London: Routledge.  [Google Scholar] ) describes how the turn from meeting predicted transport growth to managing transport demand has only recently been considered in UK transport policy. Ultimately, “barriers” thus often resemble embedded beliefs of ecological modernisation, i.e. the assumption that transport growth can be balanced environmentally, based on technological progress, as also evident in UNEP's ( 2011 UNEP. (2011). Towards a green economy: Pathways to sustainable development and poverty eradication. Retrieved 29 September 2015 from www.unep.org/greeneconomy   [Google Scholar] ) Green Growth focus, which may be seen as another ecological modernisation paradigm without real-world implications for emission growth (Hall, 2009 Hall, C.M. (2009). Degrowing tourism: Décroissance, sustainable consumption and steady-state tourism. Anatolia: An International Journal of Tourism and Hospitality Research, 20(1), 46–61. [Taylor & Francis Online]   [Google Scholar] , 2013 Hall, C.M. (2013). Framing behavioural approaches to understanding and governing sustainable tourism consumption: Beyond neoliberalism, ‘nudging’ and ‘green growth’? Journal of Sustainable Tourism, 21(7), 1091–1109. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] , 2015 Hall, C.M. (2015). Economic greenwash: On the absurdity of tourism and green growth. In M.V. Reddy & K. Wilkes (Eds.), Tourism in the green economy. (pp. 339–358). London: Earthscan by Routledge.  [Google Scholar] ).\nNew understandings of the reasons for inaction on climate change in transport contexts are thus required: “barriers” were discussed with regard to their cognitive and affective dimensions during the Freiburg 2014 workshop, where they were framed as “taboos” (Gössling & Cohen, 2014 Gössling, S., & Cohen, S. (2014). Why sustainable transport policies will fail: European Union climate policy in the light of transport taboos. Journal of Transport Geography, 39, 197–207. [Crossref] , [Web of Science ®]   [Google Scholar] ). Taboos are different from barriers of implementation, because they cannot be addressed politically without considerable (political) danger to the person taking up a given issue. To touch a taboo implies to violate an existing norm, i.e. a situation that is usually in the interest of powerful individuals, (lobby) organisations, or the broader public or community. A “transport taboo” thus describes an issue that cannot be raised without risks, possibly jeopardising the political future of any person raising the taboo. A wide range of transport taboos that politicians are unwilling to touch has been identified, such as the watering down of transport policy by lobbyism, the skewed share of transport emissions contributed by higher income classes and the broader societal glamorisation of high-energy transport consumption (Cohen & Gössling, 2015 Cohen, S.A., & Gössling, S. (2015). A darker side of hypermobility. Environment and Planning A, 47, 1661–1679. [Crossref] , [Web of Science ®]   [Google Scholar] ; for further details on transport taboos see Gössling & Cohen, 2014 Gössling, S., & Cohen, S. (2014). Why sustainable transport policies will fail: European Union climate policy in the light of transport taboos. Journal of Transport Geography, 39, 197–207. [Crossref] , [Web of Science ®]   [Google Scholar] ).\nTransport taboos are consequently issues that would appear obvious, as some solutions are ready at hand, demanding political action; yet, they are characterised by silence. A further example may be the 20 years of OECD reports recommending to remove fossil fuel subsidies, and to introduce carbon pricing ( 1991 OECD. (1991). Energy prices, taxes and carbon dioxide emissions (OECD economic studies 17). Paris: Author.  [Google Scholar] , 1999 OECD. (1999). Project on environmentally sustainable transport (EST) (Report NV/EPOC/PPC/T(99)3/FINAL/REV1). Paris: Author.  [Google Scholar] , 2008, 2015 OECD. (2015). OECD companion to the inventory of support measures for fossil fuels 2015. Retrieved 12 November 2015 from http://www.keepeek.com/Digital-Asset-Management/oecd/energy/oecd-companion-to-the-inventory-of-support-measures-for-fossil-fuels-2015_9789264239616-en#page1   [Google Scholar] ). However, the issue remains politically untouched, because this would lead to outrage by industry associations, who are powerful agents in public discourse. Yet, overcoming taboos is essential if more sustainable tourism and transport policies are to be implemented, specifically regarding climate change. At the very least, this would require political parties to stop using public sentiment to undermine sustainable transport policy initiatives by political opponents in order to gain votes on less popular measures related to climate change mitigation.\nThe papers in this special issue\nThis special issue presents nine further papers that explore avenues for behaviour change by various stakeholders in tourism and transport in order to bridge the science–policy gap in sustainable mobility. The contributions cover a wide spectrum of interests and stakeholders, and connect in various ways to the themes discussed above, notably socio-technical factors and transport taboos.\nThe first three papers investigate the role of researchers in the sustainable mobility debate, and their capacities and shortcomings to contribute to behaviour change. Hall ( in press Hall, C.M. (in press). Intervening in academic interventions: Using the lens of social marketing to examine the potential for successful sustainable tourism behavioural change. Journal of Sustainable Tourism, DOI: 10.1080/09669582.2015.1088861. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ) does this by employing social marketing themes. He questions both the theoretical knowledge base of sustainable tourism and the positioning of sustainability within the wider (tourism) literature, noting that, despite a growing body of research on sustainable tourism and mobilities, concern about these topics in tourism research is still minor, particularly in popular areas such as achieving growth in visitor numbers and expenditure. Substantive change is not evident in most destinations, or among organisations that have adopted sustainable tourism. As a way forward, Hall discusses the need for more advocacy- and participatory-based approaches so that scientists can better communicate with policy-makers and work collaboratively/co-productively with them and other upstream stakeholders. Downstream and (more activist and interventionist) upstream social marketing to the public, taking in the lessons learned from other disciplines and debates (such as that on anti-smoking), may (re)glamorise/make fashionable forms of more sustainable tourism or encourage more conventional but low transport intensity local tourism.\nMelissen and Koens ( in press Melissen, F., & Koens, K. (in press). Adding researchers' behaviour to the research agenda: Bridging the science–policy gap in sustainable tourism mobility. Journal of Sustainable Tourism, DOI: 10.1080/09669582.2015.1071384 [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ) echo Hall, arguing that researchers should not only focus on understanding the structures behind tourist behaviour, but also on how to mobilise policy and business stakeholders to contribute to the sustainable development of tourism. They find several factors or tensions (Jones, Jones, & Walsh, 2008 Jones, N., Jones, H., & Walsh, C. (2008). Political science? Strengthening science-policy dialogue in developing countries. London: Overseas Development Institute.  [Google Scholar] ) hindering researcher behaviour change towards bridging the science–policy gap in sustainable tourism mobility, and make a case for adding researchers' behaviour to the corresponding research agenda. Researchers may need to position themselves closer to the policy arena, without politicising science or moving from engaged to activist research.\nMounting sustainable tourism and transport advocacy will also lead to more attention to the environmental sustainability imperatives of researchers themselves, and the institutions for which they work. Thus the paper by Hopkins, Higham, Tapp, and Duncan ( in press Hopkins, D., Higham, J., Tapp, S., & Duncan, T. (in press). Academic mobility in the Anthropocene era: A comparative study of university policy at three New Zealand institutions. Journal of Sustainable Tourism, DOI: 10.1080/09669582.2015.1071383 [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ) in this issue links to the transport taboo of questioning academic mobility and associated carbon emissions. Set in a New Zealand university context it investigates the perceived lock-in of academic performance being dependent on, or equal to, international mobility. This can be linked back to the pioneering work of the late Karl Georg Høyer (Høyer, 2000 Høyer, K.G. (2000). Sustainable tourism – or sustainable mobility? Journal of Sustainable Tourism, 8(2), 147–161. [Taylor & Francis Online]   [Google Scholar] ; Høyer & Næss, 2001 Høyer, K.G., & Næss, P. (2001). Conference tourism: A problem for the environment as well as for research? Journal of Sustainable Tourism, 9(6), 451–470. [Taylor & Francis Online]   [Google Scholar] ). The authors find academic travel to be embedded in university policy, for example through international partnerships, the need to present research at international conferences and recruitment processes. Acknowledging New Zealand's particular geographical location, they still recommend that academic institutions consider and address the carbon emissions related to academic mobility, and to integrate sustainability more systematically into university (travel) policy.\nAnother highly mobile group possibly caught in a (socio-cultural) lock-in of flight-dependent practices is that of the younger generation in many western countries taking a gap year. Luzecka ( in press Luzecka, P. (in press). “Take a gap year!” A social practice perspective on air travel and potential transitions towards sustainable tourism mobility. Journal of Sustainable Tourism, DOI: 10.1080/09669582.2015.1115513 [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ) explores ways in which conventions related to “appropriate” gap year destinations are developed, sustained and reproduced. Numerous social mechanisms were found to facilitate overseas travel in the context of gap years, including a shared perception of difference and physical distance, which links personal development to the challenges of distant countries. This paper highlights the fact that some long-haul destinations are actually easier or cheaper to travel to than more nearby destinations. Luzecka warns that widening participation in gap year travel may further the normalisation – and psychological lock-in – of long-haul travel. The length of gap years would make them suitable for slow, and potentially more sustainable, travel, but for such a sustainable mobility transition, the socio-cultural forces that shape current gap year practices need to be taken into account.\nThe two following papers acknowledge the reality of consumers not accepting responsibility and responding to unsustainable travel mobilities, and seek ways to influence consumer decision-making through the provision of carbon information with travel products. Araña and León ( in press Araña, J.E., & León, C.J. (in press). Are tourists animal spirits? Evidence from a field experiment exploring the use of non-market based interventions advocating sustainable tourism. Journal of Sustainable Tourism, DOI: 10.1080/09669582.2015.1101128 [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ) experiment with the role of emotions and time pressure in decision-making, hypothesising that many traveller decisions are of an experiential nature. In a Spanish social tourism programme setting, they carried out a field experiment in which they manipulate the choice context of travellers, when deciding where to travel. Travel plans involved different levels of CO2 emissions, contexts about the emotional state, and decision time. Araña and León find that emotional states and the decision context can indeed affect the sustainability of travel choices. These findings have several implications for pro-environmental behaviour policies and campaigns in tourism and the effectiveness of tax incentives. Subjects showing more empathy with future generations are more likely to accept low-carbon travel options.\nEijgelaar, Nawijn, Barten, Okuhn, and Dijkstra ( in press Eijgelaar, E., Nawijn, J., Barten, C., Okuhn, L., & Dijkstra, L. (in press). Consumer attitudes and preferences on holiday carbon footprint information in the Netherlands. Journal of Sustainable Tourism, DOI: 10.1080/09669582.2015.1101129 [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ) investigate carbon labels, as a soft measure towards more sustainable travel choices that is more likely to receive industry acceptance than direct volume-reducing measures. Their case is linked to the desire of Dutch tour operators to offer such a label. Hence, they explore preferences for carbon label design in tourism. The authors tested label designs in a number of consecutive research phases under Dutch consumers. They find a number of preconditions for a tourism carbon label: it should be simple in design and connect to existing well-known EU labels for energy efficiency. But at the same time they note that sustainability is still of low priority during holiday decision-making.\nAn interesting case in science–policy interaction is Antarctica, as the continent is not controlled by a state, but through a 29-party governance regime, the Antarctic Treaty System. As little progress was made on tourism issues through the Treaty's meetings, the International Association of Antarctica Tour Operators filled this gap by self-regulating Antarctic tourism. However, their capability to self-regulate is increasingly questioned. Student, Lamers, and Amelung ( in press Student, J., Lamers, M., & Amelung, B. (in press). Towards a tipping point? Exploring the capacity to self-regulate Antarctic tourism using agent-based modelling. Journal of Sustainable Tourism, DOI: 10.1080/09669582.2015.1107079 [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ) apply agent-based modelling (ABM) to identify the challenges for the self-regulation of this carbon-intensive form of tourism. They find a number of potentially destabilising factors connected to likely future tourism development, whereby optimum group size and membership cost are crucial. More importantly, they stress the strength of ABM as a method to safely experiment with uncertainties in Antarctica, and help to provide insights for an environmentally optimised application in (sustainable Antarctic tourism) policy.\nThe final two papers investigate sustainable transport policy-making and practices at destinations. This local/regional level work reveals key aspects of the realpolitik of policy-making in ways not open to most researchers at national or international levels. Scuttari, Volgger, and Pechlaner ( in press Scuttari, A., Volgger,M., & Pechlaner, H. (in press). Transition management towards sustainable mobility in alpine destinations: Realities and realpolitik in Italy's South Tyrol region. Journal of Sustainable Tourism, DOI: 10.1080/09669582.2015.XXXXXX [Crossref] , [Web of Science ®]   [Google Scholar] ) seek ways for governing the transition towards more sustainable tourism mobility by applying a system approach. Their research in a South Tyrolean context indicates that the transition towards more sustainable transport solutions is complex and requires both public and private sector unpredictability and risk aversion to be taken into account. Scuttari et al. identify three conditions relevant to performing the transition, each one linked to a different sub-system (socio-ecological, socio-technical and governance). The transition to sustainable solutions is a complex task that can only be successful when all sub-systems – tourism, transport, governance and social-ecological – interact in informal or formal partnership. To be successful, three conditions were identified: (1) an improved understanding of what sustainable transport entails, (2) adoption of the best available technology and (3) courage and leadership to take risks with new solutions without knowing what they will bring with absolute certainty. The latter means that science should provide a better understanding of how to mitigate risk aversion or even better, how to shift the focus of risk aversion towards avoiding the risks of unsustainable development and climate change, as opposed to the risks associated with introducing, managing and using novel transport systems.\nFinally, Stanford and Guiver (in press) Stanford, D., & Guiver, J. (in press). Driving pro-environmental change in tourist destinations: Encouraging sustainable travel in national parks via partnership project creation and implementation. Journal of Sustainable Tourism, DOI: 10.1080.09669582.2015.1122018 [Web of Science ®]   [Google Scholar] explore public–private partnership led projects providing alternatives to car travel in three UK national parks as mechanisms of modal shift and pro-environmental change. They identify a number of success factors and provide practical advice on understanding and guiding future multi-partnership pro-environmental change processes in complex networks. As in the previous paper, strong local governance structures, awareness creating, trust and learning are important, and the effective communication of benefits to stakeholders appeared most significant.\nConclusions and research agenda\nThis paper has discussed three areas crucial for understanding why, despite clear scientific evidence about the growing environmental impacts of tourism transport, there is large-scale inertia in structural transitions and a lack of political willpower to enact meaningful policy change. These included the importance of addressing socio-technical factors, the barriers posed by placing faith in “technology myths” and the need to overcome “transport taboos” in policy-making. These areas shed significant light on why a science–policy gap in sustainable mobility exists, and on the issues that must be overcome if this gap is to be bridged. The societal challenge of transitioning the tourism and transport sectors to a sustainable emissions path must not be devolved entirely to the public and the marketplace, as suggested by neoliberal values. It is vital that both governments and the tourism and transport industries take a more cautious approach to the technological optimism that is fostering policy inertia: technological innovation alone will not save the day anytime soon. They must invest more in research, in operational procedures and in encouraging the development of and marketing alternatives to air travel. But most importantly, policy-makers must take a more open approach to implementing sustainable transport policies that affect the structures of provision; they will need to be lobbied to touch issues that may be politically risky, but nonetheless have been shown in other contexts to be successful in fostering desirable sustainable transport outcomes.\nBuilding on these insights, the Freiburg 2016 workshop will consequently focus on desirable transport futures, i.e. visions of desirable sustainable transport systems that have the potential to be actively taken up by wide cross sections of society (c.f. Banister & Hickman, 2013 Banister, D., & Hickman, R. (2013). Transport futures: Thinking the unthinkable. Transportation Policy, 29, 283–293. [Crossref] , [Web of Science ®]   [Google Scholar] ). A starting point for this is the analysis of sustainable transport transitions that are now underway, and the analysis of the structural, political, institutional and social/psychological factors underlying those transitions. The e-bike revolution is one example of societal change involving a low-carbon technological innovation, with uptake and adoption motivated by convenience, speed, health and cost. Many cities in Europe have re-discovered the bicycle as a transport mode with diverse benefits, and there now exists widespread and growing demand for infrastructures that facilitate cycling and other active forms of transport (Gössling & Choi, 2015 Gössling, S., & Choi, A.S. (2015). Transport transitions in Copenhagen: Comparing the cost of cars and bicycles. Ecological Economics, 113, 106–113. [Crossref] , [Web of Science ®]   [Google Scholar] ; Pucher & Buehler, 2012 Pucher, J., & Buehler, R. (2012). City cycling. Cambridge, MA: MIT Press.  [Google Scholar] ). Cycling cities have become a desirable transport future but the health and cost benefits of cycling demand that issues of cyclist safety are addressed in infrastructural provision. The rise of car sharing systems, in place of car ownership, is another timely example of a mobility transition, but is not without rebound effects, as the media suggests that it has cannibalisation effects at the expense of public transport (Schwarz, 2015 Schwarz, K. (2015, December 11). Carsharing: Wie umweltschädlich sind Car2go und Drivenow wirklich? [Carsharing: How environmentally harmful are Car2go and Drivenow actually?]. The Huffington Post (German Edition). Retrieved 1 December 2015 from http://www.huffingtonpost.de/2015/02/13/carsharing-klima-umfrage-wirtschaftswoche_n_6675908.html   [Google Scholar] ).\nIn contrast to desirable futures, while flying is highly desirable for many, continued growth in air travel on a global scale is incompatible with a sustainable transport future, and it is here that the need for urgent transition is now widely accepted. However, before entertaining alternatives to the current unsustainable transport system, it is essential to know what desirable transport futures may look like. The critical analysis of mobility transitions, including barriers confronting the achievement of desirable transport futures, is needed. A concerted research effort in the following key areas is consequently required:\nDesired transport\nFuture visions must be built upon desired transport systems. Critical examination is needed of spontaneous market uptake of desired new transport systems and their rebound effects. How have e-bike, car sharing, high-speed rail and successful public transport systems emerged in certain societies? What factors have acted as facilitators of change and how were barriers overcome? How important are individuals, i.e. specific people, in initiating change? What were the key roles of stakeholders and were low-carbon transitions an objective from the outset or a coincidental outcome? What lessons can be learned from these revolutions and what wider roles may such successes play in developing towards low-carbon transport and tourism?\nThe role of fashion\nMany trends in tourism and travel are fashion driven. Certain destinations can rise and fall substantially in a very short time. In the Netherlands long-haul travel grew rapidly until 2008 when it stabilised and started to decline. What factors influence significant changes in established patterns of consumption? Why has “environmental consciousness”, with the exception of European car purchasing, proved largely ineffective in driving low-carbon transport transitions? What potential do social marketing, celebrity endorsement and role model advocacy offer, and how can the effectiveness of these strategies be maximised? What other strategies may exist to influence and encourage the fashionability of more sustainable forms of tourism (e.g. caravanning, train journeys, “loca-tourism”, slow tourism and staycationing)? How can industry, government, the media and public organisations engage in such processes, and what in particular is the role of science and researchers?\nEconomic issues\nThe economic arguments for growth in aviation are well established, even though many assessments appear to remain partial. But what are the economic arguments that support the development of sustainable transport systems? What economic growth scenarios may be associated with low-carbon transitions to rail and electric vehicle fleets, and the new infrastructures required to facilitate active transport modes? What do economic models predict for the redistribution of travel flows under low-carbon transport scenarios? Contributions to a more complete understanding of the economics of low-carbon transport scenarios are critically important to the shift towards desired transport futures.\nPublic health and well-being\nCritical issues arise when contemplating how the sustainable transportation agenda is coupled with questions of public health and well-being. Policy outcomes driven by a public health and well-being agenda may have the potential for achieving significant environmental benefits. What potential do desirable transport futures offer to overcome personal well-being and public health risks, such as the negative health dimensions of frequent flying (Cohen & Gössling, 2015) Cohen, S.A., & Gössling, S. (2015). A darker side of hypermobility. Environment and Planning A, 47, 1661–1679. [Crossref] , [Web of Science ®]   [Google Scholar] , or the risk of pandemic associated with long-haul flights? And where mobility transitions are already in progress, can, for instance, the rising public health costs of serious injuries and deaths of cyclists be mitigated by dedicated cycle infrastructure?\nIssues of equity and ethics\nThere is a need to move beyond the Eurocentrism (c.f. Cohen & Cohen, 2015 Cohen, E., & Cohen, S.A. (2015). Beyond Eurocentrism in tourism: A paradigm shift to mobilities. Tourism Recreation Research, 40(2), 157–168. [Taylor & Francis Online]   [Google Scholar] ) that has framed debate around these issues. While the West has contributed disproportionately to the environmental crisis, emissions of unsustainable transportation are globally dispersed. Insights that are theoretically, methodologically and practically informed are required to understand sustainable transportation issues as they apply to emerging world regions (e.g. Dillimono & Dickinson, 2015 Dillimono, H.D., & Dickinson, J.E. (2015). Travel, tourism, climate change, and behavioral change: Travelers' perspectives from a developing country, Nigeria. Journal of Sustainable Tourism, 23(3), 437–454. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] on Nigerian perspectives). Growth from the middle classes in parts of Asia, Latin America, South America and Africa is also driving up global transport emissions. What equity issues arise in association with the transition from old to new transport systems? What ethical issues arise with the growth of unsustainable transportation in less developed countries? How will the continuing but declining emission footprint be distributed between countries and sectors globally? What will be the impacts of emission trading, taxation regimes, subsidies and infrastructure planning, and how will they vary between regions in light of the recent Paris Agreement?\nAdvocacy- and participatory-based approaches\nThe need exists for advocacy- and participatory-based approaches (see Bramwell, Higham, Lane, & Miller, 2016 Bramwell, B., Higham, J., Lane, B., & Miller, G. (2016). Advocacy or neutrality? Disseminating research findings and driving change toward sustainable tourism in a fast changing world. Journal of Sustainable Tourism, 24(1), 1–7. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ; Hall, in press Hall, C.M. (in press). Intervening in academic interventions: Using the lens of social marketing to examine the potential for successful sustainable tourism behavioural change. Journal of Sustainable Tourism, DOI: 10.1080/09669582.2015.1088861. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ) to enable more effective communication with policy communities, and to facilitate collaboration and co-production with policy-makers and other upstream stakeholders. What opportunities exist to implement new or underutilised methods such as simulation, serious gaming and in-depth multi-stakeholder approaches? What potential do new approaches offer to communicate the science of climate change, and internalise the challenges inherent in responding to climate change? How can new approaches serve to highlight the contribution of travel in global GHG emissions, the inherent difficulties in responding to unsustainable transportation, and potential pathways to desirable transport futures? These key areas form the basis for a continued research agenda aimed at transitioning the tourism and transport sectors to a sustainable emissions path.\nAcknowledgments\nThe convenors of the Freiburg 2014 workshop (1–4 July 2014) gratefully acknowledge the members of its Scientific Advisory Board, all of whom contributed to the success of the workshop: Dr Stewart Barr (University of Exeter, UK), Dr Jo Guiver (University of Central Lancashire, UK), Professor Michael Hall (University of Canterbury, NZ), Dr Julia Hibbert (Bournemouth University, UK), Professor Daniel Scott (University of Waterloo, Canada) and Professor David Banister (TSI, University of Oxford, UK).\nDisclosure statement\nScott A. Cohen is a reader at the University of Surrey (United Kingdom).\nJames Higham\nJames Higham is a professor at the Department of Tourism, University of Otago (New Zealand).\nStefan Gössling\nStefan Gössling is a professor at Lund University and Linnaeus University (Sweden). He is also research coordinator at the Western Norway Research Institute's Research Centre for Sustainable Tourism.\nPaul Peeters\nPaul Peeters is an associate professor at NHTV Breda University of Applied Sciences (The Netherlands).\nEke Eijgelaar\nEke Eijgelaar is a researcher at the Centre for Sustainable Tourism and Transport at NHTV Breda University for Applied Sciences (The Netherlands).\nArticle Metrics\n""","0.22600771","""http://www.tandfonline.com/doi/full/10.1080/09669582.2015.1136637""","[-0.589514,51.242722]"
"""Imperial_College_London""","""Properties and Origins of the Anisotropic Eddy-Induced Transport in the North Atlantic: Journal of Physical Oceanography: Vol 45, No 3""","""Properties and Origins of the Anisotropic Eddy-Induced Transport in the North Atlantic\nProperties and Origins of the Anisotropic Eddy-Induced Transport in the North Atlantic\nAuthors:\nAffiliationsDepartment of Mathematics and Grantham Institute for Climate Change, Imperial College London, London, United Kingdom\nSee full authors & affiliations\nFinal Form: 10 December 2014\nPublished Online: 13 March 2015\nAbstract\nSection:\nThis study examines anisotropic transport properties of the eddying North Atlantic flow, using an idealized model of the double-gyre oceanic circulation and altimetry-derived velocities. The material transport by the time-dependent flow (quantified by the eddy diffusivity tensor) varies geographically and is anisotropic, that is, it has a well-defined direction of the maximum transport. One component of the time-dependent flow, zonally elongated large-scale transients, is particularly important for the anisotropy, as it corresponds to primarily zonal material transport and long correlation time scales. The importance of these large-scale zonal transients in the material distribution is further confirmed with simulations of idealized color dye tracers, which has implications for parameterizations of the eddy transport in non-eddy-resolving models.\nKeywords:\nCorresponding author address: Igor Kamenkovich, 4600 Rickenbacker Causeway, University of Miami, Miami, FL 33149. E-mail: ikamenkovich@rsmas.miami.edu\n1. Introduction\nSection:\nThere is growing evidence for the importance of eddies—defined here as geostrophic deviations from a mean state—in the distribution of various oceanic tracers in the interior of oceanic gyres. In particular, eddies have been shown to maintain the Northern Hemisphere thermocline (e.g., Henning and Vallis 2004 ) and to control the penetration of transient atmospheric gases into the North Atlantic (e.g., Booth and Kamenkovich 2008 ). The efficiency of eddies in downgradient tracer transport has been conventionally quantified by turbulent (“eddy”) diffusivity. Under the assumptions of homogeneous and isotropic turbulence, the diffusivity K can be related to the rms Lagrangian velocity 〈υ′〉 of tracer particles and the Lagrangian correlation length scale lcorr or time scale τcorr ( Taylor 1921 ; Vallis 2006 ):\nIn the Eulerian analog of the above equation, the 〈υ′〉2 becomes the eddy kinetic energy (EKE): the Eulerian mixing length lcorr and the Eulerian time scale τcorr ( Prandtl 1925 ). The eddy diffusivity and other parameters in (1) can be estimated in observational data and numerical simulations by a variety of techniques. Such estimates have practical importance, as diffusion is widely used to parameterize eddies in non-eddy-resolving numerical models, which still account for the majority of ocean components of climate models. The diffusivities in these models are poorly constrained and determined empirically and are often taken to be spatially homogeneous and isotropic.\nExisting evidence based on observational estimates and numerical simulations, however, suggests that the eddy-induced transport is spatially inhomogeneous (e.g., LaCasce and Bower 2000 ) and anisotropic, that is, it has a preferred direction (e.g., Freeland et al. 1975 ; Spall et al. 1993 ; LaCasce 2000 ). The along-isopycnal eddy diffusivity can be described by a location-dependent two-dimensional tensor, and the preferred direction can be determined by diagonalizing this tensor. The latter approach was taken by Rypina et al. (2012) , who analyzed trajectories of both synthetic Lagrangian particles (diagnosed from the altimetric data) and the actual surface drifters in the North Atlantic. The results demonstrate that the preferred transport direction varies across the region, the transport anisotropy is caused primarily by geostrophic rather than nongeostrophic currents (see also Sallee et al. 2008 ), and the spreading of Lagrangian particles can be faster or slower than diffusive, that is, “superdiffusive” or “subdiffusive,” respectively (see also Berloff et al. 2002 ; Veneziani et al. 2005 ; Kamenkovich et al. 2009 ).\nThe origins of this complexity remain largely unclear, and several mechanisms have been proposed. The mean advection can significantly modulate the eddy-induced transport. In particular, the meridional diffusivity is enhanced at steering levels ( Green 1970 ; Killworth 1997 ) and is suppressed by zonal propagation of eddies relative to the mean zonal flow ( Ferrari and Nikurashin 2010 ); meridional shear in zonal currents can cause shear dispersion (e.g., Taylor 1953 ; Young et al. 1982 ; Smith 2005 ); and cross-jet transport barriers exist on strong currents such as the Gulf Stream and its extension ( Samelson 1992 ; Rypina et al. 2011 ) and alternating multiple jets ( Haynes et al. 2007 ; Berloff et al. 2009 ). In addition, powerful mean currents, such as those within the western boundary regions and the upper-ocean Antarctic Circumpolar Current, can dwarf the along-stream eddy-induced transport.\nIn many parts of the ocean, however, mean currents are weak relative to eddies, and the along-stream diffusivity is as important for tracer distribution as the mean advection. In these regions, the anisotropy cannot be explained by the effects of the mean advection alone ( Kamenkovich et al. 2009 ; Rypina et al. 2012 ). On the other hand, the eddy velocity variance tends to be isotropic ( Rypina et al. 2012 ) and cannot explain anisotropy in K using (1) either. Kamenkovich et al. (2009) hypothesize that the dominance of the zonal eddy diffusivity can be caused by zonally elongated eddies such as those observed in altimetry-based observational datasets ( Huang et al. 2007 ), and this hypothesis is further examined in this study. This manuscript investigates the influence of zonally elongated transient patterns on the particle spreading, describes spectral and transport properties of these transients in idealized numerical simulations ( sections 2 and 3 ) and altimetry-based velocity estimates ( section 4 ), and discusses the importance of transient motions in idealized tracer distribution in the model context in section 5 .\n2. Numerical model and simulated flow\nSection:\nThe dynamical model is adapted from Karabasov et al. (2009) and only a very brief description of it is given here. This model employs an advanced advection scheme Compact Accurately Boundary-Adjusting High-Resolution Technique (CABARET) which allows achieving highly effective spatial resolution, meaning that numerical convergence is found at much coarser spatial resolution than in the case of traditional advection schemes. An equally important and attractive property of this formulation is its numerical stability in the presence of small dissipation, which allows simulations with very high, and most realistic, Reynolds numbers (Re).\nThe vertical stratification is represented by three isopycnal layers, with the thicknesses of 250, 750, and 3000 m, counting from the top. The evolution of the potential vorticity (PV) qn in each layer is described by\nwhere the lateral Laplacian viscosity ν is 100 m2 s−1. This value has been chosen to correspond to the Munk boundary layer of 17 km that is minimally resolved with two grid points. PV in each layer is given by\nwhere the stratification parameters R1, R21, R22, and R3 are chosen so that the first and the second internal deformation radii are Rd1 = 32.2 and Rd2 = 18.9 km, respectively: β = 2 × 10−11 m−1 s−1.\nThe forcing Fn on the right-hand side of (4) includes Ekman pumping by the prescribed wind stress curl in the top layer and bottom friction in the bottom layer:\nwhere fwind is idealized wind forcing, which has a zero curl line slanted in the meridional direction. Bottom friction kbot = 10−7. The domain is square and has a size of 3840 km, and the spatial resolution is 7.5 km.\nThe simulated flow and its spectrum\nThe simulated flow consists of subtropical and subpolar gyres, separated by a well-pronounced western boundary current and its eastward jet extension (EJE hereinafter; Fig. 1a ). The entire domain is filled with mesoscale eddies, which are particularly strong in the vicinity of the EJE ( Fig. 1b ). The magnitudes of motions decrease with depth. The spatial structure of the PV is qualitatively similar to the streamfunction ( Figs. 1c,d ). This similarity is explained by the dominance of the stretching terms [last terms in (3) ], which is because the dominant length scales in the solutions are several Rossby deformation radii (see the following discussion of Fig. 2 ).\nView larger version (76K)\nFig. 1. Circulation in the top layer of the numerical simulations. (a) Time-mean (over 50 yr) streamfunction and (b) instantaneous minus the time-mean streamfunction (eddies) (m2 s−1). (c) Time-mean (over 50 yr) PV; (b) instantaneous minus the time-mean PV (eddies) (s−1).\nView larger version (60K)\nFig. 2. Spatial structure of the circulation in the numerical simulation. (a) Wavenumber k–l spectrum of velocity in the top layer, time averaged over 50 yr; absolute values of wavenumbers (k, l) are nondimensionalized by Rd1; the spectrum is nondimensionalized by the total kinetic energy (multiplied by 0.005). (b) The spectral power as a function of the angle between the wavenumber (k, l), summed over the interval K = [1/20Rd1 1/10Rd1] and divided by its maximum value. Note the presence of the anisotropic peak at small k in (a) and at angle ≈ 85° and in (b) corresponding to the zonal transients. (c) Zonal transients, isolated by the low-pass filtering (using the sine transform) of the instantaneous velocity streamfunction in the top layer (m2 s−1). (d) Zonally and time-averaged kinetic energy (weighted by the total kinetic energy) of the zonal transients in the three vertical layers.\nThe spatial structure of the eddy field is illustrated by the two-dimensional wavenumber (k–l) spectrum of the velocity—the sum of u and υ velocity spectra ( Fig. 2a ). The 2800 spectra of instantaneous velocities are computed at 7-day intervals and then averaged in time; note that these instantaneous k–l spectra do not contain information on time dependence and eddy propagation. Most of the spectral power is contained in the circular band corresponding to the total wavenumbers\nbetween (20Rd1)−1 and (10Rd1)−1. Within this spectral region in layer 1, there is a noticeable peak corresponding to the zonal wavelength k−1 = 120Rd1 (total basin width) and the meridional wavelength of l−1 = 13Rd1. This peak corresponds to a nearly meridional wavenumber ( Fig. 2b ) and is anisotropic in this sense. This anisotropic peak is separated from a second, broader, and bigger peak centered at the 30° orientation of the wavevector. The entire spectral region at k−1 > 30Rd1 will be referred to as the region of “zonal transients” to distinguish it from more isotropic flow components with shorter zonal scales, which will be loosely referred to as “isotropic eddies.” The zonal transient part of the spectrum corresponds to a relatively small portion of the total energy (e.g., 15% in layer 1); however, we will later see that the zonal transients play an important role in the anisotropic transport. Note that zonal transients are defined in terms of the zonal scales only and not based on dynamical properties. The separation between the two spectral peaks becomes less distinct in layers 2 and 3 (not shown).\nTo study the meridional structure and propagation properties of zonal transients, we isolate them by spatial filtering of the velocity streamfunction; the filtering is done in the zonal direction only, and the cutoff wavelength is 30Rd1. As the rest of the flow, the zonal transients have maximum amplitudes in the EJE vicinity ( Figs. 2c,d ). With depth, the distribution of the kinetic energy of the zonal transients becomes more uniform in the meridional direction and the relative importance of zonal transients in the regions north and south of EJE is the largest in layer 3. We will later see that this deep region also corresponds to the largest transport anisotropy.\nZonal transients propagate westward at a speed of approximately 0.035–0.05 m s−1 north and south of EJE, as estimated from the Hovmöller diagrams. The phase speed of zonal transients is noticeably smaller than the phase speed of the barotropic Rossby wave with the same wavenumbers and in the motionless medium (0.09 m s−1) but are larger than the phase speed of the first baroclinic Rossby wave (0.02 m s−1). This discrepancy is likely to be explained by the effects of the mean advection ( Berloff and Kamenkovich 2013a ), but the analysis of the normal modes of the double-gyre flow is beyond the scope of this study.\n3. Lagrangian analysis\nSection:\nProperties of the eddy-induced material transport are investigated next using Lagrangian particle trajectories. The components of the single-particle dispersion matrix for a group of N Lagrangian particles are defined as\nwhere xn and yn are the zonal and meridional displacements, respectively, of an nth particle from its initial position. The terms X and Y are the ensemble-mean displacements:\nThe dispersion matrix is diagonalized by rotating the coordinate frame, and the angle between the latitude circle and the new x axis θmax is\nThe rate at which the dispersion in the new coordinate frame (ξ, η) increases with time is used to define the spreading rates:\nwhere\nThe Lagrangian correlation time scales are calculated (e.g., Vallis 2006 ) from the Lagrangian velocity autocorrelation functions Rξ and Rη in the new coordinate frame:\nThe effects of the mean flow on the eddy-induced diffusivity is accounted for by the full trajectory-following (FTF) method ( Berloff et al. 2002 ; Rypina et al. 2012 ), which was shown by the latter study to account for such known effects of the mean flow on the eddy diffusivity as the cross-jet suppression of eddy-induced particle spreading and material transport barriers. The method calculates particle dispersion only due to the time-dependent (eddy) part of the flow but along the particle trajectories in the full (eddy plus mean) flow. This effectively captures the effects of the mean advection on the eddy-driven dispersion because the Lagrangian quantities in (1) are determined by particle location. Note that the more straightforward analysis of particles in the full flow cannot serve this purpose because of the particle dispersion by the mean flow itself.\nNeutrally buoyant Lagrangian particles are released in 50 consecutive 400-day segments, starting with 130 000 particles in each layer. To examine the spatial distribution of the anisotropic spreading rates, this area is divided into 106 km by 106 km subregions, and the particles are divided into the corresponding groups, according to their initial positions. Particle spreading rates are computed for each subregion over the 400-day time interval. Typically, most particles in each group leave the subregion boundaries before they reach the diffusive regime, and these nonlocal effects must be accounted for. To do this for each group, we define a mean “particle cloud” by its center of mass, using (X, Y), and by its size, using the average zonal/meridional displacements. If several particle clouds overlap at a given point, the dispersion at this point is estimated by the ensemble average of the corresponding individual cloud dispersions. Particle clouds that touch solid boundaries are discarded.\na. Dispersion regimes\nThe long time asymptotic behavior of (8) is traditionally used to characterize different dispersion regimes (e.g., LaCasce 2008 ). In particular, the diffusive regime corresponds to the linear increase of the dispersion with time, achieved after sufficient time has passed, and (8) then provides an estimate for the eddy diffusivities. Deviations from the diffusion are quantified here by fitting tα+1 to\nand\n; the corresponding parameters are defined as\nand\n, respectively. In a purely diffusive regime, α is zero, whereas the superdiffusive regimes correspond to positive and subdiffusive regimes correspond to negative values of this parameter.\nThe map of parameter α shows that over the 400 days used to estimate the diffusivity in this study, the dispersion is not exactly diffusive in most of the domain ( Fig. 3 ). In particular,\nand\nare positive (superdiffusive spreading) in the western part of the domain but are negative (subdiffusive spreading) in the wide region centered around EJE. Spreading tends to become more diffusive in deeper layers. These deviations from the diffusive regime can be explained by several factors. First, the superdiffusive dispersion can be caused by the effects of the persistent shear in velocities. For example, in the extreme case of stationary velocity shear and no eddies, the spreading is purely “ballistic” (α = 1). Second, nonzero values of α can be found even in the flow that is locally diffusive but whose eddy kinetic energy and diffusivity vary strongly with location. This can happen because as they spread particles enter regions with weaker (stronger) eddies and thus slow (accelerate) their spreading rates ( Berloff et al. 2002 ; Rypina et al. 2012 ); the mean flow can potentially play a dominant role in these effects.\nFig. 3. Spreading regimes in the control simulation. Parameters (left)\nand (right)\nare shown in the top layer. Positive values correspond to superdiffusive and negative values correspond to subdiffusive spreading.\nThe importance of the mean advection can be estimated here by comparing the dispersion regimes in the control FTF simulation and a more traditional “eddy-only” run, in which the effects of the mean advection are neglected, and the particles only feel (i.e., are advected by) the eddying component of the flow. The eddy-only simulation exhibits more diffusive spreading along the main axis and the basin-averaged magnitude of\ndecreases from 0.44 to 0.20. In particular, the particle spreading in the western part of the domain is no longer superdiffusive, and this difference with the control simulation is explained by the mean advection. As particles in the control run move toward EJE, they experience more powerful eddy-driven spreading, which explains the increase in their dispersion and positive values of\nand\n. These conclusions are consistent with Rypina et al. (2012) .\nb. Anisotropic dispersion\nThe eddy diffusivity is strongly anisotropic, with Kξ exceeding Kη everywhere in the domain ( Fig. 4a ; Table 1 ). The largest diffusivities are found between the gyres in the EJE-dominated part of the domain, where the eddy kinetic energy is also the highest. In the top layer, the anisotropy parameter\nis the largest in the eastern part of the domain, where aaniso reaches 10.0; the area-averaged value of this parameter is 5.2. The spreading is the weakest and most isotropic in the southeastern (northeastern) parts of the subtropical (subpolar) gyres. With depth, the spreading becomes more isotropic near the EJE region but more anisotropic elsewhere ( Fig. 4b ). This is in accord with a greater relative importance of zonal transients in these regions ( section 2 ). In the area-averaged sense, the anisotropy increases with depth and becomes particularly large in the bottom layer ( Table 1 ). The major dispersion direction is not exactly zonal (area average is approximately 10°) and is therefore not aligned with the f/h contour, where f is the Coriolis frequency and h is the total depth of the fluid. The major spreading direction also crosses the background PV contours, most notably in the east of the domain ( Figs. 1c , 4a ).\nView larger version (55K)\nFig. 4. Anisotropic spreading rates in the control simulation. (left) Spreading ellipses (see text) are superimposed here on the anisotropy parameter aaniso (shaded); every ninth ellipse is shown for presentation purposes. Also shown is the time-mean streamfunction. (right) Zonally averaged aaniso in the three vertical layers.\nTable 1. Anisotropy coefficient aaniso in four simulations, area averaged within three vertical layers.\nTable 1. Anisotropy coefficient aaniso in four simulations, area averaged within three vertical layers.\nThe correlation time scales in the major and minor directions\nand\nexhibit substantial variability in the horizontal and vertical ( Table 2 ), demonstrating that the Lagrangian velocity variance alone is not sufficient to quantify the spatial dependence in diffusivities. The longest time scales are found in the intermediate layer 2 and in the interior of the subpolar and subtropical gyres (away from EJE). The velocity variance cannot explain the anisotropy in diffusivities either since\nsubstantially exceeds\nin most of the domain. The Lagrangian velocity variance in the major and minor directions\nand\nare, in contrast, very close to each other; the area-averaged ratio between them is 1.05, 1.13, and 0.92 in layers 1, 2, and 3, respectively. This would lead to an erroneous conclusion that diffusivities should be isotropic if the variability in the correlation times is not taken into account. These results are consistent with the analysis of altimetric velocities in Rypina et al. (2012) .\nTable 2. Correlation time scale\n(days) in four simulations within three vertical layers; the reported values are horizontal averages plus or minus the spatial std dev.\nTable 2. Correlation time scale\n(days) in four simulations within three vertical layers; the reported values are horizontal averages plus or minus the spatial std dev.\nImage of typeset table\nc. Causes of the dispersion anisotropy: Mean advection and zonal transients\nWe first examine the role of the mean advection by comparing the control simulation to the eddy-only (EO) experiment (which was described in section 3a ). In the EO simulations, the anisotropy parameter aaniso decreases in the top layer, with the largest changes in the EJE vicinity (not shown). However, aaniso remains larger than 2.0 in most of the domain and is larger than 5 in the northern and southern parts of the domain; the area-averaged value is 4.0. This demonstrates that, even in the absence of mean advection, the eddies cause anisotropic particle spreading. Because of the weakness of the mean advection in the deep layers, the differences between the standard and EO runs are only noticeable in the EJE vicinity. Interestingly,\ndoes not increase in the EJE vicinity in response to the removal of the mean advection, which is inconsistent with the idea of cross-flow mixing suppression. It is, however, plausible that our Lagrangian estimates can underestimate the suppression effects by the narrow EJE due to a large size of the corresponding particle clouds.\nWe next estimate the importance of zonal transients by analyzing a “zonal transient–dominated” sensitivity experiment ( Fig. 5a ). In this run, we low-pass Fourier filter the velocity streamfunction in the zonal direction with Lfilter = 30Rd1 (simulation LPx30Rd). For this purpose, the flow is decomposed into the Fourier series, 1 all Fourier coefficients corresponding to scales shorter than Lfilter are set to zero, and the inverse transform is applied. This simulation employs the FTF technique, so the full trajectories of particles are the same as in the control simulation.\nView larger version (73K)\nFig. 5. Sensitivity runs with the Fourier-filtered flows and the importance of zonal transients on the anisotropic spreading rates. (a) Zonal transient–dominated LPx30Rd simulation; (b) isotropic eddy–dominated HPx30Rd simulation. Spreading ellipses (see text) are superimposed here on the anisotropy parameter aaniso (shaded); every ninth ellipse is shown for presentation purposes. Also shown is the time-mean streamfunction.\nThe spreading rates become strongly anisotropic with aaniso exceeding 10.0 in most of the domain; aaniso also becomes more spatially uniform. Both\nand\nare reduced compare to the control run, but the reduction in\nis particularly dramatic, and this is consistent with the strong reduction in the meridional velocity variance. However, the Lagrangian correlation time scale\nincreases, particularly south and north of EJE, and this further outlines the fact that the velocity variance alone cannot explain the anisotropy. Last, the major dispersion direction becomes nearly zonal: the area-averaged θmax increases from only 2° to 4° with depth. These results suggest that zonal transients act to induce primarily zonal material transport and increase the correlation time scale in the major direction.\nWe now reverse the sensitivity experiment and carry out a simulation in the “isotropic eddy–dominated” experiment (HPx30Rd), where zonal transients are removed from the velocity streamfunction using the high-pass Fourier filter with Lfilter = 30Rd1. Several differences with the control simulation are notable. First, the spreading becomes more isotropic with the area-averaged aaniso ≈ 2.0 in all layers. This is despite the fact that\nis generally smaller than\n; for example, their area-averaged ratio in the top layer is 0.7. Note that a diffusivity estimate based entirely on the velocity variance would erroneously suggest that particle spreading should become predominantly meridional. Second, the correlation time scale\nis reduced, particularly in layers 2 and 3, and\nis increased, but the difference between these two scales is still significant ( Table 3 ). We can hypothesize that this is explained by the effects of the mean advection and zonal transients on the dispersion by the isotropic eddies, but the exact mechanism needs to be further investigated. Distribution of\nalso becomes more spatially uniform ( Table 2 ), which suggests that the velocity variance can be more readily used to quantify eddy diffusivity. Third, the direction of the maximum spreading is more nonzonal than in the control run, and the area-averaged θmax ≈ 16°. These results demonstrate that the isotropic eddies induce weakly anisotropic transport, with more spatially uniform correlation scales.\nTable 3. Correlation time scale\n(days) in four simulations within three vertical layers; the reported values are horizontal averages plus or minus the spatial std dev.\nTable 3. Correlation time scale\n(days) in four simulations within three vertical layers; the reported values are horizontal averages plus or minus the spatial std dev.\n4. Anisotropic transport and its causes in altimetry-based estimates\nSection:\nThe model-based results in section 3 strongly indicate that the anisotropy of the eddy-induced material transport and the predominantly zonal direction of preferred particle spreading are largely controlled by zonal transients. We now test these conclusions using a 17-yr-long record (from 1992 to 2009) of the geostrophic velocities inferred from AVISO sea surface height altimetric measurements. We focus here on the subtropical North Atlantic from 20° to 50°N and from 70° to 20°W; the data and methods are the same as in Rypina et al. (2012) . Similar to the model-based k–l velocity spectrum shown in Fig. 2 , the spectrum of geostrophic velocities ( Fig. 6 ) contains a noticeable peak in its zonal transient portion, where zonal scales exceed 1000 km. Unlike the model results, however, the isotropic part of the spectrum contains multiple peaks.\nView larger version (71K)\nFig. 6. Spatial (k–l) velocity spectrum of the geostrophic velocity (sum of the u and υ velocity spectra, where u and υ are in km day−1) inferred from the AVISO satellite altimetry, time averaged over the period from 1992 to 2009.\nWe now investigate the influence of this zonal transient spectral peak on the eddy-induced diffusivity by comparing particle spreading in simulations with the unfiltered eddies (control run) to simulations with the low-pass filtered (zonal transient dominated) and high-pass filtered (isotropic eddy dominated) eddy fields. As before, the diffusivities are quantified using the FTF approach and are visualized using the diffusivity ellipses ( Fig. 7 ). In comparison to the control run (green ellipses), in the zonal transient–dominated simulations (blue ellipses) both the zonal and meridional components of diffusivity become smaller, but the meridional component decreases significantly more than the zonal component. As a result, the ellipses become nearly zonal throughout most of the domain, and the anisotropy coefficient increases from 5.4 in the control to 7.9 in the zonal transient–dominated run. If, in the opposite, zonal transients are removed in the isotropic eddy–dominated flow, the zonal component of diffusivity decreases more than the meridional, and the ellipses become less anisotropic with the domain-averaged anisotropy coefficient of only 2.5 ( Fig. 7 , bottom). All of these results are in agreement with the model-based results of section 3 .\nView larger version (81K)\nFig. 7. Anisotropic transport and its causes in altimetry-based estimates of North Atlantic circulation. (top) Diffusivity ellipses in the three simulations: full unfiltered flow (green), low-pass filtered zonal transient–dominated flow (blue), and high-pass filtered flow (red). Anisotropy parameter aaniso in three simulations: (bottom left) full unfiltered flow, (bottom middle) low-pass filtered flow, and (bottom right) high-pass filtered flow.\n5. Tracer distribution in the numerical model\nSection:\nA practical application of the diffusivity estimates is to use them to parameterize eddies in non-eddy-resolving simulations. The task of eddy parameterization is therefore to reproduce tracer distribution using the diffusion instead of the eddy advection. We test the validity of this approach in simulations with idealized tracer release experiments. The distribution of the tracer c(x, y, t) is governed by the standard advective–diffusive equation:\nwhere\nis the diffusivity tensor estimated using\nand kbh is the biharmonic diffusivity required for numerical stability; its value of −5 × 1010 m4 s−1 is the same in all simulations. The term F(x, y) is the tracer source/sink.\nWe consider evolution of an isolated tracer patch:\nwhere (x0, y0) defines a center of the patch, and sx and sy is the size of the patch. We initialize the model with three tracer release experiments: a patch centered around EJE (central patch), a patch south of EJE (southern patch), and a patch north of EJE (northern patch).\nIn the absence of eddies, each patch is assumed to be balanced by a constant tracer source F:\nwhere\nis the time-mean velocity. We, therefore, consider a tracer anomaly that is due to a steady source, and this situation is relevant to tracers that do not have a direct feedback on their sources (such as surface salinity). The particular shape of (15) also corrects for the direct effects of the mean advection on the initial patch, which simplifies a comparison to the Lagrangian studies in section 3 . Simulations with F = 0 were also carried out and led to qualitatively similar conclusions, although the quantitative analysis is more challenging because of the significant deformation of the patches by the mean advection, collision of the patches with solid walls, and entrainment of the tracer into the western boundary current and EJE. It is, however, important to note that the mean advection is not powerful enough to dwarf the effects of eddies even if F = 0 and the tracer distributions with and without eddies are substantially different within the subtropical and subpolar gyre regions ( Fig. 8 ). This demonstrates the importance of the eddy advection even in the along-mean flow direction; if the opposite were true, only cross-mean flow diffusivity would be important and the anisotropic tensor\nwould not have any practical significance.\nView larger version (36K)\nFig. 8. Importance of eddies in the idealized tracer distributions. Tracer concentrations are shown at day 100 for two simulations with F = 0 and (a) full flow and (b) mean advection only. Central patch release is not shown because of its strong deformation by the EJE. Time-mean streamlines are shown by the black contours.\nIn the control simulation, the tracer is advected by the full flow (mean and eddy) and\n= 0. Ten consecutive 400-day simulations are averaged for the analysis. By the day 200, the patches are substantially modified by the eddying flow ( Fig. 9 ); the deformation is much stronger at day 400, which complicates the analysis at later stages. The integration is not continued beyond day 400 despite the fact that the statistical steady state is not reached. The southern and northern patches are being dispersed by eddies, whereas their centers of mass are moving very little in all simulations because of the action of F. The center of mass of the central patch in the top layer, in contrast, moves northwest despite the action of F; the distortion of the patch is still significantly smaller than in the F = 0 simulation. Layers 2 and 3 and all parameterized runs described below do not have the same problem.\nView larger version (58K)\nFig. 9. Distribution of an idealized tracer in numerical simulations. Tracer patches from the three different releases (northern patch, central patch, and southern patch) are overlapped and shown (in the top layer at day 200) for the initial distribution and sensitivity experiments.\nWe next analyze a series of sensitivity simulations, in which a part of the eddying flow is removed and replaced with diffusion. The resulting errors are quantified by the mean square of the difference with the control simulation for each patch; to make these numbers more meaningful, we also divide them by the mean square changes in the control simulation ( Table 4 ):\nwhere the angular brackets stand for the spatial average, and ccontrol is the tracer concentration in the control simulation. One needs to recall that the task of diffusion-based parameterization is to reproduce large-scale fields of the control simulation. To prevent the small-scale variance from dominating the errors and to make the quantitative analysis more relevant to the task of parameterization, the tracer is smoothed with a running-mean spatial filter with a width of 112 km (15 grid points).\nTable 4. Weighted mean square error in the tracer concentration (see text) at day 200 shown for the three tracer patches and in the three vertical layers.\nTable 4. Weighted mean square error in the tracer concentration (see text) at day 200 shown for the three tracer patches and in the three vertical layers.\nImage of typeset table\nThe eddy velocities are removed and replaced with\n(x, y) estimated using (13) from the data of section 3 . The resulting tracer distributions are similar to the control simulation in terms of the path location and shape, including eastward displacement of the center of the northern patch, small westward displacement of the center of the central patch, and asymmetric deformation of the southern patch ( Fig. 9 ). There are also some noticeable differences. In addition to the tracer distribution being considerably smoother than in the control simulation (which is expected), tracer maxima in the middle of each patch are also smeared out, and the meridional dispersion is generally overestimated. The largest differences are in the central and southern patches ( Table 4 ). All these biases can be attributed to the nonuniform distribution of eddy diffusivity, nonlocal Lagrangian methods used to estimate\n, and nondiffusive particle spreading.\nWhat is the relative importance of zonal transients and isotropic eddies? To answer this question, we carried out the zonal transient–dominated simulation with LPx30Rd velocities and isotropic eddy–dominated simulation with HPx30Rd velocities. Both simulations have\n= 0. The isotropic eddy–dominated simulation is intended to estimate the importance of zonal transients by removing their effects from the control run. The flow in this run contains most of the eddy fields (everything except zonal transients), and the improvements over the simulation with\n(x, y) can be anticipated and are indeed observed in layer 1 and central patches in all layers. Nevertheless, the absence of zonal transients causes considerable biases, most notably in the southern patch, which is overly symmetric in this simulation.\nThe effects of zonal transients are further studied in the zonal transient–dominated run. Simulated tracer distributions are surprisingly close to the simulation with\n(x, y) and even show some noticeable improvements, particularly for the southern patch and in layer 3. This is despite the fact that a rather small portion of the eddying velocities is used to advect the tracer. Tracer simulation with explicit zonal transients can be further improved if additional mixing is introduced to compensate for the missing isotropic eddies. To show the potential for such improvement, we add a constant isotropic diffusion with constant K = 500 m2 s−1. This is a rather typical value for isopycnal diffusivities in coarse resolution models, but it is smaller than the area-averaged values of Kξ and Kη in the control simulation in the top two layers. Values of 250 and 1000 m2 s−1 have also been tried but led to very similar values of Ce. In comparison to both the simulations with K(x, y) and isotropic eddies, this run exhibits noticeable improvements everywhere, except in the central patch of the top layer. Clearly, an explicit simulation of zonal transients has a pronounced effect on tracer simulations, and the parameterization of the eddy transport seems more plausible in this case.\n6. Discussion and conclusions\nSection:\nThis study examines the anisotropic transport properties of the eddying North Atlantic flow, using an idealized model of the double-gyre oceanic circulation and altimetry-derived velocities. In this study, we decompose the flow into three main components: time-mean advection, large-scale zonal transients, and the remainder of the eddy field. The material transport by the time-dependent flow (quantified by the eddy diffusivity tensor) varies geographically and is anisotropic, that is, it has a well-defined direction of the maximum transport. These properties are primarily explained by the action of transient motions, rather than the effects of the time-mean advection. In particular, zonal transients correspond to the primarily zonal material transport and explain the largest part of anisotropy in diffusivities for both numerically simulated and altimetry-based velocity fields.\nZonal transients are defined using the spatial velocity spectrum, which, in the upper ocean, shows a peak at the basinwide zonal scale and a nearly meridional wavevector. Because of these spectral properties, Lagrangian velocities in zonal transient–dominated flows are predominantly zonal and have persistent correlations in time. This makes zonal transients a particularly effective vehicle for the anisotropic material transport, despite the fact that the amount of energy contained in the zonal transient portion of the spectrum is relatively small. Anisotropy in transport is due primarily to the difference in the correlation time scales, rather than anisotropy of the velocity covariance matrix. Our definition of these transients is based solely on their zonal scales and they are, strictly speaking, spectral Fourier modes in the zonal direction. The dynamical interpretation of these transients and their origins remains to be established. In particular, it is possible that zonal transients are normal modes and exist because of the linear dynamics through their interactions with the mean flow ( Berloff and Kamenkovich 2013a , b ). Alternatively, the energy at the zonal transient part of the spectrum can exist because of the nonlinear energy transfer due to interactions among transient eddies ( Arbic et al. 2014 ). Investigation of the dynamics of zonal transients is left for future studies.\nAnisotropy in transport is quantified here using a diagonalized diffusivity tensor, although the transport properties are almost never perfectly diffusive. This nondiffusive behavior, combined with spatial inhomogeneity and anisotropy, makes the parameterization of eddy-induced transport challenging. This is demonstrated by biases in idealized tracer distributions in simulations, in which the eddy-induced transport is parameterized using Lagrangian diffusivity estimates. Since such estimates are not globally available below the surface, finding an effective parameterization for the entire eddying flow may be even more difficult than our study implies. Our results suggest, however, that this task becomes easier in simulations with explicit zonal transients since these flow components are associated with a large part of the complexity in the transport, such as spatial variability in the decorrelation scales and anisotropy. Zonal transients are large enough to be resolved by most numerical simulations even at relatively coarse spatial resolution, but such non-mesoscale-resolving simulations may lack the dynamics necessary to simulate zonal transients. The importance of large-scale transients and the utility of the Lagrangian estimates of eddy diffusivity need to be further studied for more realistic, climatically relevant tracers. This can be done using simulations with and without eddy advection (as in Booth and Kamenkovich 2008 ) and will be a subject of a future study.\nAcknowledgments\nWe thank two anonymous reviewers for their helpful suggestions on improving this manuscript. IK would like to acknowledge support through the NSF Grant OCE-1154923. IR was supported by the NSF OCE-1154641 and NASA Grant NNX14AH29G.\nREFERENCES\nSection:\nArbic, B., M. Mueller, J. Richman, J. Shriver, A. Morten, R. Scott, G. Serazin, and T. Penduff, 2014: Geostrophic turbulence in the frequency–wavenumber domain: Eddy-driven low-frequency variability. J. Phys. Oceanogr., 44, 2050–2069, doi: https://doi.org/10.1175/JPO-D-13-054.1 . Link\nBerloff, P., and I. Kamenkovich, 2013a: On spectral analysis of mesoscale eddies. Part I: Linear analysis. J. Phys. Oceanogr., 43, 2505–2527, doi: https://doi.org/10.1175/JPO-D-12-0232.1 . Link\nBerloff, P., and I. Kamenkovich, 2013b: On spectral analysis of mesoscale eddies. Part II: Nonlinear analysis. J. Phys. Oceanogr., 43, 2528–2544, doi: https://doi.org/10.1175/JPO-D-12-0233.1 . Link\nBerloff, P., J. C. McWilliams, and A. Bracco, 2002: Material transport in oceanic gyres. Part I: Phenomenology. J. Phys. Oceanogr., 32, 764–796, doi: https://doi.org/10.1175/1520-0485(2002)032<0764:MTIOGP>2.0.CO;2 . Link\nBerloff, P., I. Kamenkovich, and J. Pedlosky, 2009: A mechanism for the formation of multiple zonal jets in the oceans. J. Fluid Mech., 628, 395–425, doi: https://doi.org/10.1017/S0022112009006375 . Crossref\nBooth, J., and I. Kamenkovich, 2008: Isolating the role of mesoscale eddies in mixing of a passive tracer in an eddy resolving model. J. Geophys. Res., 113, C05021, doi: https://doi.org/10.1029/2007JC004510 . Crossref\nFerrari, R., and M. Nikurashin, 2010: Suppression of eddy diffusivity across jets in the Southern Ocean. J. Phys. Oceanogr., 40, 1501–1519, doi: https://doi.org/10.1175/2010JPO4278.1 . Link\nFreeland, H. J., P. B. Rhines, and T. Rossby, 1975: Statistical observations of the trajectories of neutrally buoyant floats in the North Atlantic. J. Mar. Res., 33, 383–404.\nGreen, J. S. A., 1970: Transfer properties of the large-scale eddies and the general circulation of the atmosphere. Quart. J. Roy. Meteor. Soc., 96, 157–185, doi: https://doi.org/10.1002/qj.49709640802 . Crossref\nHaynes, P. H., D. A. Poet, and E. F. Shuckburgh, 2007: Transport and mixing in kinematic and dynamically consistent flows. J. Atmos. Sci., 64, 3640–3651, doi: https://doi.org/10.1175/JAS4030.1 . Link\nHenning, C. C., and G. Vallis, 2004: The effects of mesoscale eddies on the main subtropical thermocline. J. Phys. Oceanogr., 34, 2428–2443, doi: https://doi.org/10.1175/JPO2639.1 . Link\nHuang, H.-P., A. Kaplan, E. Curchitser, and N. Maximenko, 2007: The degree of anisotropy for mid-ocean currents from satellite observations and an eddy-permitting model simulation. J. Geophys. Res., 112, C09005, doi: https://doi.org/10.1029/2007JC004105 . Crossref\nKamenkovich, I., P. Berloff, and J. Pedlosky, 2009: Anisotropic material transport by eddies and eddy-driven currents in a model of the North Atlantic. J. Phys. Oceanogr., 39, 3162–3175, doi: https://doi.org/10.1175/2009JPO4239.1 . Link\nKarabasov, S. A., P. S. Berloff, and V. M. Goloviznin, 2009: CABARET in the ocean gyres. Ocean Modell., 30, 155–168, doi: https://doi.org/10.1016/j.ocemod.2009.06.009 . Crossref\nKillworth, P., 1997: On the parameterization of the eddy transfer. Part I. Theory. J. Mar. Res.,55, 1171–1197, doi: https://doi.org/10.1357/0022240973224102 .\nLaCasce, J. H., 2000: Floats and f/H. J. Mar. Res., 58, 61–95, doi: https://doi.org/10.1357/002224000321511205 . Crossref\nLaCasce, J. H., 2008: Lagrangian statistics from oceanic and atmospheric observations. Transport and Mixing in Geophysical Flows, J. B. Weiss and A. Provezale, Eds., Springer, 165–228. Crossref\nLaCasce, J. H., and A. Bower, 2000: Relative dispersion in the subsurface North Atlantic. J. Mar. Res., 58, 863–894, doi: https://doi.org/10.1357/002224000763485737 . Crossref\nPrandtl, L., 1925: Bericht über Untersuchungen zur ausgebildeten Turbulenz. Z. Angew. Math. Mech., 5, 136–139.\nRypina, I. I., L. J. Pratt, and M. S. Lozier, 2011: Near-surface transport pathways in the North Atlantic Ocean: Looking for throughput from the subtropical to subpolar gyre. J. Phys. Oceanogr., 41, 911–925, doi: https://doi.org/10.1175/2011JPO4498.1 . Link\nRypina, I. I., I. Kamenkovich, P. Berloff, and L. Pratt, 2012: Eddy-induced particle dispersion in the near-surface North Atlantic. J. Phys. Oceanogr., 42, 2206–2228, doi: https://doi.org/10.1175/JPO-D-11-0191.1 . Link\nSallee, J.-B., K. Speer, R. Morrow, and R. Lumpkin, 2008: An estimate of Lagrangian eddy statistics and diffusion in the mixed layer of the Southern Ocean. J. Mar. Res., 66, 441–463, doi: https://doi.org/10.1357/002224008787157458 . Crossref\nSamelson, R., 1992: Fluid exchange across a meandering jet. J. Phys. Oceanogr., 22, 431–444, doi: https://doi.org/10.1175/1520-0485(1992)022<0431:FEAAMJ>2.0.CO;2 . Link\nSmith, K. S., 2005: Tracer transport along and across coherent jets in two-dimensional turbulent flow. J. Fluid Mech., 544, 133–142, doi: https://doi.org/10.1017/S0022112005006750 . Crossref\nSpall, M. A., P. L. Richardson, and J. Price, 1993: Advection and eddy mixing in the Mediterranean salt tongue. J. Mar. Res., 51, 797–818, doi: https://doi.org/10.1357/0022240933223882 . Crossref\nTaylor, G. I., 1921: Diffusion by continuous movements. Proc. London Math. Soc., 20, 196–211, doi: https://doi.org/10.1112/plms/s2-20.1.196 . Crossref\nTaylor, G. I., 1953: Dispersion of soluble matter in solvent flowing slowly through a tube. Proc. Roy. Soc. London, A219, 186–203, doi: https://doi.org/10.1098/rspa.1953.0139 . Crossref\nVallis, G. K., 2006: Atmospheric and Oceanic Fluid Dynamics. Cambridge University Press, 745 pp.\nVeneziani, M., A. Griffa, A. M. Reynolds, Z. D. Garraffo, and E. P. Chassignet, 2005: Parameterizations of Lagrangian spin statistics and particle dispersion in the presence of coherent vortices. J. Mar. Res., 63, 1057–1083, doi: https://doi.org/10.1357/002224005775247571 . Crossref\nYoung, W. R., P. B. Rhines, and C. J. R. Garrett, 1982: Shear-flow dispersion, internal waves and horizontal mixing in the oceans. J. Phys. Oceanogr., 12, 515–527, doi: https://doi.org/10.1175/1520-0485(1982)012<0515:SFDIWA>2.0.CO;2 . Link\n1 Note that although the flow satisfies the no-normal flow and no-slip boundary conditions, the streamfunction is not periodic in the strict sense. Nevertheless, the results with the Fourier transform and with and without window tapering and the use of the sine transform lead to very similar results.\nMarch 2015\n""","0.3372391","""https://journals.ametsoc.org/doi/10.1175/JPO-D-14-0164.1""","[-0.178219,51.500505]"
"""UCL""","""Iris Publication""","""http://discovery.ucl.ac.uk/1368321/\nAbstract\nToday, passenger transport worldwide is responsible for almost 15 percent of anthropogenic energy-related emissions of carbon dioxide (CO 2 ), the most abundant greenhouse gas. If the strong forces that generate travel demand and concomitant greenhouse gas emission continue, world passenger traffic volume may rise more than fourfold over the 1990 level by 2050. During the same period, carbon dioxide emissions due to passenger transport are expected to multiply by a factor of more than 3, ultimately accounting for 2.7 billion tons of carbon in 2050. Based on these projections, the present study evaluates a range of emission-reduction options. Among these, technological measures offer the greatest potential and are key to drastically reducing carbon dioxide emissions. Radical fuel efficiency improvements in the world's automobile fleet-along with continuations of past trends in the energy intensity of other passenger transport modes-could curtail the projected 2050 baseline emissions level by about 40 percent. Simultaneously substitution of oil products by natural gas could reduce CO 2  emissions by another 25 percent and ultimately lead to emission stabilization at 1.2 billion tons of carbon in 2050; any further significant reduction CO 2  emissions would require the large-scale introduction of zero-carbon fuels. Although the CO 2 -reduction potential of transportation systems management measures is comparatively limited, such measures are needed to abate other transport sector externalities such as accidents, noise, and traffic congestion.\nPublication data is maintained in RPS. Visit https://rps.ucl.ac.uk\n› More search options\n""","0.65796405","""http://iris.ucl.ac.uk/iris/publication/782419/7""",
"""Cranfield_University""","""A review of physics-based models in prognostics: Application to gears and bearings of rotating machineryAdvances in Mechanical Engineering - Adrian Cubillo, Suresh Perinpanayagam, Manuel Esperon-Miguez, 2016""","""Download in PowerPoint\nFigure 9. Qualitative Stribeck curve: friction (µ), Sommerfeld number (N: speed, p: load, η: dynamic viscosity of the lubricant, R: radius of the bearing, c: clearance of the bearing).\nHydrodynamic contacts in rotating machinery, typically rolling and hydrodynamic bearings, are designed to operate on the hydrodynamic region, where the contact is fully lubricated and the friction forces are exclusively caused by the shear stresses of the lubricant. The fluid can be considered laminar and a simplified version of the Reynolds equation 144 using dimensionless parameters can be integrated along the bearing to calculate the film thickness and pressure distribution as shown in equation (15) , where\nh\nis the dimensionless film thickness,\np\ndxdy\n(18)\nFor plain journal bearings, the film thickness h can be obtained as a function of the geometry and the eccentricity ratio ε, as shown in equation (19) , where c is the clearance and θ is the radial angle. Thus, an analytical solution of the Reynolds equation (15) is obtained ( equation (20) ), where p is the pressure distribution as a function of the radial angle θ, the relative speed between the sliding surfaces U, the eccentricity ratio ε, the axial position y, the dynamic viscosity η and geometrical parameters: radius R, clearance c and bearing length L. The friction force can be obtained analytically as shown in equation (21) . 145 Alternatively, Sinanoglu et al. 146 successfully estimated the pressure variations of a journal bearing using an ANN, but several pressure sensors along the bearing were required to train the network\nh\n)\n(22)\nAn alternative approach is to use computational fluid dynamics (CFD) for hydrodynamic lubrication and to combine it with computational structural analysis for EHL. Stefani and Rebora 148 developed a CFD model that takes into account the wall convection, the thermo-mechanical deformations and the mixing phenomena in the groove, while Jin and Zuo 149 also used a CFD model to study the effect of different groove depths in journal bearings.\nMixed lubrication refers to the region in which partial metal–metal contact occurs and part of the load is transmitted by asperities. In this situation, surface parameters must be taken into account and the complexity and quantity of unknown parameters increase. Gelinck and Schipper 150 have developed a mixed lubrication model for line contacts which was later improved and validated for point contacts by Liu, 151 and which agreed with experimental results as shown by Lu et al. 152 The mixed lubrication model first calculates the film thickness and applies the mixed lubrication model if h < hlim is true; otherwise, the contact is considered hydrodynamic, h being the minimum film thickness and hlim the limit at which mixed lubrication occurs. The mixed lubrication model assumes a percentage of the load transmitted through asperities,\nδ\n2\n, and compares the pressure distribution transmitted through the asperities with the pressure distribution considering a Hertzian contact;\nδ\nis updated until equation (23) converges, where F3/2 is illustrated in equation (24) ,\nn\nis the dimensionless density of asperity summits,\nσ\n¯\ns\nis the dimensionless standard deviation of the asperity height distribution, W is the load, A is the apparent contact area, pmax is the maximum Hertzian pressure and\nΦ\nds\n(24)\nThe Greenwood and Williamson 153 asperity contact model was used to calculate the load transmitted through the asperities, by considering spherical summits with a height that follows a Gaussian distribution subject to elastic deformation.\nUnder mixed lubrication, the friction coefficient is calculated as a function of the shear stress of the lubricant for the load transmitted through the lubricant ( equation (16) ) and using Coulomb law ( equation (14) ) for the load transmitted through the asperities as shown in equation (25) , where\nμ\nμ\nc\nis the friction coefficient for a dry contact, F is the friction force, W is the load and\nτ\nis the shear stress of the lubricant\nμ\nSection:\n1.\nKothamasu, R, Huang, SH, Verduin, WH. System health monitoring and prognostics – a review of current paradigms and practices. Int J Adv Manuf Tech 2006; 28: 1012–1024. Google Scholar , Crossref\n2.\nJennions, IK. Integrated vehicle health management: perspectives on an emerging field. Warrendale, PA: SAE International, 2011. Google Scholar , Crossref\n3.\nMacConnell, JH. ISHM & design: a review of the benefits of the ideal ISHM system. In: Proceedings of the 2007 IEEE aerospace conference, Seattle, WA, 3–10 March 2007, pp.1–18. New York: IEEE. Google Scholar\n4.\nBaroth, E, Powers, WT, Fox, J. IVHM (Integrated Vehicle Health Management) techniques for future space vehicles. In: Proceedings of the 37th joint propulsion conference and exhibit 2001, Salt Lake City, UT, 8–11 July 2011, pp.1–10. AIAA. Google Scholar\n5.\nSikorska, JZ, Hodkiewicz, M, Ma, L. Prognostic modelling options for remaining useful life estimation by industry. Mech Syst Signal Pr 2011; 25: 1803–1836. Google Scholar , Crossref\n6.\nLee, J, Wu, F, Zhao, W. Prognostics and health management design for rotary machinery systems – reviews, methodology and applications. Mech Syst Signal Pr 2014; 42: 314–334. Google Scholar , Crossref\n7.\nEngel, SJ, Gilmartin, BJ, Bongort, K. Prognostics, the real issues involved with predicting life remaining. In: Proceedings of the IEEE aerospace conference proceedings, Big Sky, MT, 18–25 March 2000, vol. 6, pp.457–470. New York: IEEE. Google Scholar , Crossref\n8.\nEker, OF, Camci, F, Jennions, IK. Major challenges in prognostics: study on benchmarking prognostics datasets. In: Proceedings of the PHM, Dresden, 3–5 July 2012, vol. 3, pp.1–8. PHM Society. Google Scholar\n9.\nHeng, A, Zhang, S, Tan, ACC. Rotating machinery prognostics: state of the art, challenges and opportunities. Mech Syst Signal Pr 2009; 23: 724–739. Google Scholar , Crossref\n10.\nLuo, J, Namburu, M, Pattipati, K. Model-based prognostic techniques [maintenance applications]. In: Proceedings of the IEEE systems readiness technology conference (AUTOTESTCON 2003), Anaheim, CA, 22–25 September 2003, pp.330–340. New York: IEEE. Google Scholar\n11.\nLi, C, Liang, M. Time–frequency signal analysis for gearbox fault diagnosis using a generalized synchrosqueezing transform. Mech Syst Signal Pr 2012; 26: 205–217. Google Scholar , Crossref\n12.\nMu-jun, X, Shi-Yong, X. Fault diagnosis of air compressor based on RBF neural network. In: Proceedings of the 2011 international conference on mechatronic science, electric engineering and computer (MEC), Jilin, China, 19–22 August 2011, pp.887–890. New York: IEEE. Google Scholar\n13.\nFerreiro, S, Arnaiz, A, Sierra, B. Application of Bayesian networks in prognostics for a new Integrated Vehicle Health Management concept. Expert Syst Appl 2012; 39: 6402–6418. Google Scholar , Crossref\n14.\nZio, E, Di Maio, F. Fatigue crack growth estimation by relevance vector machine. Expert Syst Appl 2012; 39: 10681–10692. Google Scholar , Crossref\n15.\nPantelelis, NG, Kanarachos, AE, Gotzias, N. Neural networks and simple models for the fault diagnosis of naval turbochargers. Math Comput Simulat 2000; 51: 387–397. Google Scholar , Crossref\n16.\nSaxena, A, Saad, A. Evolving an artificial neural network classifier for condition monitoring of rotating mechanical systems. Appl Soft Comput 2007; 7: 441–454. Google Scholar , Crossref\n17.\nSu, H, Chong, K-T. Induction machine condition monitoring using neural network modeling. IEEE T Ind Electron 2007; 54: 241–249. Google Scholar , Crossref\n18.\nReda Taha, MM, Lucero, J. Damage identification for structural health monitoring using fuzzy pattern recognition (SEMC 2004 structural health monitoring, damage detection and long-term performance; Second international conference on structural engineering, mechanics and computation). Eng Struct 2005; 27: 1774–1783. Google Scholar\n19.\nBaraldi, P, Mangili, F, Zio, E. A Kalman filter-based ensemble approach with application to turbine creep prognostics. IEEE T Reliab 2012; 61: 966–977. Google Scholar , Crossref\n20.\nPolikar, R. Ensemble based systems in decision making. IEEE Circ Syst Mag 2006; 6: 21–45. Google Scholar , Crossref\n21.\nJardine, AKS, Lin, D, Banjevic, D. A review on machinery diagnostics and prognostics implementing condition-based maintenance. Mech Syst Signal Pr 2006; 20: 1483–1510. Google Scholar , Crossref\n22.\nLei, Y, Lin, J, He, Z. A review on empirical mode decomposition in fault diagnosis of rotating machinery. Mech Syst Signal Pr 2013; 35: 108–126. Google Scholar , Crossref\n23.\nSait, AS, Sharaf-Eldeen, YI. A review of gearbox condition monitoring based on vibration analysis techniques diagnostics and prognostics, vol. 5 (Proceedings of the society for experimental mechanics series). New York: Springer, 2011, pp.307–324. Google Scholar , Crossref\n24.\nAn, D, Kim, NH, Choi, JH. Options for prognostics methods: a review of data-driven and physics-based prognostics. In: Proceedings of the 54th AIAA/ASME/ASCE/AHS/ASC structures, structural dynamics, and materials conference, Boston, MA, 8–11 April 2013, pp.1–14. Reston, VA: AIAA. Google Scholar\n25.\nLuo, J, Bixby, A, Pattipati, K. An interacting multiple model approach to model-based prognostics. In: Proceedings of the 2003 IEEE international conference on systems, man and cybernetics, Washington, DC, 5–8 October 2003, vol. 1, pp.189–194. New York: IEEE. Google Scholar\n26.\nLi, B, Chow, M-Y, Tipsuwan, Y. Neural-network-based motor rolling bearing fault diagnosis. IEEE T Ind Electron 2000; 47: 1060–1069. Google Scholar , Crossref\n27.\nParis, PC, Gomez, MP, Anderson, WE. A rational analytic theory of fatigue. Trend Eng 1961; 13: 9–14. Google Scholar\n28.\nCorbetta, M, Sbarufatti, C, Manes, A. Sequential Monte Carlo sampling for crack growth prediction providing for several uncertainties. In: Proceedings of the 2nd European conference of the prognostics and health management society 2014, Nantes, 8–10 July 2014, vol. 5, pp.1–13. PHM Society. Google Scholar\n29.\nRay, A, Tangirala, S. Stochastic modeling of fatigue crack dynamics for on-line failure prognostics. IEEE T Contr Syst T 1996; 4: 443–451. Google Scholar , Crossref\n30.\nOrchard, M, Kacprzynski, G, Goebel, K. Advances in uncertainty representation and management for particle filtering applied to prognostics. In: Proceedings of the prognostics and health management international conference, Denver, CO, 6–9 October 2008, pp.1–6. New York: IEEE. Google Scholar\n31.\nOppenheimer, CH, Loparo, KA. Physically based diagnosis and prognosis of cracked rotor shafts. In: Proceedings of the components and systems diagnostics, prognostics, and health management II, Orlando, FL, 1 April 2002, pp.122–132. Bellingham, WA: SPIE. Google Scholar\n32.\nLi, CJ, Lee, H. Gear fatigue crack prognosis using embedded model, gear dynamic model and fracture mechanics. Mech Syst Signal Pr 2005; 19: 836–846. Google Scholar , Crossref\n33.\nCoppe, A, Pais, MJ, Kim, N-H. Identification of equivalent damage growth parameters for general crack geometry. In: Proceedings of the annual conference of the prognostics and health management society, Portland, OR, 10–16 October 2010, pp.1–10. PHM Society. Google Scholar\n34.\nOrsagh, RF, Sheldon, J, Klenke, CJ. Prognostics/diagnostics for gas turbine engine bearings. In: Proceedings of the 2003 IEEE aerospace conference, Big Sky, MT, 8–15 March 2003, pp.3095–3103. New York: IEEE. Google Scholar\n35.\nJaw, LC, Wang, W. Mathematical formulation of model-based methods for diagnostics and prognostics. In: Proceedings of the 2006 ASME 51st turbo expo: power for land, sea, and air, Barcelona, 8–11 May 2006, pp.691–697. New York: ASME. Google Scholar\n36.\nLi, Y, Kurfess, TR, Liang, SY. Stochastic prognostics for rolling element bearings. Mech Syst Signal Pr 2000; 14: 747–762. Google Scholar , Crossref\n37.\nLi, Y, Billington, S, Zhang, C. Adaptive prognostics for rolling element bearing condition. Mech Syst Signal Pr 1999; 13: 103–113. Google Scholar , Crossref\n38.\nSimon, D. A comparison of filtering approaches for aircraft engine health estimation. Aerosp Sci Technol 2008; 12: 276–284. Google Scholar , Crossref\n39.\nWagner, J, Shoureshi, R. A robust failure diagnostics scheme for nonlinear thermofluid processes. In: Proceedings of the 1987 American control conference, Minneapolis, MN, 10–12 June 1987, pp.1877–1882. New York: IEEE. Google Scholar\n40.\nLaroche, E, Sedda, E, Durieu, C. Methodological insights for online estimation of induction motor parameters. IEEE T Contr Syst T 2008; 16: 1021–1028. Google Scholar , Crossref\n41.\nSimani, S. Identification and fault diagnosis of a simulated model of an industrial gas turbine. IEEE T Ind Inform 2005; 1: 202–216. Google Scholar , Crossref\n42.\nPeel, L. Data driven prognostics using a Kalman filter ensemble of neural network models. In: Proceedings of the 2008 international conference on prognostics and health management (PHM 2008), Denver, CO, 6–9 October 2008, pp.1–6. New York: IEEE. Google Scholar\n43.\nSaha, B, Goebel, K, Christophersen, J. Comparison of prognostic algorithms for estimating remaining useful life of batteries. T I Meas Control 2009; 31: 293–308. Google Scholar , Link\n44.\nBaraldi, P, Cadinia, F, Mangilia, F. Prognostics under different available information. Chem Eng 2013; 33: 163–168. Google Scholar\n45.\nTinga, T. Principles of loads and failure mechanisms: applications in maintenance, reliability and design. London: Springer Science & Business Media, 2013. Google Scholar , Crossref\n46.\nCastro, J, Seabra, J. Global and local analysis of gear scuffing tests using a mixed film lubrication model. Tribol Int 2008; 41: 244–255. Google Scholar , Crossref\n47.\nMcFadden, PD, Toozhy, MM. Application of synchronous averaging to vibration monitoring of rolling element bearings. Mech Syst Signal Pr 2000; 14: 891–906. Google Scholar , Crossref\n48.\nQiu, J, Seth, BB, Liang, SY. Damage mechanics approach for bearing lifetime prognostics. Mech Syst Signal Pr 2002; 16: 817–829. Google Scholar , Crossref\n49.\nWarren, AW, Guo, YB. Acoustic emission monitoring for rolling contact fatigue of superfinished ground surfaces. Int J Fatigue 2007; 29: 603–614. Google Scholar , Crossref\n50.\nRahman, Z, Ohba, H, Yoshioka, T. Incipient damage detection and its propagation monitoring of rolling contact fatigue by acoustic emission. Tribol Int 2009; 42: 807–815. Google Scholar , Crossref\n51.\nHort, F, Mazal, P, Vlasic, F. Monitoring of acoustic emission signal of loaded axial bearings. J Mater Sci Eng A: Struct Mater Prop Microstruct Process 2010; 1: 717–724. Google Scholar\n52.\nHort, F, Mazal, P. Application of acoustic emission for measuring of contact fatigue of axial bearing. Eng Mech 2011; 18: 117–125. Google Scholar\n53.\nElforjani, M, Mba, D. Observations and location of acoustic emissions for a naturally degrading rolling element thrust bearing. J Fail Anal Prev 2008; 8: 370–385. Google Scholar , Crossref\n54.\nGuo-Lu, L, Zhi-Qiang, Z, Hai-Dou, W. Acoustic emission monitoring and failure mechanism analysis of rolling contact fatigue for Fe-based alloy coating. Tribol Int 2013; 61: 129–137. Google Scholar , Crossref\n55.\nSunnersjö, CS. Rolling bearing vibrations – the effects of geometrical imperfections and wear. J Sound Vib 1985; 98: 455–474. Google Scholar , Crossref\n56.\nSawalhi, N, Randall, RB. Vibration response of spalled rolling element bearings: observations, simulations and signal processing techniques to track the spall size. Mech Syst Signal Pr 2011; 25: 846–870. Google Scholar , Crossref\n57.\nZhang, Z-Q, Li, G-L, Wang, H-D. Investigation of rolling contact fatigue damage process of the coating by acoustics emission and vibration signals. Tribol Int 2012; 47: 25–31. Google Scholar , Crossref\n58.\nPrice, ED, Lees, AW, Friswell, MI. Detection of severe sliding and pitting fatigue wear regimes through the use of broadband acoustic emission. Proc IMechE, Part J: J Engineering Tribology 2005; 219: 85–98. Google Scholar , Link\n59.\nGuo, YB, Schwach, DW. An experimental investigation of white layer on rolling contact fatigue using acoustic emission technique. Int J Fatigue 2005; 27: 1051–1061. Google Scholar , Crossref\n60.\nTan, CK, Irving, P, Mba, D. A comparative experimental study on the diagnostic and prognostic capabilities of acoustics emission, vibration and spectrometric oil analysis for spur gears. Mech Syst Signal Pr 2007; 21: 208–233. Google Scholar , Crossref\n61.\nElasha, F, Ruiz-Cárcel, C, Mba, D. Pitting detection in worm gearboxes with vibration analysis. Eng Fail Anal 2014; 42: 366–376. Google Scholar , Crossref\n62.\nFeng, Z, Liang, M. Fault diagnosis of wind turbine planetary gearbox under nonstationary conditions via adaptive optimal kernel time–frequency analysis. Renew Energ 2014; 66: 468–477. Google Scholar , Crossref\n63.\nTan, CK, Mba, D. Identification of the acoustic emission source during a comparative study on diagnosis of a spur gearbox. Tribol Int 2005; 38: 469–480. Google Scholar , Crossref\n64.\nPeng, Z, Kessissoglou, N. An integrated approach to fault diagnosis of machinery using wear debris and vibration analysis. Wear 2003; 255: 1221–1232. Google Scholar , Crossref\n65.\nKim, Y-H, Tan, ACC, Mathew, J. Condition monitoring of low speed bearings: a comparative study of the ultrasound technique versus vibration measurements. In: Proceedings of the 1st world congress on engineering asset management (WCEAM), Gold Coast, QLD, Australia, 11–14 July 2006, pp.182–191. London: Springer. Google Scholar\n66.\nChoudhury, A, Tandon, N. Application of acoustic emission technique for the detection of defects in rolling element bearings. Tribol Int 2000; 33: 39–45. Google Scholar , Crossref\n67.\nHe, Y, Zhang, X, Friswell, MI. Observation of time-frequency characteristics of the acoustic emission from defects in rolling element bearings. Insight 2010; 52: 412–418. Google Scholar , Crossref\n68.\nJamaludin, N, Mba, D. Monitoring extremely slow rolling element bearings: part I. NDT&E Int 2002; 35: 349–358. Google Scholar , Crossref\n69.\nJamaludin, N, Mba, D. Monitoring extremely slow rolling element bearings: part II. NDT&E Int 2002; 35: 359–366. Google Scholar , Crossref\n70.\nZakrajsek, JJ, Lewicki, DG. Detecting gear tooth fatigue cracks in advance of complete fracture. Tribotest 1998; 4: 407–422. Google Scholar , Crossref\n71.\nHa, JM, Park, J, Youn, BD. Fault diagnostics of planet gears in wind turbine using autocorrelation-based time synchronous averaging (ATSA). In: Proceedings of the second European conference of the prognostics and health management society 2014, Nantes, 8–10 July 2014, pp.1–8. PHM Society. Google Scholar\n72.\nSun, J, Wood, RJK, Wang, L. Wear monitoring of bearing steel using electrostatic and acoustic emission techniques. Wear 2005; 259: 1482–1489. Google Scholar , Crossref\n73.\nHarvey, TJ, Wood, RJK, Powrie, HEG. Electrostatic wear monitoring of rolling element bearings. Wear 2007; 263: 1492–1501. Google Scholar , Crossref\n74.\nBoness, RJ, McBride, SL. Adhesive and abrasive wear studies using acoustic emission techniques. Wear 1991; 149: 41–53. Google Scholar , Crossref\n75.\nFeng, Z, Zuo, MJ, Hao, R. Gear crack assessment based on cyclic correlation analysis. In: Proceedings of the 8th international conference on reliability, maintainability and safety (ICRMS 2009), Chengdu, China, 20–24 July 2009, pp.1071–1076. New York: IEEE. Google Scholar\n76.\nKacprzynski, GJ, Roemer, GJ, Modgil, G. Enhancement of physics-of-failure prognostic models with system level features. In: Proceedings of the 2002 IEEE aerospace conference, Big Sky, MT, 9–16 March 2002, vol. 6, pp.2919–2925. New York: IEEE. Google Scholar\n77.\nKacprzynski, GJ, Sarlashkar, A, Roemer, MJ. Predicting remaining life by fusing the physics of failure modeling with diagnostics. JOM: J Min Met Mat S 2004; 56: 29–35. Google Scholar , Crossref\n78.\nPaya, BA, Esat, II, Badi, MNM. Artificial neural network based fault diagnostics of rotating machinery using wavelet transforms as a preprocessor. Mech Syst Signal Pr 1997; 11: 751–765. Google Scholar , Crossref\n79.\nTang, B, Song, T, Li, F. Fault diagnosis for a wind turbine transmission system based on manifold learning and Shannon wavelet support vector machine. Renew Energ 2014; 62: 1–9. Google Scholar , Crossref\n80.\nJack, LB, Nandi, AK. Fault detection using support vector machines and artificial neural networks, augmented by genetic algorithms. Mech Syst Signal Pr 2002; 16: 373–390. Google Scholar , Crossref\n81.\nDu, Y, Zhang, W, Zhang, Y. Fault diagnosis of rotating machines for rail vehicles based on local mean decomposition – energy moment – directed acyclic graph support vector machine. Adv Mech Eng 2016; 8: 1–6. Google Scholar , Link\n82.\nSun, X, Tan, J, Wen, Y. Rolling bearing fault diagnosis method based on data-driven random fuzzy evidence acquisition and Dempster–Shafer evidence theory. Adv Mech Eng 2016; 8: 1–8. Google Scholar , Link\n83.\nWu, TY, Chen, JC, Wang, CC. Characterization of gear faults in variable rotating speed using Hilbert-Huang Transform and instantaneous dimensionless frequency normalization. Mech Syst Signal Pr 2012; 30: 103–122. Google Scholar , Crossref\n84.\nMaru, MM, Castillo, RS, Padovese, LR. Study of solid contamination in ball bearings through vibration and wear analyses. Tribol Int 2007; 40: 433–440. Google Scholar , Crossref\n85.\nOkamoto, K, Shiihara, H, Nagayama, Y. Effective condition monitoring methods for diesel main bearing: high frequency vibration measurement and wear particle detection. Jpn Inst Mar Eng 2007; 42: 560–565. Google Scholar , Crossref\n86.\nMoosavian, A, Ahmadi, H, Tabatabaeefar, A. Comparison of two classifiers; K-nearest neighbor and artificial neural network, for fault diagnosis on a main engine journal-bearing. Shock Vib 2013; 20: 263–272. Google Scholar , Crossref\n87.\n""","0.19339481","""http://journals.sagepub.com/doi/10.1177/1687814016664660""","[-0.629225,52.074389]"
"""University_of_Birmingham""","""Public health policy and walking in England—analysis of the 2008 ‘policy window’ | BMC Public Health | Full Text""","""Public health policy and walking in England—analysis of the 2008 ‘policy window’\nAbstract\nBackground\nAlthough the government in England has a long-standing interest in walking promotion, this has not been accompanied by a coherent strategic plan or investment to support physical activity behaviour change. However, in 2008 the government announced its intention to invest £7 million into walking promotion. This article utilises Kingdon’s Multiple Streams framework as an organising principle through which to interrogate the reasons behind the increased emphasis on walking promotion as part of the public health policy agenda in England.\nMethods\nThe research adopted a case study design. Data were obtained through document analysis of relevant policies and semi-structured interviews with experts in the walking sector, including both government and non-government representatives.\nResults\nKingdon’s Multiple Streams theory proposes that at certain points in time, ‘policy windows’ are created through the convergence of a problem, an appropriate solution, and a receptive political environment, and this policy window presents an opportunity for major policy change. The findings of this research suggest that the success of London in securing the 2012 Olympic and Paralympic Games was the primary trigger in the creation of a policy window for walking promotion in recent years.\nConclusions\nDespite previous interest in walking promotion from the health and transport sectors, it was the recent alignment with the sports agenda that led to increased political commitment. This raises concerns that the research evidence on the health benefits of physical activity and rising levels of inactivity in England, are insufficient to secure government support and investment, and that multi-sector lobbying and joined-up political action may be critical in advancing this agenda.\nKeywords\nPublic healthPolicyWalkingEnglandMultiple Streams\nBackground\nEpidemiological research clearly demonstrates that adults who are physically active have a reduced risk of developing many non-communicable diseases (NCDs) including coronary heart disease (CHD), stroke, hypertension, and type II diabetes [ 1 ]. Despite these benefits, modernisation, urbanisation, and advances in technology have led to reductions in physical activity levels globally [ 2 ]. In 2011, the World Health Organization (WHO) estimated that more than 30 % of adults worldwide did not engage in sufficient levels of physical activity to benefit their health and prevent disease [ 3 ]. Consequently, physical inactivity has been identified as the fourth leading risk factor for premature mortality, accounting for an estimated 6 % of global mortality (3.2 million deaths annually) [ 4 ]. In England, recent surveillance data suggests that over 40 % of adults are failing to meet recommended physical activity levels [ 5 ]. As a result, physical inactivity is thought to cause 3.1 % of morbidity and mortality in England, and is responsible for 35,000 deaths annually [ 6 ].\nBrisk walking is a ‘sufficient’ activity to benefit health [ 7 – 9 ] and is viewed as one of the most acceptable and accessible forms of physical activity [ 10 ]. Walking is free of charge, does not require specialist equipment or facilities, and can be easily incorporated into everyday life. Walking is an ideal introduction to physical activity for people who are overweight or extremely unfit [ 11 ], and being a low impact activity, walking poses relatively few risks of injury [ 12 ]. For these reasons, walking has been identified as the form of activity with the greatest potential for increasing the overall activity levels of an inactive population [ 9 , 13 ] and also as the most likely way that all adults can achieve recommended physical activity levels [ 14 ].\nThere is increasing recognition among physical activity researchers, of the role of policy in addressing population levels of physical inactivity [ 15 , 16 ]. The development of a national policy framework is important to raise the profile of physical activity as a priority area and to provide a coherent action plan or programme of activities aimed at increasing population prevalence of physical activity [ 17 ]. Due to its broad accessibility and acceptability it has been proposed that “walking must be central to any strategy to increase physical activity” [ 18 ].\nPhysical activity and health began to be recognised as an issue requiring government support in England in the early 1990s. The ACTIVE for LIFE campaign, which was funded by the Department of Health (DH), aimed to raise awareness of the health benefits of being active and encourage regular physical activity as part of a healthy lifestyle. The campaign had a strong focus on walking, but was not accompanied by a strategic plan or investment in infrastructure or programs to support physical activity behaviour change.\nDespite initial leadership for the physical activity and health agenda from DH, the Department for Transport (DfT) began to recognise the role of walking and cycling in meeting its objectives around reducing congestion and carbon emissions. In 1996 DfT published a National Cycling Strategy [ 19 ] and announced its intentions to develop a national walking strategy [ 20 ]. Although a strategy to promote walking did not emerge until 2004, this also came from DfT in the form of Walking and Cycling: An Action Plan.\nPhysical activity promotion generally, and walking promotion specifically, has the potential to contribute to the aims and objectives of a wide range of government departments. In addition, many of the actions to promote walking fall within the remit of different departments such as health, transport, education, environment, and urban planning. Thus there has been no natural ‘home’ for walking promotion, which has presented challenges to developing a coherent and coordinated national policy.\nSince the early 2000s, several non-government organisations have established large scale walking initiatives. For example, the Countryside Agency established the national ‘Walking for Health’ programme (originally known as the Walking the Way to Health Initiative) and also the National Step-O-Meter Programme. These activities were traditionally funded through agencies such as the British Heart Foundation and the Big Lottery, as opposed to the government. However, in 2008 the government announced its intention to invest £7 million in a programme of “innovative campaigns to encourage people to walk more” [ 21 ]. This level of commitment and investment in walking promotion was unprecedented and presented a real opportunity for those working in physical activity and walking promotion to develop and deliver large-scale interventions aimed at improving the nation’s health.\nIn order to move beyond simply a description of this example of policy development, this article turns to the study of policy agendas and considerations of how issues come to be issues in the first place, how agendas change over time, and the factors which determine why some issues are given more government attention than others [ 22 ]. The conceptual framework put forward in this article, Kingdon’s Multiple Streams theory [ 23 ], serves to shed light on and explain the increased emphasis on walking promotion as part of the public health policy agenda in England. In doing so, this paper aims to answer the following questions:\n1.\nMethods\nConceptual framework\nDue to the complex nature of the policy making process, a range of theories and conceptual frameworks have been developed; these constructs serve the purpose of focusing the policy analyst’s attention on important elements within the policy process, while helping the analyst to apply structure or typologies to an otherwise chaotic and unwieldy course of events. Kingdon’s Multiple Streams framework is particularly focused on the agenda setting process and, as such, lends itself to answering the questions posed in this article [ 23 ]. This framework suggests that the policy process consists of three distinct sets of processes or ‘streams’: 1) problems; 2) policies; and 3) politics. At key points in time the three streams are joined—a problem is recognised, an appropriate solution is identified, and the political ‘mood’ is right for the government to embrace and drive forward policy change. This confluence of the three streams is referred to as a ‘policy window’; a juncture at which an opportunity for major policy change can be grasped. Kingdon’s framework is put forward as a useful heuristic device with which to understand agenda setting and policy change.\nStudy design\nThe research adopted a case study design. Therefore the focus was on gaining in-depth insights into the political processes surrounding walking promotion in England, rather than making generalisations about the applicability of the findings to other cases. Data were obtained through document analysis and semi-structured interviews and triangulation techniques were used to verify the validity of the results [ 24 ]. The focus of the research was on the period up to October 2012. The study was approved by Loughborough University Research Ethics Committee.\nDocument analysis\nA literature and web search was undertaken to identify both past and present documents relevant to walking policy in England. The web-search mainly focused on the websites of DH, DfT, and the Department for Culture, Media and Sport (DCMS). Various search terms were used including ‘physical activity’, ‘active travel’ and ‘walking’, and all identified documents were considered. To ensure the comprehensive inclusion of relevant documents, all interviewees were asked to identify documents that they felt were important for understanding the development, content, and/or implementation of walking policy in England. Any documents which had not been previously identified were obtained and included in the analysis. A list of the key documents included in the analysis is provided in Table  1 .\nTable 1\nWalk England (2008).\n \nAlthough each of these organisations is concerned, in some way, with walking promotion, the aims and objectives of each organisation differ and include access to the countryside, pedestrian safety, and transport emissions. The organisations vary substantially in terms of their size and resources; the largest organisations are the Ramblers and Sustrans, while the smallest organisation is Walk England. The primary purpose was not to compare across cases but to consider each organisation’s perspective in order to reach well-rounded conclusions about the development and dynamics of walking promotion as a public health policy issue in England.\nKey representatives from each of these organisations were identified using existing knowledge of the organisations and by searching their respective websites. The selected interviewees were either the Chief Executive Officer (CEO) (particularly for smaller organisations) or, if appropriate, the strategic lead for walking and/or health (particularly for organisations with a broader agenda). In addition, DH and DfT have been identified as the ‘main players’ in promoting physical activity for adults [ 25 ]. Interviews were conducted with representatives from each of these departments; the interviewees were the Head of Physical Activity and the Head of Active Travel, respectively.\nSnowball sampling was used to complement the purposive approach [ 26 ]. This involved asking each of the interviewees to identify other colleagues or acquaintances with relevant knowledge and experience who they felt would make a valuable contribution to the research. This approach led to the identification of interviewees from several other organisations including Intelligent Health (a limited company which aims to create physical activity opportunities close to where people live and work), Knowledge into Action (a charity focused on improving health and healthcare), and Sport England (the DCMS funded body responsible for the delivery of sport in England from grassroots to elite level), as well as several independent consultants and other known advocates.\nThe interview schedule typically included the following themes: how walking fits within the aims and objectives of the different organisations; the roles of the different NGOs within the broad field of walking promotion; which aspects of the broad walking agenda agencies are mostly closely aligned to; how the organisations are funded; who they are accountable to; the main programs that the organisations deliver; relationships/collaborations with other organisations; relationships with government; level of political influence of each NGO; perceptions of how the issue of walking has been dealt with by the government; and barriers to establishing greater political support and investment into walking promotion in England. The interview schedule for the government representatives included questions on: how responsibility for walking promotion has been allocated or dispersed across government; consultation and decision making processes related to the development of walking policy; the main challenges in developing and implementing policy to promote walking; and relationships and interactions with the key NGOs on walking related issues.\nFifteen interviews were conducted in total and took place between April and October 2012. The duration of interviews ranged from 35 min to two hours, and the typical length was one hour. All interviews were recorded on a digital audio device, with consent, and were subsequently transcribed verbatim. Each transcript was sent to the respective interviewee, to confirm that it accurately conveyed what was said or intended. In total, the interview data consisted of 285 pages of transcript.\nData analysis\nBoth the documents and the interview transcripts were uploaded into NVivo qualitative software package and analysed using inductive content analysis. Therefore, the coding categories and the names for each concept and theme were derived directly and inductively from the data. The coding themes were then allocated to one of the following three groupings: problems; policies; and politics, in order to analyse the results in relation to Kingdon's Multiple Streams framework [ 23 ]. To confirm the reliability of the analysis, all data were coded on two separate occasions, allowing the lead researcher to confirm or refine the coding system developed during the initial analysis.\nResults\nThe following section is set out according to the broad, yet distinct categories in Kingdon’s Multiple Streams framework: problems; policies; and politics. The article focuses on events and decisions taking part in each of these ‘streams’ before considering how these factors have converged to make a ‘policy window’ for increased support and investment in walking promotion in England.\nThe problem stream\nWalking levels in England have been in decline since the mid-1970s and this reduction in walking has been accompanied by an increase in car use [ 27 ]. The consequences of this shift include reduced overall physical activity levels, increased traffic congestion, and higher levels of carbon emissions. The problems associated with low levels of walking have been recognised by several well established interest groups/organisations, which formed a key focus of the empirical research. These types of interest groups play an important role in nearly every aspect of health policy, from bringing issues to the attention of government, proposing new policy options, and building pressure for action [ 28 ].\nIt is imperative that issues are defined in a way which will attract political interest. According to Weiss [ 29 ], issue definition is concerned with the organisation of a set of facts, beliefs, and perceptions, or ‘how people think about circumstances’. The way in which an issue is ‘packaged’ determines how it is perceived by both policymakers and the public and thus can impact upon the agenda-building process [ 30 ]. ‘Symbols’, which can be described as “objects to which people attach political significance”, are used to attract attention to an issue, to define an issue in a specific way, and to mobilise support for specific policy options over others [ 30 ]. The issue of walking promotion has been defined or ‘packaged’ in three primary ways: as a health issue; a transport issue; and as an environment issue; and this has impacted on how responsibility for walking promotion has been dealt with by the government. A senior staff member from the Ramblers stated, for example:\n“I think it has been spread between transport and health and environment… and it’s kind of shifted and moved around depending on whether you’re talking about the countryside or whether you’re talking about urban walking, or obesity or issues like that” (London, May 2012).\nSometimes recognition that a problem exists is sufficient for the problem to make it onto the political agenda; however there are usually many problems competing for recognition, meaning that only a fraction of them make it into the formal process of political deliberations. Which problems receive government attention is often influenced by ‘policy entrepreneurs’ [ 23 , 31 ]. These entrepreneurs are highly motivated individuals who seek to raise the profile of an issue among both government officials and the general public. Policy entrepreneurs typically hold positions of leadership within relevant interest groups and are usually well connected politically. The main roles of an entrepreneur are to define and reframe problems, advocate new ideas, specify policy alternatives, broker ideas among policy actors, mobilise public opinion, and help set the decision-making agenda [ 32 ].\nThere have been several long standing advocates for walking promotion, who have been instrumental in bringing the issue to the attention of government and for encouraging political action. These include Dr William Bird, a general practitioner who was instrumental in the establishment of the national led walk program Walking for Health, and Sir Muir Gray, who has held several senior positions in preventive health and has been described as a “a ceaseless champion of walking as a means of tackling obesity and inactivity” [ 33 ]. A former employee at DH reflected on the powerful influence of these types of policy entrepreneurs:\n“They can walk the talk. They brought good examples of what was happening elsewhere… you talk about people being influential and stuff like that. It's a fact of life that certain people will like other people and listen to what they say. And it happens more than you could ever believe in terms of someone having the ear of a Minister” (London, July 2012).\nThe lobbying efforts of these policy entrepreneurs have been facilitated by several factors including growing research evidence on the health benefits of walking [ 9 , 10 ] and prevalence data on rising levels of inactivity, for example from the ‘Allied Dunbar Fitness Survey’ [ 34 ], and more recently the Health Survey for England [ 5 , 35 ]. One of the biggest challenges for these policy entrepreneurs, however, has been to convince policymakers that walking promotion legitimately falls within the government’s remit. There is a long history of policy in England which emphasises the importance of individuals taking responsibility for their own health behaviours. For example, Saving Lives: Our Healthier Nation [ 36 ], identified behavioural risk factors such as smoking and physical activity as an individual responsibility and beyond the remit of the government. Even some of the more recent policy documents, including Healthy Lives, Healthy People—A Call to Action on Obesity in England [ 37 ], emphasise the need for individuals to take responsibility for their own health by making healthier lifestyle choices. Therefore the challenge has not only been to convince the government of the magnitude and consequences of the problem of low walking levels but also to convince them that dealing with the problem is a government responsibility.\nAn additional barrier to walking promotion, which was expressed by representatives from both DH and DfT, is the perception that walking is such a simple behaviour that the general public will not view walking promotion as sufficiently complex or necessitating high level expertise, to warrant political attention, and thus this will not be considered an appropriate use of scarce government resource. This sentiment is captured by the following quote from a senior government official:\n“Governments can feel a little foolish promoting walking in a sense that it's a Daily Mail headline—Government tells people to walk!—Government gives people lessons on walking! Suddenly you can be ridiculed because it’s such a natural thing to do” (London, April 2012).\nThe policy stream\nThe linking of solutions to policy problems is thought to increase the chances of gaining political attention and support for an issue. Having pre-formulated policy solutions can increase the government’s confidence that there are appropriate solutions to the identified problem and thus that the problem can be dealt with in a timely fashion without the need for drawn-out political deliberations on appropriate policies. Therefore once one or more problems are identified, ‘policy communities’, consisting of experts in the area, try to affix solutions to the problem, usually driven by their own values and interests [ 38 ].\nEach of the key walking organisations has conceptualised different policy solutions, including led walk schemes, infrastructure changes to improve the environment for walking, and resources such as websites and maps. Multiple Streams theory holds that the survival of ideas and solutions in the policy stream is determined by three factors.\nFirst, the degree of technical feasibility, which relates to how easily a theoretically sound idea can actually be translated into practice. Ideas that can make the transition from theory to practice with the least difficulty are thought to stand a better chance of survival.\nSecond, survival is determined by whether solutions are widely supported by a range of specialists within the policy community. The more wide-spread support there is for a policy solution, the greater the likelihood that the solution will be adopted.\nThe third factor relates to budgetary implications, with less costly solutions often receiving a greater level of support from policymakers [ 22 ].\nIn recent years two walking programmes have received substantial government resource; Natural England’s Walking for Health programme and Walk England’s Walk4Life Miles project, which received £3 million and £1.4 million respectively from DH in 2008. Natural England’s Walking for Health programme is a led walk initiative, established in 2000. Walking for Health had already expanded into a national programme and in 2010 the programme consisted of over 600 local schemes, all of which were delivered by a network of over 11,000 trained volunteers [ 39 ]. This programme, in many ways, met Kingdon’s proposed criteria for survival within the policy stream. Walking for Health had a proven track record of feasibility, the programme had widespread support from various stakeholders (and particularly Dr William Bird), and it could be delivered at relatively low cost due to the engagement of a large network of (existing) volunteers.\nWalk England’s Walk4Life Miles project was a new initiative which would involve setting up 2012 one mile sign-posted walking routes across the country. It was envisaged that the one-mile routes would be safe, attractive, and connected to where people live, and that people would be able to use the miles to test their fitness, using the principles of the Rockport One-Mile Walk Test [ 40 ]. The aim of the project was to get 30,000 people to improve their fitness and sustain an increase in physical activity [ 41 ]. The simplicity of this intervention would facilitate judgements of feasibility and cost and, although there was not wide spread support for the initiative from the walking sector as a whole, it was lobbied for fiercely by Walk England, as illustrated by the following quote:\n“I found out that Walk England had snaffled a million quid… the reason that happened was that [they] never got off the phone from [the Department of Health]. They badgered, badgered, badgered, badgered and badgered. And just badgered [the Department of Health] so badly that in the end that’s what happened” (London, May 2012).\nAlthough the ‘evidence-based policy movement’ has sought to promote the rigorous analysis of policy options in order to improve decision-making [ 42 , 43 ], the findings of this research lend support to Head’s suggestion that policy development is often based more on politics and professional judgement, rather than on research evidence alone [ 43 ], and highlights the influence that key ‘policy entrepreneurs’ can have in the decision making process.\nThe politics stream\nThe politics stream relates to the political ‘mood’ and openness to change based on the current political climate [ 22 , 23 ]. Clearly a range of factors such as impending elections, a change in government, and interest group activity can lead to the inclusion or exclusion of different topics on the political agenda, as well as influencing how these problems are perceived by the electorate and policymakers, and how potential solutions are evaluated.\nIn July 2005 it was announced that London would host the 2012 Olympic and Paralympic Games. Subsequently DCMS released Before, During and After: Making the Most of the London 2012 Games [ 21 ], which outlined the Government’s intention to make the UK a world-leading sporting nation. However a key feature of both the bid and the subsequent policy was the promise of delivering a ‘physical activity legacy’ which would inspire population increases in sport and physical activity, or, as one interviewee summarised it, political interest in physical activity and walking promotion was bolstered by the world’s largest sports mega-event: “The driver, I would say, was the Olympics, because funding was allocated to help meet that target” (London, July 2012).\nSpecifically this policy identified the target of getting two million more people ‘active’ by 2012, and committed to investing £7 million into walking promotion as a key approach to achieving this target. Interestingly, the basis of this legacy is the belief that elite sport success can act as a catalyst for increased physical activity and sport participation among the masses; a belief that has little evidence from previous sports mega-events [ 44 – 47 ].\nThe ‘policy window’\nAt key points in time the three streams outlined above are joined together: a problem is recognised, an appropriate solution is identified, and the political ‘mood’ is right for the government to embrace and drive forward policy change. This confluence of the three streams is referred to by Kingdon as a ‘policy window’.\nThe success of London in securing the 2012 Olympic and Paralympic Games was the primary trigger in the creation of a policy window for walking promotion in recent years. The profile of hosting this mega-event meant that political interest was high, and the subsequent promise of delivering a physical activity legacy provided a ‘problem’ in that the government were now required to provoke large scale increases in physical activity [ 21 , 48 ]. Time and resources were allocated to delivering this target and thus the government were seeking appropriate policy solutions in which to invest. A former employee at DH recollected on this situation:\n“We had a target to meet and we had to get two million people active so we had to find programmes that would do that and it was very clear that the biggest potential was in walking. I think what possibly wasn’t clear was what the right interventions were” (London, July 2012).\nTherefore, the role of interest groups and policy entrepreneurs was to identify appropriate policy solutions and to convince the government of their value. Two organisations were successful in this endeavour, Natural England and Walk England.\nA key feature of the policy window however, is that as quickly as it opens, it may close, due to other competing agendas or simply a change in the political ‘climate’. In May 2010 there was a general election and a change in government. When the new government came into power, the UK (and the rest of the world) was in the midst of an economic recession. In an attempt to address the economic crisis the coalition government undertook a review of non-departmental public bodies, including Natural England. The review concluded that Walking for Health was peripheral to Natural England’s core objectives and was not something that it should be delivering. A competitive tendering process ensued and in March 2012, the Ramblers took over the coordination of the Walking for Health programme [ 49 ].\nIn addition, there was a Treasury review of the public spending commitments made by the previous government between 1st January 2010 and the General Election [ 50 ]. This review examined £34 billion of spending that was approved during the previous government’s final few months in office. The aim of the review was to assess whether these commitments were affordable, whether they would deliver value for money, and whether they were considered a priority for the new government. In total 12 projects were cancelled because they were deemed unaffordable and not a government priority, one of which was Walk England’s Walk4Life Miles project. This is an example of the ‘window of opportunity’ closing due to a change in politics.\nDiscussion\nThis article reports on the application of Kingdon’s Multiple Streams theory to explain the recent rise of walking promotion on the political agenda in England. The framework provided a useful structure for the study of agenda setting in this discrete area of policy, thus reinforcing the utility and wide applicability of Kingdon’s Multiple Streams theory for policy analysis.\nThe analysis identified the London 2012 Olympic and Paralympic Games as the primary driver behind the government’s increased interest in walking promotion in England. Both the 2012 Games bid and the subsequent policy used the rhetoric of inspiring population level increases in physical activity. It is interesting to note that despite a long-standing interest in walking from DH and DfT, it was alignment with the sports agenda that led to increased investment in walking promotion in recent years. This is supported by the concept of ‘generalisation of interests’ which proposes that if policy entrepreneurs are able to demonstrate the relevance of an issue to a broad audience (and a range of government departments), this increases the appeal of the issue and the likelihood of securing government engagement and support [ 51 , 52 ].\nThe £7 million investment into walking promotion in 2008 was motivated by the perceived potential of sports mega-events to lead to population level increases in sport and physical activity participation; however, there is little evidence to support this notion [ 44 – 47 ]. Hosting sports mega-events does, however, generate political interest and thus sport can be a strong ‘symbol’ for getting physical activity onto the political agenda. Therefore further research is needed to understand how these events may be better utilised as a vehicle for encouraging mass participation in sport and physical activity. It should be noted that linking physical activity promotion with sports mega-events alone is insufficient, as it fails to recognise the importance of physical activity as a critical lifestyle behaviour for the prevention and control of NCDs. In addition, this sort of interest and commitment is often short-lived and is not sustained beyond the event itself. In the case of the London 2012 Games, the target of getting two million more people active as a result of hosting the Games was dropped even before the event took place [ 53 , 54 ].\nFollowing the government’s promise to deliver a physical activity ‘legacy’ as a result of hosting the Games, it committed to investing in a suite of “innovative campaigns to encourage people to walk more” [ 21 ]. The government elected to fund two walking initiates; Natural England’s Walking for Health programme and Walk England’s Walk4Life Miles project, neither of which were supported by a robust scientific evidence base.\nAlthough there is some evidence that walking in groups is an effective approach to increasing physical activity levels [ 55 ], relatively little is known about the effectiveness of other approaches to encourage people to walk more. The National Institute for Health and Care Excellence advocate for action to promote both leisure and transport related walking [ 14 ], through a range of portfolios including leisure services, parks, transport, and the environment, however further research is needed on exactly what types of interventions are effective and cost-effective.\nIn the absence of strong evidence of effectiveness, the lobbying efforts of policy entrepreneurs will be particularly critical. In addition it is advantageous to package interventions in a way which attracts political interest and aligns with other government priorities. In recent years, Walk England were particularly successful in this regard; the concept of 2012 routes gave this intervention a (albeit loose) connection to the 2012 Games and provided DH with a clear policy solution linked to the legacy target. Thus although the initiative was innovative, lacked a sound theoretical or empirical evidence base, and did not meet Kingdon’s criteria of having wide-spread support, Walk England were able to secure government investment.\nFurther research is clearly needed to build the evidence base on effective walking interventions. In the meantime, lobbying for interventions which lack evidence of effectiveness should be undertaken with caution. If these programs do not lead to the desired outcome in terms of increasing physical activity levels, they will have the adverse effect of undermining the government’s trust and confidence, which is likely to lead to reductions in future support and investment.\nEvidently there is still work to be done to a) raise awareness of the health benefits of physical activity; b) emphasise the importance and potential of walking promotion for influencing population levels of physical activity; c) build the evidence base on effective approaches to promoting walking; and d) encourage the development and implementation of policy level actions, with sustained support and investment, to increase population levels of physical activity and reduce NCD prevalence.\nConclusion\nThis paper utilised Kingdon’s Multiple Streams framework as an organising principle through which to interrogate the reasons behind the government’s increased interest and investment in walking promotion in 2008. Overall it appears that government interest in walking promotion in England has largely been motivated by sport and the promise of delivering a ‘legacy’ as a result of hosting the London 2012 Olympic and Paralympic Games. This raises concerns that the research evidence on the health benefits of physical activity and rising levels of inactivity in England, are insufficient to secure government support and investment, and that multi-sector lobbying and joined-up political action may be critical in advancing this agenda.\nDeclarations\nAcknowledgements\nThis manuscript is an output from the lead author’s PhD research which was undertaken at Loughborough University and supervised by Professor Barrie Houlihan.\nCompeting interests\nThe authors declare that they have no competing interests.\nAuthors’ contributions\nKM collected the data, undertook the analysis, and prepared the draft manuscript. JG contributed substantial intellectual content and made a significant contribution to writing and revising the manuscript. Both authors read and approved the final manuscript.\nAuthors’ Affiliations\n(1)\nBritish Heart Foundation Centre on Population Approaches for Non-Communicable Disease Prevention, Nuffield Department of Population Health, University of Oxford\n(2)\nSchool of Sport, Exercise and Rehabilitation Sciences, University of Birmingham\nReferences\nPhysical Activity Guidelines Advisory Committee. Physical activity guidelines advisory committee report 2008. Washington, DC; 2008. Google Scholar\nNg S, Popkin B. Time use and physical activity: a shift away from movement across the globe. Obes Rev. 2012;13(8):659–80. View Article PubMed PubMed Central Google Scholar\nWorld Health Organization. Global status report on noncommunicable disease 2010. Geneva: World Health Organization; 2011. Google Scholar\nWorld Health Organization. Global health risks: Mortality and burden of disease attributable to selected major risks. Geneva: World Health Organization; 2009. Google Scholar\nHealth and Social Care Information Centre. Health Survey for England, 2012 [Internet]. Leeds, UK; 2013. Available from: http://www.hscic.gov.uk/catalogue/PUB13218 .\nDepartment of Health. Let’s Get moving commissioning guidance—a physical activity care pathway. London: Department of Health; 2009. Google Scholar\nBlair S, Kohl III H, Paffenbarger Jr R, Clark D, Cooper K, Gibbons L. Physical fitness and all-cause mortality—a prospective study of healthy men and women. J Am Med Assoc. 1989;262:2395–401. View Article Google Scholar\nAinsworth B, Haskell W, Whitt M, Irwin M, Swartz A, Strath S, et al. Compendium of physical activities: an update of activity codes and MET intensities. Med Sci Sports Exerc. 2000;32(9 Suppl):S498–504. View Article PubMed Google Scholar\nMorris J, Hardman A. Walking to health. Sport Med. 1997;23(5):306–32. View Article Google Scholar\nBlair S, Kohl III H, Gordon N, Paffenbarger Jr R. How much physical activity is good for health? Annu Rev Public Health. 1992;13:99–126. View Article PubMed Google Scholar\nDavison R, Grant S. Is walking sufficient exercise for health? Sport Med. 1993;16(6):369–73. View Article Google Scholar\nParkkari J, Kannus P, Natri A, Lapinleimu I, Palvanen M, Heiskanen M, et al. Active living and injury risk. Int J Sports Med. 2004;25(3):209–16. View Article PubMed Google Scholar\nHillsdon M, Thorogood M. A systematic review of physical activity promotion strategies. Br J Sports Med. 1996;30(2):84–9. View Article PubMed PubMed Central Google Scholar\nNational Institute for Health and Clinical Excellence. Walking and cycling: local measures to promote walking and cycling as forms of travel or recreation. London: National Institute for Health and Clinical Excellence; 2012. Google Scholar\nSallis J, Bauman A, Pratt M. Environmental and policy interventions to promote physical activity. Am J Prev Med. 1998;15(4):379–97. View Article PubMed Google Scholar\nKohl III H, Craig C, Lambert E, Inoue S, Alkandari J, Leetongin G, et al. The pandemic of physical inactivity: global action for public health. Lancet. 2012;380:294–305. View Article PubMed Google Scholar\nDaugbjerg S, Kahlmeier S, Racioppi F, Martin-Diener E, Martin B, Oja P, et al. Promotion of physical activity in the European region: content analysis of 27 national policy documents. J Phys Act Health. 2009;6:805–17. View Article PubMed Google Scholar\nSharp I, White J, Rogers L. Physical activity: An agenda for action. London: National Forum for Coronary Heart Disease Prevention; 1995. Google Scholar\nDepartment for Transport. The national cycling strategy. London: Department for Transport; 1996. Google Scholar\nDepartment for Transport. Developing a strategy for walking. London: Department for Transport; 1996. Google Scholar\nDepartment for Culture Media and Sport. Before, during and after: making the most of the London 2012 games. London: Department for Culture Media and Sport; 2008. Google Scholar\nKingdon J. Agendas, alternatives and public policies. 2nd ed. New York: Harper Collins College Publishers; 1995. Google Scholar\nKingdon J. Agendas, alternatives and public policies. Boston: Little Brown; 1984. Google Scholar\nGrix J. The foundations of research. 2nd ed. Palgrave Macmillan: Basingstoke, Hampshire; 2010. Google Scholar\nParliamentary Office of Science and Technology. Postnote—Health benefits of physical activity transport. London: Parliamentary Office of Science and Technology; 2001. Google Scholar\nOliver P. Snowball sampling. In: Jupp V, editor. The SAGE dictionary of social research methods. London: Sage; 2006. Google Scholar\nDepartment of Health. At least five a week. Nutrition Bulletin. London: Department of Health; 2004. Google Scholar\nPeterson M. Motivation, mobilisation and monitoring: the role of interest groups in health policy. J Health Polit. 1999;24:416–20. Google Scholar\nWeiss J. The powers of problem definition: the case of government paperwork. Policy Sci. 1989;22:97–121. View Article Google Scholar\nZahariadis N. Ambiguity and choice in public policy: political decision making in modern democracies. Washington, DC: Georgetown University Press; 2003. Google Scholar\nPolsby N. Political innovation in America: the politics of policy initiation. New Haven, Connecticut: Yale University Press; 1984. Google Scholar\nRoberts N, King P. Policy entrepreneurs: Their activity structure and function in the policy process. J Public Adm Res Theory. 1991;2:147–75. Google Scholar\nDe Moor D. Dr. Gray’s walking cure. Book reviews: Winter 2009. 2009. Google Scholar\nCouncil S. Health Education Authority. London: Allied Dunbar Fitness Survey; 1992. Google Scholar\nStamatakis E, Ekelund U, Wareham N. Temporal trends in physical activity in England: the health survey for England 1991 to 2004. Prev Med (Baltimore). 2007;45(6):416–23. View Article Google Scholar\nDepartment of Health. Saving lives: Our healthier nation. London: Department of Health; 1999. Google Scholar\nDepartment of Health. Healthy lives, healthy people: a call to action on obesity in England. London: Department of Health; 2011. Google Scholar\nMarsh D, Rhodes R. Policy networks in British government. Clarendon: Oxford, UK; 1992. View Article Google Scholar\nWalking for Health. The future of walking for health [Internet]. 2011. Available from: http://www.walkingforhealth.org.uk/news/2011/02/future-walking-for-health .\nKline G, Porcari J, Hintermeister R, Freedson P, Ward A, McCarron R, et al. Estimation of VO2 max from a one-mile track walk, gender, age and body weight. Med Sci Sports Exerc. 1987;19(3):253–9. View Article PubMed Google Scholar\nWalk England. Active challenge routes. Bristol; 2010 Google Scholar\nBrownson R, Baker E, Left T. Evidence based public health. New York: Oxford University Press; 2011. Google Scholar\nHead B. Reconsidering evidence-based policy: key issues and challenges. Policy Soc. 2010;29(2):77–94. View Article Google Scholar\nWeed M, Coren E, Fiore J, Wellard I, Chatziefstathiou L, Mansfield D, et al. Developing a physical activity legacy from the London 2012 Olympic and Paralympic Games: a policy-led systematic review. Perspect Public Heal. 2012;132(2):75–80. View Article Google Scholar\nCoalter F. London 2012: a sustainable sporting legacy? In: Vigor A, Mean M, editors. After the Goldrush: a sustainable Olympics for London. London: ippr and Demos; 2004. Google Scholar\nMahtani K, Protheroe J, Slight S, Demarzo M, Blakeman T, Barton C, et al. Can the London 2012 Olympics “inspire a generation” to do more physical or sporting activities? An overview of systematic reviews. BMJ Open. 2013. Google Scholar\nGrix J, Carmichael F. Why do governments invest in elite sport? A polemic. Int J Sport Policy Polit. 2012;4(1):73–90. View Article Google Scholar\nDepartment for Culture Media and Sport. Plans for the legacy from the 2012 Olympic and paralympic games. London: Department for Culture Media and Sport; 2010. Google Scholar\nMacmillan Cancer Support, Ramblers. The Ramblers and Macmillan Cancer Support to take over Walking for Health [Internet]. 2012. Available from: http://www.ramblers.org.uk/media-centre/press-releases/2012/march/ramblers-and-macmillan-take-over-walking-for-health.aspx .\nTreasury HM. Statement by the Chief Secretary to the Treasury, Rt Hon Danny Alexander MP, on review to public spending commitments made since 1 January 2010 [Internet]. 2010. Available from: http://www.hm-treasury.gov.uk/statement_cst_170610.htm . Google Scholar\nRommetvedt H. Politikkens almenngjøring og den ny-pluralistiske parlamentarismen. Bergen: Fagbokforlaget; 2002. Google Scholar\nBergsgard N, Rommetvedt H. Sport and politics: the case of Norway. Int Rev Sociol Sport. 2006;41(7):7–27. View Article Google Scholar\nGibson O. Jeremy Hunt admits London 2012 legacy targets will be scrapped [Internet]. The Guardian. 2011. Available from: http://www.theguardian.com/sport/2011/mar/28/jeremy-hunt-london-2012-legacy .\nGibson O. Hugh Robertson admits to struggling with legacy for grassroots sport [Internet]. The Guardian. 2012. Available from: http://www.theguardian.com/sport/2012/mar/05/hugh-robertson-legacy-games-2012 .\nKassavou A, Turner A, French D. Do interventions to promote walking in groups increase physical activity? A meta-analysis. Int J Behav Nutr Phys Act. 2013;10:18. View Article PubMed PubMed Central Google Scholar\nCopyright\n© Milton and Grix. 2015\nThis article is published under license to BioMed Central Ltd. This is an Open Access article distributed under the terms of the Creative Commons Attribution License ( http://creativecommons.org/licenses/by/4.0 ), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly credited. The Creative Commons Public Domain Dedication waiver ( http://creativecommons.org/publicdomain/zero/1.0/ ) applies to the data made available in this article, unless otherwise stated.\n""","0.14156464","""https://bmcpublichealth.biomedcentral.com/articles/10.1186/s12889-015-1915-y""","[-1.933663,52.454008]"
"""Imperial_College_London""","""Environmental Health Perspectives – Traffic Air Pollution and Other Risk Factors for Respiratory Illness in Schoolchildren in the Niger-Delta Region of Nigeria""","""Contact EHP\nTraffic Air Pollution and Other Risk Factors for Respiratory Illness in Schoolchildren in the Niger-Delta Region of Nigeria\n[do action=”authors”]B. Adetoun Mustapha, Marta Blangiardo, David J. Briggs, Anna L. Hansell[/do][do action=”affiliations”]MRC-HPA Centre for Environment and Health, Imperial College London, United Kingdom[/do][do action=”citation-string”]Environ Health Perspect 119:1478-1482 (2011). http://dx.doi.org/10.1289/ehp.1003099 [online 30 June 2011] [/do]\nResearch Article\nAbstract\n[do action=”abstract”]\nBackground: Association of childhood respiratory illness with traffic air pollution has been investigated largely in developed but not in developing countries, where pollution levels are often very high.\nObjectives: In this study we investigated associations between respiratory health and outdoor and indoor air pollution in schoolchildren 7–14 years of age in low socioeconomic status areas in the Niger Delta.\nMethods: A cross-sectional survey was carried out among 1,397 schoolchildren. Exposure to home outdoor and indoor air pollution was assessed by self-report questionnaire. School air pollution exposures were assessed using traffic counts, distance of schools to major streets, and particulate matter and carbon monoxide measurements, combined using principal components analysis. Hierarchical logistic regression was used to examine associations with reported respiratory health, adjusting for potential confounders.\nResults: Traffic disturbance at home (i.e., traffic noise and/or fumes evident inside the home vs. none) was associated with wheeze [odds ratio (OR) = 2.16; 95% confidence interval (CI), 1.28–3.64], night cough (OR = 1.37; 95% CI, 1.03–1.82), phlegm (OR = 1.49; 95% CI, 1.09–2.04), and nose symptoms (OR = 1.40; 95% CI, 1.03–1.90), whereas school exposure to a component variable indicating exposure to fine particles was associated with increased phlegm (OR = 1.38; 95% CI, 1.09–1.75). Nonsignificant positive associations were found between cooking with wood/coal (OR = 2.99; 95% CI, 0.88–10.18) or kerosene (OR = 2.83; 95% CI, 0.85–9.44) and phlegm compared with cooking with gas.\nConclusion: Traffic pollution is associated with respiratory symptoms in schoolchildren in a deprived area of western Africa. Associations may have been underestimated because of nondifferential misclassification resulting from limitations in exposure measurement.\n[/do][do action=”abstract”]Key words: asthma, developing country, indoor air pollution, Niger Delta, outdoor air pollution, respiratory, schoolchildren[/do]\n[do action=”notes-rule-above”]Address correspondence to A. Hansell, MRC-HPA Centre for Environment and Health, Imperial College London, London W2 1PG, United Kingdom. Telephone: 44-0-20-7594-3344. Fax: 44-0-20-7594-3193. E-mail: a.hansell@imperial.ac.uk [/do][do action=”notes”]This work formed part of B.A. Mustapha’s PhD, funded through a postgraduate scholarship provided by the Commonwealth Scholarship Commission (CSC), United Kingdom.[/do][do action=”notes”]B.A.M. works for Shell Petroleum Development Company of Nigeria Limited but did not receive any support from the company for this study, and the company is not in any way involved in this study. The other authors declare they have no actual or potential competing financial interests.[/do][do action=”notes”]\nThe authors acknowledge facilitation by M. Ogbe of the study ethics approval at Delta State University and guidance on the questionnaire survey and thank M. Joffe for his involvement in early discussions on the research proposal. Multilivel statistical analyses were conducted by M.B.\n[/do][do action=”notes”] Received 15 October 2010; accepted 30 June 2011; online 30 June 2011.[/do]\nMany epidemiologic studies, mainly from developed countries, have shown that exposures to air pollution from ambient particulate matter (PM) pollution and road traffic are associated with respiratory health in children, including upper and lower respiratory symptoms ( Bayer-Oglesby et al. 2005 ; Brunekreef et al. 2009 ; Kuehni et al. 2006 ; Künzli et al. 2000 ; Pierse et al. 2006 ), changes in pulmonary function ( Neuberger et al. 2004 ), diagnosed asthma ( McConnell et al. 2006 ), medication use ( Rabinovitch et al. 2006 ), and use of medical care ( Jalaludin et al. 2004 ). The evidence of a causal association is strongest for traffic exposure and exacerbations of asthma in children ( Health Effects Institute 2010 ).\nResearch on health effects of exposures to particulates and traffic pollution in children is sparse in developing countries and particularly scanty in Africa, where exposures are higher than in developed countries ( Ezzati et al. 2004 ). One of the few studies on traffic air pollution and health in Africa comes from an International Study of Asthma and Allergies in Children (ISAAC) analysis ( Brunekreef et al. 2009 ), which suggested dose–response relationships between self-reported truck traffic on the street of residence and current wheeze, rhinoconjunctivitis, and eczema in children 13–14 and 6–7 years of age in two African centers—one in the city of Ibadan, Nigeria, and one in Morocco.\nOutdoor PM levels in cities of developing countries including Nigeria are generally much higher than in developed countries because of dispersed heating with small-scale solid fuel use, uncontrolled industrial emissions, and the large numbers of noncatalyst two-stroke engine vehicles. Many vehicles are old and/or poorly maintained, which adds to traffic-related air pollution ( Brunekreef 2005 ). Indoor sources of air pollution also need to be considered, as they can be significant contributors to exposure, particularly in rural areas (World Health Organization and European Commission Joint Research Centre 2002). This study was therefore undertaken to help address the lack of studies in developing countries by testing the hypothesis that ambient and indoor air pollution are risk factors for respiratory illnesses among schoolchildren in Warri, Nigeria, and its environs.\nMethods\nDescription of study area. Warri is a city in Delta state, located in southern Nigeria, an area of lowland rainforest. Intensive oil exploration and production takes place in and around Warri, and it is the location of a major constellation of petrochemical complexes; hence, it is popularly called “oil city.” Outdoor air pollution comes from multiple sources such as oil production and refining in the Niger-Delta region, including gas flaring; refuse and bush burning; and road traffic, largely made up of buses and motorcycles (locally referred to as “okada”) used for public transportation as well as trucks conveying petrol from the Warri refinery to other parts of the country. Vehicles are usually older models originally imported secondhand from developed countries, and there are no exhaust emissions controls. Exposures to indoor air pollution are exacerbated by the use of fuels such as biomass and kerosene, traditional cooking facilities, and poor ventilation.\nThe Nigerian government is faced with huge developmental challenges. As is true of governments in many developing countries, air quality monitoring and regulation are not a top priority, given the struggle to provide basic necessities such as clean water, food, shelter, basic education, and health care to a rapidly increasing population. In addition, environmental monitoring is hampered by the limited and inconsistent supply of electricity; the difficult terrain of the Niger Delta and frequent political upheavals may also have contributed to a lack of both government and non-government-funded research. Uncertainty about the health impact of ambient air pollution in the region has led to environmental controversies characterized by claims and counter-claims about adverse health effects.\nStudy population and study design. In March–June 2004, a cross-sectional survey was conducted of students 7–14 years of age attending mixed-sex, state primary and secondary schools across 10 municipal areas: Warri, Ebrumede, Effurun, Jeddo, Ubeji, Otor-Udu, Owhrode, Ovu, Udu, and Eku. Twenty of 43 schools in areas identified as being of low socioeconomic status were chosen at random using a metric of 16 indicators specifically developed for the study region ( Mustapha 2008 ). However, three of the schools did not take part in the study because of lack of students of the right age (two schools) or the absence of head teacher (one school).\nStudents self-completed a written questionnaire in English that included questions about respiratory symptoms based on the ISAAC questionnaire ( Ellwood et al. 2000 ). Preliminary testing indicated that most of the questions required clarification. Questions were therefore read out loud by the interviewer (B.A.M.), who provided additional explanation in Warri Pidgin English. For example, the word “phlegm” was changed to “thick mucus,” and “wheeze” was explained as whistling in the chest. The word “problem” in the ISAAC question “Have you ever had a problem with sneezing, or a runny, or blocked nose when you DID NOT have a cold or the flu?” was changed to “pain,” because pain would be interpreted as discomfort or nuisance, whereas “problem” is interpreted locally as major injury from a fight or something involving the police or military. The question on phlegm production is adapted from the International Union Against Tuberculosis and Lung Disease questionnaire ( Burney et al. 1989 ), in which rainy season is the nearest seasonal equivalent to winter in Nigeria; the other seasons are dry season and harmattan. Other items on the questionnaire concerned demographic and socioeconomic characteristics, respiratory symptoms, perceived sources and levels of indoor air pollution, outdoor exposures, and other risk factors for respiratory illnesses ( Mustapha 2008 ).\nOur analysis concentrates on the following five respiratory outcomes:\nWheeze in the previous 12 months (question wording: “Have you had wheezing or noise in your chest at any time in the last 12 months?”)\nNight cough in the previous 12 months (“Have you been woken by an attack of coughing at any time in the last 12 months”)\nPhlegm (“Do you usually bring up any thick mucus from your chest first thing in the morning in the rainy season?”)\nRhinitis ever (“Have you ever had pain in trying to sneeze or running or blocked nose when you did not have a cold?”)\nDoctor-diagnosed asthma ever (“Has a doctor ever told you that you have asthma?”).\nEthical approval for the research protocol was granted by Delta State University, Abraka, Nigeria. Permission was also obtained from the Delta State Ministry of Education, the Delta State Ministry of Health, and local education authorities in the area, as well as head teachers of participating schools. Only students who gave oral informed consent participated in the study.\nExposure assessment. Because routine air pollution monitoring in Warri is extremely limited and inadequate as a basis for exposure assessment, and because opportunities for purpose-designed monitoring were constrained by lack of a reliable electricity supply, security issues, and funding limitations, a number of proxy exposure measures were used:\nSelf-reported indicators of exposure from the questionnaire survey: traffic disturbance (noise and/or fumes) at home, primary home cooking fuel (gas, kerosene, or wood/coal), overcrowding (four or more people sleeping in a room), living with ex- or current smokers, pets with fur or feathers in the home, school nonindustrial pollution (traffic fumes/open burning/cooking smoke), school industrial pollution (gas vapor/flaring), home nonindustrial pollution, and home industrial pollution.\nMeasurements conducted by one of the authors (B.A.M.) that were combined in principal component analysis (PCA) ( King and Jackson 1999 ) to create an index of air pollution exposure: a) distance to major roads—linear distance between the nearest main road and nearest school building; b) vehicle counts (categorized as cars, minibuses, trucks, and motorcycles) per 30 min during peak hours on the nearest major road to school (carried out once at each school); c) monitored carbon monoxide (CO): a 1-hr average taken three times on the adjacent road, using a hand-held Gastec monitor (Gastec Corporation, Kanagawa, Japan). The three readings were averaged (carried out on two occasions at each school); d) monitored PM of various aerodynamic diameters (micrometers), noted below: median mass-equivalent measured with a Dustmate portable environmental monitor (Turnkey Instruments Ltd, Northwich, UK) for 12 to 37 min (mean, 20 min) (carried out on two occasions at each school) for the following fractions: coarse [total suspended particulates (TSP)–PM10], intermediate (PM10–PM2.5), fine (PM2.5–PM1.0), and very fine (< PM1.0)]. Variation in duration of PM measurements was attributable to limitations of battery life of monitor and lack of electricity to recharge battery in the field.\nTiming of the monitoring differed between schools and was not concurrent with the questionnaire survey. Measurements at each school were made on weekdays between 1000 and 1400 hours when the schools were in session, and, under sunny weather conditions, when temperatures were between 26 and 31°C. CO and PM were measured twice at each school, and the higher values from each pair of CO or PM readings were used to derive PCA exposure indexes.\nWe used PCA to create exposure indexes based on measured traffic counts, distance to road, and CO and PM concentrations, using SPSS version 12.0 (SPSS Inc., Chicago, IL, USA). A varimax rotation was performed to maximize independence of the components, and components with eigenvalues > 1.0 were selected ( Table 1 ). This resulted in three exposure components, explaining a total of 78% of the variance. Component 1 appeared to reflect vehicle emissions, because it loaded positively on cars/minibuses, motorcycles, and CO, and inversely on distance from road. Component 2 loaded positively on coarse and intermediate PM and positively on distance from road, possibly representing crustal PM from open ground at greater distance from roads and waste burning. Component 3 showed high positive loadings on fine and very fine PM and on truck traffic and therefore appeared to represent mainly secondary particles derived from more distant (i.e., regional) road and industrial sources.\nDownload larger image (TIF File)\nStatistical analysis. Prevalence rates in percentages were computed for the health and exposure variables. We used Student’s t-test to determine the presence of significant differences (p ≤ 0.05) in measured environmental variables between schools where > 90% of children reported traffic fumes compared with schools where < 10% of children reported traffic fumes as hazard around their schools. We used Pearson correlation analysis to explore the relationship between school CO, PM concentrations, traffic counts, and distance to major roads using SPSS version 12.0.\nWe used multilevel logistic regression in R (R Project for Statistical Computing, Vienna, Austria) to assess the relationship of the five questionnaire health outcomes (wheeze, night cough, phlegm, rhinitis, and doctor-diagnosed asthma) with the self-reported indoor and outdoor air pollution exposures and the three PCA components (vehicle emissions, coarse particles, and fine particles). Self-reported school exposures (exposure to traffic fumes, open burning, cooking smoke, gas vapor, or gas flaring at school) were not included in the model because they were significantly correlated with factored components and measured CO. Potential confounders included in the models were sex, age, presence of pets in the house, overcrowding, traffic disturbance at home, type of home cooking fuel (wood or coal; kerosene), and presence of smokers in the house. The effect of clustering by school (n = 17) and geographic area (north, central, west, south east, south) was explored by including school or school plus area as random effects in the model. Final models were selected as those with the lowest Akaike’s Information Criterion.\nResults\nA total of 1,518 children 7–14 years of age were recruited into the survey, and 1,397 (92%) completed usable questionnaires. The median age was 12 years, and 675 (48.3%) were male. Prevalence of the main health outcomes, self-reported potential risk factors in the home, school, and local environments, are shown in Table 2 . Night cough (23%), rhinitis (19%), and phlegm (16%) had the highest prevalences in the study group, whereas doctor-diagnosed asthma was rare (0.9%). Practically all children (99%) reported some form of school or home pollution, either in the form of traffic fumes, open bush burning, cooking smoke, gas vapor, or gas flaring at home or school. Traffic disturbance at home was reported by 28% of children. Overcrowding was common, with three-quarters of children (77%) reporting that they slept in a room with at least three other people. Kerosene was the main fuel used for cooking (by 66%), and a third of children (34%) lived in households with a pet.\nDownload larger image (TIF File)\nMotorcycles and cars/minibuses dominated the traffic, making up 54% and 44%, respectively, of the total number of vehicles counted. Traffic counts in schools located in urban areas typically had total counts of approximately 2,000 vehicles/hour; schools located in rural areas had 20–60 vehicles per hour. The distance between each school and a major road ranged from 3 to 123 m, with a median of 23 m. Measured CO concentrations at schools ranged from 0 to 28 ppm ( Figure 1 ). The highest CO concentrations were measured at schools located close to major roads, and the lowest concentrations were measured at schools in villages farther from the main road. The mean (± SD) CO concentration for the 12 schools located within mean distance of 27.0 m to a major road was 9.9 ± 9.3 ppm compared with 1.2 ± 1.6 ppm for the five schools located within mean distance of 68.6 m to a major road. Measured CO was strongly correlated with total vehicle counts (r = 0.725; p = 0.001).\nDownload larger image (TIF File)\nCoarse and intermediate particles dominated the PM fraction in all schools, on average. About 47% of the in-school PM comprised coarse particles, 42% intermediate, 7.4% fine, and 3.6% very fine.\nFor the multilevel logistic regression, the best-fitting models had a random intercept for school (vs. school plus geographic area) only. Traffic disturbance at home was found to be consistently associated with four of the five health outcomes: wheeze in the previous 12 months [odds ratio (OR) = 2.16; 95% confidence interval (CI), 1.28–3.64], night cough in the previous 12 months (OR = 1.37; 95% CI, 1.03–1.82), phlegm production (OR = 1.49; 95% CI, 1.09–2.04), and rhinitis (OR = 1.40; 95% CI, 1.03–1.90) ( Table 3 ). Almost all of the indoor and outdoor air pollution variables showed positive associations with wheeze, night cough, and phlegm, but none of these reached statistical significance except for the component variable “school fine particles” for phlegm production (OR = 1.38; 95% CI, 1.09–1.75). A household variable, overcrowding, was significantly associated with wheeze (OR = 2.23; 95% CI, 1.11–4.46). There were only 12 cases of doctor-diagnosed asthma, so it is perhaps not surprising that no clear association patterns were seen.\nDownload larger image (TIF File)\nDiscussion\nThis study of schoolchildren in low socioeconomic areas of southern Nigeria exposed to multiple sources of outdoor and indoor air pollution suggested that traffic pollution at home was associated with respiratory symptoms of wheeze, cough, phlegm, and rhinitis. Phlegm was also associated with a component variable thought to reflect exposure at school to fine particles from distant sources, although measured concentrations of fine particles were also correlated with the number of trucks outside each school (r = 0.476; p = 0.053).\nOur findings are broadly consistent with other studies that have reported associations between respiratory illnesses in children and proximity to busy roads, especially those traveled by large numbers of trucks ( Brunekreef et al. 2009 ; Ciccone et al. 1998 ; Hirsch et al. 1999 ; Janssen et al. 2003 ; McConnell et al. 2006 ; Nicolai et al. 2003 ; Venn et al. 2005 ), including two of the very few studies involving African populations ( Brunekreef et al. 2009 ; Venn et al. 2005 ). As previously noted, self-reported truck traffic was associated with asthma symptoms among ISAAC study participants in Nigeria and Morocco ( Brunekreef et al. 2009 ) and “Almost the whole day truck traffic” versus “Never” was associated with wheeze among children 13–14 years of age in three of five African centers (in Morocco, Cote d’Ivoire, Cameroon, and Gabon) that were not included in multivariate analyses because of incomplete data. A study of adults and children in an urban community in Ethiopia ( Venn et al. 2005 ) found that among 3,592 individuals living within 150 m of a road, the risk of wheeze increased significantly in linear relation to proximity to the road (adjusted OR = 1.17 per 30 m proximity; 95% CI, 1.01–1.36). The only other Nigerian study of air pollution and respiratory health in schoolchildren that we identified ( Ana et al. 2009 ) was a pilot study of 400 children in senior secondary schools who were approximately 15 years of age and older (i.e., older than in the present study), conducted in the urban center of Ibadan in western Nigeria. Only descriptive results were presented, and no air quality measurements were conducted. Further, schools were purposely selected to be located near major roadways, so prevalences of self-reported exposures cannot be readily compared with the present study.\nA potentially important source of air pollution in the Warri area is the petrochemical industry. Robins et al. (2005) found prior day exposures to both sulfur dioxide and PM10 were associated with lower respiratory symptoms among children at a school bordering a refinery in Durban, South Africa. Another South African study found associations between asthma symptoms and exposure to petrochemical refinery emissions in Cape Town estimated based on wind factors and distance of residence from refinery (White et al. 2009).\nReported indoor air pollution was not significantly associated with the outcomes investigated in this study, but phlegm was positively associated with cooking with wood or coal or with kerosene instead of gas. We did not find a relationship between kerosene use and wheeze or rhinitis, in contrast with a study in urban Ethiopia ( Venn et al. 2001 ). We did not see statistically significant associations between living with smokers and cough, phlegm, or wheeze symptoms ( Table 3 ) as might have been expected ( Strachan and Cook 1998 ). However, this result may relate to the question being a poor indicator of indoor air pollution exposures (e.g., because of ventilation in Nigerian houses or smoking habits) or lack of statistical power, or both, rather than a lack of effect.\nThe low prevalence of diagnosed asthma in this study (0.9%), despite a relatively high prevalence of self-reported symptoms such as wheeze (5.4%), may indicate undiagnosed asthma due to limited access to health services in this low socioeconomic status area. As noted by Burney et al. (1989) , recognition of asthma depends on the quality of health services in a study area and, in addition, on readiness of doctors to attach the label “asthma” to asthmalike symptoms. Main priorities for many community health centers in this area of Nigeria are major tropical and life-threatening infectious diseases such as malaria and tuberculosis, and a diagnosis of asthma is likely to indicate either those with severe disease or those who are richer and better able to access health care.\nLimitations of this study. Because of logistic difficulties and limited resources, individual-level measurements of indoor and outdoor air pollution exposures and modeled air pollution exposures were not available. The self-reported exposures and limited school-based measurements could have led to exposure misclassification, but we consider that this was likely to have been largely nondifferential and therefore to have led to an underestimate of the impacts on health.\nSelf-reported air pollution exposure may introduce misclassification bias because of individual reporting differences. In a survey of English households, Hunter et al. (2004) found factors such as a person with respiratory disease in the home, belief that pollution is harmful, and socioeconomic status influenced reporting of air pollution exposures. However, other European studies have shown population mean values of reported annoyance with air pollution correlate reasonably well with measured air pollution levels ( Forsberg et al. 1997 ; Jacquemin et al. 2007 ; Oglesby et al. 2000 ).\nThe validity of our survey results is supported by the consistency in exposures reported among children within each school and the consistency of the reported school exposures with measurements taken at each school. For the five main self-reported measures of school-related pollution (traffic, flaring, gas vapor, open burning, and cooking), the concordance among children within schools averaged between 92.5 and 97.7%. In addition, children reporting traffic problems at school were more likely to attend schools sited closer to roads than children who did not. The 12 schools with > 90% of children reporting traffic fumes at school were an average (± SD) of 27.0 ± 27.2 m from the nearest main road, compared with an average distance of 68.6 ± 36.7 m for the five schools where < 10% of children reported traffic-related problems.\nMeasurements of PM and CO were made only for very short time periods and therefore may not fully reflect usual or long-term exposures. In addition, equipment used for CO measurements was relatively insensitive, and many measurements were close to or below the detection limit. Traffic counts were conducted only once. However, these measurements were not used alone, but in combination with other variables in PCA to estimate a pollution index. The PCA compensates for uncertainties in individual measures, as the weight of evidence is taken from a number of variables.\nConclusion\nIn this study, ambient air pollution from traffic had a modest association with respiratory symptoms in schoolchildren in Africa, even after accounting for personal and household risk factors such as overcrowding and use of biomass cooking fuels. There were significant logistical problems conducting this study in a deprived but polluted area of Nigeria, which may have led to an underestimate of the effect size, and findings need to be confirmed in further African studies of this age group. There were very small numbers of children with diagnosed asthma, and an association between traffic pollution and asthma was not demonstrated. However, asthma diagnosis may be an unreliable outcome in similar African settings, as it is partly dependent on access to health care.\nAttached Files\nPDF Version\nReferences\nAna GREE, Shendell DG, Odeshi TA, Sridhar MKC. 2009. Identification and initial characterization of prominent air pollution sources and respiratory health at secondary schools in Ibadan, Nigeria. J Asthma 46:670–676.\nBayer-Oglesby L, Grize L, Gassner M, Takken-Sahli K, Sennhauser F, Neu U, et al. 2005. Decline of ambient air pollution levels and improved respiratory health in Swiss children. Environ Health Perspect 113:1632–1637.\nBrunekreef B.. 2005. Out of Africa.. Occup Environ Med 62:351–352.\nBrunekreef B, Stewart AW, Anderson HR, Lai CK, Strachan DP, Pearce N. 2009. Self-reported truck traffic on the street of residence and symptoms of asthma and allergic disease: a global relationship in ISAAC Phase 3. Environ Health Perspect 117:1791–1798.\nBurney PGJ, Laitinen LA, Perdrizet S, et al. 1989. Validity and repeatability of the IUATLD (1984) bronchial symptoms questionnaire: an international comparison. Eur Respir J 2:940–946.\nCiccone G, Forastiere F, Agabiti N, Biggeri A, Bisanti L, Chellini E, et al. 1998. Road traffic and adverse respiratory effects in children. SIDRIA Collaborative Group. Occup Environ Med 55:771–778.\nEllwood P, Asher MI, Beasley R, Clayton TO, Stewart AW on behalf of the ISAAC Steering Committee and the ISAAC Phase Three Study Group 2000. International Study of Asthma and Allergies in Children, Phase 3 Manual. ISAAC International Data Centre, Auckland, New Zealand. Available: http://isaac.auckland.ac.nz/phases/phase​three/phasethreemanual.pdf [accessed 28 June 2011]\nEzzati M, Lopez AD, Rodgers A, Murray CJL, eds 2004. Comparative Quantification of Health Risks: Global and Regional Burden of Disease Attribution to Selected Major Risk Factors. Vol 2. Geneva:World Health Organization. Available: http://www.who.int/publications/cra/en/ [accessed 28 June 2011]\nForsberg B, Stjernberg N, Wall S.. 1997. People can detect poor air quality well below guideline concentrations: a prevalence study of annoyance reactions and air pollution from traffic. Occup Environ Med 54(1):44–48.\nHealth Effects Institute. HEI Panel on the Health Effects of Traffic-Related Air Pollution 2010. HEI Special Report 17. Traffic-Related Air Pollution: A Critical Review of the Literature on Emissions, Exposure, and Health Effects. HEI Special Report 17. Boston, MA:Health Effects Institute, Available: http://pubs.healtheffects.org/view.php?i​d=334 [accessed 28 June 2011].\nHirsch T, Weiland SK, von Mutius E, Safeca AF, Grafe H, Csaplovics H, et al. 1999. Inner city air pollution and respiratory health and atopy in children. Eur Respir J 14:669–677.\nHunter PR, Bickerstaff K, Davies MA. 2004. Potential sources of bias in the use of individual’s recall of the frequency of exposure to air pollution for use in exposure assessment in epidemiological studies: a cross-sectional survey. Environ Health 3:3..\nJacquemin B, Sunyer J, Forsberg B, Götschi T, Bayer-Oglesby L, Ackermann-Liebrich U, et al. 2007. Annoyance due to air pollution in Europe. Int J Epidemiol 36(4):809–820.\nJalaludin BB, O’Toole BI, Leeder SR. 2004. Acute effects of urban ambient air pollution on respiratory symptoms, asthma medication use, and doctor visits for asthma in a cohort of Australian children. Environ Res 95(1):32–42.\nJanssen NAH, Brunekreef B, van Vliet P, Aarts F, Meliefste K, Harssema H, et al. 2003. The relationship between air pollution from heavy traffic and allergic sensitization, bronchial hyperresponsiveness, and respiratory symptoms in Dutch schoolchildren. Environ Health Perspect 111:1512–1518.\nKing JR, Jackson DA. 1999. Variable selection in large environmental data sets using principal components analysis. Environmetrics 10(1):67–77.\nKuehni CE, Strippoli MF, Zwahlen M, Silverman M. 2006. Association between reported exposure to road traffic and respiratory symptoms in children: evidence of bias. Int J Epidemiol 35(3):779–786.\nKünzli N, Kaiser R, Medina S, Studnicka M, Chanel O, Filliger P, et al. 2000. Public-health impact of outdoor and traffic-related air pollution: a European assessment. Lancet 356(9232):795–801.\nMcConnell R, Berhane K, Yao L, Jerrett M, Lurmann F, Gilliland F, et al. 2006. Traffic, susceptibility, and childhood asthma. Environ Health Perspect 114:766–772.\nMustapha BA. 2008. A Study of Air Pollution and Respiratory Health in Schoolchildren in Warri, Delta State, Nigeria. [PhD Thesis]. London:University of London.\nNeuberger M, Schimek MG, Horak F Jr, Moshammer H, Kundi M, Frischer T, et al. 2004. Acute effects of particulate matter on respiratory diseases, symptoms and functions: epidemiological results of the Austrian Project on Health Effects of Particulate Matter (AUPHEP). Atmos Environ 38(24):3971–3981.\nNicolai T, Carr D, Weiland SK, Duhme H, von Ehrenstein O, Wagner C, et al. 2003. Urban traffic and pollutant exposure related to respiratory outcomes and atopy in a large sample of children. Eur Respir J 21:956–963.\nOglesby L, Künzli N, Monn C, Schindler C, Ackermann-Liebrich U, Leuenberger P.. 2000. Validity of annoyance scores for estimation of long term air pollution exposure in epidemiologic studies: the Swiss Study on Air Pollution and Lung Diseases in Adults (SAPALDIA). Am J Epidemiol 152:75–83.\nPierse N, Rushton L, Harris RS, Kuehni CE, Silverman M, Grigg J. 2006. Locally generated particulate pollution and respiratory symptoms in young children. Thorax 61:216–220.\nRabinovitch N, Strand M, Gelfand EW. 2006. Particulate levels are associated with early asthma worsening in children with persistent disease. Am J Respir Crit Care Med 173:1098–1105.\nRobins TG, Batterman S, Mentz GB, Kistnasamy B, Jack C, Irusen E, et al. 2005. Respiratory health and air pollution in South Durban: the Settlers school study. Epidemiology 16(5):S79.\nStrachan DP, Cook DG. 1998. Health effects of passive smoking. 6. Parental smoking and childhood asthma: longitudinal and case-control studies. Thorax 53:204–212.\nVenn AJ, Yemaneberhan H, Bekele Z, Lewis SA, Parry E, Britton J. 2001. Increased risk of allergy associated with the use of kerosene fuel in the home. Am J Respir Crit Care Med 164(9):1660–1664.\nVenn A, Yemaneberhan H, Lewis S, Parry E, Britton J.. 2005. Proximity of the home to roads and the risk of wheeze in an Ethiopian population. Occup Environ Med 62(6):376–380.\nWhite N, teWaterNaude J, van der Walt A, Ravenscroft G, Roberts W, Ehrlich R 2009. Meteorologically estimated exposure but not distance predicts asthma symptoms in schoolchildren in the environs of a petrochemical refinery: a cross-sectional study. Environ Health 25:8:45; doi:10.1186/1476-069X-8-45 [Online 25 September 2009].\nWorld Health Organization (WHO) and European Commission Joint Research Centre (EC RJC) 2002. Guidelines for Concentration and Exposure-Response Measurement of Fine and Ultra Fine Particulate Matter for Use in Epidemiological Studies (Schwela D, Morawska L, Kotzias D, eds). Available: http://whqlibdoc.who.int/hq/2002/a76621.​pdf [accessed 28 June 2011]\nInformation for Our Readers\nA Note about Our Table of Contents\nEHP operates under a continuous publication model in which new content is published every day, instead of just one day a month. As a result, each monthly table of contents starts with one article, and grows each day throughout the month. Sign up for our e-mail alerts to be notified when new content is available!\nAnnouncements\n""","0.23301682","""https://ehp.niehs.nih.gov/1003099/""","[-0.178219,51.500505]"
"""Imperial_College_London""","""Developing Low Gasoline Particulate Emission Engines Through Improved Fuel Delivery""","""Developing Low Gasoline Particulate Emission Engines Through Improved Fuel Delivery\nPaper #:\nhttps://doi.org/10.4271/2014-01-2843\nCitation:\nOudeNijeweme, D., Freeland, P., Behringer, M., and Aleiferis, P., \""Developing Low Gasoline Particulate Emission Engines Through Improved Fuel Delivery,\"" SAE Technical Paper 2014-01-2843, 2014, https://doi.org/10.4271/2014-01-2843 .\n8\nAbstract:\nParticulate emissions are of growing concern due to health impacts. Many urban areas around the world currently have particulate matter levels exceeding the World Health Organisation safe limits. Gasoline engines, especially when equipped with direct injection systems, contribute to this pollution. In recognition of this fact European limits on particulate mass and number are being introduced. A number of ways to meet these new stringent limits have been under investigation. The focus of this paper is on particulate emissions reduction through improvements in fuel delivery.This investigation is part of the author's ongoing particulate research and development that includes optical engine spray and combustion visualisation, CFD method development, engine and vehicle testing with the aim to move particulate emission development upstream in the development process. As part of this work, a spark eroded and a laser drilled injector were fully characterised in a spray vessel under key engine running conditions. Injector nozzle geometries and mass flow data were also measured in great detail.This paper demonstrates using both steady state and transient engine testing that very significant improvements in particulate emissions can be made. Control strategies enabling multiple injections of smaller volumes of fuel per injection are the most promising technology. The MAHLE Flexible ECU (MFE) combined with injector testing allowed early stage development and demonstrated these effects for a number of key engine operating conditions. Most notably it was found that particulate matter emissions could be reduced by 80-90% during the catalyst light off phase. A new approach was developed (MASTER) to simultaneously assess the effects of calibration changes on all emissions to increase testing efficiency and hence get to more optimised solutions faster. This approach was successfully tested on a production engine comparing two injectors achieving 82% reduction in particulate number emissions during the first 200seconds of the NEDC relative to the EU5b baseline.Finally it was found that both fuel properties and injector deposits can have a significant effect on particulate emissions.\nEvent:\n""","0.76158047","""http://papers.sae.org/2014-01-2843/""","[-0.178219,51.500505]"
"""Brunel_University_London""","""Performance and Analysis of a 4-Stroke Multi-Cylinder Gasoline Engine with CAI Combustion""","""Performance and Analysis of a 4-Stroke Multi-Cylinder Gasoline Engine with CAI Combustion\nPaper #:\nhttps://doi.org/10.4271/2002-01-0420\nCitation:\nZhao, H., Li, J., Ma, T., and Ladommatos, N., \""Performance and Analysis of a 4-Stroke Multi-Cylinder Gasoline Engine with CAI Combustion,\"" SAE Technical Paper 2002-01-0420, 2002, https://doi.org/10.4271/2002-01-0420 .\n19\nAbstract:\nControlled Auto-Ignition (CAI) combustion was realised in a production type 4-stroke 4-cylinder gasoline engine without intake charge heating or increasing compression ratio. The CAI engine operation was achieved using substantially standard components modified only in camshafts to restrict the gas exchange processThe engine could be operated with CAI combustion within a range of load (0.5 to 4 bar BMEP) and speed (1000 to 3500 rpm). Significant reductions in both specific fuel consumption and CO emissions were found. The reduction in NOx emission was more than 93% across the whole CAI range. Though unburned hydrocarbons were higher under the CAI engine operation.In order to evaluate the potential of the CAI combustion technology, the European NEDC driving cycle vehicle simulation was carried out for two identical vehicles powered by a SI engine and a CAI/SI hybrid engine, respectively. The simulation results showed only moderate improvement in fuel economy and exhaust emissions because of low utilisation of CAI during the drive cycle.In order to take full advantage of the CAI combustion technology, detailed analyses were carried out on the engine's performance, heat release and combustion characteristics, emissions and the effect of gas exchange processes. These analyses showed that the engine's performance and emissions were mainly affected by the trapped residual fractions and residual temperature. In addition, the backflow was found to affect the combustion and emission as well.\nAlso in:\n""","0.7269776","""http://papers.sae.org/2002-01-0420/""","[-0.472855,51.532848]"
"""UCL""","""Iris Publication""","""http://discovery.ucl.ac.uk/1428699/\nAbstract\nThe future may herald higher energy prices and greater regulation of shipping's greenhouse gas emissions.  Especially with the introduction of the Energy Efficiency Design Index (EEDI), tools are needed to assist engineers in selecting the best solutions to meet evolving requirements for reducing fuel consumption and associated carbon dioxide (CO₂) emissions.  To that end, a concept design tool, the Ship Impact Model (SIM), for quickly calculating the technical performance of a ship with different CO₂ reducing technologies at an early design stage has been developed.  The basis for this model is the calculation of changes from a known baseline ship and the consideration of profitability as the main incentive for ship owners or operators to invest in technologies that reduce CO₂ emissions.  The model and its interface with different technologies (including different energy sources) is flexible to different technology options; having been developed alongside technology reviews and design studies carried out by the partners in two different projects, ``Low Carbon Shipping - A Systems Approach'' majority funded by the RCUK energy programme and ``Energy Technology Institute Heavy Duty Vehicle Efficiency - Marine'' led by Rolls-Royce.  The model has been used alongside a wider economic and logistic model of the international shipping system, the focus of which is on large cargo ships engaged in ocean-crossing trade, to potentially advise on regulation and what CO₂ emission reductions are possible from shipping.  The Ship Impact Model (SIM) allows a large design space to be explored quickly, incorporating economic considerations at a single ship level and supporting combinations of technologies and design and operational parameters.  Whilst considering that comparisons against actual ship data have been limited, the model has a high enough fidelity and accuracy to be used as a decision tool in the selection between different technologies (providing the technologies are adequately described).\nPublication data is maintained in RPS. Visit https://rps.ucl.ac.uk\n› More search options\n""","0.5725689","""http://iris.ucl.ac.uk/iris/publication/943996/1""",
"""Brunel_University_London""","""Editorial | Proceedings of the Institution of Civil Engineers - Transport""","""Proceedings of the Institution of Civil Engineers - Transport\nProceedings of the Institution of Civil Engineers - Transport\nISSN 0965-092X | E-ISSN 1751-7710\nPhD, CEng, MCIHT, MICE, PGCHE, FHEA\nx\nDepartment of Mechanical, Aerospace and Civil Engineering, Brunel University, London, UK\nAuthor Affiliations\nPublished Online: July 11, 2016\nKey:\nFree content\nTrial content\nWelcome to the August 2016 issue of Transport. This edition presents six papers covering important theoretical and practical aspects of transportation engineering. On behalf of the editorial board, I thank the authors for their hard work and valuable contributions to the journal. I would also like to extend my appreciation to our esteemed reviewers for their invaluable support.\nTransport networks are one of the most important national assets. Economic prosperity, rapid urbanisation, increasing traffic and ageing infrastructures all have immense impact on safe and efficient operation of this vital asset. Some of these factors are addressed in this issue.\nThe first paper ( Appiah et al., 2016 ) deals with truck characteristics in traffic micro-simulation. The authors present an approach to incorporating the operating characteristics of a local truck fleet in the calibration of micro-simulation models. This approach is different from conventional model calibration where focus is given to adjusting the parameters of driving behaviour logic. The second paper ( Mohapatra et al., 2016 ) reports the influence of conflicting traffic on U-turns at uncontrolled median openings under mixed traffic conditions in an Indian context. With rapid urbanisation and increased traffic volume, most urban roads in India are constructed as multi-lane roads, while many existing two-lane roads are also being widened to multi-lane roads. These multi-lane roads are generally constructed with a raised median, in order to segregate the opposing traffic movements. The authors showed that the impact of conflicting traffic is greater on four-lane roads compared to six-lane roads. In the third paper ( Zong et al., 2016 ), the authors present a model for investigating the feasibility of an integrated transportation demand management (TDM) programme in the Nanhai district of China to mitigate the traffic congestion and reduce exhaust gas emission from motor vehicles. The TDM programme includes a bus priority policy, a motorcycle restriction policy and a congestion pricing policy. The authors demonstrate that all three policies would have a positive effect on Nanhai's transport system. All three papers address key transport issues which traffic engineers and researchers will find very useful.\nIn recent years, railway industries have faced a massive demand for increasing train speeds. However, switch and turnout parts of the track are two critical parts where speed reduction is necessary. In order to develop a more efficient system, the fourth paper ( Sadeghi et al., 2016 ) presents a mathematical model of the impact of railway geometry on the safety of train running and permissible speed. The model is based on the railway vehicle and track parameters such as curve radius, switch initial angle and track gauge with running speed. The model accuracy is verified in field trials. This paper is a good example of how theoretical modelling could help to solve practical issues.\nThe fifth and sixth papers address concrete pavement rehabilitation. The fifth paper ( Lu and Rong, 2016 ), presents the impact of gradation on rubblised Portland cement concrete pavement. Rubblisation is a popular technique for upgrading severely deteriorated concrete pavement. Many previous studies have shown that rubblised concrete with a hot-mix asphalt (HMA) overlay improves pavement performance, especially its cracking resistance. The authors present two studies and demonstrate that if the rubblised gradation matches the requirement for the crushed stone base of the flexible pavement, tensile strains at the HMA overlay bottom develop at a slower pace, indicating an improvement in deterioration resistance (namely cracking) of the overlay system. This article should be a good resource for practitioners and researchers alike. The final paper ( Gao, 2016 ), presents a mathematical model for evaluating the impact of top-down surface cracking in concrete pavement. Surface cracks of concrete pavement not only impact safety and ride quality, but also reduce service life. The author shows that crack length and load position significantly influence the stress intensity factors, and that stress intensity factors are less affected by the elastic modulus of the pavement material than might be expected. Observing that studies on the mechanism of crack propagation in a cement concrete pavement are rather limited, this paper should serve to enhance current knowledge in this field.\nWe trust you find these papers useful and rewarding to read. Comments on this issue or on general journal-related matters will be received with great interest.\nReferences\n""","0.42523515","""http://www.icevirtuallibrary.com/doi/10.1680/jtran.2016.169.4.185""","[-0.472855,51.532848]"
"""UCL""","""Iris Publication""","""http://discovery.ucl.ac.uk/1368086/\nAbstract\nA study is presented of the rates of penetration of different transport technologies under policy constraints on CO 2  emissions. The response of this sector is analyzed within an overall national level of restriction, with a focus on automobiles, light trucks, and heavy freight trucks. Using the US as an example, a linked set of three models is used to carry out the analysis: a multi-sector computable general equilibrium model of the economy, a MARKAL-type model of vehicle and fuel supply technology, and a model simulating the split of personal and freight transport among modes. Results highlight the importance of incremental improvements in conventional internal combustion engine technology, and, in the absence of policies to overcome observed consumer discount rates, the very long time horizons before radical alternatives like the internal combustion engine hybrid drive train vehicle are likely to take substantial market share. © 2004 Elsevier Ltd. All rights reserved.\nPublication data is maintained in RPS. Visit https://rps.ucl.ac.uk\n› More search options\n""","0.76707876","""http://iris.ucl.ac.uk/iris/publication/781022/7""",
"""Imperial_College_London""","""Technologies to measure indicators for road user charging | Proceedings of the Institution of Civil Engineers - Transport""","""Proceedings of the Institution of Civil Engineers - Transport\nProceedings of the Institution of Civil Engineers - Transport\nISSN 0965-092X | E-ISSN 1751-7710\nTechnologies to measure indicators for road user charging\nAuthors: \nMSc, PhD, FRIN, FInstCES, MICE, MIHT\nx\nEdward J. Bloustein School of Planning and Public Policy, Rutgers University, New Brunswick, NJ, USA\n, ,\nPublished Online: May 25, 2015\nKey:\nTrial content\nAbstract\nA technically and economically feasible road user charging scheme should be based on quantities that are readily and accurately measurable, as well as being directly variable with the amount of road use and its impact on the environment and society. A key requirement for a pricing scheme is that the charging regime used should be easy for motorists to understand, but at the same time flexible enough for the operator to implement a wide range of policies to meet different aims. A set of variable road user charging indicators is identified herein by considering both the associated costs of a trip and the operational requirements for a feasible road pricing scheme. The study then focused on identifying a set of currently feasible technologies to measure these variables in real-time with high accuracy. Particular attention was paid to the need accurately to track vehicle movements and link these movements to geographical areas and road types, and the key pollutants and particulate matter, all of which have different potential effects that are in some cases dependent on location and time of emissions. Other issues, such as congestion measurement, are also discussed.\nKeywords:\n""","0.62041175","""http://www.icevirtuallibrary.com/doi/10.1680/tran.2010.163.2.63""","[-0.178219,51.500505]"
"""Cranfield_University""","""Modelling and simulation of a fuel cell powered electric drivetrain for wide body passenger aircraftProceedings of the Institution of Mechanical Engineers, Part G: Journal of Aerospace Engineering - R Felix Moreno, JT Economou, D Bray, K Knowles, 2013""","""Night Noise Fact Sheet, BAA Heathrow. Google Scholar\n3.\nMorrell P and Lu Chen Y. Aircraft noise social cost and charge mechanisms ± a case study of Amsterdam Airport Schiphol. Transportation Research Part D 5., 2000, pp.305–320. Google Scholar\n4.\nControl of ground noise and emissions at Heathrow. Operational Safety Instruction, BAA Heathrow, 12 January 2011. Google Scholar\n5.\nInternational Civil Aviation Organization. Focus on: Environment, Quebec, Canada: ICAO, 2010. Google Scholar\n6.\nAircraft emission charges Zurich Airport. Flughafen Zürich AG, Environmental Services, July 2000. Google Scholar\n7.\nJoint demonstration of new electric taxi system. Corporate Communications, Lufthansa Technik AG, Hamburg, Germany, 8 December 2011. Google Scholar\n8.\nSpiegel, C. PEM fuel cell modeling and simulation using Matlab, London: Academic Press, 2008. Google Scholar\n9.\nGou, B, Woon, KN, Diong, B. Fuel cells: modeling, control, and applications, Boca Raton: CRC Press, 2010. Google Scholar\n10.\nKrishnan, R. Permanent magnet synchronous and brushless DC motor drives, Boca Raton: CRC Press, 2010. Google Scholar\n11.\nGenta, G. Motor vehicle dynamics, Singapore: World Scientific Publishing, 1997. Google Scholar , Crossref\n12.\nAdams J, Woong-Chui AY, Oglesby KA, et al. The development of Ford’s P2000 fuel cell vehicle. SAE Paper 2000-01-1061, 2000. Google Scholar\n13.\nGao L, Jiang Z and Dougal RA. Evaluation of active hybrid fuel cell/battery power sources. IEEE Trans Aerosp Electron Syst 2005; 41(1): 346–355. Google Scholar\n14.\nGarcia P, Torreglosa JP, Fernández LM, et al. Viability study of a FC-battery-SC tramway controlled by equivalent consumption minimization strategy. Int J Hydrogen Energy 2012; 37(11): 9368–9382. Google Scholar\n15.\nHoneywell APU reliability exceeds 10,000 hours. Press Release. Honeywell Aerospace Media Center, 15 June 2009. Google Scholar\n16.\nMark 1100 product data sheet. Ballard Power Systems Inc., Burnaby British Columbia, Canada, 2006. Google Scholar\n17.\nFCvelocity-HD6 product data sheet. Ballard Power Systems Inc., Burnaby British Columbia, Canada. 2011. Google Scholar\n18.\nAIAA. Aerospace America. Beyond the more electric aircraft, Reston, VA: American Institute of Aeronautics and Astronautics, 2005. Google Scholar\n""","0.61919415","""http://journals.sagepub.com/doi/10.1177/0954410012473389""","[-0.629225,52.074389]"
"""Imperial_College_London""","""Characteristics of Ethanol, Butanol, Iso-Octane and Gasoline Sprays and Combustion from a Multi-Hole Injector in a DISI Engine""","""Characteristics of Ethanol, Butanol, Iso-Octane and Gasoline Sprays and Combustion from a Multi-Hole Injector in a DISI Engine\nPaper #:\nhttps://doi.org/10.4271/2008-01-1591\nCitation:\nSerras-Pereira, J., Aleiferis, P., Richardson, D., and Wallace, S., \""Characteristics of Ethanol, Butanol, Iso-Octane and Gasoline Sprays and Combustion from a Multi-Hole Injector in a DISI Engine,\"" SAE Int. J. Fuels Lubr. 1(1):893-909, 2009, https://doi.org/10.4271/2008-01-1591 .\n17\nAbstract:\nRecent pressures on vehicle manufacturers to reduce their average fleet levels of CO2 emissions have resulted in an increased drive to improve fuel economy and enable use of fuels developed from renewable sources that can achieve a net reduction in the CO2 output of each vehicle. The most popular choice for spark-ignition engines has been the blending of ethanol with gasoline, where the ethanol is derived either from agricultural or cellulosic sources such as sugar cane, corn or decomposed plant matter. However, other fuels, such as butanol, have also arisen as potential candidates due to their similarities to gasoline, e.g. higher energy density than ethanol. To extract the maximum benefits from these new fuels through optimized engine design and calibration, an understanding of the behaviour of these fuels in modern engines is necessary. In particular, the use of direct injection spark-ignition technology requires spray formation and combustion characteristics to be quantified in order to improve both injector design and operating strategies. To this end an optical investigation of spray development and combustion was undertaken in a single-cylinder direct-injection spark-ignition engine with a centrally mounted multi-hole injector. Specifically, crank-angle resolved imaging studies were performed and batches of images from 100 consecutive cycles were acquired with synchronised in-cylinder pressure logging. The engine was motored and fired at 1500 RPM stoichiometrically under part load (0.5 bar intake pressure), with injection timing set early in the intake stroke to promote homogeneous mixture formation. The effects were investigated at engine coolant temperatures of 20 °C and 90 °C using gasoline, iso-octane, ethanol and butanol. Projected spray areas as seen through the piston crown were calculated to reveal information about the atomization and evaporation processes for each fuel. Additionally, flame areas and centroids were calculated to analyse the combustion process relative to measured in-cylinder pressure histories.\nAlso in:\n""","0.5107356","""http://papers.sae.org/2008-01-1591/""","[-0.178219,51.500505]"
"""Imperial_College_London""","""Day-to-day congestion pricing and network resilience: Transportmetrica A: Transport Science: Vol 11, No 9""","""Original Articles\nDay-to-day congestion pricing and network resilience\nAccepted author version posted online: 28 Aug 2015\nPublished online: 09 Oct 2015\nGet access /doi/full/10.1080/23249935.2015.1087234?needAccess=true\nAbstract\nOne important indicator of traffic network resilience is rapidity, which measures the speed at which a system returns to its normal state after a disruption. In this paper, we propose a day-to-day tolling scheme to increase the rapidity of road traffic systems after disturbances caused by natural or man-made events such as accidents, flooding, earthquake, and infrastructure damage. The theory of projected dynamical systems is applied to model the transient behaviour of traffic when faced with network disruptions. We further provide three computationally tractable solution methods for designing the toll under various assumptions on the information availability. The effectiveness of the proposed tolling scheme is guaranteed by theoretically established estimates. Numerical experiments on several test networks demonstrate the effectiveness of the dynamic tolling mechanisms in improving the rapidity and the potential cost efficiency of the traffic systems.\n""","0.78030723","""http://www.tandfonline.com/doi/full/10.1080/23249935.2015.1087234""","[-0.178219,51.500505]"
"""Queen's_University_Belfast""","""Sustainable non-automotive vehicles: The simulation challenges - Queen's University Belfast Research Portal - Research Directory & Institutional Repository for QUB""","""Sustainable non-automotive vehicles: The simulation challenges\nResearch output: Contribution to journal › Article\nEarly online date\nView graph of relations\nSimulation is a well-established and effective approach to the development of fuel-efficient and low-emissions vehicles in both on-highway and off-highway applications.\nThe simulation of on-highway automotive vehicles is widely reported in literature, whereas research relating to non-automotive and off-highway vehicles is relatively sparse. This review paper focuses on the challenges of simulating such vehicles and discusses the differences in the approach to drive cycle testing and experimental validation of vehicle simulations. In particular, an inner-city diesel-electric hybrid bus and an ICE (Internal Combustion Engine) powered forklift truck will be used as case studies.\nComputer prediction of fuel consumption and emissions of automotive vehicles on standardised drive cycles is well-established and commercial software packages such as AVL CRUISE have been specifically developed for this purpose. The vehicles considered in this review paper present new challenges from both the simulation and drive-cycle testing perspectives. For example, in the case of the forklift truck, the drive cycles involve reversing elements, variable mass, lifting operations, and do not specify a precise velocity-time profile. In particular, the difficulties associated with the prediction of productivity, i.e. the maximum rate of completing a series of defined operations, are discussed. In the case of the hybrid bus, the standardised drive cycles are unrepresentative of real-life use and alternative approaches are required in the development of efficient and low-emission vehicles.\nTwo simulation approaches are reviewed: the adaptation of a standard automotive vehicle simulation package, and the development of bespoke models using packages such as MATLAB/Simulink.\nDOI\n""","0.59978807","""http://pure.qub.ac.uk/portal/en/publications/sustainable-nonautomotive-vehicles-the-simulation-challenges(6fedbc54-b626-48b5-9247-e18e64a36c78).html""","[-5.934759,54.583863]"
"""University_of_Exeter""","""Proximity-based modelling of cross-contamination through agent-based simulation: a feasibility study | SpringerLink""",""", Volume 2, Issue 1 , pp 61–71 | Cite as\nProximity-based modelling of cross-contamination through agent-based simulation: a feasibility study\nAuthors\n2 Shares\nAbstract\nProximity-based modelling methodology enables mathematical representation of a real system that is characterised by the existence of entities that come into physical contact. Healthcare systems can benefit from this methodology since physical proximity between entities (e.g., patients, clinical items like surgical equipment and blood units) can result in the spread of infectious diseases and cross-contamination. The existing analytical techniques, which are mainly based on differential equations, are unsuitable for representing the fine-grained, micro-world view of the entity interactions that we intend to model. We therefore extend Agent-Based Simulation (ABS) by enabling individual agents to be aware of the physical location of the other agents being modelled in a 3-dimensional space – this is a perquisite for our proximity-based modelling methodology. To demonstrate the feasibility of our approach, we experiment with a scenario wherein boxes of degradable clinical items, modelled as agents, are stored in close proximity. We use Cutting and Packing Optimisation (CPO) algorithms from literature to define the arrangement of these agents in the 3-D space and to make the individual agents ‘location-aware’. An ABS model then simulates cross-contamination by modelling the spread of contaminants among the agents confined in the well-defined space. Our approach can be used to model analogous situations wherein physical proximity between entities in the underlying system is a necessary condition for entity interactions.\nKeywords\nagents agent-based simulation container loading algorithm cutting and packing optimisation cross-contamination proximity modelling \nReferences\nAcharyulu GVRK and Madhavedi S (2011) Factors contributing to perishability in traditional fresh produce distribution system: a study on tomato and banana chains in Andhra Pradesh, India. International Journal of Advanced Economics and Business Management 1 (1), 1–5. Google Scholar\nAckerley N, Sertkaya A and Lange R (2010) Food transportation safety: characterizing risks and controls by use of expert opinion. Food Protection Trends 30 (4), 212–222. Google Scholar\nAshby BH (1995) Protecting perishable foods during transport by truck. Handbook no. 669, U.S. Department of Agriculture, Argicultural Marketing Service [WWW document] http://www.ams.usda.gov/AMSv1.0/getfile?dDocName=STELDEV3021003 (accessed 29 June 2012).\nBagni R, Berchi R and Cariello P (2002) A comparison of simulation models applied to epidemics. Journal of Artificial Societies and Social Simulation 5 (3), http://jasss.soc.surrey.ac.uk/5/3/5.html , (accessed 28 September 2012).\nBischoff EE (2006) 3-D packing of items with limited load bearing strength. European Journal of Operational Research 168 (3), 952–966. CrossRef Google Scholar\nBhat RV (1988) Mould deterioration of agricultural commodities during transit: problems faced by developing countries. International Journal of Food Microbiology 7 (3), 219–225. CrossRef Google Scholar\nBunn DW and Oliveira FS (2001) Agent-based simulation - an application to the new electricity trading. IEEE Transactions on Evolutionary Computation 5 (5), 493–503. CrossRef Google Scholar\nCarley KM, et al (2006) Bio war: scalable agent-based model of bioattacks. IEEE Transactions on Systems, Man, and Cybernetics, Part A: Systems and Humans 36 (2), 252–265. CrossRef Google Scholar\nCASOS (2012) Center for Computational Analysis of Social and Organizational Systems. School of Computer Science, Carnegie Mellon [WWW document] http://www.casos.cs.cmu.edu/ (accessed 30 June 2012).\nChen H-K, Hsueh C-F and Chang M-S (2009) Production scheduling and vehicle routing with time windows for perishable food products. Computers & Operations Research 36 (7), 2311–2319. CrossRef Google Scholar\nCoburn BJ, Wagner BG and Blower S (2009) Modelling influenza epidemics and pandemics: insights into the future of swine flu (H1N1). BMC Medicine 7:30. CrossRef Google Scholar\nDowning TE, Moss S and Pahl-Wostl C (2001) Understanding climate policy using participatory agent-based social simulation. In Multi‐agent Based Simulation. Lecture Notes in Computer Science 1979/2001. (Moss S & Davidsson P, Eds) pp. 127–140, Springer-Verlag, Berlin. Google Scholar\nDunham JB (2005) An agent-based spatially explicit epidemiological model in mason. Journal of Artificial Societies and Social Simulation 9, (1), http://jasss.soc.surrey.ac.uk/9/1/3.html (accessed 28 September 2012). Google Scholar\nEidelson BM and Lustick I (2004) VIR-pox: an agent-based analysis of smallpox preparedness and response policy. Journal of Artificial Societies and Social Simulation 7 (3), http://jasss.soc.surrey.ac.uk/7/3/6.html (accessed 28 September 2012).\nEmrich S, Suslov S and Judex F (2007) Fully agent based modellings of epidemic spread using AnyLogic. In Proceedings of EUROSIM (Zupančič B, Karba R and Blažič S, Eds) 9–13 September 2007, Ljubljana, Slovenia. Google Scholar\nEubank S, et al (2004) Modelling disease outbreaks in realistic urban social networks. Nature 429 (6988), 180–184. CrossRef Google Scholar\nFerguson NM, Cummings DAT, Fraser C, Cajka JC, Cooley PC and Burke DS (2006) Strategies for mitigating an influenza pandemic. Nature 442 (7101), 448–452. CrossRef Google Scholar\nGordon TJ (2003) A simple agent model of an epidemic. Technological Forecasting and Social Change 70 (5), 397–417. CrossRef Google Scholar\nGotts NM, Polhill JG and Law ANR (2003) Agent-based simulation in the study of social dilemmas. Artificial Intelligence Review 19 (1), 3–92. CrossRef Google Scholar\nHalloran ME et al (2008) Modelling targeted layered containment of an influenza pandemic in the United States. Proceedings of the National Academy of Sciences of the United States of America 105 (12), 4639–4644. CrossRef Google Scholar\nHalloran ME, Longini Jr. IM, Nizam A and Yang Y (2002) Containing bioterrorist smallpox. Science 298 (5597), 1428–1432. CrossRef Google Scholar\nHarding PL and Dyer Jr. RMM (1942) Effect of thinning on some of the phyical and chemical characters of Valencia oranges. In Proceeding of the Florida State Hortricultural Society, 55: 34–38 [WWW document] http://www.fshs.org (accessed 29 June 2012).\nHotchkiss JR, Strike DG, Simonson DA, Broccard AF and Crooke PS (2005) An agent-based and spatially explicit model of pathogen dissemination in the intensive care unit. Critical Care Medicine 33 (1), 168–176. CrossRef Google Scholar\nKatsaliaki K and Mustafee N (2011) Applications of simulation research within the healthcare context. Journal of the Operation Research Society 62 (8), 1431–1451. CrossRef Google Scholar\nMacal CM and North MJ (2006) Tutorial on agent-based modelling and simulation part 2: how to model with agents. In Proceedings of the 2006 Winter Simulation Conference (Perrone LF, Wieland FP, Liu J, Lawson BG, Nicol DM, Fujimoto RM, Eds), pp 73–83. Google Scholar\nMacal CM and North MJ (2010) Tutorial on agent-based modelling and simulation. Journal of Simulation 4 (3), 151–162. CrossRef Google Scholar\nMustafee N, Katsaliaki K and Taylor SJE (2010) Profiling literature in healthcare simulation. SIMULATION: Transactions of the Society of Modelling and Simulation International 86 (8–9), 543–558. CrossRef Google Scholar\nPatlolla P, Gunupudi V, Mikler AR and Jacob RT (2004) Agent-based simulation tools in computational epidemiology. In Innovative Internet Community Systems, Lecture Notes in Computer Science 3473/2006. (Böhme, T, Rosillo VML, Unger H and Unger H Eds), pp. 212–223, Springer-Verlag, Berlin. Google Scholar\nPisinger D (2002) Heuristics for the container loading problem. European Journal of Operational Research 141 (2), 292–382. CrossRef Google Scholar\nRaberto M, Cincottia S, Focardib SM and Marchesic M (2001) Agent-based simulation of a financial market. Physica A: Statistical Mechanics and its Applications 299 (1–2), 319–327. CrossRef Google Scholar\nRobinson EA and McLeod J (1989) Packaging device and method. United States Patent, Patent Number: 4807424, Date of Patent: 28 February1989 [WWW document] http://www.google.com/patents/US4807424 (accessed 29 June 2012).\nShaliz CR (2006) Methods and techniques of complex systems science: an overview. In Complex Systems Science in Biomedicine (Deisboeck TS and Kresh JY, Eds), pp 33–114, Springer, New York. CrossRef Google Scholar\nSibbel R and Urban C (2001) Agent-based modelling and simulation for hospital management. In Cooperative Agent: Applications in the Social Sciences (Saam NJ and Schmidt B, Eds), pp 183–202, Kluwer Academic Publishers, the Netherlands. CrossRef Google Scholar\nSilcowitz-Hansen M (2010) Jinngine – a physics engine written in java. [WWW document] http://code.google.com/p/jinngine/ (accessed 29 June 2012).\nSong J, Haasb CT and Caldas CH (2007) A proximity-based method for locating RFID tagged objects. Advanced Engineering Informatics 21 (4), 367–376. CrossRef Google Scholar\nStainsby H, Taboada M and Luque E (2009) Towards an Agent-Based Simulation of Hospital Emergency Departments. In Proceedings of the 2009 IEEE International Conference on Services Computing, 21–25 September, Bangalore, Indiapp 536–539, IEEE Computer Society. Google Scholar\nTournas VH and Katsoudas E (2005) Mould and yeast flora in fresh berries, grapes and citrus fruits. International Journal of Food Microbiology 105 (1), 11–17. CrossRef Google Scholar\nVaught JB (2006) Blood collection, shipment, processing, and storage. Cancer Epidemiology, Biomarkers & Prevention 15 (9), 1582–1584. CrossRef Google Scholar\nWascher G, Haubner H and Schumann H (2007) An improved typology of cutting and packing problems. European Journal of Operational Research 183 (3), 1109–1130. CrossRef Google Scholar\nWorld Health Organisation (2002) Guidelines on Prevention and Control of Hospital Associated Infections. WHO, Regional Office for South-East Asia, New Delhi. Google Scholar\nWorld Health Organisation (2003) Guide to good storage practices for pharmaceuticals. WHO Technical Report Series No. 908, WHO, Geneva, Switzerland. Google Scholar\nWorld Health Organisation (2009) WHO guiding principles on human organ transplantation. Report of the Regional Meeting, WHO Western Pacific Region, Malaysia. Google Scholar\nXJ Technologies (2011) AnyLogic agent based modelling – help files. [WWW document] http://www.xjtek.com/anylogic/help (accessed 3 November 2011).\nCopyright information\n""","0.44058618","""https://link.springer.com/article/10.1057%2Fhs.2012.16""","[-3.533832,50.735262]"
"""Brunel_University_London""","""TRANSPORT ON COMPLEX NETWORKS: FLOW, JAMMING AND OPTIMIZATION | International Journal of Bifurcation and Chaos , Vol 17, No 07 | World Scientific""","""International Journal of Bifurcation and Chaos\nTRANSPORT ON COMPLEX NETWORKS: FLOW, JAMMING AND OPTIMIZATION\nBOSILJKA TADIĆ\nDepartment for Theoretical Physics, Jožef Stefan Institute, P. O. Box 3000, 1001 Ljubljana, Slovenia\nG. J. RODGERS\nDepartment of Mathematical Sciences, Brunel University, Uxbridge, Middlesex UB8 3PH, UK\nSTEFAN THURNER\nComplex Systems Research Group, Medical University of Vienna HNO, Währinger Gürtel 18-20, A-1090 Vienna, Austria\nReceived: April 12, 2006\nRevised: July 3, 2006\nMany transport processes on networks depend crucially on the underlying network geometry, although the exact relationship between the structure of the network and the properties of transport processes remain elusive. In this paper, we address this question by using numerical models in which both structure and dynamics are controlled systematically. We consider the traffic of information packets that include driving, searching and queuing. We present the results of extensive simulations on two classes of networks; a correlated cyclic scale-free network and an uncorrelated homogeneous weakly clustered network. By measuring different dynamical variables in the free flow regime we show how the global statistical properties of the transport are related to the temporal fluctuations at individual nodes (the traffic noise) and the links (the traffic flow). We then demonstrate that these two network classes appear as representative topologies for optimal traffic flow in the regimes of low density and high density traffic, respectively. We also determine statistical indicators of the pre-jamming regime on different network geometries and discuss the role of queuing and dynamical betweenness for the traffic congestion. The transition to the jammed traffic regime at a critical posting rate on different network topologies is studied as a phase transition with an appropriate order parameter. We also address several open theoretical problems related to the network dynamics.\nKeywords: Information traffic; correlated scale-free networks; jamming indicators; dynamic betweenness\nCited by (85):\nKai Liu , Xiaoyong Yan .  (2018) Current-flow efficiency of networks. Physica A: Statistical Mechanics and its Applications 492, 463-471.  Online publication date: 1-Feb-2018. [Crossref]\nChristopher Dabrowski , Kevin Mills .  (2017) Using realistic factors to simulate catastrophic congestion events in a network. Computer Communications 112, 93-108.  Online publication date: 1-Nov-2017. [Crossref]\nShi-Bao Li , Ya He , Jian-Hang Liu , Zhi-Gang Zhang , Jun-Wei Huang .  (2017) Congestion control strategy on complex network with privilege traffic. International Journal of Modern Physics C 28:09.  Online publication date: 1-Sep-2017. [ Abstract | PDF (400 KB) | PDF Plus (396 KB) ]\nDávid Csercsik , Sándor Imre .  (2017) Cooperation and coalitional stability in decentralized wireless networks. Telecommunication Systems 64:4, 571-584.  Online publication date: 1-Apr-2017. [Crossref]\nDan Yang , Liming Pan , Tao Zhou .  (2017) Lower bound of assortativity coefficient in scale-free networks. Chaos: An Interdisciplinary Journal of Nonlinear Science 27:3, 033113.  Online publication date: 1-Mar-2017. [Crossref]\nMarco Cogoni , Giovanni Busonera , Paolo Anedda , Gianluigi Zanetti .  (2017) Transition to congestion in communication/computation networks for near-optimal and sub-optimal resource management via Monte Carlo simulations. Journal of Network and Computer Applications 81, 1-11.  Online publication date: 1-Mar-2017. [Crossref]\nXianxia Yang , Jie Li , Cunlai Pu , Meichen Yan , Rajput Ramiz Sharafat , Jian Yang , Konstantinos Gakis , Panos M. Pardalos .  (2017) Traffic congestion and the lifetime of networks with moving nodes. Physical Review E 95:1.  Online publication date: 1-Jan-2017. [Crossref]\nDarja Wagner , Till Becker .  (2017) Evaluation of the Applicability of Random Walks for Generation of Material Flow Network Models. Procedia CIRP 63, 488-492.  Online publication date: 1-Jan-2017. [Crossref]\nN. Ben Haddou , H. Ez-zahraouy , A. Rachadi .  (2016) Implantation of the global dynamic routing scheme in scale-free networks under the shortest path strategy. Physics Letters A 380:33, 2513-2517.  Online publication date: 1-Jul-2016. [Crossref]\nNora Ben Haddou , Hamid Ez-Zahraouy , Abdelilah Benyoussef .  (2015) An adaptive routing scheme in scale-free networks. International Journal of Modern Physics C 26:12.  Online publication date: 1-Dec-2015. [ Abstract | PDF (431 KB) | PDF Plus (466 KB) ]\nChristopher Dabrowski .  (2015) Catastrophic event phenomena in communication networks: A survey. Computer Science Review 18, 10-45.  Online publication date: 1-Nov-2015. [Crossref]\nMiroslav Andjelković , Bosiljka Tadić , Slobodan Maletić , Milan Rajković .  (2015) Hierarchical sequencing of online social graphs. Physica A: Statistical Mechanics and its Applications 436, 582-595.  Online publication date: 1-Oct-2015. [Crossref]\nGang Liu , Yongshu Li , Jiawei Guo , Zheng Li .  (2015) Maximum transport capacity of a network. Physica A: Statistical Mechanics and its Applications 432, 315-320.  Online publication date: 1-Aug-2015. [Crossref]\nJaime Clark , Miguel Kiwi , Felipe Torres , José Rogan , Juan Alejandro Valdivia .  (2015) Generalization of the Ehrenfest urn model to a complex network. Physical Review E 92:1.  Online publication date: 1-Jul-2015. [Crossref]\nDavid Csercsik , Sandor Imre .  (2015) Position guided local routing and reconfiguration in mobile telecommunication networks with scale-free topology. 2015 23rd Mediterranean Conference on Control and Automation (MED), 947-952. [Crossref]\nMiroslav Andjelković , Neelima Gupte , Bosiljka Tadić .  (2015) Hidden geometry of traffic jamming. Physical Review E 91:5.  Online publication date: 1-May-2015. [Crossref]\nKoutarou Tamura , Hideki Takayasu , Misako Takayasu .  (2015) Extraction of conjugate main-stream structures from a complex network flow. Physical Review E 91:4.  Online publication date: 1-Apr-2015. [Crossref]\nKOSMAS KOSMIDIS , MORITZ BEBER , MARC-THORSTEN HÜTT .  (2015) NETWORK HETEROGENEITY AND NODE CAPACITY LEAD TO HETEROGENEOUS SCALING OF FLUCTUATIONS IN RANDOM WALKS ON GRAPHS. Advances in Complex Systems 18:01n02.  Online publication date: 1-Feb-2015. [ Abstract | PDF (770 KB) | PDF Plus (786 KB) ]\n2015. Internet: Topology and Modeling. Fundamentals of Complex Networks, 137-193. [Crossref]\nA. Avena-Koenigsberger , J. Goni , R. Sole , O. Sporns .  (2014) Network morphospace. Journal of The Royal Society Interface 12:103, 20140881-20140881.  Online publication date: 24-Dec-2014. [Crossref]\nXiaoling Nian , Hongguang Fu .  (2014) Efficient routing on two layer degree-coupled networks. Physica A: Statistical Mechanics and its Applications 410, 421-427.  Online publication date: 1-Sep-2014. [Crossref]\nXiaoling Nian , Hongguang Fu .  (2014) Maximization of entropy in a two layer asymmetry-coupled network. 2014 6th International Conference on Computational Aspects of Social Networks, 25-30. [Crossref]\nZhi-Hong Zhu , Jian-Feng Zheng , Zi-You Gao , Hao-Ming Du .  (2014) Properties of volume–capacity ratio in congested complex networks. Physica A: Statistical Mechanics and its Applications 400, 200-206.  Online publication date: 1-Apr-2014. [Crossref]\nSatyam Mukherjee .  (2014) Quantifying individual performance in Cricket — A network analysis of batsmen and bowlers. Physica A: Statistical Mechanics and its Applications 393, 624-637.  Online publication date: 1-Jan-2014. [Crossref]\nZhi-Qiang Zhu , Chuan-Jian Liu , Jian-Liang Wu , Bin Liu .  (2013) The information transmission in community networks. Physica A: Statistical Mechanics and its Applications 392:17, 3827-3832.  Online publication date: 1-Sep-2013. [Crossref]\nVimal Kishore , Abhijeet R. Sonawane , M. S. Santhanam .  (2013) Manipulation of extreme events on scale-free networks. Physical Review E 88:1.  Online publication date: 1-Jul-2013. [Crossref]\nYi Shen .  (2013) An adaptive strategy based on linear prediction of queue length to minimize congestion in Barabási—Albert scale-free networks. Chinese Physics B 22:5, 058902.  Online publication date: 1-May-2013. [Crossref]\nC. N. Angstmann , I. C. Donnelly , B. I. Henry .  (2013) Pattern formation on networks with reactions: A continuous-time random-walk approach. Physical Review E 87:3.  Online publication date: 1-Mar-2013. [Crossref]\nNikolay E. Galich .  (2013) Fractal Networks of Real Worlds of Fluorescing DNA in Complete Set of Chromosomes inside Blood Cells for Medical Diagnostics. Open Journal of Biophysics 03:04, 232-244.  Online publication date: 1-Jan-2013. [Crossref]\nJelena Živkovic , Bosiljka Tadic .  (2013) Nanonetworks: The graph theory framework for modeling nanoscale systems. Mathematics of Quantum Technologies 2:1.  Online publication date: 1-Jan-2013. [Crossref]\nJ.-Q. Dong , Z.-G. Huang , Z. Zhou , L. Huang , Z.-X. Wu , Y. Do , Y.-H. Wang .  (2012) Enhancing transport efficiency by hybrid routing strategy. EPL (Europhysics Letters) 99:2, 20007.  Online publication date: 1-Jul-2012. [Crossref]\nVimal Kishore , M. S. Santhanam , R. E. Amritkar .  (2012) Extreme events and event size fluctuations in biased random walks on networks. Physical Review E 85:5.  Online publication date: 1-May-2012. [Crossref]\nHayafumi Watanabe , Hideki Takayasu , Misako Takayasu .  (2012) Biased diffusion on the Japanese inter-firm trading network: estimation of sales from the network structure. New Journal of Physics 14:4, 043034.  Online publication date: 1-Apr-2012. [Crossref]\nZi-Qi Zhu , Xiao-Ling Jin , Zhi-Long Huang .  (2012) Search for Directed Networks by Different Random Walk Strategies. Chinese Physics Letters 29:3, 038901.  Online publication date: 1-Mar-2012. [Crossref]\nMatheus P. Viana , João L. B. Batista , Luciano da F. Costa .  (2012) Effective number of accessed nodes in complex networks. Physical Review E 85:3.  Online publication date: 1-Mar-2012. [Crossref]\nMing-yang Zhou , Shi-min Cai , Zhong-qian Fu .  (2012) Traffic dynamics in scale-free networks with tunable strength of community structure. Physica A: Statistical Mechanics and its Applications 391:4, 1887-1893.  Online publication date: 1-Feb-2012. [Crossref]\nREGINALD D. SMITH .  (2011) THE DYNAMICS OF INTERNET TRAFFIC: SELF-SIMILARITY, SELF-ORGANIZATION, AND COMPLEX PHENOMENA. Advances in Complex Systems 14:06, 905-949.  Online publication date: 1-Dec-2011. [ Abstract | PDF (854 KB) | PDF Plus (879 KB) ]\nWei Huang , Shengyong Chen .  (2011) Epidemic metapopulation model with traffic routing in scale-free networks. Journal of Statistical Mechanics: Theory and Experiment 2011:12, P12004.  Online publication date: 1-Dec-2011. [Crossref]\nMing Tang , Tao Zhou .  (2011) Efficient routing strategies in scale-free networks with limited bandwidth. Physical Review E 84:2.  Online publication date: 1-Aug-2011. [Crossref]\nVimal Kishore , M. S. Santhanam , R. E. Amritkar .  (2011) Extreme Events on Complex Networks. Physical Review Letters 106:18.  Online publication date: 1-May-2011. [Crossref]\nJ. Scholz , M. Greiner .  (2011) Self-organizing weights for Internet AS-graphs and surprisingly simple routing metrics. EPL (Europhysics Letters) 94:2, 28008.  Online publication date: 1-Apr-2011. [Crossref]\nGonzalo Travieso , Luciando da Fontoura Costa .  (2011) Effective networks for real-time distributed processing. Journal of Systems Science and Complexity 24:1, 39-50.  Online publication date: 1-Feb-2011. [Crossref]\nLucas Antiqueira , Luciano da Fontoura Costa . 2011. Structure-Dynamics Interplay in Directed Complex Networks with Border Effects. Complex Networks, 46-56. [Crossref]\nJ. Giabbanelli Philippe .  (2010) Impact of complex network properties on routing in backbone networks. 2010 IEEE Globecom Workshops, 389-393. [Crossref]\nSandro Meloni , Jesús Gómez-Gardeñes .  (2010) Local empathy provides global minimization of congestion in communication networks. Physical Review E 82:5.  Online publication date: 1-Nov-2010. [Crossref]\nM. Mitrović , G. Paltoglou , B. Tadić .  (2010) Networks and emotion-driven user communities at popular blogs. The European Physical Journal B 77:4, 597-609.  Online publication date: 1-Oct-2010. [Crossref]\nLiu Wei-Kai , Guan Zhi-Hong , Liao Rui-Quan .  (2010) Optimal Capacity Allocation on Heterogeneous Complex Transport Networks. Chinese Physics Letters 27:10, 108902.  Online publication date: 1-Oct-2010. [Crossref]\nJian WANG , Yan-Heng LIU , Cheng ZHANG , Cheng-Yue LI .  (2010) Analyzing and Modeling Cascading Dynamics of Internet. Journal of Software 21:8, 2050-2058.  Online publication date: 20-Sep-2010. [Crossref]\nWei Huang , Tommy W. S. Chow .  (2010) Effective strategy of adding nodes and links for maximizing the traffic capacity of scale-free network. Chaos: An Interdisciplinary Journal of Nonlinear Science 20:3, 033123.  Online publication date: 1-Sep-2010. [Crossref]\nYu-Han Chen , Bing-Hong Wang , Li-Chao Zhao , Changsong Zhou , Tao Zhou .  (2010) Optimal transport on supply-demand networks. Physical Review E 81:6.  Online publication date: 1-Jun-2010. [Crossref]\nWeikai Liu , Zhi-Hong Guan , Ruiquan Liao .  (2010) Optimal resource allocation on heterogeneous complex transport networks. 2010 Chinese Control and Decision Conference, 2985-2988. [Crossref]\nKe Hu , Chaofei Liu , Tao Hu , Yi Tang .  (2010) Enhancing traffic capacity for scale-free networks by the one-way links. Journal of Physics A: Mathematical and Theoretical 43:17, 175101.  Online publication date: 30-Apr-2010. [Crossref]\nMilovan Šuvakov , Bosiljka Tadić .  (2010) Modeling collective charge transport in nanoparticle assemblies. Journal of Physics: Condensed Matter 22:16, 163201.  Online publication date: 28-Apr-2010. [Crossref]\nSatyam Mukherjee , Neelima Gupte , Gautam Mukherjee .  (2010) Statistical characterizers of transport in communication networks. Physical Review E 81:4.  Online publication date: 1-Apr-2010. [Crossref]\nP R Villas Boas , F A Rodrigues , G Travieso , L da F Costa .  (2010) Sensitivity of complex networks measurements. Journal of Statistical Mechanics: Theory and Experiment 2010:03, P03009.  Online publication date: 1-Mar-2010. [Crossref]\nWei Huang , Tommy W S Chow .  (2010) An efficient strategy for enhancing traffic capacity by removing links in scale-free networks. Journal of Statistical Mechanics: Theory and Experiment 2010:01, P01016.  Online publication date: 1-Jan-2010. [Crossref]\nR. Palotai , P. Csermely .  (2009) Network modules help the identification of key transport routes, signaling pathways in cellular and other networks. Annalen der Physik 18:12, 822-829.  Online publication date: 23-Dec-2009. [Crossref]\nB. Tadić , M. Mitrović .  (2009) Jamming and correlation patterns in traffic of information on sparse modular networks. The European Physical Journal B 71:4, 631-640.  Online publication date: 1-Oct-2009. [Crossref]\nMarija Mitrović , Bosiljka Tadić .  (2009) Spectral and dynamical properties in classes of sparse networks with mesoscopic inhomogeneities. Physical Review E 80:2.  Online publication date: 1-Aug-2009. [Crossref]\nMing Tang , Zonghua Liu , Xiaoming Liang , P. M. Hui .  (2009) Self-adjusting routing schemes for time-varying traffic in scale-free networks. Physical Review E 80:2.  Online publication date: 1-Aug-2009. [Crossref]\nDiego Garlaschelli .  (2009) The weighted random graph model. New Journal of Physics 11:7, 073005.  Online publication date: 1-Jul-2009. [Crossref]\nHong-Li Zeng , Yan-Dong Guo , Chen-Ping Zhu , Marija Mitrovic , Bosiljka Tadic .  (2009) Congestion patterns of traffic studied on Nanjing city dual graph. 2009 16th International Conference on Digital Signal Processing, 1-8. [Crossref]\nK. Kim , B. Kahng , D. Kim .  (2009) Jamming transition in traffic flow under the priority queuing protocol. EPL (Europhysics Letters) 86:5, 58002.  Online publication date: 1-Jun-2009. [Crossref]\nSatyam Mukherjee , Neelima Gupte .  (2009) Queue-length synchronization in communication networks. Physical Review E 79:5.  Online publication date: 1-May-2009. [Crossref]\nMao-Bin Hu , Rui Jiang , Yong-Hong Wu , Wen-Xu Wang , Qing-Song Wu .  (2008) Routing on a weighted scale-free network. Physica A: Statistical Mechanics and its Applications 387:19-20, 4967-4972.  Online publication date: 1-Aug-2008. [Crossref]\nBosiljka Tadić , Zoran Levnajić .  (2008) Robust dynamical effects in traffic and chaotic maps on trees. Pramana 70:6, 1099-1108.  Online publication date: 1-Jun-2008. [Crossref]\nJan Scholz , Wolfram Krause , Martin Greiner .  (2008) Decorrelation of networked communication flow via load-dependent routing weights. Physica A: Statistical Mechanics and its Applications 387:12, 2987-3000.  Online publication date: 1-May-2008. [Crossref]\nTao Zhou .  (2008) Mixing navigation on networks. Physica A: Statistical Mechanics and its Applications 387:12, 3025-3032.  Online publication date: 1-May-2008. [Crossref]\n""","0.56027544","""http://www.worldscientific.com/doi/abs/10.1142/S0218127407018452""","[-0.472855,51.532848]"
"""Cranfield_University""","""A neurofuzzy-controlled power management strategy for a series hybrid electric vehicleProceedings of the Institution of Mechanical Engineers, Part D: Journal of Automobile Engineering - Daniel Chindamo, John T Economou, Marco Gadola, Kevin Knowles, 2014""","""Laraminie, J, Lowry, J. Electric vehicle technology explained. New York: John Wiley, 2003. Google Scholar , Crossref\n2.\nChau, KT, Wong, YS. Overview of power management in hybrid electric vehicles. Energy Conversion Managmt2002; 43(15): 1953–1968. Google Scholar , Crossref\n3.\nLee, HD, Sul, SK. Fuzzy-logic-based torque control strategy for parallel-type hybrid electric vehicle. IEEE Trans Ind Electron1998; 45: 625–632. Google Scholar , Crossref\n4.\nKheir, NA, Salman, MA, Schouten, NJ. Emissions and fuel economy trade-off for hybrid vehicles using fuzzy logic. Math Comput Simulations2004; 66: 155–172. Google Scholar , Crossref\n5.\nSchouten, NJ, Salman, MA, Kheir, NA. Energy management strategies for parallel hybrid vehicles using fuzzy logic. Control Engng Practice2003; 11: 171–177. Google Scholar , Crossref\n6.\nAtes, Y, Erdinc, O, Uzunouglu, M, Vural, B. Energy management of an FC/UC hybrid vehicular power system using a combined neural network-wavelet transform based strategy. Int J Hydrogen Energy2010; 35: 774–783. Google Scholar , Crossref\n7.\nHu, X, Murgovski, N, Johannesson, L, Egardt, B. Energy efficiency analysis of a series plug-in hybrid electric bus with different energy management strategies and battery sizes. Appl Energy2013; 111: 1001–1009. Google Scholar , Crossref\n8.\nBanjac, T, Trenc, F, Katrasnik, T. Energy conversion efficiency of hybrid electric heavy-duty vehicles operating according to diverse drive cycles. Energy Conversion Managmt2009; 50: 2865–2878. Google Scholar , Crossref\n9.\nMontazeri, M, Poursamad, A, Ghalichi, B. Application of genetic algorithm for optimization of control strategy in parallel hybrid electric vehicles. J Franklin Inst2006; 343: 420–435. Google Scholar , Crossref\n10.\nSalmasi, F. Control strategies for hybrid vehicles: evolution, classification, comparison and future trends. IEEE Trans Veh Technol56 (2007) 2393–2404. Google Scholar , Crossref\n11.\nPérez, L, Bossio, G, Moitre, D, García, G. Optimization of power management in an hybrid electric vehicle using dynamic programming. Math Comput Simulations2006; 73: 244–254. Google Scholar , Crossref\n12.\nFierro, R, Lewis, FL. Control of nonholonomic mobile robot using neural networks. IEEE Trans Neural Networks1998; 9: 589–600. Google Scholar , Crossref , Medline\n13.\nMamdani, EH. Application of fuzzy algorithms for control of simple dynamic plant. Proc IEEE1974; 121: 1585–1588. Google Scholar\n14.\nJouili, K, Jerbi, H, Braiek, NB. An advanced fuzzy logic gain scheduling trajectory control for nonlinear systems. J Process Control2010; 20: 426–440. Google Scholar , Crossref\n15.\nChindamo, D, Gadola, M, Romano, M. A simulation tool for optimization and performance prediction of a generic hybrid electric series powertrain. Int J Automot Technol2014; 15: 1–10. Google Scholar , Crossref\n16.\nMacVicar-Whelan, PJ. Fuzzy sets for man–machine interaction. Int J Man–Machine Studies1976; 8: 687–697. Google Scholar , Crossref\n17.\nTakagi, T, Sugeno, M. Fuzzy identification of systems and its application to modeling and control. IEEE Trans Systems, Man, Cybernetics1985; 15: 116–132. Google Scholar , Crossref\n18.\nTanaka, K, Sugeno, M. Stability analysis and design of fuzzy control systems. Fuzzy Sets Systems1992; 45: 135–156. Google Scholar , Crossref\n19.\nShepherd, CM. Design of primary and secondary cells – Part 2. An equation describing battery discharge. J Electrochem Soc1965; 112: 657–664. Google Scholar , Crossref\n20.\nTremblay, O, Dessaint, L-A, Dekkiche, A-I. A generic battery model for the dynamic simulation of hybrid electric vehicles. In: 2007 vehicle power and propulsion conference, Arlington, Texas, USA, 9–12 September 2007, pp. 284–289. New York: IEEE. Google Scholar\n21.\nGallardo-Lozano, J, Milanés-Montero, MI, Guerrero Martínez, MA, Romero-Cadaval, E. Electric vehicle battery charger for smart grids. Electric Power Systems Res2012; 90: 18–29. Google Scholar , Crossref\n22.\nLunz, B, Yan, Z, Gerschler, JB, Sauer, DU. Influence of plug-in hybrid electric vehicle charging strategies on charging and battery degradation costs. Energy Policy2012; 46: 511–519. Google Scholar , Crossref\n23.\nSorrentino, M, Rizzo, G, Arise, I. Analysis of a rule-based control strategy for on-board energy management of series hybrid vehicles. Control Engng Practce2011; 19: 1433–1441. Google Scholar , Crossref\n24.\nMusardo, C, Rizzoni, G, Guezzennec, Y, Staccia, B. An adaptive algorithm for hybrid electric vehicle energy management. Eur J Control2005; 11: 509–524. Google Scholar , Crossref\n25.\nKim, N, Cha, S, Peng, H. Optimal control of hybrid electric vehicles based on Pontryagin’s minimum principle. IEEE Trans Control Systems Technol2011; 19: 1279–1287. Google Scholar , Crossref\n26.\nSundstrom, O, Guzzella, L, Soltic, P. Torque-assist hybrid electric powertrain sizing: from optimal control towards a sizing law. IEEE Trans Control Systems Technol2010; 18: 837–849. Google Scholar , Crossref\n27.\nSakawa, M, Kato, K, Ushiro, S, Inaoka, M. Operation planning of district heating and cooling plants using genetic algorithms for mixed integer programming. Appl Soft Comput2001; 1: 139–150. Google Scholar , Crossref\n""","0.5196425","""http://journals.sagepub.com/doi/10.1177/0954407014522777""","[-0.629225,52.074389]"
"""Imperial_College_London""","""A pricing and investment strategy for national roads | Proceedings of the Institution of Civil Engineers - Transport""","""Proceedings of the Institution of Civil Engineers - Transport\nProceedings of the Institution of Civil Engineers - Transport\nISSN 0965-092X | E-ISSN 1751-7710\nA pricing and investment strategy for national roads\nAuthors: \nOBE, CEng, FICE, FIHT, FRTPI, FREng\nx\nPublished Online: May 25, 2015\nKey:\nTrial content\nAbstract\nMain road traffic has doubled in the last quarter-century and its growth continues. During this time the length of the trunk road network has been reduced by almost a fifth and motorway construction has all but halted. Combinations of additional strategic road capacity and national road pricing are examined to explore what mix of these would provide a package of measures which would ease future congestion whilst maintaining adequate levels of mobility. A combination of ‘efficient pricing’—which would replace the existing road taxation regime—and the provision of an additional 600 lane km of strategic road space a year would reduce congestion and carbon emissions whilst providing the mobility needed for a growing and successful economy. The net revenues from pricing would be more than sufficient to pay for the additional capacity and the higher charges to road users would be more than offset by improved strategic road travel conditions.\nKeywords:\n""","0.88529897","""https://www.icevirtuallibrary.com/doi/10.1680/tran.2008.161.3.103""","[-0.178219,51.500505]"
"""Imperial_College_London""","""Inverse discrete choice modelling: theoretical and practical considerations for imputing respondent attributes from the patterns of observed choices: Transportation Planning and Technology: Vol 41, No 1""","""ABSTRACT\nABSTRACT\nThe growing availability of geotagged big data has stimulated substantial discussion regarding their usability in detailed travel behaviour analysis. Whilst providing a large amount of spatio-temporal information about travel behaviour, these data typically lack semantic content characterising travellers and choice alternatives. The inverse discrete choice modelling (IDCM) approach presented in this paper proposes that discrete choice models (DCMs) can be statistically inverted and used to attach additional variables from observations of travel choices. Suitability of the approach for inferring socioeconomic attributes of travellers is explored using mode choice decisions observed in London Travel Demand Survey. Performance of the IDCM is investigated with respect to the type of variable, the explanatory power of the imputed variable, and the type of estimator used. This method is a significant contribution towards establishing the extent to which DCMs can be credibly applied for semantic enrichment of passively collected big data sets while preserving privacy.\n: Wiley. [Crossref]   [Google Scholar] ).\nThe inverse discrete choice modelling (IDCM) approach, proposed by Pawlak, Zolfaghari, and Polak ( 2015 Pawlak, J., A. Zolfaghari, and J. W. Polak. 2015. “Imputing Socioeconomic Attributes for Movement Data by Analysing Patterns of Visited Places and Google Places Database: Bridging between Big Data and Behavioural Analysis.” Austin, TX, 11–13 July.  [Google Scholar] ), and extended in this paper, aims at data enrichment by making use of the extensive body of empirical results developed in the field of discrete choice models (DCMs). DCMs are fundamental transport modelling and policy-making tools which take advantage of the natural prevalence of discrete choices (e.g. mode, route and destination) in transport contexts. They have been used and developed over the past decades, which proves their versatility and robustness. Relying on known behavioural foundations and assumptions firmly grounded in the microeconomic theory (Train and McFadden 1978 Train, Kenneth, and Daniel McFadden. 1978. “The Goods/Leisure Tradeoff and Disaggregate Work Trip Mode Choice Models.” Transportation Research 12 (5): 349–353. doi: 10.1016/0041-1647(78)90011-4 [Crossref]   [Google Scholar] ), DCMs provide a way of linking attributes of individuals and discrete alternatives to specific decisions. We therefore seek to explore this functionality in an inverse way: to enrich data explicitly or implicitly capturing choice behaviours with additional variables characterising individuals.\nSpecifically, IDCM postulates that knowledge of choice sets, choices, and the preference structure captured in the form of a DCM provides a means of inferring attributes of the choice maker or choice alternatives. The probabilistic enrichment which IDCM leads to also has the side benefit of preserving privacy of a particular individual while obtaining the aggregate shares of attributes.\nThe application of IDCM in the context of transport modelling are various. For instance, enriching automatic number plate recognition camera data with travellers’ socioeconomic attributes can enable the ability to advice on the best means of communicating a message to a particular user group, which can further increase the likelihood of more timely reaction and reduce exposure to the impacts of disruptions. As analysing people’s movement using OD matrices, where knowledge of people’s demographics is essential, represents a vital tool for transport policy-making aimed at designing and operating a sustainable and equitable urban transport system, another application can be origin-destination (OD) matrix profiling. Such OD matrix profiling is desirable in cities in emerging countries where fixed monitoring infrastructures of regular data collection mechanisms are not always readily available. Moreover, enrichment of smart card data (e.g. London Oyster card data) can promote revenue generation from more detailed audience segmentation for on-board marketing, for example, advertisements on buses and undergrounds. And understanding of electric vehicle users will help develop more personalised charging services with different preferences revealed in their choice behaviours such as choices of charging durations and positions. The proposed methodology is also applicable in other domains such as humanitarian and disaster operations by enabling the identification of vulnerable individuals such as the elderly (de Montjoye et al. 2013 de Montjoye, Yves-Alexandre, Jordi Quoidbach, Florent Robic, and Alex Pentland. 2013. Predicting Personality Using Novel Mobile Phone-Based Metrics.\nHeidelberg\n: Springer. [Crossref]   [Google Scholar] ).\nIn this paper, the theoretical foundations and consequent properties of the IDCM are systematically explored and formally codified. In addition, we present the first empirical application of the approach which was previously only used in a simulation study. Finally, the present contribution introduces the concept of mutual information (MI) and hence formalises the notion of explanatory power (EP) of a variable which lies at the heart of the IDCM performance.\nThis paper is structured as follows. Section 2 defines specific terms to facilitate understanding of the approach in the wider context of enrichment methods. Section 3 reviews the literature on existing data enrichment approaches and discusses solutions to inverse problems (IPs) in reference to IDCM. Section 4 formalises the IDCM using microeconomic and econometric foundations, develops research hypotheses based on previous studies, and introduces validation methods. Section 5 presents details about the enrichment exercise design using empirical data set and the IDCM, followed by discussing the findings in Section 6. Section 7 concludes the paper and provides suggestions for future research avenues.\n2.  Definition of terms\nIn order to facilitate understanding of this study, Section 2 provides the definition of several specific terms used in this paper.\nGeotagged data: Geotagging, or georeferencing, involves the process of adding geographical identification metadata to data otherwise containing no information about spatial meanings (Hill 2009 Hill, Linda L. 2009. Georeferencing: The Geographic Associations of Information.\nCambridge\n,\nMA\n: MIT Press. [Crossref]   [Google Scholar] ), such as geographical coordinates, or other identifiers of a specific location, for example, name of the place, ordnance survey grid reference or postcode. Increasingly, geotagging is done passively through built-in location technologies including satellite navigation and mobile network triangulation. In the context of travel behavioural analysis, a series of geotagged data collected from a particular respondent can be used to re-construct individual movement pattern, also called a ‘trajectory’ (Giannotti et al. 2007 Giannotti, Fosca, Mirco Nanni, Fabio Pinelli, and Dino Pedreschi. 2007. “Trajectory Pattern Mining.” ACM.  [Google Scholar] ), which can be further used to analyse corresponding activity patterns. The methods discussed in this paper are particularly aimed at geotagged data that arise as a by-product of the functioning of operational systems (e.g. public transport payment systems, navigation and fleet management systems) although geotagged data are also relevant to data collected as part of a deliberated research design.\nData semantics: The semantic content of data refers to the variables which characterise these data points, thus providing the meaning and describing use of the data (Wood 1985 Wood, J. 1985. “What’s in a Link?” Readings in Knowledge Representation. Morgan Kaufmann.  [Google Scholar] ). Data semantics can therefore be viewed as a mapping between the information stored in the data and the real-world objects they represent (Sheth 1997 Sheth, Amit. 1997. “Panel: Data Semantics: What, Where and How?” In Database Applications Semantics, 601–610.\nCopenhagen\n: Springer. [Crossref]   [Google Scholar] ), reflecting the extent to which the data have been interpreted, that is, the meaning implicitly or explicitly represented by the data (Smith 1990 Smith, Gary W. 1990. Modeling Security-Relevant Data Semantics.\nOakland\n,\nCA\n: IEEE. [Crossref]   [Google Scholar] ). By ‘low semantics’ or ‘of low semantic content’, we refer to data that contain very few variables characterising the data points themselves.\nSemantic enrichment: Semantic enrichment involves the process of increasing semantic content of particular data. ‘Enrichment’ means adding supplementary information to the original data set by using other sources of information, for example, other databases or pattern recognition rules.\nImputation: Imputation originates from statistics where it represents the process of replacing missing data with substituted values (Rubin 2004 Rubin, Donald B. 2004. Multiple Imputation for Nonresponse in Surveys. Vol. 81.\nNew York\n: Wiley.  [Google Scholar] ) derived from either external information sources or statistical modelling procedure. Broadly speaking, imputation serves as a mechanism for semantic enrichment. It is important because missing data can introduce a substantial amount of bias in data analysis. Imputation can occur at a level of the whole data point (unit imputation) or a particular component of it (item imputation). In the present analysis, we aim to enrich observed respondents’ choice data with a set of socioeconomic which can be classified as a form of ‘item imputation’.\n3.  Literature review\nThe literature review below consists of two parts: Section 3.1 discusses existing approaches to data semantics enrichment, while Section 3.2 scopes the wider domain of IPs which IDCM draws upon.\n3.1.  Enrichment of data semantics\nFollow-up surveys, for example, questionnaires or diaries, are the most obvious ways of enriching geotagged transport big data sources. They are applicable only to cases where the respondents can be approached. In most instances, however, follow-up survey approaches are not feasible, for example, on the grounds of costs and burden of additional data collection, due to privacy regulations, or simply because the original data set was collected so long ago that detailed recollection of particular behaviour would be dubious. Therefore, a number of alternative approaches seeking to enrich the original data without the need for follow-up contact with original respondents have emerged.\nThese approaches were developed based on the availability of mature movement map-matching and trajectory decomposition techniques. For instance, Lou et al. ( 2009 Lou, Yin, Chengyang Zhang, Yu Zheng, Xing Xie, Wei Wang, and Yan Huang. 2009. “Map-Matching for Low-Sampling-Rate GPS Trajectories”. ACM.  [Google Scholar] ) proposed global map-matching algorithm ST-Matching for low-sampling-rate GPS trajectories, that is, GPS data points collected between relatively long intervals. Dodge, Weibel, and Forootan ( 2009 Dodge, Somayeh, Robert Weibel, and Ehsan Forootan. 2009. “Revealing the Physics of Movement: Comparing the Similarity of Movement Characteristics of Different Types of Moving Objects.” Computers, Environment and Urban Systems 33 (6): 419–434. doi: 10.1016/j.compenvurbsys.2009.07.008 [Crossref] , [Web of Science ®]   [Google Scholar] ) suggested a segmentation and feature extraction method that can classify trajectory data of unknown moving objects and assign to known moving objects with learned movement characteristics. With the availability of the aforementioned techniques, the semantics of travel behaviour data sets have been significantly enriched by imputing, for example, modes of transport, trip destinations and purposes, or activity types.\nEarly activity recognition studies relied on rather limiting assumptions where either types of places or routes between places were eliminated from analyses (Bennewitz et al. 2005 Bennewitz, Maren, Wolfram Burgard, Grzegorz Cielniak, and Sebastian Thrun. 2005. “Learning Motion Patterns of People for Compliant Robot Motion.” The International Journal of Robotics Research 24 (1): 31–48. doi: 10.1177/0278364904048962 [Crossref] , [Web of Science ®]   [Google Scholar] ), which has inevitably constrained the scope of studies. Giannotti et al. ( 2007 Giannotti, Fosca, Mirco Nanni, Fabio Pinelli, and Dino Pedreschi. 2007. “Trajectory Pattern Mining.” ACM.  [Google Scholar] ), therefore, documented ‘trajectory pattern’ that characterises a collection of independent routes sharing the same sequences of visited places with similar travel times. This has enabled consistent description of frequent travel behaviours.\nResearchers are also interested in spatial occurrences of certain movement attributes such as tourism attraction visits. For example, Ester et al. ( 1996 Ester, Martin, Hans-Peter Kriegel, Jörg Sander, and Xiaowei Xu. 1996. A Density-based Algorithm for Discovering Clusters in Large Spatial Databases with Noise.  [Google Scholar] ) presented Density-based Spatial Clustering of Applications with Noise to classify large spatial databases. Based on this study, Andrienko et al. ( 2011 Andrienko, Gennady, Natalia Andrienko, Christophe Hurter, Salvatore Rinzivillo, and Stefan Wrobel. 2011. From Movement Tracks Through Events to Places: Extracting and Characterizing Significant Places from Mobility Data.\nProvidence, RI\n: IEEE.  [Google Scholar] ) suggested a visual analytics procedure that determined places of interest based on time-varying characteristics of movements. Montoliu, Blom, and Gatica-Perez ( 2013 Montoliu, Raul, Jan Blom, and Daniel Gatica-Perez. 2013. “Discovering Places of Interest in Everyday Life from Smartphone Data.” Multimedia Tools and Applications 62 (1): 179–207. doi: 10.1007/s11042-011-0982-z [Crossref] , [Web of Science ®]   [Google Scholar] ) proposed a framework that combined time-based and grid-based clustering techniques to discover places-of-interest from mobile phone data collected through multiple sources.\nRegarding the detection of transport modes, the most common approach seeks to infer mode based on average and maximum speeds, derived from the underlying positioning data (Gong et al. 2014 Gong, Lei, Takayuki Morikawa, Toshiyuki Yamamoto, and Hitomi Sato. 2014. “Deriving Personal Trip Data from GPS Data: A Literature Review on the Existing Methodologies.” Procedia-Social and Behavioral Sciences 138: 557–565. doi: 10.1016/j.sbspro.2014.07.239 [Crossref]   [Google Scholar] ). Additional information, like GIS land-use data, has been incorporated to increase detection accuracy (Chung and Shalaby 2005 Chung, Eui-Hwan, and Amer Shalaby. 2005. “A Trip Reconstruction Tool for GPS-Based Personal Travel Surveys.” Transportation Planning and Technology 28 (5): 381–401. doi: 10.1080/03081060500322599 [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ; Stopher, FitzGerald, and Zhang 2008 Stopher, Peter, Camden FitzGerald, and Jun Zhang. 2008. “Search for a Global Positioning System Device to Measure Person Travel.” Transportation Research Part C: Emerging Technologies 16 (3): 350–369. doi: 10.1016/j.trc.2007.10.002 [Crossref] , [Web of Science ®]   [Google Scholar] ). Nevertheless, a recent study (Brunauer et al. 2013 Brunauer, Richard, Michael Hufnagl, Karl Rehrl, and Andreas Wagner. 2013. Motion Pattern Analysis Enabling Accurate Travel Mode Detection from Gps Data Only.\nThe Hague\n: IEEE. [Crossref]   [Google Scholar] ) suggested a GPS-only travel mode detection approach using feed forward multilayer perceptrons that extracted and analysed distinct motion patterns of different modes, for example, acceleration and horizontal angular speed.\nIn terms of trip purpose identification, detailed GIS land-use data is often used in the development of relevant enrichment procedures. Wolf, Guensler, and Bachman ( 2001 Wolf, J., R. Guensler, and W. Bachman. 2001. Elimination of the Travel Diary: An Experiment to Derive Trip Purpose from GPS Travel Data.\nWashington\n,\nND\n: Morgan Kaufmann.  [Google Scholar] ). Particle swarm optimisation (PSO) (Eberhart and Kennedy 1995 Eberhart, Russ C., and James Kennedy. 1995. A New Optimizer using Particle Swarm Theory.\nNagoya\n: IEEE. [Crossref]   [Google Scholar] ) is a relatively recent heuristic search method based on collaborative behaviour of birds and fishes. Although both GA and PSO are population-based search processes relying on information sharing among population members with deterministic and probabilistic rules (Hassan et al. 2005 Hassan, Rania, Babak Cohanim, Olivier De Weck, and Gerhard Venter. 2005. “A Comparison of Particle Swarm Optimization and the Genetic Algorithm”.  [Google Scholar] ), PSO is more computationally inexpensive.\nAnother rapidly developing set of approaches involve random and pseudo-random exploration, that is, so-called Monte Carlo (MC) approaches (Hammersley 2013 Hammersley, John. 2013. Monte Carlo Methods.\nNew York\n: Springer Science & Business Media.  [Google Scholar] ). In the applied contexts, the MC process was found superior to gradient-descent and random search methods (Keilis-Borok and Yanovskaja 1967 Keilis-Borok, V. I., and T. B. Yanovskaja. 1967. “Inverse Problems of Seismology (Structural Review).” Geophysical Journal International 13 (1–3): 223–234. doi: 10.1111/j.1365-246X.1967.tb02156.x [Crossref] , [Web of Science ®]   [Google Scholar] ). Markov chain Monte Carlo is a powerful simulation technique for performing integration (Gilks 2005 Gilks, Walter R. 2005. Markov Chain Monte Carlo. Wiley Online Library. [Crossref]   [Google Scholar] ) that has revolutionised the application of Bayesian methods in IPs. For instance, Bui-Thanh and Girolami ( 2014 Bui-Thanh, Tan, and Mark Girolami. 2014. “Solving Large-Scale PDE-Constrained Bayesian Inverse Problems with Riemann Manifold Hamiltonian Monte Carlo.” Inverse Problems 30 (11): 114014. doi: 10.1088/0266-5611/30/11/114014 [Crossref] , [Web of Science ®]   [Google Scholar] ) implemented it to solve heat conduction IPs.\nOverall, there clearly exists a plethora of potential approaches to solving IPs, and exploration of their applicability in IDCM appears a warranted avenue of research which the current study is contributing to.\n4.  Methodology\nSection 4 outlines the IDCM approach in detail. Specifically, Section 4.1 introduces two estimators and contexts that they fit in. Section 4.2 provides the theoretical foundations, derivation and mathematical expression of IDCM. Section 4.3 presents the hypothesis development for evaluating the proposed method while Section 4.4 discusses validation methods of the IDCM performance.\n4.1.  Estimation methods\nIn current contribution, two estimators corresponding to two statistical estimation approaches are used to solve the proposed IDCM. These two approaches are maximum likelihood estimation (MLE) and maximum a posteriori (MAP) estimation.\nIn statistics, a likelihood function\nrepresents the probability for the occurrence of an independent and identically distributed sample configuration\ngiven the probability density\nwith known parameters\n(Harris and Stöcker 1998 Harris, John W., and Horst Stöcker. 1998. Handbook of Mathematics and Computational Science.\nNew York\n.\n5.  Application of IDCM to imputation from the London travel demand survey\nSection 5 demonstrates an application of the IDCM approach to imputing socioeconomic attributes of travellers from real-world observations of their travel mode choices. By removing respondent attribute data, the London Travel Demand Survey (LTDS) is used to mimic geotagged trace data in the imputation procedure. These attribute data, conversely, can act as a comparison to validate the imputation quality.\nParticularly, Section 5.1 introduces LTDS and how it is pre-processed to fit the scope of the analysis. Section 5.2 presents the procedure of calibrating the DCM of mode choice. Section 5.3 shows how the experiments of imputation are designed and conducted. The flow chart in Figure 2 illustrates the overall process of these experiments.\nInverse discrete choice modelling: theoretical and practical considerations for imputing respondent attributes from the patterns of observed choices\nAll authors\nCSV Display Table\nIn the MLE approach as defined in Equation (12), it is assumed that no prior knowledge on the parameters is available, that is, equal probabilities occur in all categories of either socioeconomic attributes or mode choices. Hence, the joint log-likelihood that should be maximised to find the MLE estimates is defined as the summation of the logarithms of the probabilities of all trips undertaken by the individual. For a sample consisting of\nrespondents independent of each other, it is equivalent to Equation (20):\n(20)\nIn terms of the MAP approach, the MAP estimator of the attribute to be imputed has been defined on the basis of Equations (8) and (12), leading to the expression in Equation (21):\n(21)\nThe prior\ncan be derived from corresponding estimation subsample. The process is achieved using exhaustive search over the given parameter space which is computationally manageable due to the independence between respondents, and finite thanks to the discrete nature of imputed variables. This furthermore guarantees the solution to be the global optimum.\n6.  Results\nSection 6 discusses findings from the four series of imputation experiments over 10 repetitions performed on the 20% imputation subsamples as outlined in Section 5.3. PCPs of each imputed variable of all holdout samples based on MLE and MAP estimates are presented in Figure 3 .\nInverse discrete choice modelling: theoretical and practical considerations for imputing respondent attributes from the patterns of observed choices\nAll authors\nDisplay full size\nFigure 3. Comparison of PCPs using MLE and MAP estimators.\nWe are also interested in the shares of individuals characterised by specific attributes in imputed and observed samples by conducting sample enumeration, which is a standard technique used frequently in investigating performance of DCMs (de Dios Ortúzar and Willumsen 1994 de Dios Ortúzar, Juan, and Luis G. Willumsen. 1994. Modelling Transport.\nHoboken\n,\nNJ\n: Wiley.  [Google Scholar] ). Due to large sample sizes, chi-squared test is used to validate the approach on aggregate level. And Table 3 shows the p-values of chi-squared test based on the two estimators.\nInverse discrete choice modelling: theoretical and practical considerations for imputing respondent attributes from the patterns of observed choices\nAll authors\nCSV Display Table\nIt can be seen from Figure 3 and Table 3 that the PCP and the chi-squared test statistics of each imputed variable using same estimators are stable across randomly selected subsamples, which provides a reasonable premise for the following analyses.\nFigure 3 shows that the MAP estimator generally performs no worse than its MLE counterpart on the individual level as it improves PCPs of the MLE-based imputation. Particularly in the first graph, performance of the MAP estimator almost equals to that of the MLE estimator. This is probably due to the equal distribution across genders, which have led to similar information of the uniform prior distribution of the MLE estimator. It is also noticed that the IDCM model is generally better at predicting nominal attributes than ordinal attributes. This is reasonably understandable as ordinal attributes (e.g. income) consist of more categories and therefore more input information is required for more accurate prediction. Moreover, ordinal attributes are imputed using the average value of each category for simplification, which introduce extra noise that reduces the prediction accuracy.\nThe results of chi-squared test in Table 3 demonstrate that the MAP also significantly improves the imputation quality on the overall sample level. This is indicated by all p-values over .05, showing that imputed samples do not differ from corresponding observed sample at a 95% confidence level. This is intuitive in the sense that MAP estimators usually involve more relevant information than MLE estimators.\nThe findings above are also related to the hypothesis developed in Section 4.3. Rather than\n, we calculate MIs (in bits) between travel modes and each attribute of all folds so as to explore the relationship between the EP and imputation quality of IDCM. Results are presented in Figure 4 .\nInverse discrete choice modelling: theoretical and practical considerations for imputing respondent attributes from the patterns of observed choices\nAll authors\nDisplay full size\nFigure 4. Correlation pattern between MI and PCPs.\nAs is seen in Figure 4 , the nominal variables show a pattern that higher PCP is produced by higher EP. This is in line with the results of the MC experiments by Pawlak, Zolfaghari, and Polak ( 2015 Pawlak, J., A. Zolfaghari, and J. W. Polak. 2015. “Imputing Socioeconomic Attributes for Movement Data by Analysing Patterns of Visited Places and Google Places Database: Bridging between Big Data and Behavioural Analysis.” Austin, TX, 11–13 July.  [Google Scholar] ). In particular, the relationship shows diminishing marginal improvement in PCP as the MI grows, which seems to be logarithmic or square root.\nThe ordinal variable, however, does not follow the trend of nominal variables. There are two potential explanations for this phenomenon. First, the income attribute can have three or more different values, as opposed to two in the nominal variables above, which increase the complexity of imputing the exact value of the variable from same amount of input information, that is, single discrete choice. Moreover, income is discretised and grouped into three levels with the average value of each level used in the IDCM imputation, hence reducing the MI with the choice. The exact reason will be explored in the future. It should be noted that we do not discuss the correlation between MI and PCPs using the MAP. This is because the amount of information contained in MAP-based PCPs has to some extent been ‘polluted’ by the prior information.\n7.  Conclusions\nThis paper formalises and extends a data enrichment approach which uses IDCM to infer socioeconomic characteristics of travel decision-makers from observations of discrete travel choices. Performance of the IDCM applied to a mode choice model based on real-world data set is explored. The empirical results are compared to that from the earlier MC experiment which employs the same inversion mechanisms.\nIt is observed that performance of the IDCM is highly sensitive to the EP of the imputed variable, measured by MI between the variable and discrete choices, in corresponding DCM. Specifically, performance of imputing the same type of variables using the proposed method is improved as the EP increases. Moreover, the nature of the imputed variable also plays a significant role. Particularly, attributes with numerical meanings or having more than two potential values, such as ordinal variables, can be more difficult to impute than nominal variables and two-category categorical variables. The exact reason for this will be investigated in the future.\nThis study can be viewed as an important step towards bridging the gap between travel behaviour analysis and data collected by ICT devices. The substantial benefit of using the increasingly available geotagged data to substitute traditional surveys while preserving individual privacy provide sufficient rationale to continue developing such enrichment approaches. For further investigation, MC experiment will be expanded to explore the role of DCM structures and EP of variables in determining imputation quality. It is hoped that this avenue will lead to new theoretical and empirical insights enabling more effective and robust enrichment procedures.\nDisclosure statement\nNo potential conflict of interest was reported by the authors.\nTable 1.  MNL model estimation results.\nAttribute coefficients\n""","0.22319865","""http://www.tandfonline.com/doi/full/10.1080/03081060.2018.1402745""","[-0.178219,51.500505]"
"""Imperial_College_London""","""Inverse discrete choice modelling: theoretical and practical considerations for imputing respondent attributes from the patterns of observed choices: Transportation Planning and Technology: Vol 41, No 1""","""ABSTRACT\nABSTRACT\nThe growing availability of geotagged big data has stimulated substantial discussion regarding their usability in detailed travel behaviour analysis. Whilst providing a large amount of spatio-temporal information about travel behaviour, these data typically lack semantic content characterising travellers and choice alternatives. The inverse discrete choice modelling (IDCM) approach presented in this paper proposes that discrete choice models (DCMs) can be statistically inverted and used to attach additional variables from observations of travel choices. Suitability of the approach for inferring socioeconomic attributes of travellers is explored using mode choice decisions observed in London Travel Demand Survey. Performance of the IDCM is investigated with respect to the type of variable, the explanatory power of the imputed variable, and the type of estimator used. This method is a significant contribution towards establishing the extent to which DCMs can be credibly applied for semantic enrichment of passively collected big data sets while preserving privacy.\n: Wiley. [Crossref]   [Google Scholar] ).\nThe inverse discrete choice modelling (IDCM) approach, proposed by Pawlak, Zolfaghari, and Polak ( 2015 Pawlak, J., A. Zolfaghari, and J. W. Polak. 2015. “Imputing Socioeconomic Attributes for Movement Data by Analysing Patterns of Visited Places and Google Places Database: Bridging between Big Data and Behavioural Analysis.” Austin, TX, 11–13 July.  [Google Scholar] ), and extended in this paper, aims at data enrichment by making use of the extensive body of empirical results developed in the field of discrete choice models (DCMs). DCMs are fundamental transport modelling and policy-making tools which take advantage of the natural prevalence of discrete choices (e.g. mode, route and destination) in transport contexts. They have been used and developed over the past decades, which proves their versatility and robustness. Relying on known behavioural foundations and assumptions firmly grounded in the microeconomic theory (Train and McFadden 1978 Train, Kenneth, and Daniel McFadden. 1978. “The Goods/Leisure Tradeoff and Disaggregate Work Trip Mode Choice Models.” Transportation Research 12 (5): 349–353. doi: 10.1016/0041-1647(78)90011-4 [Crossref]   [Google Scholar] ), DCMs provide a way of linking attributes of individuals and discrete alternatives to specific decisions. We therefore seek to explore this functionality in an inverse way: to enrich data explicitly or implicitly capturing choice behaviours with additional variables characterising individuals.\nSpecifically, IDCM postulates that knowledge of choice sets, choices, and the preference structure captured in the form of a DCM provides a means of inferring attributes of the choice maker or choice alternatives. The probabilistic enrichment which IDCM leads to also has the side benefit of preserving privacy of a particular individual while obtaining the aggregate shares of attributes.\nThe application of IDCM in the context of transport modelling are various. For instance, enriching automatic number plate recognition camera data with travellers’ socioeconomic attributes can enable the ability to advice on the best means of communicating a message to a particular user group, which can further increase the likelihood of more timely reaction and reduce exposure to the impacts of disruptions. As analysing people’s movement using OD matrices, where knowledge of people’s demographics is essential, represents a vital tool for transport policy-making aimed at designing and operating a sustainable and equitable urban transport system, another application can be origin-destination (OD) matrix profiling. Such OD matrix profiling is desirable in cities in emerging countries where fixed monitoring infrastructures of regular data collection mechanisms are not always readily available. Moreover, enrichment of smart card data (e.g. London Oyster card data) can promote revenue generation from more detailed audience segmentation for on-board marketing, for example, advertisements on buses and undergrounds. And understanding of electric vehicle users will help develop more personalised charging services with different preferences revealed in their choice behaviours such as choices of charging durations and positions. The proposed methodology is also applicable in other domains such as humanitarian and disaster operations by enabling the identification of vulnerable individuals such as the elderly (de Montjoye et al. 2013 de Montjoye, Yves-Alexandre, Jordi Quoidbach, Florent Robic, and Alex Pentland. 2013. Predicting Personality Using Novel Mobile Phone-Based Metrics.\nHeidelberg\n: Springer. [Crossref]   [Google Scholar] ).\nIn this paper, the theoretical foundations and consequent properties of the IDCM are systematically explored and formally codified. In addition, we present the first empirical application of the approach which was previously only used in a simulation study. Finally, the present contribution introduces the concept of mutual information (MI) and hence formalises the notion of explanatory power (EP) of a variable which lies at the heart of the IDCM performance.\nThis paper is structured as follows. Section 2 defines specific terms to facilitate understanding of the approach in the wider context of enrichment methods. Section 3 reviews the literature on existing data enrichment approaches and discusses solutions to inverse problems (IPs) in reference to IDCM. Section 4 formalises the IDCM using microeconomic and econometric foundations, develops research hypotheses based on previous studies, and introduces validation methods. Section 5 presents details about the enrichment exercise design using empirical data set and the IDCM, followed by discussing the findings in Section 6. Section 7 concludes the paper and provides suggestions for future research avenues.\n2.  Definition of terms\nIn order to facilitate understanding of this study, Section 2 provides the definition of several specific terms used in this paper.\nGeotagged data: Geotagging, or georeferencing, involves the process of adding geographical identification metadata to data otherwise containing no information about spatial meanings (Hill 2009 Hill, Linda L. 2009. Georeferencing: The Geographic Associations of Information.\nCambridge\n,\nMA\n: MIT Press. [Crossref]   [Google Scholar] ), such as geographical coordinates, or other identifiers of a specific location, for example, name of the place, ordnance survey grid reference or postcode. Increasingly, geotagging is done passively through built-in location technologies including satellite navigation and mobile network triangulation. In the context of travel behavioural analysis, a series of geotagged data collected from a particular respondent can be used to re-construct individual movement pattern, also called a ‘trajectory’ (Giannotti et al. 2007 Giannotti, Fosca, Mirco Nanni, Fabio Pinelli, and Dino Pedreschi. 2007. “Trajectory Pattern Mining.” ACM.  [Google Scholar] ), which can be further used to analyse corresponding activity patterns. The methods discussed in this paper are particularly aimed at geotagged data that arise as a by-product of the functioning of operational systems (e.g. public transport payment systems, navigation and fleet management systems) although geotagged data are also relevant to data collected as part of a deliberated research design.\nData semantics: The semantic content of data refers to the variables which characterise these data points, thus providing the meaning and describing use of the data (Wood 1985 Wood, J. 1985. “What’s in a Link?” Readings in Knowledge Representation. Morgan Kaufmann.  [Google Scholar] ). Data semantics can therefore be viewed as a mapping between the information stored in the data and the real-world objects they represent (Sheth 1997 Sheth, Amit. 1997. “Panel: Data Semantics: What, Where and How?” In Database Applications Semantics, 601–610.\nCopenhagen\n: Springer. [Crossref]   [Google Scholar] ), reflecting the extent to which the data have been interpreted, that is, the meaning implicitly or explicitly represented by the data (Smith 1990 Smith, Gary W. 1990. Modeling Security-Relevant Data Semantics.\nOakland\n,\nCA\n: IEEE. [Crossref]   [Google Scholar] ). By ‘low semantics’ or ‘of low semantic content’, we refer to data that contain very few variables characterising the data points themselves.\nSemantic enrichment: Semantic enrichment involves the process of increasing semantic content of particular data. ‘Enrichment’ means adding supplementary information to the original data set by using other sources of information, for example, other databases or pattern recognition rules.\nImputation: Imputation originates from statistics where it represents the process of replacing missing data with substituted values (Rubin 2004 Rubin, Donald B. 2004. Multiple Imputation for Nonresponse in Surveys. Vol. 81.\nNew York\n: Wiley.  [Google Scholar] ) derived from either external information sources or statistical modelling procedure. Broadly speaking, imputation serves as a mechanism for semantic enrichment. It is important because missing data can introduce a substantial amount of bias in data analysis. Imputation can occur at a level of the whole data point (unit imputation) or a particular component of it (item imputation). In the present analysis, we aim to enrich observed respondents’ choice data with a set of socioeconomic which can be classified as a form of ‘item imputation’.\n3.  Literature review\nThe literature review below consists of two parts: Section 3.1 discusses existing approaches to data semantics enrichment, while Section 3.2 scopes the wider domain of IPs which IDCM draws upon.\n3.1.  Enrichment of data semantics\nFollow-up surveys, for example, questionnaires or diaries, are the most obvious ways of enriching geotagged transport big data sources. They are applicable only to cases where the respondents can be approached. In most instances, however, follow-up survey approaches are not feasible, for example, on the grounds of costs and burden of additional data collection, due to privacy regulations, or simply because the original data set was collected so long ago that detailed recollection of particular behaviour would be dubious. Therefore, a number of alternative approaches seeking to enrich the original data without the need for follow-up contact with original respondents have emerged.\nThese approaches were developed based on the availability of mature movement map-matching and trajectory decomposition techniques. For instance, Lou et al. ( 2009 Lou, Yin, Chengyang Zhang, Yu Zheng, Xing Xie, Wei Wang, and Yan Huang. 2009. “Map-Matching for Low-Sampling-Rate GPS Trajectories”. ACM.  [Google Scholar] ) proposed global map-matching algorithm ST-Matching for low-sampling-rate GPS trajectories, that is, GPS data points collected between relatively long intervals. Dodge, Weibel, and Forootan ( 2009 Dodge, Somayeh, Robert Weibel, and Ehsan Forootan. 2009. “Revealing the Physics of Movement: Comparing the Similarity of Movement Characteristics of Different Types of Moving Objects.” Computers, Environment and Urban Systems 33 (6): 419–434. doi: 10.1016/j.compenvurbsys.2009.07.008 [Crossref] , [Web of Science ®]   [Google Scholar] ) suggested a segmentation and feature extraction method that can classify trajectory data of unknown moving objects and assign to known moving objects with learned movement characteristics. With the availability of the aforementioned techniques, the semantics of travel behaviour data sets have been significantly enriched by imputing, for example, modes of transport, trip destinations and purposes, or activity types.\nEarly activity recognition studies relied on rather limiting assumptions where either types of places or routes between places were eliminated from analyses (Bennewitz et al. 2005 Bennewitz, Maren, Wolfram Burgard, Grzegorz Cielniak, and Sebastian Thrun. 2005. “Learning Motion Patterns of People for Compliant Robot Motion.” The International Journal of Robotics Research 24 (1): 31–48. doi: 10.1177/0278364904048962 [Crossref] , [Web of Science ®]   [Google Scholar] ), which has inevitably constrained the scope of studies. Giannotti et al. ( 2007 Giannotti, Fosca, Mirco Nanni, Fabio Pinelli, and Dino Pedreschi. 2007. “Trajectory Pattern Mining.” ACM.  [Google Scholar] ), therefore, documented ‘trajectory pattern’ that characterises a collection of independent routes sharing the same sequences of visited places with similar travel times. This has enabled consistent description of frequent travel behaviours.\nResearchers are also interested in spatial occurrences of certain movement attributes such as tourism attraction visits. For example, Ester et al. ( 1996 Ester, Martin, Hans-Peter Kriegel, Jörg Sander, and Xiaowei Xu. 1996. A Density-based Algorithm for Discovering Clusters in Large Spatial Databases with Noise.  [Google Scholar] ) presented Density-based Spatial Clustering of Applications with Noise to classify large spatial databases. Based on this study, Andrienko et al. ( 2011 Andrienko, Gennady, Natalia Andrienko, Christophe Hurter, Salvatore Rinzivillo, and Stefan Wrobel. 2011. From Movement Tracks Through Events to Places: Extracting and Characterizing Significant Places from Mobility Data.\nProvidence, RI\n: IEEE.  [Google Scholar] ) suggested a visual analytics procedure that determined places of interest based on time-varying characteristics of movements. Montoliu, Blom, and Gatica-Perez ( 2013 Montoliu, Raul, Jan Blom, and Daniel Gatica-Perez. 2013. “Discovering Places of Interest in Everyday Life from Smartphone Data.” Multimedia Tools and Applications 62 (1): 179–207. doi: 10.1007/s11042-011-0982-z [Crossref] , [Web of Science ®]   [Google Scholar] ) proposed a framework that combined time-based and grid-based clustering techniques to discover places-of-interest from mobile phone data collected through multiple sources.\nRegarding the detection of transport modes, the most common approach seeks to infer mode based on average and maximum speeds, derived from the underlying positioning data (Gong et al. 2014 Gong, Lei, Takayuki Morikawa, Toshiyuki Yamamoto, and Hitomi Sato. 2014. “Deriving Personal Trip Data from GPS Data: A Literature Review on the Existing Methodologies.” Procedia-Social and Behavioral Sciences 138: 557–565. doi: 10.1016/j.sbspro.2014.07.239 [Crossref]   [Google Scholar] ). Additional information, like GIS land-use data, has been incorporated to increase detection accuracy (Chung and Shalaby 2005 Chung, Eui-Hwan, and Amer Shalaby. 2005. “A Trip Reconstruction Tool for GPS-Based Personal Travel Surveys.” Transportation Planning and Technology 28 (5): 381–401. doi: 10.1080/03081060500322599 [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ; Stopher, FitzGerald, and Zhang 2008 Stopher, Peter, Camden FitzGerald, and Jun Zhang. 2008. “Search for a Global Positioning System Device to Measure Person Travel.” Transportation Research Part C: Emerging Technologies 16 (3): 350–369. doi: 10.1016/j.trc.2007.10.002 [Crossref] , [Web of Science ®]   [Google Scholar] ). Nevertheless, a recent study (Brunauer et al. 2013 Brunauer, Richard, Michael Hufnagl, Karl Rehrl, and Andreas Wagner. 2013. Motion Pattern Analysis Enabling Accurate Travel Mode Detection from Gps Data Only.\nThe Hague\n: IEEE. [Crossref]   [Google Scholar] ) suggested a GPS-only travel mode detection approach using feed forward multilayer perceptrons that extracted and analysed distinct motion patterns of different modes, for example, acceleration and horizontal angular speed.\nIn terms of trip purpose identification, detailed GIS land-use data is often used in the development of relevant enrichment procedures. Wolf, Guensler, and Bachman ( 2001 Wolf, J., R. Guensler, and W. Bachman. 2001. Elimination of the Travel Diary: An Experiment to Derive Trip Purpose from GPS Travel Data.\nWashington\n,\nND\n: Morgan Kaufmann.  [Google Scholar] ). Particle swarm optimisation (PSO) (Eberhart and Kennedy 1995 Eberhart, Russ C., and James Kennedy. 1995. A New Optimizer using Particle Swarm Theory.\nNagoya\n: IEEE. [Crossref]   [Google Scholar] ) is a relatively recent heuristic search method based on collaborative behaviour of birds and fishes. Although both GA and PSO are population-based search processes relying on information sharing among population members with deterministic and probabilistic rules (Hassan et al. 2005 Hassan, Rania, Babak Cohanim, Olivier De Weck, and Gerhard Venter. 2005. “A Comparison of Particle Swarm Optimization and the Genetic Algorithm”.  [Google Scholar] ), PSO is more computationally inexpensive.\nAnother rapidly developing set of approaches involve random and pseudo-random exploration, that is, so-called Monte Carlo (MC) approaches (Hammersley 2013 Hammersley, John. 2013. Monte Carlo Methods.\nNew York\n: Springer Science & Business Media.  [Google Scholar] ). In the applied contexts, the MC process was found superior to gradient-descent and random search methods (Keilis-Borok and Yanovskaja 1967 Keilis-Borok, V. I., and T. B. Yanovskaja. 1967. “Inverse Problems of Seismology (Structural Review).” Geophysical Journal International 13 (1–3): 223–234. doi: 10.1111/j.1365-246X.1967.tb02156.x [Crossref] , [Web of Science ®]   [Google Scholar] ). Markov chain Monte Carlo is a powerful simulation technique for performing integration (Gilks 2005 Gilks, Walter R. 2005. Markov Chain Monte Carlo. Wiley Online Library. [Crossref]   [Google Scholar] ) that has revolutionised the application of Bayesian methods in IPs. For instance, Bui-Thanh and Girolami ( 2014 Bui-Thanh, Tan, and Mark Girolami. 2014. “Solving Large-Scale PDE-Constrained Bayesian Inverse Problems with Riemann Manifold Hamiltonian Monte Carlo.” Inverse Problems 30 (11): 114014. doi: 10.1088/0266-5611/30/11/114014 [Crossref] , [Web of Science ®]   [Google Scholar] ) implemented it to solve heat conduction IPs.\nOverall, there clearly exists a plethora of potential approaches to solving IPs, and exploration of their applicability in IDCM appears a warranted avenue of research which the current study is contributing to.\n4.  Methodology\nSection 4 outlines the IDCM approach in detail. Specifically, Section 4.1 introduces two estimators and contexts that they fit in. Section 4.2 provides the theoretical foundations, derivation and mathematical expression of IDCM. Section 4.3 presents the hypothesis development for evaluating the proposed method while Section 4.4 discusses validation methods of the IDCM performance.\n4.1.  Estimation methods\nIn current contribution, two estimators corresponding to two statistical estimation approaches are used to solve the proposed IDCM. These two approaches are maximum likelihood estimation (MLE) and maximum a posteriori (MAP) estimation.\nIn statistics, a likelihood function\nrepresents the probability for the occurrence of an independent and identically distributed sample configuration\ngiven the probability density\nwith known parameters\n(Harris and Stöcker 1998 Harris, John W., and Horst Stöcker. 1998. Handbook of Mathematics and Computational Science.\nNew York\n.\n5.  Application of IDCM to imputation from the London travel demand survey\nSection 5 demonstrates an application of the IDCM approach to imputing socioeconomic attributes of travellers from real-world observations of their travel mode choices. By removing respondent attribute data, the London Travel Demand Survey (LTDS) is used to mimic geotagged trace data in the imputation procedure. These attribute data, conversely, can act as a comparison to validate the imputation quality.\nParticularly, Section 5.1 introduces LTDS and how it is pre-processed to fit the scope of the analysis. Section 5.2 presents the procedure of calibrating the DCM of mode choice. Section 5.3 shows how the experiments of imputation are designed and conducted. The flow chart in Figure 2 illustrates the overall process of these experiments.\nInverse discrete choice modelling: theoretical and practical considerations for imputing respondent attributes from the patterns of observed choices\nAll authors\nCSV Display Table\nIn the MLE approach as defined in Equation (12), it is assumed that no prior knowledge on the parameters is available, that is, equal probabilities occur in all categories of either socioeconomic attributes or mode choices. Hence, the joint log-likelihood that should be maximised to find the MLE estimates is defined as the summation of the logarithms of the probabilities of all trips undertaken by the individual. For a sample consisting of\nrespondents independent of each other, it is equivalent to Equation (20):\n(20)\nIn terms of the MAP approach, the MAP estimator of the attribute to be imputed has been defined on the basis of Equations (8) and (12), leading to the expression in Equation (21):\n(21)\nThe prior\ncan be derived from corresponding estimation subsample. The process is achieved using exhaustive search over the given parameter space which is computationally manageable due to the independence between respondents, and finite thanks to the discrete nature of imputed variables. This furthermore guarantees the solution to be the global optimum.\n6.  Results\nSection 6 discusses findings from the four series of imputation experiments over 10 repetitions performed on the 20% imputation subsamples as outlined in Section 5.3. PCPs of each imputed variable of all holdout samples based on MLE and MAP estimates are presented in Figure 3 .\nInverse discrete choice modelling: theoretical and practical considerations for imputing respondent attributes from the patterns of observed choices\nAll authors\nDisplay full size\nFigure 3. Comparison of PCPs using MLE and MAP estimators.\nWe are also interested in the shares of individuals characterised by specific attributes in imputed and observed samples by conducting sample enumeration, which is a standard technique used frequently in investigating performance of DCMs (de Dios Ortúzar and Willumsen 1994 de Dios Ortúzar, Juan, and Luis G. Willumsen. 1994. Modelling Transport.\nHoboken\n,\nNJ\n: Wiley.  [Google Scholar] ). Due to large sample sizes, chi-squared test is used to validate the approach on aggregate level. And Table 3 shows the p-values of chi-squared test based on the two estimators.\nInverse discrete choice modelling: theoretical and practical considerations for imputing respondent attributes from the patterns of observed choices\nAll authors\nCSV Display Table\nIt can be seen from Figure 3 and Table 3 that the PCP and the chi-squared test statistics of each imputed variable using same estimators are stable across randomly selected subsamples, which provides a reasonable premise for the following analyses.\nFigure 3 shows that the MAP estimator generally performs no worse than its MLE counterpart on the individual level as it improves PCPs of the MLE-based imputation. Particularly in the first graph, performance of the MAP estimator almost equals to that of the MLE estimator. This is probably due to the equal distribution across genders, which have led to similar information of the uniform prior distribution of the MLE estimator. It is also noticed that the IDCM model is generally better at predicting nominal attributes than ordinal attributes. This is reasonably understandable as ordinal attributes (e.g. income) consist of more categories and therefore more input information is required for more accurate prediction. Moreover, ordinal attributes are imputed using the average value of each category for simplification, which introduce extra noise that reduces the prediction accuracy.\nThe results of chi-squared test in Table 3 demonstrate that the MAP also significantly improves the imputation quality on the overall sample level. This is indicated by all p-values over .05, showing that imputed samples do not differ from corresponding observed sample at a 95% confidence level. This is intuitive in the sense that MAP estimators usually involve more relevant information than MLE estimators.\nThe findings above are also related to the hypothesis developed in Section 4.3. Rather than\n, we calculate MIs (in bits) between travel modes and each attribute of all folds so as to explore the relationship between the EP and imputation quality of IDCM. Results are presented in Figure 4 .\nInverse discrete choice modelling: theoretical and practical considerations for imputing respondent attributes from the patterns of observed choices\nAll authors\nDisplay full size\nFigure 4. Correlation pattern between MI and PCPs.\nAs is seen in Figure 4 , the nominal variables show a pattern that higher PCP is produced by higher EP. This is in line with the results of the MC experiments by Pawlak, Zolfaghari, and Polak ( 2015 Pawlak, J., A. Zolfaghari, and J. W. Polak. 2015. “Imputing Socioeconomic Attributes for Movement Data by Analysing Patterns of Visited Places and Google Places Database: Bridging between Big Data and Behavioural Analysis.” Austin, TX, 11–13 July.  [Google Scholar] ). In particular, the relationship shows diminishing marginal improvement in PCP as the MI grows, which seems to be logarithmic or square root.\nThe ordinal variable, however, does not follow the trend of nominal variables. There are two potential explanations for this phenomenon. First, the income attribute can have three or more different values, as opposed to two in the nominal variables above, which increase the complexity of imputing the exact value of the variable from same amount of input information, that is, single discrete choice. Moreover, income is discretised and grouped into three levels with the average value of each level used in the IDCM imputation, hence reducing the MI with the choice. The exact reason will be explored in the future. It should be noted that we do not discuss the correlation between MI and PCPs using the MAP. This is because the amount of information contained in MAP-based PCPs has to some extent been ‘polluted’ by the prior information.\n7.  Conclusions\nThis paper formalises and extends a data enrichment approach which uses IDCM to infer socioeconomic characteristics of travel decision-makers from observations of discrete travel choices. Performance of the IDCM applied to a mode choice model based on real-world data set is explored. The empirical results are compared to that from the earlier MC experiment which employs the same inversion mechanisms.\nIt is observed that performance of the IDCM is highly sensitive to the EP of the imputed variable, measured by MI between the variable and discrete choices, in corresponding DCM. Specifically, performance of imputing the same type of variables using the proposed method is improved as the EP increases. Moreover, the nature of the imputed variable also plays a significant role. Particularly, attributes with numerical meanings or having more than two potential values, such as ordinal variables, can be more difficult to impute than nominal variables and two-category categorical variables. The exact reason for this will be investigated in the future.\nThis study can be viewed as an important step towards bridging the gap between travel behaviour analysis and data collected by ICT devices. The substantial benefit of using the increasingly available geotagged data to substitute traditional surveys while preserving individual privacy provide sufficient rationale to continue developing such enrichment approaches. For further investigation, MC experiment will be expanded to explore the role of DCM structures and EP of variables in determining imputation quality. It is hoped that this avenue will lead to new theoretical and empirical insights enabling more effective and robust enrichment procedures.\nDisclosure statement\nNo potential conflict of interest was reported by the authors.\nTable 1.  MNL model estimation results.\nAttribute coefficients\n""","0.2157497","""http://www.tandfonline.com/doi/full/10.1080/03081060.2018.1402745""","[-0.178219,51.500505]"
"""Cranfield_University""","""Coordinated Airborne Studies in the Tropics (CAST): Bulletin of the American Meteorological Society: Vol 98, No 1""","""Coordinated Airborne Studies in the Tropics (CAST)\nCoordinated Airborne Studies in the Tropics (CAST)\nAuthors:\nFinal Form: 2 February 2016\nPublished Online: 23 January 2017\nAbstract\nSection:\nThe main field activities of the Coordinated Airborne Studies in the Tropics (CAST) campaign took place in the west Pacific during January–February 2014. The field campaign was based in Guam (13.5°N, 144.8°E), using the U.K. Facility for Airborne Atmospheric Measurements (FAAM) BAe-146 atmospheric research aircraft, and was coordinated with the Airborne Tropical Tropopause Experiment (ATTREX) project with an unmanned Global Hawk and the Convective Transport of Active Species in the Tropics (CONTRAST) campaign with a Gulfstream V aircraft. Together, the three aircraft were able to make detailed measurements of atmospheric structure and composition from the ocean surface to 20 km. These measurements are providing new information about the processes influencing halogen and ozone levels in the tropical west Pacific, as well as the importance of trace-gas transport in convection for the upper troposphere and stratosphere. The FAAM aircraft made a total of 25 flights in the region between 1°S and 14°N and 130° and 155°E. It was used to sample at altitudes below 8 km, with much of the time spent in the marine boundary layer. It measured a range of chemical species and sampled extensively within the region of main inflow into the strong west Pacific convection. The CAST team also made ground-based measurements of a number of species (including daily ozonesondes) at the Atmospheric Radiation Measurement Program site on Manus Island, Papua New Guinea (2.1°S, 147.4°E). This article presents an overview of the CAST project, focusing on the design and operation of the west Pacific experiment. It additionally discusses some new developments in CAST, including flights of new instruments on board the Global Hawk in February–March 2015.\n* CURRENT AFFILIATION: Centre for Atmospheric Informatics and Emissions Technology, Cranfield University, Cranfield, United Kingdom\nThis article is licensed under a Creative Commons Attribution 4.0 license .\nCORRESPONDING AUTHOR E-MAIL: Neil Harris, neil.harris@cranfield.ac.uk\nSection:\nThe CAST project involves studying the chemical composition of the atmosphere in the tropical warm pool region to improve our understanding of trace gas transport in convection.\nThe tropical tropopause layer (TTL) is the region of the tropical atmosphere between the main convective outflow at around 12–13 km and the base of the stratosphere at 17–18 km and is a very important region for composition–aerosol–climate interactions ( Randel and Jensen 2013 ). Its overall structure is intermediate between the troposphere and stratosphere, with a lapse rate smaller than the saturated adiabatic up to the cold point ( Fueglistaler et al. 2009 ). This is caused by the combined effect of slow radiative processes and the infrequent penetration of convective turrets to high altitudes. There is a marked longitudinal asymmetry in TTL temperatures, with a minimum in the region 130°E–180° during all times of the year. This minimum corresponds to the warm waters of the tropical warm pool (TWP) beneath, and there is an associated maximum in convection ( Gettelman et al. 2002 ). The TTL is the predominant route for troposphere-to-stratosphere transport, so that conditions in the TTL set the entry concentrations at the base of the stratosphere for, for example, stratospheric water vapor and very short-lived halogen species. Knowledge of the input into the TTL is a prerequisite for correct modeling of TTL (and hence stratospheric) composition and yet many aspects are poorly constrained ( Levine et al. 2007 ; Heyes et al. 2009 ). The couplings between the various processes are important. For example, improving the treatment of TTL water vapor and cirrus in global climate models requires a better understanding of convective transport and radiative transfer in the TTL, as well as improved model descriptions of the key processes.\nWe are still unclear about the entry and exit routes for the TTL, including how much material is transported quasi horizontally into the extratropical lowermost stratosphere ( Levine et al. 2008 ). What is the average residence time in the TTL? What is the nature, and importance for composition, of longitudinal variability within the TTL? How much of the very short-lived halogen species can pass through the TTL and so affect stratospheric ozone concentrations? Large discrepancies exist between models and measurements even for long-lived tracers. Some of these are due to transport—sharp horizontal gradients are observed in atmospheric tracers at boundaries between midlatitude, subtropical, and tropical air masses, which are not well represented by models ( Wofsy et al. 2011 )—and some to limited information on emissions [e.g., N2O and CH4 in this region; Ishijima et al. (2010) ]. These issues are more important for very short-lived substances (VSLSs, with lifetimes shorter than 6 months), including halogen-containing VSLSs with their poorly understood sources, atmospheric transformations, and geographic distributions ( Carpenter et al. 2014 ). Other effects such as the degree to which the locations of the emissions coincide with strong convection can also have a strong influence on the overall flux ( Russo et al. 2015 ).\nTo address these issues, the Facility for Airborne Atmospheric Measurements (FAAM) BAe-146 atmospheric research aircraft was deployed in Guam in January and February 2014 as part of the Coordinated Airborne Studies in the Tropics (CAST) campaign, a large multi-institutional project funded by the U.K. Natural Environment Research Council (NERC) and the Science and Technology Facilities Council (STFC). In Guam, it flew alongside the National Aeronautics and Space Administration’s (NASA) Global Hawk, a high-altitude autonomous aircraft used in the NASA Airborne Tropical Tropopause Experiment (ATTREX) project, and the National Science Foundation/National Center for Atmospheric Research (NSF/NCAR) Gulfstream V (GV) in the NSF Convective Transport of Active Species in the Tropics (CONTRAST) project, as described in the companion papers by Jensen et al. (2017) and Pan et al. (2017) . The measurements from all three campaigns are being jointly used to diagnose how air is carried high into the atmosphere.\nThe value inherent in having the three aircraft flying together was found in the ability to measure from the surface up into the stratosphere (see Fig. 1 in Pan et al. 2017 ). The instrument payloads on the three aircraft made many common measurements, which together have combined to provide a comprehensive dataset for interpretative studies. However, within this larger picture, each aircraft had its own scientific aims and objectives, which were appropriate to the specific aircraft’s capabilities. The Global Hawk made measurements in the upper TTL (14–20 km), including in the outflow of convection. The GV aircraft principally sampled at the same altitudes as the main convective outflow (9–15 km) and, additionally, made measurements on profiles down into the boundary layer. In the case of the FAAM aircraft, the aims were to a) investigate halocarbon production in the marine boundary layer and b) characterize the composition of air in the main convective inflow. Knowledge of the distributions of trace gases in the boundary layer and lower troposphere is needed to estimate the flux of these gases into the TTL. The role of the FAAM research aircraft was to fly over the tropical west Pacific and to measure the composition in the lower troposphere (0–8 km). These measurements characterize the air masses in the region of the main convective inflow and so are valuable in interpreting the higher-altitude measurements of the Global Hawk and the GV made during the same period. They can also be used to improve our understanding of marine halocarbon production and to investigate the influence of polluted outflow from Asia. Additional measurements were made on Manus, Papua New Guinea.\nThe majority of this paper describes the CAST measurements during January–February 2014, as well as the flight planning tools used for the FAAM aircraft and for linking its measurements with those made by the other aircraft. Some early results are also discussed. The second CAST goal is to develop the U.K. capability to use autonomous aircraft for atmospheric research. Here, in addition to learning about deploying the Global Hawk and using the data collected, CAST scientists have produced two new instruments for use on the Global Hawk, which flew over the east Pacific during February–March 2015. These are described in the final section.\nCAST MEASUREMENTS.\nSection:\nMeasurements were made on two main platforms in the west Pacific. The FAAM BAe-146 research aircraft was based at the A. B. Won Pat International Airport, Guam (13.5°N, 144.8°E). The FAAM aircraft was collocated with the NCAR Gulfstream while the NASA Global Hawk was based at Andersen Air Force Base, approximately 30 km to the northeast. A suite of ground-based instrument systems was based at the Atmospheric Radiation Measurement (ARM) facility at Manus (2.1°S, 147.4°E), in order to characterize the tropospheric composition beyond the range of the FAAM aircraft.\nFlight planning.\nThe goal of the CAST FAAM flights was to characterize the inflow to convection in the lower troposphere in the west Pacific. To extend the range of the aircraft so that it could reach into the upwelling area near the equator, overnight stops were planned at the islands of Palau (Roman Tmetuchl International Airport, Babeldaob island, Republic of Palau; 7.4°N, 134.5°E) and Chuuk (Chuuk International Airport, Weno Island, Federated States of Micronesia; 7.5°N, 151.8°E). When conditions allowed, transects were made at 100 feet (30.5 m) [with occasional dips down to 50 ft (15.2 m)] over the open ocean to give the opportunity to sample air influenced by fresh ocean emissions. Stacked runs with horizontal legs at different altitudes were planned where possible to provide information about the vertical profile of the short-lived species in the lower troposphere. A large part of the flight planning for the FAAM research aircraft was to ensure good coverage of the lower troposphere within range from Guam.\nChemical forecast products were provided by the Monitoring Atmospheric Composition and Climate (MACC) project in support of all three field campaigns. MACC assimilates comprehensive global observations of chemical composition into the European Centre for Medium-Range Weather Forecasts (ECMWF) meteorological forecasting system ( Flemming et al. 2015 ). The operational MACC system runs at 80-km horizontal resolution (T255) with 60 vertical levels. During the campaign, forecast plots for the operation domain were provided for a number of chemical species, including the FAAM measurements: O3, CO, CH4, black carbon, NO, and NO2. In addition, a number of hypothetical tracers were included to track air originating from different locations (e.g., regional emissions from China and India). A coastal emission tracer was used to track oceanic emissions of CHBr3 and other short-lived halocarbons since these are preferentially released in coastal regions ( Carpenter et al. 2009 ; Ashfold et al. 2014 ).\nLinking measurements.\nTo have near-real-time information about the air reaching the TTL from the lower troposphere, the trajectory-based approach of Ashfold et al. (2012) was adapted to meet the needs of a multiaircraft campaign. In this, the Numerical Atmospheric-Dispersion Modeling Environment (NAME) was run as an adjunct to the Met Office operational forecasting model so that it could access meteorological forecasts on a time scale quick enough to provide useful flight-planning information. The starting grid for the trajectories covered a large area of the west Pacific ( Fig. 7 ), with trajectories being released at altitudes between 8 and 18 km. Twelve-day backward trajectories were then calculated using a mixture of Met Office analyses and forecasts, so that information was available about the possible influence of lower-tropospheric air in the regions that could be sampled by the Global Hawk and the GV. Each day, trajectories were produced for 1, 2, 3 and 5 days into the future. In each 2-km-altitude layer, 5,000 particles were released in each 10° × 10° box. During the campaign, these calculations were made for a larger area at higher altitudes to reflect the larger range of the Global Hawk. The horizontal resolution of the Met Office operational model was 25 km in early 2014.\nAn example is shown in Fig. 1 for three altitude ranges (12–14, 14–16, and 16–18 km). Each point is the end point of each parcel of air that had crossed below 1 km in the preceding 12 days. For graphical clarity, only a fraction of the trajectories are shown at each level. Thus, strong, predicted low-level influence is indicated by a high percentage in each box (shown by the number), and at a given level by the denser clouds. These maps were routinely checked against flight plans for the Global Hawk and the GV to ensure that a wide range of low-level influences was sampled. In general, most flight plans met these criteria as a result of the proximity of the aircraft to the main convective region.\nView larger version (64K)\nFig. 1. Examples of trajectory-based forecast products used for multiaircraft flight planning. These plots are for 13 Feb 2014 when all three aircraft were in the same region [see Fig. 7 in Pan et al. (2016)]. The three panels show the location of air parcels which had been below 1-km altitude in the preceding 12 days at (a) 16–18, (b) 14–16, and (c) 12–14 km. The number in each box is the percentage of parcels in that box from below 1 km in the preceding 12 days. During the campaign, they were available as 1-, 3-, and 5-day forecasts for flight planning, and the NAME model was driven by analyses and forecasts from the Met Office operational model run at 25-km horizontal resolution.\nFAAM BAe-146 aircraft.\nThe FAAM BAe-146 has a science payload of up to 4 tons (∼3630 kg) devised according to the objectives of a particular campaign. The chemical composition of the tropical atmosphere is the focus of CAST and this dictated the scientific payload. The chemical species and physical parameters measured on the FAAM aircraft, along with the instruments used, are summarized in Table 1 . Trace gases with a wide range of atmospheric lifetimes, sources, and sinks were measured in order to provide information about the origin and fate of the air masses encountered, as well as about the atmospheric time scales involved. In many cases these species were also measured by the Global Hawk and/or the GV aircraft, giving good synergy between the three datasets. Understanding the distribution and chemistry of halogen species is a special focus for all three campaigns and this is reflected in the FAAM payload.\nTable 1. Instruments and measurements made by the BAe-146 (FAAM) aircraft during the CAST project. Also indicated are the synergy with other aircraft from the CONTRAST (GV) and ATTREX (Global Hawk) projects.\nTable 1. Instruments and measurements made by the BAe-146 (FAAM) aircraft during the CAST project. Also indicated are the synergy with other aircraft from the CONTRAST (GV) and ATTREX (Global Hawk) projects.\nImage of typeset table\nWhole air samples (WASs) were collected as described in Andrews et al. (2013) . Analysis of WAS canisters was carried out in the aircraft hangar, usually within 72 h of collection. Two liters of sample air were preconcentrated using a thermal desorption unit (Markes Unity2 CIA-T) and analyzed with gas chromatography–mass spectrometry (GC-MS; Agilent 7890 GC, 5977 Xtr MSD). Halocarbons were quantified using a NOAA calibration gas standard. Dimethylsulfide was quantified using a secondary standard prepared and referenced to a primary [Korea Research Institute of Standards and Science (KRISS)] standard. The full method is detailed in Andrews et al. (2013 , 2016) .\nMeasurements of a subset of halocarbons and other volatile organic compounds (VOCs) were made in flight using a new thermal desorption (TD) GC-MS system. A 1-L sample of air, drawn from a window blank inlet, pressurized to 2.5 atm (1 atm = 101,325 Pa), and dried using a multicore countercurrent nafion drier, was alternately preconcentrated or analyzed from two parallel adsorption traps (Tenax TA) of a two-channel TD system (Markes International, model TT 24/7). Analyses were refocused at the head of the column using liquid CO2 prior to separation (10 m, 180-μm inner diameter, 1-μm film, Restek RTX502.2 column; 40°–150°C at 40°C min−1) by GC (Agilent 6850) and detection by electron impact MS single-ion monitoring (Agilent 5975C), calibrated preflight against the WAS gas standard (NOAA, SX-3581). The instrument temporal resolution, and associated sample integration period, was 5 min.\nThe chemical ionization mass spectrometer (CIMS) from the Georgia Institute of Technology was configured similarly to previous deployments ( Le Breton et al. 2012 , 2013 ). The I− ionization scheme was used to detect inorganic halogens, carboxylic acids, HCN, and other trace species. For CAST, the CIMS made simultaneous measurements of BrO, BrCl, Br2, and HOBr. The 1-Hz data were averaged to 30 s for analysis. Precampaign and postflight laboratory calibrations were used relative to in-flight formic acid calibrations to quantify the sensitivities and limits of detection for the inorganic halogens, similar to that used for dinitrogen pentoxide ( Le Breton et al. 2014 ). The sensitivities ranged from 1 to 50 ion counts per part per trillion per second (ppt−1 s−1) determined by in-flight and postcampaign calibrations. The limits of detection for species varied from 0.36 to 37 ppt for 30-s-averaged data. (All mixing ratios given in this paper are by volume.) An acid scrubber was used to quantify the background signal in the instrument and inlet line.\nA broadband cavity-en-hanced absorption spectrometer (BBCEAS) was adapted to measure input/output (IO) in the 410–482-nm-wavelength region. No clear absorption feature was observable from spectra by eye with up to 100-s averaging, pointing to very low mixing ratios (<∼0.5 ppt) of IO over the sampled area. When using averaged data, a small positive bias (∼0.3 ppt) of IO was observed with respect to zero. These observations appear to support the existence of IO in the remote marine boundary layer at sub-ppt levels, but the limited sensitivity precludes robust identification of spatial gradients.\nNitrous oxide was measured using chemiluminescence and NO2 was quantified via a second channel, with NO2 being converted to NO using a blue-light LED converter centered at 395 nm. The NO2 mixing ratio is derived from the difference between the total NOx and NO mixing ratios. The instrument is calibrated via addition of 5 standard cubic centimeters per minute (sccm) of known NO concentration to the ambient sample. The conversion efficiency of the LED converter is measured in each calibration using gas-phase titration of NO to NO2 on addition of O3. In-flight calibrations were conducted above the boundary layer to ensure stable low levels of NOx with before- and after-flight calibrations made using an overflow at the inlet of zero-grade air. A more detailed description of a similar system can be found in Lee et al. (2009) .\nThe level of O3 was measured by an ultraviolet (UV) absorption photometer (Thermo Fisher, model 49C), traceable to the U.K. National Physical Laboratory primary ozone standard with an uncertainty of 2% and a precision of 1 ppb for 4-s measurements.\nThe CO level was measured by a vacuum UV fluorescence analyzer [Aero Laser GmbH, model AL5002; Gerbig et al. (1999) ]. The instrument was calibrated in flight approximately every 45 min using a synthetic-air working standard (Air Liquide, ∼500 ppb), traceable to the NOAA/Earth System Research Laboratory [Global Monitoring Division-Carbon Cycle Greenhouse Gases Group (GMD-CCGG)] surveillance standard and the World Meteorological Organization CO-scale X2004. The 1-Hz CO measurements have a 2% uncertainty and 3-ppb precision.\nThe CO2 and CH4 levels were measured by a cavity-enhanced IR absorption spectrometer (Los Gatos Research, Inc., fast greenhouse gas analyzer, model RMT-200). The instrument was customized for airborne operations ( O’Shea et al. 2013 ), so CO2 and CH4 dry mole fractions can be linearized in flight using natural-air working standards, traceable to the World Meteorological Organization CO2-scale X2007 and CH4-scale X2004. The performance of the system is estimated from one standard deviation of all in-flight “target” calibration data. The 1-Hz measurement precisions are estimated at 0.7 ppm and 2.5 ppb for CO2 and CH4, respectively. Through the addition of all known uncertainties, we estimate a total accuracy of ±1.3 ppb for CH4 and ±0.2 ppm for CO2.\nThe Passive Cavity Aerosol Spectrometer Probe 100-X (PCASP), upgraded with the SPP-200 electronics package from Droplet Measurement Technologies (DMT), measures aerosol particles with nominal diameters of 0.1–3 µm. Light from a 0.6328-µm laser is scattered by the particles and a photodetector sums the forward (over solid angles subtended by 35°–120°) and backward (60°–145°) scattered light. The probe is canister mounted under the wing and was operated at 1 Hz. The instrument was calibrated for particle size before and after the campaign. Uncertainties exist in both the sizing and the counting of particles and these are discussed, along with the calibration procedure, in Rosenberg et al. (2012) .\nThe DMT Cloud Droplet Probe (CDP; Lance et al. 2010 ) was flown on the same under-wing pylon as the PCASP. The CDP is an open-path instrument that measures the forward-scattered light (over solid angles nominally subtended by 1.7°–14°) from the 0.658-µm incident laser beam. Particles are assigned to 1 of 30 size bins over the nominal size range 3–50 µm. Calibration with certified diameter glass beads was carried out before each flight ( Rosenberg et al. 2012 ). The sample rate of the CDP was the same as for the PCASP, 1 Hz.\nManus.\nObservations started at the ARM climate facility on Manus during October 1996 ( Mather et al. 1998 ) and continued until August 2014. These observations provided the basis for many studies of the climate in the west Pacific (e.g., Long et al. 2013 and references therein). In February 2014, a suite of ground-based instruments was deployed as part of CAST to make measurements of ozone (ground and profile), short-lived halocarbons, carbon dioxide, carbon monoxide, and methane. The instruments used are now described and are also summarized in Table 2 .\nTable 2. Measurements made at the ARM site at Manus during CAST. Information about the meteorological measurements from Manus can be found online ( www.arm.gov/sites/twp/C1/instruments ).\nTable 2. Measurements made at the ARM site at Manus during CAST. Information about the meteorological measurements from Manus can be found online ( www.arm.gov/sites/twp/C1/instruments ).\nImage of typeset table\nOzone profiles were measured using ozonesondes. Air is pumped through a potassium–iodine (KI) solution in a cathode half-cell, with two electrons produced for each ozone molecule; the cell current is directly proportional to the flow of ozone through the cell. Ozonesondes have a typical response time of about 1 min at the tropopause level, with a precision of a few parts per billion. In the TTL the accuracy of the measurement is dominated by the background current ( Newton et al. 2016 and references therein). Simultaneously, vertical profiles of temperature, humidity, wind, and pressure were measured with Vaisala RS92 radiosondes.\nGround-level ozone was measured by a Thermo-Electric Corporation TE49C, which is a dual-channel ultraviolet photometer measuring ozone through absorption of radiation at 254 nm. The incoming airstream is split between two identical cells, with a scrubber removing ozone from one of the streams. The TE49C provides a measurement every 10 s and has a 20-s response time.\nGround-level trace-gas concentrations were measured by a Picarro Cavity Ring-Down Spectrometer G2401 (CRDS; Crosson 2008 ). The sample air inlet was at about 8 m above ground level with a rain cover and a 2-µm particulate filter. Water vapor in the instrument was kept below 1.5 ppm and was controlled by passing the sample flow (∼250 mL min−1) through a chiller at approximately 5°C and then through a desiccant-based nafion drier. CO2 and CH4 concentrations were recorded every 5 s, with precisions of ∼1 and ∼200 ppb, respectively. Calibrations were achieved using a target gas (CH4, 2024 ppb; CO2, 390 ppm) measured every 2 days for 10 min with low and high calibration runs on intermediate days [low (high): CH4, 1919 (2736) ppb; CO2, 360 (495) ppm]. The calibration gases are linked to the NOAA–WMO calibration scale.\nSurface concentrations of short-lived halocarbons were measured using a µDirac instrument, a gas chromatograph with an electron capture detector (GC-ECD) based on an instrument described in Gostlow et al. (2010) but with a 10-m separation column. The instrument sampled ambient air from the roughly 8-m-high mast, with a 10–20 mL min–1 flow dried using a counterflow nafion drier. Calibration runs, using a NOAA/ESRL air cylinder spiked with the target compounds, were conducted regularly (every three samples). The calibration volumes ranged from 3 to 50 mL to allow correction for drifts in instrument sensitivity and linearity. Measurement precision is species dependent, typically 2%–10% (plus or minus one standard deviation), with accuracy in the range of 5%–10% (plus or minus one standard deviation).\nOVERVIEW OF MEASUREMENTS.\nSection:\nThe FAAM BAe-146 made a total of 25 science flights totaling 90 flight hours during the CAST deployment in the west Pacific ( Fig. 2 ). Brief summaries of the flights are given in Table 3 . The flight tracks are shown in Fig. 2 , with the altitude represented by the color of the line. The large majority of the flights were below 5-km altitude, with a significant fraction in the marine boundary layer (below about 1 km), with good coverage between 2°S and 14°N and 130° and 160°E.\nView larger version (78K)\nFig. 2. Map of FAAM BAe-146 flight tracks during Jan–Feb 2014. The flight tracks are colored by altitude. The islands of Guam, Palau, and Chuuk are marked. The background shows Jan–Feb-averaged Chl-a concentrations in 2014, measured by the MODIS satellite [NASA Giovanni: Acker and Leptoukh (2007) ]. The inset shows an enlarged area around Chuuk atoll.\nTable 3. Research flights made by the BAe-146 (FAAM) aircraft during the CAST project.\nTable 3. Research flights made by the BAe-146 (FAAM) aircraft during the CAST project.\nImage of typeset table\nThe vertical distribution of the science flights can also be seen in Fig. 3 , which shows O3 and CO concentrations as a function of altitude and latitude. In general, lower O3 values are found in the marine boundary layer and at lower latitudes, while high values are found at higher altitudes and at higher latitudes. There is no obvious correlation with CO. However, when the O3 and CO data are plotted against each other ( Fig. 4 ), a bimodal relationship emerges. Further, the lower ozone values (10–40 ppb) occur when the relative humidity is high ( Fig. 4 , top). This finding reinforces that of Pan et al. (2015) , who report this bimodality throughout the altitude range covered by the NCAR GV, with a background mode of nearly constant (∼20 ppb) values throughout the troposphere and a secondary mode of higher ozone (∼35–95 ppb) in layers with lower relative humidity. The previously reported S-shaped mean profile ( Folkins et al. 2002 ) results from averaging the two modes.\nView larger version (44K)\nFig. 3. (top left) Ozone and (top right) carbon monoxide mixing ratios measured during all CAST flights as a function of latitude and altitude. (right) The means and associated two standard deviations of ozone and carbon monoxide are shown as a function of altitude. See text and Table 1 for instrumental details.\nView larger version (44K)\nFig. 4. Plots of O3 against CO colored by (bottom) NO and (top) relative humidity (10-s-averaged data).\nThe CAST measurements ( Fig. 4 ) show that high ozone and lower relative humidity often occurs with higher NO concentrations and does not occur with low CO concentrations. Preliminary analysis of the high NO measurements indicates that the air masses encountered had previously been in regions close to anthropogenic activities and/or biomass burning. For example, the MACC forecasts show the transport of biomass burning and Southeast Asian tracers to the west Pacific. The possible role of biomass burning has been thoroughly investigated by Anderson et al. (2016) using CAST and CONTRAST measurements. The presence of HCN, CH3CN, and other tracers in the high-ozone levels is explained by biomass-burning plumes, which are convectively lofted into the free troposphere undergoing dehydration during the convection. As this air descends, its relative humidity drops and ozone is produced photochemically.\nThe CHBr3 concentrations measured with the Whole Air Sampler and the onboard GC-MS are shown in Fig. 5 . In general the values are low, with even the higher values not far above the background values seen in this region ( Brinckmann et al. 2012 ). The lower amounts of CHBr3 were encountered out of the boundary layer ( Fig. 4b ). The background in Fig. 2 shows that the chlorophyll-a (Chl-a) concentrations in the surface waters of the west Pacific were low during this period. Higher Chl-a values are seen in the shallower waters approaching the islands of the Maritime Continent. The lagoon inside Chuuk atoll is relatively shallow (<60 m) and is embedded in much deeper ocean waters. It has a circumference of about 200 km and an area of about 3000 km2. If halocarbons are emitted preferentially in shallow waters ( Carpenter et al. 2009 ), then it should be discernible as an emission hotspot. The influence of short-lived halocarbon emissions from shallower waters was investigated during the FAAM flights by circling Chuuk atoll at low altitudes. The inset in Fig. 5a shows the CHBr3 observed on these flights as well as the instantaneous wind speed observed by the FAAM aircraft. Higher concentrations of CHBr3 (red) are found when air has previously passed over the atoll, indicating that the atoll is a source of CHBr3.\nView larger version (44K)\nFig. 5. CHBr3 mixing ratios (colors) sampled by the FAAM aircraft during CAST using the whole air sampler (squares) and the onboard GC-MS (circles). (a) All measurements made at altitudes less than 1 km. The enlarged inset shows the values around the Chuuk atoll. The lines associated with each measurement in the inset indicate the instantaneous wind speed measured by the aircraft. (b) The measurements at altitudes greater than 1 km. The inset shows the vertical profile of all measurements.\nThe NAME model driven by Met Office analyzed fields has been used to interpret the CHBr3 and other brominated VSLS measurements made near the tropopause on the Global Hawk in the east Pacific during 2013 and the west Pacific during 2014 ( Navarro et al. 2015 ). The approach is similar to the forecast information produced during the campaign (see above). They find that the majority of air recently injected into the TTL had come from the west Pacific in both years with similar amounts, approximately 6 (4–9) ppt, of combined organic and inorganic bromine derived from brominated VSLS.\nAt the ARM facility in Manus, CHBr3 was also observed ( Fig. 5 ). The median value in this period was 0.81 ppt, about half that previously observed at a coastal site in Malaysian Borneo ( Robinson et al. 2014 ) and similar to the values observed on the FAAM aircraft ( Fig. 4 ). A strong diurnal cycle is seen in early February in several trace gases measured at Manus with increased nocturnal amounts, providing evidence for local nighttime sources of CO2, CH4, CHBr3, and CH3I. This diurnal pattern of behavior was seen from 3 to 12 February when the winds were low and a stable boundary layer was able to form. Before and after this period winds were higher and the nighttime buildup was much less.\nTogether, the CHBr3 observations appear to be consistent with past work focused on Southeast Asia. Elevated levels are frequently observed close to coasts (e.g., Pyle et al. 2011 ) or above shallow waters, but measurements collected a relatively small distance away (less than a typical global model grid cell) rarely contain above-background levels of CHBr3. This suggests that coasts are not a large source in a regional/global sense (as found by Ashfold et al. 2014 ), and for coastal CHBr3 emissions to contribute significantly to the TTL and stratosphere would require collocation of convection ( Russo et al. 2015 ).\nGround-based ozone at Manus showed decreases at night in the quiescent period from a peak daytime value of 10 to <5-ppb levels which is consistent with oxidative uptake to the local vegetation ( Fig. 6 ). This is the only time such low values of ozone were seen in CAST. In the absence of local sources, C2Cl4 is a good tracer of large-scale transport, and its concentrations during this period were generally in the range 1–1.5 ppt, which is typical of results seen in the clean west Pacific ( Ashfold et al. 2015 ). Manus was mainly influenced by flow from the north throughout this period.\nView larger version (103K)\nFig. 6. Surface observations of (top to bottom) wind, O3, CO2, CH4, C2Cl4, CHBr3, and CH3I at the ARM facility on Manus from 1 to 24 Feb 2014. The time shown along the x axis is universal time. The shading indicates the local time, with the darker bands representing nighttime.\nA total of 39 ozonesondes were launched from Manus in February 2014, with 34 sondes providing good ozone profiles ( Fig. 7a ; Newton et al. 2016 ). These measurements are most difficult in the tropics as the ozone concentrations are low, so that any error in estimating the background current is important. Particular attention was therefore paid to measurements of the background current, leading to recommendations for changes to the standard operation procedures used in the sonde preparation. Support for this approach is provided by good agreement in a coordinated ozonesonde–GV flight (see Fig. 14 in Pan et al. 2017 ). The ozone measurements are shown in Fig. 7 alongside the corresponding MACC 1- and 4-day forecasts. The forecasts predicted the main characteristics of the observations such as increased ozone at about 400 hPa from 14 to 16 February and the low concentrations near the TTL from 19 to 23 February. The minimum reproducible ozone concentration measured in the TTL was 12 ppb, consistent with the minimum of 13 ppb measured by the GV during CONTRAST ( Pan et al. 2017 ).\nFig. 7. (left) Daily observed ozone profile in Manus and corresponding MACC forecasts with lead times of (center) 1 and (right) 4 days.\nNew technology developments.\nAs part of the collaboration with ATTREX, three new developments were included in CAST: two instruments for use on the Global Hawk, the Aerosol–Ice–Interface Transition Spectrometer (AIITS) and the Greenhouse Gas Observations in the Stratosphere and Troposphere (GHOST), along with a software tool, Real-Time Atmospheric Science Cluster Analysis (RASCAL), designed to assist aircraft scientists by performing real-time data analysis during flights. The two new instruments were flown for a total of 40 h during one test flight and two science flights in February–March 2015 from the NASA Armstrong Flight Research Center, Edwards Air Force Base, California. They were part of a payload that also included Hawkeye, the NOAA H2O and O3 instruments, the Global Hawk Whole Air Sampler (GWAS), and the Microwave Temperature Profiler (MTP) (see Jensen et al. 2017 for more details).\nAIITS was designed to probe different cirrus regimes in the TTL in order to understand fundamental nucleation and sublimation processes influencing the stratospheric water budget and fluxes, as well as the potential impact of biomass burning on cirrus ice crystal activation and growth. It is the next instrument in the Small Ice Detector (SID) family ( Hirst et al. 2001 ; Kaye et al. 2008 ). AIITS acquires 2D forward-scattering patterns from particles in the size range from about one to a few hundred micrometers and can measure the depolarization in backward and forward scattering. The patterns allow quantification of the phase, habit, and fine surface features of large aerosol and small ice crystals in the size range 2–100 µm ( Cotton et al. 2010 ; Ulanowski et al. 2014 ). Unique results were obtained by AIITS during cirrus penetrations at 16.5 km and at temperatures down to -80°C ( Fig. 8 ). These revealed a transition to smooth quasi-spherical ice particle regimes in specific regions of TTL layers in response to changing supersaturation regimes. The impact on the radiative scattering properties of cirrus in these regimes is being investigated.\nView larger version (60K)\nFig. 8. AIITS scattering patterns recorded from ice particles in the upper troposphere–lower stratosphere (UTLS), at altitudes of about 16 km and temperatures of about –80°C. The pictures are indicative of (left) a smooth quasi-spherical ice particle, (center) a columnar crystal, and (right) a pristine hexagonal plate.\nGHOST is a novel grating spectrometer designed for remote sensing of greenhouse gases from aircraft ( Humpage et al. 2014 ). It measures spectrally resolved shortwave-infrared radiance across four spectral bands from 1.27 to 2.3 µm, with a spectral resolution between 0.1 and 0.3 nm. An optical gimbal underneath the aircraft is programmed to pass solar radiation reflected from the ocean surface through a fiber optic bundle into the spectrometer with a single grating and detector for all four bands. The bands are chosen to include absorption bands for CO2 and CH4 as well as CO, H2O, and O2; O2 is used to infer information on the scattering contributions toward the measured light. The third Global Hawk flight of the CAST/ATTREX campaign targeted the overpasses of two greenhouse gas observing satellites during clear-sky conditions over the eastern Pacific ( Fig. 9 ): the NASA Orbiting Carbon Observatory (OCO-2) and the Japan Aerospace Exploration Agency (JAXA) Greenhouse Gas Observing Satellite (GOSAT). This Global Hawk flight therefore provides a very useful validation dataset for these satellites, since they both make greenhouse gas measurements using a spectral range similar to that of GHOST.\nView larger version (87K)\nFig. 9. Flight path of the NASA Global Hawk on 10 Mar 2015 (blue). The OCO-2 (green) and GOSAT (red) soundings are shown and coincide temporally with the flight leg between 25°N, 127°W and 18°N, 125°W. MODIS cloud fraction data (see gray scale bar; Platnick et al. 2015 ) coincident with the OCO-2 overpass at 2140 UTC shows the largely cloud-free conditions encountered during this leg of the flight.\nAs real-time data becomes increasingly available, mission scientists are faced with a potentially overwhelming data torrent, from which they are required to find the information on which to base decisions. At present, mission scientists often focus on a subset of the data stream, limiting the depth of the analysis that can be carried out. As part of CAST, a new software framework, RASCAL, has been developed based on recent developments in arbitrarily shaped cluster detection algorithms ( Hyde and Angelov 2015 ). It interfaces intuitively with mission scientist expert knowledge and provides real-time on-the-fly cluster and anomaly detection (i.e., for real-time diagnosis of structures such as those presented in Fig. 4 , for example, but tested simultaneously across many chemical “dimensions”). The data stream can be separated in real time, without a priori assumptions about parameter relationships, to reveal different data groups and hence isolate specific regions of interest that can be revisited virtually postflight. In combination with the expert knowledge of the mission scientists, support tools like RASCAL have the potential to be used on many research aircraft, potentially adding significant value to the results achieved in field measurement campaigns.\nSUMMARY.\nSection:\nBased in Guam as part of a joint deployment with the NASA ATTREX Global Hawk and the NSF CONTRAST GV, the FAAM research aircraft deployment during CAST has provided an excellent characterization of the lower-tropospheric atmospheric composition in the tropical warm pool region. The majority of the FAAM aircraft flights were below 5-km altitude, and a significant fraction was in the marine boundary layer with good coverage from 2°S to 14°N and from 130° to 160°E. A suite of organic and inorganic halogen compounds was measured, with the bromine-containing species being particularly well covered.\nGround-based measurements were made at the ARM facility on Manus Island, Papua New Guinea, during February 2014. These measurements characterize the tropospheric composition just south of the equator in a region inaccessible to the FAAM aircraft in this deployment. The Manus ozonesonde measurements are a valuable resource, providing a good picture of the vertical distribution of ozone in the tropical warm pool region during February with a minimum ozone concentration in the TTL of 12 ppb.\nThese measurements are being interpreted by CAST scientists in conjunction with measurements from ATTREX and CONTRAST using a range of modeling and data analysis approaches. The CAST data are stored at the British Atmospheric Data Centre ( http://badc.nerc.ac.uk/ ), and interested parties are encouraged to use them for their own studies. All users are strongly encouraged to involve the responsible instrument scientists in these studies in order to gain insight into the strengths and weaknesses of these data.\nNever before has the atmosphere over the west Pacific been observed in such detail, particularly the chemical composition, with three aircraft covering all altitudes from 0 to 20 km. New insights are starting to emerge with a much improved understanding of the tropical ozone distribution ( Pan et al. 2015 ; Anderson et al. 2016 ; Newton et al. 2016 ). These findings will be underpinned by advances in the understanding of halogen distribution ( Navarro et al. 2015 ) and chemistry building on the new tropospheric halogen measurements and modeling ( Sherwen et al. 2016 ). Such research will lead to a much greater quantitative understanding of the role of a) VSLS reaching the stratosphere and b) how halogen chemistry affects tropospheric ozone over the tropical oceans. Similar advances can be expected with respect to transport and dynamics, the role of cirrus clouds in climate, and dehydration of the stratosphere. The benefits of this unique, coordinated campaign are just starting to become clear.\nACKNOWLEDGMENTS\nCAST is funded by NERC and STFC, with Grants NE/ I030054/1 (lead award), NE/J006262/1, NE/J006238/1, NE/J006181/1, NE/J006211/1, NE/J006061/1, NE/J006157/1, NE/J006203/1, NE/J00619X/1, and NE/J006173/1. NRPH was supported by a NERC Advanced Research Fellowship (NE/G014655/1). PIP acknowledges his Royal Society Wolfson Research Merit Award. The BAe-146-301 Atmospheric Research Aircraft is flown by Directflight Ltd, and managed by the Facility for Airborne Atmospheric Measurements, which is a joint entity of the Natural Environment Research Council and the Met Office. The authors thank the staff at FAAM, Directflight, and Avalon Aero, who worked so hard toward the success of the aircraft deployment in Guam, especially for their untiring efforts when spending an unforeseen nine days in Chuuk. We thank the local staff at Chuuk and Palau, as well as the authorities in the Federated States of Micronesia for their help in facilitating our research flights. Special thanks go to the personnel associated with the ARM facility at Manus, Papua New Guinea, without whose help the ground-based measurements would not have been possible. Thanks to the British Atmospheric Data Centre (BADC) for hosting our data and the NCAS Atmospheric Measurement Facility for providing the radiosonde and ground-based ozone equipment. Chlorophyll-a data used in Fig. 1 were extracted using the Giovanni online data system, maintained by the NASA GES DISC. We acknowledge the MODIS mission scientists and associated NASA personnel for the production of this dataset. Finally we thank many individuals associated with the ATTREX and CONTRAST campaigns for their help in the logistical planning, and we would like to single out Jim Bresch for his excellent and freely provided meteorological advice.\nREFERENCES\nSection:\nAcker, J. G., and G. Leptoukh, 2007: Online analysis enhances use of NASA Earth science data. Eos, Trans. Amer. Geophys. Union, 88, 14–17, doi: https://doi.org/10.1029/2007EO020003 . Crossref\nAnderson, D. C., and Coauthors, 2016: A pervasive role for biomass burning in tropical high ozone/low water structures. Nat. Commun., 7, 10267, doi: https://doi.org/10.1038/ncomms10267 . Crossref\nAndrews, S. J., C. E. Jones, and L. J. Carpenter, 2013: Aircraft measurements of very short-lived halocarbons over the tropical Atlantic Ocean. Geophys. Res. Lett., 40, 1005–1010, doi: https://doi.org/10.1002/grl.50141 . Crossref\nAndrews, S. J., and Coauthors, 2016: A comparison of very short lived halocarbon (VSLS) and DMS aircraft measurements in the tropical west Pacific from CAST, ATTREX and CONTRAST. Atmos. Meas. Tech., 9, 5213–5225, doi: https://doi.org/10.5194/amt-9-5213-2016 . Crossref\nAshfold, M. J., N. R. P. Harris, E. L. Atlas, A. J. Manning, and J. A. Pyle, 2012: Transport of short-lived species into the tropical tropopause layer. Atmos. Chem. Phys., 12, 6309–6322, doi: https://doi.org/10.5194/acp-12-6309-2012 . Crossref\nAshfold, M. J., N. R. P. Harris, A. J. Manning, A. D. Robinson, N. J. Warwick, and J. A. Pyle, 2014: Estimates of tropical bromoform emissions using an inversion method. Atmos. Chem. Phys., 14, 979–994, doi: https://doi.org/10.5194/acp-14-979-2014 . Crossref\nAshfold, M. J., and Coauthors, 2015: Rapid transport of East Asian pollution to the deep tropics. Atmos. Chem. Phys., 15, 3565–3573, doi: https://doi.org/10.5194/acp-15-3565-2015 . Crossref\nBrinckmann, S., A. Engel, H. Bönisch, B. Quack, and E. Atlas, 2012: Short-lived brominated hydrocarbons—Observations in the source regions and the tropical tropopause layer. Atmos. Chem. Phys., 12, 1213–1228, doi: https://doi.org/10.5194/acp-12-1213-2012 . Crossref\nCarpenter, L. J., C. E. Jones, R. M. Dunk, K. E. Hornsby, and J. Woeltjen, 2009: Air–sea fluxes of biogenic bromine from the tropical and North Atlantic Ocean. Atmos. Chem. Phys., 9, 1805–1816, doi: https://doi.org/10.5194/acp-9-1805-2009 . Crossref\nCarpenter, L. J., and Coauthors, 2014: Ozone-depleting substances (ODSs) and other gases of interest to the Montreal Protocol. Scientific Assessment of Ozone Depletion: 2014, A. Engel and S. A. Montzka, Eds., Global Ozone Research and Monitoring Project Rep. 55, World Meteorological Organization, 1–101. [Available online at www.wmo.int/pages/prog/arep/gaw/ozone_2014/documents/Full_report_2014_Ozone_Assessment.pdf .]\nCotton, R., S. Osborne, Z. Ulanowski, E. Hirst, P. H. Kaye, and R. Greenaway, 2010: The ability of the Small Ice Detector (SID2) to characterize cloud particle and aerosol morphologies obtained during flights of the FAAM BAe-146 research aircraft. J. Atmos. Oceanic Technol., 27, 290–303, doi: https://doi.org/10.1175/2009JTECHA1282.1 . Link\nCrosson, E. R., 2008: A cavity ring-down analyzer for measuring atmospheric levels of methane, carbon dioxide, and water vapor. Appl. Phys. B, 92, 403–408, doi: https://doi.org/10.1007/s00340-008-3135-y . Crossref\nFlemming, J., and Coauthors, 2015: Tropospheric chemistry in the Integrated Forecasting System of ECMWF. Geosci. Model Dev., 8, 975–1003, doi: https://doi.org/10.5194/gmd-8-975-2015 . Crossref\nFolkins, I., C. Braun, A. M. Thompson, and J. Witte, 2002: Tropical ozone as an indicator of deep convection. J. Geophys. Res., 107, 4184, doi: https://doi.org/10.1029/2001JD001178 . Crossref\nFueglistaler, S., A. E. Dessler, T. J. Dunkerton, I. Folkins, Q. Fu, and P. W. Mote, 2009: Tropical tropopause layer. Rev. Geophys., 47, RG1004, doi: https://doi.org/10.1029/2008RG000267 . Crossref\nGerbig, C., S. Schmitgen, D. Kley, A. Volz-Thomas, K. Dewey, and D. Haaks, 1999: An improved fast-response VUV resonance flourescence CO instrument. J. Geophys. Res., 104, 1699–1704, doi: https://doi.org/10.1029/1998JD100031 . Crossref\nGettelman, A., M. L. Salby, and F. Sassi, 2002: Distribution and influence of convection in the tropical tropopause region. J. Geophys. Res., 107, doi: https://doi.org/10.1029/2001JD001048 . Crossref\nGostlow, B., and Coauthors, 2010: Micro-DIRAC: An autonomous instrument for halocarbon measurements. Atmos. Meas. Tech., 3, 507–521, doi: https://doi.org/10.5194/amt-3-507-2010 . Crossref\nHeyes, W. J., G. Vaughan, G. Allen, A. Volz-Thomas, H.-W. Pätz, and R. Busen, 2009: Composition of the TTL over Darwin: Local mixing or long-range transport? Atmos. Chem. Phys., 9, 7725–7736, doi: https://doi.org/10.5194/acp-9-7725-2009 . Crossref\nHirst, E., P. H. Kaye, R. S. Greenaway, P. Field, and D. W. Johnson, 2001: Discrimination of micrometre-sized ice and super-cooled droplets in mixed-phase cloud. Atmos. Environ., 35, 33–47, doi: https://doi.org/10.1016/S1352-2310(00)00377-0 . Crossref\nHopkins, J. R., K. A. Read, and A. C. Lewis, 2003: A two column method for long-term monitoring of non-methane hydrocarbons (NMHCs) and oxygenated volatile organic compounds. J. Environ. Monit., 5, 8–13, doi: https://doi.org/10.1039/b202798d . Crossref\nHumpage, N., and Coauthors, 2014: GreenHouse Observations of the Stratosphere and Troposphere (GHOST): A novel shortwave infrared spectrometer developed for the Global Hawk unmanned aerial vehicle. Proc. SPIE 9242, Remote Sensing of Clouds and the Atmosphere XIX and Optics in Atmospheric Propagation and Adaptive Systems XVII, A. Comerón et al., Eds., International Society for Optical Engineering (SPIE Proceedings, Vol. 92420P), doi: 10.1117/12.2067330.\nHyde, R., and P. Angelov, 2015: A new online clustering approach for data in arbitrary shaped clusters. Proc. Second Int. Conf. on Cybernetics, Gydnia, Poland, IEEE, 228–233, doi: 10.1109/CYBConf.2015.7175937.\nIshijima, K., and Coauthors, 2010: Stratospheric influence on the seasonal cycle of nitrous oxide in the troposphere as deduced from aircraft observations and model simulations. J. Geophys. Res., 115, D20308, doi: https://doi.org/10.1029/2009JD013322 . Crossref\nJensen, E. J., and Coauthors, 2017: The NASA Airborne Tropical Tropopause Experiment (ATTREX): High-altitude aircraft measurements in the tropical western Pacific. Bull. Amer. Meteor. Soc., 98, 129–143, doi: https://doi.org/10.1175/BAMS-D-14-00263.1 . Link\nKaye, P. H., E. Hirst, R. S. Greenaway, Z. Ulanowski, E. Hesse, P. J. DeMott, C. Saunders, and P. Connolly, 2008: Classifying atmospheric ice crystals by spatial light scattering. Opt. Lett., 33, 1545, doi: https://doi.org/10.1364/OL.33.001545 . Crossref\nKennedy, O. J., and Coauthors, 2011: An aircraft based three channel broadband cavity enhanced absorption spectrometer for simultaneous measurements of NO3, N2O5 and NO2. Atmos. Meas. Tech., 4, 1759–1776, doi: https://doi.org/10.5194/amt-4-1759-2011 . Crossref\nLance, S., C. A. Brock, D. Rogers, and J. A. Gordon, 2010: Water droplet calibration of the Cloud Droplet Probe (CDP) and in-flight performance in liquid, ice and mixed-phase clouds during ARCPAC. Atmos. Meas. Tech., 3, 1683–1706, doi: https://doi.org/10.5194/amt-3-1683-2010 . Crossref\nLe Breton, M., and Coauthors, 2012: Airborne observations of formic acid using a chemical ionization mass spectrometer. Atmos. Meas. Tech., 5, 3029–3039, doi: https://doi.org/10.5194/amt-5-3029-2012 . Crossref\nLe Breton, M., and Coauthors, 2013: Airborne hydrogen cyanide measurements using a chemical ionisation mass spectrometer for the plume identification of biomass burning forest fires. Atmos. Chem. Phys., 13, 9217–9232, doi: https://doi.org/10.5194/acp-13-9217-2013 . Crossref\nLe Breton, M., and Coauthors, 2014, The first airborne comparison of N2O5 measurements over the UK using a CIMS and BBCEAS during the RONOCO campaign. Anal. Methods, 6, 9731–9743, doi: https://doi.org/10.1039/c4ay02273d . Crossref\nLee, J. D., S. J. Moller, K. A. Read, A. C. Lewis, L. Mendes, and L. J. Carpenter, 2009: Year-round measurements of nitrogen oxides and ozone in the tropical North Atlantic marine boundary layer. J. Geophys. Res., 114, D21302, doi: https://doi.org/10.1029/2009JD011878 . Crossref\nLenschow, D. H., 1986: Aircraft measurements in the boundary layer. Probing the Atmospheric Boundary Layer, D. H. Lenschow, Ed., Amer. Meteor. Soc., 39–55.\nLevine, J. G., P. Braesicke, N. R. P. Harris, N. H. Savage, and J. A. Pyle, 2007: Pathways and timescales for troposphere-to-stratosphere transport via the tropical tropopause layer and their relevance for very short lived substances. J. Geophys. Res., 112, D04308, doi: https://doi.org/10.1029/2005JD006940 . Crossref\nLevine, J. G., P. Braesicke, N. R. P. Harris, and J. A. Pyle, 2008: Seasonal and inter-annual variations in troposphere-to-stratosphere transport from the tropical tropopause layer. Atmos. Chem. Phys., 8, 3689–3703, doi: https://doi.org/10.5194/acp-8-3689-2008 . Crossref\nLiu, D., and Coauthors, 2015: The importance of Asia as a source of black carbon to the European Arctic during springtime 2013. Atmos. Chem. Phys., 15, 11 537–11 555, doi: https://doi.org/10.5194/acp-15-11537-2015 . Crossref\nLong, C. N., and Coauthors, 2013: ARM research in the equatorial western Pacific: A decade and counting. Bull. Amer. Meteor. Soc., 94, 695–708, doi: https://doi.org/10.1175/BAMS-D-11-00137.1 . Link\nMather, J. H., T. P. Ackerman, W. E. Clements, F. J. Barnes, M. D. Ivey, L. D. Hatfield, and R. M. Reynolds, 1998: An Atmospheric Radiation and Cloud Station in the tropical western Pacific. Bull. Amer. Meteor. Soc., 79, 627–642, doi: https://doi.org/10.1175/1520-0477(1998)079<0627:AARACS>2.0.CO;2 .\nNavarro, M. A., and Coauthors, 2015: Airborne measurements of organic bromine compounds in the Pacific tropical tropopause layer. Proc. Nat. Acad. Sci., 112, 13 789–13 793, doi: https://doi.org/10.1073/pnas.1511463112 . Crossref\nNewton, R., G. Vaughan, H. M. A. Ricketts, L. L. Pan, A. J. Weinheimer, and C. Chemel, 2016: Ozonesonde profiles from the west Pacific warm pool: Measurements and validation. Atmos. Chem. Phys., 6, 619–634, doi: https://doi.org/10.5194/acp-16-619-2016 . Crossref\nO’Shea, S. J., S. J.-B. Bauguitte, M. W. Gallagher, D. Lowry, and C. J. Percival, 2013: Development of a cavity-enhanced absorption spectrometer for airborne measurements of CH4 and CO2. Atmos. Meas. Tech., 6, 1095–1109, doi: https://doi.org/10.5194/amt-6-1095-2013 . Crossref\nPan, L. L., and Coauthors, 2015: Bimodal distribution of free tropospheric ozone over the tropical western Pacific revealed by airborne observations. Geophys. Res. Lett., 42, 7844–7851, doi: https://doi.org/10.1002/2015GL065562 . Crossref\nPan, L. L., and Coauthors, 2017: The Convective Transport of Active Species in the Tropics (CONTRAST) experiment. Bull. Amer. Meteor. Soc., 98, 106–128, doi: https://doi.org/10.1175/BAMS-D-14-00272.1 . Link\nPetersen, G. N., and I. A. Renfrew, 2009: Aircraft-based observations of air–sea fluxes over Denmark Strait and the Irminger Sea during high wind speed conditions. Quart. J. Roy. Meteor. Soc., 135, 2030–2045, doi: https://doi.org/10.1002/qj.355 . Crossref\nPlatnick, S., and Coauthors, 2015: MODIS Atmosphere L2 Cloud Product (06_L2). NASA MODIS Adaptive Processing System, NASA Goddard Space Flight Center, accessed 23 October 2015, doi: 10.5067/MODIS/MYD06_L2.006.\nPyle, J. A., and Coauthors, 2011: Bromoform in the tropical boundary layer of the Maritime Continent during OP3. Atmos. Chem. Phys., 11, 529–542, doi: https://doi.org/10.5194/acp-11-529-2011 . Crossref\nRandel, W., and E. Jensen, 2013: Physical processes in the tropical tropopause layer and their roles in a changing climate. Nat. Geosci., 6, 169–176, doi: https://doi.org/10.1038/ngeo1733 . Crossref\nRobinson, A. D., and Coauthors, 2014: Long-term halocarbon observations from a coastal and an inland site in Sabah, Malaysian Borneo. Atmos. Chem. Phys., 14, 8369–8388, doi: https://doi.org/10.5194/acp-14-8369-2014 . Crossref\nRosenberg, P. D., A. R. Dean, P. I. Williams, J. R. Dorsey, A. Minikin, M. A. Pickering, and A. Petzold, 2012: Particle sizing calibration with refractive index correction for light scattering optical particle counters and impacts upon PCASP and CDP data collected during the Fennec campaign. Atmos. Meas. Tech., 5, 1147–1163, doi: https://doi.org/10.5194/amt-5-1147-2012 . Crossref\nRusso, M. R., M. J. Ashfold, N. R. P. Harris, and J. A. Pyle, 2015: On the emissions and transport of bromoform: Sensitivity to model resolution and emission location. Atmos. Chem. Phys., 15, 14 031–14 040, doi: https://doi.org/10.5194/acp-15-14031-2015 . Crossref\nSherwen, T., and Coauthors, 2016: Iodine’s impact on tropospheric oxidants: A global model study in GEOS-Chem. Atmos. Chem. Phys., 16, 1161–1186, doi: https://doi.org/10.5194/acp-16-1161-2016 . Crossref\nStröm, J., R. Busen, M. Quante, B. Guillemet, P. R. A. Brown, and J. Heintzenberg, 1994: Pre-EUCREX intercomparison of airborne humidity measuring instruments. J. Atmos. Oceanic Technol., 11, 1392–1399, doi: https://doi.org/10.1175/1520-0426(1994)011<1392:PEIOAH>2.0.CO;2 .\nUlanowski, Z., P. H. Kaye, E. Hirst, R. S. Greenaway, R. J. Cotton, E. Hesse, and C. T. Collier, 2014: Incidence of rough and irregular atmospheric ice particles from Small Ice Detector 3 measurements. Atmos. Chem. Phys., 14, 1649–1662, doi: https://doi.org/10.5194/acp-14-1649-2014 . Crossref\nWhalley, L. K., A. C. Lewis, J. B. McQuaid, R. M. Purvis, J. D. Lee, K. Stemmler, C. Zellweger, and P. Ridgeon, 2004: Two high-speed, portable GC systems designed for the measurement of nonmethane hydrocarbons and PAN: Results from the Jungfraujoch high altitude observatory. J. Environ. Monit., 6, 234–241, doi: https://doi.org/10.1039/b310022g . Crossref\nWilson, K. L., and J. W. Birks, 2006: Mechanism and elimination of a water vapor interference in the measurement of ozone by UV absorbance. Environ. Sci. Technol., 40, 6361–6367, doi: https://doi.org/10.1021/es052590c . Crossref\nWofsy, S. C., and Coauthors, 2011: HIAPER Pole-to-Pole Observations (HIPPO): Fine-grained, global-scale measurements of climatically important atmospheric gases and aerosols. Philos. Trans. Roy. Soc., 369A, 2073–2086, doi: https://doi.org/10.1098/rsta.2010.0313 . Crossref\nJanuary 2017\n""","0.17837967","""http://journals.ametsoc.org/doi/10.1175/BAMS-D-14-00290.1""","[-0.629225,52.074389]"
"""Imperial_College_London""","""Modeling the bilateral micro-searching behavior for urban taxi services using the absorbing markov chain approach - Wong - 2005 - Journal of Advanced Transportation - Wiley Online Library""","""Journal of Advanced Transportation\nModeling the bilateral micro-searching behavior for urban taxi services using the absorbing markov chain approach\nAuthors\nK.I. Wong and M.G.H. Bell, Centre for Transport Studies, Department of Civil and Environmental Engineering, Imperial College London, England, UK\nS. C. Wong,\nS.C. Wong, Department of Civil Engineering, The University of Hong Kong, Hong Kong. P.R., China\nM. G. H. Bell,\nK.I. Wong and M.G.H. Bell, Centre for Transport Studies, Department of Civil and Environmental Engineering, Imperial College London, England, UK\nHai Yang\nHai Yang, Department of Civil Engineering, The Hong Kong University of Science and Technology, Hong Kong, P.R., China\nFirst published:\nCited by (CrossRef): 22 articles Check for updates\nCitation tools\nFunding Information\nAbstract\nThis paper develops a mathematical model that is based on the absorbing Markov chain approach to describe taxi movements, taking into account the stochastic searching processes of taxis in a network. The local searching behavior of taxis is specified by a logit form, and the O-D demand of passengers is estimated as a logit model with a choice of taxi meeting point. The relationship between customer and taxi waiting times is modeled by a double-ended queuing system. The problem is solved with a set of non-linear equations, and some interesting results are presented. The research provides a novel and potentially useful formulation for describing the urban taxi services in a network.\nCroucher Foundation of Hong Kong\nResearch Grants Council of the Hong Kong Special Administrative Region. Grant Number: HKUST6107/03E and HKU7134/03E\nRelated content\nArticles related to the one you are viewing\nCiting Literature\nNumber of times cited: 22\n1\nZhong Zheng, Soora Rasouli, Harry Timmermans, Modeling taxi driver anticipatory behavior, Computers, Environment and Urban Systems, 2018\nCrossRef\n2\nYuxiong Ji, Yuchuan Du, Yue Liu, H. Michael Zhang, Empirical Behavioral Study of Airport-Serving Taxi Drivers Using Automatic Vehicle Location Data, Journal of Urban Planning and Development, 2017, 143, 1, 04016026\nCrossRef\n3\nLuliang Tang, Fei Sun, Zihan Kan, Chang Ren, Luling Cheng, Uncovering Distribution Patterns of High Performance Taxis from Big Trace Data, ISPRS International Journal of Geo-Information, 2017, 6, 12, 134\nCrossRef\n4\nYing Shi, Zhaotong Lian, Optimization and strategic behavior in a passenger–taxi service system, European Journal of Operational Research, 2016, 249, 3, 1024\nCrossRef\n5\nR.C.P. Wong, W.Y. Szeto, S.C. Wong, A two-stage approach to modeling vacant taxi movements, Transportation Research Part C: Emerging Technologies, 2015, 59, 147\nCrossRef\n6\nR.C.P. Wong, W.Y. Szeto, S.C. Wong, A Two-Stage Approach to Modeling Vacant Taxi Movements, Transportation Research Procedia, 2015, 7, 254\nCrossRef\n7\nLuis M. Martinez, Gonçalo H. A. Correia, José M. Viegas, An agent-based simulation model to assess the impacts of introducing a shared-taxi system: an application to Lisbon (Portugal), Journal of Advanced Transportation, 2015, 49, 3, 475\nWiley Online Library\n8\nR. C. P. Wong, W. Y. Szeto, S. C. Wong, Behavior of taxi customers in hailing vacant taxis: a nested logit model for policy analysis, Journal of Advanced Transportation, 2015, 49, 8, 867\nWiley Online Library\n9\nR.C.P. Wong, W.Y. Szeto, S.C. Wong, A cell-based logit-opportunity taxi customer-search model, Transportation Research Part C: Emerging Technologies, 2014, 48, 84\nCrossRef\n10\nR.C.P. Wong, W.Y. Szeto, S.C. Wong, Bi-level decisions of vacant taxi drivers traveling towards taxi stands in customer-search: Modeling methodology and policy implications, Transport Policy, 2014, 33, 73\nCrossRef\n11\nR.C.P. Wong, W.Y. Szeto, S.C. Wong, Hai Yang, Modelling multi-period customer-searching behaviour of taxi drivers, Transportmetrica B: Transport Dynamics, 2014, 2, 1, 40\nCrossRef\n12\nWai Yuen Szeto, Ryan Cheuk Pong Wong, Sze Chun Wong, Hai Yang, A time-dependent logit-based taxi customer-search model, International Journal of Urban Sciences, 2013, 17, 2, 184\nCrossRef\n13\nXianbiao Hu, Song Gao, Yi-Chang Chiu, Dung-Ying Lin, Modeling Routing Behavior for Vacant Taxicabs in Urban Traffic Networks, Transportation Research Record: Journal of the Transportation Research Board, 2012, 2284, 81\nCrossRef\n14\nJosep Maria Salanova, Miquel Estrada, Georgia Aifadopoulou, Evangelos Mitsakis, A review of the modeling of taxi services, Procedia - Social and Behavioral Sciences, 2011, 20, 150\nCrossRef\n16\nHai Yang, Teng Yang, Equilibrium properties of taxi markets with search frictions, Transportation Research Part B: Methodological, 2011, 45, 4, 696\nCrossRef\n17\nR. M. N. T. Sirisoma, S. C. Wong, W. H. K. Lam, D. Wang, H. Yang, P. Zhang, Empirical evidence for taxi customer-search model, Proceedings of the Institution of Civil Engineers - Transport, 2010, 163, 4, 203\nCrossRef\n18\nHai Yang, Cowina W.Y. Leung, S.C. Wong, Michael G.H. Bell, Equilibria of bilateral taxi–customer searching and meeting on networks, Transportation Research Part B: Methodological, 2010, 44, 8-9, 1067\nCrossRef\n19\nHai Yang, C.S. Fung, K.I. Wong, S.C. Wong, Nonlinear pricing of taxi services, Transportation Research Part A: Policy and Practice, 2010, 44, 5, 337\nCrossRef\n20\nK.I. Wong, S.C. Wong, Hai Yang, J.H. Wu, Modeling urban taxi services with multiple user classes and vehicle modes, Transportation Research Part B: Methodological, 2008, 42, 10, 985\n""","0.7723578","""http://onlinelibrary.wiley.com/doi/10.1002/atr.5670390107/abstract""","[-0.178219,51.500505]"
"""Cranfield_University""","""Application of an automated aircraft architecture generation and analysis tool to unmanned aerial vehicle subsystem designProceedings of the Institution of Mechanical Engineers, Part G: Journal of Aerospace Engineering - David M Judt, Craig P Lawson, 2015""","""Howe, D. Aircraft conceptual design synthesis, London: Professional Engineering Publishing Limited, 2000. Google Scholar , Crossref\n3.\nMattingly, D, Heiser, WH, Pratt, DT. Aircraft engine design, 2nd ed. AIAA Education Series. Reston, VA: AIAA, 2003. Google Scholar\n4.\nMoir, I, Seabridge, A. Design and development of aircraft systems: An introduction, 2nd ed. London: Professional Engineering Publishing Limited, 2012. Google Scholar , Crossref\n5.\nMoir, I, Seabridge, A. Aircraft systems: Mechanical, electrical, and avionics subsystems integration, 3rd ed. New York: Wiley, 2011. Google Scholar\n6.\nMavris D, Tenorio C and Armstrong M. A methodology for aircraft systems architecture definition. In: 46th AIAA aerospace sciences meeting, Reno, Nevada, 7–10 January 2008. Google Scholar\n7.\nMavris D, Tenorio C and Armstrong M. Architecture subsystem sizing and coordinated optimization methods. In: 47th AIAA aerospace sciences meeting, Orlando, FL, USA, January 2009. Google Scholar\n8.\nArmstrong M. A process for function based architecture definition and modeling. MSc Thesis, Georgia Institute of Technology, USA, 2008. Google Scholar\n9.\nJudt DM and Lawson CP. Methodology for automated aircraft systems architecture enumeration and analysis. In: AIAA ATIO Conference, Indianapolis, Indiana, USA, 2012. Google Scholar\n10.\nLiscouet-Hanke S. A simulation framework for aircraft power systems architecting. In: ICAS, Anchorage, Alaska, 2008. Google Scholar\n11.\nLiscouet-Hanke S. A model-based methodology for integrated preliminary sizing and analysis of aircraft power system architectures. PhD Thesis, Université de Toulouse, 2008. Google Scholar\n12.\nTenorio C. Methods for collaborative conceptual design of aircraft power architectures. PhD Thesis, Georgia Institute of Technology, USA, 2010. Google Scholar\n13.\nOlvander J, Lunden B and Gavel H. A computerized optimization framework for the morphological matrix applied to aircraft conceptual design. Comput-Aid Des 2009; 41: 187–196. Google Scholar\n14.\nGavel H, Oelvander J, Johansson B, et al. Aircraft fuel system synthesis aided by interactive morphology and optimization. In: 45th AIAA Aerospace sciences meeting, Reno, Nevada, 2007. Google Scholar\n15.\nSafavi E, Gopinath V, Olvander J, et al. A collaborative tool for conceptual aircraft systems design. In: AIAA Modeling and simulation technologies conference, Minneapolis, Minnesota, 2012. Google Scholar\n16.\nChepko A, Weck O, Linne D, et al. Architecture modeling of in-situ oxygen production and its impacts on lunar campaigns. In: AIAA SPACE 2008 conference & exposition, San Diego, California, 2008. Google Scholar\n17.\nPate D, Patterson M and German B. Methods for optimizing a family of reconfigurable aircraft. In: 11th AIAA Aviation technology, integration and operations, Virginia Beach, VA, USA, 20–22 September 2011. Google Scholar\n18.\nVilleneuve F. A method for concept and technology exploration of aerospace architectures. PhD Thesis, Georgia Institute of Technology, USA, 2007. Google Scholar\n19.\nZeidner L, Rock B, Desai N, et al. Application of a technology screening methodology for rotorcraft alternative power systems. In: 48th AIAA Aerospace sciences meeting, Orlando, Florida, 2010. Google Scholar\n20.\nDorigo, M, Gambardella, LM. Ant colonies for the traveling salesman problem. Biosystems 1997; 43(2): 73–81. Google Scholar , Crossref , Medline\n21.\nJudt DM. Methods for automated aircraft systems architecture generation, analysis and selection. PhD Thesis, Cranfield University, UK, 2014. Google Scholar\n22.\nSAE International. Guidelines and methods for conducting the safety assessment process on civil airborne systems and equipment. Aerospace Recommended Practice 4761, Issued 1996 – 12, 1996. Google Scholar\n23.\nSAE International. Certification considerations for highly-integrated or complex aircraft systems. Aerospace Recommended Practice 4754, Issued 1996 – 11, 1996. Google Scholar\n24.\nINCOSE. Systems engineering handbook v.3, 2006. Google Scholar\n25.\nInternational Standard. Systems and software engineering – Systems life cycle processes. ISO/IEC 15288, 2008. Google Scholar\n26.\nMoir, I, Seabridge, A. Design and development of aircraft system, 2nd ed. New York: Wiley, 2013. Google Scholar\n27.\nHZ-20 thermoelectric module datasheet. San Diego, CA: Hi-Z Technology, Inc., 2002. Google Scholar\n28.\nFleming J, Ng W and Ghamaty S. Thermoelectric power generation for UAV applications. In: 1st International energy conversion engineering conference, Portsmouth, Virginia, 2003. Google Scholar\n29.\nNavid, A, Vanderpool, D, Bah, A. Towards optimization of a pyroelectric energy converter for harvesting waste heat. Int J Heat Mass Transfer 2010; 53: 4060–4070. Google Scholar , Crossref\n30.\nStirling engine assessment. Palo Alto, CA: EPRI, 2002. Google Scholar\n31.\nWood JG and Lane N. Advanced 35 W free-piston stirling engine for space power applications. Space Technology and Applications International Forum–STAIF, Albuquerque, New Mexico, 2003. Google Scholar\n32.\nGeankoplis, CJ. Transport processes and separation process principles, 4th ed. Englewood Cliffs, NJ: Prentice Hall, 2003. Google Scholar\n33.\nSpiegel, C. PEM fuel cell modeling and simulation using MATLAB, 1st ed. San Diego, CA: Academic Press, 2008. Google Scholar\n34.\nXiaojin, L, Yu, X, Zhigang, S. Mass minimization of a discrete regenerative fuel cell (RFC) system for on-board energy storage. J Power Sources 2010; 195: 4811–4815. Google Scholar , Crossref\n35.\nFederal Aviation Regulations, Part 25: Airworthiness standards: Transport category. Google Scholar\n36.\nLapeña-Rey N, Mosquera J, Bataller E, et al. First fuel-cell manned aircraft. J Aircraft 2010; 47(6): 1825–1835. Google Scholar\n37.\nRomeo G, Moraglio I and Novarese C. ENFICA-FC: Preliminary survey & design of 2-seat aircraft powered by fuel cells electric propulsion. In: 7thAIAA Aviation technology, integration and operations conference, Belfast, Northern Ireland, 18–20 September 2007. Google Scholar\n38.\nRoss H. Fly around the world with a solar powered airplane. In: 26th Congress of international council of the aeronautical sciences (ICAS), Anchorage, Alaska, 14–19 September 2008. Google Scholar\n39.\nhttp://www.solarimpulse.com/en/airplane (accessed December 2013). Google Scholar\n40.\nRichardson TD. Phantom eye – accelerated air vehicle structural development through prototyping. In” 53rd AIAA/ASME/ASCE/AHS/ASC Structures, structural dynamics and materials conference, Honolulu, Hawaii, 2012. Google Scholar\n41.\nhttp://www.avinc.com/uas/stratospheric/global_observer/ (accessed March 2014). Google Scholar\n42.\nSachs G, Lenz J and Holzapfel F. Unlimited endurance performance of solar UAVs with minimal or zero electric energy storage. In: AIAA Guidance navigation and control conference, Chicago, Illinois, 2009. Google Scholar\n43.\nMontagnier O and Bovet L. Optimization of a solar-powered high altitude long endurance UAV. In: 27th International congress of the aeronautical sciences, Nice, France, 2010. Google Scholar\nVol 229, Issue 9, 2015\nFramework setting in traditional design practice\nFramework application\n""","0.38127205","""http://journals.sagepub.com/doi/10.1177/0954410014558691""","[-0.629225,52.074389]"
"""UCL""","""Iris Publication""","""Log In\nPlease report any queries concerning the funding data grouped in the sections named \""Externally Awarded\"" or \""Internally Disbursed\"" (shown on the profile page) to           your Research Finance Administrator. Your can find your Research Finance Administrator at http://www.ucl.ac.uk/finance/research/post_award/post_award_contacts.php by entering your department\nPlease report any queries concerning the student data shown on the profile page to:\nExploratory visualisation of congestion evolutions on urban transport networks\nPublication Type:\nCheng T, Tanaksaranond G, Brunsdon C, Haworth J\nPublication date:\nTransportation Research Part C: Emerging Technologies\nVolume:\n""","0.89567053","""http://iris.ucl.ac.uk/iris/publication/1104362/13""",
"""UCL""","""Iris Publication""","""Log In\nPlease report any queries concerning the funding data grouped in the sections named \""Externally Awarded\"" or \""Internally Disbursed\"" (shown on the profile page) to           your Research Finance Administrator. Your can find your Research Finance Administrator at https://www.ucl.ac.uk/finance/research/rs-contacts.php by entering your department\nPlease report any queries concerning the student data shown on the profile page to:\nTransport modelling: carbon, cold starts, speed, and congestion modelling with National Travel Survey data\nPublication Type:\n""","0.89374804","""http://iris.ucl.ac.uk/iris/publication/1066408/1""",
"""University_of_Southampton""","""Taking the Bus: Incorporating Public Transport Timetable Data into Health Care Accessibility ModellingEnvironment and Planning A - David Martin, Hannah Jordan, Paul Roderick, 2008""","""PDF\nAbstract\nThis paper is concerned with geographical access to hospital services by public transport. By taking advantage of newly available public transport timetable data, a software tool is developed for the analysis of bus travel times under specified journey scenarios. The example of population access to Derriford Hospital in Devon, England, is used to illustrate the application of these methods, and the social and spatial pattern of accessibility by bus is explored. The analysis reveals substantial differences between access by public and private transport, and highlights the difficulty of combining conventional drive-time analysis with the discontinuous accessibility provided by public transport. There is a need for more attention to be paid to the incorporation of public transport in accessibility modelling.\nReferences\nSection:\nArcury, T A, Gesler, W M, Preisser, J S, Sherman, J, Spencer, J, Perin, J, 2005, “The effects of geography and spatial behaviour on health care utilization among the residents of a rural region” Health Services Research 40 135–156 Google Scholar , Crossref , Medline\nBlythe, P T, 2004, “Congestion charging: challenges to meet the UK policy objectives” Review of Network Economics 3 356–370 Google Scholar , Crossref\nChristie, S, Fone, D, 2003, “Equity of access to tertiary hospitals in Wales: a travel time analysis” Journal of Public Health Medicine 25 344–350 Google Scholar , Crossref , Medline\nCloke, P, Milborne, P, Thomas, C, 1997, “Living lives in different ways? Deprivation, marginalization and changing lifestyles in rural England” Transactions of the Institute of British Geographers, New Series 22 210–230 Google Scholar\nDamiani, M, Propper, C, Dixon, J, 2005, “Mapping choice in the NHS: cross sectional study of routinely collected data” British Medical Journal 330 284 Google Scholar , Crossref , Medline\nDETR, 2000 Our Countryside: The Future. A Fair Deal for Rural England Department of the Environment, Transport and the Regions (The Stationery Office, London) Google Scholar\nDfT, 2004, “Smarter choices: changing the way we travel”, Department for Transport, London, http://www.dft.gov.uk/stellent/groups/dft_control/documents/contentservertemplate/dft_index.hcst?n=13850&1=2 Google Scholar\nExworthy, M, Washington, A E, 2006, “Organizational strategies to tackle health care disparities in the USA” Health Services Management Research 19 44–51 Google Scholar , Link\nFortney, J, Rost, K, Warren, J, 2000, “Comparing alternative methods of measuring geographic access to health services” Health Services and Outcomes Research Methodology 1 173–184 Google Scholar , Crossref\nGulliford, M, Figueroa-Munoz, J, Morgan, M, Hughes, D, Gibson, B, Beech, R, Hudson, M, 2002, “What does access to health care mean?” Journal of Health Services Research and Policy 7 186–188 Google Scholar , Link\nHandy, S, Niemeier, D, 1997, “Measuring accessibility: an exploration of issues and alternatives” Environment and Planning A 29 1175–1194 Google Scholar , Link\nHaynes, R, Lovett, A, Sünnenberg, G, 2003, “Potential accessibility, travel time, and consumer choice: geographical variations in general medical practice registrations in Eastern England” Environment and Planning A 35 1733–1750 Google Scholar , Link\nHaynes, R, Jones, A P, Sauerzapf, V, Zhao, H, 2006, “Validation of travel times to hospital estimated by GIS” International Journal of Health Geographies 5 40 Google Scholar , Crossref , Medline\nHiggs, G, 2005, “A literature review of the use of GIS-based measures of access to health care services” Health Services and Outcomes Research Methodology 5 119–139 Google Scholar , Crossref\nHumphries, J S, Wakerman, J, Wells, R, 2006, “What do we mean by sustainable rural health services? Implications for rural health research” Australian Journal of Rural Health 14 33–35 Google Scholar , Crossref , Medline\nJoseph, A E, Phillips, D R, 1984 Accessibility and Utilization: Geographical Perspectives on Health Care Delivery (Harper and Row, New York) Google Scholar\nLove, D, Lindquist, P, 1995, “The geographical accessibility of hospitals to the aged: a geographic information systems analysis within Illinois” Health Services Research 29 629–651 Google Scholar , Medline\nLovett, A, Haynes, R, Sünnenberg, G, Gale, S, 2002, “Car travel time and accessibility by bus to general practitioner services: a study using patient registers and GIS” Social Science and Medicine 55 97–111 Google Scholar , Crossref , Medline\nLovett, A, Sünnenberg, G, Haynes, R M, 2003, “Accessibility to GP surgeries in South Norfolk: a GIS-based assessment of the changing situation 1997–2000”, in Socio-Economic Application of Geographic Information Science Innovations in GIS 9, Eds Kidner, D, Higgs, G, White, S (Taylor and Francis, London) pp 181–198 Google Scholar , Crossref\nMartin, D, Roderick, P, Diamond, I, Clements, S, Stone, N, 1998, “Geographical aspects of the uptake of renal replacement therapy in England” International Journal of Population Geography 4 227–242 Google Scholar , Crossref\nMartin, D, Wrigley, H, Barnett, S, Roderick, P, 2002, “Increasing the sophistication of access measurement in a rural healthcare study” Health and Place 8 3–13 Google Scholar , Crossref , Medline\nNess, M, 2000, “ATCO file format for interchange of timetable data”, Atkins, W S, http://www.atco.org.uk/itdocs/images/atco-cif-spec.pdf Google Scholar\nNoble, M, Penhale, B, Smith, G, Wright, G, 1999, “Measuring multiple deprivation at the local level”, Department of Applied Social Studies and Social Research, University of Oxford, Oxford, http://www.communities.gov.uk/pub/458/MeasuringmultipledeprivationatthelocallevelPDF218Kb_id1128458.pdf Google Scholar\nODPM, 2004, The English Indices of Deprivation 2004 Office of the Deputy Prime Minister, London, http://www.communities.gov.uk/pub/446/lndicesofdeprivation2004revisedPDF2198Kb_id1128446.pdf Google Scholar\nONS, Office for National Statistics, Titchfield, Hants Google Scholar\n2001a Census: Census Area Statistics (England and Wales) Google Scholar\n2001b Census: Digitised Boundary Data (England and Wales) computer file Google Scholar\n2004 All Fields Postcode Directory 2004 User Guide Google Scholar\nPhibbs, C, Luft, H, 1995, “Correlation of travel time on roads versus straight line distance” Medical Care Research and Review 52 532–542 Google Scholar , Link\nSchuurman, N, Fiedler, R S, Grzybowski, S C W, Grund, D, 2006, “Defining rational hospital catchments for non-urban areas based on travel time” International Journal of Health Geographies 5 43 Google Scholar , Crossref , Medline\nSEU, 2003 Making the Connections: Final Report on Transport and Social Exclusion Social Exclusion Unit, Office of the Deputy Prime Minister, London Google Scholar\nSherwood, K B, Lewis, G J, 2000, “Accessing health care in a rural area: an evaluation of a voluntary medical transport scheme in the English Midlands” Health and Place 6 337–350 Google Scholar , Crossref , Medline\nTownsend, P, Phillimore, P, Beattie, A, 1988 Health and Deprivation: Inequality and the North (Croom Helm, London) Google Scholar\nVickers, D, Rees, P, 2007, “Creating the National Statistics 2001 output area classification” Journal of the Royal Statistical Society, Series A: Statistics in Society 170 379–403 Google Scholar , Crossref\nWaters, N, 1999, “Transportation GIS: GIS-T”, in Geographical Information Systems, Principles, Techniques, Applications and Management 2nd edition, Eds Longley, P A, Goodchild, M F, Maguire, D J, Rhind, D W (John Wiley, Chichester, Sussex) pp 827–844 Google Scholar\n""","0.40398246","""http://journals.sagepub.com/doi/10.1068/a4024""","[-1.395685,50.934189]"
"""Brunel_University_London""","""On the need for bump event correction in vibration test profiles representing road excitations in automobilesProceedings of the Institution of Mechanical Engineers, Part D: Journal of Automobile Engineering - A Steinwolf, J A Giacomin, W J Staszewski, 2002""","""Baddeley A. Human Memory: Theory and Practice, 1997 (Psychology Press, Hove, East Sussex). Google Scholar\n2.\nShinozuka M., Jan C.-M. Digital simulation of random processes and its applications J. Sound Vibr., 1972, 25, 111–128. Google Scholar Crossref\n3.\nCrolla D. A., Soliman A., Elsayed F. M., Elalaily M. M. Experimental results from a slow-active suspension system Int. J. Veh. Des., 1993, 14 (2–3), 226–245. Google Scholar\n4.\nSherratt F. Current applications of frequency domain fatigue life estimation Environ. Engng, December 1996, 12–20. Google Scholar\n5.\nSteinwolf A. Shaker simulation of random vibration with a high kurtosis value J. IES, 1997, 40 (3), 33–43. Google Scholar\n6.\nSteinwolf A. Approximation and simulation of probability distributions with a variable kurtosis value Comput. Statist. Data Analysis, 1996, 21 (2), 163–180. Google Scholar Crossref\n7.\nSmallwood D. O. Generation of stationary non-Gaussian time histories with a specified cross-spectral density Shock Vibr., 1997, 4, 361–377. Google Scholar Crossref\n8.\nMerritt R. G. A stochastic model for the pulse method-part 2: random part. In Proceedings of the 43rd IES Annual Technical Meeting, Los Angeles, California, 1997, pp. 121–129. Google Scholar\n9.\nConnon W. H. Comments on kurtosis of military vehicle vibration data J. IES, 1991, 34 (5), 38–41. Google Scholar\n10.\nCharles D. Derivation of environment descriptions and test severities from measured road transportation data Environ. Engng, December 1992, 30–32; March 1993, 25–26. Google Scholar\n11.\nGiacomin J. A., Steinwolf A., Staszewski W. J. A vibration mission synthesis algorithm for mildly non-stationary road data. In Proceedings of the Sixth ATA International Conference, Florence, 1999. Google Scholar\n12.\nGiacomin J., Bracco R. An experimental approach for the vibration optimisation of automotive seats. In Proceedings of the Third ATA International Conference on Vehicle Comfort and Ergonomics, Bologna, 1995. Google Scholar\n13.\nChui Ch. K. An Introduction to Wavelets, Analysis and its Applications, Vol. 1, 1992 (Academic Press, Boston, Massachusetts). Google Scholar\n14.\nNewland D. E. Random Vibration, Spectral and Wavelet Analysis, 1993 (Longman, New York). Google Scholar\n15.\nStaszewski W. J., Giacomin J. A. Application of the wavelet based FRFs to the analysis of nonstationary vehicle data. In Proceedings of the 15th International Modal Analysis Conference, Orlando, Florida, 1997. Google Scholar\n16.\nLee S. K., White P. R. Application of wavelet analysis to the impact harshness of a vehicle Proc. Instn Mech. Engrs, Part C, Journal of Mechanical Engineering Science, 2000, 214 (C11), 1331–1338. Google Scholar Link\n17.\nDonoho D., Johnstone I. Ideal denoising in an orthonormal basis chosen from a library of bases C.R. Acad. Sci. Paris, 1994, Sér. I, 319, 1317–1322. Google Scholar\n18.\nStaszewski W. J. Wavelet based compression and feature selection for vibration analysis J. Sound Vibr., 1998, 211 (5), 735–760. Google Scholar Crossref\n19.\nHamming R. W. Digital Filters, 1983 (Prentice-Hall, Englewood Cliffs, New Jersey). Google Scholar\n20.\nMallat S. A Wavelet Tour of Signal Processing, 1998 (Academic Press, San Diego, California). Google Scholar\n21.\nGiacomin J. A., Steinwolf A., Staszewski W. J. An algorithm for mildly nonstationary mission synthesis (MNMS) Engng Integrity, 2000, 7, 44–56. Google Scholar\n""","0.63578176","""http://journals.sagepub.com/doi/10.1243/0954407021529110""","[-0.472855,51.532848]"
"""Aston_University""","""Green technologies in the automotive industry - Research Explorer : Aston University""","""Green technologies in the automotive industry\nResearch output: Chapter in Book/Report/Conference proceeding › Chapter\nSocial Responsibility Centre & Sustainability Group\nAbstract\nIn most of the discussions about environmental issues and policies, transportation is highlighted as one of the main sources of pollutant emissions and energy consumption. The attention given to the automotive industry is understandable in this context due to its size, expansion, presence in our daily lives, and of course its environmental impact. If we scrutinize the “greenness” of car manufacturers we will find issues of concern from the raw material use, production processes, use, and end-of-life of vehicles. The main issues for production are high consumption of energy, raw materials, water and the waste stream, which contains the four substances of concern (cadmium, lead, hexavalent chromium, mercury). In respect of carbon emissions and energy use the use of cars is the main phase of its life-cycle due to the combination of internal combustion engines with fossil fuels. The most recent pressure is aimed at the end-of-life vehicles (ELV). In addition to the pollution from vehicle use, traffic jams and car accidents continue to be part of the downside of a car culture. Landfills sites are becoming scarce and the contamination of soil and aquifers completes the picture.\n""","0.6757598","""https://research.aston.ac.uk/portal/en/researchoutput/green-technologies-in-the-automotive-industry(9554202d-8159-4044-b390-2f7a1d9c3134).html""","[-1.888803,52.487018]"
"""Imperial_College_London""","""Study of Permanent Shear Thinning of VM Polymer Solutions | SpringerLink""","""Study of Permanent Shear Thinning of VM Polymer Solutions\nAuthors\nH. A. Spikes Email author\nOpen Access\n2 Citations\nAbstract\nThe ultrashear viscometer (USV) has been adapted and employed to investigate the permanent shear thinning of polystyrene solutions in a series of phthalate ester base fluids. The permanent shear stability index based on viscosities measured at 106 s−1, PSSI(106), has been found to be a convenient way to express the magnitude of permanent shear thinning. When comparing permanent shear thinning at various shear rates in the USV, it is very important to take account of the different times of shear that are present at different shear rates. The PSSI(106) value divided by the total time of shear is then a useful way of quantifying and comparing permanent shear thinning rates. Tests using polystyrene in different viscosity base fluids have shown that this rate of permanent shear thinning depends on shear stress and not shear rate and varies linearly with polymer concentration. The rate of permanent shear thinning also varies exponentially with shear stress, suggestive of a stress-promoted polymer breakdown process. By using a small volume of test fluid in the USV and solvent extraction after a test, it has proved possible to obtain molecular weight distributions of polymer after shear using gel permeation chromatography (GPC). This indicates that the polymer breakdown process is different at low and high polymer concentrations, with molecule fragmentation at low polymer concentration but mid-chain scission at high concentration. A key feature of the USV is that, unlike other methods currently used to measure permanent shear thinning behaviour of engine oils, it subjects the test fluid to well-defined, controllable high shear conditions. Coupled with the use of GPC, this makes it possible for the first time to relate quantitatively the permanent shear thinning of engine oils to shear conditions and to polymer degradation response.\nKeywords\nDownload article PDF\n1 Introduction\nIn order to increase vehicle efficiency and thereby limit CO2 emissions, there is a general trend to use lower and lower viscosity engine lubricants in order to reduce hydrodynamic friction losses. While engine oil viscosity is controlled primarily by the viscosity of the base oil present, it is considerably modified by dissolved polymeric additives known as viscosity index improvers or viscosity modifiers (VMs). The prime function of these additives is to increase the viscosity index of their blends, but it is now recognised that they may also contribute to reducing hydrodynamic friction by undergoing temporary shear thinning at the high shear rates present in some engine components. Unfortunately, while temporary shear thinning may be desirable, it is often accompanied by permanent shear thinning resulting from the scission of polymer molecular chains at high shear rates, and this is always undesirable. We thus require viscosity modifiers that show considerable temporary but very little permanent shear thinning.\nThis paper explores some aspects of permanent shear thinning of polymer solutions. First previous work on the permanent shear thinning of polymer solutions is outlined. This is followed by new experimental work in which an ultrashear viscometer (USV) is used to subject polymer solutions of viscosities comparable to those of engine oils to well-defined shear conditions. Using a range of different viscosity base fluids, it is confirmed that permanent shear thinning is controlled by applied shear stress rather than shear rate. A method is then developed that is able to extract and analyse the very small amount of sheared fluid in a USV to explore the molecular nature of the polymer breakdown that causes permanent shear thinning.\n2 Background\nIt has long been known that solutions of high molecular weight polymers can show permanent shear thinning (permanent viscosity loss) when subject to high shear conditions. Thus a patent of 1937 describes both the milling of polymeric lubricating oil additives to reduce their average molecular weight and the development of a “shear viscosity breaking test” to assess the stability of viscosity-index-improved oils [ 1 ]. Throughout the 1950s to 1970s, there was considerable research work on permanent shear thinning with respect to both the mastication of solid polymers and viscosity loss of polymer solutions. Three useful reviews in the 1970s summarise the state of knowledge at this time [ 2 , 3 , 4 ]. Mackenzie and Jemmett noted the development of an early rule of thumb, that hydrocarbon-based polymer breakdown in solution is likely to occur when;\n$$ {\\text{solution}}\\;{\\text{viscosity}} \\times {\\text{shear}}\\;{\\text{rate}} \\times {\\text{MWt}}^{2} > \\, 1 \\times 10^{14} $$\n(1)\nwhere viscosity has units Poise, shear rate s−1, and MWt is the weight average molecular weight in g/mol. In the light of recent knowledge, this must be regarded as highly approximate—for example, it does not take any account of polymer architecture. It does, however, indicate the importance of molecular weight and viscosity in promoting permanent shear thinning.\nSince the shear stress is the product of viscosity and shear rate, the above expression also suggests that it may be shear stress rather than shear rate that controls polymer breakdown. This question has been a matter of some debate. Early studies focused on the influence of shear rate on polymer breakdown and thus tended to give the impression that this was the driving factor [ 5 , 6 , 7 ]. However, the development of models to describe polymer breakdown [ 8 ] and also the observation that the rate of permanent shear thinning generally decreased with increasing temperature [ 9 , 10 ] and increased with increasing viscosity [ 11 ] led to the gradual recognition that polymer breakdown might be dependent on the shear stress present in solution. This was confirmed by Yu et al. [ 12 ], who compared permanent shear thinning of polymer solutions in different viscosity base oils and found that it was more rapid in high-viscosity oils, in accord with it being controlled by shear stress rather than shear rate.\nFrom Eq.  1 , it can be very roughly estimated that, for a 10 cP solution of 105 MWt polymer, a shear rate of at least 106 s−1 is required for permanent shear thinning to occur. Such shear rates are difficult to obtain in conventional laminar flow viscometers and led to the early development of ultrasonic [ 13 , 14 ], orifice [ 5 ], and engine bench test [ 15 ] methods of obtaining measurable permanent shear thinning. Studies were also carried out using capillary [ 16 , 17 ] and concentric cylinder [ 10 , 18 , 19 ] viscometers, but these were generally employed to test very high molecular weight polymers whose solutions showed permanent viscosity loss at 104 or 105 s−1. They broadly confirmed the dependence of the onset of permanent viscosity loss on shear rate and molecular weight indicated by Eq.  1 .\nUp to the 1970s, there was considerable work to explore the mechanistic origins of permanent shear thinning. Early work by Frenkel [ 20 ], followed by an influential model of permanent shear thinning by Bueche [ 8 ], suggested that polymer molecule scission was most likely to occur at the central bond of a polymer chain due to the accumulation of stress at this location. In the 1960s the technique of gel permeation chromatography (GPC) was first applied to study the change in molecular weight distribution that accompanies permanent shear thinning. This gave variable results, with some studies and conditions producing a preponderance of fragments with half the molecular weight of the starting value [ 10 , 12 ] but others showing randomly sized fragments or the formation of predominantly low molecular weight species [ 19 ].\nAnother experimental technique introduced in the 1960s was the use of radical trapping to monitor the rate of polymer bond breaking due to shear [ 21 , 22 , 23 ]. This is a potentially powerful technique but it was shown that the presence of such traps can increase the rate of polymer degradation by inhibiting the reformation of broken bonds, a role also accomplished by oxygen [ 24 ].\nVarious molecular-based models have been developed to describe the way that applied shear causes polymer scission, of which the most influential are those of Beuche [ 8 ] and de Gennes [ 25 ]. Both of these are based on the concept of stress-augmented thermal activation in which the activation energy in the normal Arrhenius rate equation is reduced by a mechanical work term originating from the action of applied force on molecular bonds, so that the rate of bond scission, R, depends on\n$$ R = K{\\text{e}}^{{ - \\left( {E - F\\delta } \\right)/k_{\\text{B}} T}} $$\n(2)\nwhere E is the energy needed to break the bond, F is the tensile force applied to the bond and δ is a distance approximately equal to the distance the bond will stretch before breaking. K is a prefactor, k B the Boltzmann constant, and T the absolute temperature. For polymers, the force F depends on a friction factor that describes the viscous force applied to a polymer segment and on the number of segments over which this force accumulates [ 8 ].\nSince the 1970s, research on permanent shear thinning has been more fragmentary, especially concerning the breakdown of viscosity modifier additives. The main focus has been practical, i.e., on refining and correlating polymer breakdown tests with performance in engine [ 26 , 27 , 28 , 29 , 30 ], automatic transmission [ 31 ], hydraulic [ 32 ], and gear [ 33 ] systems. This is most problematic with respect to engine oils since many other factors influence change of viscosity during use including fuel dilution and oxidation [ 34 ]. In addition to engine tests, three main bench tests have emerged, based, respectively, on a diesel injector [ 35 ], sonic degradation [ 36 ] and a taper roller bearing [ 37 ]. Mortier has compared the main bench test methods for measuring shear stability of VM-containing lubricants [ 38 ]. In most bench tests, viscosity loss is quantified by comparing the low shear rate viscosity of the test lubricant before and after severe shearing, but Alexander has noted that in terms of engine performance it might be more relevant to compare the high shear rate viscosities of the sheared and unsheared oils [ 39 ].\nMost comparisons of different test methods for assessing permanent shear stability find that those where the lubricant is subject to elastohydrodyamic (EHD) conditions, such as in rolling bearings and gears, give higher levels of permanent viscosity loss than injector tests [ 31 , 40 ]. This is to be expected on the basis that shear stress drives polymer breakdown, since the high pressures in EHD contacts result in large increases in lubricant viscosity and thus high shear stresses, even at quite low shear rates. In an ingenious study, Walker et al. extracted small volumes of polymer-containing and polymeric lubricants from a sliding EHD contact and, based on viscosity loss and GPC, found very severe breakdown of the polymers [ 41 ].\nMany studies have compared the shear stability of different VM types, though Mortier has noted that the ranking varies depending on the test employed [ 38 ]. Covitch has studied the influence of polymer molecular architecture on shear stability and found strong dependence on polymer structure, with star polymers giving greater stability than linear ones, with branched structures intermediate [ 42 ].\nRecently there has been growing interest in the influence of polymer shear stability on fuel economy of engine oils, and van Dam has shown that fuel economy of heavy-duty engine oils correlates with the high temperature viscosity of the oils as measured after extraction from engine tests or after an injector test [ 43 , 44 ]. This is not unexpected but does suggest that fuel economy prediction models should be based, at least in part, on the properties of degraded rather than fresh oils.\nCompared with early work, the main focus of VM work in recent years has been on permanent changes in viscosity resulting from shear, with less consideration of the causative molecular weight reductions produced by high shear, although a few researchers have continued to apply GPC to analyse shear thinned oils [ 27 , 41 ]. Herbeaux et al. noted that for dilute polymer solutions the specific viscosity, η sp, and thus the polymer solution viscosity η are proportional to the concentration c and weight average molecular weight \\( \\bar{M}_{\\text{w}} \\);\n$$ \\eta_{\\text{sp}} = \\frac{\\eta }{{\\eta_{\\text{base}} }} - 1 = Kc\\bar{M}_{\\text{w}} $$\n(3)\nwhere η base is the base oil viscosity [ 45 ]. They used this, together with a model of how MWt changes with shearing time, to develop and apply a model for how viscosity should vary during shearing tests. Covitch et al. also used a similar, though somewhat more complex approach applicable to more concentrated, semidilute, polymer solutions, to develop a model of viscosity loss of heavy-duty diesel lubricants;\n$$ \\eta_{\\text{sp}} = k^{\\prime } c\\bar{M}_{\\text{w}}^{a} + k^{\\prime \\prime } c^{2} \\bar{M}_{\\text{w}}^{a} $$\n(4)\nwhere k′, k″ and a are constants, with a having the value 1.1 [ 46 ].\nFundamental research on polymer breakdown under shear outside of the VM literature has continued since the 1970s, with particular emphasis on polymer response to different types of flow field. In laminar shear, the fluid is exposed to a combination of rotation and deformation and this combination is relatively benign in terms of the forces experienced by polymer chains in solution. Odell et al. studied polymer breakdown in pure elongation flow and found very rapid polymer breakdown to occur above a critical shear rate that could be related to the relaxation time of the polymer molecules [ 47 , 48 , 49 ]. GPC showed rupture of molecules at or close to the central bond and a critical shear rate for rupture that was inversely proportional to the square of the MWt, reminiscent of Eq.  1 . These researchers interpreted their findings in terms of the stress-augmented thermal activation described by Eq.  2 [ 48 ]. Recently Vanapalli et al. [ 50 ] have examined polymer breakdown in turbulent flow and developed general scaling rules for polymer breakdown. In non-turbulent conditions, they suggest that the onset of polymer scission depends linearly on the viscosity while in turbulent flow this dependence is much weaker at η 0.25, due to tension-inducing velocity fluctuation in the flow. By analysing previous literature on polymer shear degradation, they concluded that many studies that were presumed to be in laminar flow must actually have involved some turbulence, for example at the inlet and outlet of capillaries, and that it should be very difficult to obtain polymer scission in pure laminar flow.\nFrom the above, it can be seen that the extensive literature on polymer permanent shear thinning of polymer solutions can be divided broadly into two groups, work looking specifically at VM polymer solutions and more fundamental studies of polymer scission under shear. Considering all of the research conducted, it is perhaps surprising that we still have no ability to predict VM polymer degradation and consequent viscosity loss and are thus reliant on bench tests. There are several key problems. One is that almost all studies of VM polymer degradation are carried out in spray nozzles, rolling bearings or ultrasonic systems where permanent shear thinning can be quite easily achieved. However, the shear rate and indeed the shear conditions in most such devices are impossible to quantify accurately so that results from such studies cannot be interpreted at a fundamental level. Also in many tests carried out on these devices, only a fraction of the fluid actually passes through the high shear system from where it is returned to a reservoir. This makes analysis of the rate of polymer breakdown and the effect of this on overall viscosity change very difficult to analyse, although valiant attempts have been made to do so [ 51 , 52 , 53 ].\nTo be relevant to polymer degradation in the highly laminar flow conditions likely to be present in thin film plain bearing conditions, polymer degradation should be studied at such conditions, though it is interesting to note that physics-based studies of polymer degradation suggest that little polymer breakdown ought to take place in laminar flow [ 49 ]. One possibility is to use capillary flow, but this gives a variation of shear rate across the diameter, and it has also been shown that polymer degradation is dominated by the conditions at the capillary inlet [ 54 ]. Another important issue in studies of polymer breakdown using capillaries and orifices is that, unless a series of carefully chosen capillaries of different diameters are used, solutions flowing at high shear rate will spend less time in a capillary than those flowing at low shear rate. This has to be taken into account when comparing polymer degradation rates, which should describe how much degradation occurs per unit time of shear rather per pass through the capillary.\nThe most promising alternative to a capillary is a narrow gap concentric cylinder or truncated cone geometry. Viscometers based on this geometry have been employed since the 1980s to measure the viscosity of lubricants up to 106 s−1 [ 55 , 56 ] and, more recently, up to 107 s−1 [ 57 ]. In a recent study, it was shown that the application of shear rates above 106 s−1 in a concentric cylinder viscometer results in significant permanent viscosity loss of polymer solutions and that this can be used to compare the shear stability of VMs [ 58 ]. From the point of view of fundamental research, a key limitation of this type of viscometer is that the volume of fluid being sheared is very small and quite inaccessible. This makes it problematic to use chemical methods such as GPC to study the sheared sample posttest. An ingenious way around this problem was employed by Porter et al. [ 19 ], who used a continuous flow of test fluid through a concentric cylinder gap.\nThe current paper describes work in which a high shear rate concentric viscometer is employed to study polymer breakdown in solution at high shear rates. Care is taken when comparing polymer breakdown rates to compensate for the different times that fluids are sheared at different shear rates. A series of different base fluids having very similar chemical structure but with different viscosities is used to confirm previous studies and show that polymer degradation rate depends on shear stress and not shear rate. Finally, a method is developed to extract the sheared volume of fluid from the concentric viscometer and analyse it using GPC.\n3 Materials\nIn order to explore the mechanism of permanent shear thinning, well-characterised polymers with low polydispersity are desirable. Polystyrenes were chosen since these are commercially available as chromatography standards at a series of molecular weights and with polydispersity indices below 1.04. Since these polymers do not dissolve in predominantly aliphatic base oils such as mineral oils, phthalate esters were used as solvents. The aromatic structure of these fluids mean that they are good solvents for polystyrene while, because they are widely used as plasticisers, they are commercially available in pure form with a series of alkyl groups and thus viscosities.\nTable  1 lists the phthalate ester solvents used as base oils and their viscometric properties, Table  2 lists the polystyrene polymers, and Table  3 shows the solutions studied and their low shear rate viscometric properties.\nTable 1\n4 Test Methods\n4.1 Ultrashear Viscometer Method\nPermanent shear thinning was measured using a method devised by Holtzinger et al. [ 58 ] and further developed in the current study. This employs a PCS Instruments Ultra Shear Viscometer (USV) to subject a small lubricant sample to a very high shear rate at controlled temperature.\nThe USV is based on a concentric cylinder geometry with a very small gap of typically between 1 and 1.5 μm. Normally, viscometers with such geometry are limited to a maximum shear rate of ca 106 s−1 since above this level the temperature rise due to shear heating becomes excessive. In the USV this problem is overcome by using a very short shearing time to ensure any such temperature rise is very small. A motor accelerates a flywheel to high speed and then a clutch system engages to transmit the rotational energy to the inner cylinder (rotor) for just a few revolutions at a set shear rate. Depending on the lubricant viscosity and thus the shear stress applied, a small amount of shear heating can still occur within this time frame, but the USV is able to measure the increase in temperature on the stator and, using heat transfer theory, estimate the temperature rise within the contact. The temperature of the chamber is then reduced slightly using this temperature offset to ensure that in the next engagement the lubricant sample reaches the sought test temperature just when the viscosity is measured.\nIn the USV, a series of engagements is generally made, namely one to obtain the temperature offset and then three consecutive engagements for measurement. A torque sensor is fitted to the outer concentric cylinder (stator), and the average measurements of the last three engagements are used to determine a viscosity value. Holtzinger et al. [ 58 ] defined this process as one cycle but in the current study, in order to more accurately describe the shear history of the test sample, each engagement will be termed one shear cycle, so there will be four shear cycles for every data point measured.\nAs found previously by Holtzinger, most high MWt polymer-containing test samples show a progressive fall in viscosity in the USV at high shear rates due to permanent shear thinning.\nFigure  1 compares the reduction in viscosity against number of shear cycles at two applied shear rates, 3 × 106 and 6 × 106 s−1 for a 2 wt% solution of 100 k g/mol MWt PS in DEHP at 80 °C.\nOpen image in new window\nFig. 2\nGPCs of different volumes of unsheared 2 wt% solution of 200 k PS in DEHP extracted from the USV using THF\n5 Quantification and Interpretation of Permanent Shear Thinning\nIn most studies of permanent shear thinning the level of permanent viscosity loss of VM solutions is quantified by a non-dimensional value, of which the two most common are the permanent viscosity loss (PVL) and the permanent shear stability index (PSSI). These are defined in terms of the kinematic viscosities at 100 °C of the sheared (KVsheared), unsheared (KVfresh), and base oil (KVbase).\n$$ {\\text{PVL}} = \\frac{{{\\text{KV}}_{\\text{fresh}} - {\\text{KV}}_{\\text{sheared}} }}{{{\\text{KV}}_{\\text{fresh}} }} $$\n(5)\n$$ {\\text{PSSI}} = \\frac{{{\\text{KV}}_{\\text{fresh}} - {\\text{KV}}_{\\text{sheared}} }}{{{\\text{KV}}_{\\text{fresh}} - {\\text{KV}}_{\\text{base}} }} $$\n(6)\nPVL thus describes the fractional loss of polymer solution viscosity due to shear while PSSI is the fraction of the original thickening by the polymer that is lost due to shear.\nIt is not possible to evaluate the above two measurements of permanent shear thinning in the USV since it is not possible to extract enough sample to measure its KVsheared. It is, however, possible to measure the viscosity at 106 s−1 within the USV after degradation. Therefore, as was suggested by Holtzinger et al. [ 58 ], the two expressions equivalent to PVL and PSSI were calculated in this study:\n$$ {\\text{PVL}}\\left( {10^{6} } \\right) = \\frac{{\\eta_{\\text{fresh}} - \\eta_{\\text{sheared}} }}{{\\eta_{\\text{fresh}} }} $$\n(5)\n$$ {\\text{PSSI}}\\left( {10^{6} } \\right) = \\frac{{\\eta_{\\text{fresh}} - \\eta_{\\text{sheared}} }}{{\\eta_{\\text{fresh}} - \\eta_{\\text{base}} }} $$\n(6)\nwhere η sheared is the dynamic viscosity measured in the USV at 106 s−1 and the test temperature after shearing, η fresh is the dynamic viscosity value measured in the USV at 106 s−1 and the test temperature before shearing and η base is the base oil dynamic viscosity at the test temperature.\nIt is important to note that neither PVL nor PSSI is a system property since both will depend on the conditions under which they are measured and on the viscosity of the base oil and the concentration of polymer [ 59 ]. PSSI is, however, much less dependent on concentration than PVL since it measures the fraction of polymer thickening lost rather than fraction of blend viscosity lost. PSSI(106) can also be expressed in terms of specific viscosities as defined in Eq.  3 as;\n$$ {\\text{PSSI}}\\left( {10^{6} } \\right) = \\frac{{\\eta_{\\text{sp,fresh}} - \\eta_{\\text{sp,sheared}} }}{{\\eta_{\\text{sp,fresh}} }} $$\n(7)\nwhere the polymer solution viscosities are measured at 106 s−1.\nEquation  7 relates the PSSI(106) to the specific viscosity at 106 s−1. Based on this, and assuming that the high-shear-rate-specific viscosity varies linearly with concentration and molecular weight, as indicated by Eq.  3 for low shear rate, and that we can sum the contributions to specific viscosity of the undegraded and degraded polymer, we obtain from Eq.  7 ;\n$$ {\\text{PSSI}}\\left( {10^{6} } \\right) = \\frac{{kc_{0} \\bar{M}_{\\text{w}} - \\left( {kc\\bar{M}_{\\text{w}} + k\\left( {c_{0} - c} \\right)\\bar{M}_{\\text{w,sheared}} } \\right)}}{{kc_{o} \\bar{M}_{\\text{w}} }} $$\n(8)\nor\n$$ {\\text{PSSI}}\\left( {10^{6} } \\right) = \\frac{{\\left( {c_{0} - c} \\right)\\left( {\\bar{M}_{\\text{w}} - \\bar{M}_{\\text{w,sheared}} } \\right)}}{{c_{0} \\bar{M}_{\\text{w}} }} $$\n(9)\nwhere c 0 and \\( \\bar{M}_{\\text{w}} \\) are the initial concentration and average molecular weight of the sample prior to shear, c is the concentration of the undegraded polymer after shear and \\( \\bar{M}_{\\text{w,sheared}} \\) is the average molecular weight of the sheared sample. It should be noted that polymer concentrations are based on weight, not number of molecules, so the increase in concentration of lower molecular weight polymer due to degradation will be identical to the reduction in concentration of the higher molecular weight polymer.\nThis suggests that the PSSI(106) should vary linearly with the reduction in concentration of the undegraded polymer and thus be proportional, at least in the early stages of degradation, to the rate of polymer scission.\n6 Permanent Shear Thinning Rate: Time Effect\nAs discussed in the background in this paper, when comparing shear thinning at different conditions, it is important to take account of any differences in the times that shear is applied to the fluid during a test when comparing rates of shear thinning. In the USV single cycle, the fluid shear force is monitored over 8 revolutions of the rotor. Prior to this, there is a short period of about 1.5 revolutions after the fluid has reached its set shear rate and torque has stabilized. Upon clutch disengagement, deceleration is very rapid. Since the rotor speed increases with increasing shear rate, so the time that the fluid is subjected to its set shear rate decreases with shear rate. Table  4 lists the estimated times for which the fluid is within 10% of its stabilized torque in a single cycle at different shear rates. To compare shear thinning rates at different shear rates, the measured loss of viscosity must be divided by this corresponding shear time. It should be noted that these times per cycle are calculated for the 1.28 μm gap used and will vary inversely with the gap size.\nTable 4\n7 Results\n7.1 Effect of Polymer Concentration and Molecular Weight on Viscosity at 106 s−1\nSince PVL(106) and PSSI(106) are based on measurements at 106 s−1, it is of interest to look at the way that polymer viscosity measured at this shear rate varies with polymer concentration and molecular weight prior to any permanent shear thinning. Three different MWt PS polymers were studied in solution in DEHP at 80 °C.\nFigure  3 shows the dependence of both viscosity and specific viscosity on concentration at 106 s−1. The specific viscosity is as defined in Eq.  3 except that the polymer solution viscosity is measured at 106 s−1. All solutions except for 4 and 6 wt% of 100 k PS in DEHP are in the dilute regime; for this polymer the transition from dilute to semidilute is around 3.5 wt% for 100 k PS in DEHP at low shear rate. As expected, both the viscosity and specific viscosity at 106 s−1 increase with polymer concentration and MWt. The dependence on concentration is practically linear up to 3 wt%, but greater than linear above this concentration. This type of dependence is similar to that of low shear rate viscosity.\nOpen image in new window\nFig. 16\nComparison of unsheared and sheared 10 wt% 200 k PS in DEHP at different shear rates and for different amounts of shear cycles at 80 °C. Black curve is the unsheared case\nAt first sight, it is counterintuitive that a concentrated solution gives primarily mid-chain scission while a low concentration gives fragmentation since one might expect a more concentrated solution with more direct polymer–polymer entanglement points to produce multiple rupture sites. The higher concentration solution will have higher viscosity and thus higher shear stress at a given strain rate. It is possible that at high shear stress a stress-augmented thermal activation process dominates to produce rapid mid-chain scission while at lower shear stress polymer degradation is much slower, and has a larger thermal activation component. To test this, an extended study with different shear stresses and at various temperatures would be necessary.\n8 General Discussion\nThis study has shown the utility of the USV to measure the permanent shear thinning of polymer solutions at high shear rates and thus high shear stresses. In practice, since it can measure the viscosity of liquids up to 20 cP at 107 s−1, the USV is able to apply shear stresses up to 0.2 MPa at this strain rate. This combination of shear rate and shear stress is much higher than in most viscometers and is only possible because the short duration of shear precludes significant shear heating. At such high shear stresses, considerable permanent shear thinning of the polystyrene polymer solutions studied occurs, and this can be monitored by subjecting the solution sample to repeated cycles of shear.\nOne limitation of this approach is that it is only possible to monitor the change in viscosity measured at high shear rate since insufficient shear-degraded fluid is available for low shear rate viscosity measurement. This can be viewed as a disadvantage or an advantage. It means that it is not straightforward to relate the results directly to polymer solution viscosity theory, especially in terms of the impact of molecular weight, since the measured viscosity will incorporate a temporary shear thinning effect of any polymer present. However, it has been suggested that the impact of polymer shear degradation measured at high shear rate is more relevant to engine friction than that measured at low shear rate [ 44 ].\nWhen interpreting permanent shear thinning in the USV, it is very important to take account of the fact that the polymer solution is subjected to different shearing times at different shear rates, so the shear thinning rate must be determined by dividing the amount of shear thinning by this time of shear. This issue is also present and may have been neglected, in some previous shear thinning studies using capillary and orifice viscometers where the time of passage of the lubricant through a capillary depends on the shear rate.\nIt has been found that the amount of shear thinning is usefully expressed in terms of the permanent shear stability index, PSSI, since, as shown in Eq.  7 , this can be related directly to the specific viscosity change and thus, from Eq.  9 , to the rate of change of concentration of polymer. Equation  9 applies formally only if the polymer solution viscosities are measured at low shear rate, in which case the PSSI should be proportional to the initial polymer concentration change and to the change in average MWt. When PSSI(106) is measured at 106 s−1 in the USV its dependence on the change in MWt should be much lower since, as shown in non-shear thinning measurements, specific viscosity increases only slowly with MWt.\nThe study has confirmed that the rate of shear thinning depends on shear stress rather than strain rate and increases approximately exponentially with shear stress in accord with the stress-augmented thermal activation model. This dependence on shear stress has practical importance when we consider the fact that there is a trend towards lower and lower lubricant viscosities. In pure sliding hydrodynamic conditions the lubricant film thickness depends on viscosity and sliding speed according to\n$$ h \\propto \\left( {\\eta u_{\\text{s}} } \\right)^{a} $$\n(10)\nwhere a is typically ca. 0.5. Assuming this value for a, the shear rate thus depends on η and u s according to;\n$$ \\dot{\\gamma } = \\frac{{u_{\\text{s}} }}{h} \\propto \\left( {\\frac{{u_{\\text{s}} }}{\\eta }} \\right)^{0.5} $$\n(11)\nBy contrast, shear stress dependence on η and u s is;\n$$ \\tau = \\eta \\dot{\\gamma } = \\eta \\frac{{u_{\\text{s}} }}{h} \\propto \\left( {u_{\\text{s}} \\eta } \\right)^{0.5} $$\n(12)\nThese relationships imply that reductions in lubricant viscosity will tend to increase shear rates but reduce shear stresses in hydrodynamic contacts. Therefore, if permanent shear thinning is shear stress controlled, it will become less of a problem as oil viscosities are reduced, but if it is shear rate controlled it will become worse. However, this does not take account of another trend in lubricated components, which is towards higher power densities and thus larger contact pressures. This will tend to increase viscosity within contacts due to a piezoviscous response, which will increase shear stress.\nIt is of interest to compare the observation of permanent shear thinning in this study with the long-standing rule of thumb described in Eq.  1 . If we assume a representative high shear rate viscosity of 10 cP, then the product of shear rate with viscosity and MWt2 varies with shear rate and MWt as shown in Table  5 . Based on the threshold of 1014 in Eq.  1 , we would thus expect to see significant permanent shear thinning of the 50 k polymer at 106 s−1. In practice, this is not the case and a more appropriate threshold for the onset of permanent shear thinning for the PS studied would appear to be 1015.\nTable 5\n""","0.10512339","""https://link.springer.com/article/10.1007%2Fs11249-017-0888-7""","[-0.178219,51.500505]"
"""University_of_York""","""Measurement of NOx Fluxes from a Tall Tower in Central London, UK and Comparison with Emissions Inventories - Environmental Science & Technology (ACS Publications)""","""Table of Contents\nMeasurement of NOx Fluxes from a Tall Tower in Central London, UK and Comparison with Emissions Inventories\n†National Centre for Atmospheric Science and ‡Department of Chemistry, University of York, York YO10 5DD, U.K.\n§ Centre for Ecology and Hydrology (Edinburgh Research Station), Penicuik EH26 0QB, U.K.\n⊥ Environmental Research Group, King’s College London, Fourth Floor, Franklin Wilkins Building, 150 Stamford Street, London WC2R 2LS, U.K.\nEnviron. Sci. Technol.\n, 2015, 49 (2), pp 1025–1034\nDOI: 10.1021/es5049072\nPublication Date (Web): December 12, 2014\nCopyright © 2014 American Chemical Society\n* Phone: +44 0 1904 322575; e-mail: james.lee@york.ac.uk .\nACS AuthorChoice - This is an open access article published under a Creative Commons Attribution (CC-BY) License , which permits unrestricted use, distribution and reproduction in any medium, provided the author and source are cited.\nReferences\nAbstract\nDirect measurements of NOx concentration and flux were made from a tall tower in central London, UK as part of the Clean Air for London (ClearfLo) project. Fast time resolution (10 Hz) NO and NO2 concentrations were measured and combined with fast vertical wind measurements to provide top-down flux estimates using the eddy covariance technique. Measured NOx fluxes were usually positive and ranged from close to zero at night to 2000–8000 ng m–2 s–1 during the day. Peak fluxes were usually observed in the morning, coincident with the maximum traffic flow. Measurements of the NOx flux have been scaled and compared to the UK National Atmospheric Emissions Inventory (NAEI) estimate of NOx emission for the measurement footprint. The measurements are on average 80% higher than the NAEI emission inventory for all of London. Observations made in westerly airflow (from parts of London where traffic is a smaller fraction of the NOx source) showed a better agreement on average with the inventory. The observations suggest that the emissions inventory is poorest at estimating NOx when traffic is the dominant source, in this case from an easterly direction from the BT Tower. Agreement between the measurements and the London Atmospheric Emissions Inventory (LAEI) are better, due to the more explicit treatment of traffic flow by this more detailed inventory. The flux observations support previous tailpipe observations of higher NOx emitted from the London vehicle diesel fleet than is represented in the NAEI or predicted for several EURO emission control technologies. Higher-than-anticipated vehicle NOx is likely responsible for the significant discrepancies that exist in London between observed NOx and long-term NOx projections.\nReferences\nIntroduction\nThe oxides of nitrogen NOx (defined as the sum of NO and NO2), are emitted as a consequence of most combustion processes. The majority of NOx is emitted as NO, which is rapidly oxidized to NO2 upon reaction with ozone (O3), with the reverse of this process being caused by the action of sunlight on NO2 to form NO and O3. NO2 is known to have significant direct health effects on humans. At high concentrations it causes inflammation of the airways, and long-term exposure may affect lung function and enhance the response to allergens. (1, 2) In addition, NOx contributes to the formation of O3 and secondary particles through a series of photochemical reactions. (3) As a result of this, NO2 is included in a series of air pollutants identified as part of the EU Air Quality Directive (AQD, 2008) (4) which sets limit values for hourly and annual mean exposure. It has been shown by measurements and models that the annual mean limit value of 40 μg m–3 continues to be exceeded in many urban centers throughout the UK, (5) including London. Measures are in place to control the emissions of nitrogen oxides, and UK emissions are projected to decline by about 35% between 2010 and 2020. (6) However, it is known that ambient NO2 concentrations do not respond linearly to reductions in the concentration of NOx (e.g., Derwent et al. (7) ), mainly because of the chemical coupling of ozone (O3) and NOx under ambient conditions. (8) In addition, changes in diesel emission control technology have led to increases in directly emitted NO2. (9) Trends in ambient concentrations of NOx and NO2 in the UK have generally shown a decrease in concentration from 1996 to 2002, followed by a period of more stable concentrations from 2004–2012. (10) This is not in line with the expected decrease suggested by the UK emission factors. (11)\nAir pollutant emission inventories provide input data for air pollution models, which in turn are used for predicting current and future air pollution. This is typically done using a “bottom up” approach involving estimated emissions from different source sectors to produce yearly emission estimates. However, it is known that this method can contain large uncertainties, with the errors propagating through into errors in air pollution models. (12) Evaluation of emission inventories can be carried out by comparing air quality model predictions (using inputs from the inventory) to observed concentrations, (13, 14) however this method does not provide a direct comparison with the emission rate as it requires knowledge of other parameters such as chemistry and meteorology. The eddy covariance technique provides a direct measurement of the flux to the atmosphere of a particular pollutant, thus providing a “top down” approach to quantifying emissions. (15) Flux measurements also provide information on both spatial and temporal change in emissions from a calculated flux footprint, giving insight into controls and sources. The majority of eddy covariance measurements made to date have concentrated on fluxes of greenhouse gases (CO2, CH4, and N2O) (16, 17) and volatile organic compounds (VOCs), (18-20) largely from biogenic sources. Some eddy covariance NOx flux measurements have been made and have typically focused on emissions from soils, (21) forests, (22-24) or snow. (25, 26) Recently, however, it has been shown that this method can be extended to the urban canopy for CO2 (27-29) and VOCs, (30-32) with one study of urban NOx. (33)\nIn this study, we use the eddy covariance technique to directly measure the flux of NO and NO2 from a tall tower (190 m) in central London as part of the Clean Air for London (ClearfLo) project. (34) The results are compared to local traffic flow, and a flux footprint is calculated to allow comparison with two emission inventories, one for the whole of the UK and one specific to London.\nExperimental Section\nMeasurement Site\nMeasurements were made during June–August 2012 and March–April 2013 from the top of the BT Tower, a 190-m-tall telecommunications tower situated in central London, UK (51°31′17.4″N, 0°8′20.04″W). Mean building height is 8.8 ± 3.0 m within 1–10 km of the tower and 5.6 ± 1.8 m for suburban London beyond this. (30, 35) The area surrounding the tower is dominated by roads and commercial/residential buildings, but also includes some urban parkland and pervious ground. A map of the location of the tower within London is shown in the Supporting Information (SI) (Figure S1). The gas inlet and ultrasonic anemometer were attached to a mast that extended ∼3 m above the top of the tower. Air was pumped down a ∼40-m Teflon tube (1/2 in. OD) at a flow rate of ∼30 L min–1 to the gas instruments, which were housed in a room inside the tower.\nThe most prevalent wind direction during the summer 2012 measurement period was the SW sector (∼50% of the time), with other wind sectors split approximately equally. Wind speed was 6.7 m s–1 on average, with the highest wind speeds measured when the wind was from a NW direction. Average temperature was 15.1 ± 4.3 °C. During the March–April 2013 measurement period, the most prevalent wind direction was between 0–90° (50%), again with other directions split approximately equally. Wind speed was higher than that of summer 2012, being 8.8 m s–1 on average, with the highest wind speed when the wind was from the SW direction. As expected, average temperature was lower than that of the summer 2012 period, being 9.7 ± 2.4 °C.\nNOx Measurements\nMeasurements of NO were made using an Ecophysics 780TR instrument, which uses the chemiluminescence technique. (36, 37) NO2 was quantified in a second identical NO instrument by initial photolytic conversion to NO using blue light LED diodes centered at 395 nm. The 395-nm wavelength has a specific affinity for NO2 photolytic conversion to NO, giving high analyte selectivity within the channel, (38) and there is a low probability of other species such as nitrous acid (HONO) being photolyzed. The diode-based converter also has a very low residence time for the air sample (<0.1 s) which allows 10 Hz measurements of NO2 to be made. The NO instruments were calibrated every 36 h by addition of a known amount of NO to the sample line, made by diluting a gas standard (5 ppm of NO in N2, BOC – traceable to NPL scale) in NOx free air (Ecophysics PAG003). The conversion efficiency of the NO2 converter was also measured during each calibration by gas-phase titration of the known NO upon addition of O3, with typical conversion efficiencies being 30–35%. It is estimated that the total error (including accuracy and precision) is around 10% for NO and 15% for NO2 at 10 ppbV.\nMeteorology Measurements\nFast (20 Hz), 3-dimensional wind vectors and sonic temperature were measured from next to the sample line inlet by a Gill Instruments R3-50 ultrasonic anemometer. The data were logged, along with that from the NOx instrument, using a custom National Instruments LabView program. The boundary layer height was measured using a HALO Photonic Doppler LiDAR instrument. (39)\nFlux Calculations and Uncertainties\nNO and NO2 fluxes (FNO and FNO2) were calculated using eqs 1 and 2 .\n(1)\n(2)\nCi is the number of instrument counts (in Hz) and Si is the associated instrument sensitivity (in Hz ppb–1) for species i (NO and NO2). Vmol is the molar volume (calculated for each individual point), α is the photolytic conversion efficiency of NO2 to NO, and w is the vertical wind component measured by the ultrasonic anemometer. A “prime” symbol represents an instantaneous deviation from the mean, and a horizontal bar denotes the covariance of 2 scalars.\nProcessed data were filtered using a three-step quality assurance algorithm whereby data were deemed of satisfactory quality if the following conditions were met: The level of turbulence was sufficient, i.e. locally derived friction velocity u* ≥ 0.2 m s–1 (<5% of the data is rejected due to this parameter). The number of spikes in w, NO, and NO2 did not exceed 1% of total in each half-hourly averaging period. The stationarity test described by Foken et al., (40, 41) which requires the flux for the complete averaging interval (here 30 min) to be within 30% of the fluxes calculated for the subintervals (6 × 5 min), was satisfied.\nTotal measurement uncertainty, i.e. the sum of total random and systematic uncertainties, was estimated using the 24-h differencing method (42) which assumes that the difference between pairs of observations taken exactly 24 h apart under similar meteorological conditions (air temperature, wind speed, and direction) is mainly attributable to stochastic factors. Using multiple pairs of observations, the standard deviation of the random error can be calculated from eq 3 .\n(3)\nThe environmental conditions were deemed similar if air temperatures diverged by less than 3 °C, wind speed diverged by less than 2 m s–1, and wind directions originated from the same quadrant.\nCauses of systematic uncertainties are varied and include calibration procedures, instrumentation limitations, or data processing artifacts. Unlike random uncertainties, systematic errors can be minimized by careful data processing and correction.\nSuccessive calibration events were linearly interpolated over time, canceling out errors due to calibration drifts provided that the drift was linear over time.\nTo estimate potential turbulence attenuation in the sampling line, which can lead to underestimation of the actual flux, fluxes of CO2 measured using by a Picarro G2301-f sampling off the same line as the NO and NO2 analyzers were compared with fluxes measured by a Licor 7500 open-path analyzer mounted near the ultrasonic anemometer. The underlying assumption is that turbulence attenuation and molecular interactions with the sampling tube are comparable for CO2, NO, and NO2 molecules. Rather than correct for attenuation, this systematic uncertainty was added to the estimated stochastic component and presented as confidence interval in what follows.\nFlux Footprint\nTo carry out meaningful interpretation of the data, it is necessary to calculate the flux footprint of the measurement. It is not possible to get footprint models to fully account for the spatial variability of building heights, topography, and surface heat flux from an urban environment. In this case, the Kormann and Meixner (43) footprint model (K–M model) was applied, which accounts for non-neutral stratification but assumes homogeneous surfaces. The aerodynamic roughness length for momentum was assumed to be 1 m as used in previous BT Tower flux studies. (35) The sample height for the BT Tower was 190 m. The K–M model was used to estimate the flux footprint on a half-hourly time base. A Microsoft Excel tool (based on the K–M model) calculated the distance from the measurement point from which a set percentage of the measured flux is emitted. Figure S4 in the SI shows a histogram of the calculated footprints for 50%, 70%, and 90% of the flux for the measurement period. The analysis here uses the footprint from which 90% of the flux is predicted to originate, which shows a range of 150–19 980 m, with a median of 4695 m.\nReferences\nResults and Discussion\nMeasurements of the NOx flux were made during two time periods, June–August 2012 (36 days) and March–April 2013 (28 days). Downtime was due mainly to instrument failure of both the fast NOx instrument and 3-D sonic anemometer, as well as a failure in the sample pump. Despite this, data coverage on the days when measurements was taken was 61%, meaning the data set provides a unique opportunity to examine the diurnal and seasonal behavior of NOx fluxes from central London.\nThe full time series of data is shown in the SI Figure S2, with NOx concentrations averaged to the 30-min flux averaging time. Typically NO concentrations vary from close to zero at night to a maximum of 10–100 μg m–3 during the day, whereas NO2 ranges from 5–80 μg m–3. Also shown in SI Figure S2 is the time series of NO and NO2 from an urban background site in at North Kensington, London, which is approximately 5 km west of the BT Tower. (44) These data show a trend similar to that of the BT Tower for most of the time, although at generally higher levels. A regression analysis of the two data sets (BT Tower and North Kensington, shown in SI Figure S3), shows North Kensington data being on average 10% higher for NO and 6% higher for total NOx (R2 of 0.65 and 0.58, respectively). This result gives confidence that, at least for total NOx, the BT Tower site is representative of the wider London area.\nRandom uncertainties (1 σ) obtained by 24-h differencing were 441 ng m–2 s–1 for FNO, 475 ng m–2 s–1 for FNO2, and 510 ng m–2 s–1 for FNOx (FNO + FNO2); residual systematic uncertainties were estimated at 15% of the measured flux. Maximum NOx fluxes are measured during the daytime, with values from 2000 ± 741 to 5000 ± 1191 ng m–2 s–1 for NO and 2000 ± 775 to 12 000 ± 2275 ng m–2 s–1 for NO2. Measured fluxes are usually positive, demonstrating, as expected, that NOx emission dominates over deposition in this urban environment and that it is likely to be dominated by anthropogenic emissions. NOx can be lost to the surface by dry deposition, (45) and assuming a deposition velocity of 0.1 cm–1 and a NOx concentration of 50 μg m–3, then the downward flux can be estimated to be in the region of 100 ng m–2 s–1, which is more than an order of magnitude smaller than the observed values. NO and NO2 fluxes show a distinct diurnal profile. NO flux is close to zero at night (although still positive), with a rise starting at 05:00 to a peak of 1800–1900 ng m–2 s–1 between 08:00 and 12:00. The NO flux then usually starts to decrease throughout the rest of the day and into the night, reaching the nighttime value of 100–200 ng m–2 s–1 at around 20:00. NO2 flux also typically shows a diurnal profile with 500–1000 ng m–2 s–1 measured at night followed by a rise to 2200–2300 ng m–2 s–1 from 05:00 until 12:00, with levels then remaining constant until around 16:00. There follows a steady decrease in NO2 flux throughout the rest of the day and into the night, with levels reaching around 1200 ng m–2 s–1 at midnight.\nVery few direct flux measurements of NO and NO2 have been made in an urban environment, however the values measured in this study are comparable to those of a study in the urban area of Norfolk, VA, USA, which reported total NOx fluxes in the range 5000–8000 ng m–2 s–1. (33) Direct measurements of NOx fluxes have been made previously over forested and snowpack environments, with the measured fluxes still positive, but typically an order of magnitude smaller than measured here. (22, 24, 25) Because of the close coupling of NO and NO2, it is the sum NOx that is typically reported in emission inventories, and so the rest of this work will concentrate on measurements of total NOx. This also allows us to discount the chemistry associated with the interconversion of NO and NO2, which can happen on a very fast time scale. Total NOx is likely to be conserved between emission and sampling on the BT Tower, as formation of NOx reservoir species such as PAN and HNO3 takes place on a much longer time scale than the time between emission from street level and sampling at the tower (estimated as 3–8 min).\nAnalysis of the wind sector dependence of the flux can help to identify the sources of the species in question. Figure 1 shows bivariate polar plots with the joint flux footprint–wind direction of the NOx flux, created using the Openair package. (46) The flux footprint used was calculated using the method described above. Two plots are shown to reflect daytime (05:00–19:00) and nighttime fluxes. During the daytime, there are clearly higher fluxes measured when the calculated footprint is smaller, in particular when the wind is from an E/NE direction from the tower. Fluxes then get smaller as the footprint gets larger in all directions. This is a reflection of the reduced traffic density (and hence traffic emissions), further away from central London. At night the fluxes are lower in all directions and for all footprints (as expected), however there is much less of a reduction in flux as the footprint gets larger. An explanation for this behavior is likely that traffic emissions are much less important for the total nighttime NOx emission, with the majority of the emissions from commercial, industrial, and domestic combustion. Hence, there is more homogeneity over London during the night compared to the daytime. There are still greater fluxes measured when the wind was from the NE–SE sector, which is probably due to the area to the east of the tower being more urban in nature than that to the west.\nFigure 1. Wind-sector dependence of the NOx flux for all data averaged during (a) daytime (05:00–19:00) and (b) nighttime (20:00–04:00). The radial axis shows the calculated flux footprint in meters for each measurement.\nConcentrations of a given pollutant in the atmosphere are largely dependent on its emission rate, meteorology, and chemical processing. It is useful to consider diurnal profiles in all these quantities because it can help understand the processes leading to what is observed. For diurnal averages, systematic uncertainties greatly outweigh random uncertainties which decrease as 1/√n, with n being the sample size. Average diurnal cycles have been calculated for the entire measurement period, for NOx flux, average traffic volume at 20 traffic counting sites within the flux footprint of the site, boundary layer height, and NOx concentration, and these data are shown in Figure 2 (all times local time). Standard deviations of the average diurnals are also shown, demonstrating the relatively small day to day variability of the measurements. The traffic data used can be thought of as a proxy for total traffic flow across the entire flux footprint area, and a map of the location of the traffic counting sites used is shown in the SI (Figure S5). Data from each day are binned into hourly time periods (local time − UTC + 1 h) and averaged, with the time stamp being the midtime of the averaging period. NOx flux shows a diurnal cycle with positive fluxes seen throughout the day. From 00:00 to 04:00 fluxes are slightly decreasing from 1400 ± 210 ng m–2 s–1 to 450 ± 67 ng m–2 s–1, with a rise starting at around 04:30, consistent with the onset of the morning rush hour in London (at 05:30 local time). There follows a steady increase in the NOx flux to around 4000 ± 600 ng m–2 s–1 at 10:00, levels that remain until 17:00 (with a slight second peak at 16:00). This is broadly similar to the average traffic count data, providing more evidence that the majority of the NOx emissions sampled at the BT Tower are from road traffic emissions. There then follows a steady decrease in the NOx flux throughout the rest of the day, to around 1200 ± 180 ng m–2 s–1 at 00:00. This is, again, broadly in line with the traffic flow. NOx concentrations are reasonably stable at ∼18–20 μg m–3 throughout the night, followed by a rapid rise starting at 04:30 (at a time similar to the rise in NOx flux). This rapid rise is due to a combination of the increase in fluxes, and the fact that the boundary layer height does not increase until around 06:30. Once the boundary layer starts to grow (from ∼300 m at 08:00 to 1700 m at 12:00), the rise in NOx concentrations is less rapid, and in fact they start to fall after a peak of 22 μg m–3 at 08:00 until 16:00. This is likely due to dilution effects caused by the increasing height of the boundary layer, meaning the NOx is emitted into a larger volume. After 15:30, the NOx concentrations start to rise again, despite a decrease in flux. This is again likely due to the meteorology, with a decreasing boundary layer height into the night.\nAlso, plotted in Figure 2 are the weekday and weekend diurnal averages for the data. During the day, traffic counts are on average lower during the weekend, particularly during the morning where the difference is up to 50%. This is reflected in the NOx flux data, although it does not show as pronounced a difference between weekend and weekday. This is potentially due to the type of traffic at the weekend, which is likely to be predominantly buses and larger vehicles (mainly powered by diesel engines), whereas during the week, private cars and taxis maybe more prevalent. During the night, traffic levels are actually higher on the weekend than during the day, also likely to be a result of public transport and the large nighttime weekend economy of London. This is also reflected in the NOx flux measurements showing higher values from midnight to 06:30 for weekends compared to weekdays.\nFigure 2. Average diurnal profiles for 36 days of data during Jun–Aug 2012 and 28 days during March–April 2013. Data shown are average traffic count (see text for further details), NOx flux, boundary layer depth, and NOx mass mixing ratio. All times are local time, with the time stamp being the midpoint of an hour averaging period. Error bars reflect the 95% confidence intervals in the mean of the different measurements used to calculate the diurnal average. The red dotted line shows weekday data and the blue dashed line shows weekend data.\nThe flux data were binned into 4 different regimes according to the calculated footprint (0–2.5, >2.5–5, >5–10, and >10–20 km radial distance from the BT Tower), and average diurnal profiles for each are plotted in Figure 3 . The shaded regions represent the 95% confidence of the day to day variability of the flux measurements. All regimes show a similar diurnal profile, with the flux starting to rise at around 04:30, with a peak between 10:00 and 14:00. The highest fluxes are seen in the two smallest footprint regimes, with both showing similar values during daytime of around 4500 ± 675 ng m–2 s–1. The 5–10 km regime shows lower daytime peak fluxes of 3200 ± 480 ng m–2 s–1, with the 10–20 km regime lower still, with a peak of 2950 ± 442 ng m–2 s–1 at 10:00 and then a decline throughout the day. All 4 regimes show similar NOx fluxes at night of around 1000 ± 150 ng m–2 s–1, the exception being the 0–2.5 km, which does exhibit some elevated flux levels up to 1500 ng m–2 s–1, and appears to start to rise slightly earlier than the other regimes. All this behavior is consistent with traffic emissions being the dominant source of NOx, especially in central London. It is expected that traffic volume will be higher closer to central London and this is shown by the average traffic counts also plotted in the different footprint bins in Figure 4 . As a result of this, the smaller footprint regimes from the BT Tower show the largest daytime fluxes. At night, it is likely that a smaller proportion of the NOx will come from traffic sources, meaning the measured flux will be similar in all flux regimes out to 20 km from the measurements site.\nFigure 3. Average diurnal profiles for NOx flux in 4 different footprint regimes (red trace). The error bars reflect the 95% confidence intervals in the mean of the different measurements used to calculate the diurnal average. All times are local time, with the time stamp being the midpoint of an hourly averaging period. Also shown is the average traffic flow at 6 sites within each of the individual footprint areas (blue trace).\nEmissions Inventories\nTo put the measured data in some context, a comparison has been carried out against inventories of NOx emissions for London. The UK National Atmospheric Emissions Inventory (NAEI) shows official annual, spatially disaggregated, 1 × 1 km gridded emission maps for a wide range of atmospheric pollutants, including NOx. A detailed description on how the emissions maps are produced is given in Bush et al. (47) Briefly, annual emission estimates are generated from 11 source sectors, according to those laid out by the United Nations Economic Commission for Europe (UNECE). For each sector, a national total emission estimate is produced from a combination of reported emissions and estimates based on modeling. The UK National Atmospheric Emission Inventory (NAEI) gives an estimate of the NOx emissions in 1-km2 grids over the UK, including a breakdown of the different sources. The NAEI estimate for NOx emissions for London is shown in the SI (Figure S6). The map is centered on the BT Tower, and features of London characterized by large NOx emissions can clearly be seen (e.g., Heathrow airport to the West and the M25 orbital motorway circling the city). Four maps are shown, with the contribution from 3 of the most important sectors (road transport; domestic, industrial, and commerical combustion; and other transport (rail and shipping)), as well as the total emissions. Also shown on the maps are 5-km and 10-km radius circles from the tower, indicative of the flux footprint bins described above. It suggests that around 65% of NOx emissions from central London are from road and other transport, with the majority of the remainder from commercial, domestic, and industrial combustion.\nThe London Atmospheric Emissions Inventory (LAEI) provides emissions estimates of 9 air pollutants (including NOx), on a 20 m × 20 m grid square scale. The inventory reflects the geography of the roads in London, enabling an accurate assessment of population exposure and health impacts. Two versions of the LAEI are used in this study. The standard LAEI (LAEI base) is the 2012 inventory based on methods set out in the Greater London Authority datastore, (48) but updated for 2012 emission data. Also, we use an enhanced version of the LAEI, which uses measured roadside emissions based on extensive vehicle emission remote sensing. (49) Both emissions inventories discussed are purely annual averages with no seasonal or finer temporal detail.\nComparison with Measurements\nFigure 4. Comparison of the averaged measured fluxes, scaled to give an annual emission rate, with the estimate of the National Atmospheric Emission Inventory (NAEI) and two versions of the London Atmospheric Emissions Inventory (LAEI); see text for details. The different colors in the columns represent the estimates from different source sectors.\nFigure 4 shows estimated emissions of NOx taken from the NAEI and LAEI for 2.5-, 5-, and 10-km radial distance from the tower, along with the estimates for sections in easterly (30–150°) and westerly (210–330°) directions and the source sector estimate divided into road transport, commercial and residential combustion, and other transport (which is mainly rail in London). For the NAEI data for a 20-km radial distance is also plotted, however this data is not available for the LAEI. Also plotted is the averaged measured NOx flux for the different footprint regimes, also divided into periods of easterly and westerly wind directions and scaled to give a yearly emission rate.\nThe measurements are seen to be significantly higher than those of the NAEI (outside the estimated experimental flux systematic error of 15%) under all regimes. The agreement between the measurement and the inventory tends to get worse for the larger footprint regimes, with the measurement being 2.2 times higher than the inventory for the 10–20 km regime, and only 1.6 times higher for the 0–2.5 km regime. There is much more scope for error when considering a comparison between larger flux footprints and the inventory, as the further the air has traveled, the more different emission inventory grid squares it could have passed over, making a comparison with the inventory more difficult. In general, the agreement is better for the westerly flow conditions, with the measurement being 1.36 and 1.38 times higher than the inventory for the 2.5- and 5-km footprints, respectively, whereas for the easterly flow, the agreement is worse (1.6 and 1.9 times higher for 2.5 and 5 km). The difference in source sector between the 2.5- and 5-km radius is small. Road transport dominates (62% and 60% for 2.5 and 5 km, respectively), with the remainder from commercial and domestic combustion (29% and 27%) and other transport (4% and 10%). There is a lower contribution from road transport for the westerly flow conditions (48% for both 2.5- and 5-km radius), giving a potential reason for the better agreement here. It is likely that road transport is the most poorly constrained part of the NAEI, and hence when this is less important to the total emission rate, the agreement with the measurement is better.\nFor the base LAEI, the comparison shows a much closer agreement of the measurements with the inventory compared to that with the NAEI discussed above. The inventory is within the measurement error for the average of all wind directions, with the measurement 1.03 and 1.1 times higher than the inventory in the 2.5- and 5-km regimes, respectively. The agreement is similarly good in westerly flow, and although in easterly flow the measurement is now 1.07 times lower for the 2.5-km footprint and 1.03 times higher for the 5-km footprint, these are still well within measurement error. For the 10-km footprint, the LAEI falls outside the systematic error of the measurements for all the data separated into easterly and westerly flow regimes, with the measurements being 1.16 and 1.48 times higher than the inventory for westerly and easterly flow, respectively. A comparison of the measurements to the enhanced LAEI (which has generally increased road transport NOx emissions), shows the measurements being slightly lower than the inventory for data from the 2.5- and 5-km flux footprints, although again these is still within the systematic error of the measurements for all the data and the westerly flow. It is in the easterly flow conditions where the measurements are now significantly lower than the inventory, with the underestimation of 20% and 17% for the 2.5- and 5-km regimes falling outside the flux measurement error. For the 10-km flux footprint regime, the enhanced LAEI brings the emission estimates into much better agreement with the measurements than the base case, with the data from both easterly and westerly flows showing agreement within 10%.\nIn general, both the LAEIs seem to be doing a reasonable job of estimating NOx emissions in central London, and certainly better than the NAEI estimations. The LAEI, particularly in its enhanced form with measured road traffic emissions, has a much more explicit treatment of road transport emission than the NAEI, thus potentially providing a more accurate estimate of NOx emissions in London. It uses vehicle speed and vehicle flow data from each road link using GPS-based vehicle speed, and automatic number plate recognition data to enhance vehicle stock information. The inventory also makes predictions of primary NO2 emissions, something that is potentially important in London due to the high proportion of diesel-fueled vehicles, which are likely to have a higher direct primary NO2 emission compared to gasoline vehicles. (50) The LAEI containing the enhanced treatment of traffic emissions actually overestimates the NOx emission in the central London footprint regimes (0–5 km from the BT Tower), with greater overestimation outside the error of the measurements under easterly flow conditions. This suggests potential extra errors in the treatment of traffic flow in the center of London to the east of the BT Tower within the LAEI. The LAEI has a significant contribution from other sources, which are mainly from nonroad mobile machinery (e.g., cranes, construction vehicles). These are virtually zero in the NAEI and it could be errors in these sources that are contributing to the overestimation of the inventory in central London. The better comparison with the LAEI compared to the NAEI supports previous tailpipe observations of higher NOx emitted from the London vehicle diesel fleet than is represented in the NAEI or predicted for several EURO emission control technologies, and shows that a detailed treatment of traffic emissions is required to properly predict the NOx emissions. (11) There are no studies to our knowledge that specifically evaluate the London or national inventories. However, it is clear from recent remote sensing measurements in London during 2012 that emissions of NOx have not decreased as expected through emissions legislation. (49) This higher-than-anticipated vehicle NOx is likely responsible for the significant discrepancies that exist in London between observed NOx and long-term NOx projections, and show that a detailed representation of traffic emissions is required to accurately represent NOx in London.\n""","0.50133216","""http://pubs.acs.org/doi/10.1021/es5049072""",
"""Imperial_College_London""","""Impact of London's road traffic air and noise pollution on birth weight: retrospective population based cohort study | The BMJ""","""Impact of London's...\nImpact of London's road traffic air and noise pollution on birth weight: retrospective population based cohort study\nCCBYNC Open access\nResearch\nImpact of London's road traffic air and noise pollution on birth weight: retrospective population based cohort study\nBMJ 2017; 359 doi: https://doi.org/10.1136/bmj.j5299 (Published 05 December 2017) Cite this as: BMJ 2017;359:j5299\nRachel B Smith, research associate 1 2 ,\nDaniela Fecht, research fellow 3 ,\nJohn Gulliver, senior lecturer 1 ,\nSean D Beevers, senior lecturer 4 ,\nDavid Dajnak, deputy manager 4 ,\nMarta Blangiardo, senior lecturer 1 ,\nRebecca E Ghosh, research associate 3 ,\nAnna L Hansell, assistant director 2 3 ,\nFrank J Kelly, professor 2 4 ,\nH Ross Anderson, emeritus professor 4 5 ,\nMireille B Toledano, reader 1 2\n1MRC-PHE Centre for Environment and Health, Department of Epidemiology and Biostatistics, School of Public Health, Imperial College London, St Mary’s Campus, Norfolk Place, London W2 1PG, UK\n2NIHR HPRU in Health Impact of Environmental Hazards, King's College London, London, UK\n3UK Small Area Health Statistics Unit, MRC-PHE Centre for Environment and Health, Department of Epidemiology and Biostatistics, School of Public Health, Imperial College London, London, UK\n4MRC-PHE Centre for Environment and Health, Environmental Research Group, Faculty of Life Sciences and Medicine, King's College London, London, UK\n5Population Health Research Institute, St George’s, University of London, London, UK\nCorrespondence to: M B Toledano m.toledano{at}imperial.ac.uk\nAccepted 1 November 2017\nAbstract\nObjective To investigate the relation between exposure to both air and noise pollution from road traffic and birth weight outcomes.\nDesign Retrospective population based cohort study.\nSetting Greater London and surrounding counties up to the M25 motorway (2317 km2), UK, from 2006 to 2010.\nParticipants 540 365 singleton term live births.\nMain outcome measures Term low birth weight (LBW), small for gestational age (SGA) at term, and term birth weight.\nResults Average air pollutant exposures across pregnancy were 41 μg/m3 nitrogen dioxide (NO2), 73 μg/m3 nitrogen oxides (NOx), 14 μg/m3 particulate matter with aerodynamic diameter <2.5 μm (PM2.5), 23 μg/m3 particulate matter with aerodynamic diameter <10 μm (PM10), and 32 μg/m3 ozone (O3). Average daytime (LAeq,16hr) and night-time (Lnight) road traffic A-weighted noise levels were 58 dB and 53 dB respectively. Interquartile range increases in NO2, NOx, PM2.5, PM10, and source specific PM2.5 from traffic exhaust (PM2.5 traffic exhaust) and traffic non-exhaust (brake or tyre wear and resuspension) (PM2.5 traffic non-exhaust) were associated with 2% to 6% increased odds of term LBW, and 1% to 3% increased odds of term SGA. Air pollutant associations were robust to adjustment for road traffic noise. Trends of decreasing birth weight across increasing road traffic noise categories were observed, but were strongly attenuated when adjusted for primary traffic related air pollutants. Only PM2.5 traffic exhaust and PM2.5 were consistently associated with increased risk of term LBW after adjustment for each of the other air pollutants. It was estimated that 3% of term LBW cases in London are directly attributable to residential exposure to PM2.5>13.8 μg/m3during pregnancy.\nConclusions The findings suggest that air pollution from road traffic in London is adversely affecting fetal growth. The results suggest little evidence for an independent exposure-response effect of traffic related noise on birth weight outcomes.\nIntroduction\nAir pollution is a major public health issue. It has been associated with reduced fetal growth, 1 through which it may have extensive and permanent influences on the life course. 2 A key contributor to urban ambient pollution is road traffic and, critically, vehicle emissions are released near people. Urban particulate matter includes a large contribution from outside the urban area, and locally emitted particles. Close to roads an individual would be exposed to more primary exhaust and non-exhaust (brake or tyre wear and resuspension of road dust induced by vehicles) particles. Further away from roads an individual would be exposed to more nitrate and secondary organic aerosol as a proportion of their total particulate dose.\nRoad traffic also produces noise, which has been associated with adverse health outcomes such as hypertension and cardiovascular disease. 3 Research on how noise affects birth outcomes is more limited, but a possible effect on LBW has been suggested. 4 Noise could potentially influence fetal growth through stress, hypertension, and sleep disturbance. 4 5 6\nEvidence about the relative roles of air and noise pollution on birth weight is limited and inconsistent. 7 8 9 To address health impacts of traffic effectively these need to be better understood. In this study, we investigate long term exposure to both traffic related air and noise pollution during pregnancy in relation to birth weight outcomes.\nMethods\nBirths data\nThe study boundary was the M25, an orbital motorway encompassing all of Greater London and parts of other counties (2317 km2), as traffic information, and therefore air pollution and noise estimates, was not available for beyond the M25. Figure 1 shows the study area. We extracted 671 509 singleton births occurring within the M25 from 2006 to 2010 from the UK National Births and Stillbirth registers held at the UK Small Area Health Statistics Unit and supplied by the Office for National Statistics. These registers provide routinely collected data on all births in the country, including date of birth, birth weight, sex, and mother’s age. We appended gestational age and baby’s ethnicity from the NHS Numbers for Babies (NN4B) dataset, with 99.2% linkage. The method of gestational age assessment is not recorded on NN4B records. It is likely to be based on the more accurate and recent information from a mother’s routine second trimester scan but a proportion may be based on the date of the last menstrual period. 10\nFig 1\nDownload powerpoint\nPatient involvement\nNo patients were involved in setting the research question or the outcome measures, nor were they involved in developing plans for design or implementation of the study. No patients were asked to advise on interpretation or writing up of results. There are no plans to disseminate the results of the research to study participants or the relevant patient community.\nResults\nTable 1 shows that 2.6% and 9.5% of term births were classified as LBW and SGA respectively. Over the study period of 2006 to 2010, there were temporal trends for LBW (decreasing), air pollutant exposures (decreasing particularly for PM2.5 traffic-exhaust, PM2.5, PM10), and an increasing proportion of births with high noise exposures, the latter reflecting change in spatial distribution of maternal addresses over time, as noise modelling was not time varying. Supplementary table 1 in web appendix 1 shows that air pollutant exposures were positively correlated (0.45 to 1.00), except with O3 (-0.46 to -0.77). Daytime and night-time road traffic noise were very highly correlated (∼1.00), and road traffic noise was positively correlated with air pollutant exposures (0.15 to 0.50) except O3 (∼-0.15). Maternal age, ethnicity, birth registration type, birth season, birth year, deprivation (Carstairs quintile), and tobacco expenditure were associated with outcomes and exposures (supplementary tables 2 and 3 in web appendix 1).\nTable 1\nDownload powerpoint\nAfter adjustment for each air pollutant, in turn, there was no evidence that increasing night-time or daytime road traffic noise exposure (analysed as either a categorical or continuous variable) was associated with increasing risk of term LBW ( figs 3 and 5 ) or term SGA (supplementary tables 8 and 9 in web appendix 1). There was some suggestion of an association with reduced term birth weight in the highest night-time road traffic noise category after adjustment for NO2 or NOx but not after adjustment for PM2.5 traffic exhaust or PM2.5 traffic non-exhaust. However, this was not evident in adjusted joint exposure generalised additive models – which indicated that once adjusted for any of the primary traffic related air pollutants, in turn, there appears to be no relation between road traffic noise and term birth weight ( fig 6 and web appendix 1). A weak association remained between road traffic noise and reduced term birth weight after adjustment for PM2.5, PM10, and O3 in linear regression (supplementary figure 3 and supplementary tables 8 and 9 in web appendix 1) and generalised additive models (web appendix 1).\nTrimester specific air pollution models\nFor term LBW, odds ratios for primary traffic related air pollutant exposures in the second and third trimesters tended to be stronger than for first trimester exposures (supplementary table 10 in web appendix 1). Conversely, for term SGA, odds ratios for exposures in earlier trimesters were stronger than the third trimester exposure for PM2.5 traffic exhaust and PM2.5 traffic non-exhaust, and first trimester exposure appeared to be strongest for PM2.5 and PM10 (supplementary table 10 in web appendix 1). However, confidence intervals for trimester specific effects overlapped. These analyses are presented according to prespecified pollutant specific increments (not IQR) to allow comparison between trimesters for each pollutant.\nAdditional analyses\nCompared with unadjusted analyses (supplementary tables 4 to 6 in web appendix 1), effect sizes were generally reduced in single or joint pollutant adjusted models. Given the strong relation between exposures and census output area level deprivation, we ran birth weight models without adjustment for Carstairs quintile to check for overadjustment, however, there were only small changes in birth weight coefficients (<1 g) and the pattern of results was unchanged (not shown). The inclusion of a random intercept for middle layer super output areas (to models adjusted for all other covariates described) resulted in relatively small changes to associations for noise, term LBW, or SGA, but considerable attenuation of associations between air pollutants and term birth weight (-18% to -28% for primary traffic related air pollutants, and -35% to -49% for pollutants including regional or urban background contributions).\nAll sensitivity analyses were conducted on joint air pollutant-noise models. Noise analyses were largely unchanged after excluding those exposed to aircraft or rail noise greater than 50 dB (not shown). We did not observe interactions between ethnicity and air pollution or road traffic noise exposures for term LBW or SGA. Ethnicity-exposure interactions were observed in term birth weight analyses with both primary traffic related air pollutants (P value<0.001) and road traffic noise exposures (∼0.028 for daytime noise, 0.005 for night-time noise), with inverse relations for primary traffic related air pollutants across all ethnic strata (supplementary table 11 in web appendix 1).\nThe population attributable fraction estimated for term LBW for exposure to PM2.5 over the 25th centile of the distribution (ie, 13.8 μg/m3) during pregnancy was 3% (0% to 7%). This 3% corresponds to 93 (0-216) cases of term LBW out of a total of 2950 cases each year on average in our London study population which are directly attributable to residential exposure during pregnancy to PM2.5>13.8 μg/m3.\nDiscussion\nTo our knowledge, this is the largest UK study on air pollution and birth weight, and the first UK study and largest study worldwide of birth weight and noise exposure. We observed that long term exposure during pregnancy to NO2, NOx, PM2.5 overall and specifically from traffic exhaust and non-exhaust sources, and PM10, were all associated with increased risk of LBW at term, across London. There was strong confounding of the relation between road traffic noise and birth weight by primary traffic related air pollutant coexposures, and our results, particularly from generalised additive models, suggest little evidence for an independent exposure-response effect of traffic related noise on birth weight outcomes. Our findings from two air pollutant models suggest that associations between term LBW and air pollutants emitted from vehicle exhausts may be driven by the fine particulate matter (PM2.5 traffic exhaust) component rather than the gaseous NOx component.\nStrengths and weaknesses of this study\nThis study benefits from highly spatially resolved air pollution modelling assigned at address level, and noise levels estimated at address point. For noise particularly, this represents an advance on previous studies which have assigned noise exposure with lower spatial precision (eg, at postcode level, 8 or according to 50 m or 250 m buffers around maternal address, 7 or based on road proximity) 28 , and consequently reduces potential exposure misclassification, as noise levels may change dramatically over short distances (tens of metres). Nonetheless, the potential for exposure misclassification remains. For air pollution, there may be some exposure misclassification close to sources (where gradients of primary pollutants are steep). However, most people do not live within 10 m to 30 m of the centre of a main road so the impact on this study will be low. The percentage of maternal residences in our dataset within 10 m of a major road (annual average daily traffic (AADT) >10 000 vehicles) was 0.07%, within 20 m was 5%, and within 30 m was 11%. We examined the relation between living within 10 m, 20 m, and 30m of a major road and key individual level variables (ethnicity, birth registration type, and maternal age). These variables were not associated with living within 10 m of a major road. The percentage of mothers living within either 20 m or 30 m of a major road was slightly greater (by up to 3%) for non-white ethnicities (v white), unmarried mothers (v married), and younger (v older) maternal age groups. However, these percentage differences are very small (≤3%), so there is no reason to assume that this would introduce serious bias. Most importantly, however, whilst there may be some exposure misclassification between the exposure at the actual address versus the grid point estimate assigned, this should introduce no bias because we have assigned the nearest 20 m × 20 m point. To introduce bias we would always have to choose the point on the side of the residence closest to the road and this is unlikely.\nThe air pollutant model predicted PM2.5 and PM10 slightly more accurately than NO2 and NOx, but the model bias was in the same direction (over prediction) for all these pollutants. Greater model prediction uncertainty for NO2 and NOx may result in effect estimates for NO2 and NOx being more conservative than those for PM2.5 and PM10 and therefore may limit our ability to directly compare the magnitude of effect estimates for NO2 or NOx with PM2.5 or PM10.\nThe noise model is likely to have overestimated and underestimated noise on some minor roads (owing to the constant for traffic on minor roads), but there is no geographical pattern (ie, autocorrelation) in any bias as a result of this, 17 however, to reduce potential exposure misclassification we categorised noise exposure for analysis. We avoided selection bias by using all birth registration data. Direct measures of individual level smoking or deprivation data were unavailable, but we adjusted for tobacco expenditure and deprivation (Carstairs quintile) at census output area level, as in previous epidemiological studies. 29 30 We have also adjusted for birth registration type, an individual level variable which relates to both individual level qualifications and housing tenure (and thus socioeconomic status or deprivation) and individual level smoking. 31 We cannot exclude the possibility of some residual confounding by maternal smoking, passive smoking, or deprivation, but we have adjusted for deprivation and smoking by proxy at individual level, in addition to at area level. Information on parity was not available as part of this study, so we could not adjust for any potential confounding effects directly, but an association between parity and exposure is most likely through deprivation (at area level or individual level), ethnicity, or maternal age, and these have been adjusted for. There is some evidence to suggest that extremes of ambient temperature may be associated with adverse birth outcomes (eg, preterm birth or early delivery and LBW). 32 33 34 35 36 Meteorological conditions, including ambient temperature, are related to air pollution levels. By adjusting for season we did adjust for general seasonal variation in average temperatures, but we could not adjust for exposure to extreme ambient temperatures as we did not have data on temperature linked to the births data. We could not account for residential mobility during pregnancy (∼16% in UK 37 ), nor exposures away from maternal residence (eg, workplace or transport), indoor air pollution, or exposure modification owing to behaviours (eg, opening windows), or building characteristics (eg, bedroom façade). These could contribute to exposure misclassification.\nWe were not able to adjust for spontaneous versus medical intervention early delivery (which could influence the outcome indirectly by gestation period), as data on delivery type were not available as part of this study from the birth registry or NHS Numbers for Babies (NN4B) datasets. If clinical practice in medical intervention for early delivery varies spatially (eg, between hospitals or owing to cultural factors), this could potentially confound the spatial component of exposure metrics. However, all our epidemiological models included a random effect for small area (middle layer super output areas – average population 8000) specifically to account for underlying spatial patterns in the data, so we do not think this should be a serious issue. Multiple hypothesis tests were performed, so the multiple testing problem (ie, that the probability of a Type 1 error will be greater than 0.05 (5%)), should be considered when interpreting P values.\nStrengths and weaknesses in relation to other studies\nOur single air pollutant model findings are consistent with recent meta-analyses which report increased risk of low birth weight (LBW) and reduced mean birth weight associated with NO2, 1 PM2.5, 38 and PM10. 1 39 Meta-analysis results for O3 are less clear: odds ratio for LBW of 1.01 (95% confidence interval, 0.82 to 1.25) for each 20 ppb increase in pregnancy exposure to O3. 1 To our knowledge, only three Californian studies, have examined source specific PM2.5 and birth weight. Converted to the same interquartile range (IQR) (0.35 μg/m3) scale as our PM2.5 traffic exhaust analyses, these studies each report 2% increased odds of term LBW for PM2.5 from diesel and 3% to 4% increased odds for PM2.5 from gasoline, 40 41 42 consistent in magnitude with our odds ratio for term LBW of 1.04 (95% confidence interval, 1.01 to 1.07) for each IQR increase. To our knowledge, no previous study has reported two pollutant models including source specific PM2.5. Our findings, that only PM2.5 traffic exhaust (out of PM2.5 traffic exhaust, NO2, and NOx) showed a consistent elevated risk with mutual adjustment, suggesting that associations between LBW and air pollutants emitted from vehicle exhausts may be driven by the fine particulate matter (PM2.5 traffic exhaust) component rather than the gaseous NOx component is an important and new contribution to scientific knowledge. Our study also shows associations between LBW and fine particulate matter from road traffic which is not emitted from the vehicle exhaust (ie, brake or tyre wear particles and vehicle induced resuspension of road dust). However, owing to multicollinearity in models containing both PM2.5 traffic exhaust and PM2.5 traffic non-exhaust, we could not separate potential effects of traffic related exhaust and non-exhaust related PM2.5. The magnitude of association with PM2.5 traffic exhaust was consistently stronger than with PM2.5 traffic non-exhaust, and this could reflect differing chemical constituents (and thus toxicity) of the PM2.5 mixture from different sources.\nWe found that associations between road traffic noise and term birth weight were strongly attenuated when adjusted for primary air pollutants related to traffic: to null when adjusted for PM2.5 traffic exhaust or PM2.5 traffic non-exhaust, although after adjustment for NO2 or NOx an association between night-time noise and reduced birth weight in the highest exposure category remained, which could possibly reflect a threshold effect. The results of our generalised additive models adjusted for NO2 or NOx, however, do not support an independent association with road traffic noise, or suggest any threshold effect for noise. The most recent systematic review of noise exposure and birth weight found “evidence supportive of associations between LBW and noise exposure” particularly for very high noise levels, but the evidence was inconsistent, 4 based on 10 occupational studies, four aircraft noise studies, and two traffic noise studies. Three previous studies have examined long term air pollution and noise exposures jointly. 7 8 9 Our findings are consistent with a small cohort study (n=6438) in Barcelona, which suggested elevated risks of term LBW and small for gestational age (SGA) associated with noise and air pollution exposures in single exposure adjusted models, but in a joint exposure model term LBW risk was associated with third trimester PM2.5 (for each 3.6 μg/m3, odds ratio 1.31, 95% confidence interval 1.07 to 1.61), but not noise (for each 6.7 dB (A-weighted), 0.89, 0.71 to 1.12). 7 Term birth weight was not associated with NO2, NOx, or road traffic noise, in either fully adjusted single exposure models or joint exposure models in the Danish National Birth Cohort (n=75 166). 9\nOur findings contrast with a registry based study in Vancouver (n=68 238), which found associations between all transportation (road traffic, railway, and aircraft) noise (Lden) and reduced term birth weight or LBW which remained after adjustment for PM2.5, PM10, and primary road traffic air pollution (NO2 and NOx), however, associations for air pollutants were attenuated to null by adjustment for transportation noise. 8 Road traffic noise showed similar associations with term birth weight or LBW in single exposure models, but road traffic noise adjusted for air pollution was not analysed. 8 We, however, found an association between the road traffic noise and reduced birth weight remained after adjustment for PM2.5 or PM10 (which include regional and urban background contributions) – one possible explanation is that adjusting for PM2.5 or PM10 did not fully control for confounding of noise by air pollution coexposures from road traffic. This should be noted by other researchers investigating potential health effects of road traffic noise.\nCompared with London, the noise distribution in Vancouver was wider (Lden mean 60.2 dB(A-weighted), range 6.2-89.0), mean air pollution exposures were lower and with less contrast in Vancouver (PM2.5 mean 4.1 μg/m3, range 0-11.3; NO2 mean 33.7 μg/m3, range 0-64.5) and Denmark (NO2 median 11.0 μg/m3, 5th-95th centiles 7.1–26.3), and air pollutant-noise correlations were lower in Vancouver (correlations with road traffic noise: 0.05 for NO2, 0.09 for PM2.5; and all transportation noise: 0.18 for NO2, 0.16 for PM2.5), but higher in Denmark (0.47 between NO2 and road traffic noise). 8 9 These differences, which could reflect differences in pollutant sources, may contribute to the contrasting findings from Denmark and Vancouver compared with our study. In our study the noise model floor means that the minimum modelled value of night-time noise from road traffic in London was 42.4 dB, 17 which is higher than the recommended upper limit of exposure of total noise of 40 dB proposed by the Night Noise Guidelines for Europe. 43 It is possible that we did not have a sufficiently low noise exposure reference group, to detect small associations between noise and birth weight, above the guideline level.\nIn the broader context, our findings contrast with reviews of joint air pollution and noise studies which suggest independent effects of road traffic noise on other health outcomes (eg, cardiovascular outcomes), after adjustment for air pollution. 44 45 This could reflect different biological pathways between noise and fetal growth versus other health outcomes at later stages of life. The fetus has no direct exposure to the environment, but exposure is mediated through the mother and placenta, and this may modify effects. Threshold effects may be relevant for exposure to noise, and the threshold could vary between health outcomes, possibly being higher for effects on birth weight versus, for example, cardiovascular outcomes. Alternatively, it might reflect differences between studies in the ability to control for confounding by air pollution from road traffic specifically. We did note that associations between noise and birth weight were more strongly attenuated by adjustment for primary road traffic-related air pollutants (NO2, NOx, PM2.5 traffic exhaust, PM2.5 traffic non-exhaust) compared with background air pollutants (PM2.5 and PM10). This suggests that adjusting for the background pollutants may not fully adjust for the confounding effects of air pollution coexposures directly from road traffic, in our study. With respect to cardiovascular outcomes, it has been noted that “more studies using air pollution indicators specific to road traffic are needed to properly assess if road noise and pollutant effects on CV outcomes are subjected to the confounding effect of one another.” 45\nOur results did not give a clear indication as to which trimester could be most influential with respect to air pollution and fetal growth, and previous study findings have been inconsistent on this point. The most recent meta-analyses are suggestive overall of stronger associations for later trimesters between LBW or reduced birth weight and PM2.5 and PM10, 38 39 but unclear for NO2. 1 One potential explanation for this is that earlier trimester exposures may be more prone to exposure measurement bias from residential mobility (in studies assigning exposure according to maternal residential address at birth), and thus attenuated towards the null. However, there are persuasive findings from a natural experiment of air pollution reductions during the 2008 Bejing Olympics, supporting the importance of the third trimester exposures to air pollution in relation to term birth weight. 46 This is biologically plausible, as during the third trimester the rate of fetal growth and weight gain increases dramatically and reaches its peak at about week 33. 47 48\nWe found effect modification by ethnicity of the relation between air pollution and reduced birth weight in line with previous studies, although results for different ethnic groups have been inconsistent. 49 50 51 52 53 54 Effect modification by ethnicity could reflect increased susceptibility to the adverse impacts of air pollution, owing to environmental inequality or differing biological susceptibility.\nBiological mechanisms in which air pollution or noise may impair fetal growth are not established. Hypothesised mechanisms for air pollution are oxidative stress; endocrine disruption; changes to maternal-placental blood flow and oxygen or nutrition transfer; 55 placental mitochondrial damage; 56 and placental growth or function, 57 whilst those for noise are stress triggered endocrine or immune response disruption, plasma catecholamine increase or placental blood flow decrease, 4 hypertension, 5 and sleep disturbance. 6 Convincing evidence that maternal passive smoking during pregnancy is causally related to reduced birth weight, 58 strongly supports the biological plausibility of an association between ambient air pollution and reduced birth weight, by analogy.\nConclusion\nThis study suggests that in Greater London, which has 19% of all annual births in England and Wales, 59 air pollution from road traffic is having a detrimental impact upon babies’ health, before they are born. We estimate that 3% of term LBW cases in London are directly attributable to residential exposure during pregnancy to PM2.5>13.8 μg/m3. Our results suggest little evidence for an independent exposure-response effect of traffic related noise on birth weight, but we cannot rule out that an association might be observed in a study area with a wider range of noise exposures. Our findings should be broadly generalisable to other UK and European cities or urban areas with comparable exposure levels and profiles. At city scale, environmental health policies aimed at reducing road traffic air pollution could reduce the burden of LBW, SGA, and subsequent lifelong morbidity. With the annual number of births projected to continue increasing in London, 60 the absolute health burden will increase at the population level, unless air quality in London improves.\nWhat is already known on this topic\nRoad traffic pollution comprises not only air pollutants such as NO2 and particulate matter, but also noise\nThere is a large body of research demonstrating associations between maternal exposure to ambient air pollution during pregnancy and reduced birth weight, low birth weight (LBW), or small for gestational age (SGA)\nThe relation between road traffic noise and birth weight is unclear, and research examining traffic related air pollutant and noise coexposures together is very limited, so the extent to which observed air pollution associations might be attributable to road traffic noise is poorly understood\nWhat this study adds\nThere is an increased risk of LBW specifically in relation to the air pollution profile of London\nExposure to local air pollution from road traffic is associated with increased risk of LBW in London, but there is little evidence for an independent exposure-response effect of traffic related noise on birth weight\nReducing exposure to traffic related air pollution could reduce the burden of LBW, SGA, and subsequent morbidity, and ultimately give babies in urban environments a healthier start in life\nAcknowledgments\nWe thank Margaret Douglass and Peter Hambly of the Small Area Health Statistics Unit (SAHSU) database team for technical support and the TRAFFIC study group for their constructive comments. CACI tobacco expenditure data are Copyright 1996-2014 CACI Limited.\nFootnotes\nContributors: MBT, JG, HRA, SDB, and FJK contributed to study conception and design. DF, JG, SDB, DD, HRA, and FJK contributed to exposure assessment. REG, DF, and ALH acquired health and confounder data. RBS contributed to study design, wrote the statistical analysis plan, conducted the data analyses, and drafted the initial report. MBT contributed to the statistical analysis plan, the data analyses, and initial drafting of the report. MB contributed to the study design and statistical analysis plan. All authors contributed to interpreting the analyses and critically revising the article, approved the final draft, and agree to be accountable for all aspects of the work. All authors had full access to all of the data in the study and can take responsibility for the integrity of the data and the accuracy of the data analysis. MBT is the guarantor.\nFunding: This work was funded by the UK Natural Environment Research Council, Medical Research Council (MRC), Economic and Social Research Council, Department of Environment, Food and Rural Affairs, and Department of Health (DH) (NE/I00789X/1, NE/I008039/1) through the cross research council Environmental Exposures & Health Initiative. The research was part funded by the National Institute for Health Research Health Protection Research Unit (NIHR HPRU) in Health Impact of Environmental Hazards at King’s College London in partnership with Public Health England (PHE). The work of the UK SAHSU is funded by PHE as part of the MRC-PHE Centre for Environment and Health, funded also by the UK MRC (MR/L01341X/1). The views expressed are those of the authors and not necessarily those of the NHS, the NIHR, PHE, or DH. The funders had no role in the study design; collection, analysis, and interpretation of data; writing of the report; or decision to submit the article for publication.\nCompeting interests: All authors have completed the ICMJE uniform disclosure form at www.icmje.org/coi_disclosure.pdf and declare: no support from any organisation for the submitted work other than those detailed above; no financial relationships with any organisations that might have an interest in the submitted work in the previous three years; no other relationships or activities that could appear to have influenced the submitted work.\nEthical approval: The study used SAHSU data (UK National Births and Stillbirth register data and NHS Numbers for Babies (NN4B)), supplied by the Office for National Statistics. The study was covered by national research ethics approval from the London-South East Research Ethics Committee (reference 17/LO/0846). Data access was covered by the Health Research Authority Confidentiality Advisory Group under Regulation 5 of the Health Service (Control of Patient Information) Regulations 2002 (reference 14/CAG/1039).\nData sharing: No additional data are available.\nTransparency: The lead author, MBT, affirms that the manuscript is an honest, accurate, and transparent account of the study being reported; that no important aspects of the study have been omitted; and that any discrepancies from the study as planned have been explained.\nThis is an Open Access article distributed in accordance with the terms of the Creative Commons Attribution (CC BY 4.0) license, which permits others to distribute, remix, adapt and build upon this work, for commercial use, provided the original work is properly cited. See: http://creativecommons.org/licenses/by/4.0/ .\nReferences\n""","0.17252782","""http://www.bmj.com/content/359/bmj.j5299""","[-0.178219,51.500505]"
"""Cranfield_University""","""Coordinated Airborne Studies in the Tropics (CAST): Bulletin of the American Meteorological Society: Vol 98, No 1""","""Coordinated Airborne Studies in the Tropics (CAST)\nCoordinated Airborne Studies in the Tropics (CAST)\nAuthors:\nAffiliationsMet Office, Exeter, United Kingdom\nSee full authors & affiliations\nFinal Form: 2 February 2016\nPublished Online: 23 January 2017\nAbstract\nSection:\nThe main field activities of the Coordinated Airborne Studies in the Tropics (CAST) campaign took place in the west Pacific during January–February 2014. The field campaign was based in Guam (13.5°N, 144.8°E), using the U.K. Facility for Airborne Atmospheric Measurements (FAAM) BAe-146 atmospheric research aircraft, and was coordinated with the Airborne Tropical Tropopause Experiment (ATTREX) project with an unmanned Global Hawk and the Convective Transport of Active Species in the Tropics (CONTRAST) campaign with a Gulfstream V aircraft. Together, the three aircraft were able to make detailed measurements of atmospheric structure and composition from the ocean surface to 20 km. These measurements are providing new information about the processes influencing halogen and ozone levels in the tropical west Pacific, as well as the importance of trace-gas transport in convection for the upper troposphere and stratosphere. The FAAM aircraft made a total of 25 flights in the region between 1°S and 14°N and 130° and 155°E. It was used to sample at altitudes below 8 km, with much of the time spent in the marine boundary layer. It measured a range of chemical species and sampled extensively within the region of main inflow into the strong west Pacific convection. The CAST team also made ground-based measurements of a number of species (including daily ozonesondes) at the Atmospheric Radiation Measurement Program site on Manus Island, Papua New Guinea (2.1°S, 147.4°E). This article presents an overview of the CAST project, focusing on the design and operation of the west Pacific experiment. It additionally discusses some new developments in CAST, including flights of new instruments on board the Global Hawk in February–March 2015.\n* CURRENT AFFILIATION: Centre for Atmospheric Informatics and Emissions Technology, Cranfield University, Cranfield, United Kingdom\nThis article is licensed under a Creative Commons Attribution 4.0 license .\nCORRESPONDING AUTHOR E-MAIL: Neil Harris, neil.harris@cranfield.ac.uk\nSection:\nThe CAST project involves studying the chemical composition of the atmosphere in the tropical warm pool region to improve our understanding of trace gas transport in convection.\nThe tropical tropopause layer (TTL) is the region of the tropical atmosphere between the main convective outflow at around 12–13 km and the base of the stratosphere at 17–18 km and is a very important region for composition–aerosol–climate interactions ( Randel and Jensen 2013 ). Its overall structure is intermediate between the troposphere and stratosphere, with a lapse rate smaller than the saturated adiabatic up to the cold point ( Fueglistaler et al. 2009 ). This is caused by the combined effect of slow radiative processes and the infrequent penetration of convective turrets to high altitudes. There is a marked longitudinal asymmetry in TTL temperatures, with a minimum in the region 130°E–180° during all times of the year. This minimum corresponds to the warm waters of the tropical warm pool (TWP) beneath, and there is an associated maximum in convection ( Gettelman et al. 2002 ). The TTL is the predominant route for troposphere-to-stratosphere transport, so that conditions in the TTL set the entry concentrations at the base of the stratosphere for, for example, stratospheric water vapor and very short-lived halogen species. Knowledge of the input into the TTL is a prerequisite for correct modeling of TTL (and hence stratospheric) composition and yet many aspects are poorly constrained ( Levine et al. 2007 ; Heyes et al. 2009 ). The couplings between the various processes are important. For example, improving the treatment of TTL water vapor and cirrus in global climate models requires a better understanding of convective transport and radiative transfer in the TTL, as well as improved model descriptions of the key processes.\nWe are still unclear about the entry and exit routes for the TTL, including how much material is transported quasi horizontally into the extratropical lowermost stratosphere ( Levine et al. 2008 ). What is the average residence time in the TTL? What is the nature, and importance for composition, of longitudinal variability within the TTL? How much of the very short-lived halogen species can pass through the TTL and so affect stratospheric ozone concentrations? Large discrepancies exist between models and measurements even for long-lived tracers. Some of these are due to transport—sharp horizontal gradients are observed in atmospheric tracers at boundaries between midlatitude, subtropical, and tropical air masses, which are not well represented by models ( Wofsy et al. 2011 )—and some to limited information on emissions [e.g., N2O and CH4 in this region; Ishijima et al. (2010) ]. These issues are more important for very short-lived substances (VSLSs, with lifetimes shorter than 6 months), including halogen-containing VSLSs with their poorly understood sources, atmospheric transformations, and geographic distributions ( Carpenter et al. 2014 ). Other effects such as the degree to which the locations of the emissions coincide with strong convection can also have a strong influence on the overall flux ( Russo et al. 2015 ).\nTo address these issues, the Facility for Airborne Atmospheric Measurements (FAAM) BAe-146 atmospheric research aircraft was deployed in Guam in January and February 2014 as part of the Coordinated Airborne Studies in the Tropics (CAST) campaign, a large multi-institutional project funded by the U.K. Natural Environment Research Council (NERC) and the Science and Technology Facilities Council (STFC). In Guam, it flew alongside the National Aeronautics and Space Administration’s (NASA) Global Hawk, a high-altitude autonomous aircraft used in the NASA Airborne Tropical Tropopause Experiment (ATTREX) project, and the National Science Foundation/National Center for Atmospheric Research (NSF/NCAR) Gulfstream V (GV) in the NSF Convective Transport of Active Species in the Tropics (CONTRAST) project, as described in the companion papers by Jensen et al. (2017) and Pan et al. (2017) . The measurements from all three campaigns are being jointly used to diagnose how air is carried high into the atmosphere.\nThe value inherent in having the three aircraft flying together was found in the ability to measure from the surface up into the stratosphere (see Fig. 1 in Pan et al. 2017 ). The instrument payloads on the three aircraft made many common measurements, which together have combined to provide a comprehensive dataset for interpretative studies. However, within this larger picture, each aircraft had its own scientific aims and objectives, which were appropriate to the specific aircraft’s capabilities. The Global Hawk made measurements in the upper TTL (14–20 km), including in the outflow of convection. The GV aircraft principally sampled at the same altitudes as the main convective outflow (9–15 km) and, additionally, made measurements on profiles down into the boundary layer. In the case of the FAAM aircraft, the aims were to a) investigate halocarbon production in the marine boundary layer and b) characterize the composition of air in the main convective inflow. Knowledge of the distributions of trace gases in the boundary layer and lower troposphere is needed to estimate the flux of these gases into the TTL. The role of the FAAM research aircraft was to fly over the tropical west Pacific and to measure the composition in the lower troposphere (0–8 km). These measurements characterize the air masses in the region of the main convective inflow and so are valuable in interpreting the higher-altitude measurements of the Global Hawk and the GV made during the same period. They can also be used to improve our understanding of marine halocarbon production and to investigate the influence of polluted outflow from Asia. Additional measurements were made on Manus, Papua New Guinea.\nThe majority of this paper describes the CAST measurements during January–February 2014, as well as the flight planning tools used for the FAAM aircraft and for linking its measurements with those made by the other aircraft. Some early results are also discussed. The second CAST goal is to develop the U.K. capability to use autonomous aircraft for atmospheric research. Here, in addition to learning about deploying the Global Hawk and using the data collected, CAST scientists have produced two new instruments for use on the Global Hawk, which flew over the east Pacific during February–March 2015. These are described in the final section.\nCAST MEASUREMENTS.\nSection:\nMeasurements were made on two main platforms in the west Pacific. The FAAM BAe-146 research aircraft was based at the A. B. Won Pat International Airport, Guam (13.5°N, 144.8°E). The FAAM aircraft was collocated with the NCAR Gulfstream while the NASA Global Hawk was based at Andersen Air Force Base, approximately 30 km to the northeast. A suite of ground-based instrument systems was based at the Atmospheric Radiation Measurement (ARM) facility at Manus (2.1°S, 147.4°E), in order to characterize the tropospheric composition beyond the range of the FAAM aircraft.\nFlight planning.\nThe goal of the CAST FAAM flights was to characterize the inflow to convection in the lower troposphere in the west Pacific. To extend the range of the aircraft so that it could reach into the upwelling area near the equator, overnight stops were planned at the islands of Palau (Roman Tmetuchl International Airport, Babeldaob island, Republic of Palau; 7.4°N, 134.5°E) and Chuuk (Chuuk International Airport, Weno Island, Federated States of Micronesia; 7.5°N, 151.8°E). When conditions allowed, transects were made at 100 feet (30.5 m) [with occasional dips down to 50 ft (15.2 m)] over the open ocean to give the opportunity to sample air influenced by fresh ocean emissions. Stacked runs with horizontal legs at different altitudes were planned where possible to provide information about the vertical profile of the short-lived species in the lower troposphere. A large part of the flight planning for the FAAM research aircraft was to ensure good coverage of the lower troposphere within range from Guam.\nChemical forecast products were provided by the Monitoring Atmospheric Composition and Climate (MACC) project in support of all three field campaigns. MACC assimilates comprehensive global observations of chemical composition into the European Centre for Medium-Range Weather Forecasts (ECMWF) meteorological forecasting system ( Flemming et al. 2015 ). The operational MACC system runs at 80-km horizontal resolution (T255) with 60 vertical levels. During the campaign, forecast plots for the operation domain were provided for a number of chemical species, including the FAAM measurements: O3, CO, CH4, black carbon, NO, and NO2. In addition, a number of hypothetical tracers were included to track air originating from different locations (e.g., regional emissions from China and India). A coastal emission tracer was used to track oceanic emissions of CHBr3 and other short-lived halocarbons since these are preferentially released in coastal regions ( Carpenter et al. 2009 ; Ashfold et al. 2014 ).\nLinking measurements.\nTo have near-real-time information about the air reaching the TTL from the lower troposphere, the trajectory-based approach of Ashfold et al. (2012) was adapted to meet the needs of a multiaircraft campaign. In this, the Numerical Atmospheric-Dispersion Modeling Environment (NAME) was run as an adjunct to the Met Office operational forecasting model so that it could access meteorological forecasts on a time scale quick enough to provide useful flight-planning information. The starting grid for the trajectories covered a large area of the west Pacific ( Fig. 7 ), with trajectories being released at altitudes between 8 and 18 km. Twelve-day backward trajectories were then calculated using a mixture of Met Office analyses and forecasts, so that information was available about the possible influence of lower-tropospheric air in the regions that could be sampled by the Global Hawk and the GV. Each day, trajectories were produced for 1, 2, 3 and 5 days into the future. In each 2-km-altitude layer, 5,000 particles were released in each 10° × 10° box. During the campaign, these calculations were made for a larger area at higher altitudes to reflect the larger range of the Global Hawk. The horizontal resolution of the Met Office operational model was 25 km in early 2014.\nAn example is shown in Fig. 1 for three altitude ranges (12–14, 14–16, and 16–18 km). Each point is the end point of each parcel of air that had crossed below 1 km in the preceding 12 days. For graphical clarity, only a fraction of the trajectories are shown at each level. Thus, strong, predicted low-level influence is indicated by a high percentage in each box (shown by the number), and at a given level by the denser clouds. These maps were routinely checked against flight plans for the Global Hawk and the GV to ensure that a wide range of low-level influences was sampled. In general, most flight plans met these criteria as a result of the proximity of the aircraft to the main convective region.\nView larger version (64K)\nFig. 1. Examples of trajectory-based forecast products used for multiaircraft flight planning. These plots are for 13 Feb 2014 when all three aircraft were in the same region [see Fig. 7 in Pan et al. (2016)]. The three panels show the location of air parcels which had been below 1-km altitude in the preceding 12 days at (a) 16–18, (b) 14–16, and (c) 12–14 km. The number in each box is the percentage of parcels in that box from below 1 km in the preceding 12 days. During the campaign, they were available as 1-, 3-, and 5-day forecasts for flight planning, and the NAME model was driven by analyses and forecasts from the Met Office operational model run at 25-km horizontal resolution.\nFAAM BAe-146 aircraft.\nThe FAAM BAe-146 has a science payload of up to 4 tons (∼3630 kg) devised according to the objectives of a particular campaign. The chemical composition of the tropical atmosphere is the focus of CAST and this dictated the scientific payload. The chemical species and physical parameters measured on the FAAM aircraft, along with the instruments used, are summarized in Table 1 . Trace gases with a wide range of atmospheric lifetimes, sources, and sinks were measured in order to provide information about the origin and fate of the air masses encountered, as well as about the atmospheric time scales involved. In many cases these species were also measured by the Global Hawk and/or the GV aircraft, giving good synergy between the three datasets. Understanding the distribution and chemistry of halogen species is a special focus for all three campaigns and this is reflected in the FAAM payload.\nTable 1. Instruments and measurements made by the BAe-146 (FAAM) aircraft during the CAST project. Also indicated are the synergy with other aircraft from the CONTRAST (GV) and ATTREX (Global Hawk) projects.\nTable 1. Instruments and measurements made by the BAe-146 (FAAM) aircraft during the CAST project. Also indicated are the synergy with other aircraft from the CONTRAST (GV) and ATTREX (Global Hawk) projects.\nImage of typeset table\nWhole air samples (WASs) were collected as described in Andrews et al. (2013) . Analysis of WAS canisters was carried out in the aircraft hangar, usually within 72 h of collection. Two liters of sample air were preconcentrated using a thermal desorption unit (Markes Unity2 CIA-T) and analyzed with gas chromatography–mass spectrometry (GC-MS; Agilent 7890 GC, 5977 Xtr MSD). Halocarbons were quantified using a NOAA calibration gas standard. Dimethylsulfide was quantified using a secondary standard prepared and referenced to a primary [Korea Research Institute of Standards and Science (KRISS)] standard. The full method is detailed in Andrews et al. (2013 , 2016) .\nMeasurements of a subset of halocarbons and other volatile organic compounds (VOCs) were made in flight using a new thermal desorption (TD) GC-MS system. A 1-L sample of air, drawn from a window blank inlet, pressurized to 2.5 atm (1 atm = 101,325 Pa), and dried using a multicore countercurrent nafion drier, was alternately preconcentrated or analyzed from two parallel adsorption traps (Tenax TA) of a two-channel TD system (Markes International, model TT 24/7). Analyses were refocused at the head of the column using liquid CO2 prior to separation (10 m, 180-μm inner diameter, 1-μm film, Restek RTX502.2 column; 40°–150°C at 40°C min−1) by GC (Agilent 6850) and detection by electron impact MS single-ion monitoring (Agilent 5975C), calibrated preflight against the WAS gas standard (NOAA, SX-3581). The instrument temporal resolution, and associated sample integration period, was 5 min.\nThe chemical ionization mass spectrometer (CIMS) from the Georgia Institute of Technology was configured similarly to previous deployments ( Le Breton et al. 2012 , 2013 ). The I− ionization scheme was used to detect inorganic halogens, carboxylic acids, HCN, and other trace species. For CAST, the CIMS made simultaneous measurements of BrO, BrCl, Br2, and HOBr. The 1-Hz data were averaged to 30 s for analysis. Precampaign and postflight laboratory calibrations were used relative to in-flight formic acid calibrations to quantify the sensitivities and limits of detection for the inorganic halogens, similar to that used for dinitrogen pentoxide ( Le Breton et al. 2014 ). The sensitivities ranged from 1 to 50 ion counts per part per trillion per second (ppt−1 s−1) determined by in-flight and postcampaign calibrations. The limits of detection for species varied from 0.36 to 37 ppt for 30-s-averaged data. (All mixing ratios given in this paper are by volume.) An acid scrubber was used to quantify the background signal in the instrument and inlet line.\nA broadband cavity-en-hanced absorption spectrometer (BBCEAS) was adapted to measure input/output (IO) in the 410–482-nm-wavelength region. No clear absorption feature was observable from spectra by eye with up to 100-s averaging, pointing to very low mixing ratios (<∼0.5 ppt) of IO over the sampled area. When using averaged data, a small positive bias (∼0.3 ppt) of IO was observed with respect to zero. These observations appear to support the existence of IO in the remote marine boundary layer at sub-ppt levels, but the limited sensitivity precludes robust identification of spatial gradients.\nNitrous oxide was measured using chemiluminescence and NO2 was quantified via a second channel, with NO2 being converted to NO using a blue-light LED converter centered at 395 nm. The NO2 mixing ratio is derived from the difference between the total NOx and NO mixing ratios. The instrument is calibrated via addition of 5 standard cubic centimeters per minute (sccm) of known NO concentration to the ambient sample. The conversion efficiency of the LED converter is measured in each calibration using gas-phase titration of NO to NO2 on addition of O3. In-flight calibrations were conducted above the boundary layer to ensure stable low levels of NOx with before- and after-flight calibrations made using an overflow at the inlet of zero-grade air. A more detailed description of a similar system can be found in Lee et al. (2009) .\nThe level of O3 was measured by an ultraviolet (UV) absorption photometer (Thermo Fisher, model 49C), traceable to the U.K. National Physical Laboratory primary ozone standard with an uncertainty of 2% and a precision of 1 ppb for 4-s measurements.\nThe CO level was measured by a vacuum UV fluorescence analyzer [Aero Laser GmbH, model AL5002; Gerbig et al. (1999) ]. The instrument was calibrated in flight approximately every 45 min using a synthetic-air working standard (Air Liquide, ∼500 ppb), traceable to the NOAA/Earth System Research Laboratory [Global Monitoring Division-Carbon Cycle Greenhouse Gases Group (GMD-CCGG)] surveillance standard and the World Meteorological Organization CO-scale X2004. The 1-Hz CO measurements have a 2% uncertainty and 3-ppb precision.\nThe CO2 and CH4 levels were measured by a cavity-enhanced IR absorption spectrometer (Los Gatos Research, Inc., fast greenhouse gas analyzer, model RMT-200). The instrument was customized for airborne operations ( O’Shea et al. 2013 ), so CO2 and CH4 dry mole fractions can be linearized in flight using natural-air working standards, traceable to the World Meteorological Organization CO2-scale X2007 and CH4-scale X2004. The performance of the system is estimated from one standard deviation of all in-flight “target” calibration data. The 1-Hz measurement precisions are estimated at 0.7 ppm and 2.5 ppb for CO2 and CH4, respectively. Through the addition of all known uncertainties, we estimate a total accuracy of ±1.3 ppb for CH4 and ±0.2 ppm for CO2.\nThe Passive Cavity Aerosol Spectrometer Probe 100-X (PCASP), upgraded with the SPP-200 electronics package from Droplet Measurement Technologies (DMT), measures aerosol particles with nominal diameters of 0.1–3 µm. Light from a 0.6328-µm laser is scattered by the particles and a photodetector sums the forward (over solid angles subtended by 35°–120°) and backward (60°–145°) scattered light. The probe is canister mounted under the wing and was operated at 1 Hz. The instrument was calibrated for particle size before and after the campaign. Uncertainties exist in both the sizing and the counting of particles and these are discussed, along with the calibration procedure, in Rosenberg et al. (2012) .\nThe DMT Cloud Droplet Probe (CDP; Lance et al. 2010 ) was flown on the same under-wing pylon as the PCASP. The CDP is an open-path instrument that measures the forward-scattered light (over solid angles nominally subtended by 1.7°–14°) from the 0.658-µm incident laser beam. Particles are assigned to 1 of 30 size bins over the nominal size range 3–50 µm. Calibration with certified diameter glass beads was carried out before each flight ( Rosenberg et al. 2012 ). The sample rate of the CDP was the same as for the PCASP, 1 Hz.\nManus.\nObservations started at the ARM climate facility on Manus during October 1996 ( Mather et al. 1998 ) and continued until August 2014. These observations provided the basis for many studies of the climate in the west Pacific (e.g., Long et al. 2013 and references therein). In February 2014, a suite of ground-based instruments was deployed as part of CAST to make measurements of ozone (ground and profile), short-lived halocarbons, carbon dioxide, carbon monoxide, and methane. The instruments used are now described and are also summarized in Table 2 .\nTable 2. Measurements made at the ARM site at Manus during CAST. Information about the meteorological measurements from Manus can be found online ( www.arm.gov/sites/twp/C1/instruments ).\nTable 2. Measurements made at the ARM site at Manus during CAST. Information about the meteorological measurements from Manus can be found online ( www.arm.gov/sites/twp/C1/instruments ).\nImage of typeset table\nOzone profiles were measured using ozonesondes. Air is pumped through a potassium–iodine (KI) solution in a cathode half-cell, with two electrons produced for each ozone molecule; the cell current is directly proportional to the flow of ozone through the cell. Ozonesondes have a typical response time of about 1 min at the tropopause level, with a precision of a few parts per billion. In the TTL the accuracy of the measurement is dominated by the background current ( Newton et al. 2016 and references therein). Simultaneously, vertical profiles of temperature, humidity, wind, and pressure were measured with Vaisala RS92 radiosondes.\nGround-level ozone was measured by a Thermo-Electric Corporation TE49C, which is a dual-channel ultraviolet photometer measuring ozone through absorption of radiation at 254 nm. The incoming airstream is split between two identical cells, with a scrubber removing ozone from one of the streams. The TE49C provides a measurement every 10 s and has a 20-s response time.\nGround-level trace-gas concentrations were measured by a Picarro Cavity Ring-Down Spectrometer G2401 (CRDS; Crosson 2008 ). The sample air inlet was at about 8 m above ground level with a rain cover and a 2-µm particulate filter. Water vapor in the instrument was kept below 1.5 ppm and was controlled by passing the sample flow (∼250 mL min−1) through a chiller at approximately 5°C and then through a desiccant-based nafion drier. CO2 and CH4 concentrations were recorded every 5 s, with precisions of ∼1 and ∼200 ppb, respectively. Calibrations were achieved using a target gas (CH4, 2024 ppb; CO2, 390 ppm) measured every 2 days for 10 min with low and high calibration runs on intermediate days [low (high): CH4, 1919 (2736) ppb; CO2, 360 (495) ppm]. The calibration gases are linked to the NOAA–WMO calibration scale.\nSurface concentrations of short-lived halocarbons were measured using a µDirac instrument, a gas chromatograph with an electron capture detector (GC-ECD) based on an instrument described in Gostlow et al. (2010) but with a 10-m separation column. The instrument sampled ambient air from the roughly 8-m-high mast, with a 10–20 mL min–1 flow dried using a counterflow nafion drier. Calibration runs, using a NOAA/ESRL air cylinder spiked with the target compounds, were conducted regularly (every three samples). The calibration volumes ranged from 3 to 50 mL to allow correction for drifts in instrument sensitivity and linearity. Measurement precision is species dependent, typically 2%–10% (plus or minus one standard deviation), with accuracy in the range of 5%–10% (plus or minus one standard deviation).\nOVERVIEW OF MEASUREMENTS.\nSection:\nThe FAAM BAe-146 made a total of 25 science flights totaling 90 flight hours during the CAST deployment in the west Pacific ( Fig. 2 ). Brief summaries of the flights are given in Table 3 . The flight tracks are shown in Fig. 2 , with the altitude represented by the color of the line. The large majority of the flights were below 5-km altitude, with a significant fraction in the marine boundary layer (below about 1 km), with good coverage between 2°S and 14°N and 130° and 160°E.\nView larger version (78K)\nFig. 2. Map of FAAM BAe-146 flight tracks during Jan–Feb 2014. The flight tracks are colored by altitude. The islands of Guam, Palau, and Chuuk are marked. The background shows Jan–Feb-averaged Chl-a concentrations in 2014, measured by the MODIS satellite [NASA Giovanni: Acker and Leptoukh (2007) ]. The inset shows an enlarged area around Chuuk atoll.\nTable 3. Research flights made by the BAe-146 (FAAM) aircraft during the CAST project.\nTable 3. Research flights made by the BAe-146 (FAAM) aircraft during the CAST project.\nImage of typeset table\nThe vertical distribution of the science flights can also be seen in Fig. 3 , which shows O3 and CO concentrations as a function of altitude and latitude. In general, lower O3 values are found in the marine boundary layer and at lower latitudes, while high values are found at higher altitudes and at higher latitudes. There is no obvious correlation with CO. However, when the O3 and CO data are plotted against each other ( Fig. 4 ), a bimodal relationship emerges. Further, the lower ozone values (10–40 ppb) occur when the relative humidity is high ( Fig. 4 , top). This finding reinforces that of Pan et al. (2015) , who report this bimodality throughout the altitude range covered by the NCAR GV, with a background mode of nearly constant (∼20 ppb) values throughout the troposphere and a secondary mode of higher ozone (∼35–95 ppb) in layers with lower relative humidity. The previously reported S-shaped mean profile ( Folkins et al. 2002 ) results from averaging the two modes.\nView larger version (44K)\nFig. 3. (top left) Ozone and (top right) carbon monoxide mixing ratios measured during all CAST flights as a function of latitude and altitude. (right) The means and associated two standard deviations of ozone and carbon monoxide are shown as a function of altitude. See text and Table 1 for instrumental details.\nView larger version (44K)\nFig. 4. Plots of O3 against CO colored by (bottom) NO and (top) relative humidity (10-s-averaged data).\nThe CAST measurements ( Fig. 4 ) show that high ozone and lower relative humidity often occurs with higher NO concentrations and does not occur with low CO concentrations. Preliminary analysis of the high NO measurements indicates that the air masses encountered had previously been in regions close to anthropogenic activities and/or biomass burning. For example, the MACC forecasts show the transport of biomass burning and Southeast Asian tracers to the west Pacific. The possible role of biomass burning has been thoroughly investigated by Anderson et al. (2016) using CAST and CONTRAST measurements. The presence of HCN, CH3CN, and other tracers in the high-ozone levels is explained by biomass-burning plumes, which are convectively lofted into the free troposphere undergoing dehydration during the convection. As this air descends, its relative humidity drops and ozone is produced photochemically.\nThe CHBr3 concentrations measured with the Whole Air Sampler and the onboard GC-MS are shown in Fig. 5 . In general the values are low, with even the higher values not far above the background values seen in this region ( Brinckmann et al. 2012 ). The lower amounts of CHBr3 were encountered out of the boundary layer ( Fig. 4b ). The background in Fig. 2 shows that the chlorophyll-a (Chl-a) concentrations in the surface waters of the west Pacific were low during this period. Higher Chl-a values are seen in the shallower waters approaching the islands of the Maritime Continent. The lagoon inside Chuuk atoll is relatively shallow (<60 m) and is embedded in much deeper ocean waters. It has a circumference of about 200 km and an area of about 3000 km2. If halocarbons are emitted preferentially in shallow waters ( Carpenter et al. 2009 ), then it should be discernible as an emission hotspot. The influence of short-lived halocarbon emissions from shallower waters was investigated during the FAAM flights by circling Chuuk atoll at low altitudes. The inset in Fig. 5a shows the CHBr3 observed on these flights as well as the instantaneous wind speed observed by the FAAM aircraft. Higher concentrations of CHBr3 (red) are found when air has previously passed over the atoll, indicating that the atoll is a source of CHBr3.\nView larger version (44K)\nFig. 5. CHBr3 mixing ratios (colors) sampled by the FAAM aircraft during CAST using the whole air sampler (squares) and the onboard GC-MS (circles). (a) All measurements made at altitudes less than 1 km. The enlarged inset shows the values around the Chuuk atoll. The lines associated with each measurement in the inset indicate the instantaneous wind speed measured by the aircraft. (b) The measurements at altitudes greater than 1 km. The inset shows the vertical profile of all measurements.\nThe NAME model driven by Met Office analyzed fields has been used to interpret the CHBr3 and other brominated VSLS measurements made near the tropopause on the Global Hawk in the east Pacific during 2013 and the west Pacific during 2014 ( Navarro et al. 2015 ). The approach is similar to the forecast information produced during the campaign (see above). They find that the majority of air recently injected into the TTL had come from the west Pacific in both years with similar amounts, approximately 6 (4–9) ppt, of combined organic and inorganic bromine derived from brominated VSLS.\nAt the ARM facility in Manus, CHBr3 was also observed ( Fig. 5 ). The median value in this period was 0.81 ppt, about half that previously observed at a coastal site in Malaysian Borneo ( Robinson et al. 2014 ) and similar to the values observed on the FAAM aircraft ( Fig. 4 ). A strong diurnal cycle is seen in early February in several trace gases measured at Manus with increased nocturnal amounts, providing evidence for local nighttime sources of CO2, CH4, CHBr3, and CH3I. This diurnal pattern of behavior was seen from 3 to 12 February when the winds were low and a stable boundary layer was able to form. Before and after this period winds were higher and the nighttime buildup was much less.\nTogether, the CHBr3 observations appear to be consistent with past work focused on Southeast Asia. Elevated levels are frequently observed close to coasts (e.g., Pyle et al. 2011 ) or above shallow waters, but measurements collected a relatively small distance away (less than a typical global model grid cell) rarely contain above-background levels of CHBr3. This suggests that coasts are not a large source in a regional/global sense (as found by Ashfold et al. 2014 ), and for coastal CHBr3 emissions to contribute significantly to the TTL and stratosphere would require collocation of convection ( Russo et al. 2015 ).\nGround-based ozone at Manus showed decreases at night in the quiescent period from a peak daytime value of 10 to <5-ppb levels which is consistent with oxidative uptake to the local vegetation ( Fig. 6 ). This is the only time such low values of ozone were seen in CAST. In the absence of local sources, C2Cl4 is a good tracer of large-scale transport, and its concentrations during this period were generally in the range 1–1.5 ppt, which is typical of results seen in the clean west Pacific ( Ashfold et al. 2015 ). Manus was mainly influenced by flow from the north throughout this period.\nView larger version (103K)\nFig. 6. Surface observations of (top to bottom) wind, O3, CO2, CH4, C2Cl4, CHBr3, and CH3I at the ARM facility on Manus from 1 to 24 Feb 2014. The time shown along the x axis is universal time. The shading indicates the local time, with the darker bands representing nighttime.\nA total of 39 ozonesondes were launched from Manus in February 2014, with 34 sondes providing good ozone profiles ( Fig. 7a ; Newton et al. 2016 ). These measurements are most difficult in the tropics as the ozone concentrations are low, so that any error in estimating the background current is important. Particular attention was therefore paid to measurements of the background current, leading to recommendations for changes to the standard operation procedures used in the sonde preparation. Support for this approach is provided by good agreement in a coordinated ozonesonde–GV flight (see Fig. 14 in Pan et al. 2017 ). The ozone measurements are shown in Fig. 7 alongside the corresponding MACC 1- and 4-day forecasts. The forecasts predicted the main characteristics of the observations such as increased ozone at about 400 hPa from 14 to 16 February and the low concentrations near the TTL from 19 to 23 February. The minimum reproducible ozone concentration measured in the TTL was 12 ppb, consistent with the minimum of 13 ppb measured by the GV during CONTRAST ( Pan et al. 2017 ).\nFig. 7. (left) Daily observed ozone profile in Manus and corresponding MACC forecasts with lead times of (center) 1 and (right) 4 days.\nNew technology developments.\nAs part of the collaboration with ATTREX, three new developments were included in CAST: two instruments for use on the Global Hawk, the Aerosol–Ice–Interface Transition Spectrometer (AIITS) and the Greenhouse Gas Observations in the Stratosphere and Troposphere (GHOST), along with a software tool, Real-Time Atmospheric Science Cluster Analysis (RASCAL), designed to assist aircraft scientists by performing real-time data analysis during flights. The two new instruments were flown for a total of 40 h during one test flight and two science flights in February–March 2015 from the NASA Armstrong Flight Research Center, Edwards Air Force Base, California. They were part of a payload that also included Hawkeye, the NOAA H2O and O3 instruments, the Global Hawk Whole Air Sampler (GWAS), and the Microwave Temperature Profiler (MTP) (see Jensen et al. 2017 for more details).\nAIITS was designed to probe different cirrus regimes in the TTL in order to understand fundamental nucleation and sublimation processes influencing the stratospheric water budget and fluxes, as well as the potential impact of biomass burning on cirrus ice crystal activation and growth. It is the next instrument in the Small Ice Detector (SID) family ( Hirst et al. 2001 ; Kaye et al. 2008 ). AIITS acquires 2D forward-scattering patterns from particles in the size range from about one to a few hundred micrometers and can measure the depolarization in backward and forward scattering. The patterns allow quantification of the phase, habit, and fine surface features of large aerosol and small ice crystals in the size range 2–100 µm ( Cotton et al. 2010 ; Ulanowski et al. 2014 ). Unique results were obtained by AIITS during cirrus penetrations at 16.5 km and at temperatures down to -80°C ( Fig. 8 ). These revealed a transition to smooth quasi-spherical ice particle regimes in specific regions of TTL layers in response to changing supersaturation regimes. The impact on the radiative scattering properties of cirrus in these regimes is being investigated.\nView larger version (60K)\nFig. 8. AIITS scattering patterns recorded from ice particles in the upper troposphere–lower stratosphere (UTLS), at altitudes of about 16 km and temperatures of about –80°C. The pictures are indicative of (left) a smooth quasi-spherical ice particle, (center) a columnar crystal, and (right) a pristine hexagonal plate.\nGHOST is a novel grating spectrometer designed for remote sensing of greenhouse gases from aircraft ( Humpage et al. 2014 ). It measures spectrally resolved shortwave-infrared radiance across four spectral bands from 1.27 to 2.3 µm, with a spectral resolution between 0.1 and 0.3 nm. An optical gimbal underneath the aircraft is programmed to pass solar radiation reflected from the ocean surface through a fiber optic bundle into the spectrometer with a single grating and detector for all four bands. The bands are chosen to include absorption bands for CO2 and CH4 as well as CO, H2O, and O2; O2 is used to infer information on the scattering contributions toward the measured light. The third Global Hawk flight of the CAST/ATTREX campaign targeted the overpasses of two greenhouse gas observing satellites during clear-sky conditions over the eastern Pacific ( Fig. 9 ): the NASA Orbiting Carbon Observatory (OCO-2) and the Japan Aerospace Exploration Agency (JAXA) Greenhouse Gas Observing Satellite (GOSAT). This Global Hawk flight therefore provides a very useful validation dataset for these satellites, since they both make greenhouse gas measurements using a spectral range similar to that of GHOST.\nView larger version (87K)\nFig. 9. Flight path of the NASA Global Hawk on 10 Mar 2015 (blue). The OCO-2 (green) and GOSAT (red) soundings are shown and coincide temporally with the flight leg between 25°N, 127°W and 18°N, 125°W. MODIS cloud fraction data (see gray scale bar; Platnick et al. 2015 ) coincident with the OCO-2 overpass at 2140 UTC shows the largely cloud-free conditions encountered during this leg of the flight.\nAs real-time data becomes increasingly available, mission scientists are faced with a potentially overwhelming data torrent, from which they are required to find the information on which to base decisions. At present, mission scientists often focus on a subset of the data stream, limiting the depth of the analysis that can be carried out. As part of CAST, a new software framework, RASCAL, has been developed based on recent developments in arbitrarily shaped cluster detection algorithms ( Hyde and Angelov 2015 ). It interfaces intuitively with mission scientist expert knowledge and provides real-time on-the-fly cluster and anomaly detection (i.e., for real-time diagnosis of structures such as those presented in Fig. 4 , for example, but tested simultaneously across many chemical “dimensions”). The data stream can be separated in real time, without a priori assumptions about parameter relationships, to reveal different data groups and hence isolate specific regions of interest that can be revisited virtually postflight. In combination with the expert knowledge of the mission scientists, support tools like RASCAL have the potential to be used on many research aircraft, potentially adding significant value to the results achieved in field measurement campaigns.\nSUMMARY.\nSection:\nBased in Guam as part of a joint deployment with the NASA ATTREX Global Hawk and the NSF CONTRAST GV, the FAAM research aircraft deployment during CAST has provided an excellent characterization of the lower-tropospheric atmospheric composition in the tropical warm pool region. The majority of the FAAM aircraft flights were below 5-km altitude, and a significant fraction was in the marine boundary layer with good coverage from 2°S to 14°N and from 130° to 160°E. A suite of organic and inorganic halogen compounds was measured, with the bromine-containing species being particularly well covered.\nGround-based measurements were made at the ARM facility on Manus Island, Papua New Guinea, during February 2014. These measurements characterize the tropospheric composition just south of the equator in a region inaccessible to the FAAM aircraft in this deployment. The Manus ozonesonde measurements are a valuable resource, providing a good picture of the vertical distribution of ozone in the tropical warm pool region during February with a minimum ozone concentration in the TTL of 12 ppb.\nThese measurements are being interpreted by CAST scientists in conjunction with measurements from ATTREX and CONTRAST using a range of modeling and data analysis approaches. The CAST data are stored at the British Atmospheric Data Centre ( http://badc.nerc.ac.uk/ ), and interested parties are encouraged to use them for their own studies. All users are strongly encouraged to involve the responsible instrument scientists in these studies in order to gain insight into the strengths and weaknesses of these data.\nNever before has the atmosphere over the west Pacific been observed in such detail, particularly the chemical composition, with three aircraft covering all altitudes from 0 to 20 km. New insights are starting to emerge with a much improved understanding of the tropical ozone distribution ( Pan et al. 2015 ; Anderson et al. 2016 ; Newton et al. 2016 ). These findings will be underpinned by advances in the understanding of halogen distribution ( Navarro et al. 2015 ) and chemistry building on the new tropospheric halogen measurements and modeling ( Sherwen et al. 2016 ). Such research will lead to a much greater quantitative understanding of the role of a) VSLS reaching the stratosphere and b) how halogen chemistry affects tropospheric ozone over the tropical oceans. Similar advances can be expected with respect to transport and dynamics, the role of cirrus clouds in climate, and dehydration of the stratosphere. The benefits of this unique, coordinated campaign are just starting to become clear.\nACKNOWLEDGMENTS\nCAST is funded by NERC and STFC, with Grants NE/ I030054/1 (lead award), NE/J006262/1, NE/J006238/1, NE/J006181/1, NE/J006211/1, NE/J006061/1, NE/J006157/1, NE/J006203/1, NE/J00619X/1, and NE/J006173/1. NRPH was supported by a NERC Advanced Research Fellowship (NE/G014655/1). PIP acknowledges his Royal Society Wolfson Research Merit Award. The BAe-146-301 Atmospheric Research Aircraft is flown by Directflight Ltd, and managed by the Facility for Airborne Atmospheric Measurements, which is a joint entity of the Natural Environment Research Council and the Met Office. The authors thank the staff at FAAM, Directflight, and Avalon Aero, who worked so hard toward the success of the aircraft deployment in Guam, especially for their untiring efforts when spending an unforeseen nine days in Chuuk. We thank the local staff at Chuuk and Palau, as well as the authorities in the Federated States of Micronesia for their help in facilitating our research flights. Special thanks go to the personnel associated with the ARM facility at Manus, Papua New Guinea, without whose help the ground-based measurements would not have been possible. Thanks to the British Atmospheric Data Centre (BADC) for hosting our data and the NCAS Atmospheric Measurement Facility for providing the radiosonde and ground-based ozone equipment. Chlorophyll-a data used in Fig. 1 were extracted using the Giovanni online data system, maintained by the NASA GES DISC. We acknowledge the MODIS mission scientists and associated NASA personnel for the production of this dataset. Finally we thank many individuals associated with the ATTREX and CONTRAST campaigns for their help in the logistical planning, and we would like to single out Jim Bresch for his excellent and freely provided meteorological advice.\nREFERENCES\nSection:\nAcker, J. G., and G. Leptoukh, 2007: Online analysis enhances use of NASA Earth science data. Eos, Trans. Amer. Geophys. Union, 88, 14–17, doi: https://doi.org/10.1029/2007EO020003 . Crossref\nAnderson, D. C., and Coauthors, 2016: A pervasive role for biomass burning in tropical high ozone/low water structures. Nat. Commun., 7, 10267, doi: https://doi.org/10.1038/ncomms10267 . Crossref\nAndrews, S. J., C. E. Jones, and L. J. Carpenter, 2013: Aircraft measurements of very short-lived halocarbons over the tropical Atlantic Ocean. Geophys. Res. Lett., 40, 1005–1010, doi: https://doi.org/10.1002/grl.50141 . Crossref\nAndrews, S. J., and Coauthors, 2016: A comparison of very short lived halocarbon (VSLS) and DMS aircraft measurements in the tropical west Pacific from CAST, ATTREX and CONTRAST. Atmos. Meas. Tech., 9, 5213–5225, doi: https://doi.org/10.5194/amt-9-5213-2016 . Crossref\nAshfold, M. J., N. R. P. Harris, E. L. Atlas, A. J. Manning, and J. A. Pyle, 2012: Transport of short-lived species into the tropical tropopause layer. Atmos. Chem. Phys., 12, 6309–6322, doi: https://doi.org/10.5194/acp-12-6309-2012 . Crossref\nAshfold, M. J., N. R. P. Harris, A. J. Manning, A. D. Robinson, N. J. Warwick, and J. A. Pyle, 2014: Estimates of tropical bromoform emissions using an inversion method. Atmos. Chem. Phys., 14, 979–994, doi: https://doi.org/10.5194/acp-14-979-2014 . Crossref\nAshfold, M. J., and Coauthors, 2015: Rapid transport of East Asian pollution to the deep tropics. Atmos. Chem. Phys., 15, 3565–3573, doi: https://doi.org/10.5194/acp-15-3565-2015 . Crossref\nBrinckmann, S., A. Engel, H. Bönisch, B. Quack, and E. Atlas, 2012: Short-lived brominated hydrocarbons—Observations in the source regions and the tropical tropopause layer. Atmos. Chem. Phys., 12, 1213–1228, doi: https://doi.org/10.5194/acp-12-1213-2012 . Crossref\nCarpenter, L. J., C. E. Jones, R. M. Dunk, K. E. Hornsby, and J. Woeltjen, 2009: Air–sea fluxes of biogenic bromine from the tropical and North Atlantic Ocean. Atmos. Chem. Phys., 9, 1805–1816, doi: https://doi.org/10.5194/acp-9-1805-2009 . Crossref\nCarpenter, L. J., and Coauthors, 2014: Ozone-depleting substances (ODSs) and other gases of interest to the Montreal Protocol. Scientific Assessment of Ozone Depletion: 2014, A. Engel and S. A. Montzka, Eds., Global Ozone Research and Monitoring Project Rep. 55, World Meteorological Organization, 1–101. [Available online at www.wmo.int/pages/prog/arep/gaw/ozone_2014/documents/Full_report_2014_Ozone_Assessment.pdf .]\nCotton, R., S. Osborne, Z. Ulanowski, E. Hirst, P. H. Kaye, and R. Greenaway, 2010: The ability of the Small Ice Detector (SID2) to characterize cloud particle and aerosol morphologies obtained during flights of the FAAM BAe-146 research aircraft. J. Atmos. Oceanic Technol., 27, 290–303, doi: https://doi.org/10.1175/2009JTECHA1282.1 . Link\nCrosson, E. R., 2008: A cavity ring-down analyzer for measuring atmospheric levels of methane, carbon dioxide, and water vapor. Appl. Phys. B, 92, 403–408, doi: https://doi.org/10.1007/s00340-008-3135-y . Crossref\nFlemming, J., and Coauthors, 2015: Tropospheric chemistry in the Integrated Forecasting System of ECMWF. Geosci. Model Dev., 8, 975–1003, doi: https://doi.org/10.5194/gmd-8-975-2015 . Crossref\nFolkins, I., C. Braun, A. M. Thompson, and J. Witte, 2002: Tropical ozone as an indicator of deep convection. J. Geophys. Res., 107, 4184, doi: https://doi.org/10.1029/2001JD001178 . Crossref\nFueglistaler, S., A. E. Dessler, T. J. Dunkerton, I. Folkins, Q. Fu, and P. W. Mote, 2009: Tropical tropopause layer. Rev. Geophys., 47, RG1004, doi: https://doi.org/10.1029/2008RG000267 . Crossref\nGerbig, C., S. Schmitgen, D. Kley, A. Volz-Thomas, K. Dewey, and D. Haaks, 1999: An improved fast-response VUV resonance flourescence CO instrument. J. Geophys. Res., 104, 1699–1704, doi: https://doi.org/10.1029/1998JD100031 . Crossref\nGettelman, A., M. L. Salby, and F. Sassi, 2002: Distribution and influence of convection in the tropical tropopause region. J. Geophys. Res., 107, doi: https://doi.org/10.1029/2001JD001048 . Crossref\nGostlow, B., and Coauthors, 2010: Micro-DIRAC: An autonomous instrument for halocarbon measurements. Atmos. Meas. Tech., 3, 507–521, doi: https://doi.org/10.5194/amt-3-507-2010 . Crossref\nHeyes, W. J., G. Vaughan, G. Allen, A. Volz-Thomas, H.-W. Pätz, and R. Busen, 2009: Composition of the TTL over Darwin: Local mixing or long-range transport? Atmos. Chem. Phys., 9, 7725–7736, doi: https://doi.org/10.5194/acp-9-7725-2009 . Crossref\nHirst, E., P. H. Kaye, R. S. Greenaway, P. Field, and D. W. Johnson, 2001: Discrimination of micrometre-sized ice and super-cooled droplets in mixed-phase cloud. Atmos. Environ., 35, 33–47, doi: https://doi.org/10.1016/S1352-2310(00)00377-0 . Crossref\nHopkins, J. R., K. A. Read, and A. C. Lewis, 2003: A two column method for long-term monitoring of non-methane hydrocarbons (NMHCs) and oxygenated volatile organic compounds. J. Environ. Monit., 5, 8–13, doi: https://doi.org/10.1039/b202798d . Crossref\nHumpage, N., and Coauthors, 2014: GreenHouse Observations of the Stratosphere and Troposphere (GHOST): A novel shortwave infrared spectrometer developed for the Global Hawk unmanned aerial vehicle. Proc. SPIE 9242, Remote Sensing of Clouds and the Atmosphere XIX and Optics in Atmospheric Propagation and Adaptive Systems XVII, A. Comerón et al., Eds., International Society for Optical Engineering (SPIE Proceedings, Vol. 92420P), doi: 10.1117/12.2067330.\nHyde, R., and P. Angelov, 2015: A new online clustering approach for data in arbitrary shaped clusters. Proc. Second Int. Conf. on Cybernetics, Gydnia, Poland, IEEE, 228–233, doi: 10.1109/CYBConf.2015.7175937.\nIshijima, K., and Coauthors, 2010: Stratospheric influence on the seasonal cycle of nitrous oxide in the troposphere as deduced from aircraft observations and model simulations. J. Geophys. Res., 115, D20308, doi: https://doi.org/10.1029/2009JD013322 . Crossref\nJensen, E. J., and Coauthors, 2017: The NASA Airborne Tropical Tropopause Experiment (ATTREX): High-altitude aircraft measurements in the tropical western Pacific. Bull. Amer. Meteor. Soc., 98, 129–143, doi: https://doi.org/10.1175/BAMS-D-14-00263.1 . Link\nKaye, P. H., E. Hirst, R. S. Greenaway, Z. Ulanowski, E. Hesse, P. J. DeMott, C. Saunders, and P. Connolly, 2008: Classifying atmospheric ice crystals by spatial light scattering. Opt. Lett., 33, 1545, doi: https://doi.org/10.1364/OL.33.001545 . Crossref\nKennedy, O. J., and Coauthors, 2011: An aircraft based three channel broadband cavity enhanced absorption spectrometer for simultaneous measurements of NO3, N2O5 and NO2. Atmos. Meas. Tech., 4, 1759–1776, doi: https://doi.org/10.5194/amt-4-1759-2011 . Crossref\nLance, S., C. A. Brock, D. Rogers, and J. A. Gordon, 2010: Water droplet calibration of the Cloud Droplet Probe (CDP) and in-flight performance in liquid, ice and mixed-phase clouds during ARCPAC. Atmos. Meas. Tech., 3, 1683–1706, doi: https://doi.org/10.5194/amt-3-1683-2010 . Crossref\nLe Breton, M., and Coauthors, 2012: Airborne observations of formic acid using a chemical ionization mass spectrometer. Atmos. Meas. Tech., 5, 3029–3039, doi: https://doi.org/10.5194/amt-5-3029-2012 . Crossref\nLe Breton, M., and Coauthors, 2013: Airborne hydrogen cyanide measurements using a chemical ionisation mass spectrometer for the plume identification of biomass burning forest fires. Atmos. Chem. Phys., 13, 9217–9232, doi: https://doi.org/10.5194/acp-13-9217-2013 . Crossref\nLe Breton, M., and Coauthors, 2014, The first airborne comparison of N2O5 measurements over the UK using a CIMS and BBCEAS during the RONOCO campaign. Anal. Methods, 6, 9731–9743, doi: https://doi.org/10.1039/c4ay02273d . Crossref\nLee, J. D., S. J. Moller, K. A. Read, A. C. Lewis, L. Mendes, and L. J. Carpenter, 2009: Year-round measurements of nitrogen oxides and ozone in the tropical North Atlantic marine boundary layer. J. Geophys. Res., 114, D21302, doi: https://doi.org/10.1029/2009JD011878 . Crossref\nLenschow, D. H., 1986: Aircraft measurements in the boundary layer. Probing the Atmospheric Boundary Layer, D. H. Lenschow, Ed., Amer. Meteor. Soc., 39–55.\nLevine, J. G., P. Braesicke, N. R. P. Harris, N. H. Savage, and J. A. Pyle, 2007: Pathways and timescales for troposphere-to-stratosphere transport via the tropical tropopause layer and their relevance for very short lived substances. J. Geophys. Res., 112, D04308, doi: https://doi.org/10.1029/2005JD006940 . Crossref\nLevine, J. G., P. Braesicke, N. R. P. Harris, and J. A. Pyle, 2008: Seasonal and inter-annual variations in troposphere-to-stratosphere transport from the tropical tropopause layer. Atmos. Chem. Phys., 8, 3689–3703, doi: https://doi.org/10.5194/acp-8-3689-2008 . Crossref\nLiu, D., and Coauthors, 2015: The importance of Asia as a source of black carbon to the European Arctic during springtime 2013. Atmos. Chem. Phys., 15, 11 537–11 555, doi: https://doi.org/10.5194/acp-15-11537-2015 . Crossref\nLong, C. N., and Coauthors, 2013: ARM research in the equatorial western Pacific: A decade and counting. Bull. Amer. Meteor. Soc., 94, 695–708, doi: https://doi.org/10.1175/BAMS-D-11-00137.1 . Link\nMather, J. H., T. P. Ackerman, W. E. Clements, F. J. Barnes, M. D. Ivey, L. D. Hatfield, and R. M. Reynolds, 1998: An Atmospheric Radiation and Cloud Station in the tropical western Pacific. Bull. Amer. Meteor. Soc., 79, 627–642, doi: https://doi.org/10.1175/1520-0477(1998)079<0627:AARACS>2.0.CO;2 .\nNavarro, M. A., and Coauthors, 2015: Airborne measurements of organic bromine compounds in the Pacific tropical tropopause layer. Proc. Nat. Acad. Sci., 112, 13 789–13 793, doi: https://doi.org/10.1073/pnas.1511463112 . Crossref\nNewton, R., G. Vaughan, H. M. A. Ricketts, L. L. Pan, A. J. Weinheimer, and C. Chemel, 2016: Ozonesonde profiles from the west Pacific warm pool: Measurements and validation. Atmos. Chem. Phys., 6, 619–634, doi: https://doi.org/10.5194/acp-16-619-2016 . Crossref\nO’Shea, S. J., S. J.-B. Bauguitte, M. W. Gallagher, D. Lowry, and C. J. Percival, 2013: Development of a cavity-enhanced absorption spectrometer for airborne measurements of CH4 and CO2. Atmos. Meas. Tech., 6, 1095–1109, doi: https://doi.org/10.5194/amt-6-1095-2013 . Crossref\nPan, L. L., and Coauthors, 2015: Bimodal distribution of free tropospheric ozone over the tropical western Pacific revealed by airborne observations. Geophys. Res. Lett., 42, 7844–7851, doi: https://doi.org/10.1002/2015GL065562 . Crossref\nPan, L. L., and Coauthors, 2017: The Convective Transport of Active Species in the Tropics (CONTRAST) experiment. Bull. Amer. Meteor. Soc., 98, 106–128, doi: https://doi.org/10.1175/BAMS-D-14-00272.1 . Link\nPetersen, G. N., and I. A. Renfrew, 2009: Aircraft-based observations of air–sea fluxes over Denmark Strait and the Irminger Sea during high wind speed conditions. Quart. J. Roy. Meteor. Soc., 135, 2030–2045, doi: https://doi.org/10.1002/qj.355 . Crossref\nPlatnick, S., and Coauthors, 2015: MODIS Atmosphere L2 Cloud Product (06_L2). NASA MODIS Adaptive Processing System, NASA Goddard Space Flight Center, accessed 23 October 2015, doi: 10.5067/MODIS/MYD06_L2.006.\nPyle, J. A., and Coauthors, 2011: Bromoform in the tropical boundary layer of the Maritime Continent during OP3. Atmos. Chem. Phys., 11, 529–542, doi: https://doi.org/10.5194/acp-11-529-2011 . Crossref\nRandel, W., and E. Jensen, 2013: Physical processes in the tropical tropopause layer and their roles in a changing climate. Nat. Geosci., 6, 169–176, doi: https://doi.org/10.1038/ngeo1733 . Crossref\nRobinson, A. D., and Coauthors, 2014: Long-term halocarbon observations from a coastal and an inland site in Sabah, Malaysian Borneo. Atmos. Chem. Phys., 14, 8369–8388, doi: https://doi.org/10.5194/acp-14-8369-2014 . Crossref\nRosenberg, P. D., A. R. Dean, P. I. Williams, J. R. Dorsey, A. Minikin, M. A. Pickering, and A. Petzold, 2012: Particle sizing calibration with refractive index correction for light scattering optical particle counters and impacts upon PCASP and CDP data collected during the Fennec campaign. Atmos. Meas. Tech., 5, 1147–1163, doi: https://doi.org/10.5194/amt-5-1147-2012 . Crossref\nRusso, M. R., M. J. Ashfold, N. R. P. Harris, and J. A. Pyle, 2015: On the emissions and transport of bromoform: Sensitivity to model resolution and emission location. Atmos. Chem. Phys., 15, 14 031–14 040, doi: https://doi.org/10.5194/acp-15-14031-2015 . Crossref\nSherwen, T., and Coauthors, 2016: Iodine’s impact on tropospheric oxidants: A global model study in GEOS-Chem. Atmos. Chem. Phys., 16, 1161–1186, doi: https://doi.org/10.5194/acp-16-1161-2016 . Crossref\nStröm, J., R. Busen, M. Quante, B. Guillemet, P. R. A. Brown, and J. Heintzenberg, 1994: Pre-EUCREX intercomparison of airborne humidity measuring instruments. J. Atmos. Oceanic Technol., 11, 1392–1399, doi: https://doi.org/10.1175/1520-0426(1994)011<1392:PEIOAH>2.0.CO;2 .\nUlanowski, Z., P. H. Kaye, E. Hirst, R. S. Greenaway, R. J. Cotton, E. Hesse, and C. T. Collier, 2014: Incidence of rough and irregular atmospheric ice particles from Small Ice Detector 3 measurements. Atmos. Chem. Phys., 14, 1649–1662, doi: https://doi.org/10.5194/acp-14-1649-2014 . Crossref\nWhalley, L. K., A. C. Lewis, J. B. McQuaid, R. M. Purvis, J. D. Lee, K. Stemmler, C. Zellweger, and P. Ridgeon, 2004: Two high-speed, portable GC systems designed for the measurement of nonmethane hydrocarbons and PAN: Results from the Jungfraujoch high altitude observatory. J. Environ. Monit., 6, 234–241, doi: https://doi.org/10.1039/b310022g . Crossref\nWilson, K. L., and J. W. Birks, 2006: Mechanism and elimination of a water vapor interference in the measurement of ozone by UV absorbance. Environ. Sci. Technol., 40, 6361–6367, doi: https://doi.org/10.1021/es052590c . Crossref\nWofsy, S. C., and Coauthors, 2011: HIAPER Pole-to-Pole Observations (HIPPO): Fine-grained, global-scale measurements of climatically important atmospheric gases and aerosols. Philos. Trans. Roy. Soc., 369A, 2073–2086, doi: https://doi.org/10.1098/rsta.2010.0313 . Crossref\nJanuary 2017\n""","0.17888252","""https://journals.ametsoc.org/doi/10.1175/BAMS-D-14-00290.1""","[-0.629225,52.074389]"
"""Brunel_University_London""","""Air pollution interventions and their impact on public health | SpringerLink""",""", Volume 57, Issue 5 , pp 757–768 | Cite as\nAir pollution interventions and their impact on public health\nAuthors\nAbstract\nIntroduction\nNumerous epidemiological studies have found a link between air pollution and health. We are reviewing a collection of published intervention studies with particular focus on studies assessing both improvements in air quality and associated health effects.\nMethods\nInterventions, defined as events aimed at reducing air pollution or where reductions occurred as a side effect, e.g. strikes, German reunification, from the 1960s onwards were considered for inclusion. This review is not a complete record of all existing air pollution interventions. In total, 28 studies published in English were selected based on a systematic search of internet databases.\nResults\nOverall air pollution interventions have succeeded at improving air quality. Consistently published evidence suggests that most of these interventions have been associated with health benefits, mainly by the way of reduced cardiovascular and/or respiratory mortality and/or morbidity. The decrease in mortality from the majority of the reviewed interventions has been estimated to exceed the expected predicted figures based on the estimates from time-series studies.\nConclusion\nThere is consistent evidence that decreased air pollution levels following an intervention resulted in health benefits for the assessed population.\nKeywords\nAir pollution Intervention study Public health \nB. Forsberg and S. Medina on behalf of the Aphekom Collaborative Network. A detailed list of the Aphekom collaborative network is provided as an electronic appendix “Online Appendix I. Aphekom collaborative network”.\nElectronic supplementary material\nThe online version of this article (doi:  10.1007/s00038-012-0369-6 ) contains supplementary material, which is available to authorized users.\nNotes\nAcknowledgments\nThe Aphekom project was funded jointly by the European Commission’s Programme on Community Action in the Field of Public Health (2003–2008) under Grant Agreement No. 2007105 (54.39 %), and by the many institutions that have dedicated resources to the fulfilment of this city-based project (45.61 %). This project could not have been possible without the invaluable contribution of the Aphekom collaborative network.\nConflict of interest\nThe authors declare that they have no conflict of interest.\nSupplementary material\nSupplementary material 1 (PDF 225 kb)\nReferences\nAir Pollution Act (1987a) (Marketing, Sale and Distribution of Fuels) Regulations, 1990. http://www.irishstatutebook.ie/1990/en/si/0123.html . Accessed 29 July 2009\nAir Pollution Act (1987b) (Marketing, Sale and Distribution of Fuels) (Amendment) Regulations, 1998 and 2000. http://www.irishstatutebook.ie/1998/en/si/0118.html , http://www.irishstatutebook.ie/2000/en/si/0278.html . Accessed 29 July 2009\nAtkinson RW, Anderson HR, Sunyer J, Ayres J, Baccini M, Vonk JM, Boumghar A, Forastiere F, Forsberg B, Touloumi G, Schwartz J, Katsouyanni K (2001) Acute effects of particulate air pollution on respiratory admissions, results from APHEA 2 project. Am J Respir Crit Care Med 164:1860–1866 PubMed Google Scholar\nAvol EL, Gauderman WJ, Tan SM, London SJ, Peters JM (2001) Respiratory effects of relocating to areas of differing air pollution levels. Am J Respir Crit Care Med 164:2067–2072 PubMed Google Scholar\nBarnett AG, Williams GM, Schwartz J, Neller AH, Best TL, Petroeschevsky AL, Simpson RW (2005) Air pollution and child respiratory health—a case-crossover study in Australia and New Zealand. Am J Respir Crit Care Med 171:1272–12778 PubMed CrossRef Google Scholar\nBayer-Oglesby L, Grize L, Gassner M, Takken-Sahli K, Sennhauser FH, Neu U, Schindler C, Braun-Fahrländer C (2005) Decline of ambient air pollution levels and improved respiratory health in Swiss children. Environ Health Perspect 113(11):1632–1637 PubMed CrossRef Google Scholar\nBell ML, Davis DL (2001) Reassessment of the lethal London fog of 1952: novel indicators of acute and chronic consequences of acute exposure to air pollution. Environ Health Perspect 109(Supplement 3):389–394 PubMed Google Scholar\nBreitner S, Stölzel M, Cyrys J, Pitz M, Wölke G, Kreyling W, Küchenhoff H, Heinrich J, Wichmann H-E, Peters A (2008) Short-term mortality rates during a decade of improved air quality in Erfurt Germany. Environ Health Perspect 117(3):448–454 PubMed CrossRef Google Scholar\nClancy L, Goodman P, Sinclair H, Dockery DW (2002) Effect of air-pollution control on death rates in Dublin, Ireland: an intervention study. Lancet 360:1210–1214 PubMed CrossRef Google Scholar\nDockery DW, Pope CA, Xu X, Spengler JD, Ware JH, Fay ME, Ferris BG, Speizer FE (1993) An association between air pollution and mortality in six U.S. cities. N Engl J Med 329(24):1753–1759 PubMed CrossRef Google Scholar\nEC Report (2004) Assessment of the Effectiveness of European Air Quality Policies and Measures. Case study 2—comparison of the EU and US air quality standards & planning requirements. http://ec.europa.eu/environment/archives/cafe/activities/pdf/case_study2.pdf . Accessed 18 April 2012\nEuropean Environment Agency (2011) EEA Report No 8/2010. Impact of selected policy measures on Europe’s air quality. ISSN 1725-2237. http://www.eea.europa.eu/publications/impact-of-selected-policy-measures . Accessed 10 Jan 2011\nEbelt S, Brauer M, Cyrys J, Tuch T, Kreyling WG, Wichmann HE, Heinrich J (2001) Air quality in postunification Erfurt, East Germany: associating changes in pollutant concentrations with changes in emissions. Environ Health Perspect 109(4):325–333 PubMed CrossRef Google Scholar\nEliasson J, Hultkrantz L, Nerhagen L, Smidfelt Rosqvist L (2009) The Stockholm congestion—charging trial 2006: overview of effects. Transp Res Part A 43:240–250 Google Scholar\nFriedman MS, Powell KE, Hutwagner L, Graham LM, Teague WG (2001) Impact of changes in transportation and commuting behaviors during the 1996 Summer Olympic Games in Atlanta on air quality and childhood asthma. J Am Med Assoc 285:897–905 CrossRef Google Scholar\nFrye C, Hoelscher B, Cyrys J, Wjst M, Wichmann H-E, Heinrich J (2003) Association of lung function with declining ambient air pollution. Environ Health Perspect 111:383–387 PubMed CrossRef Google Scholar\nGodlee F (1991) Air pollution I: from pea souper to photochemical smog. Br Med J 303:1459–1461 CrossRef Google Scholar\nGoodman P, Clancy L (2002) Summary of the intervention to reduce particulate pollution levels in Dublin. APHEIS health impact assessment of air pollution in 26 European cities. Second year report, 2000–2001. Appendix 6. Institut de Veille Sanitaire, Saint-Maurice, September 2002, pp 217–219 Google Scholar\nGoodman PG, Dockery DW, Clancy L (2004) Cause-specific mortality and the extended effects of particulate pollution and temperature exposure. Environ Health Perspect 112(2):179–185 PubMed CrossRef Google Scholar\nGoodmana PG, Rich DQ, Zeka A, Clancy L, Dockery DW (2009) Effect of air pollution controls on black smoke and sulfur dioxide concentrations across Ireland. J Air Waste Manag Assoc 59:207–213 CrossRef Google Scholar\nGoodmanb PG, Haw S, Kabir Z, Clancy L (2009) Are there health benefits associated with comprehensive smoke-free laws. Int J Public Health 54(6):367–378 CrossRef Google Scholar\nHall JV, Brajer V, Lurmann FW (2008) Measuring the gains from improved air quality in the San Joaquin Valley. J Environ Manage 88:1003–1015 PubMed CrossRef Google Scholar\nHedley AJ, Wong C-M, Thach TQ, Ma S, Lam T-H, Anderson HR (2002) Cardiorespiratory and all-cause mortality after restrictions on sulphur content of fuel in Hong Kong: an intervention study. Lancet 360:1646–1652 PubMed CrossRef Google Scholar\nHeinrich J, Hoelscher B, Wichmann HE (2000) Decline of ambient air pollution and respiratory symptoms in children. Am J Respir Crit Care Med 161(6):1930–1936 PubMed Google Scholar\nHou Q, An XQ, Wang Y, Guo JP (2010) An evaluation of resident exposure to respirable particulate matter and health economic loss in Beijing during Beijing 2008 Olympic Games. Sci Total Environ 408(19):4026–4032 PubMed CrossRef Google Scholar\nHuang W, Zhu T, Pan X, Hu M, Wang T, Jia Y, Zhang L, Liu X, Zhang Y, Li C, Tang X (2009) Changes in heart rate variability in the cardiovascular elderly Beijing residents during the Beijing Olympics. ISEE 2009 abstract Google Scholar\nInvernizzi G, Ruprecht A, Mazza R, De Marco C, Močnik G, Sioutas C, Westerdahl D (2011) Measurement of black carbon concentration as an indicator of air quality benefits of traffic restriction policies within the ecopass zone in Milan, Italy. Atmos Environ 45:3522–3527 CrossRef Google Scholar\nJohansson C, Burman L, Forsberg B (2009) The effects of congestions tax on air quality and health. Atmos Environ 43(31):4843–4854 CrossRef Google Scholar\nKatsouyanni K, Touloumi G, Spix C, Schwartz J, Balducci F, Medina S, Rossi G, Wojtyniak B, Sunyer J, Bacharova L, Schouten JP, Ponka A, Anderson HR (1997) Short-term effects of ambient sulphur dioxide and particulate matter on mortality in 12 European cities: results from time series data from the APHEA project. Br Med J 314:1658–1663 CrossRef Google Scholar\nKelly I, Clancy L (1984) Mortality in a general hospital and urban air pollution. Ir J Med Sci 77:322–324 Google Scholar\nKrämer U, Behrendt H, Dolgner R, Ranft U, Ring J, Willer H, Schlipkoeter HW (1999) Airway diseases and allergies in East and West German children during the first 5 years after reunification: time trends and the impact of sulphur dioxide and total suspended particles. Int J Epidemiol 28:865–873 PubMed CrossRef Google Scholar\nLee JT, Son JY, Cho YS (2007) Benefits of mitigated ambient air quality due to transportation control on childhood asthma hospitalization during the 2002 Summer Asian Games in Busan, Korea. J Air Waste Manag Assoc 57(8):968–973 PubMed CrossRef Google Scholar\nLi Y, Wang W, Kan H, Xu X, Chen B (2010) Air quality and outpatient visits for asthma in adults during the 2008 Summer Olympic Games in Beijing. Sci Total Environ 408:1226–1227 PubMed CrossRef Google Scholar\nLighthall D, Nunes D, Tyner T (2009) Environmental Health Evaluation of Rule 4901: domestic wood burning—a case study of the Fresno/Clovis and Bakersfield metropolitan areas. http://www.csufresno.edu/ccchhs/institutes_programs/CVHPI/publications/WoodBurningReport.pdf . Accessed 10 September 2009\nMedina S, Plasencia A, Ballester F, Mücke HG, Schwartz J (2004) Apheis: public health impact of PM10 in 19 European cities. J Epidemiol Community Health 58:831–836 PubMed CrossRef Google Scholar\nPeel JL, Tolbert PE, Klein M, Metzger KB, Flanders WD, Todd K, Mulholland JA, Ryan PB, Frumkin H (2005) Ambient air pollution and respiratory emergency department visits. Epidemiology 16:164–174 PubMed CrossRef Google Scholar\nPeel JL, Klein M, Flanders WD, Mulholland JA, Tolbert PE (2010) Impact of improved air quality during the 1996 Atlanta Olympic games on multiple cardiovascular and respiratory outcomes. Res Rep Health Eff Inst (148):3–23 Google Scholar\nPeters J, Hedley AJ, Wong CM, Lam TH, Ong SG, Liu J, Spiegelhalter DJ (1996) Effects of an ambient air pollution intervention and environmental tobacco smoke on children’s respiratory health in Hong Kong. Int J Epidemiol 25(4):821–828 PubMed CrossRef Google Scholar\nPeters A, Breitner S, Cyrys J, Stölzel M, Pitz M, Wölke,G, Heinrich J, Kreyling W, Küchenhoff H, Wichmann H-E (2009) The influence of improved air quality on mortality risks in Erfurt, Germany. HEI Res Rep Health Eff Inst (137):5–77 Google Scholar\nPope CA III (1989) Respiratory disease associated with community air pollution and a steel mill, Utah Valley. Am J Public Health 79(5):623–628 PubMed CrossRef Google Scholar\nPope CAIII (Health Effects Institute, 2010) Appendix C. Accountability studies of air pollution and human health: where are we now and where does the research go next? In: Proceedings of an HEI Workshop on further research to assess the health impacts of actions taken to improve air quality. Communication 15. Health Effects Institute, Boston. http://pubs.healtheffects.org/getfile.php?u=584 . Accessed 21 Feb 2011\nPope CAIII, Dockery DW (2006) Health effects of fine particulate air pollution: lines that connect. J Air Waste Manag Assoc 56:709–742 PubMed CrossRef Google Scholar\nPope CA III, Schwartz J, Ransom MR (1992) Daily mortality and PM10 pollution in Utah Valley. Arch Environ Health 47(3):211–217 PubMed CrossRef Google Scholar\nPope CA III, Burnett RT, Thun MJ, Calle EE, Krewski D, Ito K, Thurston GD (2002) Lung cancer, cardiopulmonary mortality, and long-term exposure to fine particulate air pollution. J Am Med Assoc 287:1132–1141 CrossRef Google Scholar\nPope CAIII, Rodermund DL, Gee MM (2007) Mortality effects of a copper smelter strike and reduced ambient sulfate particulate matter air pollution. Environ Health Perspect 115(5):679–683 PubMed CrossRef Google Scholar\nRansom MR, Pope CA III (1992) Elementary school absences and PM10 pollution in Utah Valley. Environ Res 58(2):204–219 PubMed CrossRef Google Scholar\nRansom MR, Pope CA III (1995) External health costs of a steel mill. Contemp Econ Policy 13(2):86–97 CrossRef Google Scholar\nRich DQ, George P, Goodman PG, Ohman-Strickland P, Clancy L, Kotlov T, Dockery DW (2009) Effect of air pollution control on mortality in county Cork Ireland. Health Effects Institute Annual Conference abstract. Health Effects Institute, Boston Google Scholar\nSamoli E, Analitis A, Touloumi G, Schwartz J, Anderson HR, Sunyer J, Bisanti L, Zmirou D, Vonk JM, Pekkanen J, Goodman P, Paldy A, Schindler C, Katsouyanni K (2005) Estimating the exposure–response relationships between particulate matter and mortality within the APHEA Multicity Project. Environ Health Perspect 113(11):88–95 PubMed Google Scholar\nSamoli E, Peng R, Ramsay T, Pipikou M, Touloumi G, Dominici F, Burnett R, Cohen A, Krewski D, Samet J, Katsouyanni K (2008) Acute effects of ambient particulate matter on mortality in Europe and North America: results from the APHENA study. Environ Health Perspect 116(11):1480–1486 PubMed CrossRef Google Scholar\nSuguri D, Ranft U, Schikowski T, Krämer U (2006) The influence of large-scale airborne particle decline and traffic-related exposure on children’s lung function. Environ Health Perspect 114:282–288 CrossRef Google Scholar\nTonne C, Beevers S, Armstrong BG, Kelly F, Wilkinson P (2008) Air pollution and mortality benefits of the London Congestion Charge: Spatial and socioeconomic inequalities. Occup Environ Med 65:620–627 PubMed CrossRef Google Scholar\nTonne C, Beevers S, Kelly FJ, Jarup L, Wilkinson P, Armstrong B (2010) An approach for estimating the health effects of changes over time in air pollution: an illustration using cardio-respiratory hospital admissions in London. Occup Environ Med 67:422–427 PubMed CrossRef Google Scholar\nTransport for London (2007) Central London congestion charging, impacts monitoring. Fifth annual report. The Mayor of London, Greater London Authority, London Google Scholar\nU.S. EPA (2008) Integrated Science Assessment (ISA) for Sulfur Oxides – Health Criteria (Final Report). U.S. Environmental Protection Agency, Washington, DC, EPA/600/R-08/047F Google Scholar\nWang W, Primbs T, Tao S, Massey Simonich SL (2009) Atmospheric particulate matter pollution during the 2008 Beijing Olympics. Environ Sci Technol 43(14):5314–5320 PubMed CrossRef Google Scholar\nWong CM, Lam TH, Hedley AJ, Ong SG, Tam AYC, Liu J, Spiegelhalter DJ (1998) Comparison between two districts of the effects of an air pollution intervention on bronchial responsiveness in primary school children in Hong Kong. J Epidemiol Community Health 52:571–578 PubMed CrossRef Google Scholar\nWeb-reference 1 (2003) http://yosemite.epa.gov/r9/r9sips.nsf/4d1098913b85a99188256f9d0059cafe/C0A5DC4ED6D143CF88256E00005E13F7/$file/SJV+4901+Clean.pdf?OpenElement . Accessed 9 Sep 2009\nWu S, Deng F, Niu J, Huang Q, Liu Y, Guo X (2010) Association of heart rate variability in taxi drivers with marked changes in particulate air pollution in Beijing in (2008). Environ Health Perspect 118(1):87–91 PubMed Google Scholar\nZhang J, Zhu T, Huang W, Kipen H, Wang G, Rich D, Zhu P, Wang Y, Hu M, Lu S-E, Ohman-Strikland P, Gong J, Tong J (2009) The Beijing HEART study: study hypotheses and preliminary results. ISEE 2009 abstract Google Scholar\nCopyright information\n© Swiss School of Public Health 2012\nAuthors and Affiliations\n2.St. George’s, University of LondonLondonUK\n3.Brunel UniversityLondonUK\n4.French Institute for Public Health Surveillance, InVSParisFrance\n5.Department of Hygiene, Epidemiology and Medical Statistics, Medical SchoolUniversity of AthensAthensGreece\n6.National Center for Scientific Research, GREQAM and IDEPMarseilleFrance\n7.Umeå UniversityUmeåSweden\n""","0.22970033","""https://link.springer.com/article/10.1007%2Fs00038-012-0369-6""","[-0.472855,51.532848]"
"""Imperial_College_London""","""Cognitive Agent Based Critical Information Gathering and Dissemination in Vehicular Ad hoc Networks | SpringerLink""",""", Volume 69, Issue 4 , pp 1107–1129 | Cite as\nCognitive Agent Based Critical Information Gathering and Dissemination in Vehicular Ad hoc Networks\nAuthors\nM. S. Kakkasageri Email author\nS. S. Manvi\n3 Citations\nAbstract\nNext generation vehicles will have capability of sensing, computing, and communicating capabilities. Different components in a vehicle have to constantly exchange available information with other vehicles on the road and cooperate for the purpose of ensuring safety and comfort using a Vehicular Ad hoc Network (VANET). Critical information like navigation, cooperative collision avoidance, lane-changing, speed limit, accident, obstacle or road condition warnings, etc. play a significant role for safety-related applications in VANET. Such kind of critical information gathering and dissemination is challenging, because of their delay-sensitive nature. This paper proposes an agent based model that consists of heavy-weight static cognitive (based on Belief Desire Intention : BDI) and light-weight mobile agents. Proposed model executes push (gather/store and disseminate) and pull (gather/store) operations on information gathered based on information relevance, criticalness and importance. The simulation results show that BDI based information gathering and dissemination scheme performs better than the reliable broadcast scheme in terms of bandwidth utilization, packet delivery ratio, push latency (information saturation time) and push/pull decision latency.\nKeywords\nVehicular ad hoc networks Cognitive agents BDI architecture \nThis is a preview of subscription content, log in to check access\nPreview\nUnable to display preview.  Download preview PDF.\nReferences\n1.\nCaliskan, M., Mauve, M., Rech, B., & Luebke, A. (2005). Collection of dedicated information in vehicular ad hoc networks. In 12th World congress on intelligent transport systems. San Francisco, USA (pp. 1–12). Google Scholar\n2.\nFubler, H., Moreno, T., Transier, M., Kruger, R., Hartenstein, H., & Effelsberg, W. (2005). Studying vehicle movements on highways and their impact on ad-hoc connectivity. In ACM international conference on mobileComputingandNetworking (MobiCom). Cologne, Germany (pp. 26–27). Google Scholar\n3.\nSchnaufer, S., Fubler, H., Transier, M., & Effelsberg, W. (2006). Vehicular ad-hoc networks: Single-hop broadcast is not enough. In 3rd International workshop on intelligent transportation (WIT 2006). Hamburg, Germany (pp. 49–54). Google Scholar\n4.\nBalon, N., & Guo, J. (2006). Increasing broadcast reliability in vehicular ad hoc networks. In 3rd International workshop on vehicular ad hoc networks (VANET 2006). Los Angeles, USA (pp. 1–2). Google Scholar\n5.\nManvi, S., Kakkasageri, M., Pitt, J., & Rathmell, A. (2006). Multi agent systems as a platform for VANETs. In International conference on autonomous agents and multi agent systems (AAMAS). Hakodate, Japan (pp. 35–42). Google Scholar\n6.\nManvi S., Kakkasageri M., Pitt J. (2009) Multiagent based information dissemination in vehicular ad hoc networks. Mobile Information Systems, IOS Press 5(4): 363–389 Google Scholar\n7.\nManvi S., Kakkasageri M. (2008) Issues in mobile ad hoc networks for vehicular communication. IETE Technical Review 25(2): 59–72 Google Scholar\n8.\nShibata, N. et al. (2006). A method for sharing traffic jam information using inter-vehicle communication. http://ito-lab.naist.jp/themes/pdffiles/060725.shibata.v2vcom06.pdf . Accessed 12 October 2009.\n9.\nKumar, D., Kherani, A., & Altman, E. (2006). Route lifetime based optimal hop selection in VANETs on highway: An analytical viewpoint. IFIP Networking. Coimbra, Portugal (pp. 799–814). Google Scholar\n10.\nJohnson, M., Nardis, L., & Ramchandran, K. (2006). Collaborative content distribution for vehicular ad hoc networks. In Allerton conference on communication, control, and computing. Monticello, USA (pp. 2649–2657). Google Scholar\n11.\nCaliskan, M., Barthels, A., Scheuermann, B., & Mauve, M. (2007). Predicting parking lot occupancy in vehicular ad hoc networks. In 65th IEEE vehicular technology conference (VTC2007). Dublin, Ireland (pp. 277–281). Google Scholar\n12.\nChawathe, S. (2006). Inter-vehicle data dissemination in sparse equipped traffic. In 9th IEEE international conference on intelligent transportation systems (ITSC). Toronto, Canada (pp. 273–280). Google Scholar\n13.\nResta, G., Santi, P., & Simon, J. (2007). Analysis of multi-hop emergency message propagation in vehicular ad hoc networks. In 8th ACM international symposium on mobile ad hoc networking and computing. Montreal, Canada (pp. 140–149). Google Scholar\n14.\nSaxena, N., Basu, K., & Das, S. (2004). Design and performance analysis of a dynamic hybrid scheduling algorithm for heterogeneous asymmetric environments. In 18th International parallel and distributed processing symposium (IPDPS 2004). Santa Fe, New Mexico (pp. 26–30). Google Scholar\n15.\nChuah, M., & Fu, F. (2006). Performance study of robust data transfer protocol for VANETS. In 2nd International conference on mobile ad hoc and sensor networks. Hong Kong (pp. 123–135). Google Scholar\n16.\nNadeem, T., Shankar, P., & Iftode, L. (2006). A comparative study of data dissemination models for VANETs. In 3rd Annual international conference on mobile and ubiquitous systems. San Jose, California, USA (pp. 1–10). Google Scholar\n17.\nMahajan, A., Potnis, N., Gopalan, K., & Wang, A. (2007). Modeling VANET deployment in urban settings. In 10th ACM symposium on modeling, analysis, and simulation of wireless and mobile systems. Greece (pp. 151–158). Google Scholar\n18.\nLochert, C., Scheuermann, B., & Mauve, M. (2007). Probabilistic aggregation for data dissemination in VANETs. In 4th ACM international workshop on vehicular ad hoc networks. Canada (pp. 1–8). Google Scholar\n19.\nCamara, D. et al. (2008). Virtual access points for stream based traffic dissemination. In IEEE Asia-Pacific services computing conference. Yilan, Taiwan (pp. 1628–1632). Google Scholar\n20.\nLee U. et al (2008) Dissemination and harvesting of urban data using vehicular sensing platforms. IEEE Transaction on Vehicular Technology 58(2): 882–901 Google Scholar\n21.\nXu, B. et al. (2007). A feasibility study on disseminating spatio-temporal information via vehicular ad-hoc networks. http://cs.uic.edu/~boxu/mp2p/v2vcom07-final-xu.pdf . Accessed 12 October 2009.\n22.\nPark, S., & Zou, C. (2008). Reliable traffic information propagation in vehicular ad-hoc networks. In IEEE sarnoff symposium. NJ, USA, Princeton (pp. 1–6). Google Scholar\n23.\nOnus, M. et al. (2005). Efficient broadcasting and gathering in wireless ad-hoc networks. In 8th International symposium on parallel architectures, algorithms and networks. Sydney, NSW, Australia (pp. 346–351). Google Scholar\n24.\nCampelli, L., Cesana, M., & Fracchia, R. (2007). Directional broadcast forwarding of alarm messages in VANETs. http://antlab.elet.polimi.it/PUB/WONS2007.pdf . Accessed 14 October 2009.\n25.\nRosi, U., Hyder, C., & Kim, T. (2008). A novel approach for infrastructure deployment for VANET. In 2nd International conference on future generation communication and networking (FGCN ’08). Hainan Island, China (pp. 234–238). Google Scholar\n26.\nAdler, C., & Strassberger, M. (2006). Putting together the pieces—a comprehensive view on cooperative local danger warning. http://www.mobile.ifi.lmu.de/common/..../adst06.pdf . Accessed 21 March 2008.\n27.\nMoukas, A., Chandrinos, K., & Maes, P. (1998). Trafficopter: A distributed collection system for traffic information. In 2nd International workshop on cooperative information agents, learning, mobility and electronic commerce for information discovery on the internet. Paris, France (pp. 33–43). Google Scholar\n28.\nCollins, K., & Muntean, G. (2008). A vehicle route management solution enabled by wireless vehicular networks. In 68th IEEE vehicular technology conference (VTC Fall 2008). Canada (pp. 1–5). Google Scholar\n29.\nMartinez, F., Toh, C., Cano, J., Calafate, C., & Manzoni, P. (2011). Determining the representative factors affecting warning message dissemination in VANETs. Wireless Personal Communications, Springer. doi:  10.1007/s11277-011-0379-3 .\n30.\nMartinez F., Toh C., Cano J., Calafate C., Manzoni P. (2011) A street broadcast reduction scheme (SBR) to mitigate the broadcast storm problem in VANETs. Wireless Personal Communications, Springer 56(3): 559–572 CrossRef Google Scholar\n31.\nChou L., Yang J., Hsieh Y., Chang D., Tung C. (2011) Intersection-based routing protocol for VANETs. Wireless Personal Communications, Springer 60(1): 105–124 CrossRef Google Scholar\n32.\nNetwork Simulator–ns-2. http://www.isi.edu/nsnam/ns . Accessed 25 March 2008.\n46.\nBai, F., Sadagopan, N., & Helmy, A. (2003). Important: A framework to systematically analyze the impact of mobility on performance of routing protocols for ad hoc networks. In 22th IEEE annual joint conference on computer communications and networking (INFOCOM’03) (pp. 825–835). Google Scholar\n47.\nXiuchao, W., & Ananda, A. (2004). Link characteristics estimation for IEEE 802.11 DCF based WLAN. In 29th Annual IEEE international conference on local computer networks (LCN’04). Tampa, USA (pp. 302–309). Google Scholar\n48.\nWiethlter, S., & Hoene, C. (2004). Design and verification of an IEEE 802.11e EDCF simulation model in ns-2.26. In Technical report (pp. 1–44). University of Berlin: Telecommunication Networks Group. Google Scholar\nCopyright information\n© Springer Science+Business Media, LLC. 2012\nAuthors and Affiliations\n""","0.4339211","""https://link.springer.com/article/10.1007%2Fs11277-012-0623-5""","[-0.178219,51.500505]"
"""UCL""","""Iris Publication""","""http://discovery.ucl.ac.uk/1557223/\nAbstract\nThis paper proposes that there has been an evolving pattern of urban transport policy and planning in many Western cities, which has been associated with changes in mobility patterns and attitudes to different transport modes and to city living in general. Looking over the past 50 year period, a three-stage transport policy development cycle is proposed, starting with Stage 1 – a rapid increase in car ownership and use in Western cities from the 1950s, often associated with the growth of a domestic car industry. This led to a policy response that involved catering for vehicle use by building urban motorways and large car parks, reducing investment in public transport and with more negative attitudes towards cycling and walking. After some time the negative aggregate consequences of increasing car use and provision become widely apparent, through increasing congestion, air pollution, traffic accidents, etc. Now the policy priority switches in Stage 2 - from accommodating motor vehicles to providing for people movement, particularly through improvements to public transport. Beijing has recently made this transition, with a 5 year programme to build 550 km of new metro lines, instead of further increasing road capacity. Several cities (e.g. London and Copenhagen) have moved beyond this to a Stage 3 in which the priority is to provide a liveable city with a focus on activity and interaction, in which car traffic is reduced, some elevated roads are demolished and roadspace is reallocated to sustainable modes of transport and to provide enhanced public space. Finally, the paper considers whether developing cities that are in Stage 1 and experiencing rapid motorisation could learn from this evolutionary model: 1. By ensuring that they do not promote land use polices which may lead to a ‘lock-in’ that prevents evolution beyond a car-based city, and 2. By compressing the development cycle – speeding up the implementation of more sustainable transport policies and avoiding wasted investment in roads-based infrastructure.\nPublication data is maintained in RPS. Visit https://rps.ucl.ac.uk\n› More search options\n""","0.65771043","""http://iris.ucl.ac.uk/iris/publication/1296220/1""",
"""UCL""","""Iris Publication""","""http://discovery.ucl.ac.uk/1527808/\nAbstract\nSocial justice has increasingly been used as a criterion to evaluate urban transport policies. The distribution of levels of accessibility across the city is one of the main issues in this field, as the disadvantages faced by some groups in the access to key services and facilities may contribute to processes of social exclusion. The analysis of this issue has traditionally made use of measures of potential accessibility, often looking at the geographic mismatch between jobs and residences and, more recently, also at inequalities between the levels of public transport provision in different areas of the city. However, the applicability of this kind of analysis in the assessment of public policies is limited by the fact that the measures used may not be reliable indicators of the actual effects of the policies in the wellbeing of the local populations.  This paper addresses this problem by focusing on the social imbalances in the realization of the accessibility potential of each neighbourhood in a metropolitan area. The main hypothesis is that levels of realized accessibility depend not only in the locations of residences, main centres, and transport facilities, but also on the actual daily destinations and travel modes of the population in each neighbourhood.   A series of indicators of potential and realized accessibility is estimated for each neighbourhood, including gravity-based job accessibility measures, the ratio between public and private transport accessibility, actual times to work and commuting distances, and the effect of modal choice and congestion on time to work. These indicators are then compared with variables measuring the socio-economic structure of the population using correlation analysis.  The study incorporates aspects that are often neglected in the estimation of travel times to work. The modelling of trips to work in each area is based on a large set of destinations for the working population in each sector of activity, and considers information on starting time of different jobs, and on the proportion of walking trips. The modelling of public transport trips includes information about the availability and frequency of services and the time of walking, waiting and interchange sections. Car and bus travel times include the effects of road congestion at different times of the day.  The analysis is applied to the case of the Lisbon Metropolitan Area at two moments in time, assessing the distributive effect of a series of policies that gave priority to the expansion of the private transport network, combined with trends such as population ageing and urban fragmentation.  The analysis suggests that while it is possible to identify inequalities in times to work of groups with different socio-economic status, these inequalities are mainly explained by different levels of private transport usage and not by geographic factors such as the mismatch between locations of jobs and people or between levels of transport provision and the mobility needs of the population in each neighbourhood.   These results have implications in the debate regarding the role of spatial planning in addressing equity aspects in urban transport networks. These implications are discussed in the closing section of the paper.\nPublication data is maintained in RPS. Visit https://rps.ucl.ac.uk\n› More search options\n""","0.68124855","""http://iris.ucl.ac.uk/iris/publication/1190374/1""",
"""Imperial_College_London""","""Lung Development and Aging | Annals of the American Thoracic Society""","""Annals of the American Thoracic Society\nDepartment of Paediatrics, Imperial College, London, United Kingdom; and Royal Brompton Harefield National Health Service Foundation Trust, London, United Kingdom\nCorresponding Author: Andrew Bush\nAbstract\nSection:\nThe onset of chronic obstructive pulmonary disease (COPD) can arise either from failure to attain the normal spirometric plateau or from an accelerated decline in lung function. Despite reports from numerous big cohorts, no single adult life factor, including smoking, accounts for this accelerated decline. By contrast, five childhood risk factors (maternal and paternal asthma, maternal smoking, childhood asthma and respiratory infections) are strongly associated with an accelerated rate of lung function decline and COPD. Among adverse effects on lung development are transgenerational (grandmaternal smoking), antenatal (exposure to tobacco and pollution), and early childhood (exposure to tobacco and pollution including pesticides) factors. Antenatal adverse events can operate by causing structural changes in the developing lung, causing low birth weight and prematurity and altered immunological responses. Also important are mode of delivery, early microbiological exposures, and multiple early atopic sensitizations. Early bronchial hyperresponsiveness, before any evidence of airway inflammation, is associated with adverse respiratory outcomes. Overlapping cohort studies established that spirometry tracks from the preschool years to late middle age, and those with COPD in the sixth decade already had the worst spirometry at age 10 years. Alveolar development is now believed to continue throughout somatic growth and is adversely impacted by early tobacco smoke exposure. Genetic factors are also important, with genes important in lung development and early wheezing also being implicated in COPD. The inescapable conclusion is that the roots of COPD are in early life, and COPD is a disease of childhood adverse factors interacting with genetic factors.\nKeywords:\nKeywords: atopy ; asthma ; nicotine ; chronic obstructive pulmonary disease ; microbiome\nIn 1977, in a classic report, Fletcher and Peto ( 1 ) proposed a model (their Figure 1 ) in which all comers attained a normal FEV1 at age 25 years, and progression to respiratory disability was solely determined by rate of decline of spirometry thereafter. Smoking history was seen as the chief determinant of rate of decline, and events before age 25 years were irrelevant. In their far less well known, but far more accurate Figure 2, they incorporated different starting levels of FEV1 at age 25 years, as well as different rates of decline, into their model. These findings have been taken forward and have had to be substantially modified by a recent study combining three cohorts. This confirmed two trajectories to chronic obstructive pulmonary disease (COPD) or, strictly speaking, to an FEV1/FVC ratio of less than 70%. There were approximately equal numbers in each trajectory. Of those who failed to attain an FEV1 of 80% before age 40 years, 26% had developed COPD during the 22 years of observation, whereas 7% with a normal FEV1 aged 40 years developed COPD within the same time period due to an accelerated rate of decline in FEV1 ( 2 ). Critically, the rate of decline was unrelated to smoking, nor could the authors identify any current feature associated with rapid decline in spirometry. The only logical conclusion is that all COPD risk is determined before the age of 40 years, either genetically or by environmental adverse influences or their interactions ( Figure 1 ).\nFigure 1. Why adults get premature airway disease. Note that all the factors have origins in childhood; there is no consistent adult-onset feature identified in the literature.\n[More] [Minimize]\nThis conclusion is supported by a European study that identified five adverse childhood influences that were associated with a lower FEV1 and a more rapid rate of decline of spirometry (and, hence, a greater COPD risk in adult life) ( 3 ). These were maternal and paternal asthma, maternal smoking, and childhood asthma and severe respiratory infections. Childhood disadvantage was at least as important as heavy smoking. The focus is therefore on any adverse event increasing the likelihood of one or more of these disadvantages. The first lesson from normal lung growth for pediatricians is that by asking five simple questions (antenatally, asking the mother three simple questions) ( Table 1 ) ( 4 ), a population of children at high risk for later premature airflow obstruction can be identified. Second, any factor increasing the likelihood of the development of childhood asthma or an increased propensity to respiratory infection will contribute to accelerated lung aging. Gene polymorphisms, for example in a disintegrin and metalloproteinase domain 33 (ADAM33), have also been associated with accelerated decline in lung function ( 5 ) (see below). Finally, no adult life influence, including smoking, has consistently been associated with accelerated decline in spirometry. The conclusion is inescapable: both the two recently described trajectories to COPD ( 2 ) are determined before adult life, and, if COPD is to be prevented, measures starting in adult life are too late.\nTable 1. Simple key questions to identify children at high risk for chronic obstructive pulmonary disease\nAntenatally and postnatally\nDoes the child have asthma?\nHas the child had severe respiratory infections?\nThe best description of the normal evolution of spirometry is from the Global Lung Initiative ( 6 ). The group used 97,759 measurements in healthy nonsmokers from 72 centers in 33 countries aged between 2.5 and 95 years to construct predictive equations for spirometry. From their smooth curves, three key stages emerge: for normal lung health, spirometry needs to be normal at first measurement (now best described by the raised volume, rapid thoracic compression technique at birth [ 7 ], or preschool standard spirometry [ 8 ], stage 1), needs to grow normally in childhood to attain a normal plateau at age 20 to 25 years (stage 2), and declines with aging at a normal rate (stage 3). Key influences on these stages are discussed in turn. Finally, new data challenging the concepts of normal alveolar growth are presented. Space allows only a summary of many factors leading to childhood asthma and respiratory infections.\nKey Stage 1: Before Birth\nSection:\nThe morphological phases of lung development in utero have been well described; airway caliber is determined largely in the second half of pregnancy. Recently, the gene expression studies of normal lung development have been determined ( 9 ) and have broadly confirmed the utility of the morphological stages. The complexities of the pathways of branching morphogenesis have been reviewed ( 10 , 11 ) and will not be discussed further, except insofar as they lead to important genetic clues into lung aging.\nPreconception adverse events may impact the fetus. Grandmaternal smoking has a double-hit effect; it increases the risk of maternal asthma and, even if the mother herself does not smoke, increases the risk of her offspring having asthma ( 12 , 13 ).\nAntenatal adverse effects can be mediated through reducing airway caliber, altering fetal immune responses, inducing either or both prematurity and low birth weight, and influencing the mode of delivery. Many different antenatal adverse effects on lung growth have been described ( 14 ), including the effects of maternal stress on fetal immune responses ( 15 ), but most information is available for nicotine and tobacco smoke. These are worsened if mother or fetus have non-null GSTT1, highlighting the importance of gene–environment interactions ( 16 ). Recently, the adverse effects on early childhood spirometry of maternal exposure to environmental pollution have come to the fore ( 17 , 18 ), and, although the mechanisms are speculative, it is clear that early airflow obstruction is the result ( 19 ).\nMaternal hypertension of pregnancy has been described as causing airflow obstruction in the baby ( 20 ), but this has been disputed recently, with attention focusing on prepregnancy hypertension as being important ( 21 ). More studies are needed to confirm or otherwise the developmental role of maternal blood pressure on the baby.\nStructural Changes\nMost of the data have come from animal models of nicotine exposure of the pregnant dam. Antenatal changes described include increased collagen deposition ( 22 ), increased MUC5AC expression ( 23 ), and airway lengthening and reduction in caliber ( 24 ). The readout in the fetus is airway obstruction and airway hyperresponsiveness (AHR) at birth. Note that AHR occurs in the absence of allergen exposure (mice) and any evidence of airway inflammation (mice, infants [ 24 , 25 ]). The anatomical changes are likely also exacerbated by loss of alveolar tethering points ( 26 ) and increased airway smooth muscle thickness ( 27 )\nImmunological Changes\nThere are a large number of studies looking at the effects of pregnancy exposures on cord blood mononuclear cell function. Maternal smoking and previous pregnancies affect cord blood mononuclear cell proliferation to allergens ( 28 ). Abnormal cytokine responses at birth predict wheeze with viral infections in early life ( 29 ), including rhinovirus-induced wheeze, which is strongly associated with subsequent asthma ( 30 ). Maternal smoking is also associated with abnormal toll-like receptor function ( 31 ).\nBirth Weight, Low Birth Weight, and Prematurity\nA recent metaanalysis has shown that any cause of low birth weight is associated with subsequent childhood and adult asthma ( 32 ). The Aberdeen Birth cohort demonstrated a linear relationship between birth weight (adjusted for relevant maternal factors) and spirometry at age 45 to 50 years ( 33 ). Tobacco smoking is a well-known cause of preterm delivery, the risk of which is reduced by tobacco legislation ( 34 ). Very preterm infants are well known to be left with fixed and variable airflow obstruction, and, although outcomes are improving ( 35 ), even those preterm babies requiring no treatment in the newborn period have airflow limitation ( 36 ), so improvements in neonatal intensive care are unlikely to abolish the problem. The decrements in spirometry in bronchopulmonary dysplasia survivors are greater than those of healthy preterm infants ( 37 ). Furthermore, even modest degrees of prematurity (up to 37 weeks’ gestation) are associated with impaired spirometry in the late teenage years ( 38 ) and increased use of asthma medications in childhood ( 39 – 41 ). Low birth weight of itself is a risk factor for subsequent asthma ( 32 ). There may be a differential effect of low birth weight in babies who are small (SGA), as opposed to appropriate (AGA), weight for gestation age; at age 20 to 22 years, spirometry was strongly predicted by birth weight in the SGA but not the AGA group ( 42 ). It should be noted that, as protocols for resuscitation of the newborn ( 43 ) and subsequent ventilation ( 44 ) have changed, so have the different contributions of airway and parenchymal disease in “new” and “old” bronchopulmonary dysplasia ( 45 )\nMode of Delivery\nDelivery by caesarean section is associated with an increased risk of atopic disorders ( 46 , 47 ), probably mediated via an effect on the fetal microbiome ( 48 ). Especially if at least one parent is allergic, children delivered by caesarean section have a higher prevalence of asthma at age 8 years, and children of nonallergic parents were more likely to be sensitized ( 49 ). Because there are no randomized controlled trials of caesarean section delivery, it is not possible to disentangle the effects of caesarean delivery from the causes leading to the need for caesarean delivery.\nKey Stage 2: Childhood Lung Growth\nSection:\nLessons from the Birth Cohorts\nThe ideal study would have recruited babies antenatally and followed them through with repeated measurements until death; such a study has not been done, and so we have to rely on a series of overlapping cohorts ( 50 – 53 ), reviewed in Reference 54 . Although there are some discrepancies, the general message is that lung function at age 4 to 6 years is determined by lung function and bronchial hyperresponsiveness soon after birth, and thereafter tracks; hence, decrements at age 4 to 6 years are reflected in adult lung function, at least to age 50 years. There may be further deterioration at school age and beyond, but no improvements.\nThis view has recently been challenged, at least in the context of preterm survivors. A group of preterm babies at age 7 to 9 years had evidence of airflow obstruction, the degree of which related to the intensity of neonatal treatment, but this had normalized by age 20 to 22 years ( 42 ); interestingly, birth weight was a strong determinant of airflow obstruction in the SGA but not the AGA low birth weight babies. However, this difference was not found in another study ( 55 ). The differences might relate to the proportions of SGA and AGA babies in the different studies or the relative insensitivity of spirometry to distal airway disease. Overall, however, it is clear that the preschool years represent a critical window for long-term lung health.\nThe presence of AHR is important in long-term lung function and requires a developmental perspective. Three groups have measured neonatal AHR, and all showed significant relationships with long-term outcomes, albeit with slightly different results ( 56 – 60 ). The COPSAC (Copenhagen Prospective Studies on Asthma in Childhood) data ( 59 ) suggested that 40% of airway obstruction at age 7 years was determined antenatally and 60% postnatally; neonatal AHR was more strongly associated with asthma at age 7 years than neonatal lung function. It should be noted that neonatal AHR is not related to airway inflammation ( 25 ) and is presumably determined by anatomical factors (see above); thus, small airways increase resistance more for a given proportionate radius change because resistance is inversely related to the fourth power of the radius. Although AHR and lung function at birth were described as independent risk factors for childhood lung function ( 61 ), in reality abnormal anatomy is likely to underlie both. Finally, the longest-running study of AHR from birth to adult life showed that the adult relationship between AHR and asthma was established before age 6 years ( 62 ).\nTobacco and Nicotine\nThe effects of passive smoking were described in a series of metaanalyses ( 63 – 69 ), which have been recently updated ( 70 ); they are sufficiently well known that, in the interest of space, they will not be further discussed. Of interest, recent data showed that maternal smoking and the child taking up smoking have additive effects on the child’s lung function ( 71 ).\nPollution\nThe association of exposure to outdoor pollution postnatally with poorer lung function, asthma, respiratory infections, and a lower rate of growth of spirometry has been well described ( 72 – 74 ), but it may be difficult to disentangle the confounding effects of socioeconomic status. Recently, the beneficial effects of legislation leading to improved air quality on the growth of children’s lungs have been described ( 2 ). Globally, indoor exposure to burning biomass fuels may be most important, and measures to improve indoor air quality improve children’s lung function ( 75 ). Organophosphorus pesticides have recently been implicated as affecting child lung development ( 76 ).\nAsthma and Atopy\nEarly impairment of lung function is associated with objectively diagnosed asthma at age 10 years ( 77 ). It has long been known that early sensitization to aeroallergens is associated with persistent wheeze, loss of lung function, and the development of AHR ( 78 ). Understanding has advanced with the realization that atopy is not an all-or-none phenomenon but can be quantified ( 79 ) and has a developmental perspective. The Manchester group used machine learning approaches to analyze data on patterns of wheeze and atopic sensitization and showed that only multiple early sensitizations were important ( 80 ). In a subsequent study, they showed that persistent wheeze, early multiple atopic sensitizations, and asthma attacks are associated with reduced growth in lung function ( 81 ). Asthma itself is associated with poorer lung growth. As yet unexplained, in the CAMP (Childhood Asthma Management Program) study, approximately one-third of subjects lost percent predicted lung function over the study period, independent of prescribed treatment ( 82 ).\nEarly Viral Infections\nThat acute viral infections are important causes of early respiratory morbidity due to bronchiolitis and wheeze is indisputable. However, whether they cause asthma to develop in an infant who would otherwise not go on to the disease, or are a marker for an asthma propensity, or both, is controversial. It is clear from cord blood studies (see above) that there is antenatal programming favoring viral wheeze; a study from Perth showed that respiratory function was impaired before the development of bronchiolitis, and this decrement tracked into mid-childhood ( 83 ). Respiratory syncytial virus bronchiolitis is a devastating illness, but studies as to whether it is causally associated with asthma are controversial ( 84 , 85 ). Recently, attention has focused on rhinovirus as being more associated with later asthma ( 30 ). The balance of evidence is that allergic sensitization precedes viral wheezing ( 86 ), and it is likely that sensitization rather than viral infections drive the march to asthma. However, this conclusion must still be considered tentative.\nMicrobiome\nThe role of bacteria in normal and abnormal immune development, as well as exacerbations of airway disease ( 87 ), has recently come to the fore. The lower airway is now known not to be sterile as was once believed ( 88 ). Early nasopharyngeal bacterial colonization is associated with altered immune responses ( 89 ), a greater likelihood of wheezing ( 90 ), and worse respiratory infective outcomes ( 91 )—therefore, a double hit at least hypothetically in accelerating lung aging subsequently. It is likely that the fundamental abnormality is an underlying mucosal immune defect, but this is still contentious. By contrast, environmental bacterial and fungal diversity is associated with a reduced risk of asthma ( 92 ). Animal studies have shown that the microbiome is essential for normal immune development ( 93 ), and interactions between allergens and the microbiome influence the body’s immune responses ( 94 , 95 ). The long-term effects of an abnormal microbiome on lung aging are currently unknown, but their influences on asthma risk mean that they are likely significant (see above).\nNutrition\nThere is evidence that an early and rapid gain in weight may be associated with poorer lung growth, in addition to the effects of low birth weight and SGA ( 96 ). However, paradoxically, greater weight gain in later childhood may be associated with better spirometry ( 97 ).\nKey Stage 3: The Aging Lung\nSection:\nThere has been much recent information that has increased our understanding of lung aging since Fletcher and Peto’s manuscript ( 2 , 98 – 101 ). In summary, it is clear that many patients with COPD have a normal rate of lung aging, and, indeed, those who fail to attain the normal plateau in early adult life are at the highest risk of COPD. Asthma and bronchial hyperresponsiveness are risk factors for accelerated decline, but no other environmental factor, including smoking, has consistently been implicated as a cause. The Framingham study reported traffic pollution as being important ( 102 ), but the caveats about socioeconomic status (see above) remain.\nThe role of asthma and AHR in accelerated decline in airway function is multifactorial. The combination of a preexisting low FEV1 and airway inflammation (as shown by elevation in fractional exhaled nitric oxide) is associated with accelerated decline ( 103 ), as are asthma attacks ( 104 ). The Groningen group showed that patients with asthma who stopped smoking and used inhaled corticosteroids had a slower rate of decline; AHR predicted decline independent of baseline FEV1 ( 105 ). However, the two are interrelated; they also showed that low childhood FEV1 and less increase over time was associated with adult AHR ( 106 )\nGenes, Lung Growth, and Lung Aging\nSection:\nGenetic factors, including gene-by-environment interactions via a variety of epigenetic mechanisms, are clearly important in lung development and aging. It is likely that a rich harvest of COPD genes will be found in normal lung development ( 107 ). There are substantial commonalities between genes causing reduced lung function in both smokers and nonsmokers ( 108 ). The conventional approaches have recently been taken forward by using systems genetic approaches ( 109 ).\nAntenatally Important Genes\nADAM33 is an exemplar gene with different roles at different developmental stages. It is important antenatally during airway branching morphogenesis ( 110 ). Levels in the fetus depend on maternal atopy, via an IL-13 pathway ( 111 ). There is an adverse interaction between antenatal tobacco exposure and ADAM33 polymorphisms and lung function at age 8 years ( 112 ). ADAM33 polymorphisms are associated with increased airway resistance in the preschool years ( 113 ), are associated with asthma and bronchial hyperresponsiveness in adults ( 114 ), and those known to convey susceptibility to COPD were associated with an accelerated rate of decline in spirometry in a Dutch general population ( 5 ).\nGenes Important in Early Postnatal Life\nThe β-receptor gene links early lung function, asthma, and COPD. Much is known about β-receptor function in asthma, but very little is known about any possible role in infancy. Maximal flow at functional residual capacity and bronchial hyperresponsiveness (BHR) were measured soon after birth in infants; having any Glyn 27 or Arg 16 allele was associated with reduced maximal flow at functional residual capacity ( 1 ), independent of maternal smoking or atopic status, but BHR was independent of genotype. The patients were restudied at age 11 years, and β-receptor genotype had no association with either spirometry or BHR, possibly because of low statistical power. More than 80% of the children had at least one parent with asthma, so caution should be exercised before extrapolating to low-risk populations. In another study ( 115 ) there was an association between arg16 gln27 and a positive BHR at age 6 years. The gly16 gln27 haplotype was associated with better spirometry at 6 and 11 years of age and less likelihood of an asthma diagnosis at the later time point, but at age 11 years, arg16 gln27 was associated with worse spirometry. A further study found associations with β-receptor haplotypes in adults with COPD, asthma, and other respiratory problems ( 116 ). β-receptor polymorphisms also predicted symptoms of asthma continuing into adult life ( 117 ), but like other genetic studies, the association was weak. One study examined the genetics of preschool wheeze phenotypes and related them to COPD genes ( 118 ). They found that at least three COPD genes were involved in lung growth and development and were involved in antenatal and early life responses to tobacco smoke exposure. More recently, low circulating concentrations of the antiinflammatory protein CC16, which are known to be associated with an accelerated decline in FEV1 in patients with COPD ( 98 , 119 ), have also been found to be associated with accelerated decline in a general adult population and impaired childhood lung function ( 120 ).\nGenome-Wide Association Studies of Spirometry: Developmental Genes\nThere have been a large number of recent important genome-wide association studies both of normal lung function ( 121 – 123 ) and of COPD, many but not all of the latter focusing on lung function ( 122 – 126 ). A recent genome-wide association study implicated the CHRNA5/3 region and in particular HTR4 in airflow obstruction ( 127 ). At least some of the genes identified are also active in important in utero developmental pathways (e.g., wnt/β-catenin [ 128 ]). However, other genes important in premature onset of adult COPD ( 129 ), such as alpha-1 antitrypsin, appear not to have a developmental role, although interestingly those heterozygous for mutations in this gene appear to have increased respiratory reserve ( 130 )\nAlveolar Growth\nSection:\nConventional wisdom was that alveolar growth was largely a postnatal phenomenon, with an initial rapid phase in the first 2 years of life and a much slower phase until age 8 years, whereupon alveoli increased in size but not in number. A series of recent papers have challenged this concept. In nonhuman primates, where alveolar counts can be made at different ages, alveolar numbers increase until adult maturity. In humans, inhalation of hyperpolarized helium (He3) can be used to calculate alveolar size using a number of mathematical modeling techniques and has demonstrated that alveolar size does not change between the ages of 7 and 21 years ( 131 ).\nAdverse effects on alveolar growth have really only been studied in the context of prematurity and its treatment. In animal models, hyperoxia, systemic steroids, and nicotine all impair secondary septation and neoalveolarization ( 132 – 134 ). He3 data in humans ( 135 ) suggest that maternal smoking in pregnancy may increase alveolar size and reduce numbers. The fact that nicotine itself is implicated in both impaired airway and alveolar development calls into question the safety of e-cigarettes ( 136 ). There is also some evidence of catch-up growth, although this is based on cross-sectional studies, not longitudinal data; there are no neonatal data with corresponding studies in childhood and adult life. One group used carbon monoxide transfer as a surrogate for the size of the alveolar–capillary membrane and showed this was normal at rest and on exercise in adult life ( 137 ). He3 data in preterm survivors in adolescence showed that alveolar size was normal ( 138 ). Nitrogen washout can be used to partition gas mixing abnormalities into airway (Scond) and alveolar (Sacin) ( 139 , 140 ). Compared with normal infants, preterm survivors in childhood had, as expected, an abnormal Scond, but Sacin was normal, implying normal alveolarization ( 141 ). However, it should be said that if many alveoli were completely destroyed, Sacin would still be normal, because they would give no signal. Also, all these studies assumed that alveolarization had been abnormal in the newborn period, but they could not measure it, so that there had been true catch-up growth remains conjectural. However, taken together, the evidence is that alveolarization continues for longer, and there is greater potential for catch-up growth, than was previously believed. Certainly, lungs apparently destroyed by necrotizing pneumonias usually recover completely ( 142 ), so at least the potential for catch-up is certainly present. Intriguingly, being brought up at altitude in hypoxic conditions appears to stimulate alveolarization while having no effect on airway function ( 143 ); this raises the intriguing question as to whether keeping the preterm survivors very well oxygenated is as wise as we believed.\nCOPD: Relevance of Developmental Aspects of Lung Function\nSection:\nThere is one final lesson to be learned from developmental aspects of lung growth. The Global Initiative for Chronic Obstructive Lung Disease defines COPD as an FEV1/FVC ratio less than 70%. However, this ratio changes with age ( 144 ); the lungs of young children empty so efficiently that the forced expiratory volume in 0.5 second (FEV0.5)/FVC ratio has to be used ( 7 ), because FEV1/FVC is 100%. Conversely, after age 50 years, increasing numbers of normal people will have FEV1/FVC ratio less than 70%, and after age 70 years, more than 15% of normal people will have FEV1/FVC ratio less than 70%. This use of a fixed ratio without considering the developmental background has two important consequences. The first is that many more normal elderly people will be diagnosed as having COPD ( 145 ). The second is that the severity of the premature airflow obstruction in young adults and even children will not be appreciated; an FEV1/FVC ratio of 75% will be very abnormal at this age. This underscores the fact that premature airflow obstruction is primarily a pediatric disease; this is being overlooked, and intervention delayed, by relying on a ratio that is falsely reassuring at a young age.\nSummary and Conclusions: What Does This Mean for the Future of Lung Health?\nSection:\nIt is clear that if we are to prevent COPD from becoming an ever more important cause of death in adults, we must optimize lung health from before birth and in early childhood. We have much to learn about detailed mechanisms, but there is much we can do now while these studies are going on. We must focus on three preventive measures that have been shown to work. As a matter of urgency, we need to tighten our grip on all forms of tobacco and nicotine exposure, including e-cigarettes. We must legislate to reduce exposure to outdoor pollution, in particular ensuring that very tight controls on vehicle emissions in residential areas are enforced. We need to acknowledge that healthy aging starts in childhood, and unhealthy aging does as well. If fundamental research in the prevention of COPD is to be done, it will be done in early life. Finally, in particular in low- and middle-income country settings, we must ensure that indoor biomass fuel exposure is minimized. The message needs to be gotten across that COPD is not all about a disease that smokers bring on themselves but is in fact just disease of childhood disadvantage and genetics, which must be addressed in childhood if death rates are to drop.\nReferences\n""","0.12283076","""http://www.atsjournals.org/doi/10.1513/AnnalsATS.201602-112AW""","[-0.178219,51.500505]"
"""StaffOxfordUniversityPhysics""","""Trace gas and aerosol interactions in the fully coupled model of aerosol-chemistry-climate ECHAM5-HAMMOZ: 1. Model description and insights from the spring 2001 TRACE-P experiment - Pozzoli - 2008 - Journal of Geophysical Research: Atmospheres - Wiley Online Library""","""Journal of Geophysical Research: Atmospheres\nPrevious article in issue: Characterization of the composition, structure, and seasonal variation of the mixing layer above the extratropical tropopause as revealed by MOZAIC measurements\nPrevious article in issue: Characterization of the composition, structure, and seasonal variation of the mixing layer above the extratropical tropopause as revealed by MOZAIC measurements\n16 April 2008\nComposition and Chemistry\nTrace gas and aerosol interactions in the fully coupled model of aerosol-chemistry-climate ECHAM5-HAMMOZ: 1. Model description and insights from the spring 2001 TRACE-P experiment\nAuthors\nLaboratoire de Modélisation de la Chimie Atmosphérique, École Polytechnique Fédérale de Lausanne, Lausanne, Switzerland\nNow at Atmosphere in Earth System, Max Planck Institute for Meteorology, Hamburg, Germany.\nDepartment of Environmental Science and Engineering, California Institute of Technology, Pasadena, California, USA\nNow at Atmospheric, Oceanic and Planetary Physics, University of Oxford, Oxford, UK.\nCited by (CrossRef): 13 articles Check for updates\nCitation tools\nCiting literature\nAbstract\n[1] In this paper, we introduce the ECHAM5-HAMMOZ aerosol-chemistry-climate model that includes fully interactive simulations of Ox-NOx-hydrocarbons chemistry and of aerosol microphysics (including prognostic size distribution and mixing state of aerosols) implemented in the General Circulation Model ECHAM5. The photolysis rates used in the gas chemistry account for aerosol and cloud distributions and a comprehensive set of heterogeneous reactions is implemented. The model is evaluated with trace gas and aerosol observations provided by the TRACE-P aircraft experiment. Sulfate concentrations are well captured but black carbon concentrations are underestimated. The number concentrations, surface areas, and optical properties are reproduced fairly well near the surface but underestimated in the upper troposphere. CO concentrations are well reproduced in general while O3 concentrations are overestimated by 10–20 ppbv. We find that heterogeneous chemistry significantly influences the regional and global distributions of a number of key trace gases. Heterogeneous reactions reduce the ozone surface concentrations by 18–23% over the TRACE-P region and the global annual mean O3 burden by 7%. The annual global mean OH concentration decreases by 10% inducing a 7% increase in the global CO burden. Annual global mean HNO3 surface concentration decreases by 15% because of heterogenous reaction on mineral dust. A comparison of our results to those from previous studies suggests that the choice of uptake coefficients for a given species is the critical parameter that determines the global impact of heterogeneous chemistry on a trace gas (rather than the description of aerosol properties and distributions). A prognostic description of the size distribution and mixing state of the aerosols is important, however, to account for the effect of heterogeneous chemistry on aerosols as further discussed in the second part of this two-part series.\nSupporting Information\nAuxiliary material for this article contains one text file, 14 figures, and three tables.\nAuxiliary material files may require downloading to a local drive depending on platform, browser, configuration, and size. To open auxiliary materials in a browser, click on the label. To download, Right-click and select “Save Target As…” (PC) or CTRL-click and select “Download Link to Disk” (Mac).\nSee Plugins for a list of applications and supported file formats.\nAdditional file information is provided in the readme.txt.\nFilename\njgrd14161-sup-0001-readme.txt plain text document, 4K\nreadme.txt\nFigure S1. Map of the TRACE-P DC8 and P3B flights.\njgrd14161-sup-0005-fs02.eps PS document, 649K\nFigure S2. Vertical profiles of simulated versus observed meteorological parameters for the ensemble of TRACE-P P3B flights.\njgrd14161-sup-0006-fs03.eps PS document, 615K\nFigure S3. Vertical profiles of simulated versus observed trace gases (CO, OH, O3) for the ensemble of TRACE-P P3B flights.\njgrd14161-sup-0007-fs04.eps PS document, 549K\nFigure S4. Vertical profiles of simulated versus observed trace gases (SO2, NO, NO2) for the ensemble of TRACE-P P3B flights.\njgrd14161-sup-0008-fs05.eps PS document, 439K\nFigure S5. Vertical profiles of simulated versus observed photolysis rates for the ensemble of TRACE-P P3B flights.\njgrd14161-sup-0009-fs06.eps PS document, 645K\nFigure S6. Vertical profiles of simulated versus observed aerosol concentrations and optical properties for the ensemble of TRACE-P P3B flights.\njgrd14161-sup-0010-fs07.eps PS document, 675K\nFigure S7. Vertical profiles of simulated versus observed aerosol size distributions for the ensemble of TRACE-P P3B flights.\njgrd14161-sup-0011-fs08.eps PS document, 75K\nFigure S8. Taylor diagrams comparing the ECHAM5-HAMMOZ BASE simulation to the DC8 flight and P3B flight TRACE-P observations.\njgrd14161-sup-0012-fs09.eps PS document, 80K\nFigure S9. Simulated mean vertical profiles of aerosol concentrations and contributions (%) of each aerosol species to the total aerosol surface in two different regions.\njgrd14161-sup-0013-fs10.eps PS document, 446K\nFigure S10. Flight tracks of DC8-06 and DC8-13.\njgrd14161-sup-0014-fs11.eps PS document, 1318K\nFigure S11. CO concentration at 1000, 725 and 500 hPa over the Trace-P region during flight DC8-06.\njgrd14161-sup-0015-fs12.eps PS document, 1313K\nFigure S12. CO concentration at 1000, 725 and 500 hPa over the Trace-P region during flight DC8-13.\njgrd14161-sup-0016-fs13.eps PS document, 143K\nFigure S13. Vertical profiles of aerosol surface contribution for each aerosol species and vertical profiles of O3, OH, SO2, HNO3, sulfate, mineral dust, and black carbon at 0800 (UTC) of flight DC8-06.\njgrd14161-sup-0017-fs14.eps PS document, 146K\nFigure S14. Vertical profiles of aerosol surface contribution for each aerosol species and vertical profiles of O3, OH, SO2, HNO3, sulfate, mineral dust, and black carbon at 0800 (UTC) of flight DC8-13.\njgrd14161-sup-0024-t01.txt plain text document, 2K\nTab-delimited Table 1.\njgrd14161-sup-0025-t02.txt plain text document, 2K\nTab-delimited Table 2.\njgrd14161-sup-0026-t03.txt plain text document, 1K\nTab-delimited Table 3.\njgrd14161-sup-0027-t04.txt plain text document, 1K\nTab-delimited Table 4.\njgrd14161-sup-0028-t05.txt plain text document, 1K\nTab-delimited Table 5.\njgrd14161-sup-0029-t06.txt plain text document, 1K\nTab-delimited Table 6.\njgrd14161-sup-0030-t07.txt plain text document, 1K\nTab-delimited Table 7.\njgrd14161-sup-0031-t08.txt plain text document, 1K\nTab-delimited Table 8.\njgrd14161-sup-0032-t09.txt plain text document, 1K\nTab-delimited Table 9.\njgrd14161-sup-0033-t10.txt plain text document, 1K\nTab-delimited Table 10.\njgrd14161-sup-0034-t11.txt plain text document, 1K\nTab-delimited Table 11.\njgrd14161-sup-0035-t12.txt plain text document, 1K\nTab-delimited Table 12.\nPlease note: Wiley-Blackwell is not responsible for the content or functionality of any supporting information supplied by the authors. Any queries (other than missing content) should be directed to the corresponding author for the article.\nRelated content\nArticles related to the one you are viewing\nCiting Literature\nNumber of times cited: 13\n1\nAnoop S. Mahajan, Isabelle De Smedt, Mriganka Sekhar Biswas, Sachin Ghude, Suvarna Fadnavis, Chaitri Roy, Michel van Roozendael, Inter-annual variations in satellite observations of nitrogen dioxide and formaldehyde over India, Atmospheric Environment, 2015, 116, 194\nCrossRef\n2\nSijia Lou, Hong Liao, Bin Zhu, Impacts of aerosols on surface-layer ozone concentrations in China through heterogeneous reactions and changes in photolysis rates, Atmospheric Environment, 2014, 85, 123\n3\nMohanad El-Harbawi, Air quality modelling, simulation, and computational methods: a review, Environmental Reviews, 2013, 21, 3, 149\nCrossRef\n4\nBjorn Stevens, Marco Giorgetta, Monika Esch, Thorsten Mauritsen, Traute Crueger, Sebastian Rast, Marc Salzmann, Hauke Schmidt, Jürgen Bader, Karoline Block, Renate Brokopf, Irina Fast, Stefan Kinne, Luis Kornblueh, Ulrike Lohmann, Robert Pincus, Thomas Reichler, Erich Roeckner, Atmospheric component of the MPI-M Earth System Model: ECHAM6, Journal of Advances in Modeling Earth Systems, 2013, 5, 2, 146\nWiley Online Library\n5\nE. Harris, B. Sinha, D. van Pinxteren, A. Tilgner, K. W. Fomba, J. Schneider, A. Roth, T. Gnauk, B. Fahlbusch, S. Mertes, T. Lee, J. Collett, S. Foley, S. Borrmann, P. Hoppe, H. Herrmann, Enhanced Role of Transition Metal Ion Catalysis During In-Cloud Oxidation of SO2, Science, 2013, 340, 6133, 727\nCrossRef\n6\nEliza Harris, Bärbel Sinha, Peter Hoppe, Shuhei Ono, High-Precision Measurements of33S and34S Fractionation during SO2Oxidation Reveal Causes of Seasonality in SO2and Sulfate Isotopic Composition, Environmental Science & Technology, 2013, 47, 21, 12174\nCrossRef\n7\nArlene M. Fiore, Vaishali Naik, Dominick V. Spracklen, Allison Steiner, Nadine Unger, Michael Prather, Dan Bergmann, Philip J. Cameron-Smith, Irene Cionni, William J. Collins, Stig Dalsøren, Veronika Eyring, Gerd A. Folberth, Paul Ginoux, Larry W. Horowitz, Béatrice Josse, Jean-François Lamarque, Ian A. MacKenzie, Tatsuya Nagashima, Fiona M. O'Connor, Mattia Righi, Steven T. Rumbold, Drew T. Shindell, Ragnhild B. Skeie, Kengo Sudo, Sophie Szopa, Toshihiko Takemura, Guang Zeng, Global air quality and climate, Chemical Society Reviews, 2012, 41, 19, 6663\nCrossRef\n8\nSusan C. Anenberg, Joel Schwartz, Drew Shindell, Markus Amann, Greg Faluvegi, Zbigniew Klimont, Greet Janssens-Maenhout, Luca Pozzoli, Rita Van Dingenen, Elisabetta Vignati, Lisa Emberson, Nicholas Z. Muller, J. Jason West, Martin Williams, Volodymyr Demkine, W. Kevin Hicks, Johan Kuylenstierna, Frank Raes, Veerabhadran Ramanathan, Global Air Quality and Health Co-benefits of Mitigating Near-Term Climate Change through Methane and Black Carbon Emission Controls, Environmental Health Perspectives, 2012, 120, 6, 831\nCrossRef\n9\nD. Shindell, J. C. I. Kuylenstierna, E. Vignati, R. van Dingenen, M. Amann, Z. Klimont, S. C. Anenberg, N. Muller, G. Janssens-Maenhout, F. Raes, J. Schwartz, G. Faluvegi, L. Pozzoli, K. Kupiainen, L. Hoglund-Isaksson, L. Emberson, D. Streets, V. Ramanathan, K. Hicks, N. T. K. Oanh, G. Milly, M. Williams, V. Demkine, D. Fowler, Simultaneously Mitigating Near-Term Climate Change and Improving Human Health and Food Security, Science, 2012, 335, 6065, 183\nCrossRef\n10\nQuentin Bourgeois, Isabelle Bey, Pollution transport efficiency toward the Arctic: Sensitivity to aerosol scavenging and source regions, Journal of Geophysical Research, 2011, 116, D8\nWiley Online Library\n11\nA.W. Strawa, T.W. Kirchstetter, A.G. Hallar, G.A. Ban-Weiss, J.P. McLaughlin, R.A. Harley, M.M. Lunden, Optical and physical properties of primary on-road vehicle particle emissions and their implications for climate change, Journal of Aerosol Science, 2010, 41, 1, 36\nCrossRef\n12\nA. Vlasenko, T. Huthwelker, H. W. Gäggeler, M. Ammann, Kinetics of the heterogeneous reaction of nitric acid with mineral dust particles: an aerosol flowtube study, Physical Chemistry Chemical Physics, 2009, 11, 36, 7921\nCrossRef\n13\nL. Pozzoli, I. Bey, S. Rast, M. G. Schultz, P. Stier, J. Feichter, Trace gas and aerosol interactions in the fully coupled model of aerosol-chemistry-climate ECHAM5-HAMMOZ: 2. Impact of heterogeneous chemistry on the global aerosol distributions, Journal of Geophysical Research, 2008, 113, D7\n""","0.20161192","""http://onlinelibrary.wiley.com/doi/10.1029/2007JD009007/abstract""",
"""Imperial_College_London""","""Multi-class dynamic traffic assignment with physical queues: intersection-movement-based formulation and paradox: Transportmetrica A: Transport Science: Vol 12, No 10""","""KEYWORDS: Multi-class dynamic traffic assignment ,  approach proportion ,  variational inequality ,  extragradient method ,  paradox\n1.  Introduction\nDynamic traffic assignment (DTA) is an important topic due to its wide applications in transport planning and management (Szeto and Lo 2006 Szeto, W. Y., and H. K. Lo. 2006. “Dynamic Traffic Assignment: Properties and Extensions.” Transportmetrica 2 (1): 31–52. doi: 10.1080/18128600608685654 [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ). In general, DTA can be classified into the simulation-based approach (e.g. Yagar 1971 Yagar, S. 1971. “Dynamic Traffic Assignment by Individual Path Minimisation and Queuing.” Transportation Research 5 (3): 179–196. doi: 10.1016/0041-1647(71)90020-7 [Crossref]   [Google Scholar] ; Mahmassani, Hu, and Jayakrishnan 1995 Mahmassani, H. S., T. Hu, and R. Jayakrishnan. 1992. “Dynamic Traffic Assignment and Simulation for Advanced Network Informatics (DYNASMART).” Proceedings of the 2nd international CAPRI seminar on Urban Traffic Networks. Capri, July.  [Google Scholar] ; Mahut and Florian 2010 Mahut, M., and M. Florian. 2010. “Traffic Simulation with Dynameq.” In Fundamentals of Traffic Simulation, edited by Jaume Barceló, 323–361.\nNew York\n: Springer. [Crossref]   [Google Scholar] ) and the analytical approach (see Ran and Boyce 1996 Ran, B., and D. E. Boyce. 1996. Modeling Dynamic Transportation Network: An Intelligent Transportation System Oriented Approach.\nSpringer\n: Heidelberg. [Crossref]   [Google Scholar] ; Peeta and Ziliaskopoulos 2001 Peeta, S., and A. K. Ziliaskopoulos. 2001. “Foundations of Dynamic Traffic Assignment: The Past, the Present and the Future.” Networks and Spatial Economics 1 (3–4): 233–265. doi: 10.1023/A:1012827724856 [Crossref]   [Google Scholar] ; Szeto and Lo 2005 Szeto, W. Y., and H. K. Lo. 2005. “Dynamic Traffic Assignment: Review and Future Research Directions.” Journal of Transportation Systems Engineering and Information Technology 5 (5): 85–100.  [Google Scholar] ; and Szeto and Wong 2012 Szeto, W. Y., and S. C. Wong. 2012. “Dynamic Traffic Assignment: Model Classifications and Recent Advances in Travel Choice Principles.” Central European Journal of Engineering 2 (1): 1–18. [Crossref]   [Google Scholar] for comprehensive reviews). The simulation-based approach focuses on enabling practical deployment for realistic networks, its applicability in real-life networks, and its ability to capture traffic dynamics and microscopic driver behaviour such as lane-changing behaviour. However, the solution properties of the corresponding models, such as solution existence and uniqueness, are not guaranteed and cannot be determined in advance.\nIn contrast, the analytical approach is more suitable for analysing the properties of DTA via various frameworks. These frameworks include the optimisation model (Merchant and Nemhauser 1978a Merchant, D. K., and G. L. Nemhauser. 1978a. “A Model and an Algorithm for the Dynamic Traffic Assignment Problems.” Transportation Science 12 (3): 183–199. doi: 10.1287/trsc.12.3.183 [Crossref]   [Google Scholar] , 1978b Merchant, D. K., and G. L. Nemhauser. 1978b. “Optimality Conditions for a Dynamic Traffic Assignment Model.” Transportation Science 12 (3): 200–207. doi: 10.1287/trsc.12.3.200 [Crossref]   [Google Scholar] ; Carey 1987 Carey, M. 1987. “Optimal Time-Varying Flows on Congested Networks.” Operations Research 35 (1): 58–69. doi: 10.1287/opre.35.1.58 [Crossref] , [Web of Science ®]   [Google Scholar] ; Carey and Watling 2012 Carey, M., and D. Watling. 2012. “Dynamic Traffic Assignment Approximating the Kinematic Wave Model: System Optimum, Marginal Costs, Externalities and Tolls.” Transportation Research Part B: Methodological 46 (5): 634–648. doi: 10.1016/j.trb.2012.01.008 [Crossref] , [Web of Science ®]   [Google Scholar] ), optimal control (Friesz et al. 1989 Friesz, T. L., J. Luque, R. L. Tobin, and B. W. Wie. 1989. “Dynamic Network Traffic Assignment Considered as a Continuous Time Optimal Control Problem.” Operations Research 37 (6): 893–901. doi: 10.1287/opre.37.6.893 [Crossref] , [Web of Science ®]   [Google Scholar] ; Ran, Boyce, and LeBlanc 1993 Ran, B., D. E. Boyce, and L. J. LeBlanc. 1993. “A New Class of Instantaneous Dynamic User-Optimal Traffic Assignment Models.” Operations Research 41 (1): 192–202. doi: 10.1287/opre.41.1.192 [Crossref] , [Web of Science ®]   [Google Scholar] ; Chow 2009a Chow, A. H. F. 2009a. “Dynamic System Optimal Traffic Assignment – A State-Dependent Control Theoretic Approach.” Transportmetrica 5 (2): 85–106. doi: 10.1080/18128600902717483 [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] , 2009b Chow, A. H. F. 2009b. “Properties of System Optimal Traffic Assignment with Departure Time Choice and Its Solution Method.” Transportation Research Part B: Methodological 43(3): 325–344. doi: 10.1016/j.trb.2008.07.006 [Crossref] , [Web of Science ®]   [Google Scholar] ; Ma et al. 2014a Ma, R., X. J. Ban, and J.-S. Pang. 2014a. “Continuous-time Dynamic System Optimum for Single-Destination Traffic Networks with Queue Spillbacks.” Transportation Research Part B: Methodological 68: 98–122. doi: 10.1016/j.trb.2014.06.003 [Crossref] , [Web of Science ®]   [Google Scholar] , 2014b Ma, R., X. J. Ban, and J.-S. Pang. 2014b. “Continuous-time Dynamic User Equilibrium Model with Departure-Time Choice and Capacitated Queue.” Proceedings of the 5th International Symposium on Dynamic Traffic Assignment, Salerno, Italy, 17–19 June.  [Google Scholar] ), variational inequality (Friesz et al. 1993 Friesz, T. L., D. Bernstein, T. E. Smith, R. L. Tobin, and B. W. Wie. 1993. “A Variational Inequality Formulation of the Dynamic Network User Equilibrium Problem.” Operations Research 41 (1): 179–191. doi: 10.1287/opre.41.1.179 [Crossref] , [Web of Science ®]   [Google Scholar] ; Ran and Boyce 1996 Ran, B., and D. E. Boyce. 1996. Modeling Dynamic Transportation Network: An Intelligent Transportation System Oriented Approach.\nSpringer\n: Heidelberg. [Crossref]   [Google Scholar] ; Chen and Hsueh 1998 Chen, H. K., and C. F. Hsueh. 1998. “A Model and an Algorithm for the Dynamic User-Optimal Route Choice Problem.” Transportation Research Part B: Methodological 32 (3): 219–234. doi: 10.1016/S0191-2615(97)00026-X [Crossref] , [Web of Science ®]   [Google Scholar] ; Huang and Lam 2002 Huang, H. J., and W. H. K. Lam. 2002. “Modeling and Solving the Dynamic User Equilibrium Route and Departure Time Choice Problem in Network With Queues.” Transportation Research Part B: Methodological 36 (3): 253–273. doi: 10.1016/S0191-2615(00)00049-7 [Crossref] , [Web of Science ®]   [Google Scholar] ; Lo and Szeto 2002a Lo, H. K., and W. Y. Szeto. 2002a. “A Cell-Based Variational Inequality Formulation of the Dynamic User Optimal Assignment Problem.” Transportation Research Part B: Methodological 36 (5): 421–443. doi: 10.1016/S0191-2615(01)00011-X [Crossref] , [Web of Science ®]   [Google Scholar] , 2002b Lo, H. K., and W. Y. Szeto. 2002b. “A Cell-Based Dynamic Traffic Assignment Model: Formulation and Properties.” Mathematical and Computer Modelling 35 (7–8): 849–865. doi: 10.1016/S0895-7177(02)00055-9 [Crossref] , [Web of Science ®]   [Google Scholar] ; Szeto and Lo 2004 Szeto, W. Y., and H. K. Lo. 2004. “A Cell-Based Simultaneous Route and Departure Time Choice Model with Elastic Demand.” Transportation Research Part B: Methodological 38 (7): 593–612. doi: 10.1016/j.trb.2003.05.001 [Crossref] , [Web of Science ®]   [Google Scholar] , 2006 Szeto, W. Y., and H. K. Lo. 2006. “Dynamic Traffic Assignment: Properties and Extensions.” Transportmetrica 2 (1): 31–52. doi: 10.1080/18128600608685654 [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ; Han, Friesz, and Yao 2013c Han, K., T. L. Friesz, and T. Yao. 2013c. “Existence of Simultaneous Route and Departure Choice Dynamic User Equilibrium.” Transportation Research Part B: Methodological 53: 17–30. doi: 10.1016/j.trb.2013.01.009 [Crossref] , [Web of Science ®]   [Google Scholar] ), nonlinear complementarity problem (NCP) (Wie, Tobin, and Carey 2002 Wie, B. W., R. L. Tobin, and M. Carey. 2002. “The Existence, Uniqueness and Computation of an Arc-Based Dynamic Network User Equilibrium Formulation.” Transportation Research Part B: Methodological 36 (10): 897–918. doi: 10.1016/S0191-2615(01)00041-8 [Crossref] , [Web of Science ®]   [Google Scholar] ; Ban et al. 2008 Ban, X. J., H. X. Liu, M. C. Ferris, and B. Ran. 2008. “A Link-Node Complementarity Model and Solution Algorithm for Dynamic User Equilibria with Exact Flow Propagations.” Transportation Research Part B: Methodological 42 (9): 823–842. doi: 10.1016/j.trb.2008.01.006 [Crossref] , [Web of Science ®]   [Google Scholar] ), nonlinear equation system (Long et al. 2015b Long, J. C., W. Y. Szeto, Q. Shi, Z. Y. Gao, and H. J. Huang. 2015b. “A Nonlinear Equation System Approach to the Dynamic Stochastic User Equilibrium Simultaneous Route and Departure Time Choice Problem.” Transportmetrica A: Transport Science 11 (5): 388–419. doi: 10.1080/23249935.2014.1003112 [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ), fixed point problem (Szeto, Jiang, and Sumalee 2011 Szeto, W. Y., Y. Jiang, and A. Sumalee. 2011. “A Cell-Based Model for Multi-Class Doubly Stochastic Dynamic Traffic Assignment.” Computer-Aided Civil and Infrastructure Engineering 26: 595–611. doi: 10.1111/j.1467-8667.2011.00717.x [Crossref] , [Web of Science ®]   [Google Scholar] ; Meng and Khoo 2012 Meng, Q., and H. L. Khoo. 2012. “A Computational Model for the Probit-Based Dynamic Stochastic User Optimal Traffic Assignment Problem.” Journal of Advanced Transportation 46 (1): 80–94. doi: 10.1002/atr.149 [Crossref] , [Web of Science ®]   [Google Scholar] ), differential variational inequality (Friesz et al. 2013 Friesz, T. L., K. Han, P. A. Neto, A. Meimand, and T. Yao. 2013. “Dynamic User Equilibrium Based on a Hydrodynamic Model.” Transportation Research Part B: Methodological 47 (1): 102–126. doi: 10.1016/j.trb.2012.10.001 [Crossref] , [Web of Science ®]   [Google Scholar] ; Friesz and Meimand 2014 Friesz, T. L., and A. Meimand. 2014. “A Differential Variational Inequality Formulation of Dynamic Network User Equilibrium with Elastic Demand.” Transportmetrica A: Transport Science 10 (7): 661–668. doi: 10.1080/18128602.2012.751684 [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ), and differential complementarity problem (Ban et al. 2012b Ban, X. J., J. S. Pang, H. X. Liu, and R. Ma. 2012b. “Modeling and Solving Continuous-Time Instantaneous Dynamic User Equilibria: A Differential Complementarity Systems Approach.” Transportation Research Part B: Methodological 46 (3): 389–408. doi: 10.1016/j.trb.2011.11.002 [Crossref] , [Web of Science ®]   [Google Scholar] ) frameworks.\nAll of the preceding analytical frameworks are formulated as either path-based models (e.g. Friesz et al. 1993 Friesz, T. L., D. Bernstein, T. E. Smith, R. L. Tobin, and B. W. Wie. 1993. “A Variational Inequality Formulation of the Dynamic Network User Equilibrium Problem.” Operations Research 41 (1): 179–191. doi: 10.1287/opre.41.1.179 [Crossref] , [Web of Science ®]   [Google Scholar] ; Huang and Lam 2002 Huang, H. J., and W. H. K. Lam. 2002. “Modeling and Solving the Dynamic User Equilibrium Route and Departure Time Choice Problem in Network With Queues.” Transportation Research Part B: Methodological 36 (3): 253–273. doi: 10.1016/S0191-2615(00)00049-7 [Crossref] , [Web of Science ®]   [Google Scholar] ; Lo and Szeto 2002a Lo, H. K., and W. Y. Szeto. 2002a. “A Cell-Based Variational Inequality Formulation of the Dynamic User Optimal Assignment Problem.” Transportation Research Part B: Methodological 36 (5): 421–443. doi: 10.1016/S0191-2615(01)00011-X [Crossref] , [Web of Science ®]   [Google Scholar] , 2002b Lo, H. K., and W. Y. Szeto. 2002b. “A Cell-Based Dynamic Traffic Assignment Model: Formulation and Properties.” Mathematical and Computer Modelling 35 (7–8): 849–865. doi: 10.1016/S0895-7177(02)00055-9 [Crossref] , [Web of Science ®]   [Google Scholar] ; Szeto and Lo 2004 Szeto, W. Y., and H. K. Lo. 2004. “A Cell-Based Simultaneous Route and Departure Time Choice Model with Elastic Demand.” Transportation Research Part B: Methodological 38 (7): 593–612. doi: 10.1016/j.trb.2003.05.001 [Crossref] , [Web of Science ®]   [Google Scholar] , 2006 Szeto, W. Y., and H. K. Lo. 2006. “Dynamic Traffic Assignment: Properties and Extensions.” Transportmetrica 2 (1): 31–52. doi: 10.1080/18128600608685654 [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ; Perakis and Roels 2006 Perakis, G., and Roels, G. 2006. “An Analytical Model for Traffic Delays and the Dynamic User Equilibrium Problem.” Operations Research 54 (6): 1151–1171. doi: 10.1287/opre.1060.0307 [Crossref] , [Web of Science ®]   [Google Scholar] ; Szeto 2008 Szeto, W. Y.. 2008. “Enhanced Lagged Cell-Transmission Model for Dynamic Traffic Assignment.” Transportation Research Record: Journal of the Transportation Research Board 2085: 76–85. doi: 10.3141/2085-09 [Crossref] , [Web of Science ®]   [Google Scholar] ; Szeto, Jiang, and Sumalee 2011 Szeto, W. Y., Y. Jiang, and A. Sumalee. 2011. “A Cell-Based Model for Multi-Class Doubly Stochastic Dynamic Traffic Assignment.” Computer-Aided Civil and Infrastructure Engineering 26: 595–611. doi: 10.1111/j.1467-8667.2011.00717.x [Crossref] , [Web of Science ®]   [Google Scholar] ) or link-based models (e.g. Carey 1987 Carey, M. 1987. “Optimal Time-Varying Flows on Congested Networks.” Operations Research 35 (1): 58–69. doi: 10.1287/opre.35.1.58 [Crossref] , [Web of Science ®]   [Google Scholar] ; Ran and Boyce 1996 Ran, B., and D. E. Boyce. 1996. Modeling Dynamic Transportation Network: An Intelligent Transportation System Oriented Approach.\nSpringer\n: Heidelberg. [Crossref]   [Google Scholar] ; Chen and Hsueh 1998 Chen, H. K., and C. F. Hsueh. 1998. “A Model and an Algorithm for the Dynamic User-Optimal Route Choice Problem.” Transportation Research Part B: Methodological 32 (3): 219–234. doi: 10.1016/S0191-2615(97)00026-X [Crossref] , [Web of Science ®]   [Google Scholar] ; Wie, Tobin, and Carey 2002 Wie, B. W., R. L. Tobin, and M. Carey. 2002. “The Existence, Uniqueness and Computation of an Arc-Based Dynamic Network User Equilibrium Formulation.” Transportation Research Part B: Methodological 36 (10): 897–918. doi: 10.1016/S0191-2615(01)00041-8 [Crossref] , [Web of Science ®]   [Google Scholar] ; Ban et al. 2008 Ban, X. J., H. X. Liu, M. C. Ferris, and B. Ran. 2008. “A Link-Node Complementarity Model and Solution Algorithm for Dynamic User Equilibria with Exact Flow Propagations.” Transportation Research Part B: Methodological 42 (9): 823–842. doi: 10.1016/j.trb.2008.01.006 [Crossref] , [Web of Science ®]   [Google Scholar] ). The merit of path-based models is that the path-related information, such as path flows and sets, can be obtained and imported to dynamic network loading (DNL) models to model flow propagation at merges and diverges and track spillback queues. Nevertheless, a path-based model normally suffers from the computational burden of path enumeration or relies on path-generation heuristics with no guarantee on convergence to handle huge path sets, even for medium networks. Instead, link-based models can avoid these two demerits and thus be applied to large networks. However, link-based models cannot be used to capture realistic traffic dynamics such as queue spillback (in one exception, Ma et al. ( 2014b Ma, R., X. J. Ban, and J.-S. Pang. 2014b. “Continuous-time Dynamic User Equilibrium Model with Departure-Time Choice and Capacitated Queue.” Proceedings of the 5th International Symposium on Dynamic Traffic Assignment, Salerno, Italy, 17–19 June.  [Google Scholar] ) proposed a link-based dynamic user optimal (DUO) model that could capture queue spillback for single-destination cases). If it is not captured, the flow pattern and locations of severe congestion may be estimated incorrectly and the strategy adopted may actually worsen network performance (Lo and Szeto 2004 Lo, H. K., and W. Y. Szeto. 2004. “Modeling Advanced Traveler Information Services: Static Versus Dynamic Paradigms.” Transportation Research Part B: Methodological 38 (6): 495–515. doi: 10.1016/j.trb.2003.06.001 [Crossref] , [Web of Science ®]   [Google Scholar] , 2005 Lo, H. K., and W. Y. Szeto. 2005. “Road Pricing for Hyper-congestion.” Transportation Research Part A 39 (7–9): 705–722.  [Google Scholar] ).\nTo retain the benefits of both the link- and path-based models, Long et al. ( 2013 Long, J. C., H. J. Huang, Z. Y. Gao, and W. Y. Szeto. 2013. “An Intersection-Movement-Based Dynamic User Optimal Route Choice Problem.” Operations Research 61 (5): 1134–1147. doi: 10.1287/opre.2013.1202 [Crossref] , [Web of Science ®]   [Google Scholar] , 2015a Long, J. C., W. Y. Szeto, H. J. Huang, and Z. Y. Gao. 2015a. “An Intersection-Movement-Based Stochastic Dynamic User Optimal Route Choice Model for Assessing Network Performance.” Transportation Research Part B: Methodological 74: 182–217. doi: 10.1016/j.trb.2014.12.008 [Crossref] , [Web of Science ®]   [Google Scholar] ) developed intersection-movement-based DTA models for general networks with multiple destinations. They formulated the traffic assignment problem in terms of approach proportions, that is, the proportion of traffic on the current link or node that selects a downstream link when leaving an intersection (or a node). This definition requires either two adjacent links or one origin link and one outgoing link to define an intersection movement. This is different from the classical definition, according to which only downstream links are used to define the proportion. An approach-proportion implicitly contains the traveller’s path information, as a path can be deduced by checking the downstream links involved in defining the approach proportions from origin to destination. As a result, this type of model can retain the advantages of both the link- and path-based models. First, as in link-based models, path enumeration and path-set generation can be avoided in the solution procedure for intersection-movement-based models. Second, as in path-based models, the realistic effects of physical queues can be captured in intersection-movement-based models when a physical queue DNL model is adopted, as the approach proportions contain the traveller’s path information. However, compared with link-based models, intersection-movement-based models have more decision variables, as each link flow or demand rate is disaggregated by downstream links (which very often number more than one) to define intersection movements and the corresponding approach proportions.\nMost of the preceding models, including the intersection-movement-based DTA models, consider only a single vehicle class. It is important to capture multiple vehicle classes in a DTA model and the interactions between different types of vehicles for several reasons. First, interactions between vehicle classes have been identified as a cause of traffic hysteresis, capacity decreases, and the wide scattering of flow–density relationships in a congested regime (Ngoduy 2010 Ngoduy, D. 2010. “Multi-Class First-Order Modelling of Traffic Networks Using Discontinuous Flow-Density Relationships.” Transportmetrica 6 (2): 121–141. doi: 10.1080/18128600902857925 [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ). Second, it is clear that trucks have a great influence on highway capacity, as they travel more slowly than cars and can become moving bottlenecks. Therefore, without considering different vehicle types and their interactions, realistic traffic dynamics and queue spillback cannot be modelled properly and the total system travel time cannot be estimated precisely. Third, many empirical studies have shown that vehicle emissions are closely related to speed and vehicle type; for example, the emissions of trucks are greater than those of cars. Therefore, it is important to capture traffic heterogeneity in estimating total vehicle emissions. Fourth, it is essential to distinguish user classes in the application of class-specific or priority control or when different types of traffic information are available to different user classes (Ngoduy 2010 Ngoduy, D. 2010. “Multi-Class First-Order Modelling of Traffic Networks Using Discontinuous Flow-Density Relationships.” Transportmetrica 6 (2): 121–141. doi: 10.1080/18128600902857925 [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ).\nThis paper develops a multi-class intersection-movement-based DTA model based on the DUO principle and concept of approach proportion. The problem is formulated as a VI problem. The DNL model proposed by Bliemer ( 2007 Bliemer, M. C. J. 2007. “Dynamic Queuing and Spillback in Analytical Multi-Class Dynamic Network Loading Model.” Transportation Research Record: Journal of the Transportation Research Board 2029 (1): 14–21. doi: 10.3141/2029-02 [Crossref] , [Web of Science ®]   [Google Scholar] ) is modified and incorporated into the VI formulation. Unlike some single-class DNL models (Ban et al. 2012a Ban, X. J., J. S. Pang, H. X. Liu, and R. Ma. 2012a. “Continuous-Time Point-Queue Models in Dynamic Network Loading.” Transportation Research Part B: Methodological 46 (3): 360–380. doi: 10.1016/j.trb.2011.11.004 [Crossref] , [Web of Science ®]   [Google Scholar] ; Han, Friesz, and Yao 2013a Han, K., T. L. Friesz, and T. Yao. 2013a. “A Partial Differential Equation Formulation of Vickrey’s Bottleneck Model, Part I: Methodology and Theoretical Analysis.” Transportation Research Part B: Methodological 49: 55–74. doi: 10.1016/j.trb.2012.10.003 [Crossref] , [Web of Science ®]   [Google Scholar] , 2013b Han, K., T. L. Friesz, and T. Yao. 2013b. “A Partial Differential Equation Formulation of Vickrey’s Bottleneck Model, Part II: Numerical Analysis and Computation.” Transportation Research Part B: Methodological 49: 75–93. doi: 10.1016/j.trb.2012.10.004 [Crossref] , [Web of Science ®]   [Google Scholar] ), this DNL model can capture car–truck interactions and allow approach proportions to be used as inputs. An extragradient method that requires only mild assumptions is adopted to solve the problem. Numerical examples are set to illustrate the importance of considering multiple vehicle classes. In addition, a car–truck interaction paradox, which states that allowing trucks to travel in a network or increasing the demand of trucks can improve total car travel time, is proposed, discussed, and examined. The findings have important implications for managing road networks with multiple types of traffic. For example, it is possible to relax road restrictions for trucks or large vehicles so that the total car travel time can be further improved or vice versa. The findings also open up new research directions for traffic management such as road restrictions and priority control for specific vehicle classes. This paper makes two main contributions. First, it proposes a multi-class intersection-movement-based DTA model that considers interactions between different types of vehicles and physical queues. Second, it proposes and examines the paradox associated with the interactions between trucks and cars.\nThe remainder of this paper proceeds as follows. Section 2 introduces the VI formulation for the intersection-movement-based multi-class DTA problem. It then depicts the DNL model encapsulated for calculating the mapping function in the VI formulation. Section 3 presents the extragradient solution method. Numerical examples are given in Section 4. Finally, Section 5 provides our conclusions and future research directions.\n2.  Formulation\n2.1  Notations\nWe consider a network with multiple origins and destinations and various classes of vehicles according to vehicle type. The network is formed by nodes and links. To simplify the presentation of the formulation, the network is designed to have the following properties. First, a node in a network can only have one status, that is, an origin, a destination, or an intermediate node. Second, at least two links are required to connect an origin and a destination. Third, there is one dummy link coming out from a destination with an infinite capacity. The first requirement can easily be satisfied by designing the network carefully. The second requirement is always satisfied for large networks. For small networks, this requirement can be satisfied by breaking down each link directly connecting an origin and a destination into a pair of links: one going into an intermediate node, and one coming out from the node. The third requirement aims to avoid developing additional sub-models to deal with flow propagation for the links going into a destination.\nThe following notations are used throughout this paper.\n2.1.1  Sets\n""","0.7279187","""http://www.tandfonline.com/doi/full/10.1080/23249935.2016.1190421""","[-0.178219,51.500505]"
"""Imperial_College_London""","""Teleconsultations reduce greenhouse gas emissionsJournal of Health Services Research &amp; Policy - Tiago Cravo Oliveira, James Barlow, Luís Gonçalves, Steffen Bayer, 2013""","""Section:\n1.\nNHS Sustainable Development Unit. Sustainability in the NHS: health check 2012, Cambridge: NHS Sustainable Development Unit, 2012. Google Scholar\n2.\nLynch T. Greening health care: how hard can that be? J Health Serv Res Policy 2011; 16: 247–248. Google Scholar Link\n3.\nMayor S. NHS should bring in measures to reduce its carbon footprint, BMA says. BMJ 2008; 336: 740–740. Google Scholar Crossref , Medline\n4.\nMerrell RC, Doarn CR. Telemedicine is green!!. Telemed J E-Health 2009; 15: 731–732. Google Scholar Crossref , Medline\n5.\nMasino C, Rubinstein E, Lem L, . The impact of telemedicine on greenhouse gas emissions at an academic health science center in Canada. Telemed J E-Health 2010; 16: 973–976. Google Scholar Crossref , Medline\n6.\nLewis D, Tranter G, Axford AT. Use of videoconferencing in Wales to reduce carbon dioxide emissions, travel costs and time. J Telemed Telecare 2009; 15: 137–138. Google Scholar Link\n7.\nDorrian C, Fergunson J, Ah-See K, . Head and neck cancer assessment by flexible endoscopy and telemedicine. J Telemed Telecare 2009; 15: 118–121. Google Scholar Link\n8.\nBond A, Jones A, Haynes R, . Tackling climate change close to home: mobile breast screening as a model. J Health Serv Res Policy 2009; 14: 165–167. Google Scholar Link\n9.\nJarrett J, Woodcock J, Griffiths UK, . Effect of increasing active travel in urban England and Wales on costs to the National Health Service. Lancet 2012; 379: 2198–2205. Google Scholar Crossref , Medline\n10.\nInstituto Nacional de Estatística (INE). Estatísticas dos transportes 2011, Lisboa: Instituto Nacional de Estatística, 2012. Google Scholar\n11.\nAssociação Automóvel de Portugal (ACAP). O comércio e a indústria automóvel em Portugal, Lisboa: Associação Automóvel de Portugal, 2008. Google Scholar\n12.\nAEA for Defra and DECC. 2012 Guidelines to Defra/DECC’s GHG conversion factors for company reporting, London, UK: AEA for Defra and DECC, 2012. Google Scholar\n13.\nAsociación Española de Fabricantes de Automóviles y Camiones (ANFAC). European motor vehicle parc 2008, Spain: ANFAC, 2010. Google Scholar\n14.\nEurostat. Average carbon dioxide emissions per km from new passenger cars (code: tsdtr450), Luxembourg: Eurostat, 2013. Google Scholar\n15.\nMinistry of Health and Long-Term Care. Patient travel assistance programs in Ontario – findings of a review of the northern health travel grant program and cancer care Ontario radiation re-referral policy, Ontario: Ministry of Health and Long-Term Care, 2000. Google Scholar\n16.\n""","0.5687062","""http://journals.sagepub.com/doi/10.1177/1355819613492717""","[-0.178219,51.500505]"
"""Aston_University""","""Taking the carbon out of the car - Research Explorer : Aston University""","""Taking the carbon out of the car\nResearch output: Contribution to journal › Article\nJulia King ORCiD: http://orcid.org/0000-0002-8563-7646\nAbstract\nEffective measures are being taken to reduce emissions from cars, which are now emerging as a major contributor to climate change. Developed countries will need to reduce emissions by at least 80% by 2050 to achieve stabilization of atmospheric CO2 concentration between 450 and 550 ppm, and have a unique opportunity to avoid the most damaging effects of climate change. The UK is aiming at completely decarbonising transport by 2050 through a combination of more efficient vehicles, cleaner fuels, and smart driving choices. The European Commission has proposed a mandatory CO2 target on new car CO 2 efficiency, which is an urgent needed development. The nation is also using regulatory targets for local schemes, such as free parking or congestion charging, break points for company car tax, and vehicle excise duty. Car ownership and use should thereby continue to drive economic growth and enhance quality of life around the world without destroying the planet.\nDetails\n""","0.67723644","""https://research.aston.ac.uk/portal/en/researchoutput/taking-the-carbon-out-of-the-car(e1096051-23a9-48d4-9a13-6cf1879ba813).html""","[-1.888803,52.487018]"
"""Imperial_College_London""","""A Chemical and Morphological Study of Diesel Injector Nozzle Deposits - Insights into their Formation and Growth Mechanisms""","""A Chemical and Morphological Study of Diesel Injector Nozzle Deposits - Insights into their Formation and Growth Mechanisms\nPaper #:\nhttps://doi.org/10.4271/2017-01-0798\nCitation:\nRounthwaite, N., Williams, R., McGivery, C., Jiang, J. et al., \""A Chemical and Morphological Study of Diesel Injector Nozzle Deposits - Insights into their Formation and Growth Mechanisms,\"" SAE Int. J. Fuels Lubr. 10(1):106-114, 2017, https://doi.org/10.4271/2017-01-0798 .\n9\nAbstract:\nModern diesel passenger car technology continues to develop rapidly in response to demanding emissions, performance, refinement, cost and fuel efficiency requirements. This has included the implementation of high pressure common rail fuel systems employing high precision injectors with complex injection strategies, higher hydraulic efficiency injector nozzles and in some cases <100µm nozzle hole diameters. With the trend towards lower diameter diesel injector nozzle holes and reduced cleaning through cavitation with higher hydraulic efficiency nozzles, it is increasingly important to focus on understanding the mechanism of diesel injector nozzle deposit formation and growth. In this study such deposits were analysed by cross-sectioning the diesel injector along the length of the nozzle hole enabling in-depth analysis of deposit morphology and composition change from the inlet to the outlet, using state-of-the-art electron microscopy techniques. Deposits produced in the injector nozzles of the industry standard fouling test (CEC F-98-08 DW10B bench engine) were compared with those formed in a vehicle driven on a chassis dynamometer, using a drive cycle more representative of real world vehicle conditions, to explore the effects of differing drive cycles and engine technologies. Fouling in all tests was accelerated with the addition of 1ppm zinc neodecanoate, as specified in the CEC DW10B test. This in-depth characterisation revealed a complex multi-layered system of deposits inside the diesel injector nozzle. Through analysing these layers the mechanisms enabling the initial deposit formation and growth can be postulated.\nAlso in:\n""","0.515975","""http://papers.sae.org/2017-01-0798/""","[-0.178219,51.500505]"
"""University_of_Aberdeen""","""An investigation into the feasibility and potential benefits of shared taxi services to commuter stations: Urban, Planning and Transport Research: Vol 2, No 1""","""An investigation into the feasibility and potential benefits of shared taxi services to commuter stations\nPDF\nAbstract\nParking is a serious problem at many rail stations where large numbers of commuters ‘park and ride’ mainly on a single occupancy basis. In many cases, these stations are not designed for mass parking, resulting in on-street parking conflicts with residents and local commercial businesses. Furthermore, congestion around stations is a growing problem, compounded by rail passengers being picked up by friends or relatives resulting in queues of waiting cars at station entrances. These ‘kiss and ride’ trips require double the fuel (home to station to home again) and impinge on the time of the driver providing the lift. In this paper, it is anticipated that the introduction of shared taxis to rail stations has the potential to relieve these parking and congestion problems while also providing an affordable extra service to the rail station for those without access to a car or other suitable public transport service. A model for shared taxi operation is presented and the potential viability and benefits of such a service is illustrated using data from two varied case study sites: (1) a station in South East England providing rail access to London and (2) a smaller station in Central Scotland providing rail access to Edinburgh.\n""","0.724696","""http://www.tandfonline.com/doi/abs/10.1080/21650020.2014.908736""","[-2.099122,57.165019]"
"""Imperial_College_London""","""Environmental Health Perspectives – Research Recommendations for Selected IARC-Classified Agents""","""Review October 2010 | Volume 118 | Issue 10\nEnviron Health Perspect; DOI:10.1289/ehp.0901828\nResearch Recommendations for Selected IARC-Classified Agents\n[do action=”authors”]Elizabeth M. Ward1, Paul A. Schulte2, Kurt Straif3, Nancy B. Hopf4, Jane C. Caldwell5, Tania Carreón2, David M. DeMarini5, Bruce A. Fowler6, Bernard D. Goldstein7, Kari Hemminki8, Cynthia J. Hines2, Kirsti Husgafvel Pursiainen9, Eileen Kuempel2, Joellen Lewtas10, Ruth M. Lunn11, Elsebeth Lynge12, Damien M. McElvenny13, Hartwig Muhle14, Tamie Nakajima15, Larry W. Robertson16, Nathaniel Rothman17, Avima M. Ruder2, Mary K. Schubauer-Berigan2, Jack Siemiatycki18, Debra Silverman17, Martyn T. Smith19, Tom Sorahan20, Kyle Steenland21, Richard G. Stevens22, Paolo Vineis23, Shelia Hoar Zahm17, Lauren Zeise24, Vincent J. Cogliano3[/do][do action=”affiliations”]1American Cancer Society, Atlanta Georgia, USA; 2National Institute for Occupational Safety and Health, Cincinnati, Ohio, USA; 3International Agency for Research on Cancer, Lyon, France; 4Institute universitaire romand de Sante au Travail, Lausanne, Switzerland; 5U.S. Environmental Protection Agency, Research Triangle Park, North Carolina, USA; 6Agency for Toxic Substances and Disease Registry, Chamblee, Georgia, USA; 7University of Pittsburgh, Pittsburgh, Pennsylvania, USA; 8German Cancer Research Center, Heidelberg, Germany; 9Finnish Institute of Occupational Health, Helsinki, Finland; 10University of Washington, Seattle, Washington, USA; 11National Institute of Environmental Health Sciences, National Institutes of Health, Department of Health and Human Services, Research Triangle Park, North Carolina, USA; 12University of Copenhagen, Copenhagen, Denmark; 13University of Central Lancashire/Westlakes Scientific Consulting, Cumbria, Lancashire, United Kingdom; 14Fraunhofer Institute of Toxicology and Experimental Medicine, Hannover, Germany; 15Nagoya University Graduate School of Medicine, Nagoya, Japan; 16University of Iowa, Iowa City, Iowa, USA; 17National Cancer Institute, National Institutes of Health, Department of Health and Human Services, Bethesda, Maryland, USA; 18University of Montreal Hospital Research Center, Montreal, Quebec, Canada; 19University of California, Berkeley, Berkeley, California, USA; 20Institute of Occupational and Environmental Medicine, University of Birmingham, Birmingham, United Kingdom; 21Rollins School of Public Health, Emory University, Atlanta, Georgia, USA; 22University of Connecticut Health Center, Farmington, Connecticut, USA; 23Imperial College London, London, United Kingdom; 24California Environmental Protection Agency, Oakland, California, USA[/do][do action=”citation-string”]Environ Health Perspect 118:1355-1362 (2010). http://dx.doi.org/10.1289/ehp.0901828 [online 18 June 2010] [/do]\nAbstract\n[do action=”abstract”]\nObjectives: There are some common occupational agents and exposure circumstances for which evidence of carcinogenicity is substantial but not yet conclusive for humans. Our objectives were to identify research gaps and needs for 20 agents prioritized for review based on evidence of widespread human exposures and potential carcinogenicity in animals or humans.\nData sources: For each chemical agent (or category of agents), a systematic review was conducted of new data published since the most recent pertinent International Agency for Research on Cancer (IARC) Monograph meeting on that agent.\nData extraction: Reviewers were charged with identifying data gaps and general and specific approaches to address them, focusing on research that would be important in resolving classification uncertainties. An expert meeting brought reviewers together to discuss each agent and the identified data gaps and approaches.\nData synthesis: Several overarching issues were identified that pertained to multiple agents; these included the importance of recognizing that carcinogenic agents can act through multiple toxicity pathways and mechanisms, including epigenetic mechanisms, oxidative stress, and immuno- and hormonal modulation.\nConclusions: Studies in occupational populations provide important opportunities to understand the mechanisms through which exogenous agents cause cancer and intervene to prevent human exposure and/or prevent or detect cancer among those already exposed. Scientific developments are likely to increase the challenges and complexities of carcinogen testing and evaluation in the future, and epidemiologic studies will be particularly critical to inform carcinogen classification and risk assessment processes.\n[/do][do action=”abstract”]Key words: animal, carcinogen, carcinogenesis, epidemiology, human, IARC, mechanisms of carcinogenicity, occupational[/do]\n[do action=”notes-rule-above”]Address correspondence to E.M. Ward, Epidemiology and Surveillance Research, American Cancer Society, 250 Williams St., Atlanta, GA 30303 USA. Telephone: (404) 327-6552. Fax: (404) 327-6450. E-mail: elizabeth.ward@cancer.org [/do][do action=”notes”]This research was supported by the American Cancer Society, the National Institute for Occupational Safety and Health, the Monographs Program of the International Agency for Research on Cancer, the Intramural Research Program of the National Institute of Environmental Health Sciences [National Institutes of Health (NIH)], and the Division of Cancer Epidemiology and Genetics, National Cancer Institute (NIH).[/do][do action=”notes”] The findings and conclusions in this report are those of the authors and do not necessarily represent the views of any of the U.S. Government agencies with which some of the authors are affiliated. R.M.L. did not participate in the discussions of metallic cobalt with tungsten, formaldehyde, or styrene. [/do][do action=”notes”]The authors declare they have no actual or potential competing financial interests.[/do][do action=”notes”] Received 15 December 2009; accepted 18 June 2010; online 18 June 2010.[/do]\nForty-five years after the World Health Organization recognized cancer as a world health problem by creating the International Agency for Research on Cancer (IARC), carcinogenic exposures in the workplace remain a concern. Many known and suspected carcinogens are found in today’s workplaces, and uncertainties about the health effects of exposure to these hazards have delayed regulatory action and the search for safer alternatives. In this review we focus primarily on chemicals, metals, dusts, and physical agents for which there is widespread human exposure, predominantly in occupational settings, and we address unresolved questions regarding carcinogenicity. Most of these agents are in IARC Groups 2A and 2B—agents for which there is sufficient evidence of carcinogenicity in animals but limited evidence for carcinogenicity in humans.\nA project to systematically identify data gaps was initiated by the National Occupational Research Agenda team of the U.S. National Institute for Occupational Safety and Health (NIOSH) to enhance occupational cancer research and involved joint planning with IARC, the American Cancer Society, the U.S. National Institute of Environmental Health Sciences, and the U.S. National Cancer Institute. In this review we present the results of this effort and identify opportunities for further research that would resolve classification uncertainties for selected high-priority agents. The process included a meeting to identify high-priority agents; expert reviews of each agent to update the literature since the last Monograph evaluation and to identify research priorities; and a workshop to discuss the identified data gaps and approaches. Expert reviewers were selected by the planning committee based on expertise in epidemiology and toxicology and on knowledge of the agents. For many agents, we recognized that opportunities for cohort studies would be limited, and reviewers were encouraged to consider possible experimental studies to elucidate carcinogenic mechanisms and molecular epidemiologic studies to develop intermediate biomarker data that could be used in classification.\nFull reviews and recommendations will be published in an IARC technical report. Here, we summarize recommendations for each of the agents and address some overarching topics  pertaining to several agents or categories of agents.\nOverarching Topics\nCarcinogenic mechanisms. Most tumors arise from multiple genetic and epigenetic changes, many of which are difficult to measure in vivo in experimental animals or humans. Genetic changes can be broadly defined to involve either inherited or somatic changes in the DNA sequence. Epigenetic modifications generally involve modification (e.g., by methylation or acetylation) of DNA or histones in chromatin or the binding of microRNAs (noncoding RNAs 21–23 bases) to homologous sequences in mRNA, resulting in a double-stranded structure that can decrease production of the corresponding protein ( Garzon et al. 2009 ; Mathews et al. 2009 ). Recent advances in cancer biology support the view that carcinogenic agents can act through multiple toxicity pathways and mechanisms, including both genetic and epigenetic changes. Alterations in gene expression and levels of key proteins are considered an essential component of the mechanisms by which most tumors arise ( Croce 2009 ; Jones and Baylin 2007 ). Although standard methods for detecting agents that cause mutation have been in place for decades, no standardized, validated assays are available for routine assessments for epigenetic events.\n“Omics,” the study of large sets of biological molecules, is an emerging tool to study genetic and epigenetic events related to specific exposures. Although the number of omic techniques is ever expanding, the most developed techniques are high-throughput DNA sequencing, transcriptomics (studying gene expression), epigenomics (studying epigenetic regulation of gene expression), proteomics (studying large sets of proteins; the proteome), and metabolomics (studying large sets of metabolites; the metabolome). Omic technologies can be used to study the effects of the same chemicals in experimental animals and in human cells in vitro, eventually allowing for a more comprehensive human carcinogenicity and assessment of carcinogenic mechanisms. A broad all-encompassing approach is needed that uses the same technologies in experimental animals, human cells in culture, and human populations. Eventually, a bioinformatics database of human responses to different chemical exposures and associated chronic diseases could be used to compare the effects of novel chemicals with those of established carcinogens. Given the sensitivity of omic analyses, low-dose adverse effects could also be observed and distinguished from high-dose phenomena, and if exposures were accurately assessed, dose–response data could be incorporated into risk assessments.\nOxidative stress has been invoked as a mechanism in the carcinogenicity of a number of agents, including some metals and particles. Oxidative damage to cellular DNA, the epigenome (including proteins), and lipids can occur when reactive oxygen species (ROS) escape cell antioxidant and repair mechanisms ( Mayne 2003 ; Shi et al. 2004 ; Valavanidis et al. 2009 ). Proposed carcinogenic mechanisms include direct genotoxicity as well as tumor promotion (e.g., arsenic and perhaps other metals are thought to promote tumors by causing oxidative stress that interferes with apoptosis) ( Shi et al. 2004 ). Several methodologic issues present challenges to validation of oxidative stress biomarker assays, including highly variable background levels of specific DNA lesions (e.g., between individuals and between experiments) and the need to consider biomarkers of nitration as well as oxidation ( Mayne 2003 ). Research is needed to examine the relationship between exposure to toxic agents and oxidative stress biomarkers and between these biomarkers and risk of cancer, while controlling for the many individual factors that contribute to oxidative stress. Guidelines on standardizing the collection and measurement of oxidative stress biomarkers in humans ( American Thoracic Society 1999 ; Horvath et al. 2005 ) are important to facilitate their effective use.\nImmunomodulation is also associated with cancer in humans and plays a particularly important role for some lymphomas ( Hartge et al. 2006 ) and other cancers. Although biological markers measured in blood are available to assess clinically significant immune dysfunction, identification and standardization of biomarkers of more subtle changes in immune status in humans with specific exposures is complicated by the enormous variety of markers and assays and the high level of intraindividual and interindividual variability due, in part, to the inherently dynamic role of the immune system. Several agents discussed here [e.g., polychlorinated biphenyls (PCBs)] have been associated with lymphomas, and investigation of their immunomodulatory effects may clarify their carcinogenic potential.\nAddressing the role of genetic susceptibility to carcinogenic exposures is also important; however, the stable and reproducible associations are few. Examining genetic polymorphisms related to carcinogen metabolism and/or DNA repair may facilitate identification of higher cancer risks in susceptible subgroups and clarify the role of specific agents in mixed exposures. However, the magnitude of such associations may be modest and involve multiple genes or metabolic pathways, making  them difficult to detect.\nIssues in exposure assessment. Some agents considered in this review may occur as extremely small particles with at least one dimension between 1 and 100 per unit mass than larger particles of the same composition, and the smaller particles appear to be more biologically reactive, toxic, and carcinogenic than larger-size particles. Thus, their toxic effects may need to be evaluated separately from larger particles of the same chemical composition ( Schulte et al. 2009 ). Critical exposure metrics that should be included are particle count, surface area, mass, and density. Other physical and chemical properties can influence the biological activity and toxicity of nanoparticles, including contaminants and the degree of agglomeration ( Schulte et al. 2009 ). Use of several agents we consider to be nanoparticles is increasing, including nano-titanium dioxide (TiO2), in products.\nIn occupational settings where many Group 2 carcinogens are used, levels of exposure may be relatively low and potential for multiple exposures high. High-quality exposure assessment will be required to assess quantitative exposure response for specific agents while accounting for other potentially carcinogenic exposures. Historical monitoring data, when available, may be used to create a job-exposure matrix. Biomarkers of exposure to agents with long biological half-lives, such as serum levels of PCBs ( Burns et al. 2008 ), may be useful in assessing historical exposures, whereas biomarkers of internal dose, such as hemoglobin adducts, may be useful to characterize recent exposures ( Angerer et al. 2007 ). Biomarkers of effects related to carcinogenicity, such as DNA adducts in urothelial cells ( Zhou et al. 1997 ) and chromosomal aberrations in peripheral lymphocytes ( Yong et al. 2009 ), are useful when population size, latency, and/or lack of historical data preclude study of traditional epidemiologic end points.\nStudy design. Some agents discussed here are used primarily in small businesses with high turnover, where it is difficult to assemble large study populations. Alternative approaches include use of union records, national census records, or records of individuals licensed to perform certain work (e.g., certified pesticide applicators), case–control studies with enhanced exposure assessment, and cross-sectional surveys examining intermediate markers. It may be possible to recruit participants outside of the workplace through the media and then use a validated biomarker to confirm and quantify recent exposure.\nEpidemiologic studies using death certificates may fail to identify excesses in cancer sites with high survival rates or excesses in specific morphologic types of cancer. The ability to study cancer incidence rather than mortality—linking occupational cohorts with regional or national cancer registries—would improve detection of cancers with high survival rates, the accuracy of diagnostic information, and more timely identification of carcinogenic hazards. In several Nordic countries, national cancer registries that are linked to census occupational data (and in Norway to a serum bank) have been an important resource for studies of occupational and environmental exposures. Such resources could be developed in other countries.\nInterpretation of evidence for excesses in lymphohematopoietic cancers (LHC) for several agents has been complicated by inconsistencies in specific tumor sites. These differences may result from inaccuracy of death certificate diagnosis as well as from changes in LHC classification and grouping over time. Epidemiologic and animal studies  may consider morphologically distinct hematologic cancers as separate end points, even though they may share common cellular origins. As knowledge of hematologic malignancies evolves, it is important to reexamine approaches to disease categorization in epidemiology and animal toxicology. Over time, there has been growing recognition of close relationships and overlap of such morphologically diverse disorders as chronic lymphocytic leukemia and multiple myeloma, now considered subclassifications of mature B-cell neoplasms ( Swerdlow et al. 2008 ).\nData gaps and research priorities for specific agents. The agents, exposure circumstances, and prior IARC Monograph evaluations of the agents considered are listed in the Supplemental Material (doi:10.1289/ehp.0901828).\nLead and lead compounds. Although the occurrence of lead in the environment has decreased greatly because of the elimination of most leaded gasoline, substantial occupational exposures continue primarily via lead in the battery industry and lead pigments in paints ( IARC 2006c ). Evidence for carcinogenicity in workers exposed to inorganic lead is most consistent for stomach cancer (rate ratio, 1.3–1.5), with lung, kidney, and brain cancer showing elevation in some but not all studies ( IARC 2006c ). Background rates of stomach cancer are highly variable; therefore, epidemiologic studies should consider local referent rates and internal dose–response analyses. Additional studies of new cohorts with well-documented lead exposure, as well as further follow-up of existing cohorts, would be useful. A study of the NIOSH Adult Blood Lead Exposure Surveillance (ABLES) registry—which includes 50,000 workers with at least one blood lead measurement during 1990–2007—is currently under way. Future studies could be strengthened by including a) assessment of the correlation of blood lead measurements with cumulative exposure as measured by bone lead; b) assessment of whether Helicobacter pylori infection is associated with higher blood lead levels; and c) evaluation of genetic susceptibility factors, such as polymorphisms in the δ-aminolevulinate dehydratase (ALAD) gene. Further experimental research is needed to evaluate the mechanisms by which lead may cause cancer, with particular emphasis on oxidative stress/apoptosis and the roles of cellular defense mechanisms, signaling pathways, and intracellular lead-binding patterns.\nIndium phosphide and other indium compounds. Intratracheal installation of indium phosphide causes pulmonary inflammation and high incidences of lung tumors in experimental animals ( IARC 2006b ). No epidemiologic studies have evaluated indium compounds specifically for cancer. Studies of workers in the U.S. semiconductor industry are unlikely to be informative because of limited historical exposure, multiple exposures in wafer fabrication, and little historical exposure-monitoring information. Epidemiologic studies, if feasible, may be most informative in secondary indium-refining industries (primary refining likely results in lower indium and higher cadmium exposure). Recent findings of pulmonary effects among indium workers in Asia ( Chonan et al. 2007 ; Hamaguchi et al. 2008 ) should be investigated further. Concurrent studies of exposure and biomarkers of genetic damage, such as chromosomal aberrations in accessible cells of exposed workers (e.g., nasal epithelium, buccal cells, shed urinary cells, or circulating lymphocytes), may be useful. Further experimental research should investigate mechanisms of indium compound–induced toxicity and carcinogenicity, with particular focus on oxidative stress, inhibition of protective protein synthetic mechanisms, and DNA damage.\nMetallic cobalt (with or without tungsten carbide). The evidence for carcinogenicity of cobalt with tungsten carbide in humans comes from studies finding increased lung cancer risks among workers in the hard-metal industry in France and Sweden ( IARC 2006d ). The prevalence of such exposures is increasing ( Busch et al. 2010 ). There is good experimental evidence that cobalt and cobalt with tungsten carbide produce cellular toxicity via formation of ROS, leading to oxidative stress and triggering a number of cellular regulatory pathways ( Fenoglio et al. 2008 ). Research recommendations include updating the French and Swedish studies and studying additional cohorts of hard-metal manufacturing workers; these studies should include assessment of molecular biomarkers of early cellular effects and genetic polymorphisms associated with cellular protective systems. Further research is needed into the toxicity of exposure to cobalt with tungsten carbide in the nanoparticle size range.\nWelding. Epidemiologic studies indicate a 20–40% increased risk of lung cancer among welders ( Ambroise et al. 2006 ; Siew et al. 2008 ). Experimental studies are suggestive—but not conclusive—of lung carcinogenicity of welding-fume exposure ( Antonini 2003 ; Zeidler-Erdely et al. 2008 ). Many in vitro and in vivo studies have shown welding fumes to be genotoxic ( Antonini et al. 2003 ). Pulmonary effects consistent with oxidative stress and inflammatory responses have been observed in experimental animals. Genotoxic effects observed in welders include elevated 8-hydroxydeoxyguanine in urine; DNA–protein crosslinks, sister chromatid exchanges, and increased micronuclei in lymphocytes; increased DNA strand breaks, chromosome aberrations, and increased micronuclei in buccal epithelial cells ( Antonini et al. 2003 ; Danadevi et al. 2004 ). Research needs include reexamination of existing cohorts and establishing new cohorts with improved exposure assessment (e.g., the type of welding process, the type of metal being welded, the types of rods and fluxes used, and other characteristics of the welding environment such as abrasives, cleaners, and degreasers used, and if feasible, biomarkers of exposure to manganese or iron) and improved smoking data. Experimental studies are needed on inhalation exposure to different types of welding fumes, including ultrafine/nano-size particles, and on epigenetic mechanisms, gene expression pathways, and functional level changes related to welding fume exposure ( Rim et al. 2007 ; Salnikow and Zhitkovich 2008 ). In addition, welders have an increased risk of ocular melanoma ( El Ghissassi et al. 2009 ). Further research is needed to determine whether this is due to ultraviolet radiation, other forms of electromagnetic radiation, or metal and chemical fumes emitted during welding.\nTiO2. Elevated lung tumor rates have been observed in rats after chronic inhalation or intratracheal administration of TiO2 ( Baan et al. 2006 ). A consistent dose–response relationship for either pulmonary inflammation or lung tumor response was observed for fine and ultrafine TiO2 particle sizes when dose was expressed as the particle surface area retained in rat lungs ( Dankovic et al. 2007 ). These data include doses associated with the overloading of rat lung particle clearance, which occurs at lower mass doses for ultrafine TiO2 than for fine-sized TiO2, and is related to the increased surface area of the ultrafine particles. Lung overload is associated with persistent pulmonary inflammation, ROS, cell injury and proliferation, and fibrosis in rats and mice; and with gene mutation and lung tumors in rats. Qualitatively similar lung responses, including reduced lung clearance, pulmonary inflammation, and fibrosis, have been observed in workers in dusty jobs, although elevated lung tumors have not been observed in epidemiologic studies of TiO2 workers ( Baan et al. 2006 ).\nRecent subchronic studies in rats confirm earlier findings that particle size (as well as crystal structure) and coatings can influence pulmonary responses (inflammation, cytotoxicity, and cell proliferation) to TiO2 ( Sager et al. 2008 ; Sager and Castranova 2009 ; Warheit et al. 2006 , 2007 ) and suggest that inhaled TiO2 may act through a secondary genotoxic mechanism involving chronic inflammation and oxidative stress related to particle surface area ( Schins and Knaapen 2007 ). The observation of inhaled discrete nanoscale TiO2 particles inside rat alveolar epithelial cell organelles, including the nucleus ( Geiser et al. 2005 ), suggests that direct genotoxic mechanisms are also possible ( Schins and Knaapen 2007 ). Epidemiologic studies with well-characterized exposures and adequate follow-up are needed, especially for workers producing or using nanoscale TiO2. Possible cohorts include workers in industries using nanoscale TiO2, such as the cosmetic industry. Given increasing applications of nano-TiO2 in consumer products, there is a need to develop better techniques to detect TiO2 in tissues and to examine possible carcinogenicity of nano-TiO2 by other routes of exposure (e.g., oral, dermal).\nDiesel engine exhaust. Two meta-analyses estimated the summary risk for lung cancer and diesel engine exhaust (DE) exposure to range from 1.33 [95% confidence interval (CI), 1.24–1.44] ( Bhatia et al. 1998 ) to 1.47 (95% CI, 1.29–1.67) ( Lipsett and Campleman 1999 ); only a few studies have included retrospective exposure assessment ( Garshick et al. 2008 ; Neumeyer-Gromen et al. 2009 ; Steenland et al. 1990 ). Two studies nearing completion will provide information on quantitative exposure–response data based on historical exposure estimates. These include a cohort and nested case–control study of lung cancer in U.S. nonmetal miners with a wide range of DE exposure ( National Research Council and Institute of Medicine 2008) and additional retrospective exposure assessment in a truck driver cohort with light-to-moderate DE exposure (Garshick E, personal communication). If the research demonstrates exposure response, it will be important to identify the underlying mechanisms of DE-induced carcinogenesis and identify the components of DE that are most biologically active in humans. DNA adducts formed by nitro-polycyclic aromatic hydrocarbons (PAHs) and PAHs in animal and cellular studies have been well documented. These and other biomarkers could be incorporated in cross-sectional epidemiologic studies of DE exposure and biomarkers of inflammation, genotoxicity, and other relevant early biological effects.\nRefractory ceramic fibers. Refractory ceramic fibers (RCF), which have replaced asbestos as high-temperature insulation, induce benign and malignant lung tumors in rats ( Mast et al. 1995 ). Only one small U.S. occupational cohort exposed to these biopersistent fibers has been studied; at last follow-up, there were only nine lung cancer deaths ( LeMasters et al. 2003 ). A European study found an exposure-related excess of pleural plaques after controlling for past asbestos exposure ( Cowie et al. 2001 ). Identification and follow-up of new and established U.S. and European cohorts would be useful. Animal research has not been conducted on the combined effects of RCF and granular, low-biosoluble particles such as TiO2, which can aggravate effects of inhaled fibers. The impact of fiber length on carcinogenicity should also be investigated.\nThe validity of negative dose–response data in rats after inhalation exposure to RCF is questionable because there are indications that the sensitivity of the rat inhalation model with man-made fibers is relatively low ( Muhle and Pott 2000 ; Wardenbach et al. 2005 ). Future research in developing a sensitive rat inhalation model for RCF is needed.\nCarbon black. Sorahan and Harrington (2007) reported elevated lung cancer in an update of the U.K. carbon worker cohort standardized mortality ratio, 1.46; 95% CI, 1.13–1.85), with some analyses suggesting that carbon black may be a late-stage carcinogen. No new chronic studies in animals have been published since the IARC Monograph ( Baan et al. 2006 ). Several recent subchronic studies in rats and mice ( Duffin et al. 2007 ; Sager and Castranova 2009 ; Stoeger et al. 2006 ) have shown that particle size and surface area dose of carbon black and other poorly soluble particles influence the pulmonary inflammation response, considered key in the pathway to particle-induced lung cancer in rats ( Schins and Knaapen 2007 ). Research needs include updating epidemiology cohorts with data on work histories and exposures in relation to particle size and surface area, and recruitment of additional carbon black facilities. The relationship between occupational exposure to carbon black and validated biomarkers of oxidative stress should be examined and exposure–response relationships in humans and rodents quantified, including the role of particle size.\nStyrene and styrene-7,8-oxide. In 2008, a U.S. National Toxicology Program (NTP) expert panel reviewed styrene, finding limited evidence in humans but sufficient evidence of animal carcinogenicity from multiple studies in mice by multiple routes ( Styrene Expert Panel 2008 ). Epidemiologic studies of styrene in the styrene–butadiene rubber industry have been limited by multiple exposures, a limitation partially addressed by retrospective exposure assessment ( Sathiakumar et al. 2005 ). Studies in the fiberglass boat– building industry have been limited by small size and short duration of exposure ( Ruder et al. 2004 ). Interpretation of the epidemiologic evidence is complicated by findings of higher risk in less-exposed cohorts, variation in high-LHC sites in different studies, and inconsistency in findings for pancreatic cancer. At least 70 publications released since the styrene monograph ( IARC 2002 ) explore various mechanistic aspects of potential carcinogenicity in humans and rodents. Recommendations for new research include pooled analyses of human studies on chromosome aberrations and other genotoxic effects and updating the existing epidemiologic studies with particular attention to the accurate diagnosis and classification of LHCs.\nPropylene oxide. Since the last IARC review (IARC 1994), only one epidemiologic study of U.S. propylene oxide (PO) manufacturing workers has been published ( Olsen et al. 1997 ); the authors did not find increased mortality due to cancer by duration of exposure with or without latency, nor did they find increased cancer risk by process (PO vs.  ethylene oxide). Recent exposure and biomarker studies have shown that PO forms chemically stable hemoglobin and DNA adducts and that concentrations of these adducts are related linearly to air concentrations of PO ( Boogaard et al. 1999 ); in addition, Czene et al. (2002) reported that hemoglobin and DNA adducts and sister chromatic exchanges were increased significantly in workers occupationally exposed to PO. Potential cohorts for future epidemiologic studies exist in a number of industries and countries; occupational study cohorts should include women, if possible, because PO might be a mammary carcinogen ( Rudel et al. 2007 ).\nFormaldehyde. Formaldehyde has been classified by IARC as a Group 1 carcinogen based on sufficient evidence for nasopharyngeal cancer in humans ( Baan et al. 2009 ; IARC 2006a ). Both IARC and the NTP scientific review panel have recently supported a causal relation between formaldehyde and acute myeloid leukemia based on new research findings ( Baan et al. 2009 ; Beane Freeman et al. 2009 ; Formaldehyde Expert Panel 2009 ; Zhang et al. 2009 ); however, more research is needed to elucidate the mechanism by which formaldehyde could cause myeloid leukemia in humans. Mechanisms through which inhaled formaldehyde may cause leukemia should be explored further, including exposure to circulating blood or stem cells in the nose and pathways by which inhaled formaldehyde or formaldehyde-derived intermediates can reach bone marrow or lymphatic tissue. Follow-up of existing occupational cohorts should continue, with registry linkage to identify incident cancers and attention to appropriate classification and grouping of LHCs. Additional studies of the genotoxic and hematologic effects of formaldehyde exposure in occupational cohorts and in experimental animals would be useful, and such studies should incorporate sensitive biological markers of internal dose.\nAcetaldehyde. Acetaldehyde is the first metabolite of ethanol oxidation. It binds to DNA, forming stable DNA adducts that are observed in alcohol consumers ( Seitz and Stickel 2007 ). Numerous epidemiologic studies in alcohol drinkers with alcohol dehydrogenase (ALDH2) deficiency or low aldehyde dehydrogenase (ADH1B) activity ( Lachenmeier et al. 2009 ; Salaspuro 2009 ) provide the most compelling evidence for the carcinogenicity of acetaldehyde. A recent large-scale case–control study reported a multiplicative combined risk for esophageal cancer among alcohol and tobacco consumers who were low ADH1B and ALDH2-deficient carriers (OR = 382.3; 95% CI, 47.4–3084.9 for those drinking > 30 g/day) ( Lee et al. 2008 ). These studies strongly suggest that acetaldehyde derived from the metabolism of ethanol contributes to upper digestive tract cancers. The accumulated scientific evidence warrants a new evaluation of acetaldehyde by IARC. Exposures to acetaldehyde in occupational settings should be characterized and the potential for conducting epidemiologic studies explored. These studies should consider all potential sources of exposure to acetaldehyde and the extent to which genetic polymorphisms influence carcinogenic risks. Studies in the flavoring industry may be of particular interest.\nTrichloroethylene (TCE). Since the IARC review ( IARC 1995b ), numerous publications have evaluated associations between TCE exposure in humans and cancers at several sites, including kidney and liver cancer, and non-Hodgkin lymphoma (NHL). Meta-analyses would be useful because individual studies have limited statistical power for these relatively uncommon cancer sites. Additional studies of cancer incidence and mortality in new cohorts without multiple solvent exposures (e.g., those using TCE for a final degreasing after assembly-line production of kitchen utensils) would be beneficial. Research is needed to determine which TCE metabolites are the agents of carcinogenesis for specific sites. Studies of effects of TCE exposure on cell-signaling pathways and epigenetic changes induced by TCE and its metabolites would help in determining potential mechanisms of carcinogenicity. TCE is metabolized by the cytochrome P450 (CYP) pathway to oxidative metabolites and by the glutathione (GSH) conjugation pathway to genotoxic metabolites; incorporation of data on genetic polymorphisms in glutathione S-transferase and CYP2E1 would be useful in this regard.\nTetrachloroethylene (Perc). Since the IARC review ( IARC 1995a ), several human epidemiologic studies have reported associations between Perc exposure and esophageal cancer and NHL, with some evidence for breast, urinary bladder, and kidney cancer ( Ruder 2006 ). Although many industries use Perc, the chief venue of Perc exposure is dry-cleaning shops, which generally have < 10 employees ( Gold et al. 2008 ). Further studies in this industry could be facilitated by using exhaled-breath specimens for study inclusion and exposure assessment ( McKernan et al. 2008 ). Two U.S. dry-cleaning cohorts could be pooled for mortality and cancer incidence studies ( Blair et al. 2003 ; Ruder et al. 2001 ), and additional cohorts of workers outside the United States and Europe should be identified. A major research gap is that mechanisms of carcinogenicity are not characterized sufficiently or tested; studies are needed that evaluate the genotoxic and oxidative potential of alternative metabolic pathways. Last, adequate physiologically based pharmacokinetic (PBPK) models should be developed that allow for prediction of metabolism and difference in metabolism between species for a number of key metabolites to aid in the identification of sensitive subpopulations and target organs for a carcinogenic response.\nMethylene chloride [dichloromethane (DCM)]. Inhalation exposure to DCM causes lung and liver tumors in mice and mammary tumors in rats ( IARC 1999b ). Epidemiologic case–control and cohort studies have found positive, but inconsistent, associations for cancers of a number of sites. Based on animal and epidemiologic studies to date, sites of particular interest for future studies include brain, breast, and the lymphohematopoietic system. Available epidemiologic studies of DCM are limited by small numbers of exposed cases, few women enrolled, and poor exposure assessments. The major research need is the identification of new large cohorts with adequate numbers of women and robust exposure assessment using current and retrospective department-specific exposure or biological markers. In addition to identifying larger cohorts of film and textile workers, some potential new occupations include workers in furniture stripping or automobile body repair shops. Urinary DCM has been shown to correlate with air measurements ( Imbriani and Ghittori 2005 ), and studies are needed to develop and evaluate urinary DCM measurements for use in exposure assessment. Recent mechanistic studies have questioned the role of the GSH pathway in toxicity ( Landi et al. 2003 ; Watanabe and Guengerich 2006 ; Watanabe et al. 2007 ). DCM has been reported to be mutagenic in bacteria without activation ( IARC 1999b ). Clearly, research is needed with regard to the metabolites involved and the mechanism of carcinogenicity of DCM-induced rodent tumors, especially in the context of informing human risk. Before accurate PBPK models can be developed, the metabolism and metabolites responsible for toxicity at specific targets should be investigated.\nChloroform (trichloromethane). Chloroform causes cancer in rats and mice, most likely through a mechanism involving cytotoxicity ( Schoeny et al. 2006 ), and there is weak evidence for the genotoxicity of chloroform ( IARC 1999a ). Exposure to chloroform is primarily through drinking water and swimming pool water; thus, the epidemiology is based on exposure to this complex mixture and not to chloroform per se. Since the last IARC evaluation ( IARC 1999a ), several epidemiologic studies have been published on the association between exposure to chloroform in disinfection by-products (DBPs) and risk of bladder cancer, including a pooled analysis of previous case–control studies ( Villanueva et al. 2004 ) and a new case–control study from Spain ( Villanueva et al. 2007 ). However, drinking water with high levels of chloroform also contains high levels of other trihalomethanes (THMs) and other DBPs, and bladder cancer associated with drinking water may result from dermal/inhalation exposure to the brominated THMs or DBPs other than chloroform. Future IARC evaluations should address the entire group of DBPs in drinking water. Exposures to chloroform and other DBPs may be higher from showering, bathing, or swimming than from oral exposure to drinking water. Other THMs/DBPs should be evaluated for biological effects in rodents via the dermal and/or inhalation route. Epidemiologic case–control studies should incorporate information on route of exposure and detailed DBP exposure assessment, as well as pooling information from multiple studies and countries, where feasible. Epidemiologic studies are warranted for high-exposure groups such as competitive swimmers and indoor pool attendants/lifeguards. There should also be follow-up of cohorts of medical personnel exposed to chloroform when chloroform was used as an anesthetic gas.\nPCBs. Identifying research gaps for PCBs is considerably more difficult, because a large volume of epidemiologic and mechanistic data has been published since the last IARC evaluation ( IARC 1987 ). Moreover, mixtures of PCBs associated with occupational and environmental exposure have changed over time and vary across the occupational and population groups studied. In addition, environmental and metabolic processes substantially alter the composition of PCB mixtures in the environment and in the body. As a result, residual PCBs in the environment involve altered mixtures differing in composition—and possibly more toxic and persistent—than the mixtures that were used commercially ( Cogliano 1998 ). Among most occupational cohorts, dermal and airborne exposures predominate, whereas among the general population, dietary exposures are generally most significant. Although most studies of highly exposed occupational cohorts find cancer excesses for specific cancer sites, the sites involved have been quite variable. Associations between NHL and levels of certain PCB congeners in serum have been reported in several cohort and case–control studies ( Engel et al. 2007 ; Rothman et al. 1997 ), whereas studies of serum levels of PCBs and breast cancer have been inconsistent, although largely negative ( Ward et al. 2000 ). Additional studies within highly exposed populations, including an in-progress cancer incidence study within the large (> 26,000 workers) NIOSH cohort ( Prince et al. 2006 ; Ruder et al. 2006 ), nested case–control studies in this cohort and/or occupational cohorts in other countries, and analysis of PCB blood levels in cases and controls, might be informative. Mechanisms of genotoxicity/carcinogenicity for PCBs appear to involve ROS, oxidative stress, oxidative DNA damage, and formation of DNA adducts ( Jeong et al. 2008 ; Ludewig et al. 2008 ). More research is needed on these mechanisms and on cell proliferation, which could also play an important role in the induction of mutations and subsequent carcinogenicity.\nDi(2-ethylhexyl) phthalate (DEHP). Although extensive human exposure to DEHP occurs through its use as a plasticizer of polyvinyl chloride (PVC), definitive epidemiologic studies are not available because of the difficulty in identifying highly exposed workers in retrospective cohort or case–control studies. Since the previous monograph review, which concluded that liver cancer in animals resulted from induction of peroxisome proliferator-activated receptor-α (PPARα) and that peroxisome proliferation activation was not relevant to humans (IARC 2000), several lines of evidence have suggested that DEHP may have multiple mechanisms of carcinogenesis, such as induction of cell proliferation, decreased apoptosis, and oxidative DNA damage, some of which might be relevant to humans ( Rusyn et al. 2006 ). The hypothesized PPARα mode of action has also been questioned ( Guyton et al. 2009 ). A study of DEHP-induced tumorigenesis in wild-type and PPARα-null mice found that the incidence of liver tumor in PPARα-null mice exposed to 0.05% DEHP was higher (25.8%) than that in similarly exposed wild-type mice (10.0%) ( Ito et al. 2007 ). Microarray profile studies found that patterns of up- or down-regulated genes are quite different in hepatocellular adenoma tissues of wild-type and PPARα-null mice exposed to DEHP ( Takashima et al. 2008 ). Animal studies have also suggested additional target organs in rats [pancreatic acinar-cell adenoma ( David et al. 2000 ) and testicular Leydig cell tumors ( Voss et al. 2005 )]. Future studies in mouse models using hPPARαTetOff (which expresses the human receptor only in liver) or hPPARαPAC (which expresses the human receptor in liver, kidney, heart, intestine, and brown adipose tissues) may elucidate the role of human PPARα in DEHP carcinogenesis. Further characterization of DEHP exposures in industry is needed and could be carried out in established cohorts in PVC-processing factories using mono-2-ethylhexyl phthalate and mono(2-ethyl-5-carboxypentyl) phthalate as sensitive and specific biomarkers of DEHP exposure.\nAtrazine. Schoeny et al. (2006) reported that atrazine caused mammary gland tumors in Sprague-Dawley rats through accelerated aging within the brain–pituitary–ovarian axis (i.e., constant estrus); however, they found that it was not carcinogenic in F344 rats or via the diet in CD-1 mice, but it did cause lymphomas via intraperitoneal injection in CD-1 mice. Although the mechanism by which atrazine causes mammary tumors in Sprague-Dawley rats may not be relevant to humans ( Schoeny et al. 2006 ), additional studies would help to clarify the situation. For example, does atrazine interfere with the hypothalamic–pituitary–ovarian axis or alter the secretion of luteinizing hormone and prolactin in humans? More extensive microarray and proteomic studies in rodents and humans would help to characterize the pathways disrupted by atrazine. Studies should also investigate the ability of atrazine to alter immune function and aromatase in species relevant to humans, as well as in human molecular epidemiology studies. Several studies have found nonsignificant associations between atrazine exposure and NHL; for example, a study of 36,513 atrazine-exposed pesticide applicators in the U.S. Agricultural Health Study (AHS) demonstrated nonsignificant excesses of lung cancer, bladder cancer, NHL, and multiple myeloma ( Rusiecki et al. 2004 ). Follow-up of the AHS cohort through 2006 is now under way and, along with analysis of biomarkers among corn farmers and similar studies in atrazine-exposed women ( Bakke et al. 2008 ; Vermeulen et al. 2005 ), could shed light on the effects of atrazine.\nShift work. Excess incidence of breast cancer has been observed consistently in studies of women with prolonged exposure to shift work involving exposure to light at night ( Kolstad 2008 ; Stevens 2009 ). Research needs in this area include a) a better definition of what is meant by shift work and related exposure metrics; b) studies of markers of circadian disruption in non–day workers; c) better descriptions of controls and their exposure to light at night; and d) investigation of the effect of variations in expression of circadian genes on cancer in shift workers. An emerging area of interest is the relative toxicity of occupational chemical exposure depending on time of day of that exposure. The marked circadian variations in cell division and DNA repair during the daily cycle are controlled by the circadian genes ( Haus and Smolensky 2006 ; Stevens et al. 2007 ). Therefore, non–day workers may have very different susceptibility to occupational exposures compared with day workers. Studies are also needed to determine if shift work is associated with other cancers, especially hormonally related cancers, and prostate cancer in particular. If further experimental and epidemiologic evidence confirms a causal association between exposure to light at night and breast cancer, it will be important to develop interventions to reduce the risk.\nConclusions\nResearch gaps and opportunities have been identified that can help to resolve uncertainties regarding the carcinogenicity in humans of a number of important IARC-classified agents. We hope that this process will lead to well-planned epidemiologic and mechanistic studies for these agents, as well as renewed interest and funding for studies of agents for which there are substantial or widespread occupational and environmental exposures.\nSeveral important scientific developments are likely to increase the challenges and complexities of carcinogen testing and evaluation in the future. Use of omics techniques will accelerate the understanding of the cellular and molecular basis for biological responses to environmental and occupational exposures, and high-throughput technologies will increase the number of agents that can be tested. The important role of organ and organism-level responses such as inflammation, immunomodulation, and hormonal influences, as well as interindividual variation in susceptibility and genetic repair in the carcinogenic process, are increasingly understood. Therefore, the science of carcinogen testing and evaluation must be increasingly multidisciplinary, examining biologic responses from the molecular to the organism, and using test systems and approaches that capture multiple mechanisms and end points.\nMost carcinogenic mechanisms are not simple, and evidence is often too limited to conclude lack of relevance to humans. When evidence regarding mechanism is considered in the upgrading or downgrading of carcinogens, it should be evaluated with the same rigor as traditional epidemiologic and bioassay data [see, for example, the IARC preamble (IARC 2006e) with regard to epidemiologic studies, including types of studies to be considered, quality of studies, role of meta- and pooled analyses, and criteria for causality]. Epidemiologic studies will be particularly critical in evaluating the relationship between intermediate biomarkers and cancer risk in occupational groups or in the general population and in investigating genetic susceptibility factors. In the rush to embrace new biotechnologies in epidemiology, we must not lose sight of the tremendous gains in knowledge that have accrued from conventional epidemiologic occupational cohort and case–control studies. We encourage investigators to continue to search for study populations in which the linkage of work history information and mortality or cancer incidence data can be informative about the cancer risks of workers with different job or industry titles or different exposure histories. We also encourage release (in deidentified form) of completed epidemiologic studies for reanalysis, as is commonly done with government-funded studies in the United States.\nIn this review we discuss only a small fraction of potentially carcinogenic agents—generally those for which there is substantial evidence for animal carcinogenicity but as yet inconclusive evidence of human carcinogenicity. For most other agents, there exists little or no evidence by which to evaluate  animal or human carcinogenicity because  neither adequately designed animal bioassays nor human studies have been done. However, even the modest research agenda outlined here will be difficult to achieve given current trends. Although objective evaluation of trends in research funding and productivity related to environmental/occupational risk factors for cancer is difficult, there is a general sense that funding for occupational cancer research has declined over the past two decades and that fewer and fewer epidemiologists, exposure assessment experts, and toxicologists are attracted to careers in this area. A more formal evaluation of these trends could consider what measures could encourage a) renewed interest in this field; b) training, career, and funding opportunities; and c) advances in addressing legal–ethical barriers to accessing worksites, study populations, and personal/medical data. If measures are not taken to stem declines in this area of research, we will continue to have an extremely limited epidemiologic knowledge base for the evaluation of potential carcinogens.\nAttached Files\nSupplemental Material (108 KB) PDF\nReferences\nAmbroise D, Wild P, Moulin JJ. 2006. Update of a meta-analysis on lung cancer and welding. Scand J Work Environ Health 32:22–31.\nAmerican Thoracic Society. 1999. Recommendations for standardized procedures for the online and offline measurement of exhaled lower respiratory nitric oxide and nasal nitric oxide in adults and children—1999. Am J Respir Crit Care Med 160:2104–2117.\nAngerer J, Ewers U, Wilhelm M. 2007. Human biomonitoring: state of the art. Int J Hyg Environ Health 210(3–4):201–208.\nAntonini JM. 2003. Health effects of welding. Crit Rev Toxicol 33:61–103.\nAntonini J, Taylor M, Zimmer A, Roberts J. 2003. Pulmonary responses to welding fumes: role of metal constituents. J Toxicol Environ Health Part A 67:233–249.\nBaan R, Grosse Y, Straif K, Secretan B, El Ghissassi F, Bouvard V, et al. 2009. A review of human carcinogens—part F: chemical agents and related occupations. Lancet Oncol 10:1143–1144.\nBaan R, Straif K, Grosse Y, Secretan B, El Ghissassi F, Cogliano V. 2006. Carcinogenicity of carbon black, titanium dioxide and talc. Lancet Oncol 7:295–296.\nBakke B, De Roos AJ, Barr DB, Stewart PA, Blair A, Beane Freeman LB, et al. 2008. Exposure to atrazine and selected non-persistent pesticides among corn farmers during a growing season. J Expo Sci Environ Epidemiol 19:544–554.\nBeane Freeman LE, Blair A, Lubin JH, Stewart PA, Hayes RB, Hoover RN, et al. 2009. Mortality from lymphohematopoietic malignancies among workers in formaldehyde industries: the National Cancer Institute Cohort. J Natl Cancer Inst 101:751–761.\nBhatia R, Lopipero P, Smith AH. 1998. Diesel exhaust exposure and lung cancer. Epidemiology 9:84–91.\nBlair A, Petralia SA, Stewart PA. 2003. Extended mortality follow-up of a cohort of dry cleaners. Ann Epidemiol 13:50–56.\nBoogaard PJ, Rocchi PS, van Sittert NJ. 1999. Biomonitoring of exposure to ethylene oxide and propylene oxide by determination of hemoglobin adducts: correlations between airborne exposure and adduct levels. Int Arch Occup Environ Health 72:142–150.\nBurns CJ, Collins JJ, Budinsky RA, Bodner K, Wilken M, Craig Rowlands J, et al. 2008. Factors related to dioxin and furan body levels among Michigan workers. Environ Res 106(2):250–256.\nBusch W, Kühnel D, Schirmer K, Scholz S. 2010. Tungsten carbide cobalt nanoparticles exert hypoxia-like effects on the gene expression level in human keratinocytes. BMC Genomics 11:65; doi: 10.1186/1471-2164-11-65 .\nChonan T, Taguchi O, Omae K. 2007. Interstitial pulmonary diseases in indium processing workers. Eur Respir J 29:317–324.\nCogliano VJ. 1998. Assessing the cancer risk from environmental PCBs. Environ Health Perspect 106:317–323.\nCowie HA, Wild P, Beck J, Auburtin G, Piekarski C, Massin N, et al. 2001. An epidemiological study of the respiratory health of workers in the European refractory ceramic fibre industry. Occup Environ Med 58:800–810.\nCroce CM. 2009. Causes and consequences of microRNA dysregulation in cancer. Nat Rev Genet 10:704–714.\nCzene K, Osterman-Golkar S, Yun X, Li G, Zhao F, Pérez HL, et al. 2002. Analysis of DNA and hemoglobin adducts and sister chromatid exchanges in a human population occupationally exposed to propylene oxide: a pilot study. Cancer Epidemiol Biomarkers Prev 11:315–318.\nDanadevi K, Rozati R, Banu BS, Grover P. 2004. Genotoxic evaluation of welders occupationally exposed to chromium and nickel using the Comet and micronucleus assays. Mutagenesis 19:35–41.\nDankovic D, Kuempel E, Wheeler M. 2007. An approach to risk assessment for TiO2. Inhal Toxicol 19:205–212.\nDavid RM, Moore MR, Finney DC, Guest D. 2000. Chronic toxicity of di(2-ethylhexyl)phthalate in rats. Toxicol Sci 55:433–443.\nDuffin R, Tran L, Brown D, Stone V, Donaldson K.. 2007. Proinflammogenic effects of low-toxicity and metal nanoparticles in vivo and in vitro: highlighting the role of particle surface area and surface reactivity. Inhal Toxicol 19:849–856.\nEl Ghissassi F, Baan R, Straif K, Grosse Y, Secretan B, Bouvard V, et al. 2009. A review of human carcinogens—part D: radiation. Lancet Oncol 10:751–752.\nEngel LS, Laden F, Andersen A, Strickland PT, Blair A, Needham LL, et al. 2007. Polychlorinated biphenyl levels in peripheral blood and non-Hodgkin’s lymphoma: a report from three cohorts. Cancer Res 67:5545–5552.\nFenoglio I, Corazzari I, Francia C, Bodoardo S, Fubini B. 2008. The oxidation of glutathione by cobalt/tungsten carbide contributes to hard metal-induced oxidative stress. Free Radic Res 42:437–445.\nFormaldehyde Expert Panel. 2009. Formaldehyde Expert Panel Report. Part B – Recommendation for Listing Status for Formaldehyde and Scientific Justification for the Recommendation. National Toxicology Program. Available: http://ntp.niehs.nih.gov/ntp/roc/twelfth​/2009/November/FA_PartB.pdf [accessed 17 August 2010].\nGarshick E, Laden F, Hart JE, Rosner B, Davis ME, Eisen EA, et al. 2008. Lung cancer and vehicle exhaust in trucking industry workers. Environ Health Perspect 116:1327–1332.\nGarzon R, Calin GA, Croce CM. 2009. MicroRNAs in cancer. Annu Rev Med 60:167–179.\nGeiser M, Rothen-Rutishauser B, Kapp N, Schurch S, Kreyling W, Schulz H, et al. 2005. Ultrafine particles cross cellular membranes by nonphagocytic mechanisms in lungs and in cultured cells. Environ Health Perspect 113:1555–1560.\nGold LS, De Roos AJ, Waters M, Stewart P. 2008. Systematic literature review of uses and levels of occupational exposure to tetrachloroethylene. J Occup Environ Hyg 5:807–839.\nGuyton KZ, Chiu WA, Bateson TF, Jinot J, Scott CS, Brown RC, et al. 2009. A reexamination of the PPAR-α activation mode of action as a basis for assessing human cancer risks of environmental contaminants. Environ Health Perspect 117:1664–1672.\nHamaguchi T, Omae K, Takebayashi T, Kikuchi Y, Yoshioka N, Nishiwaki Y, et al. 2008. Exposure to hardly soluble indium compounds in ITO production and recycling plants is a new risk for interstitial lung damage. Occup Environ Med 65:51–55.\nHartge P, Wang SS, Bracci PM, Devesa SS, Holly EA. 2006. Non-Hodgkin lymphoma. In: Cancer Epidemiology and Prevention (Schottenfeld D, Fraumeni JF Jr, eds). 3rd ed. New York:Oxford University Press, 898–918.\nHaus E, Smolensky M. 2006. Biological clocks and shift work: circadian dysregulation and potential long-term effects. Cancer Causes Control 17:489–500.\nHorvath I, Hunt J, Barnes PF, ATS/ERS Task Force on Exhaled Breath Condensate. 2005. Exhaled breath condensate: methodological recommendations and unresolved questions. Eur Respir J 26:523–548.\nIARC (International Agency for Research on Cancer). 1987. Overall evaluations of carcinogenicity: an updating of IARC monographs volumes 1 to 42. IARC Monogr Eval Carcinog Risks Hum 7: suppl1–440.\nIARC (International Agency for Research on Cancer). 1994. Propylene oxide. IARC Monogr Eval Carcinog Risks Hum 60:181–232.\nIARC (International Agency for Research on Cancer). 1995. Tetrachloroethylene. IARC Monogr Eval Carcinog Risks Hum 63:159–221.\nIARC (International Agency for Research on Cancer). 1995. Trichloroethylene. IARC Monogr Eval Carcinog Risks Hum 63:75–158.\nIARC (International Agency for Research on Cancer). 1999. Chloroform. IARC Monogr Eval Carcinog Risks Hum 73:131–182.\nIARC (International Agency for Research on Cancer). 1999. Dichloromethane. IARC Monogr Eval Carcinog Risks Hum 71:251–315.\nIARC (International Agency for Research on Cancer). 2000. Di(2-ethylhexyl) phthalate. IARC Monogr Eval Carcinog Risks Hum 77:41–148.\nIARC. 2002. Styrene. IARC Monogr Eval Carcinog Risks Hum 82:437–550.\nIARC (International Agency for Research on Cancer). 2006. Formaldehyde. IARC Monogr Eval Carcinog Risks Hum 88:39–325.\nIARC (International Agency for Research on Cancer). 2006. Indium phosphide. IARC Monogr Eval Carcinog Risks Hum 86:197–224.\nIARC (International Agency for Research on Cancer). 2006. Inorganic and organic lead compounds. IARC Monogr Eval Carcinog Risks Hum 87:1–471.\nIARC (International Agency for Research on Cancer). 2006. Metallic cobalt particles (with or without tungsten carbide). IARC Monogr Eval Carcinog Risks Hum 86:39–155.\nIARC (International Agency for Research on Cancer). 2006e. Preamble to the IARC Monographs (amended January 2006). Available: http://monographs.iarc.fr/ENG/Preamble/i​ndex.php [accessed 31 March 2010].\nImbriani M, Ghittori S.. 2005. Gases and organic solvents in urine as biomarkers of occupational exposure: a review. Int Arch Occup Environ Health 78:1–19.\nIto Y, Yamanoshita O, Kurata Y, Kamijima M, Aoyama T, Nakajima T. 2007. Induction of peroxisome proliferator-activated receptor alpha (PPARalpha)-related enzymes by di(2-ethylhexyl) phthalate (DEHP) treatment in mice and rats, but not marmosets. Arch Toxicol 81:219–226.\nJeong YC, Walker NJ, Burgin DE, Kissling G, Gupta M, Kupper L, et al. 2008. Accumulation of M1dG DNA adducts after chronic exposure to PCBs, but not from acute exposure to polychlorinated aromatic hydrocarbons. Free Radic Biol Med 45:585–591.\nJones PA, Baylin SB. 2007. The epigenomics of cancer. Cell 128:683–692.\nKolstad HA. 2008. Nightshift work and risk of breast cancer and other cancers—a critical review of the epidemiologic evidence. Scand J Work Environ Health 34:5–22.\nLachenmeier DW, Kanteres F, Rehm J. 2009. Carcinogenicity of acetaldehyde in alcoholic beverages: risk assessment outside ethanol metabolism. Addiction 104:533–550.\nLandi S, Naccarati A, Ross MK, Hanley NM, Dailey L, Devlin RB, et al. 2003. Induction of DNA strand breaks by trihalomethanes in primary human lung epithelial cells. Mutat Res 538:41–50.\nLee CH, Lee JM, Wu DC, Goan YG, Chou SH, Wu IC, et al. 2008. Carcinogenetic impact of ADH1B and ALDH2 genes on squamous cell carcinoma risk of the esophagus with regard to the consumption of alcohol, tobacco and betel quid. Int J Cancer 122:1347–1356.\nLeMasters GK, Lockey JE, Yiin JH, Hilbert TJ, Levin LS, Rice CH. 2003. Mortality of workers occupationally exposed to refractory ceramic fibers. J Occup Environ Med 45:440–450.\nLipsett M, Campleman S. 1999. Occupational exposure to diesel exhaust and lung cancer: a meta-analysis. Am J Public Health 89:1009–1017.\nLudewig G, Lehmann L, Esch H, Robertson LW. 2008. Metabolic activation of PCBs to carcinogens in vivo—a review. Environ Toxicol Pharmacol 25:241–246.\nMast RW, McConnell EE, Hesterberg TW, Chevalier J, Kotin P, Thevenaz P, et al. 1995. Multiple-dose chronic inhalation toxicity study of size-separated kaolin refractory ceramic fiber in male Fischer 244 rats. Inhal Toxicol 7:469–502.\nMathews LA, Crea F, Farrar WL. 2009. Epigenetic gene regulation in stem cells and correlation to cancer. Differentiation 78:1–17.\nMayne ST. 2003. Antioxidant nutrients and chronic disease: use of biomarkers of exposure and oxidative stress in epidemiologic research. J Nutr 133:933S–940S.\nMcKernan LT, Ruder AM, Petersen MR, Hein MJ, Forrester CL, Sanderson WT, et al. 2008. Biological exposure assessment to tetrachloroethylene for workers in the dry cleaning industry. Environ Health 7:12.; doi: 10.1186/1476-069X-7-12\nMuhle H, Pott F. 2000. Asbestos as reference material for fibre-induced cancer. Int Arch Occup Environ Health 73:S53–S59.\nNational Research Council and Institute of Medicine. 2008. Respiratory Disease Research at NIOSH: Reviews of Research Programs of the National Institute for Occupational Safety and Health. Washington, DC:National Academies Press.\nNeumeyer-Gromen A, Razum O, Kersten N, Seidler A, Zeeb H. 2009. Diesel motor emissions and lung cancer mortality—results of the second follow-up of a cohort study in potash miners. Int J Cancer 124:1900–1906.\nOlsen GW, Lacy SE, Bodner KM, Chau M, Arceneaux TG, Cartmill JB, et al. 1997. Mortality from pancreatic and lymphopoietic cancer among workers in ethylene and propylene chlorohydrin production. Occup Environ Med 54:592–598.\nPrince MM, Ruder AM, Hein MJ, Waters MA, Whelan EA, Nilsen N, et al. 2006. Mortality and exposure response among 14,458 electrical capacitor manufacturing workers exposed to polychlorinated biphenyls (PCBs). Environ Health Perspect 114:1508–1514.\nRim KT, Park KK, Kim YH, Lee YH, Han JH, Chung YH, et al. 2007. Gene-expression profiling of human mononuclear cells from welders using cDNA microarray. J Toxicol Environ Health A 70:1264–1277.\nRothman N, Cantor KP, Blair A, Bush D, Brock JW, Helzlsouer K, et al. 1997. A nested case-control study of non-Hodgkin lymphoma and serum organochlorine residues. Lancet 350:240–244.\nRudel RA, Attfield KR, Schifano JN, Brody JG. 2007. Chemicals causing mammary gland tumors in animals signal new directions for epidemiology, chemicals testing, and risk assessment for breast cancer prevention. Cancer 109(suppl 1):22635–2666.\nRuder AM. 2006. Potential health effects of occupational chlorinated solvent exposure. Ann N Y Acad Sci 1076:207–227.\nRuder AM, Hein MJ, Nilsen N, Waters MA, Laber P, Davis-King K, et al. 2006. Mortality among workers exposed to polychlorinated biphenyls (PCBs) in an electrical capacitor manufacturing plant in Indiana: an update. Environ Health Perspect 114:18–23.\nRuder AM, Ward EM, Brown DP. 2001. Mortality in dry-cleaning workers: an update. Am J Ind Med 39:121–132.\nRuder AM, Ward EM, Dong M, Okun AH, Davis-King K. 2004. Mortality patterns among workers exposed to styrene in the reinforced plastic boatbuilding industry: an update. Am J Ind Med 45:165–176.\nRusiecki JA, De Roos A, Lee WJ, Dosemeci M, Lubin JH, Hoppin JA, et al. 2004. Cancer incidence among pesticide applicators exposed to atrazine in the Agricultural Health Study. J Natl Cancer Inst 96:1375–1382.\nRusyn I, Peters JM, Cunningham JL. 2006. Modes of action and species-specific effects of di-(2-ethylhexyl)phthalate in the liver. Crit Rev Toxicol 36:459–479.\nSager TM, Castranova V. 2009. Surface area of particle administered versus mass in determining the pulmonary toxicity of ultrafine and fine carbon black: comparison to ultrafine titanium dioxide. Part Fibre Toxicol 6:15; doi: 10.1186/1743-8977-6-15 .\nSager TM, Kommineni C, Castranova V. 2008. Pulmonary response to intratracheal instillation of ultrafine versus fine titanium dioxide: role of particle surface area. Part Fibre Toxicol 5:17; doi: 10.1186/1743-8977-5-17 .\nSalaspuro M. 2009. Acetaldehyde as a common denominator and cumulative carcinogen in digestive tract cancers. Scand J Gastroenterol 24:1–15.\nSalnikow K, Zhitkovich A. 2008. Genetic and epigenetic mechanisms in metal carcinogenesis and cocarcinogenesis: nickel, arsenic, and chromium. Chem Res Toxicol 21:28–44.\nSathiakumar N, Graff J, Macaluso M, Maldonado G, Matthews R, Delzell E. 2005. An updated study of mortality among North American synthetic rubber industry workers. Occup Environ Med 62:822–829.\nSchins RP, Knaapen AM. 2007. Genotoxicity of poorly soluble particles. Inhal Toxicol 19:189–198.\nSchoeny R, Haber L, Dourson M. 2006. Data considerations for regulation of water contaminants. Toxicology 221:217–224.\nSchulte PA, Schubauer-Berigan MK, Mayweather C, Geraci CL, Zumwalde R, McKernan JL. 2009. Issues in the development of epidemiologic studies of workers exposed to engineered nanoparticles. J Occup Environ Med 51:323–335.\nSeitz HK, Stickel F. 2007. Molecular mechanisms of alcohol-mediated carcinogenesis. Nat Rev Cancer 7:599–612.\nShi H, Hudson LG, Liu KJ. 2004. Oxidative stress and apoptosis in metal ion-induced carcinogenesis. Free Radic Biol Med 37:582–593.\nSiew SS, Kauppinen T, Kyyrönen P, Heikkilä P, Pukkala E. 2008. Exposure to iron and welding fumes and the risk of lung cancer. Scand J Work Environ Health 34:444–450.\nSorahan T, Harrington JM. 2007. A “lugged” analysis of lung cancer risks in UK carbon black production workers, 1951–2004. Am J Ind Med 50:555–564.\nSteenland NK, Silverman DT, Hornung RW. 1990. Case-control study of lung cancer and truck driving in the Teamsters Union. Am J Public Health 80:670–674.\nStevens RG. 2009. Light at night, circadian disruption, and breast cancer: assessment of existing evidence. Int J Epidemiol 38:963–970.\nStevens RG, Blask DE, Brainard GC, Hansen J, Lockley SW, Provencio I, et al. 2007. Meeting report: the role of environmental lighting and circadian disruption in cancer and other diseases. Environ Health Perspect 115:1357–1362.\nStoeger T, Reinhard C, Takenaka S, Schroeppel A, Karg E, Ritter B, et al. 2006. Instillation of six different ultrafine carbon particles indicates a surface area threshold dose for acute lung inflammation in mice. Environ Health Perspect 114:328–333.\nStyrene Expert Panel. 2008. Part B – Recommendation for Listing Status for “Styrene” in the Report on Carcinogens and Scientific Justification for the Recommendation. Available: http://ntp.niehs.nih.gov/files/Styrene_P​anel_report_B_final_Rdtd.pdf [accessed 17 August 2010].\nSwerdlow SH, Campo E, Harris NL, Jaffe ES, Pileri SA, Stein H, et al., eds. 2008. WHO Classification of Tumours of Haematopoietic and Lymphoid Tissues. 4th ed. Lyon:International Agency for Research on Cancer.\nTakashima K, Ito Y, Gonzalez FJ, Nakajima T. 2008. Different mechanisms of DEHP-induced hepatocellular adenoma tumorigenesis in wild-type and Pparα-null mice. J Occup Health 50:169–180.\nValavanidis A, Vlaahogianni T, Fiotakis C. 2009. 8-Hydroxy-2’-deoxyguanosine (8-OhdG): a critical biomarker of oxidative stress and carcinogenesis. J Environ Sci Health C 27:120–139.\nVermeulen R, De Roos AJ, Bakke B, Blair A, Hildesheim A, Pinto L, et al. 2005. A study on immunological responses to exposures encountered in corn farming. J Biochem Mol Toxicol 19:172.\nVillanueva CM, Cantor KP, Cordier S, Jaakkola JJ, King WD, Lynch CF, et al. 2004. Disinfection byproducts and bladder cancer. Epidemiology 15:357–367.\nVillanueva CM, Cantor KP, Grimalt JO, Malats N, Silverman D, Tardon A, et al. 2007. Bladder cancer and exposure to water disinfection by-products through ingestion, bathing, showering, and swimming in pools. Am J Epidemiol 165:148–156.\nVoss C, Zerban H, Bannasch P, Berger MR. 2005. Lifelong exposure to di-(2-ethylhexyl)-phthalate induces tumors in liver and testes of Sprague-Dawley rats. Toxicology 206:359–371.\nWard EM, Schulte P, Grajewski B, Andersen A, Patterson DG Jr, Turner W, et al. 2000. Serum organochlorine levels and breast cancer: a nested case-control study of Norwegian women. Cancer Epidemiol Biomarkers Prev 9:1357–1367.\nWardenbach P, Rödelsperger K, Roller M, Muhle H. 2005. Classification of man-made vitreous fibres: comments on the revaluation by an IARC working group. Regul Toxicol Pharmacol 43:181–193.\nWarheit DB, Webb TR, Reed KL. 2006. Pulmonary toxicity screening studies in male rats with TiO2 particulates substantially encapsulated with pyrogenically deposited amorphous silica. Part Fibre Toxicol 3:3.\nWarheit DB, Webb TR, Reed KL, Frerichs S, Sayes CM. 2007. Pulmonary toxicity study in rats with three forms of ultrafine-TiO2 particles: differential responses related to surface properties. Toxicology 230:90–104.\nWatanabe K, Guengerich FP. 2006. Limited reactivity of formyl chloride with glutathione and relevance to metabolism and toxicity of dichloromethane. Chem Res Toxicol 19:1091–1096.\nWatanabe K, Liberman RG, Skipper PL, Tannenbaum SR, Guengerich FP. 2007. Analysis of DNA adducts formed in vivo in rats and mice from 1,2-dibromoethane, 1,2-dichloroethane, dibromomethane, and dichloromethane using HPLC/accelerator mass spectrometry and relevance to risk estimates. Chem Res Toxicol 20:1594–1600.\nYong LC, Sigurdson AJ, Ward EM, Waters MA, Petersen MR, Bhatti P, et al. 2009. Increased frequency of chromosome translocations in airline pilots with long-term flying experience. Occup Environ Med 66(1):56–62.\nZeidler-Erdely PC, Kashon ML, Battelli LA, Young SH, Erdely A, Roberts RA, et al. 2008. Pulmonary inflammation and tumor induction in lung tumor susceptible A/J and resistant C57BL/6J mice exposed to welding fume. Part Fibre Toxicol 5:12; doi: 10.1186/1743-8977-5-12 .\nZhang L, Steinmaus C, Eastmond DA, Xin XK, Smith MT. 2009. Formaldehyde exposure and leukemia: a new meta-analysis and potential mechanisms. Mutat Res 681:150–168.\nZhou Q, Talaska G, Jaeger M, Bhatnagar VK, Hayes RB, Zenzer TV, et al. 1997. Benzidine-DNA adduct levels in human peripheral white blood cells significantly correlate with levels in exfoliated urothelial cells. Mutat Res 393:199–205.\nHighlighted Sections\n""","0.06964046","""https://ehp.niehs.nih.gov/0901828/""","[-0.178219,51.500505]"
"""Imperial_College_London""","""Properties and Origins of the Anisotropic Eddy-Induced Transport in the North Atlantic: Journal of Physical Oceanography: Vol 45, No 3""","""Properties and Origins of the Anisotropic Eddy-Induced Transport in the North Atlantic\nProperties and Origins of the Anisotropic Eddy-Induced Transport in the North Atlantic\nAuthors:\nFinal Form: 10 December 2014\nPublished Online: 13 March 2015\nAbstract\nSection:\nThis study examines anisotropic transport properties of the eddying North Atlantic flow, using an idealized model of the double-gyre oceanic circulation and altimetry-derived velocities. The material transport by the time-dependent flow (quantified by the eddy diffusivity tensor) varies geographically and is anisotropic, that is, it has a well-defined direction of the maximum transport. One component of the time-dependent flow, zonally elongated large-scale transients, is particularly important for the anisotropy, as it corresponds to primarily zonal material transport and long correlation time scales. The importance of these large-scale zonal transients in the material distribution is further confirmed with simulations of idealized color dye tracers, which has implications for parameterizations of the eddy transport in non-eddy-resolving models.\nKeywords:\nCorresponding author address: Igor Kamenkovich, 4600 Rickenbacker Causeway, University of Miami, Miami, FL 33149. E-mail: ikamenkovich@rsmas.miami.edu\n1. Introduction\nSection:\nThere is growing evidence for the importance of eddies—defined here as geostrophic deviations from a mean state—in the distribution of various oceanic tracers in the interior of oceanic gyres. In particular, eddies have been shown to maintain the Northern Hemisphere thermocline (e.g., Henning and Vallis 2004 ) and to control the penetration of transient atmospheric gases into the North Atlantic (e.g., Booth and Kamenkovich 2008 ). The efficiency of eddies in downgradient tracer transport has been conventionally quantified by turbulent (“eddy”) diffusivity. Under the assumptions of homogeneous and isotropic turbulence, the diffusivity K can be related to the rms Lagrangian velocity 〈υ′〉 of tracer particles and the Lagrangian correlation length scale lcorr or time scale τcorr ( Taylor 1921 ; Vallis 2006 ):\nIn the Eulerian analog of the above equation, the 〈υ′〉2 becomes the eddy kinetic energy (EKE): the Eulerian mixing length lcorr and the Eulerian time scale τcorr ( Prandtl 1925 ). The eddy diffusivity and other parameters in (1) can be estimated in observational data and numerical simulations by a variety of techniques. Such estimates have practical importance, as diffusion is widely used to parameterize eddies in non-eddy-resolving numerical models, which still account for the majority of ocean components of climate models. The diffusivities in these models are poorly constrained and determined empirically and are often taken to be spatially homogeneous and isotropic.\nExisting evidence based on observational estimates and numerical simulations, however, suggests that the eddy-induced transport is spatially inhomogeneous (e.g., LaCasce and Bower 2000 ) and anisotropic, that is, it has a preferred direction (e.g., Freeland et al. 1975 ; Spall et al. 1993 ; LaCasce 2000 ). The along-isopycnal eddy diffusivity can be described by a location-dependent two-dimensional tensor, and the preferred direction can be determined by diagonalizing this tensor. The latter approach was taken by Rypina et al. (2012) , who analyzed trajectories of both synthetic Lagrangian particles (diagnosed from the altimetric data) and the actual surface drifters in the North Atlantic. The results demonstrate that the preferred transport direction varies across the region, the transport anisotropy is caused primarily by geostrophic rather than nongeostrophic currents (see also Sallee et al. 2008 ), and the spreading of Lagrangian particles can be faster or slower than diffusive, that is, “superdiffusive” or “subdiffusive,” respectively (see also Berloff et al. 2002 ; Veneziani et al. 2005 ; Kamenkovich et al. 2009 ).\nThe origins of this complexity remain largely unclear, and several mechanisms have been proposed. The mean advection can significantly modulate the eddy-induced transport. In particular, the meridional diffusivity is enhanced at steering levels ( Green 1970 ; Killworth 1997 ) and is suppressed by zonal propagation of eddies relative to the mean zonal flow ( Ferrari and Nikurashin 2010 ); meridional shear in zonal currents can cause shear dispersion (e.g., Taylor 1953 ; Young et al. 1982 ; Smith 2005 ); and cross-jet transport barriers exist on strong currents such as the Gulf Stream and its extension ( Samelson 1992 ; Rypina et al. 2011 ) and alternating multiple jets ( Haynes et al. 2007 ; Berloff et al. 2009 ). In addition, powerful mean currents, such as those within the western boundary regions and the upper-ocean Antarctic Circumpolar Current, can dwarf the along-stream eddy-induced transport.\nIn many parts of the ocean, however, mean currents are weak relative to eddies, and the along-stream diffusivity is as important for tracer distribution as the mean advection. In these regions, the anisotropy cannot be explained by the effects of the mean advection alone ( Kamenkovich et al. 2009 ; Rypina et al. 2012 ). On the other hand, the eddy velocity variance tends to be isotropic ( Rypina et al. 2012 ) and cannot explain anisotropy in K using (1) either. Kamenkovich et al. (2009) hypothesize that the dominance of the zonal eddy diffusivity can be caused by zonally elongated eddies such as those observed in altimetry-based observational datasets ( Huang et al. 2007 ), and this hypothesis is further examined in this study. This manuscript investigates the influence of zonally elongated transient patterns on the particle spreading, describes spectral and transport properties of these transients in idealized numerical simulations ( sections 2 and 3 ) and altimetry-based velocity estimates ( section 4 ), and discusses the importance of transient motions in idealized tracer distribution in the model context in section 5 .\n2. Numerical model and simulated flow\nSection:\nThe dynamical model is adapted from Karabasov et al. (2009) and only a very brief description of it is given here. This model employs an advanced advection scheme Compact Accurately Boundary-Adjusting High-Resolution Technique (CABARET) which allows achieving highly effective spatial resolution, meaning that numerical convergence is found at much coarser spatial resolution than in the case of traditional advection schemes. An equally important and attractive property of this formulation is its numerical stability in the presence of small dissipation, which allows simulations with very high, and most realistic, Reynolds numbers (Re).\nThe vertical stratification is represented by three isopycnal layers, with the thicknesses of 250, 750, and 3000 m, counting from the top. The evolution of the potential vorticity (PV) qn in each layer is described by\nwhere the lateral Laplacian viscosity ν is 100 m2 s−1. This value has been chosen to correspond to the Munk boundary layer of 17 km that is minimally resolved with two grid points. PV in each layer is given by\nwhere the stratification parameters R1, R21, R22, and R3 are chosen so that the first and the second internal deformation radii are Rd1 = 32.2 and Rd2 = 18.9 km, respectively: β = 2 × 10−11 m−1 s−1.\nThe forcing Fn on the right-hand side of (4) includes Ekman pumping by the prescribed wind stress curl in the top layer and bottom friction in the bottom layer:\nwhere fwind is idealized wind forcing, which has a zero curl line slanted in the meridional direction. Bottom friction kbot = 10−7. The domain is square and has a size of 3840 km, and the spatial resolution is 7.5 km.\nThe simulated flow and its spectrum\nThe simulated flow consists of subtropical and subpolar gyres, separated by a well-pronounced western boundary current and its eastward jet extension (EJE hereinafter; Fig. 1a ). The entire domain is filled with mesoscale eddies, which are particularly strong in the vicinity of the EJE ( Fig. 1b ). The magnitudes of motions decrease with depth. The spatial structure of the PV is qualitatively similar to the streamfunction ( Figs. 1c,d ). This similarity is explained by the dominance of the stretching terms [last terms in (3) ], which is because the dominant length scales in the solutions are several Rossby deformation radii (see the following discussion of Fig. 2 ).\nView larger version (76K)\nFig. 1. Circulation in the top layer of the numerical simulations. (a) Time-mean (over 50 yr) streamfunction and (b) instantaneous minus the time-mean streamfunction (eddies) (m2 s−1). (c) Time-mean (over 50 yr) PV; (b) instantaneous minus the time-mean PV (eddies) (s−1).\nView larger version (60K)\nFig. 2. Spatial structure of the circulation in the numerical simulation. (a) Wavenumber k–l spectrum of velocity in the top layer, time averaged over 50 yr; absolute values of wavenumbers (k, l) are nondimensionalized by Rd1; the spectrum is nondimensionalized by the total kinetic energy (multiplied by 0.005). (b) The spectral power as a function of the angle between the wavenumber (k, l), summed over the interval K = [1/20Rd1 1/10Rd1] and divided by its maximum value. Note the presence of the anisotropic peak at small k in (a) and at angle ≈ 85° and in (b) corresponding to the zonal transients. (c) Zonal transients, isolated by the low-pass filtering (using the sine transform) of the instantaneous velocity streamfunction in the top layer (m2 s−1). (d) Zonally and time-averaged kinetic energy (weighted by the total kinetic energy) of the zonal transients in the three vertical layers.\nThe spatial structure of the eddy field is illustrated by the two-dimensional wavenumber (k–l) spectrum of the velocity—the sum of u and υ velocity spectra ( Fig. 2a ). The 2800 spectra of instantaneous velocities are computed at 7-day intervals and then averaged in time; note that these instantaneous k–l spectra do not contain information on time dependence and eddy propagation. Most of the spectral power is contained in the circular band corresponding to the total wavenumbers\nbetween (20Rd1)−1 and (10Rd1)−1. Within this spectral region in layer 1, there is a noticeable peak corresponding to the zonal wavelength k−1 = 120Rd1 (total basin width) and the meridional wavelength of l−1 = 13Rd1. This peak corresponds to a nearly meridional wavenumber ( Fig. 2b ) and is anisotropic in this sense. This anisotropic peak is separated from a second, broader, and bigger peak centered at the 30° orientation of the wavevector. The entire spectral region at k−1 > 30Rd1 will be referred to as the region of “zonal transients” to distinguish it from more isotropic flow components with shorter zonal scales, which will be loosely referred to as “isotropic eddies.” The zonal transient part of the spectrum corresponds to a relatively small portion of the total energy (e.g., 15% in layer 1); however, we will later see that the zonal transients play an important role in the anisotropic transport. Note that zonal transients are defined in terms of the zonal scales only and not based on dynamical properties. The separation between the two spectral peaks becomes less distinct in layers 2 and 3 (not shown).\nTo study the meridional structure and propagation properties of zonal transients, we isolate them by spatial filtering of the velocity streamfunction; the filtering is done in the zonal direction only, and the cutoff wavelength is 30Rd1. As the rest of the flow, the zonal transients have maximum amplitudes in the EJE vicinity ( Figs. 2c,d ). With depth, the distribution of the kinetic energy of the zonal transients becomes more uniform in the meridional direction and the relative importance of zonal transients in the regions north and south of EJE is the largest in layer 3. We will later see that this deep region also corresponds to the largest transport anisotropy.\nZonal transients propagate westward at a speed of approximately 0.035–0.05 m s−1 north and south of EJE, as estimated from the Hovmöller diagrams. The phase speed of zonal transients is noticeably smaller than the phase speed of the barotropic Rossby wave with the same wavenumbers and in the motionless medium (0.09 m s−1) but are larger than the phase speed of the first baroclinic Rossby wave (0.02 m s−1). This discrepancy is likely to be explained by the effects of the mean advection ( Berloff and Kamenkovich 2013a ), but the analysis of the normal modes of the double-gyre flow is beyond the scope of this study.\n3. Lagrangian analysis\nSection:\nProperties of the eddy-induced material transport are investigated next using Lagrangian particle trajectories. The components of the single-particle dispersion matrix for a group of N Lagrangian particles are defined as\nwhere xn and yn are the zonal and meridional displacements, respectively, of an nth particle from its initial position. The terms X and Y are the ensemble-mean displacements:\nThe dispersion matrix is diagonalized by rotating the coordinate frame, and the angle between the latitude circle and the new x axis θmax is\nThe rate at which the dispersion in the new coordinate frame (ξ, η) increases with time is used to define the spreading rates:\nwhere\nThe Lagrangian correlation time scales are calculated (e.g., Vallis 2006 ) from the Lagrangian velocity autocorrelation functions Rξ and Rη in the new coordinate frame:\nThe effects of the mean flow on the eddy-induced diffusivity is accounted for by the full trajectory-following (FTF) method ( Berloff et al. 2002 ; Rypina et al. 2012 ), which was shown by the latter study to account for such known effects of the mean flow on the eddy diffusivity as the cross-jet suppression of eddy-induced particle spreading and material transport barriers. The method calculates particle dispersion only due to the time-dependent (eddy) part of the flow but along the particle trajectories in the full (eddy plus mean) flow. This effectively captures the effects of the mean advection on the eddy-driven dispersion because the Lagrangian quantities in (1) are determined by particle location. Note that the more straightforward analysis of particles in the full flow cannot serve this purpose because of the particle dispersion by the mean flow itself.\nNeutrally buoyant Lagrangian particles are released in 50 consecutive 400-day segments, starting with 130 000 particles in each layer. To examine the spatial distribution of the anisotropic spreading rates, this area is divided into 106 km by 106 km subregions, and the particles are divided into the corresponding groups, according to their initial positions. Particle spreading rates are computed for each subregion over the 400-day time interval. Typically, most particles in each group leave the subregion boundaries before they reach the diffusive regime, and these nonlocal effects must be accounted for. To do this for each group, we define a mean “particle cloud” by its center of mass, using (X, Y), and by its size, using the average zonal/meridional displacements. If several particle clouds overlap at a given point, the dispersion at this point is estimated by the ensemble average of the corresponding individual cloud dispersions. Particle clouds that touch solid boundaries are discarded.\na. Dispersion regimes\nThe long time asymptotic behavior of (8) is traditionally used to characterize different dispersion regimes (e.g., LaCasce 2008 ). In particular, the diffusive regime corresponds to the linear increase of the dispersion with time, achieved after sufficient time has passed, and (8) then provides an estimate for the eddy diffusivities. Deviations from the diffusion are quantified here by fitting tα+1 to\nand\n; the corresponding parameters are defined as\nand\n, respectively. In a purely diffusive regime, α is zero, whereas the superdiffusive regimes correspond to positive and subdiffusive regimes correspond to negative values of this parameter.\nThe map of parameter α shows that over the 400 days used to estimate the diffusivity in this study, the dispersion is not exactly diffusive in most of the domain ( Fig. 3 ). In particular,\nand\nare positive (superdiffusive spreading) in the western part of the domain but are negative (subdiffusive spreading) in the wide region centered around EJE. Spreading tends to become more diffusive in deeper layers. These deviations from the diffusive regime can be explained by several factors. First, the superdiffusive dispersion can be caused by the effects of the persistent shear in velocities. For example, in the extreme case of stationary velocity shear and no eddies, the spreading is purely “ballistic” (α = 1). Second, nonzero values of α can be found even in the flow that is locally diffusive but whose eddy kinetic energy and diffusivity vary strongly with location. This can happen because as they spread particles enter regions with weaker (stronger) eddies and thus slow (accelerate) their spreading rates ( Berloff et al. 2002 ; Rypina et al. 2012 ); the mean flow can potentially play a dominant role in these effects.\nFig. 3. Spreading regimes in the control simulation. Parameters (left)\nand (right)\nare shown in the top layer. Positive values correspond to superdiffusive and negative values correspond to subdiffusive spreading.\nThe importance of the mean advection can be estimated here by comparing the dispersion regimes in the control FTF simulation and a more traditional “eddy-only” run, in which the effects of the mean advection are neglected, and the particles only feel (i.e., are advected by) the eddying component of the flow. The eddy-only simulation exhibits more diffusive spreading along the main axis and the basin-averaged magnitude of\ndecreases from 0.44 to 0.20. In particular, the particle spreading in the western part of the domain is no longer superdiffusive, and this difference with the control simulation is explained by the mean advection. As particles in the control run move toward EJE, they experience more powerful eddy-driven spreading, which explains the increase in their dispersion and positive values of\nand\n. These conclusions are consistent with Rypina et al. (2012) .\nb. Anisotropic dispersion\nThe eddy diffusivity is strongly anisotropic, with Kξ exceeding Kη everywhere in the domain ( Fig. 4a ; Table 1 ). The largest diffusivities are found between the gyres in the EJE-dominated part of the domain, where the eddy kinetic energy is also the highest. In the top layer, the anisotropy parameter\nis the largest in the eastern part of the domain, where aaniso reaches 10.0; the area-averaged value of this parameter is 5.2. The spreading is the weakest and most isotropic in the southeastern (northeastern) parts of the subtropical (subpolar) gyres. With depth, the spreading becomes more isotropic near the EJE region but more anisotropic elsewhere ( Fig. 4b ). This is in accord with a greater relative importance of zonal transients in these regions ( section 2 ). In the area-averaged sense, the anisotropy increases with depth and becomes particularly large in the bottom layer ( Table 1 ). The major dispersion direction is not exactly zonal (area average is approximately 10°) and is therefore not aligned with the f/h contour, where f is the Coriolis frequency and h is the total depth of the fluid. The major spreading direction also crosses the background PV contours, most notably in the east of the domain ( Figs. 1c , 4a ).\nView larger version (55K)\nFig. 4. Anisotropic spreading rates in the control simulation. (left) Spreading ellipses (see text) are superimposed here on the anisotropy parameter aaniso (shaded); every ninth ellipse is shown for presentation purposes. Also shown is the time-mean streamfunction. (right) Zonally averaged aaniso in the three vertical layers.\nTable 1. Anisotropy coefficient aaniso in four simulations, area averaged within three vertical layers.\nTable 1. Anisotropy coefficient aaniso in four simulations, area averaged within three vertical layers.\nThe correlation time scales in the major and minor directions\nand\nexhibit substantial variability in the horizontal and vertical ( Table 2 ), demonstrating that the Lagrangian velocity variance alone is not sufficient to quantify the spatial dependence in diffusivities. The longest time scales are found in the intermediate layer 2 and in the interior of the subpolar and subtropical gyres (away from EJE). The velocity variance cannot explain the anisotropy in diffusivities either since\nsubstantially exceeds\nin most of the domain. The Lagrangian velocity variance in the major and minor directions\nand\nare, in contrast, very close to each other; the area-averaged ratio between them is 1.05, 1.13, and 0.92 in layers 1, 2, and 3, respectively. This would lead to an erroneous conclusion that diffusivities should be isotropic if the variability in the correlation times is not taken into account. These results are consistent with the analysis of altimetric velocities in Rypina et al. (2012) .\nTable 2. Correlation time scale\n(days) in four simulations within three vertical layers; the reported values are horizontal averages plus or minus the spatial std dev.\nTable 2. Correlation time scale\n(days) in four simulations within three vertical layers; the reported values are horizontal averages plus or minus the spatial std dev.\nImage of typeset table\nc. Causes of the dispersion anisotropy: Mean advection and zonal transients\nWe first examine the role of the mean advection by comparing the control simulation to the eddy-only (EO) experiment (which was described in section 3a ). In the EO simulations, the anisotropy parameter aaniso decreases in the top layer, with the largest changes in the EJE vicinity (not shown). However, aaniso remains larger than 2.0 in most of the domain and is larger than 5 in the northern and southern parts of the domain; the area-averaged value is 4.0. This demonstrates that, even in the absence of mean advection, the eddies cause anisotropic particle spreading. Because of the weakness of the mean advection in the deep layers, the differences between the standard and EO runs are only noticeable in the EJE vicinity. Interestingly,\ndoes not increase in the EJE vicinity in response to the removal of the mean advection, which is inconsistent with the idea of cross-flow mixing suppression. It is, however, plausible that our Lagrangian estimates can underestimate the suppression effects by the narrow EJE due to a large size of the corresponding particle clouds.\nWe next estimate the importance of zonal transients by analyzing a “zonal transient–dominated” sensitivity experiment ( Fig. 5a ). In this run, we low-pass Fourier filter the velocity streamfunction in the zonal direction with Lfilter = 30Rd1 (simulation LPx30Rd). For this purpose, the flow is decomposed into the Fourier series, 1 all Fourier coefficients corresponding to scales shorter than Lfilter are set to zero, and the inverse transform is applied. This simulation employs the FTF technique, so the full trajectories of particles are the same as in the control simulation.\nView larger version (73K)\nFig. 5. Sensitivity runs with the Fourier-filtered flows and the importance of zonal transients on the anisotropic spreading rates. (a) Zonal transient–dominated LPx30Rd simulation; (b) isotropic eddy–dominated HPx30Rd simulation. Spreading ellipses (see text) are superimposed here on the anisotropy parameter aaniso (shaded); every ninth ellipse is shown for presentation purposes. Also shown is the time-mean streamfunction.\nThe spreading rates become strongly anisotropic with aaniso exceeding 10.0 in most of the domain; aaniso also becomes more spatially uniform. Both\nand\nare reduced compare to the control run, but the reduction in\nis particularly dramatic, and this is consistent with the strong reduction in the meridional velocity variance. However, the Lagrangian correlation time scale\nincreases, particularly south and north of EJE, and this further outlines the fact that the velocity variance alone cannot explain the anisotropy. Last, the major dispersion direction becomes nearly zonal: the area-averaged θmax increases from only 2° to 4° with depth. These results suggest that zonal transients act to induce primarily zonal material transport and increase the correlation time scale in the major direction.\nWe now reverse the sensitivity experiment and carry out a simulation in the “isotropic eddy–dominated” experiment (HPx30Rd), where zonal transients are removed from the velocity streamfunction using the high-pass Fourier filter with Lfilter = 30Rd1. Several differences with the control simulation are notable. First, the spreading becomes more isotropic with the area-averaged aaniso ≈ 2.0 in all layers. This is despite the fact that\nis generally smaller than\n; for example, their area-averaged ratio in the top layer is 0.7. Note that a diffusivity estimate based entirely on the velocity variance would erroneously suggest that particle spreading should become predominantly meridional. Second, the correlation time scale\nis reduced, particularly in layers 2 and 3, and\nis increased, but the difference between these two scales is still significant ( Table 3 ). We can hypothesize that this is explained by the effects of the mean advection and zonal transients on the dispersion by the isotropic eddies, but the exact mechanism needs to be further investigated. Distribution of\nalso becomes more spatially uniform ( Table 2 ), which suggests that the velocity variance can be more readily used to quantify eddy diffusivity. Third, the direction of the maximum spreading is more nonzonal than in the control run, and the area-averaged θmax ≈ 16°. These results demonstrate that the isotropic eddies induce weakly anisotropic transport, with more spatially uniform correlation scales.\nTable 3. Correlation time scale\n(days) in four simulations within three vertical layers; the reported values are horizontal averages plus or minus the spatial std dev.\nTable 3. Correlation time scale\n(days) in four simulations within three vertical layers; the reported values are horizontal averages plus or minus the spatial std dev.\n4. Anisotropic transport and its causes in altimetry-based estimates\nSection:\nThe model-based results in section 3 strongly indicate that the anisotropy of the eddy-induced material transport and the predominantly zonal direction of preferred particle spreading are largely controlled by zonal transients. We now test these conclusions using a 17-yr-long record (from 1992 to 2009) of the geostrophic velocities inferred from AVISO sea surface height altimetric measurements. We focus here on the subtropical North Atlantic from 20° to 50°N and from 70° to 20°W; the data and methods are the same as in Rypina et al. (2012) . Similar to the model-based k–l velocity spectrum shown in Fig. 2 , the spectrum of geostrophic velocities ( Fig. 6 ) contains a noticeable peak in its zonal transient portion, where zonal scales exceed 1000 km. Unlike the model results, however, the isotropic part of the spectrum contains multiple peaks.\nView larger version (71K)\nFig. 6. Spatial (k–l) velocity spectrum of the geostrophic velocity (sum of the u and υ velocity spectra, where u and υ are in km day−1) inferred from the AVISO satellite altimetry, time averaged over the period from 1992 to 2009.\nWe now investigate the influence of this zonal transient spectral peak on the eddy-induced diffusivity by comparing particle spreading in simulations with the unfiltered eddies (control run) to simulations with the low-pass filtered (zonal transient dominated) and high-pass filtered (isotropic eddy dominated) eddy fields. As before, the diffusivities are quantified using the FTF approach and are visualized using the diffusivity ellipses ( Fig. 7 ). In comparison to the control run (green ellipses), in the zonal transient–dominated simulations (blue ellipses) both the zonal and meridional components of diffusivity become smaller, but the meridional component decreases significantly more than the zonal component. As a result, the ellipses become nearly zonal throughout most of the domain, and the anisotropy coefficient increases from 5.4 in the control to 7.9 in the zonal transient–dominated run. If, in the opposite, zonal transients are removed in the isotropic eddy–dominated flow, the zonal component of diffusivity decreases more than the meridional, and the ellipses become less anisotropic with the domain-averaged anisotropy coefficient of only 2.5 ( Fig. 7 , bottom). All of these results are in agreement with the model-based results of section 3 .\nView larger version (81K)\nFig. 7. Anisotropic transport and its causes in altimetry-based estimates of North Atlantic circulation. (top) Diffusivity ellipses in the three simulations: full unfiltered flow (green), low-pass filtered zonal transient–dominated flow (blue), and high-pass filtered flow (red). Anisotropy parameter aaniso in three simulations: (bottom left) full unfiltered flow, (bottom middle) low-pass filtered flow, and (bottom right) high-pass filtered flow.\n5. Tracer distribution in the numerical model\nSection:\nA practical application of the diffusivity estimates is to use them to parameterize eddies in non-eddy-resolving simulations. The task of eddy parameterization is therefore to reproduce tracer distribution using the diffusion instead of the eddy advection. We test the validity of this approach in simulations with idealized tracer release experiments. The distribution of the tracer c(x, y, t) is governed by the standard advective–diffusive equation:\nwhere\nis the diffusivity tensor estimated using\nand kbh is the biharmonic diffusivity required for numerical stability; its value of −5 × 1010 m4 s−1 is the same in all simulations. The term F(x, y) is the tracer source/sink.\nWe consider evolution of an isolated tracer patch:\nwhere (x0, y0) defines a center of the patch, and sx and sy is the size of the patch. We initialize the model with three tracer release experiments: a patch centered around EJE (central patch), a patch south of EJE (southern patch), and a patch north of EJE (northern patch).\nIn the absence of eddies, each patch is assumed to be balanced by a constant tracer source F:\nwhere\nis the time-mean velocity. We, therefore, consider a tracer anomaly that is due to a steady source, and this situation is relevant to tracers that do not have a direct feedback on their sources (such as surface salinity). The particular shape of (15) also corrects for the direct effects of the mean advection on the initial patch, which simplifies a comparison to the Lagrangian studies in section 3 . Simulations with F = 0 were also carried out and led to qualitatively similar conclusions, although the quantitative analysis is more challenging because of the significant deformation of the patches by the mean advection, collision of the patches with solid walls, and entrainment of the tracer into the western boundary current and EJE. It is, however, important to note that the mean advection is not powerful enough to dwarf the effects of eddies even if F = 0 and the tracer distributions with and without eddies are substantially different within the subtropical and subpolar gyre regions ( Fig. 8 ). This demonstrates the importance of the eddy advection even in the along-mean flow direction; if the opposite were true, only cross-mean flow diffusivity would be important and the anisotropic tensor\nwould not have any practical significance.\nView larger version (36K)\nFig. 8. Importance of eddies in the idealized tracer distributions. Tracer concentrations are shown at day 100 for two simulations with F = 0 and (a) full flow and (b) mean advection only. Central patch release is not shown because of its strong deformation by the EJE. Time-mean streamlines are shown by the black contours.\nIn the control simulation, the tracer is advected by the full flow (mean and eddy) and\n= 0. Ten consecutive 400-day simulations are averaged for the analysis. By the day 200, the patches are substantially modified by the eddying flow ( Fig. 9 ); the deformation is much stronger at day 400, which complicates the analysis at later stages. The integration is not continued beyond day 400 despite the fact that the statistical steady state is not reached. The southern and northern patches are being dispersed by eddies, whereas their centers of mass are moving very little in all simulations because of the action of F. The center of mass of the central patch in the top layer, in contrast, moves northwest despite the action of F; the distortion of the patch is still significantly smaller than in the F = 0 simulation. Layers 2 and 3 and all parameterized runs described below do not have the same problem.\nView larger version (58K)\nFig. 9. Distribution of an idealized tracer in numerical simulations. Tracer patches from the three different releases (northern patch, central patch, and southern patch) are overlapped and shown (in the top layer at day 200) for the initial distribution and sensitivity experiments.\nWe next analyze a series of sensitivity simulations, in which a part of the eddying flow is removed and replaced with diffusion. The resulting errors are quantified by the mean square of the difference with the control simulation for each patch; to make these numbers more meaningful, we also divide them by the mean square changes in the control simulation ( Table 4 ):\nwhere the angular brackets stand for the spatial average, and ccontrol is the tracer concentration in the control simulation. One needs to recall that the task of diffusion-based parameterization is to reproduce large-scale fields of the control simulation. To prevent the small-scale variance from dominating the errors and to make the quantitative analysis more relevant to the task of parameterization, the tracer is smoothed with a running-mean spatial filter with a width of 112 km (15 grid points).\nTable 4. Weighted mean square error in the tracer concentration (see text) at day 200 shown for the three tracer patches and in the three vertical layers.\nTable 4. Weighted mean square error in the tracer concentration (see text) at day 200 shown for the three tracer patches and in the three vertical layers.\nImage of typeset table\nThe eddy velocities are removed and replaced with\n(x, y) estimated using (13) from the data of section 3 . The resulting tracer distributions are similar to the control simulation in terms of the path location and shape, including eastward displacement of the center of the northern patch, small westward displacement of the center of the central patch, and asymmetric deformation of the southern patch ( Fig. 9 ). There are also some noticeable differences. In addition to the tracer distribution being considerably smoother than in the control simulation (which is expected), tracer maxima in the middle of each patch are also smeared out, and the meridional dispersion is generally overestimated. The largest differences are in the central and southern patches ( Table 4 ). All these biases can be attributed to the nonuniform distribution of eddy diffusivity, nonlocal Lagrangian methods used to estimate\n, and nondiffusive particle spreading.\nWhat is the relative importance of zonal transients and isotropic eddies? To answer this question, we carried out the zonal transient–dominated simulation with LPx30Rd velocities and isotropic eddy–dominated simulation with HPx30Rd velocities. Both simulations have\n= 0. The isotropic eddy–dominated simulation is intended to estimate the importance of zonal transients by removing their effects from the control run. The flow in this run contains most of the eddy fields (everything except zonal transients), and the improvements over the simulation with\n(x, y) can be anticipated and are indeed observed in layer 1 and central patches in all layers. Nevertheless, the absence of zonal transients causes considerable biases, most notably in the southern patch, which is overly symmetric in this simulation.\nThe effects of zonal transients are further studied in the zonal transient–dominated run. Simulated tracer distributions are surprisingly close to the simulation with\n(x, y) and even show some noticeable improvements, particularly for the southern patch and in layer 3. This is despite the fact that a rather small portion of the eddying velocities is used to advect the tracer. Tracer simulation with explicit zonal transients can be further improved if additional mixing is introduced to compensate for the missing isotropic eddies. To show the potential for such improvement, we add a constant isotropic diffusion with constant K = 500 m2 s−1. This is a rather typical value for isopycnal diffusivities in coarse resolution models, but it is smaller than the area-averaged values of Kξ and Kη in the control simulation in the top two layers. Values of 250 and 1000 m2 s−1 have also been tried but led to very similar values of Ce. In comparison to both the simulations with K(x, y) and isotropic eddies, this run exhibits noticeable improvements everywhere, except in the central patch of the top layer. Clearly, an explicit simulation of zonal transients has a pronounced effect on tracer simulations, and the parameterization of the eddy transport seems more plausible in this case.\n6. Discussion and conclusions\nSection:\nThis study examines the anisotropic transport properties of the eddying North Atlantic flow, using an idealized model of the double-gyre oceanic circulation and altimetry-derived velocities. In this study, we decompose the flow into three main components: time-mean advection, large-scale zonal transients, and the remainder of the eddy field. The material transport by the time-dependent flow (quantified by the eddy diffusivity tensor) varies geographically and is anisotropic, that is, it has a well-defined direction of the maximum transport. These properties are primarily explained by the action of transient motions, rather than the effects of the time-mean advection. In particular, zonal transients correspond to the primarily zonal material transport and explain the largest part of anisotropy in diffusivities for both numerically simulated and altimetry-based velocity fields.\nZonal transients are defined using the spatial velocity spectrum, which, in the upper ocean, shows a peak at the basinwide zonal scale and a nearly meridional wavevector. Because of these spectral properties, Lagrangian velocities in zonal transient–dominated flows are predominantly zonal and have persistent correlations in time. This makes zonal transients a particularly effective vehicle for the anisotropic material transport, despite the fact that the amount of energy contained in the zonal transient portion of the spectrum is relatively small. Anisotropy in transport is due primarily to the difference in the correlation time scales, rather than anisotropy of the velocity covariance matrix. Our definition of these transients is based solely on their zonal scales and they are, strictly speaking, spectral Fourier modes in the zonal direction. The dynamical interpretation of these transients and their origins remains to be established. In particular, it is possible that zonal transients are normal modes and exist because of the linear dynamics through their interactions with the mean flow ( Berloff and Kamenkovich 2013a , b ). Alternatively, the energy at the zonal transient part of the spectrum can exist because of the nonlinear energy transfer due to interactions among transient eddies ( Arbic et al. 2014 ). Investigation of the dynamics of zonal transients is left for future studies.\nAnisotropy in transport is quantified here using a diagonalized diffusivity tensor, although the transport properties are almost never perfectly diffusive. This nondiffusive behavior, combined with spatial inhomogeneity and anisotropy, makes the parameterization of eddy-induced transport challenging. This is demonstrated by biases in idealized tracer distributions in simulations, in which the eddy-induced transport is parameterized using Lagrangian diffusivity estimates. Since such estimates are not globally available below the surface, finding an effective parameterization for the entire eddying flow may be even more difficult than our study implies. Our results suggest, however, that this task becomes easier in simulations with explicit zonal transients since these flow components are associated with a large part of the complexity in the transport, such as spatial variability in the decorrelation scales and anisotropy. Zonal transients are large enough to be resolved by most numerical simulations even at relatively coarse spatial resolution, but such non-mesoscale-resolving simulations may lack the dynamics necessary to simulate zonal transients. The importance of large-scale transients and the utility of the Lagrangian estimates of eddy diffusivity need to be further studied for more realistic, climatically relevant tracers. This can be done using simulations with and without eddy advection (as in Booth and Kamenkovich 2008 ) and will be a subject of a future study.\nAcknowledgments\nWe thank two anonymous reviewers for their helpful suggestions on improving this manuscript. IK would like to acknowledge support through the NSF Grant OCE-1154923. IR was supported by the NSF OCE-1154641 and NASA Grant NNX14AH29G.\nREFERENCES\nSection:\nArbic, B., M. Mueller, J. Richman, J. Shriver, A. Morten, R. Scott, G. Serazin, and T. Penduff, 2014: Geostrophic turbulence in the frequency–wavenumber domain: Eddy-driven low-frequency variability. J. Phys. Oceanogr., 44, 2050–2069, doi: https://doi.org/10.1175/JPO-D-13-054.1 . Link\nBerloff, P., and I. Kamenkovich, 2013a: On spectral analysis of mesoscale eddies. Part I: Linear analysis. J. Phys. Oceanogr., 43, 2505–2527, doi: https://doi.org/10.1175/JPO-D-12-0232.1 . Link\nBerloff, P., and I. Kamenkovich, 2013b: On spectral analysis of mesoscale eddies. Part II: Nonlinear analysis. J. Phys. Oceanogr., 43, 2528–2544, doi: https://doi.org/10.1175/JPO-D-12-0233.1 . Link\nBerloff, P., J. C. McWilliams, and A. Bracco, 2002: Material transport in oceanic gyres. Part I: Phenomenology. J. Phys. Oceanogr., 32, 764–796, doi: https://doi.org/10.1175/1520-0485(2002)032<0764:MTIOGP>2.0.CO;2 . Link\nBerloff, P., I. Kamenkovich, and J. Pedlosky, 2009: A mechanism for the formation of multiple zonal jets in the oceans. J. Fluid Mech., 628, 395–425, doi: https://doi.org/10.1017/S0022112009006375 . Crossref\nBooth, J., and I. Kamenkovich, 2008: Isolating the role of mesoscale eddies in mixing of a passive tracer in an eddy resolving model. J. Geophys. Res., 113, C05021, doi: https://doi.org/10.1029/2007JC004510 . Crossref\nFerrari, R., and M. Nikurashin, 2010: Suppression of eddy diffusivity across jets in the Southern Ocean. J. Phys. Oceanogr., 40, 1501–1519, doi: https://doi.org/10.1175/2010JPO4278.1 . Link\nFreeland, H. J., P. B. Rhines, and T. Rossby, 1975: Statistical observations of the trajectories of neutrally buoyant floats in the North Atlantic. J. Mar. Res., 33, 383–404.\nGreen, J. S. A., 1970: Transfer properties of the large-scale eddies and the general circulation of the atmosphere. Quart. J. Roy. Meteor. Soc., 96, 157–185, doi: https://doi.org/10.1002/qj.49709640802 . Crossref\nHaynes, P. H., D. A. Poet, and E. F. Shuckburgh, 2007: Transport and mixing in kinematic and dynamically consistent flows. J. Atmos. Sci., 64, 3640–3651, doi: https://doi.org/10.1175/JAS4030.1 . Link\nHenning, C. C., and G. Vallis, 2004: The effects of mesoscale eddies on the main subtropical thermocline. J. Phys. Oceanogr., 34, 2428–2443, doi: https://doi.org/10.1175/JPO2639.1 . Link\nHuang, H.-P., A. Kaplan, E. Curchitser, and N. Maximenko, 2007: The degree of anisotropy for mid-ocean currents from satellite observations and an eddy-permitting model simulation. J. Geophys. Res., 112, C09005, doi: https://doi.org/10.1029/2007JC004105 . Crossref\nKamenkovich, I., P. Berloff, and J. Pedlosky, 2009: Anisotropic material transport by eddies and eddy-driven currents in a model of the North Atlantic. J. Phys. Oceanogr., 39, 3162–3175, doi: https://doi.org/10.1175/2009JPO4239.1 . Link\nKarabasov, S. A., P. S. Berloff, and V. M. Goloviznin, 2009: CABARET in the ocean gyres. Ocean Modell., 30, 155–168, doi: https://doi.org/10.1016/j.ocemod.2009.06.009 . Crossref\nKillworth, P., 1997: On the parameterization of the eddy transfer. Part I. Theory. J. Mar. Res.,55, 1171–1197, doi: https://doi.org/10.1357/0022240973224102 .\nLaCasce, J. H., 2000: Floats and f/H. J. Mar. Res., 58, 61–95, doi: https://doi.org/10.1357/002224000321511205 . Crossref\nLaCasce, J. H., 2008: Lagrangian statistics from oceanic and atmospheric observations. Transport and Mixing in Geophysical Flows, J. B. Weiss and A. Provezale, Eds., Springer, 165–228. Crossref\nLaCasce, J. H., and A. Bower, 2000: Relative dispersion in the subsurface North Atlantic. J. Mar. Res., 58, 863–894, doi: https://doi.org/10.1357/002224000763485737 . Crossref\nPrandtl, L., 1925: Bericht über Untersuchungen zur ausgebildeten Turbulenz. Z. Angew. Math. Mech., 5, 136–139.\nRypina, I. I., L. J. Pratt, and M. S. Lozier, 2011: Near-surface transport pathways in the North Atlantic Ocean: Looking for throughput from the subtropical to subpolar gyre. J. Phys. Oceanogr., 41, 911–925, doi: https://doi.org/10.1175/2011JPO4498.1 . Link\nRypina, I. I., I. Kamenkovich, P. Berloff, and L. Pratt, 2012: Eddy-induced particle dispersion in the near-surface North Atlantic. J. Phys. Oceanogr., 42, 2206–2228, doi: https://doi.org/10.1175/JPO-D-11-0191.1 . Link\nSallee, J.-B., K. Speer, R. Morrow, and R. Lumpkin, 2008: An estimate of Lagrangian eddy statistics and diffusion in the mixed layer of the Southern Ocean. J. Mar. Res., 66, 441–463, doi: https://doi.org/10.1357/002224008787157458 . Crossref\nSamelson, R., 1992: Fluid exchange across a meandering jet. J. Phys. Oceanogr., 22, 431–444, doi: https://doi.org/10.1175/1520-0485(1992)022<0431:FEAAMJ>2.0.CO;2 . Link\nSmith, K. S., 2005: Tracer transport along and across coherent jets in two-dimensional turbulent flow. J. Fluid Mech., 544, 133–142, doi: https://doi.org/10.1017/S0022112005006750 . Crossref\nSpall, M. A., P. L. Richardson, and J. Price, 1993: Advection and eddy mixing in the Mediterranean salt tongue. J. Mar. Res., 51, 797–818, doi: https://doi.org/10.1357/0022240933223882 . Crossref\nTaylor, G. I., 1921: Diffusion by continuous movements. Proc. London Math. Soc., 20, 196–211, doi: https://doi.org/10.1112/plms/s2-20.1.196 . Crossref\nTaylor, G. I., 1953: Dispersion of soluble matter in solvent flowing slowly through a tube. Proc. Roy. Soc. London, A219, 186–203, doi: https://doi.org/10.1098/rspa.1953.0139 . Crossref\nVallis, G. K., 2006: Atmospheric and Oceanic Fluid Dynamics. Cambridge University Press, 745 pp.\nVeneziani, M., A. Griffa, A. M. Reynolds, Z. D. Garraffo, and E. P. Chassignet, 2005: Parameterizations of Lagrangian spin statistics and particle dispersion in the presence of coherent vortices. J. Mar. Res., 63, 1057–1083, doi: https://doi.org/10.1357/002224005775247571 . Crossref\nYoung, W. R., P. B. Rhines, and C. J. R. Garrett, 1982: Shear-flow dispersion, internal waves and horizontal mixing in the oceans. J. Phys. Oceanogr., 12, 515–527, doi: https://doi.org/10.1175/1520-0485(1982)012<0515:SFDIWA>2.0.CO;2 . Link\n1 Note that although the flow satisfies the no-normal flow and no-slip boundary conditions, the streamfunction is not periodic in the strict sense. Nevertheless, the results with the Fourier transform and with and without window tapering and the use of the sine transform lead to very similar results.\nMarch 2015\n""","0.33415756","""http://journals.ametsoc.org/doi/10.1175/JPO-D-14-0164.1""","[-0.178219,51.500505]"
"""University_of_Lancaster""","""An agent-based vehicle routing simulation tool for road networks with time-variant data - Research Portal | Lancaster University""","""An agent-based vehicle routing simulation tool for road networks with time-variant data\nResearch output: Contribution in Book/Report/Proceedings › Paper\nPublished\nProceedings of the 27th European Simulation and Modeling Conference\nPlace of Publication\n27th Annual European Simulation and Modelling Conference - Lancaster, United Kingdom\nConference\n27th Annual European Simulation and Modelling Conference\nCountry\n27th Annual European Simulation and Modelling Conference\nCountry\n23/10/13 → 25/10/13\nAbstract\nSimulation modeling is one of the analytic techniques commonly used for transportation management; it includes such activities as route planning and post-operation analysis. One of the simulation methods, agent-based simulation, has become increasingly popular due to the availability of good micro-level data collected through technologies such as GPS-enabled devices and road sensors. This paper presents the design and implementation of an agent-based simulation tool that can be used to analyse vehicle routing algorithms. We demonstrate how the tool can be used in practice by implementing two vehicle routing algorithms: shortest-path and LANTIME. LANTIME is an algorithm that can be used to minimize CO2 emissions.\nLancaster University Bailrigg Lancaster United Kingdom LA1 4YW\n+44 (0)1524 65201\n""","1.2671596","""http://www.research.lancs.ac.uk/portal/en/publications/an-agentbased-vehicle-routing-simulation-tool-for-road-networks-with-timevariant-data(bb842266-f5b8-4491-858c-1ce2901a30c5).html""","[-2.787729,54.010394]"
"""University_of_Exeter""","""A Multi-Objective Optimization for Supply Chain Network Using the Bees AlgorithmInternational Journal of Engineering Business Management - Ernesto Mastrocinque, Baris Yuce, Alfredo Lambiase, Michael S. Packianather, 2013""","""1. Introduction\nSection:\nNowadays, the complexity of the business environment is rapidly increasing [ 1 ]. This is due to several factors such as the expansion of the market, a wide range of suppliers, increased competition and customers demands on the performance of a company, in particular, the waiting time, cost and quality of the product [ 2 ]. Among these factors, if we consider the range of suppliers to the market, it is necessary to design an optimized supply chain model [ 3 ]. The supply chain is a complex network from suppliers to customers, which involves people, technologies, activities, information and resources. Its design and management has the purpose of obtaining the best global performances under unions operating criteria [ 4 ]. A typical supply chain is composed of the following elements: suppliers, manufacturing plants, warehouses, distribution centres (DCs), customers/final markets.\nThe optimization of a supply chain is related to selecting the optimum resource options in order to satisfy the objective function / functions. The single objective-based supply chain models are mostly aimed at finding the minimum total cost [ 5 , 6 ]. However, the modelling of a supply chain requires more than a single-objective such as lead-time minimization, inventory level minimization, service level maximization, environmental impact maximization and so on [ 7 ]. Sometimes these objectives may cause conflicts such as increasing the service level usually causes a growth in costs. Therefore, the aim must be to find trade-off solutions to satisfy the conflicting objectives.\nIn multi-objective optimization problems there is no single optimum solution, but there is a solution set which creates Pareto optimal solutions. Pareto optimal solutions are a set of trade-offs between different objectives and are non-dominated solutions, i.e., there is no other solution which would improve an objective without causing a worsening in at least one of the other objectives [ 8 ].\nIn the literature, several models have been proposed to solve supply chain design problems to get the Pareto optimal solutions. Most of these models are based on genetic algorithms and the fuzzy logic approach. Work has been done on the facility location problem of a four echelons supply chain (suppliers, plants, DCs and customers) [ 9 ]. The objectives of this work are to minimize the total cost, maximize customer services and the capacity utilization balance for DCs using a genetic algorithm-based approach.\nAnother reported work on supply chains is based on the supplier selection, product assembly and distribution system using a modified Pareto genetic algorithm to minimize the total cost and delivery time, and maximize the quality [ 10 ].\nA multi-objective location-inventory problem has been investigated using a multi-objective evolutionary algorithm based on the non-dominated sorting genetic algorithm II (NSGAII) in order to minimize total costs and maximize the volume fill rate and the responsiveness level [ 11 ].\nAn optimum mathematical planning model for green partner selection, which involves four objectives which are cost, time, product quality and green appraisal score, has been developed in [ 12 ]; this model employed two types of genetic algorithms to solve multi-objectives and then to find the set of Pareto optimal solutions. In this study, the weighted sum approach that can generate a greater number of solutions has been proposed.\nIn [ 13 ], the authors have developed a multi-objective fuzzy mathematical programming model for a forward/reverse supply chain minimizing the total cost and the environmental impact. This approach is composed of two parts: in the first phase the method of Jimenez et al. [ 14 ] is applied to convert the proposed multi-objective probability mixed integer programming model into an equivalent auxiliary crisp model, and in the second phase a fuzzy solution method based on the e-constraint method to find the final preferred compromise solution has been proposed.\nA multi-product, multi-stage and multi-period scheduling model is proposed in [ 15 ] to deal with multiple incommensurable goals for a multi-echelon supply chain network with uncertain market demands and product prices; a two-phase fuzzy decision-making method is presented to maximize the participants' expected profits, average safe inventory levels, average customer service levels and robustness of selected objectives to demand uncertainties.\nA bi-objective optimization approach to the designing and planning of a supply chain is proposed in [ 16 ] in order to maximize the annual profit and minimize the environmental impact; profit and environmental impacts are balanced using an optimization approach adapted from symmetric fuzzy linear programming, while the supply chain is modelled as a mixed integer linear programming optimization problem using the resource-task-network methodology.\nIn [ 17 ], a multi-objective evolutionary algorithm called the fuzzy logic non-dominated sorting genetic algorithm II (FL-NSGAII) is used to solve a multi-objective optimization problem of vehicle routing in which multiple depots, multiple customers and multiple products are considered; the travelling distance and the total travelling time are the two objective functions to be minimized.\nA random fuzzy multi-objective mixed-integer non-linear programming model for the supply chain design problem has been proposed in [ 18 ], with a spanning tree-based genetic algorithm in order to minimize the total cost and maximize customers service level.\nThe model in [ 19 ] deals with the planning of a multi-product, multi-period and multi-echelon supply chain network that consists of several existing plants at fixed places, some warehouses and distribution centres at undetermined locations, and a number of given customer zones. The supply chain planning model is constructed as a multi-objective mixed-integer linear program to satisfy several conflicting objectives, such as minimizing the total cost, raising the decision robustness in various product demand scenarios, lifting the local incentives, and reducing the total transport time. A two-phase fuzzy decision-making method has been proposed.\nIn [ 20 ], the proposed method is a bi-objective mathematical programming formulation which minimizes the total costs and the expected transportation costs after failures of facilities of a logistics network; a new hybrid solution methodology is introduced by combining the robust optimization approach, queuing theory and fuzzy multi-objective programming.\nIn addition to the above genetic algorithm and fuzzy logic-based supply chain models, several other models have also been proposed in particular based on the swarm-based optimized models. One of the swarm-based model has been proposed on an inventory model for an assembly supply chain network which has fuzzy demand for single products and a fuzzy reliability of external suppliers effect on determination of inventory policy [ 21 ]. The performance of the supply chain is assessed by two criteria including total cost and fill rate. To solve this bi-criteria model, hybridization of multi-objective particle swarm optimization and simulation optimization is considered. In [ 22 ], an optimization mathematical model integrating cost and time criteria has been solved using a modified particle swarm optimization method (MEDPSO) for solving a multi-echelon unbalanced supply chain planning problem. The results indicated that the MEDPSO method can obtain a better quality solution compared to classical GA and PSO.\nFurthermore, another swarm-based optimization model is proposed for a resource options selection problem in a bulldozer supply chain design in [ 23 ]. The model is based on the ant colony optimization technique to solve the multi-objective problem and to find the Pareto solution set where the aim is to find the best combination of the resource options by minimizing the total cost and the total lead-time.\nIn this work, the optimization of the bulldozer supply chain problem given in [ 23 ] has been selected because of the complexity of the supply chain network and its general combinatorial nature that makes it suitable for various supply chain problems, and the bees algorithm (BA), which is another swarm-based optimization technique, is proposed to solve this problem [ 24 ]. The algorithm is based on the food foraging behaviour of a swarm of bees combining a random search with a neighbourhood search. The BA has been successfully applied to several optimization problems [ 25 – 42 ].\nThere is no single algorithm which can find the best solution for all types of optimization problems according to the no-free lunch theorem [ 43 ]. In previous work, the BA has been shown to have better performance compared to the following optimization algorithms tested for continuous type benchmark functions; simplex method, stochastic simulated annealing, genetic algorithm, ant colony optimization [ 44 ]. Hence, the BA has been selected for the bulldozer supply chain problem. Note that the results found by the ant colony optimization in [ 23 ] were not global optimum. The aim of this study is to improve on the previously reported results using a multi-objective optimization approach based on the BA. The bees algorithm has also been proven to be a valid approach to get the Pareto optimal set for multi-objective problems [ 45 – 47 ]. In [ 45 ], the BA has been tested on the classical environmental/economic dispatch problem (EEDP). The EEDP was amended in conjunction with the bees algorithm to identify the best design in terms of energy performance and carbon emission reduction by adopting zero and low carbon technologies. This computer-based tool supports the decision-making process in the design of a low-carbon city. The algorithm is also tested on a welded beam design problem which involves two non-linear objective functions and seven constraints [ 46 , 47 ]. The BA results have been compared with those obtained with the non-dominated sorting genetic algorithm (NGSA) and the NGSAII, and it has been shown that the bees algorithm is able to find more non-dominated solutions.\nThe bees algorithm-based supply chain optimization model is implemented on a resource options selection problem which has been taken from the literature in order to minimize the total cost and the total lead-time of the supply chain. Several numerical experiments have been conducted in order to show the performance of the algorithm on a Pareto solutions set and later compare them to those achieved by the ant colony optimization.\nThis study is organized as follows: the description of the bees algorithm is given in section 2 , the multi-objective optimization with the bees algorithm is given in section 3 , the supply chain case study model is given in section 4 , the experimental study is given in section 5 , the results are given in section 6 and finally conclusions are given in section 7 .\n2. The bees algorithm optimization\nSection:\n2.1. Bees foraging process in nature\nDuring the harvesting season, a bee colony employs part of its population to scout [ 48 , 49 ] the fields surrounding the hive. Scout bees move randomly looking for food sources. When they return to the hive, scout bees deposit the nectar (or pollen) that they have collected during the search process. Then they start to do a ritual called the “waggle dance” to communicate with other bees and give them information about the food source [ 50 ]. The waggle dance is performed on a particular area of the hive called the “dance floor”, and communicates three basic pieces of information regarding the flower patch: the direction in which it is located, its distance from the hive, and its quality rating [ 49 , 51 ]. After the waggle dance, the dancer bee goes back to the flower patch with its followers, called recruited bees. The number of recruited bees depends on the quality rating of the patch. Flower patches that contain rich and easily available nectar or pollen sources attract the largest number of followers (foragers) [ 50 , 52 ]. Once a recruited forager returns to the hive, it will in turn waggle dance to direct other idle bees towards the food source.\n2.2. The bees algorithm\nThe bees algorithm is an optimization algorithm inspired by the natural foraging behaviour of honey bees to find the optimal solution. The flow chart of the algorithm is shown in Figure 1 .\n""","0.21012434","""http://journals.sagepub.com/doi/10.5772/56754""","[-3.533832,50.735262]"
"""Imperial_College_London""","""Advanced Forming Technology for Lightweight Components: From Theory to ApplicationAdvances in Mechanical Engineering - Dae-Cheol Ko, Jianguo Lin, Jun Yanagimoto, Woo-Jin Song, 2014""","""PDF\nThe use of lightweight component is inevitable issue for the protection of global environment. Transportation vehicle with the lightweight component can reduce the emission gas and increase fuel efficiency. First of all, the advanced forming technology is extremely important to fabricate the lightweight component. Knowledge and understanding of this advanced forming technology can lead to the development of the ultralightweight vehicle and, furthermore, can play an important role in fostering the ecofriendly global world.\nThe main objective of this special issue is to collect original research articles as well as review articles that stimulate the continuing efforts to understand the theoretical methodology and the numerical analysis on the advanced forming process and its actual experiment and application, a new insight into the formation of the lightweight component, advanced numerical simulation approach, and state-of-the-art technology in the formation of lightweight component using ultrahigh strength steel, aluminum alloy, magnesium alloy, composites, and so forth.\nIn this special issue, the editors received 30 manuscripts on various topics of advanced forming technology. After peer review and based on the comments from reviewers, 17 manuscripts have been rejected and 13 manuscripts have been accepted. A brief overview of the manuscripts is as follows.\nIn the paper titled “Feasibility study on flexibly reconfigurable roll forming process for sheet metal and its implementation,” J.-S. Yoon et al. proposed a new sheet metal forming process called the flexibly reconfigurable roll forming (FRRF) process as an alternative to existing processes for producing a multicurved sheet metal surface for a skin structure, where adjustable punches and upper and lower reconfigurable rollers as forming tools were used. In the paper titled “Research on integrated casting and forging process of aluminum automobile wheel,” Q. Zhang et al. produced aluminum structure parts, such as aluminum alloy automobile wheel, with complex shape and excellent mechanical properties by using integrated casting and forging process (ICFP) which is a new manufacturing method combining the advantages of both casting and forging. In the paper titled “A study on process design of automobile parts using extruded material by die forming,” D. Kim et al. designed die forming processes with precision dies to manufacture automobile control arm and subframe parts using aluminum extruded. In the paper titled “Research on continuous injection direct rolling process for PMMA optical plate,” H. Wang et al. proposed continuous injection direct rolling (CIDR) combined with intermittent injection and rolling process as a new technology to mold optical polymer plates with microstructured patterns. Based on establishing mathematical CIDR models, numerical analysis was performed to explode the distribution of velocity, temperature, and pressure in injection-rolling zone. In the paper titled “Cooling systems design in hot stamping tools by a thermal-fluid-mechanical coupled approach,” a new multifield simulation method was proposed for the design of hot stamping tools with cooling system by T. Lin et al. based on MpCCI (mesh-based parallel code coupling interface); thermal-fluid simulation and thermal-fluid-mechanical coupled simulation were performed and then the geometrical parameters of the cooling system were investigated for the design. In the paper titled “The effect of process and model parameters in temperature prediction for hot stamping of boron steel,” C. Sun et al. developed finite element models of the hot stamping and cold die quenching process for boron steel sheet, where the effect of tool elasticity and process parameters on work-piece temperature was investigated. In the paper titled “Effect of the die temperature and blank thickness on the formability of a laser-welded blank of a boron steel sheet with removing Al-Si coating layer,” the formability of a laser-welded boron steel sheet to improve crash energy absorption capacity in hot stamped parts was investigated by M. S. Lee et al., where a certain part of Al-Si coating layer was removed by laser ablation to avoid weakening at the welding spot. In the paper titled “Comparative numerical analysis of sheet formed into a V-shaped die using conventional and electromagnetic forming processes,” J. Kim et al. showed that damage suppression due to the tool-sheet interaction was one of the main factors contributing to the increased formability in the electromagnetic forming (EMF) as compared to the conventional forming operation and, additionally, a high level of kinetic energy produced high strain-rate constitutive and inertial, which delayed the onset of necking and increased the formability. In the paper titled “LBW/SPF/DB combined processing and microstructure of TA15 titanium alloy four-layer sandwich structure with square grid,” J. Shaosong et al. produced TA15 titanium alloy sandwich structure with square grid using the process combined laser beam welding, superplastic forming, and diffusion bonding (LBW/SPF/DB) and analyzed the microstructure of different regions before and after superplastic forming. In the paper titled “A research on the creep age forming of 2524 aluminum alloy: springback, mechanical properties, and microstructures,” L. Zhan et al. performed a series of orthogonal tests to investigate the combined effects of aging temperature, time, predeformation, and part thickness features on the springback of creep age formed of 2524 aluminum alloy sheets. In the paper titled “Fabrication of gear having functionally graded properties by direct laser melting process,” S.-W. Han et al. demonstrated the possibility to produce functionally graded properties in gear through the direct laser melting of compositionally selected metallic powders, where properties of manufactured parts depended strongly on each single laser-melted track. In the paper titled “Differential speed rolling to reduce warping in bimetallic slab,” C. H. Lee et al. investigated the effect of differential speed rolling on the reduction of warping by using FEM based on fundamental processing parameters. In the paper titled “Prediction of bending stiffness for laminated CFRP and its application to manufacturing of roof reinforcement,” J.-M. Lee et al. evaluated the effect of the stacking sequence on the bending stiffness and validated it through experiments under the same conditions as the analysis.\nDae-Cheol Ko Jianguo Lin Jun Yanagimoto Woo-Jin Song\n""","0.39211154","""http://journals.sagepub.com/doi/10.1155/2014/649406""","[-0.178219,51.500505]"
"""Imperial_College_London""","""ABC of allergies: Summer hay fever | The BMJ""","""ABC of allergies:...\nABC of allergies: Summer hay fever\nClinical Review\nABC of allergies: Summer hay fever\nBMJ 1998; 316 doi: https://doi.org/10.1136/bmj.316.7134.843 (Published 14 March 1998) Cite this as: BMJ 1998;316:843\nPeer review\nStephen Durham\nSummer hay fever causes considerable morbidity and affects quality of life at a time usually considered as the best of the year. Its prevalence has increased over the past 20 years despite falling pollen counts.\nAntihistamines and nasal corticosteroid sprays are first line treatment\nEnvironmental triggers\nThe main cause of hay fever in Britain is grass pollen, particularly perennial rye (Lolium perenne) and timothy grass (Phleum pratense). Symptoms peak during June and July. Symptoms in spring are commonly due to tree pollens, whereas symptoms in late summer and autumn may be due to weed pollens and mould spores. Rape seed may also provoke symptoms of rhinitis, although usually through irritant rather than allergic mechanisms. It has been suggested that emissions of nitrogen dioxide and ozone from vehicle exhausts have been increasing the sensitivity to airborne allergens.\nPerennial rye grass (Lolium perenne)—common in Britain\nPollen calendar for Britain\nMechanisms of rhinitis\nThe symptoms of rhinitis are caused by an interaction between grass pollen and IgE on the surface of sensitised mucosal mast cells (type 1 hypersensitivity). The cells release mediators such as histamine and leukotrienes, which produce itch, sneeze, watery anterior nasal discharge, nasal congestion, and symptoms affecting the eyes.\nHypothesis on mechanisms of summer hay fever (rationale basis for treatment). IL=interleukin, VCAM=vascular cell adhesion molecules, GM-CSF=granulocyte macrophage colony stimulating factor\nAllergens are also recognised and processed by mucosal dendritic cells (Langerhans' cells) or macrophages, which then stimulate T lymphocytes to release interleukins, which promote tissue eosinophilia and IgE production. These compounds act to produce ongoing rhinitis, symptoms …\n""","0.49061036","""http://www.bmj.com/content/316/7134/843""","[-0.178219,51.500505]"
"""Imperial_College_London""","""An improved version of the Hughes model for pedestrian flow | Mathematical Models and Methods in Applied Sciences , Vol 26, No 04 | World Scientific""","""An improved version of the Hughes model for pedestrian flow\nJose A. Carrillo1, Stephan Martin1, 2, Marie-Therese Wolfram3\n1Department of Mathematics, Imperial College London, London SW7 2AZ, UK\n2Department of Mathematics RWTH Aachen University, 52074 Aachen, Germany\n3Radon Institute for Computational and Applied Mathematics, Austrian Academy of Sciences, Altenberger Strasse 69, 4040 Linz, Austria\nReceived: 28 January 2015\nPublished: 19 January 2016\nCommunicated by N. Bellomo\nRoger Hughes proposed a macroscopic model for pedestrian dynamics, in which individuals seek to minimize their travel time but try to avoid regions of high density. One of the basic assumptions is that the overall density of the crowd is known to every agent. In this paper we present a modification of the Hughes model to include local effects, namely limited vision, and a conviction towards decision making. The modified velocity field enables smooth turning and temporary waiting behavior. We discuss the modeling in the micro- and macroscopic setting as well as the efficient numerical simulation of either description. Finally we illustrate the model with various numerical experiments and evaluate the behavior with respect to the evacuation time and the overall performance.\nKeywords: Hughes model; crowd dynamics; local vision; eikonal equations; self-organization\nAMSC: 35Q91, 35Q70, 35F21, 91C99\nCited by (11):\nPierre Degond , Piotr Minakowski , Ewelina Zatorska .  (2018) Transport of congestion in two-phase compressible/incompressible flows. Nonlinear Analysis: Real World Applications 42, 485-510.  Online publication date: 1-Aug-2018. [Crossref]\nChristophe Chalons , Paola Goatin , Luis M. Villada .  (2018) High-Order Numerical Schemes for One-Dimensional Nonlocal Conservation Laws. SIAM Journal on Scientific Computing 40:1, A288-A305.  Online publication date: 1-Jan-2018. [Crossref]\nElisabetta Carlini , Adriano Festa , Francisco J. Silva , Marie-Therese Wolfram .  (2017) A Semi-Lagrangian Scheme for a Modified Version of the Hughes’ Model for Pedestrian Flow. Dynamic Games and Applications 7:4, 683-705.  Online publication date: 1-Dec-2017. [Crossref]\nCristiana De Filippis , Paola Goatin .  (2017) The initial–boundary value problem for general non-local scalar conservation laws in one space dimension. Nonlinear Analysis 161, 131-156.  Online publication date: 1-Sep-2017. [Crossref]\n""","0.44687402","""http://www.worldscientific.com/doi/abs/10.1142/S0218202516500147""","[-0.178219,51.500505]"
"""Imperial_College_London""","""Cognitive Agent Based Critical Information Gathering and Dissemination in Vehicular Ad hoc Networks | SpringerLink""",""", Volume 69, Issue 4 , pp 1107–1129 | Cite as\nCognitive Agent Based Critical Information Gathering and Dissemination in Vehicular Ad hoc Networks\nAuthors\nM. S. Kakkasageri Email author\nS. S. Manvi\n3 Citations\nAbstract\nNext generation vehicles will have capability of sensing, computing, and communicating capabilities. Different components in a vehicle have to constantly exchange available information with other vehicles on the road and cooperate for the purpose of ensuring safety and comfort using a Vehicular Ad hoc Network (VANET). Critical information like navigation, cooperative collision avoidance, lane-changing, speed limit, accident, obstacle or road condition warnings, etc. play a significant role for safety-related applications in VANET. Such kind of critical information gathering and dissemination is challenging, because of their delay-sensitive nature. This paper proposes an agent based model that consists of heavy-weight static cognitive (based on Belief Desire Intention : BDI) and light-weight mobile agents. Proposed model executes push (gather/store and disseminate) and pull (gather/store) operations on information gathered based on information relevance, criticalness and importance. The simulation results show that BDI based information gathering and dissemination scheme performs better than the reliable broadcast scheme in terms of bandwidth utilization, packet delivery ratio, push latency (information saturation time) and push/pull decision latency.\nKeywords\nVehicular ad hoc networks Cognitive agents BDI architecture \nThis is a preview of subscription content, log in to check access\nPreview\nUnable to display preview.  Download preview PDF.\nReferences\n1.\nCaliskan, M., Mauve, M., Rech, B., & Luebke, A. (2005). Collection of dedicated information in vehicular ad hoc networks. In 12th World congress on intelligent transport systems. San Francisco, USA (pp. 1–12). Google Scholar\n2.\nFubler, H., Moreno, T., Transier, M., Kruger, R., Hartenstein, H., & Effelsberg, W. (2005). Studying vehicle movements on highways and their impact on ad-hoc connectivity. In ACM international conference on mobileComputingandNetworking (MobiCom). Cologne, Germany (pp. 26–27). Google Scholar\n3.\nSchnaufer, S., Fubler, H., Transier, M., & Effelsberg, W. (2006). Vehicular ad-hoc networks: Single-hop broadcast is not enough. In 3rd International workshop on intelligent transportation (WIT 2006). Hamburg, Germany (pp. 49–54). Google Scholar\n4.\nBalon, N., & Guo, J. (2006). Increasing broadcast reliability in vehicular ad hoc networks. In 3rd International workshop on vehicular ad hoc networks (VANET 2006). Los Angeles, USA (pp. 1–2). Google Scholar\n5.\nManvi, S., Kakkasageri, M., Pitt, J., & Rathmell, A. (2006). Multi agent systems as a platform for VANETs. In International conference on autonomous agents and multi agent systems (AAMAS). Hakodate, Japan (pp. 35–42). Google Scholar\n6.\nManvi S., Kakkasageri M., Pitt J. (2009) Multiagent based information dissemination in vehicular ad hoc networks. Mobile Information Systems, IOS Press 5(4): 363–389 Google Scholar\n7.\nManvi S., Kakkasageri M. (2008) Issues in mobile ad hoc networks for vehicular communication. IETE Technical Review 25(2): 59–72 Google Scholar\n8.\nShibata, N. et al. (2006). A method for sharing traffic jam information using inter-vehicle communication. http://ito-lab.naist.jp/themes/pdffiles/060725.shibata.v2vcom06.pdf . Accessed 12 October 2009.\n9.\nKumar, D., Kherani, A., & Altman, E. (2006). Route lifetime based optimal hop selection in VANETs on highway: An analytical viewpoint. IFIP Networking. Coimbra, Portugal (pp. 799–814). Google Scholar\n10.\nJohnson, M., Nardis, L., & Ramchandran, K. (2006). Collaborative content distribution for vehicular ad hoc networks. In Allerton conference on communication, control, and computing. Monticello, USA (pp. 2649–2657). Google Scholar\n11.\nCaliskan, M., Barthels, A., Scheuermann, B., & Mauve, M. (2007). Predicting parking lot occupancy in vehicular ad hoc networks. In 65th IEEE vehicular technology conference (VTC2007). Dublin, Ireland (pp. 277–281). Google Scholar\n12.\nChawathe, S. (2006). Inter-vehicle data dissemination in sparse equipped traffic. In 9th IEEE international conference on intelligent transportation systems (ITSC). Toronto, Canada (pp. 273–280). Google Scholar\n13.\nResta, G., Santi, P., & Simon, J. (2007). Analysis of multi-hop emergency message propagation in vehicular ad hoc networks. In 8th ACM international symposium on mobile ad hoc networking and computing. Montreal, Canada (pp. 140–149). Google Scholar\n14.\nSaxena, N., Basu, K., & Das, S. (2004). Design and performance analysis of a dynamic hybrid scheduling algorithm for heterogeneous asymmetric environments. In 18th International parallel and distributed processing symposium (IPDPS 2004). Santa Fe, New Mexico (pp. 26–30). Google Scholar\n15.\nChuah, M., & Fu, F. (2006). Performance study of robust data transfer protocol for VANETS. In 2nd International conference on mobile ad hoc and sensor networks. Hong Kong (pp. 123–135). Google Scholar\n16.\nNadeem, T., Shankar, P., & Iftode, L. (2006). A comparative study of data dissemination models for VANETs. In 3rd Annual international conference on mobile and ubiquitous systems. San Jose, California, USA (pp. 1–10). Google Scholar\n17.\nMahajan, A., Potnis, N., Gopalan, K., & Wang, A. (2007). Modeling VANET deployment in urban settings. In 10th ACM symposium on modeling, analysis, and simulation of wireless and mobile systems. Greece (pp. 151–158). Google Scholar\n18.\nLochert, C., Scheuermann, B., & Mauve, M. (2007). Probabilistic aggregation for data dissemination in VANETs. In 4th ACM international workshop on vehicular ad hoc networks. Canada (pp. 1–8). Google Scholar\n19.\nCamara, D. et al. (2008). Virtual access points for stream based traffic dissemination. In IEEE Asia-Pacific services computing conference. Yilan, Taiwan (pp. 1628–1632). Google Scholar\n20.\nLee U. et al (2008) Dissemination and harvesting of urban data using vehicular sensing platforms. IEEE Transaction on Vehicular Technology 58(2): 882–901 Google Scholar\n21.\nXu, B. et al. (2007). A feasibility study on disseminating spatio-temporal information via vehicular ad-hoc networks. http://cs.uic.edu/~boxu/mp2p/v2vcom07-final-xu.pdf . Accessed 12 October 2009.\n22.\nPark, S., & Zou, C. (2008). Reliable traffic information propagation in vehicular ad-hoc networks. In IEEE sarnoff symposium. NJ, USA, Princeton (pp. 1–6). Google Scholar\n23.\nOnus, M. et al. (2005). Efficient broadcasting and gathering in wireless ad-hoc networks. In 8th International symposium on parallel architectures, algorithms and networks. Sydney, NSW, Australia (pp. 346–351). Google Scholar\n24.\nCampelli, L., Cesana, M., & Fracchia, R. (2007). Directional broadcast forwarding of alarm messages in VANETs. http://antlab.elet.polimi.it/PUB/WONS2007.pdf . Accessed 14 October 2009.\n25.\nRosi, U., Hyder, C., & Kim, T. (2008). A novel approach for infrastructure deployment for VANET. In 2nd International conference on future generation communication and networking (FGCN ’08). Hainan Island, China (pp. 234–238). Google Scholar\n26.\nAdler, C., & Strassberger, M. (2006). Putting together the pieces—a comprehensive view on cooperative local danger warning. http://www.mobile.ifi.lmu.de/common/..../adst06.pdf . Accessed 21 March 2008.\n27.\nMoukas, A., Chandrinos, K., & Maes, P. (1998). Trafficopter: A distributed collection system for traffic information. In 2nd International workshop on cooperative information agents, learning, mobility and electronic commerce for information discovery on the internet. Paris, France (pp. 33–43). Google Scholar\n28.\nCollins, K., & Muntean, G. (2008). A vehicle route management solution enabled by wireless vehicular networks. In 68th IEEE vehicular technology conference (VTC Fall 2008). Canada (pp. 1–5). Google Scholar\n29.\nMartinez, F., Toh, C., Cano, J., Calafate, C., & Manzoni, P. (2011). Determining the representative factors affecting warning message dissemination in VANETs. Wireless Personal Communications, Springer. doi:  10.1007/s11277-011-0379-3 .\n30.\nMartinez F., Toh C., Cano J., Calafate C., Manzoni P. (2011) A street broadcast reduction scheme (SBR) to mitigate the broadcast storm problem in VANETs. Wireless Personal Communications, Springer 56(3): 559–572 CrossRef Google Scholar\n31.\nChou L., Yang J., Hsieh Y., Chang D., Tung C. (2011) Intersection-based routing protocol for VANETs. Wireless Personal Communications, Springer 60(1): 105–124 CrossRef Google Scholar\n32.\nNetwork Simulator–ns-2. http://www.isi.edu/nsnam/ns . Accessed 25 March 2008.\n46.\nBai, F., Sadagopan, N., & Helmy, A. (2003). Important: A framework to systematically analyze the impact of mobility on performance of routing protocols for ad hoc networks. In 22th IEEE annual joint conference on computer communications and networking (INFOCOM’03) (pp. 825–835). Google Scholar\n47.\nXiuchao, W., & Ananda, A. (2004). Link characteristics estimation for IEEE 802.11 DCF based WLAN. In 29th Annual IEEE international conference on local computer networks (LCN’04). Tampa, USA (pp. 302–309). Google Scholar\n48.\nWiethlter, S., & Hoene, C. (2004). Design and verification of an IEEE 802.11e EDCF simulation model in ns-2.26. In Technical report (pp. 1–44). University of Berlin: Telecommunication Networks Group. Google Scholar\nCopyright information\n© Springer Science+Business Media, LLC. 2012\nAuthors and Affiliations\n""","0.4622468","""https://link.springer.com/article/10.1007%2Fs11277-012-0623-5""","[-0.178219,51.500505]"
"""Brunel_University_London""","""Editorial | Proceedings of the Institution of Civil Engineers - Transport""","""Proceedings of the Institution of Civil Engineers - Transport\nProceedings of the Institution of Civil Engineers - Transport\nISSN 0965-092X | E-ISSN 1751-7710\nPhD, CEng, MCIHT, MICE, PGCHE, FHEA\nx\nDepartment of Mechanical, Aerospace and Civil Engineering, Brunel University, London, UK\nAuthor Affiliations\nPublished Online: July 11, 2016\nKey:\nFree content\nTrial content\nWelcome to the August 2016 issue of Transport. This edition presents six papers covering important theoretical and practical aspects of transportation engineering. On behalf of the editorial board, I thank the authors for their hard work and valuable contributions to the journal. I would also like to extend my appreciation to our esteemed reviewers for their invaluable support.\nTransport networks are one of the most important national assets. Economic prosperity, rapid urbanisation, increasing traffic and ageing infrastructures all have immense impact on safe and efficient operation of this vital asset. Some of these factors are addressed in this issue.\nThe first paper ( Appiah et al., 2016 ) deals with truck characteristics in traffic micro-simulation. The authors present an approach to incorporating the operating characteristics of a local truck fleet in the calibration of micro-simulation models. This approach is different from conventional model calibration where focus is given to adjusting the parameters of driving behaviour logic. The second paper ( Mohapatra et al., 2016 ) reports the influence of conflicting traffic on U-turns at uncontrolled median openings under mixed traffic conditions in an Indian context. With rapid urbanisation and increased traffic volume, most urban roads in India are constructed as multi-lane roads, while many existing two-lane roads are also being widened to multi-lane roads. These multi-lane roads are generally constructed with a raised median, in order to segregate the opposing traffic movements. The authors showed that the impact of conflicting traffic is greater on four-lane roads compared to six-lane roads. In the third paper ( Zong et al., 2016 ), the authors present a model for investigating the feasibility of an integrated transportation demand management (TDM) programme in the Nanhai district of China to mitigate the traffic congestion and reduce exhaust gas emission from motor vehicles. The TDM programme includes a bus priority policy, a motorcycle restriction policy and a congestion pricing policy. The authors demonstrate that all three policies would have a positive effect on Nanhai's transport system. All three papers address key transport issues which traffic engineers and researchers will find very useful.\nIn recent years, railway industries have faced a massive demand for increasing train speeds. However, switch and turnout parts of the track are two critical parts where speed reduction is necessary. In order to develop a more efficient system, the fourth paper ( Sadeghi et al., 2016 ) presents a mathematical model of the impact of railway geometry on the safety of train running and permissible speed. The model is based on the railway vehicle and track parameters such as curve radius, switch initial angle and track gauge with running speed. The model accuracy is verified in field trials. This paper is a good example of how theoretical modelling could help to solve practical issues.\nThe fifth and sixth papers address concrete pavement rehabilitation. The fifth paper ( Lu and Rong, 2016 ), presents the impact of gradation on rubblised Portland cement concrete pavement. Rubblisation is a popular technique for upgrading severely deteriorated concrete pavement. Many previous studies have shown that rubblised concrete with a hot-mix asphalt (HMA) overlay improves pavement performance, especially its cracking resistance. The authors present two studies and demonstrate that if the rubblised gradation matches the requirement for the crushed stone base of the flexible pavement, tensile strains at the HMA overlay bottom develop at a slower pace, indicating an improvement in deterioration resistance (namely cracking) of the overlay system. This article should be a good resource for practitioners and researchers alike. The final paper ( Gao, 2016 ), presents a mathematical model for evaluating the impact of top-down surface cracking in concrete pavement. Surface cracks of concrete pavement not only impact safety and ride quality, but also reduce service life. The author shows that crack length and load position significantly influence the stress intensity factors, and that stress intensity factors are less affected by the elastic modulus of the pavement material than might be expected. Observing that studies on the mechanism of crack propagation in a cement concrete pavement are rather limited, this paper should serve to enhance current knowledge in this field.\nWe trust you find these papers useful and rewarding to read. Comments on this issue or on general journal-related matters will be received with great interest.\nReferences\n""","0.5102945","""http://www.icevirtuallibrary.com/doi/10.1680/jtran.2016.169.4.185""","[-0.472855,51.532848]"
"""Imperial_College_London""","""Keratinocyte growth factor therapy in murine oleic acid-induced acute lung injury | American Journal of Physiology-Lung Cellular and Molecular Physiology""","""Keratinocyte growth factor therapy in murine oleic acid-induced acute lung injury\nK. Ulrich\n1Department of Gene Therapy, National Heart and Lung Institute, and 2Anaesthetics and Intensive Care, Chelsea and Westminster Hospital, and 3Electron Microscopy Unit, National Heart and Lung Institute, Faculty of Medicine, Imperial College London, London; and 4Gene Medicine Research Group, Nuffield Department of Clinical Laboratory Sciences, University of Oxford, United Kingdom\nM. Stern\n1Department of Gene Therapy, National Heart and Lung Institute, and 2Anaesthetics and Intensive Care, Chelsea and Westminster Hospital, and 3Electron Microscopy Unit, National Heart and Lung Institute, Faculty of Medicine, Imperial College London, London; and 4Gene Medicine Research Group, Nuffield Department of Clinical Laboratory Sciences, University of Oxford, United Kingdom\nM. E. Goddard\n1Department of Gene Therapy, National Heart and Lung Institute, and 2Anaesthetics and Intensive Care, Chelsea and Westminster Hospital, and 3Electron Microscopy Unit, National Heart and Lung Institute, Faculty of Medicine, Imperial College London, London; and 4Gene Medicine Research Group, Nuffield Department of Clinical Laboratory Sciences, University of Oxford, United Kingdom\nJ. Williams\n1Department of Gene Therapy, National Heart and Lung Institute, and 2Anaesthetics and Intensive Care, Chelsea and Westminster Hospital, and 3Electron Microscopy Unit, National Heart and Lung Institute, Faculty of Medicine, Imperial College London, London; and 4Gene Medicine Research Group, Nuffield Department of Clinical Laboratory Sciences, University of Oxford, United Kingdom\nJ. Zhu\n1Department of Gene Therapy, National Heart and Lung Institute, and 2Anaesthetics and Intensive Care, Chelsea and Westminster Hospital, and 3Electron Microscopy Unit, National Heart and Lung Institute, Faculty of Medicine, Imperial College London, London; and 4Gene Medicine Research Group, Nuffield Department of Clinical Laboratory Sciences, University of Oxford, United Kingdom\nA. Dewar\n1Department of Gene Therapy, National Heart and Lung Institute, and 2Anaesthetics and Intensive Care, Chelsea and Westminster Hospital, and 3Electron Microscopy Unit, National Heart and Lung Institute, Faculty of Medicine, Imperial College London, London; and 4Gene Medicine Research Group, Nuffield Department of Clinical Laboratory Sciences, University of Oxford, United Kingdom\nH. A. Painter\n1Department of Gene Therapy, National Heart and Lung Institute, and 2Anaesthetics and Intensive Care, Chelsea and Westminster Hospital, and 3Electron Microscopy Unit, National Heart and Lung Institute, Faculty of Medicine, Imperial College London, London; and 4Gene Medicine Research Group, Nuffield Department of Clinical Laboratory Sciences, University of Oxford, United Kingdom\nP. K. Jeffery\n1Department of Gene Therapy, National Heart and Lung Institute, and 2Anaesthetics and Intensive Care, Chelsea and Westminster Hospital, and 3Electron Microscopy Unit, National Heart and Lung Institute, Faculty of Medicine, Imperial College London, London; and 4Gene Medicine Research Group, Nuffield Department of Clinical Laboratory Sciences, University of Oxford, United Kingdom\nD. R. Gill\n1Department of Gene Therapy, National Heart and Lung Institute, and 2Anaesthetics and Intensive Care, Chelsea and Westminster Hospital, and 3Electron Microscopy Unit, National Heart and Lung Institute, Faculty of Medicine, Imperial College London, London; and 4Gene Medicine Research Group, Nuffield Department of Clinical Laboratory Sciences, University of Oxford, United Kingdom\nS. C. Hyde\n1Department of Gene Therapy, National Heart and Lung Institute, and 2Anaesthetics and Intensive Care, Chelsea and Westminster Hospital, and 3Electron Microscopy Unit, National Heart and Lung Institute, Faculty of Medicine, Imperial College London, London; and 4Gene Medicine Research Group, Nuffield Department of Clinical Laboratory Sciences, University of Oxford, United Kingdom\nD. M. Geddes\n1Department of Gene Therapy, National Heart and Lung Institute, and 2Anaesthetics and Intensive Care, Chelsea and Westminster Hospital, and 3Electron Microscopy Unit, National Heart and Lung Institute, Faculty of Medicine, Imperial College London, London; and 4Gene Medicine Research Group, Nuffield Department of Clinical Laboratory Sciences, University of Oxford, United Kingdom\nM. Takata\n1Department of Gene Therapy, National Heart and Lung Institute, and 2Anaesthetics and Intensive Care, Chelsea and Westminster Hospital, and 3Electron Microscopy Unit, National Heart and Lung Institute, Faculty of Medicine, Imperial College London, London; and 4Gene Medicine Research Group, Nuffield Department of Clinical Laboratory Sciences, University of Oxford, United Kingdom\nE. W. F. W. Alton\n1Department of Gene Therapy, National Heart and Lung Institute, and 2Anaesthetics and Intensive Care, Chelsea and Westminster Hospital, and 3Electron Microscopy Unit, National Heart and Lung Institute, Faculty of Medicine, Imperial College London, London; and 4Gene Medicine Research Group, Nuffield Department of Clinical Laboratory Sciences, University of Oxford, United Kingdom\nEmail\nAbstract\nAlveolar type II (ATII) cell proliferation and differentiation are important mechanisms in repair following injury to the alveolar epithelium. KGF is a potent ATII cell mitogen, which has been demonstrated to be protective in a number of animal models of lung injury. We have assessed the effect of recombinant human KGF (rhKGF) and liposome-mediated KGF gene delivery in vivo and evaluated the potential of KGF as a therapy for acute lung injury in mice. rhKGF was administered intratracheally in male BALB/c mice to assess dose response and time course of proliferation. SP-B immunohistochemistry demonstrated significant increases in ATII cell numbers at all rhKGF doses compared with control animals and peaked 2 days following administration of 10 mg/kg rhKGF. Protein therapy in general is very expensive, and gene therapy has been suggested as a cheaper alternative for many protein replacement therapies. We evaluated the effect of topical and systemic liposome-mediated KGF-gene delivery on ATII cell proliferation. SP-B immunohistochemistry showed only modest increases in ATII cell numbers following gene delivery, and these approaches were therefore not believed to be capable of reaching therapeutic levels. The effect of rhKGF was evaluated in a murine model of OA-induced lung injury. This model was found to be associated with significant alveolar damage leading to severe impairment of gas exchange and lung compliance. Pretreatment with rhKGF 2 days before intravenous OA challenge resulted in significant improvements in Po2, Pco2, and lung compliance. This study suggests the feasibility of KGF as a therapy for acute lung injury.\nards (acute respiratory distress syndrome) is a term generally applied to patients with severe manifestations of acute lung injury (ALI) and is characterized by severe alveolar damage. In histopathological terms, this encompasses capillary congestion, interstitial and alveolar edema, hyaline membrane formation, and alveolar type I (ATI) cell necrosis ( 4 ). ATI cells are large, with volumes of ∼3,000 μm3/cell, and each cell forms a thin (∼0.2 μm) cytoplasmic sheet ( 51 ) to facilitate gas exchange, which extends from the nucleus to cover the surface of one or more alveoli. Related to both this morphology and their inability to undergo mitosis and cellular repair, ATI cells are particularly sensitive to damage by injurious agents. The alveolar type II (ATII) cell is cuboidal and contains numerous cytoplasmic organelles, including lamellar bodies, for the cytoplasmic production and storage of surfactant ( 27 ). Importantly, the ATII cell is critical to the repair process following alveolar epithelial injury and has been shown to be involved in a combination of proliferation and differentiation ( 1 ), migration ( 30 , 76 ), and spreading ( 30 ) to cover areas of denuded alveolar epithelium. Thus ATII cell proliferation is believed to be particularly important during repair, as ATII cells differentiate into ATI cells, and thus replace ATI cells lost during the injury phase.\nHuman keratinocyte growth factor (KGF) was first cloned in 1989 from an embryonic fibroblast cell line by Finch et al. ( 19 ). KGF is a heparin-binding growth factor that is secreted by fibroblasts and is known to act via a receptor specific to epithelial cells ( 37 ). KGF induces potent proliferative activity in a variety of epithelial cells including keratinocytes, important to hair follicle development ( 8 ) and skin growth during wound healing ( 35 ). Additionally, KGF stimulates proliferation of mammary ( 62 ) and pancreatic ductal epithelia ( 75 ). Importantly, KGF also stimulates proliferation of ATII cells in vitro ( 47 ) and in vivo ( 18 ). Intratracheal administration of recombinant human KGF (rhKGF) to normal rat lungs results in ATII cell hyperplasia 2 days following administration ( 63 ). This process initially produces a “piled up” appearance to the alveolar epithelium, caused by the increased number of ATII cells. By day 3, however, the newly formed ATII cells appear to migrate outward to cover a larger area of the alveoli, and by day 6, the alveolar epithelium appears normal. However, not all newly formed ATII cells differentiate into ATI cells, and apoptosis has been shown to be involved in maintaining homeostasis between cell populations in the lung ( 18 , 57 ).\nAdministration of exogenous rhKGF has been shown to ameliorate lung injury in a range of animal models. A number of studies have demonstrated that KGF pretreatment resulted in reduced mortality following intratracheal instillation of hydrochloric acid ( 43 , 71 ), intratracheal bleomycin ( 55 , 73 ), hyperoxia ( 5 , 46 ) and Pseudomonas aeruginosa-induced lung injury ( 65 ). Amelioration of both morphological damage to the alveolar epithelium and inflammation has been demonstrated in the bleomycin ( 22 ) and hydrochloric acid models ( 43 , 71 ), P. aeruginosa-induced lung injury ( 65 ), and hyperoxia-induced lung injury ( 5 , 46 ). Exogenous KGF upregulates active ion transport by increasing the expression of sodium pumps, primarily the Na+-K+-ATPase α1-subunit ( 6 ). Thus in the α-naphthylthiourea model of acute permeability edema, KGF administration reduced lung wet-to-dry weight ratios and bronchoalveolar lavage (BAL) protein ( 21 , 36 ). Both of these effects were also demonstrated in P. aeruginosa-induced ( 65 ) and ventilator-induced lung injury ( 67 ).\nThe protective effects of KGF observed in the above studies suggest that, in addition to ATII cell hyperplasia, KGF may have many other beneficial effects on ALI. These may include scavenging of reactive oxygen species and increased DNA repair ( 59 , 69 ). Additionally, KGF has been implicated in the reduction of alveolar epithelial susceptibility to mechanical deformation in vitro ( 44 ), possibly related to changes in the cytoskeleton or the extracellular matrix. Furthermore, KGF accelerates the rate of wound closure during mechanical deformation in various cell lines and primary cells by a combination of increased cell migration rate and cell spreading ( 20 , 66 ). Atabai et al. ( 2 ) demonstrated that KGF-treated cells were more adherent to the extracellular matrix. Enhanced epithelial cell adherence to the denuded basement membrane may provide more rapid restoration of the alveolar architecture following lung injury ( 49 ). KGF also directly affects the expression of surfactant ( 70 ) and has been shown to stimulate the synthesis of all surfactant components in rat fetal ATII cells, thereby promoting maturation of the lung epithelium ( 7 ).\nThese studies raise the possibility that exogenous recombinant KGF protein might be used to stimulate alveolar epithelial repair in ALI and thus become a future therapy for ARDS. However, the significant cost of large quantities of rhKGF would likely limit the possibilities of prophylactic studies, particularly in larger animals and humans. Gene therapy, in which transfer of KGF DNA to alveolar epithelial cells may result in prolonged protein expression, has been proposed as an alternative approach. Thus, topical or systemic application of KGF-encoding plasmid DNA, complexed with cationic liposomes, may result in sufficient expression to produce ATII cell proliferation. Recently, the feasibility of this approach was demonstrated by Jeschke et al. ( 28 ) using liposome-mediated KGF gene transfer to improve dermal and epidermal regeneration following thermal injury in rats.\nSeveral experimental models of lung injury have been developed that demonstrate pathophysiological changes similar to those in ARDS ( 50 ). ALI induced by intravenous administration of oleic acid (OA) resembles ARDS in many morphological, histological, and physiological respects (reviewed in Ref. 53 ). OA-induced lung injury has been studied in many laboratory animal species and is consistently associated with severe respiratory distress characterized by hypoxemia and reduced lung compliance due to acute alveolar damage, intra-alveolar hemorrhage, and leakage of proteinaceous fluid into the air spaces ( 10 , 58 ). Histological changes include intra-alveolar edema and hemorrhage, epithelial disruption, fibrin deposition, and formation of hyaline membranes ( 11 , 29 , 52 ). The model has, however, not been well characterized in mice. Gene therapy for ARDS remains a relatively unexplored possibility, and mice have been used extensively as models of gene transfer to the lungs. With a view to investigating the potential of KGF gene therapy for ARDS, we therefore characterized a murine model of OA-induced lung injury and subsequently assessed the potential of both recombinant KGF protein and liposome-mediated gene transfer to ameliorate alveolar damage. For the latter, we assessed both topical and systemic administration, since KGF is a secreted protein, which may produce its biological effects whether produced by alveolar epithelium or pulmonary endothelium.\nMATERIALS AND METHODS\nPlasmid DNA\nThe human KGF (hKGF) cDNA was kindly supplied by Stuart Aaronson (Derald H. Ruttenberg Cancer Center, Mount Sinai School of Medicine, New York, NY) as a 2.1-kb insert in a pCEV9 backbone. The hKGF insert was excised from the pCEV9 backbone by restriction enzyme digestion and ligated into the eukaryotic expression vector pCI (Promega). The resulting plasmid was termed pCIhKGF. Evaluation of in vivo transfection efficiency was carried out using a plasmid expressing the reporter gene chloramphenicol acetyltransferase (pCF1CAT), kindly supplied by Genzyme (Framingham, MA). Large-scale purification of plasmid DNA for in vivo gene transfer was carried out using Qiagen EndoFree Giga plasmid purification columns according to the manufacturer's recommendations (Qiagen, Crawley, UK).\nIntratracheal Administration of rhKGF\nExperiments were carried out under the guidelines of the Animals (Scientific procedures) Act 1986, United Kingdom. Male BALB/c mice (6–8 wk, 19–25 g, Harlan) were anesthetized with Hypnorm/Midazolam/water (Hypnorm:MZ:H2O; 1:1:3, 0.1 ml/10 g body wt). The trachea was visualized by blunt dissection and KGF (Amgen, Thousand Oaks, CA), and 1, 5, 10, or 15 mg/kg body wt was injected directly into the trachea in a volume of no more than 60 μl. Control animals received an equal volume of KGF reconstitution solution (sterile H2O, 0.0055% Tween 20, Amgen). The incision was closed with two sutures using 6/0 silk braided suture (Johnson & Johnson, Edinburgh, UK), and the animals were left in a heated cage at 30°C until they fully recovered from the anesthetic. Analgesic (Vetagesic, 1 in 100 dilution, 6 μl/g body wt) was administered before surgery.\nImmunohistochemical Quantification of ATII Cell Proliferation\nAt appropriate time points (24 h to 1 wk) following rhKGF administration, animals were killed by dorsal arteriosection under terminal anesthesia, the trachea was cannulated, and the lungs expanded with 800–900 μl of 10% formalin (Sigma, Poole, UK). The lungs were removed in toto, immersed in 10% formalin, fixed overnight at room temperature, processed, and embedded in paraffin wax. Serial 4- to 5-μm sections were cut, and the first section was stained with Harris's hematoxylin and eosin (BDH, Lutterworth, UK) for overall morphology. ATII cells were stained with a rabbit anti-sheep surfactant protein B (SP-B) polyclonal antibody (Chemicon International, Southampton, UK). The SP-B antibody binds to the surfactant producing lamellar bodies within the ATII cell, which following binding to a secondary detection antibody can be visualized as a characteristic brown stain. The antibody also stains SP-B within Clara cells in the airways and any SP-B that has been engulfed by alveolar macrophages. However, airways were not included in the quantification process, and alveolar macrophages are morphologically and spatially distinct from ATII cells. Cross-reactivity was therefore not a confounding problem. Briefly, paraffin-embedded sections were dewaxed, and endogenous peroxidase activity was blocked with 3% H2O2. This was followed by 2-h incubation with normal goat serum (DAKO, Ely, UK). Primary antibody binding [rabbit anti-sheep SP-B (Chemicon)] was carried out for 1.5 days at 4°C, followed by binding of biotinylated goat anti-rabbit IgG secondary antibody for 1 h, incubation with streptavidin-horseradish peroxidase (DAKO) for 1 h, and incubation in 3,3′-diaminobenzidine tetrahydrochloride (DAKO) for 15 min. The slides were counterstained in Mayer's hematoxylin (BDH) for 1–2 min and then washed, dehydrated in graded alcohol, and mounted with DPX mountant (BDH). Immunoreactive ATII cells were identified as cells with brown staining within the cytoplasm and quantified by counting 10 randomly selected fields of view per slide (×200, 1 slide/animal). All slides were evaluated in a blinded fashion.\nTopical Gene Transfer\nPreparation of lipid67/KGF pDNA complexes.\nThe cationic liposome GL67 (Genzyme) was rehydrated in sterile endotoxin-free water to a final concentration of 1.2 mM. Plasmid DNA was resuspended in sterile endotoxin-free water to a final concentration of 1.6 mg/ml. Equal volumes of DNA and lipid were incubated separately at 30°C for 5 min to equilibrate temperature. Subsequently, the lipid was gently added to the DNA. The mixture was left to complex at 30°C for 15 min.\nIntranasal instillation of vector-DNA complexes.\nAnimals were individually anesthetized with methoxyflurane (Metofane; Mallingckrodt Veterinary, Mundelein, IL) in a closed chamber and held vertically while pressure was applied to the lower mandible to immobilize the tongue and prevent swallowing. Lipid-DNA complexes (80 μg pCIhKGF complexed with 120 μg GL67 in a total volume of 100 μl) were applied dropwise onto the nostrils of the animal with a pipette, allowing the mixture to be inhaled naturally. Control animals received the same volume of lipid complexed with an irrelevant plasmid (pCF1CAT).\nSystemic Gene Transfer\nPreparation of lipid and DNA.\nSequential injection of lipid and DNA was carried out as described by Tan et al. ( 60 ). Lipid [1,3-dioleoyl-3-trimethylammonium propane (DOTAP)/cholesterol in a 1:1 molar ratio, kindly supplied by Dr. Leaf Huang, Pittsburgh, PA] was diluted with 5% dextrose to contain 900 nmol of lipid in 100 μl. DNA (pCIhKGF or pCF1CAT) was prepared with sterile water to contain 50 μg in 100 μl.\nSequential injection of lipid and DNA.\nAnimals were anesthetized with Avertin (2.5%, 0.1 ml/10 g), the tail was heated transiently with warm water, and 100 μl of lipid solution (900 nmol) were injected into the tail vein. Two minutes later, 100 μl of the DNA (50 μg, pCIhKGF or pCF1CAT) solution were injected in a similar manner, and the animal was left to recover from the anesthetic in a heated cage at 30°C.\nTaqMan RT-PCR for Detection of Vector-Specific Expression\nWhole lungs were submerged in RNAlater (Ambion, Huntingdon, Cambridgeshire, UK) and stored at 4°C until further analysis. Samples were homogenized in 4 ml of RLT (Qiagen) before extraction of total RNA using RNeasy mini protocol (Qiagen). Levels of plasmid-derived mRNA were quantified by real-time quantitative multiplex TaqMan RT-PCR using the ABI Prism 7700 Sequence Detection System and Sequence Detector version 1.6.3 software (Applied Biosystems, Warrington, Cheshire, UK). The oligonucleotide primer and fluorogenic probe sequences were designed using Primer Express Software version 1.0 (Applied Biosystems). Plasmid-specific mRNA from the pCIhKGF was quantified using forward primer (5′-GCTTCTGACACAACAGTCTCGAA-3′), reverse pCI primer (5′-GGAGTGGACACCTGCCCA-3′), and the fluorogenic pCI probe (5′-FAM-TGCCTCACGACCAACTTCTGCAGC-TAMRA-3′). 18S ribosomal RNA was quantified using Ribosomal RNA Control Reagents (Applied Biosystems).\nRNA was heated to 75°C for 5 min and then reverse transcribed with TaqMan RT reagents (Applied Biosystems). The RT-reaction mix (5 μl) consisted of 1× TaqMan RT buffer, 5.5 mM MgCl2, 500 μM each dNTP, 0.4 U/μl RNase inhibitor, 1.25 U/μl MultiScribe reverse transcriptase, 0.4 μM pCI reverse primer, 0.4 μM reverse rRNA primer, and ∼5 ng total RNA. Reactions were incubated at 48°C for 30 min followed by 95°C for 5 min. Subsequently, triplicate 25-μl PCRs were performed for each sample. Each 25-μl reaction consisted of 1× TaqMan Universal PCR Mastermix (Applied Biosystems), 300 nM forward pCI primer, 300 nM reverse pCI primer, 100 nM pCI probe, 50 nM forward rRNA primer, 50 nM reverse rRNA primer, 50 nM rRNA probe, and 5 μl reverse-transcribed template. Reactions were incubated at 50°C for 2 min and then 95°C for 10 min followed by 40 cycles of 95°C for 15 s and 60°C for 1 min.\nControls included no template and no reverse transcriptase control in which total RNA or MultiScribe reverse transcriptase and RNase inhibitor were omitted from the reverse transcriptase reaction, respectively. Relative levels of plasmid-derived mRNA were determined using the ΔCT method (as described in Ref. 1a ). In this study, the amount of pCI plasmid was normalized to 18S rRNA (endogenous reference) and expressed relative to a calibrator that was used throughout the study. The calibrator was total RNA extracted from mouse lung treated with 100 μg of pCIkLux in 150 μl via intranasal instillation (as described above) and harvested 24 h postdose.\nDetection of Transgene Expression\nKGF expression in lung homogenate.\nKGF ELISA was carried out using ELISA development reagents according to the manufacturer's recommendations (R&D Systems, Abingdon, UK). Lung homogenates (100 μl) from KGF-transfected mice or rhKGF standards were tested. Absorbance was determined in a microplate reader at 450 nm (wavelength correction 540 and 570 nm). The KGF concentration was calculated from a standard curve using known amounts of hKGF (1,000 pg/ml to 15.6 pg/ml) correlated to amount of protein detected in the lung homogenate.\nInduction of Lung Injury\nMale BALB/c mice (6–8 wk, 19–25 g; Harlan, Bicester, UK) were anesthetized with Avertin (2.5%, 0.1 ml/10 g). The trachea was visualized by blunt dissection, and the animal was intubated via the oral route with a 22-gauge cannula (3S Healthcare, London, UK). Mechanical ventilation (120 strokes/min, stroke volume 200 μl) was carried out using a MiniVent (type 845; Hugo Sachs Elektronik). OA (0.2 ml/kg or 0.4 ml/kg body wt; Sigma, Poole, UK) suspended in 50 μl of sterile PBS was administered through the tail vein with a 0.5-ml insulin syringe (3S Healthcare). Control animals received 50 μl of PBS. Animals were monitored for the 1-h duration of the experiment and then killed by anesthetic overdose.\nLung Wet-To-Dry Weight Ratios\nLungs were removed in toto at the end of the experiment. The trachea and esophagus were separated from the lungs by blunt dissection, and the wet weight of the latter was determined. Subsequently, the lungs were incubated at 55°C overnight to remove all moisture. The dry weight was then measured, and the ratio of wet-to-dry weight was calculated.\nBAL\nThe animal was extubated, and a 22-gauge cannula (3S Healthcare) was inserted into the trachea. The lungs were lavaged with 500 μl of PBS three times (total volume 1.5 ml). Retrieval volume was maximized by compression of the thorax following the last lavage.\nTotal Cell Counts\nBAL fluid (BALF) samples were centrifuged at 900 relative centrifugal force (gav) for 5 min at 4°C, the supernatant was removed, and the pellet was resuspended in 100 μl of PBS. Ten microliters of the cell suspension were stained with crystal violet stain (BDH), and nucleated cells were counted in a Neubauer hemocytometer. A total of 0.5 × 106 cells in a volume of 100 μl of PBS were centrifuged (Cytospin 3; Shandon, Astmoor, UK) onto slides (700 gav for 4 min) and stained for 5 min with May and Grunwald and Giemsa stains (BDH). The slides were quantified for macrophages, neutrophils, and lymphocytes by counting a total of 200 cells/slide at ×25 magnification.\nMacrophage Inflammatory Protein-2 in Lung Homogenates\nMacrophage inflammatory protein-2 (MIP-2) levels were measured using a precoated murine MIP-2 colorimetric sandwich ELISA kit (R&D Systems) according to the manufacturer's recommendations. The MIP-2 concentration in the lung homogenate supernatant was calculated from a standard curve using known amounts of murine MIP-2 in a range from 7.8 pg/ml to 500 pg/ml.\nBALF\nTotal protein and lactate dehydrogenase measurements.\nThe total protein concentration in the BALF supernatant was measured by the Folin-Lowry method ( 48 ). Lactate dehydrogenase (LDH) levels were determined by the rate of pyruvate substrate conversion to lactate according to the manufacturer's recommendations (Sigma Diagnostics, Poole, UK).\nAlbumin estimation.\nTo quantify the leak of albumin from the serum into the alveoli, the albumin concentration in the BAL supernatant was measured. This was carried out according to the manufacturer's recommendations (Sigma Diagnostics). The absorbance was measured spectrophotometrically at 628 nm (Unicam UV1; Thermo Electron Spectrometry, Cambridge, UK). The albumin concentration in the samples was calculated from a standard curve generated by using known amounts of murine albumin (Sigma) in the range of 5–100 mg/ml.\nQuantification of Lung Injury\nLight microscopy.\nAll slides were coded and evaluated in a blinded fashion to prevent bias. A point scoring system was used to quantify the extent of lung injury and was defined semiquantitatively as the presence of any one of: 1) capillary congestion; 2) alveolar/interstitial edema; 3) presence of fibrin; 4) alveolar/interstitial hemorrhage; 5) necrosis; or 6) alveolar/interstitial neutrophils. The mean % damage score for an animal was calculated by counting a total of 24 randomly selected fields/slide (×200 magnification) for one section. For quantification, each field of view was required to contain >50% alveolar tissue.\nTransmission electron microscopy.\nThe lungs were inflated with fixative (2.5% glutaraldehyde, 50 mM sodium cacodylate buffer) in situ to a constant pressure of 25–30 cm and removed in toto into fixative and stored at 4°C for a minimum of 24 h. Samples of parenchyma of the left lobe and right upper lobe were postfixed in 1% osmium tetroxide in 50 mM sodium cacodylate buffer, dehydrated in graded alcohol and propylene oxide, and subsequently embedded in Araldite epoxy resin. Blocks were initially cut as semithin sections (1 μm) on a Reichart Ultracut E and stained with 1% toluidine blue (in 1% sodium tetraborate) for the purposes of orientation and initial morphological assessment. Ultrathin (80–100 nm) sections were cut, contrasted with uranyl acetate and lead citrate, and examined with a Hitachi 7000 transmission electron microscope.\nPhysiological Measurements of Lung Function: Dosing Optimization\nAdministration of OA for the physiological measurements of lung function was undertaken via a catheter placed in the jugular vein, as tail vein administration proved difficult and unreliable due to the experimental set up needed for lung function measurements. More efficient OA delivery is likely through the jugular compared with the tail vein. In keeping with this, administration of 0.2 ml/kg through the jugular vein resulted in 100% mortality within 1 h, equivalent to that seen with 0.4 ml/kg through the tail vein. Reduction of the jugular dose to 0.1 ml/kg prevented premature deaths over the 1-h time period, as was the case for 0.2 ml/kg administration by tail vein injection. Thus 0.1 ml/kg was used for all studies of lung mechanics and blood gas analysis.\nPhysiological Measurements of Lung Function\nLung physiological measurements were carried out as previously described in detail by Wilson et al. ( 68 ). In brief, male BALB/c mice (8–10 wk, 22–28 g, Harlan) were anesthetized by intraperitoneal injection of Hypnorm/Midazolam (Hypnorm:MZ:water 1:1:3, 0.1 ml/10 g) and placed in the supine position. An endotracheal cannula [0.76-mm inner diameter (ID), 1.22-mm outer diameter (OD)] was inserted via tracheotomy and secured with a suture. Animals were ventilated with a custom-made mouse jet ventilator system, as described by Ewart et al. ( 17 ). Airway pressure was monitored by a pressure transducer (MLT0380; ADInstruments, Chalgrove, UK), and airway flow was determined by a differential pressure transducer (PX137; OMEGA Engineering, Manchester, UK) connected to a miniature pneumotachogram in the ventilator circuit. A polyvinyl chloride (PVC) catheter (0.28-mm ID, 0.6-mm OD; Critchley Electrical Products, Silverwater, Australia) was introduced into the left carotid artery for monitoring arterial pressure using a pressure transducer (MLT844, ADInstruments) and measurement of blood gases. Rectal temperature was maintained between 36 and 37°C by the use of a heated pad. All data collected from the ventilator and blood pressure transducers during the experiment were recorded by PowerLab Data Recording System (ADInstruments).\nAfter standardization of volume history of the lungs with a sustained inflation of 35 cm/H2O for 5 s, the animals were ventilated with a tidal volume of 9–10 ml/kg, a respiratory rate of 120 breaths/min, and inspiratory:expiratory ratio of 1:2 throughout the experiment. Administration of OA was carried out via a jugular vein cutdown and cannulation. Briefly, 0.1 ml/kg of OA was loaded into 0.28-mm single-lumen PVC tubing (Critchley Electrical Products) and connected to the jugular vein line with a 30-gauge needle. OA was infused at a controlled rate using a syringe pump (0.3 ml/h, KD Scientific). Control animals received an equal volume of sterile PBS. Respiratory system compliance and resistance were measured every 15 min by the end-inflation occlusion technique. Blood gas analyses were made on serial arterial blood samples (60 μl) collected via the carotid cannula before and at 30 min and 1 h after OA administration and analyzed by a fetal scalp blood gas analyzer (Chiron Rapidlab 248; Bayer Diagnostics, Newbury, UK).\nStatistical Analysis\nData are cases represented in summary plots that are based on the median, quartiles, and extreme values. The box represents the interquartile range, which contains the 50% of values. The whiskers are lines that extend from the box to the highest and lowest values, excluding outliers, which are defined separately with circles. A line across the box indicates the median. Selected data (see Figs. 3A and 4 ) are represented as dot plots or as median ± first and third data quartile (see Fig. 9 ). Comparison of data between groups used the Kruskal-Wallis analysis of variance for multiple unpaired, nonparametric groups, followed (where permitted) by Mann-Whitney's U-test, with the Bonferroni correction for multiple comparisons. The null hypothesis was rejected at P < 0.05.\nRESULTS\nrhKGF Produces A Dose- and Time-Related Increase in ATII Cells\nIntratracheal instillation of rhKGF at 1–15 mg/kg body wt resulted in a significant (P < 0.01 for all groups) increase in SP-B-positive cells compared with animals receiving diluent alone 2 days following administration ( Fig. 1A ). The KGF-induced increase in ATII cell numbers was dose related with a peak of proliferation following 10 mg/kg of rhKGF [23 ± 2.7 compared with 8.2 ± 1 ATII cells/field of view (×200 magnification) following administration of diluent]. Representative images of SP-B immunohistochemical staining in animals receiving the diluent alone or rhKGF at 10 mg/kg body wt are shown in Fig. 2 . To ensure SP-B antibody specificity, morphological counting of ATII cells using hematoxylin and eosin-stained sections was also carried out. Significantly (P < 0.01) increased numbers of ATII cells were seen at all KGF doses (1 mg/kg, 15.2 ± 3.4; 5 mg/kg, 21.5 ± 5.2; 10 mg/kg, 28.4 ± 3.6; 15 mg/kg, 28.3 ± 2.2 compared with 10.1 ± 1.4 in animals receiving the diluent). In agreement with SP-B immunohistochemistry, 10 mg/kg produced the peak effect.\nFig. 1.Dose response (A) and time course (B) of alveolar type II (ATII) cell proliferation following intratracheal administration of recombinant human keratinocyte growth factor (rhKGF; 10 mg/kg). ATII cell numbers were determined by surfactant protein B (SP-B) immunohistochemistry (n = 6–8 animals for each group). *P < 0.05, **P < 0.01, and ***P < 0.001 compared with animals receiving the diluent only.\nDownload                 figure Download PowerPoint\nThe time course of KGF-induced proliferation was examined using 10 mg/kg of rhKGF and resulted in significantly (P < 0.01) increased SP-B-stained ATII cells at days 1, 2, 3, and 7 following administration compared with control animals receiving diluent alone ( Fig. 1B ). The number of SP-B-positive cells peaked at day 2 following rhKGF administration [26.0 ± 2.7 compared with 9.0 ± 0.6 ATII cells/field of view (×200 magnification) in animals receiving diluent alone]. By day 7, ATII cells counts were significantly (P < 0.01) decreased compared with day 2 (15.4 ± 2.3 ATII cells/field of view) but were still significantly (P < 0.05) increased compared with control animals at the same time point.\nTo exclude rhKGF-induced toxicity, hematoxylin and eosin-stained tissue sections from animals receiving 1, 5, 10, and 15 mg/kg of rhKGF obtained at day 2 were examined for the presence of edema, hemorrhage, and neutrophils. Approximately 10% of the total area from each lung section was found to include one or more of the above-mentioned parameters. However, no increase in lung damage compared with control animals was demonstrable in lung tissue following rhKGF administration (data not shown).\nTopical Administration of Liposome-KGF DNA Complexes Produces KGF mRNA, Protein, and ATII Cell Proliferation\nmRNA.\nTo circumvent the problem of detection of contaminating plasmid DNA, pCI-specific mRNA was amplified by TaqMan PCR, and relative expression was calculated by comparison to expression levels following intranasal instillation of a known standard (100 μg pCIKLux). Significant (P < 0.01) relative expression of pCIhKGF-specific mRNA was demonstrated 24 and 48 h following intranasal administration of 80 μg of pCIhKGF complexed with GL67 compared with untransfected animals ( Fig. 3A ).\nFig. 3.Shown is pCI-specific TaqMan PCR amplification following intranasal instillation of pCIhKGF/GL67 (A, 80 μg). Relative expression is compared with intranasal instillation of a known standard, 100 μg of pCIKLux (n = 6 animals for each group). **P < 0.01 compared with untransfected animals. Note log scale of y-axis. ATII cell quantification is shown using SP-B immunohistochemistry following intranasal liposome-mediated (GL67) gene transfer of pCIhKGF (B, 80 μg; n = 6 animals for each group).\nDownload                 figure Download PowerPoint\nProtein.\nIn lung homogenate, low levels of KGF were detected in pCIhKGF/GL67-transfected animals by ELISA (21.5 ± 5.7 pg/mg protein at 48 h and 21.5 ± 13.8 pg/mg protein at 72 h), with a threshold sensitivity level of the ELISA of 5 pg/ml.\nATII cell quantification.\nIntranasal instillation of pCIhKGF/GL67 (80 μg) did not result in significantly increased ATII cell numbers as quantified by SP-B immunohistochemistry ( Fig. 3B ). However, morphological ATII cell counts revealed a significant (P < 0.05) increase in ATII cell numbers 72 and 96 h following intranasal transfection [15.2 ± 4.4 and 15.3 ± 3.9 ATII cells/field of view (×200 magnification) compared with 8.1 ± 1.9 in animals receiving an irrelevant plasmid].\nSystemic Administration of Liposome-KGF DNA Is Toxic But Able To Produce KGF mRNA and ATII Cell Proliferation\nLipid-mediated gene transfer resulted in high mortality (15–40%) after intravenous injection in both pCIhKGF- and pCF1CAT-transfected animals. Thus group sizes were not consistently large enough to allow for statistical analysis.\nmRNA.\npCI-specific mRNA was amplified by TaqMan PCR, and relative expression was calculated by comparison to expression levels following intranasal instillation of a known standard (100 μg of pCIKLux). Significant (P < 0.01) relative expression of pCIhKGF-specific mRNA was demonstrated 8 and 24 h following intravenous administration of pCIhKGF (50 μg) and 2 min after injection of 900 nmol of DOTAP/cholesterol compared with untransfected animals ( Fig. 4A ).\nFig. 4.Shown is pCI-specific TaqMan PCR amplification following sequential intravenous injection of 1,3-dioleoyl-3-trimethylammonium propane (DOTAP)/cholesterol and pCIhKGF (A, 50 μg). Relative expression is compared with intranasal instillation of a known standard, 100 μg of pCIKLux (n = 6 animals for each group). **P < 0.01 compared with untransfected animals. Note log scale of y-axis. ATII cell quantification is shown using SP-B immunohistochemistry following intravenous delivery of DOTAP/cholesterol and pCIhKGF (B, 50 μg; n = 2–4 for each group).\nKGF could not be detected in homogenate following intravenous transfection with pCIhKGF/DOTAP/cholesterol.\nATII cell quantification.\nSequential intravenous gene transfer of pCIhKGF/lipid was associated with an increase in ATII cell numbers 48, 72, and 96 h after transfection as demonstrated by SP-B immunohistochemistry ( Fig. 4B ). However, due to the high mortality following intravenous gene transfer, the number of animals in each group was low, and statistical testing was not appropriate. A similar trend was observed following morphological counts [12.4 ± 1.4 at 24 h, 14.4 ± 2.7 at 48 h, 14.3 ± 1.9 at 72 h, 17 ± 0.3 at 96 h compared with 8.7 ± 1 ATII cells/field of view (×200 magnification) in animals receiving an irrelevant plasmid]. Pooling of data obtained from all time points (24, 48, 72, and 96 h) showed a significant (P < 0.01) increase in ATII cell numbers by SP-B immunohistochemistry (12.9 ± 3.7 ATII cells/field of view compared with 8.7 ± 1.6 in controls animals), which was supported by morphological assessment (14.3 ± 2.3 ATII cells/field of view compared with 8.6 ± 2.2 in control animals).\nOA Produces A Dose-Related Increase in ALI\nMacroscopic changes following OA administration.\nA dose-related difference in mortality was observed in animals treated with 0.2 and 0.4 ml/kg of OA, respectively. The higher dose was associated with 100% mortality, with death usually occurring 30–40 min following OA administration. The animals appeared cyanotic, and bloody fluid spilled out of the trachea upon extubation. At postmortem, the lungs were grossly enlarged, and severe hemorrhage affected nearly all of the lung surface. In contrast, no deaths occurred within 1 h following administration of 0.2 ml/kg of OA. At this dose, the injury appeared patchy and less severe and was commonly found at the periphery of the lung lobes. The lungs were enlarged, and bloody fluid was often found in the trachea.\nWet-to-dry weight ratios.\nIntravenous administration of OA (0.2 and 0.4 ml/kg body wt) was associated with a significant (P < 0.01) increase in the lung wet-to-dry weight ratios ( Fig. 5A ) compared with ventilated control animals receiving only PBS. This effect was not dose related. Furthermore, compared with untreated nonventilated animals, control animals that were ventilated and received intravenous PBS also had significantly (P < 0.01) increased wet-to-dry weight ratios.\nFig. 5.Lung wet-to-dry weight ratio (A), total cell counts (B), protein (C), and lactate dehydrogenase (LDH) activity (D) in bronchoalveolar lavage fluid (BALF) following intravenous oleic acid (OA); n = 6–9 each group. *P < 0.05, **P < 0.01, and ***P < 0.001 compared with ventilated, PBS-injected controls; ++P < 0.01 compared with 0.4 ml/kg of OA.\nDownload                 figure Download PowerPoint\nBALF cell counts.\nBALF total cell counts were significantly increased in animals treated with 0.2 (P < 0.001) and 0.4 ml/kg (P < 0.01) of OA compared with control animals receiving intravenous PBS alone ( Fig. 5B ). Again, ventilated PBS-treated animals also had significantly (P < 0.05) increased cell counts compared with nonventilated animals. Differential cell counts showed a small increase in % neutrophils (0.2 ml/kg, 3.3 ± 0.4% compared with 1.3 ± 0.4%, P < 0.05; 0.4 ml/kg, 1.25 ± 0.31%) compared with PBS controls. MIP-2, a proinflammatory cytokine that is chemotactic for neutrophils, was detected by ELISA in lung homogenates from animals treated with 0.2 ml/kg of OA and was significantly (P < 0.01) increased compared with untreated baseline animals (135.3 ± 21.4 pg/mg of protein compared with 32.2 ± 8.8 pg/mg of protein) but was not increased following 0.4 ml/kg of OA (60 ± 15.4 pg/mg of protein).\nBALF protein and LDH.\nAdministration of OA was associated with a dose-related increase in total protein concentration measured in BALF supernatants ( Fig. 5C ). Thus compared with control animals receiving PBS alone, BALF total protein was significantly (P < 0.001 and 0.01, respectively) higher in animals receiving the 0.2 and 0.4 ml/kg of OA. Again, compared with baseline untreated animals, a small but significant (P < 0.01) increase in total BALF protein was detected in ventilated animals that received PBS alone. This was associated with an increase in BALF supernatant albumin (0.2 ml/kg OA, 0.25 ± 0.00 μg/μl; 0.4 ml/kg OA, 0.25 ± 0.00 μg/μl compared with undetectable levels in control animals). BALF supernatant LDH activity, a marker of local cell damage, was significantly (P < 0.01) increased in a dose-related manner in animals injected with OA ( Fig. 5D ) compared with ventilated control animals given PBS alone.\nLung histology.\nCompared with untreated animals and ventilated PBS controls, OA (0.4 ml/kg) induced a significant (P < 0.01) increase in histological lung damage ( Fig. 6 ). The principal histological changes seen included the presence of fibrin in the alveolar spaces, hemorrhage, and necrosis of alveolar tissues ( Fig. 6B ). Whereas alveolar fibrin, hemorrhage, and necrosis were barely detectable in sections examined from the lungs of untreated or PBS control animals ( Fig. 6A ), all three features were significantly (P < 0.05) increased in lung sections from the OA-treated animals ( Fig. 6C ).\nFig. 6.Histological quantification of lung injury following intravenous OA (n = 6 animals for each group). Sections of hematoxylin and eosin-stained lung tissue were examined under light microscopy, and damage was recorded using the parameters described in materials and methods. A: section from control animals receiving intravenous PBS (×200) showing alveolar spaces free of cell debris and fibrin, with no evidence of hemorrhage or necrosis. B: OA administration (0.2 ml/kg) results in the appearance of hemorrhagic (h) and necrotic (n) areas (×200). These areas also contain high levels of fibrin (f). Sections are representative of 6 animals examined per group. C: overall % damage per animal was calculated as a mean of 24 fields/slide (1 slide/animal). **P < 0.01 compared with PBS-injected control animals.\nDownload                 figure Download PowerPoint\nTo allow for a more detailed analysis of the lung injury induced by intravenous OA (0.2 ml/kg), lungs were assessed by transmission electron microscopy (TEM). In addition to the fibrin formation within the alveolar spaces ( Fig. 7A ), also seen by light microscopy, areas in which the entire alveolar architecture had been damaged were evident by TEM ( Fig. 7, B and C ). These were characterized by congested and grossly swollen capillaries, and sloughing of necrotic ATI cells, leaving a denuded basement membrane. Additionally, some endothelial damage and necrosis was evident ( Fig. 7C ). The alveolar structure was severely altered, and the destroyed epithelium had apparently undergone sloughing in large fragments.\nFig. 7.Transmission electron micrographs of alveolar tissues following intravenous OA (0.2 ml/kg) are shown. A: alveolar epithelium (epi) and endothelium appear intact, but the alveolar space (AS) contains fibrin (f) and cellular debris (d). B: area showing more severe injury. Capillaries (c) appear swollen with abnormally shaped red blood cells (rbc). The epithelial basement membrane (bm) is denuded in large areas caused by loss of ATI (at1) cells. A necrotic AT1 can be seen detaching from the bm. C: extensive loss of alveolar architecture. Large fragments of AT1 cells have detached from the basement membrane, and capillaries are grossly enlarged and show some necrotic endothelial cells (ec) and denudation of both the epithelial and endothelial basement membrane. All sections, ×1,500; bar = 5 μm. Micrographs are representative of 3 animals.\nDownload                 figure Download PowerPoint\nBlood gases and lung compliance.\nAnimals undergoing lung physiological measurements demonstrated a marked decrease in arterial Po2 (PaO2, Fig. 8A ) within 30 min of OA administration, which further declined by 1 h. This was associated with marked increases in arterial Pco2 (PaCO2) during the 1-h period ( Fig. 8B ). No changes in arterial blood gases were evident in ventilated PBS control animals observed under similar conditions for 1 h. In addition, OA administration was associated with a progressive decrease in compliance ( Fig. 8C ) over 1 h.\nFig. 8.Effect of intrajugular OA on blood gases and lung compliance. ⧫, OA (0.1 ml/kg, n = 6); ▵, PBS-injected control animals (n = 4). A: arterial Po2 (PaO2, mmHg). B: arterial Pco2 (PaCO2, mmHg). C: lung compliance (ml·kg−1·cmH2O−1). Solid black line indicates median. Each symbol represents 1 animal.\nEffect of rhKGF Pretreatment on OA-Induced Lung Injury\nBALF cell counts.\nPretreatment with rhKGF (10 mg/kg) did not significantly affect the total cell numbers found in the BALF (KGF, 2 × 106 ± 2.4/ml of BALF, diluent, 2.6 × 106 ± 1.8/ml of BALF) or MIP-2 levels (KGF, 15.1 ± 5.5 pg/mg of protein, diluent, 15.4 ± 3.5 pg/mg of protein).\nBALF protein and LDH.\nNo significant differences were observed in the BALF protein concentration (KGF, 11.5 ± 4.3 μg/μl; diluent, 11.6 ± 5.3 μg/μl), albumin (KGF, 9.3 ± 3.1 μg/μl; diluent, 7.1 ± 4.2 μg/μl), and LDH activity (KGF, 790 ± 522 U/l; diluent, 1,138 ± 581 U/l) in animals pretreated with rhKGF 48 h before OA.\nLung histology.\nNo improvements were observed in histological damage in KGF-pretreated OA-injured animals (KGF, 60 ± 12% lung damage; diluent, 43 ± 14% lung damage).\nBlood gases and lung compliance.\nPretreatment of mice with rhKGF (10 mg/kg) 48 h before intra-jugular OA (0.1 ml/kg) challenge resulted in a significant (P < 0.001 and P < 0.05, respectively) improvement in arterial Po2 30 and 60 min after OA administration compared with control mice receiving the diluent only ( Fig. 9A ). Additionally, rhKGF pretreatment was associated with significantly (P < 0.01) decreased arterial Pco2 30 and 60 min after OA administration ( Fig. 9B ) compared with diluent only. Lung compliance was significantly (P < 0.01) improved in animals pretreated with rhKGF ( Fig. 9C ).\nFig. 9.Effect of rhKGF (10 mg/kg, 48-h pretreatment) on arterial blood gases (A and B) and lung compliance following intrajugular OA (C). rhKGF pretreatment (10 mg/kg, 48 h) + OA (0.1 ml/kg, n = 12); diluent-only pretreatment [48 h + OA (0.1 ml/kg, n = 12)]; PBS control (no OA, n = 4). A: arterial Po2 (PaO2, mmHg). B: arterial Pco2 (PaCO2, mmHg). C: lung compliance. Data are expressed as median ± first and third data quartile. *P < 0.05, **P < 0.01, and ***P < 0.001 compared with animals receiving the diluent only at the same time point.\nDownload                 figure Download PowerPoint\nDISCUSSION\nWe have shown that intratracheal rhKGF administration in mice resulted in a marked dose-related proliferation of ATII cells. However, whereas topically administered lipid-mediated gene transfer resulted in KGF mRNA production, KGF could not be detected in lung tissue, and only a modest effect was seen on ATII cell proliferation. To assess the potential for KGF therapy, we subsequently characterized a mouse model of ALI, showing features characteristic of the disease in humans. Finally, we assessed whether rhKGF could ameliorate the pathophysiology. Significant improvements were observed in arterial blood gases and lung compliance. These data demonstrate, for the first time, that rhKGF pretreatment can improve the clinical surrogates of ALI.\nThe mouse remains an important model system with transgenic technology making it possible to study effects of a single gene on the whole organism. Additionally, gene delivery methods and gene transfer efficiency have been well characterized in the mouse. This study has for the first time characterized the KGF response in this species in detail. Intratracheal instillation of 5 mg/kg body wt has been used most frequently in experimental ALI studies in both mice and rats ( 55 , 65 , 71 , 73 , 74 ). We confirmed that this dose is associated with significant ATII cell proliferation 2 days after administration. However, administration of 10 mg/kg appeared to result in higher and less variable ATII cell numbers. Studies in the rat have demonstrated ATII proliferation to be focal and thus resulting in piles of ATII cells within the alveoli ( 63 ). However, significant evidence of focal proliferation was not observed in this study, and cell proliferation in the lung sections from KGF-treated animals appeared to be diffuse. Furthermore, we demonstrated that ATII cell numbers were still increased at day 7 after administration, in contrast to Ulich et al. ( 63 ), who showed resolution of proliferation in rats. The administered dose was 5 mg/kg of rhKGF, and thus it is possible that the higher KGF dose used in this study extends the ATII cell proliferative response.\nNovel interventions for ALI are needed as mortality remains high, even in well-equipped intensive care units. A number of studies have recently demonstrated the possibility of gene therapy as a potential intervention, particularly addressing the inflammatory aspects of ALI, using IL-10 ( 38 , 41 ), elafin ( 54 ), neutrophil inhibitory factor ( 77 ), and heme oxygenase-1 ( 25 , 45 ). However, no studies to date have used gene transfer to address alveolar repair following ALI.\nNonviral KGF Gene Delivery Results in Modest ATII Cell Proliferation\nGL67 was first described in 1996 by Lee et al. ( 31 ), who demonstrated a 100-fold increase in reporter gene expression following intranasal transfection in mice compared with other first-generation cationic liposomes. Expression was found to peak 48 h following intranasal delivery of 80 μg of DNA. Although high levels of CAT reporter gene activity were demonstrated in lung homogenate 24–72 h following intranasal administration of pCF1CAT/GL67 complexes, significant KGF levels could not be detected in parallel studies using pCIKGF/GL67 despite evidence for gene transfer. In keeping with this, no increase in SP-B-positive cells was seen, with only a small increase in the numbers of ATII cells assessed by routine histology. Systemic lipid-mediated gene transfer has been demonstrated to transfect primarily pulmonary endothelial cells ( 32 ). However, KGF produced by capillary endothelial cells as a result of systemic gene transfer may reach across the alveolar endothelial-epithelial barrier, thus stimulating ATII cell proliferation. Lipid (DOTAP/cholesterol)-protamine sulfate-DNA (LPD) has previously been shown to be effective for intravenous lung delivery ( 32 ) but also has toxic effects. The toxicity is caused by a strong inflammatory response to the unmethylated CpG motifs in the DNA following uptake of LPD by circulating immune cells, primarily resulting in high levels of TNF-α and IFN-γ ( 34 ). Recently, reduced toxicity and increased gene transfer efficiency have been demonstrated by sequential delivery into the tail vein of cationic liposomes followed by DNA ( 60 ). Administration of the lipid before the DNA is believed to increase the retention time of plasmid DNA within the lung capillaries ( 33 ). However, the toxicity caused by systemic gene transfer was confirmed in this study, as mortality was high. In surviving animals, quantitative RT-PCR confirmed the expression of pCI-specific mRNA 8 and 24 h following systemic transfection. However, KGF could not be detected in lung homogenate or serum following intravenous pCIhKGF/DOTAP/cholesterol gene transfer at any time points. Although a clear trend toward an increase in ATII cell numbers was observed following sequential intravenous gene transfer, significance was not tested due to the low numbers in each group. However, by grouping the data from the different time points, a highly significant increase in ATII cell numbers could be demonstrated. As mentioned above regarding topical gene delivery, the resulting ATII cell numbers achieved by systemic gene transfer were lower than those resulting from delivery of KGF protein. Additionally, in the light of the high mortality observed in these experiments, systemic KGF gene transfer is currently not an appropriate strategy for evaluating the protective effect in of KGF gene transfer in the OA model of ALI. We conclude that at present, nonviral lung gene transfer by topical and systemic administration cannot match the efficacy of recombinant protein. Virus-mediated gene transfer, using vectors such as adenovirus, would likely have resulted in more efficient gene transfer. However, the significant inflammatory response associated with viral delivery would be detrimental in the ALI setting.\nIntravenous OA in Mouse Results in Severe Alveolar Injury\nThe oleic acid model is regarded as relevant for ARDS and has been extensively characterized in many larger animal species, including sheep, pigs, dogs, rats, and rabbits. Intravenous OA infusion causes severe pulmonary edema in a number of species due to an increase in the pulmonary alveolar barrier permeability. The arrest of small OA microemboli in the pulmonary capillaries results in severe congestion and hemorrhage ( 10 ). This microinfarction results in extensive necrosis of the alveolar epithelial type I cells ( 39 ) and also affects the permeability of endothelial cells ( 26 ). Neutrophil infiltration, fibrin deposition, and hyaline membrane formation are also common features ( 15 , 40 ). These pathological events lead to hypoxemia and severely compromised lung compliance ( 9 ).\nThere is only one previously reported study of OA administration in mice ( 56 ). Although poorly characterized, the pathophysiology described was similar to that seen in other animal species. In our study, intravenous OA administration in mice resulted in severe pulmonary edema and a dose-related increase in BALF total protein concentration, likely representative of a combination of serum protein leakage ( 24 ), inflammatory cells, and necrotic alveolar epithelial cells ( 10 ). Further measurement of BALF supernatant albumin levels, however, suggested that leaked serum protein contributed only ∼10% of the total BALF protein levels with the majority likely to originate from protein debris released from necrotic alveolar cells. This is supported by the significant increases in BALF total cell counts and by LDH levels in BALF supernatant as well as the finding of marked alveolar epithelial cell necrosis on TEM analysis. TEM analysis also demonstrated the presence of some endothelial injury and necrosis, which would further contribute to the overwhelming pulmonary edema and the albumin found in the BALF supernatant.\nAcute OA Does Not Result in Inflammatory Cell Infiltration\nSurprisingly, differential cell counts demonstrated only a small (albeit significant) increase in neutrophil numbers at 1 h following 0.2 ml/kg of OA. This finding contrasted with other studies in which OA was shown to cause a marked influx of neutrophils into the alveoli 4 h after OA administration ( 53 ). It is possible that transepithelial neutrophil migration does not occur within the initial hour after OA administration, and had we measured later time points, increased BAL neutrophils may have been detected ( 15 ). This possibility was supported by a significant increase in MIP-2 following OA (0.2 ml/kg) compared with untreated baselines in which no MIP-2 was detected. MIP-2 has potent neutrophil chemotactic activity and is secreted by epithelial cells as a key mediator of neutrophil recruitment in response to tissue injury ( 14 ). Thus the significant increase demonstrated in total BAL cell counts is likely to be a result of the presence of sloughed necrotic epithelial cells.\nMechanism of OA Injury Differs from ARDS\nThe OA mouse model has a number of dissimilating features to human ARDS. First, the initiating events leading to OA-induced lung injury do not resemble the clinical situation. ARDS generally results from sepsis or multiple injuries and evolves secondary to an overwhelming inflammatory cascade. OA-induced lung damage is likely to be caused by OA microemboli being trapped in the capillary bed, causing subsequent local necrosis followed by inflammation. Second, the time course of OA-induced injury development and progression is much shorter than that of human ARDS. The acute phase of human ARDS develops over 1–7 days and is also characterized by extensive damage to the alveolar epithelium, hemorrhage, and pulmonary edema, leading to severely decreased lung compliance and hypoxemia ( 3 , 61 ). However, with a view to evaluating KGF as a potential therapy for alveolar epithelial repair, this model consistently reproduces the histopathological features of ARDS.\nMechanical Ventilation Causes Some Degree of Lung Injury\nCompared with untreated baseline animals, a significant increase in wet-to-dry weight ratios was also observed in ventilated control animals given intravenous PBS. This suggests that mechanical ventilation is associated with the development of at least some degree of the pulmonary edema observed following OA administration and confirms previous observations that mechanical ventilation causes lung injury ( 42 , 64 ), including increased microvascular permeability and leakage of fluid into alveolar spaces ( 23 ). Ventilator-induced lung injury may be partly attributed to the effects of excessive airway pressure and overdistension of the alveoli during ventilation ( 13 ). It is, however, important to distinguish the above studies of lung injury caused by deliberate hyperventilation from this study, where the injury is most likely caused by dry gas ventilation and atelectasis due to low positive end-expiratory pressure (PEEP) and inadequate alveolar recruitment procedures. In these experiments, no PEEP was applied, which may affect lung expansion and exacerbate edema formation during mechanical ventilation ( 12 ). The addition of PEEP in the ventilatory strategy prevents complete alveolar collapse and reopening repeatedly during the breathing cycle and thereby reduces the shear stress forces generated.\nrhKGF Improves Gas Exchange and Lung Compliance in OA-Injured Mice Without Evidence of Increased Epithelial Repair\nPretreatment of mice with intratracheal rhKGF (10 mg/kg) 48 h before intrajugular administration of OA (0.1 ml/kg) resulted in a significant improvement in Pao2 30 and 60 min after OA administration. The improvement in Paco2 was significant 30 and 60 min after OA administration. Lung compliance was also significantly improved in animals pretreated with rhKGF and was observed as early as 15 min after OA administration. However, by comparison of the lung physiological results from rhKGF-pretreated animals to ventilated animals not receiving OA, it becomes clear that the KGF-induced improvements are relatively small. It is possible that the existing pool of ATII cells generated by the rhKGF pretreatment reduces the extent of epithelial damage caused by OA, thereby increasing gas exchange and improving the mechanics of the lung. Additionally, intratracheal rhKGF pretreatment may increase cell migration rate, cell spreading, and adherence, as described by Waters and Savla ( 66 ) and Atabai et al. ( 2 ), to repair areas of denuded basement membrane. However, whether this is likely to occur within the short time course of OA injury in this model is not known. Some evidence exists demonstrating that tracheal epithelial cells can migrate minutes after wound induction in vivo ( 16 ), but whether this occurs in alveolar epithelial cells is not known.\nPretreatment of the animals with rhKGF did not appear to ameliorate the extent of protein exudation (BALF protein and albumin), epithelial cell damage (LDH activity), or cellular infiltrate (BALF cell counts) induced by OA. Additionally, KGF pretreatment did not protect against the histological damage induced by OA, and no differences in fibrin, hemorrhage, or necrosis were detected. These findings were surprising in light of the physiological improvements demonstrated. Intrajugular administration of 0.1 ml/kg of OA in mice produces very acute and severe lung injury, resulting in damage to >40% of the lung tissue. The injury may have been too severe to detect any changes in the pathological end points, and further titration of the OA dose to result in a less acute and overwhelming lung injury may reveal an effect of rhKGF pretreatment on the less sensitive pathological end points. Furthermore, there may have been alternative mechanisms underlying the physiological improvements seen. Some studies have demonstrated increased surfactant protein production following KGF administration ( 72 ), most likely due to the hyperplasia of ATII cells. This increase in surfactant production may have helped to improve gas exchange and lung compliance by preventing alveolar collapse in the early stages of OA-induced lung injury development but would not alter the pathological and histological features of OA-induced lung injury. Additionally, KGF may have increased the number of Na+K+-ATPase pumps, as has previously been demonstrated ( 6 ), thus reducing fluid accumulation within the alveoli. Nevertheless, the results raise questions regarding the relevance of the improvements seen in the mice to the clinical picture of ALI and ARDS. It may be possible that a small, but significant, improvement in gas exchange may not be accompanied by a measurable reduction in damage to the alveolar epithelial membrane but may be sufficient to prevent morbidity/mortality by reducing the amount of time spent on mechanical ventilation. Additionally, prolonging the time KGF is present in the lung tissue may enhance the protective effect observed. Whereas we have established that a single dose of intratracheal administration of 10 mg/kg of rhKGF appears to produce the maximum ATII proliferative effect, multiple rhKGF administrations may further improve the protective effect. Finally, it is possible that prolonged expression achieved by gene transfer with a vector expressing high levels of KGF may result in enhanced protective effects.\nThe potential of ameliorating ALI by KGF pretreatment has been confirmed in this study using a murine model of very severe ALI. Whereas KGF did not appear to directly affect alveolar epithelial repair and integrity, measurements of blood gases and lung compliance demonstrated significant improvements in gas exchange, possibly linked to increased presence of surfactant proteins secreted from proliferating ATII cells. Further optimization of the OA model with respect to time course and dosing may reveal histological and pathological improvements.\nGRANTS\n""","0.14388697","""http://www.physiology.org/doi/10.1152/ajplung.00450.2004""","[-0.178219,51.500505]"
"""Imperial_College_London""","""Nanoparticle emissions from biofuelled vehicles—their characteristics and impact on the number-based regulation of atmospheric particles - Kumar - 2010 - Atmospheric Science Letters - Wiley Online Library""","""Nanoparticle emissions from biofuelled vehicles—their characteristics and impact on the number-based regulation of atmospheric particles\nAuthors\nE-mail address: prashant.kumar@cantab.net\nFaculty of Engineering and Physical Sciences, University of Surrey, Guildford GU2 7XH, UK\nDivision of Civil, Chemical and Environmental Engineering, Faculty of Engineering and Physical Sciences, University of Surrey, Guildford GU2 7XH, Surrey, UK.\nSearch for more papers by this author\nHelen ApSimon\nUK National Focal Centre for Integrated Assessment Modelling, Centre for Environmental Policy, Imperial College London, South Kensington, London SW7 2AX, UK\nCited by (CrossRef): 21 articles Check for updates\nCitation tools\nCiting literature\nAbstract\nThe transport sector is the dominant source of nanoparticles in the urban atmosphere. It is also responsible for about 20–25% of current global CO2 emissions, a figure that is expected to grow to about 30–50% by 2050 (Fuglestvedt et al., 2008 ). One option to counter this trend and contribute to the attainment of carbon emission reduction targets is the use of biofuels in road vehicles. This leads to a reduction in CO, CO2 and particle mass emissions, though particle number emissions may increase. This article discusses the potential impact of the particle number concentrations derived from biofuel vehicles on existing regulatory concerns over atmospheric nanoparticles. Copyright © 2010 Royal Meteorological Society\nArticles related to the one you are viewing\nCiting Literature\nNumber of times cited: 21\n1\nMarina Torres Pacheco, Magno Marcos Miotto Parmigiani, Maria de Fatima Andrade, Lidia Morawska, Prashant Kumar, A review of emissions and concentrations of particulate matter in the three major metropolitan areas of Brazil, Journal of Transport & Health, 2017, 4, 53\nCrossRef\n2\nMaria de Fatima Andrade, Prashant Kumar, Edmilson Dias de Freitas, Rita Yuri Ynoue, Jorge Martins, Leila D. Martins, Thiago Nogueira, Pedro Perez-Martinez, Regina Maura de Miranda, Taciana Albuquerque, Fabio Luiz Teixeira Gonçalves, Beatriz Oyama, Yang Zhang, Air quality in the megacity of São Paulo: Evolution over the last 30 years and future perspectives, Atmospheric Environment, 2017, 159, 66\nCrossRef\n3\nSungwoon Jung, Jeongsoo Kim, A Review on the Characteristics of Air Pollutants Emitted from Passenger Cars in Korea, Journal of ILASS-Korea, 2016, 21, 4, 223\nCrossRef\n4\nAditya Kumar Patra, Sneha Gautam, Prashant Kumar, Emissions and human health impact of particulate matter from surface mining operation—A review, Environmental Technology & Innovation, 2016, 5, 233\nCrossRef\n6\nPrashant Kumar, Maria de Fatima Andrade, Rita Yuri Ynoue, Adalgiza Fornaro, Edmilson Dias de Freitas, Jorge Martins, Leila D. Martins, Taciana Albuquerque, Yang Zhang, Lidia Morawska, New directions: From biofuels to wood stoves: The modern and ancient air quality challenges in the megacity of São Paulo, Atmospheric Environment, 2016, 140, 364\n7\nP. Kumar, A. Wiedensohler, W. Birmili, P. Quincey, M. Hallquist, The Quality of Air, 2016, 73, 369\nCrossRef\n8\nAnju Goel, Prashant Kumar, A review of fundamental drivers governing the emissions, dispersion and exposure to vehicle-emitted nanoparticles at signalised traffic intersections, Atmospheric Environment, 2014, 97, 316\nCrossRef\n9\nArun Kumar, Prashant Kumar, Ananthitha Anandan, Teresa F. Fernandes, Godwin A. Ayoko, George Biskos, Engineered Nanomaterials: Knowledge Gaps in Fate, Exposure, Toxicity, and Future Directions, Journal of Nanomaterials, 2014, 2014, 1\n11\nPrashant Kumar, Lidia Morawska, Recycling concrete: An undiscovered source of ultrafine particles, Atmospheric Environment, 2014, 90, 51\nCrossRef\n12\nPrashant Kumar, Lidia Morawska, Wolfram Birmili, Pauli Paasonen, Min Hu, Markku Kulmala, Roy M. Harrison, Leslie Norford, Rex Britter, Ultrafine particles in cities, Environment International, 2014, 66, 1\n13\nPrashant Kumar, Devendra P. Saroj, Water–energy–pollution nexus for growing cities, Urban Climate, 2014, 10, 846\nCrossRef\n14\nPrashant Kumar, Boulent Imam, Footprints of air pollution and changing environment on the sustainability of built infrastructure, Science of The Total Environment, 2013, 444, 85\nCrossRef\n15\nPrashant Kumar, Liisa Pirjola, Matthias Ketzel, Roy M. Harrison, Nanoparticle emissions from 11 non-vehicle exhaust sources – A review, Atmospheric Environment, 2013, 67, 252\nCrossRef\n16\nMathew R. Heal, Prashant Kumar, Roy M. Harrison, Particles, air quality, policy and health, Chemical Society Reviews, 2012, 41, 19, 6606\nCrossRef\n17\nPei Lu, Caiting Li, Guangming Zeng, Xuwen Xie, Zhihong Cai, Yangxin Zhou, Yapei Zhao, Qi Zhan, Zheng Zeng, Research on soot of black smoke from ceramic furnace flue gas: Characterization of soot, Journal of Hazardous Materials, 2012, 199-200, 272\nCrossRef\n18\nMatteo Carpentieri, Prashant Kumar, Alan Robins, An overview of experimental results and dispersion modelling of nanoparticles in the wake of moving vehicles, Environmental Pollution, 2011, 159, 3, 685\nCrossRef\n19\nPrashant Kumar, B.R. Gurjar, A.S. Nagpure, Roy M. Harrison, Preliminary Estimates of Nanoparticle Number Emissions from Road Vehicles in Megacity Delhi and Associated Health Impacts, Environmental Science & Technology, 2011, 45, 13, 5514\nCrossRef\n20\nM. L. A. Tavares, N. Queiroz, I. M. G. Santos, A. L. Souza, E. H. S. Cavalcanti, A. K. D. Barros, R. Rosenhaim, L. E. B. Soledade, A. G. Souza, Sunflower biodiesel, Journal of Thermal Analysis and Calorimetry, 2011, 106, 2, 575\n""","0.630214","""http://onlinelibrary.wiley.com/doi/10.1002/asl.307/abstract""","[-0.178219,51.500505]"
"""Imperial_College_London""","""Multi-class dynamic traffic assignment with physical queues: intersection-movement-based formulation and paradox: Transportmetrica A: Transport Science: Vol 12, No 10""","""KEYWORDS: Multi-class dynamic traffic assignment ,  approach proportion ,  variational inequality ,  extragradient method ,  paradox\n1.  Introduction\nDynamic traffic assignment (DTA) is an important topic due to its wide applications in transport planning and management (Szeto and Lo 2006 Szeto, W. Y., and H. K. Lo. 2006. “Dynamic Traffic Assignment: Properties and Extensions.” Transportmetrica 2 (1): 31–52. doi: 10.1080/18128600608685654 [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ). In general, DTA can be classified into the simulation-based approach (e.g. Yagar 1971 Yagar, S. 1971. “Dynamic Traffic Assignment by Individual Path Minimisation and Queuing.” Transportation Research 5 (3): 179–196. doi: 10.1016/0041-1647(71)90020-7 [Crossref]   [Google Scholar] ; Mahmassani, Hu, and Jayakrishnan 1995 Mahmassani, H. S., T. Hu, and R. Jayakrishnan. 1992. “Dynamic Traffic Assignment and Simulation for Advanced Network Informatics (DYNASMART).” Proceedings of the 2nd international CAPRI seminar on Urban Traffic Networks. Capri, July.  [Google Scholar] ; Mahut and Florian 2010 Mahut, M., and M. Florian. 2010. “Traffic Simulation with Dynameq.” In Fundamentals of Traffic Simulation, edited by Jaume Barceló, 323–361.\nNew York\n: Springer. [Crossref]   [Google Scholar] ) and the analytical approach (see Ran and Boyce 1996 Ran, B., and D. E. Boyce. 1996. Modeling Dynamic Transportation Network: An Intelligent Transportation System Oriented Approach.\nSpringer\n: Heidelberg. [Crossref]   [Google Scholar] ; Peeta and Ziliaskopoulos 2001 Peeta, S., and A. K. Ziliaskopoulos. 2001. “Foundations of Dynamic Traffic Assignment: The Past, the Present and the Future.” Networks and Spatial Economics 1 (3–4): 233–265. doi: 10.1023/A:1012827724856 [Crossref]   [Google Scholar] ; Szeto and Lo 2005 Szeto, W. Y., and H. K. Lo. 2005. “Dynamic Traffic Assignment: Review and Future Research Directions.” Journal of Transportation Systems Engineering and Information Technology 5 (5): 85–100.  [Google Scholar] ; and Szeto and Wong 2012 Szeto, W. Y., and S. C. Wong. 2012. “Dynamic Traffic Assignment: Model Classifications and Recent Advances in Travel Choice Principles.” Central European Journal of Engineering 2 (1): 1–18. [Crossref]   [Google Scholar] for comprehensive reviews). The simulation-based approach focuses on enabling practical deployment for realistic networks, its applicability in real-life networks, and its ability to capture traffic dynamics and microscopic driver behaviour such as lane-changing behaviour. However, the solution properties of the corresponding models, such as solution existence and uniqueness, are not guaranteed and cannot be determined in advance.\nIn contrast, the analytical approach is more suitable for analysing the properties of DTA via various frameworks. These frameworks include the optimisation model (Merchant and Nemhauser 1978a Merchant, D. K., and G. L. Nemhauser. 1978a. “A Model and an Algorithm for the Dynamic Traffic Assignment Problems.” Transportation Science 12 (3): 183–199. doi: 10.1287/trsc.12.3.183 [Crossref]   [Google Scholar] , 1978b Merchant, D. K., and G. L. Nemhauser. 1978b. “Optimality Conditions for a Dynamic Traffic Assignment Model.” Transportation Science 12 (3): 200–207. doi: 10.1287/trsc.12.3.200 [Crossref]   [Google Scholar] ; Carey 1987 Carey, M. 1987. “Optimal Time-Varying Flows on Congested Networks.” Operations Research 35 (1): 58–69. doi: 10.1287/opre.35.1.58 [Crossref] , [Web of Science ®]   [Google Scholar] ; Carey and Watling 2012 Carey, M., and D. Watling. 2012. “Dynamic Traffic Assignment Approximating the Kinematic Wave Model: System Optimum, Marginal Costs, Externalities and Tolls.” Transportation Research Part B: Methodological 46 (5): 634–648. doi: 10.1016/j.trb.2012.01.008 [Crossref] , [Web of Science ®]   [Google Scholar] ), optimal control (Friesz et al. 1989 Friesz, T. L., J. Luque, R. L. Tobin, and B. W. Wie. 1989. “Dynamic Network Traffic Assignment Considered as a Continuous Time Optimal Control Problem.” Operations Research 37 (6): 893–901. doi: 10.1287/opre.37.6.893 [Crossref] , [Web of Science ®]   [Google Scholar] ; Ran, Boyce, and LeBlanc 1993 Ran, B., D. E. Boyce, and L. J. LeBlanc. 1993. “A New Class of Instantaneous Dynamic User-Optimal Traffic Assignment Models.” Operations Research 41 (1): 192–202. doi: 10.1287/opre.41.1.192 [Crossref] , [Web of Science ®]   [Google Scholar] ; Chow 2009a Chow, A. H. F. 2009a. “Dynamic System Optimal Traffic Assignment – A State-Dependent Control Theoretic Approach.” Transportmetrica 5 (2): 85–106. doi: 10.1080/18128600902717483 [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] , 2009b Chow, A. H. F. 2009b. “Properties of System Optimal Traffic Assignment with Departure Time Choice and Its Solution Method.” Transportation Research Part B: Methodological 43(3): 325–344. doi: 10.1016/j.trb.2008.07.006 [Crossref] , [Web of Science ®]   [Google Scholar] ; Ma et al. 2014a Ma, R., X. J. Ban, and J.-S. Pang. 2014a. “Continuous-time Dynamic System Optimum for Single-Destination Traffic Networks with Queue Spillbacks.” Transportation Research Part B: Methodological 68: 98–122. doi: 10.1016/j.trb.2014.06.003 [Crossref] , [Web of Science ®]   [Google Scholar] , 2014b Ma, R., X. J. Ban, and J.-S. Pang. 2014b. “Continuous-time Dynamic User Equilibrium Model with Departure-Time Choice and Capacitated Queue.” Proceedings of the 5th International Symposium on Dynamic Traffic Assignment, Salerno, Italy, 17–19 June.  [Google Scholar] ), variational inequality (Friesz et al. 1993 Friesz, T. L., D. Bernstein, T. E. Smith, R. L. Tobin, and B. W. Wie. 1993. “A Variational Inequality Formulation of the Dynamic Network User Equilibrium Problem.” Operations Research 41 (1): 179–191. doi: 10.1287/opre.41.1.179 [Crossref] , [Web of Science ®]   [Google Scholar] ; Ran and Boyce 1996 Ran, B., and D. E. Boyce. 1996. Modeling Dynamic Transportation Network: An Intelligent Transportation System Oriented Approach.\nSpringer\n: Heidelberg. [Crossref]   [Google Scholar] ; Chen and Hsueh 1998 Chen, H. K., and C. F. Hsueh. 1998. “A Model and an Algorithm for the Dynamic User-Optimal Route Choice Problem.” Transportation Research Part B: Methodological 32 (3): 219–234. doi: 10.1016/S0191-2615(97)00026-X [Crossref] , [Web of Science ®]   [Google Scholar] ; Huang and Lam 2002 Huang, H. J., and W. H. K. Lam. 2002. “Modeling and Solving the Dynamic User Equilibrium Route and Departure Time Choice Problem in Network With Queues.” Transportation Research Part B: Methodological 36 (3): 253–273. doi: 10.1016/S0191-2615(00)00049-7 [Crossref] , [Web of Science ®]   [Google Scholar] ; Lo and Szeto 2002a Lo, H. K., and W. Y. Szeto. 2002a. “A Cell-Based Variational Inequality Formulation of the Dynamic User Optimal Assignment Problem.” Transportation Research Part B: Methodological 36 (5): 421–443. doi: 10.1016/S0191-2615(01)00011-X [Crossref] , [Web of Science ®]   [Google Scholar] , 2002b Lo, H. K., and W. Y. Szeto. 2002b. “A Cell-Based Dynamic Traffic Assignment Model: Formulation and Properties.” Mathematical and Computer Modelling 35 (7–8): 849–865. doi: 10.1016/S0895-7177(02)00055-9 [Crossref] , [Web of Science ®]   [Google Scholar] ; Szeto and Lo 2004 Szeto, W. Y., and H. K. Lo. 2004. “A Cell-Based Simultaneous Route and Departure Time Choice Model with Elastic Demand.” Transportation Research Part B: Methodological 38 (7): 593–612. doi: 10.1016/j.trb.2003.05.001 [Crossref] , [Web of Science ®]   [Google Scholar] , 2006 Szeto, W. Y., and H. K. Lo. 2006. “Dynamic Traffic Assignment: Properties and Extensions.” Transportmetrica 2 (1): 31–52. doi: 10.1080/18128600608685654 [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ; Han, Friesz, and Yao 2013c Han, K., T. L. Friesz, and T. Yao. 2013c. “Existence of Simultaneous Route and Departure Choice Dynamic User Equilibrium.” Transportation Research Part B: Methodological 53: 17–30. doi: 10.1016/j.trb.2013.01.009 [Crossref] , [Web of Science ®]   [Google Scholar] ), nonlinear complementarity problem (NCP) (Wie, Tobin, and Carey 2002 Wie, B. W., R. L. Tobin, and M. Carey. 2002. “The Existence, Uniqueness and Computation of an Arc-Based Dynamic Network User Equilibrium Formulation.” Transportation Research Part B: Methodological 36 (10): 897–918. doi: 10.1016/S0191-2615(01)00041-8 [Crossref] , [Web of Science ®]   [Google Scholar] ; Ban et al. 2008 Ban, X. J., H. X. Liu, M. C. Ferris, and B. Ran. 2008. “A Link-Node Complementarity Model and Solution Algorithm for Dynamic User Equilibria with Exact Flow Propagations.” Transportation Research Part B: Methodological 42 (9): 823–842. doi: 10.1016/j.trb.2008.01.006 [Crossref] , [Web of Science ®]   [Google Scholar] ), nonlinear equation system (Long et al. 2015b Long, J. C., W. Y. Szeto, Q. Shi, Z. Y. Gao, and H. J. Huang. 2015b. “A Nonlinear Equation System Approach to the Dynamic Stochastic User Equilibrium Simultaneous Route and Departure Time Choice Problem.” Transportmetrica A: Transport Science 11 (5): 388–419. doi: 10.1080/23249935.2014.1003112 [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ), fixed point problem (Szeto, Jiang, and Sumalee 2011 Szeto, W. Y., Y. Jiang, and A. Sumalee. 2011. “A Cell-Based Model for Multi-Class Doubly Stochastic Dynamic Traffic Assignment.” Computer-Aided Civil and Infrastructure Engineering 26: 595–611. doi: 10.1111/j.1467-8667.2011.00717.x [Crossref] , [Web of Science ®]   [Google Scholar] ; Meng and Khoo 2012 Meng, Q., and H. L. Khoo. 2012. “A Computational Model for the Probit-Based Dynamic Stochastic User Optimal Traffic Assignment Problem.” Journal of Advanced Transportation 46 (1): 80–94. doi: 10.1002/atr.149 [Crossref] , [Web of Science ®]   [Google Scholar] ), differential variational inequality (Friesz et al. 2013 Friesz, T. L., K. Han, P. A. Neto, A. Meimand, and T. Yao. 2013. “Dynamic User Equilibrium Based on a Hydrodynamic Model.” Transportation Research Part B: Methodological 47 (1): 102–126. doi: 10.1016/j.trb.2012.10.001 [Crossref] , [Web of Science ®]   [Google Scholar] ; Friesz and Meimand 2014 Friesz, T. L., and A. Meimand. 2014. “A Differential Variational Inequality Formulation of Dynamic Network User Equilibrium with Elastic Demand.” Transportmetrica A: Transport Science 10 (7): 661–668. doi: 10.1080/18128602.2012.751684 [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ), and differential complementarity problem (Ban et al. 2012b Ban, X. J., J. S. Pang, H. X. Liu, and R. Ma. 2012b. “Modeling and Solving Continuous-Time Instantaneous Dynamic User Equilibria: A Differential Complementarity Systems Approach.” Transportation Research Part B: Methodological 46 (3): 389–408. doi: 10.1016/j.trb.2011.11.002 [Crossref] , [Web of Science ®]   [Google Scholar] ) frameworks.\nAll of the preceding analytical frameworks are formulated as either path-based models (e.g. Friesz et al. 1993 Friesz, T. L., D. Bernstein, T. E. Smith, R. L. Tobin, and B. W. Wie. 1993. “A Variational Inequality Formulation of the Dynamic Network User Equilibrium Problem.” Operations Research 41 (1): 179–191. doi: 10.1287/opre.41.1.179 [Crossref] , [Web of Science ®]   [Google Scholar] ; Huang and Lam 2002 Huang, H. J., and W. H. K. Lam. 2002. “Modeling and Solving the Dynamic User Equilibrium Route and Departure Time Choice Problem in Network With Queues.” Transportation Research Part B: Methodological 36 (3): 253–273. doi: 10.1016/S0191-2615(00)00049-7 [Crossref] , [Web of Science ®]   [Google Scholar] ; Lo and Szeto 2002a Lo, H. K., and W. Y. Szeto. 2002a. “A Cell-Based Variational Inequality Formulation of the Dynamic User Optimal Assignment Problem.” Transportation Research Part B: Methodological 36 (5): 421–443. doi: 10.1016/S0191-2615(01)00011-X [Crossref] , [Web of Science ®]   [Google Scholar] , 2002b Lo, H. K., and W. Y. Szeto. 2002b. “A Cell-Based Dynamic Traffic Assignment Model: Formulation and Properties.” Mathematical and Computer Modelling 35 (7–8): 849–865. doi: 10.1016/S0895-7177(02)00055-9 [Crossref] , [Web of Science ®]   [Google Scholar] ; Szeto and Lo 2004 Szeto, W. Y., and H. K. Lo. 2004. “A Cell-Based Simultaneous Route and Departure Time Choice Model with Elastic Demand.” Transportation Research Part B: Methodological 38 (7): 593–612. doi: 10.1016/j.trb.2003.05.001 [Crossref] , [Web of Science ®]   [Google Scholar] , 2006 Szeto, W. Y., and H. K. Lo. 2006. “Dynamic Traffic Assignment: Properties and Extensions.” Transportmetrica 2 (1): 31–52. doi: 10.1080/18128600608685654 [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ; Perakis and Roels 2006 Perakis, G., and Roels, G. 2006. “An Analytical Model for Traffic Delays and the Dynamic User Equilibrium Problem.” Operations Research 54 (6): 1151–1171. doi: 10.1287/opre.1060.0307 [Crossref] , [Web of Science ®]   [Google Scholar] ; Szeto 2008 Szeto, W. Y.. 2008. “Enhanced Lagged Cell-Transmission Model for Dynamic Traffic Assignment.” Transportation Research Record: Journal of the Transportation Research Board 2085: 76–85. doi: 10.3141/2085-09 [Crossref] , [Web of Science ®]   [Google Scholar] ; Szeto, Jiang, and Sumalee 2011 Szeto, W. Y., Y. Jiang, and A. Sumalee. 2011. “A Cell-Based Model for Multi-Class Doubly Stochastic Dynamic Traffic Assignment.” Computer-Aided Civil and Infrastructure Engineering 26: 595–611. doi: 10.1111/j.1467-8667.2011.00717.x [Crossref] , [Web of Science ®]   [Google Scholar] ) or link-based models (e.g. Carey 1987 Carey, M. 1987. “Optimal Time-Varying Flows on Congested Networks.” Operations Research 35 (1): 58–69. doi: 10.1287/opre.35.1.58 [Crossref] , [Web of Science ®]   [Google Scholar] ; Ran and Boyce 1996 Ran, B., and D. E. Boyce. 1996. Modeling Dynamic Transportation Network: An Intelligent Transportation System Oriented Approach.\nSpringer\n: Heidelberg. [Crossref]   [Google Scholar] ; Chen and Hsueh 1998 Chen, H. K., and C. F. Hsueh. 1998. “A Model and an Algorithm for the Dynamic User-Optimal Route Choice Problem.” Transportation Research Part B: Methodological 32 (3): 219–234. doi: 10.1016/S0191-2615(97)00026-X [Crossref] , [Web of Science ®]   [Google Scholar] ; Wie, Tobin, and Carey 2002 Wie, B. W., R. L. Tobin, and M. Carey. 2002. “The Existence, Uniqueness and Computation of an Arc-Based Dynamic Network User Equilibrium Formulation.” Transportation Research Part B: Methodological 36 (10): 897–918. doi: 10.1016/S0191-2615(01)00041-8 [Crossref] , [Web of Science ®]   [Google Scholar] ; Ban et al. 2008 Ban, X. J., H. X. Liu, M. C. Ferris, and B. Ran. 2008. “A Link-Node Complementarity Model and Solution Algorithm for Dynamic User Equilibria with Exact Flow Propagations.” Transportation Research Part B: Methodological 42 (9): 823–842. doi: 10.1016/j.trb.2008.01.006 [Crossref] , [Web of Science ®]   [Google Scholar] ). The merit of path-based models is that the path-related information, such as path flows and sets, can be obtained and imported to dynamic network loading (DNL) models to model flow propagation at merges and diverges and track spillback queues. Nevertheless, a path-based model normally suffers from the computational burden of path enumeration or relies on path-generation heuristics with no guarantee on convergence to handle huge path sets, even for medium networks. Instead, link-based models can avoid these two demerits and thus be applied to large networks. However, link-based models cannot be used to capture realistic traffic dynamics such as queue spillback (in one exception, Ma et al. ( 2014b Ma, R., X. J. Ban, and J.-S. Pang. 2014b. “Continuous-time Dynamic User Equilibrium Model with Departure-Time Choice and Capacitated Queue.” Proceedings of the 5th International Symposium on Dynamic Traffic Assignment, Salerno, Italy, 17–19 June.  [Google Scholar] ) proposed a link-based dynamic user optimal (DUO) model that could capture queue spillback for single-destination cases). If it is not captured, the flow pattern and locations of severe congestion may be estimated incorrectly and the strategy adopted may actually worsen network performance (Lo and Szeto 2004 Lo, H. K., and W. Y. Szeto. 2004. “Modeling Advanced Traveler Information Services: Static Versus Dynamic Paradigms.” Transportation Research Part B: Methodological 38 (6): 495–515. doi: 10.1016/j.trb.2003.06.001 [Crossref] , [Web of Science ®]   [Google Scholar] , 2005 Lo, H. K., and W. Y. Szeto. 2005. “Road Pricing for Hyper-congestion.” Transportation Research Part A 39 (7–9): 705–722.  [Google Scholar] ).\nTo retain the benefits of both the link- and path-based models, Long et al. ( 2013 Long, J. C., H. J. Huang, Z. Y. Gao, and W. Y. Szeto. 2013. “An Intersection-Movement-Based Dynamic User Optimal Route Choice Problem.” Operations Research 61 (5): 1134–1147. doi: 10.1287/opre.2013.1202 [Crossref] , [Web of Science ®]   [Google Scholar] , 2015a Long, J. C., W. Y. Szeto, H. J. Huang, and Z. Y. Gao. 2015a. “An Intersection-Movement-Based Stochastic Dynamic User Optimal Route Choice Model for Assessing Network Performance.” Transportation Research Part B: Methodological 74: 182–217. doi: 10.1016/j.trb.2014.12.008 [Crossref] , [Web of Science ®]   [Google Scholar] ) developed intersection-movement-based DTA models for general networks with multiple destinations. They formulated the traffic assignment problem in terms of approach proportions, that is, the proportion of traffic on the current link or node that selects a downstream link when leaving an intersection (or a node). This definition requires either two adjacent links or one origin link and one outgoing link to define an intersection movement. This is different from the classical definition, according to which only downstream links are used to define the proportion. An approach-proportion implicitly contains the traveller’s path information, as a path can be deduced by checking the downstream links involved in defining the approach proportions from origin to destination. As a result, this type of model can retain the advantages of both the link- and path-based models. First, as in link-based models, path enumeration and path-set generation can be avoided in the solution procedure for intersection-movement-based models. Second, as in path-based models, the realistic effects of physical queues can be captured in intersection-movement-based models when a physical queue DNL model is adopted, as the approach proportions contain the traveller’s path information. However, compared with link-based models, intersection-movement-based models have more decision variables, as each link flow or demand rate is disaggregated by downstream links (which very often number more than one) to define intersection movements and the corresponding approach proportions.\nMost of the preceding models, including the intersection-movement-based DTA models, consider only a single vehicle class. It is important to capture multiple vehicle classes in a DTA model and the interactions between different types of vehicles for several reasons. First, interactions between vehicle classes have been identified as a cause of traffic hysteresis, capacity decreases, and the wide scattering of flow–density relationships in a congested regime (Ngoduy 2010 Ngoduy, D. 2010. “Multi-Class First-Order Modelling of Traffic Networks Using Discontinuous Flow-Density Relationships.” Transportmetrica 6 (2): 121–141. doi: 10.1080/18128600902857925 [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ). Second, it is clear that trucks have a great influence on highway capacity, as they travel more slowly than cars and can become moving bottlenecks. Therefore, without considering different vehicle types and their interactions, realistic traffic dynamics and queue spillback cannot be modelled properly and the total system travel time cannot be estimated precisely. Third, many empirical studies have shown that vehicle emissions are closely related to speed and vehicle type; for example, the emissions of trucks are greater than those of cars. Therefore, it is important to capture traffic heterogeneity in estimating total vehicle emissions. Fourth, it is essential to distinguish user classes in the application of class-specific or priority control or when different types of traffic information are available to different user classes (Ngoduy 2010 Ngoduy, D. 2010. “Multi-Class First-Order Modelling of Traffic Networks Using Discontinuous Flow-Density Relationships.” Transportmetrica 6 (2): 121–141. doi: 10.1080/18128600902857925 [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ).\nThis paper develops a multi-class intersection-movement-based DTA model based on the DUO principle and concept of approach proportion. The problem is formulated as a VI problem. The DNL model proposed by Bliemer ( 2007 Bliemer, M. C. J. 2007. “Dynamic Queuing and Spillback in Analytical Multi-Class Dynamic Network Loading Model.” Transportation Research Record: Journal of the Transportation Research Board 2029 (1): 14–21. doi: 10.3141/2029-02 [Crossref] , [Web of Science ®]   [Google Scholar] ) is modified and incorporated into the VI formulation. Unlike some single-class DNL models (Ban et al. 2012a Ban, X. J., J. S. Pang, H. X. Liu, and R. Ma. 2012a. “Continuous-Time Point-Queue Models in Dynamic Network Loading.” Transportation Research Part B: Methodological 46 (3): 360–380. doi: 10.1016/j.trb.2011.11.004 [Crossref] , [Web of Science ®]   [Google Scholar] ; Han, Friesz, and Yao 2013a Han, K., T. L. Friesz, and T. Yao. 2013a. “A Partial Differential Equation Formulation of Vickrey’s Bottleneck Model, Part I: Methodology and Theoretical Analysis.” Transportation Research Part B: Methodological 49: 55–74. doi: 10.1016/j.trb.2012.10.003 [Crossref] , [Web of Science ®]   [Google Scholar] , 2013b Han, K., T. L. Friesz, and T. Yao. 2013b. “A Partial Differential Equation Formulation of Vickrey’s Bottleneck Model, Part II: Numerical Analysis and Computation.” Transportation Research Part B: Methodological 49: 75–93. doi: 10.1016/j.trb.2012.10.004 [Crossref] , [Web of Science ®]   [Google Scholar] ), this DNL model can capture car–truck interactions and allow approach proportions to be used as inputs. An extragradient method that requires only mild assumptions is adopted to solve the problem. Numerical examples are set to illustrate the importance of considering multiple vehicle classes. In addition, a car–truck interaction paradox, which states that allowing trucks to travel in a network or increasing the demand of trucks can improve total car travel time, is proposed, discussed, and examined. The findings have important implications for managing road networks with multiple types of traffic. For example, it is possible to relax road restrictions for trucks or large vehicles so that the total car travel time can be further improved or vice versa. The findings also open up new research directions for traffic management such as road restrictions and priority control for specific vehicle classes. This paper makes two main contributions. First, it proposes a multi-class intersection-movement-based DTA model that considers interactions between different types of vehicles and physical queues. Second, it proposes and examines the paradox associated with the interactions between trucks and cars.\nThe remainder of this paper proceeds as follows. Section 2 introduces the VI formulation for the intersection-movement-based multi-class DTA problem. It then depicts the DNL model encapsulated for calculating the mapping function in the VI formulation. Section 3 presents the extragradient solution method. Numerical examples are given in Section 4. Finally, Section 5 provides our conclusions and future research directions.\n2.  Formulation\n2.1  Notations\nWe consider a network with multiple origins and destinations and various classes of vehicles according to vehicle type. The network is formed by nodes and links. To simplify the presentation of the formulation, the network is designed to have the following properties. First, a node in a network can only have one status, that is, an origin, a destination, or an intermediate node. Second, at least two links are required to connect an origin and a destination. Third, there is one dummy link coming out from a destination with an infinite capacity. The first requirement can easily be satisfied by designing the network carefully. The second requirement is always satisfied for large networks. For small networks, this requirement can be satisfied by breaking down each link directly connecting an origin and a destination into a pair of links: one going into an intermediate node, and one coming out from the node. The third requirement aims to avoid developing additional sub-models to deal with flow propagation for the links going into a destination.\nThe following notations are used throughout this paper.\n2.1.1  Sets\n""","0.23330605","""http://www.tandfonline.com/doi/full/10.1080/23249935.2016.1190421""","[-0.178219,51.500505]"
"""Brunel_University_London""","""Preferential behaviour and scaling in diffusive dynamics on networks - IOPscience""","""Preferential behaviour and scaling in diffusive dynamics on networks\nBernard Kujawski1, Bosiljka Tadić2 and G J Rodgers1\nPublished 25 May 2007 • IOP Publishing and Deutsche Physikalische Gesellschaft\n1 Department of Mathematical Sciences, Brunel University, Uxbridge, Middlesex UB8 3PH, UK\n2 Department for Theoretical Physics, Jožef Stefan Institute, P O Box 3000, SI-1001 Ljubljana, Slovenia\nDates\n1367-2630/9/5/154\nAbstract\nWe study the fluctuation properties and return-time statistics on inhomogeneous scale-free networks using packets moving with two different dynamical rules; random diffusion (RD) and locally navigated diffusive motion with preferred edges. Scaling in the fluctuations of noise and flow occurs when the dispersion of a quantity at each node or edge increases like its mean to the power μ. We show that the occurrence of scaling in the fluctuations of the number of packets passing nodes and the number of packets flowing along edges is related to preferential behaviour in, respectively, the topology or the dynamics. Within our model, no preference leads to no scaling. When scaling does occur it is non-universal; for RD the number of packets passing a node scales with an exponent μ which increases continuously with increased acquisition time window from μ = 1/2 at small windows, to μ = 1 at long time windows. In preferentially navigated diffusive motion, busy nodes and edges have exponent μ = 1, in contrast to less busy parts of the network, where an exponent μ = 1/2 is found. Broad distributions of the return times at nodes and edges illustrate that the basis of the observed scaling is the cooperative behaviour between groups of nodes or edges. These conclusions are relevant for a large class of diffusive dynamics on networks, including packet transport with local navigation rules.\nExport citation and abstract\nBibTeX RIS\n1. Introduction\nIn transport processes on networks, complex dynamical behaviour may be caused by the structure of underlying network geometry (for a recent review see [ 1 , 2 ] and references therein). Recently the methods of statistical physics have been used to analyse and model traffic of information packets on communication networks [ 3 ]–[ 13 ]. It has been recognized that the inhomogeneous degree distributions found in the scale-free networks may be one cause of this behaviour, however, when the dynamics include local navigation rules, other structural details appear to be necessary [ 1 , 12 , 14 ]. Queuing at nodes, which is essential for high density information packet transport [ 1 , 6 , 8 , 12 , 14 , 15 ], and is usually absent in other transport processes such as charge transport [ 16 ], is another cause of collective behaviour in transport dynamics. Typically, at high packet density a transition to a jammed traffic regime eventually occurs. On scale-free networks the hubs play an important role in the onset of this transition [ 5 , 6 , 15 ], [ 17 ]–[ 19 ]. To increase the traffic efficiency in this regime various improved routing methods have been suggested, based both on network structure and dynamic properties [ 11 ], [ 20 ]–[ 22 ].\nMany dynamically measurable outputs exhibit scaling features, indicating a degree of universality that, in turn, can be used to probe a network's structural and traffic properties [ 1 ]. Distributions of transport times, waiting times and noise fluctuations exhibit power-law behaviour in different network models. However, it is not an easy task to relate the emergent dynamical features to particular structural properties, firstly because of the network's power-law inhomogeneity but also because of different structural elements, i.e. nodes or edges, or higher (hidden) structures, that may play a role in the dynamics. Therefore, a more systematic study of traffic scaling properties, that considers structure beyond the node's connectivity, is necessary in order to reveal the origin of scaling and relate the observed scaling properties to the specific structural and dynamical features on complex networks.\nIn view of the long-range correlations in packet streams on inhomogeneous networks, analysis of traffic noise, defined by the number of packets processed by a node, and traffic flow, the number of packets passing along an edge, can give interesting information about traffic conditions and the underlying network structure [ 1 ]. In recent studies a multi-channel analysis of traffic noise on networks [ 23 ]–[ 25 ] reveals that the set of fluctuations {σi} of the traffic time-series {hi(t)} measured at all nodes in the network i = 1,2, ..., N obeys the scaling law\nThe exponent μ is often found to be either μ = 1/2 or μ = 1, suggesting a universal behaviour across different networks [ 23 ]. However, recently it was found [ 1 , 24 , 25 ] that the exponent μ may depend on traffic conditions and the type of measurements taken. Similar results, in which non-universal scaling was found to depend on the acquisition time window, were found in the analysis of stock market time series [ 26 , 27 ]. A unique exponent between these two universal values was also found in the analysis of the genome-wide time series of the gene expression of yeast [ 28 ], the dynamics of which is naturally limited by the cell cycle.\nIn this paper we address the question of scaling in the diffusive dynamics on networks, by carefully selecting the inhomogeneity of the network and the dynamical rule, in order to determine the origin of the scaling and its robustness. To demonstrate the importance of these dynamic phenomena in real-world networks, we employ a non-trivial model for the transport of information packets [ 1 , 7 , 12 , 14 ]. For the purpose of this work we use a simple scale-free network [ 29 , 30 ] with a clear inhomogeneity in the node connectivity but with low clustering and no edge correlations. We consider two types of diffusive motion of the packets on the graph: random diffusion (RD) and local navigation with preferred edges, described below. In an inhomogeneous network, nodes and edges play a different role in diffusion processes. For instance, in a random walk dynamics (with no dynamic preference) the number of hits to a node of degree k is proportional to k [ 31 , 32 ], however, this number is partitioned along k edges connecting the node to the rest of the network.\nIn comparison to the models considered in [ 23 , 24 ], our traffic model is more realistic in that:\n1.  \npackets are created at a given rate R and travel to specified destinations on the network, selected randomly;\n2.  \npackets queue dynamically at nodes;\n3.  \npackets are navigated locally according to a specified algorithm.\nConsequently the travel-times are determined self-consistently rather than being fixed as an adjustable external parameter of the model and have a broad distribution with a power-law tail, which depends on the network structure navigation algorithms [ 14 ]. The waiting times of packets is also determined self-consistently by the dynamics. Depending on the type of queuing discipline employed, the waiting time distribution can also have a power-law tail on scale-free networks [ 14 ]. Throughout this work we use low packet densities in order to keep the time series of traffic noise and flow stationary and avoid the effect of large queuing times (see [ 1 ] for a study of dense traffic on structured networks).\nOur main findings suggest that the presence of a preference in either the topology, such as in node connectivity, or in the dynamics, such as by edge-preferred navigation, leads to the scaling of fluctuations. When this scaling occurs, careful analysis shows that it is non-universal, depending both on the acquisition-time and on the importance of the nodes or edges in the transport process. These findings of collective dynamical behaviour on networks are further substantiated with a study of the return-times statistics for nodes and edges.\nThe organization of this paper is as follows. In section  2 , we define the network and the traffic model and summarize the main features of the transport process. In section  3 , the results for noise and flow fluctuations are given for various parameters and dynamic rules and in section  4 the origins of scaling are discussed and compared with transport on much simpler geometries. In section  5 , the results for the return-times distributions are obtained for the network dynamics studied in section  3 , and section  6 gives a short summary and discussion of our results.\n2. Traffic of information packets with queuing and navigation\n2.1. Network structure\nWe consider a simple scale-free network [ 29 , 30 ] with a power-law inhomogeneity in node connectivity, low clustering and no correlations between edges. Such a network can be easily grown with a preferential attachment rule in which a node with two links is added to the network at each time step and each link is connected to a node of degree k with a rate proportional to k+α. In the emergent structure, with total number of nodes N, the degree of the ith added node ki ~ (i/N)−1/(1+α), and hence the degree distribution has a power-law tail, P(k) ~ k−τ with τ = 2 + α, as shown analytically [ 30 ]. A detailed analysis of the structure of the networks grown in this way shows that the clustering is very low and link correlations are entirely absent, in contrast to correlated scale-free networks, grown with the algorithms described in [ 31 ]. For our simulations of packet diffusion we grow a simple uncorrelated scale-free network of N = 1002 nodes and E = 2N edges, which has a degree distribution with a power-law exponent τ ≈ 2.5.\nOnce the network is generated, we consider it's structure as fixed, and start the transport processes on it. During these dynamics, at each time step each node can create a new packet with probability R/N. At creation each packet is assigned a random destination address, another node on the network where it should be delivered. Packets move diffusively through the network, either performing a random walk or navigated according to the algorithm described below. Once at the destination address packets disappear from the network. In this model packets move towards their destination simultaneously, forming queues at the nodes on the way. We assume a finite queue buffer of length H = 1000 at each node. The first in–first out (FIFO) queuing discipline is applied. The maximum length of the queue is important for transport close to the congestion state and has an impact on the scaling of the fluctuations on nodes [ 1 , 25 ].\n2.2. RD and edge-preferred navigation\nThe motion of packets through the network can either be random or navigated using some rules, which may affect the role of different nodes and edges in the transport process. In the case of RD a node that is processing a packet selects one of its neighbouring nodes at random to send the packet to it. Hence the nodes on the network are visited at a rate proportional of their connectivity, and hence nodes with a high degree are often visited by moving packets. Implementation of a navigation algorithm [ 1 , 22 ] will create a bias in the use of nodes and edges on a given topology. Here we consider one such navigation algorithm, referred to as the CD (connectivity-degree) algorithm, that introduces a preference for less used edges in the traffic history [ 22 ]. In particular, a node i that is processing a packet at time step t selects one of its neighbour nodes, j, that has the minimum value of the quantity sij(t) defined as the product\nwhere kj is the degree of the node j and Fij(t) is the cumulative number of packets forwarded from node i → j up to the time t. This means that the CD algorithm is completely deterministic, involves a search of the nearest neighbourhood of the processing node, prefers to send packet to nodes away from the hubs and hence introduces a dynamical inhomogeneity to the network transport. In this way, from the point of view of nodes, the topological inhomogeneity of the network appears to be dynamically reduced. At the same time, an unequal use of edges appears, that is measured by the packet flow on them. Note that this property of the navigation rules may reduce jamming problems at high traffic density, which often occur on scale-free networks in algorithms based on the shortest paths [ 22 ]. We consider low packet density by keeping a low posting rate R, which is much below the jamming rate for this network's structure and navigation rules, in order to minimize the potential effects of long queues and to retain the stationarity of the traffic time series. It should be stressed that in this work the primary motivation for the edge-preferred navigation as defined in equation ( 2 ) was not a potential improvement of traffic efficiency on a scale-free network (for different structures and navigation rules see [ 1 , 15 , 21 ]). As mentioned in the introduction, both the network structure with simplest scale-free degree inhomogeneity and the navigation rules with the preferred edges are employed here with the purpose to clearly demonstrate the genesis of dynamical scaling at nodes and edges.\n2.3. Traffic properties\nFor the fixed network topology described above and a fixed posting rate of packets R, we simulate packet transport both with RD rules and with the CD navigation algorithm. The transport properties are measured by a number of global and local statistical quantities [ 1 , 7 , 12 , 14 ], which depend on the diffusion rules. Here we summarize several traffic properties which are relevant for further discussion. In figure  1 we show how the two diffusion rules effect the distributions of travel times of packets and number of packets processed by each node on the scale-free network. Both in the RD and in the navigated transport the distribution of travel-times exhibits a power-law tail, however, both slopes and cutoffs are different (figure  1 (a)). The average (over time windows) number of packets\nhi\nprocessed by a node i with degree ki is shown in figure  1 b. In the random diffusion RD the number of hits at a node is linearly proportional to node degree. However, when the edge-preferred navigation of packets is used, as defined in equation ( 2 ), traffic emerges in which the nodes play an equal role independently of their degree.\nZoom In\nDownload figure: Standard Export PowerPoint slide\n3. Scaling of noise signal at nodes and edges\nNoise and flow are two local characteristics of the traffic that are determined by the number of packets transported in a given time window tk at a node i hi(tk), and along a link i → j and j → i, fij(tk). The index tk = 1, 2, ..., Kmax enumerates time windows of length TWIN time steps. Therefore, the flow fij(tk) within tkth time window can be written as the difference of the cumulative flows at upper and lower boundaries of the window:\nDuring the transport process we record a set of fluctuating time-series, one for each of the N nodes {hi(tk)}, i = 1,2, ..., N, and similarly another set of time-series collected for each of the 2N edges {fij(tk)} on the network. In the simulations we fix the creation rates of packets at R = 0.01 for the RD and R = 0.1 for CD-navigated diffusion, which are well below the respective jamming rates Rmax on these network structures; Rmax = 0.06 for RD and Rmax = 0.5 for CD.\nThe distribution of dynamic flow along edges of the network is shown in figure  2 (a). In the case of traffic for RD the distribution is dominated by an average value and a width which depends on the packet density. In contrast, the CD navigation algorithm induces a non-symmetric flow distribution created by the dynamically preferred edges. Examples of time series recorder at a preferred node and at a preferred edge are shown in figure  2 (b). A detailed analysis of such time series is given in the following.\n3.1. Signal fluctuations at nodes with scale-free connectivity\nWe determine the dispersion σi and an average\nhi\nof long time series recorded at all nodes {hi(tk)}, i = 1,2, ..., N and k = 1,2, ..., Kmax. Plots of σi against\nhi\nare given in figure  3 (a) and (c), where each point represents one node of our scale-free network. The two curves correspond to the results for RD dynamics and for the transport with the CD navigation algorithm and a fixed acquisition time window TWIN = 4000 time steps. Clearly, these plots obey the scaling equation ( 1 ) with a well defined exponent μ, which is different for the two algorithms. For RD the value of μ is clearly between the two limits 1/2 and 1 mentioned above, whereas in the case of the CD navigation algorithm μ appears to be close to 1. By changing the width of the time window in which the data is collected we find that the scaling law still holds, but with a different exponent μ. This applies for both RD and CD, however, the functional dependencies μ(TWIN) are different. The results are shown in figures  3 (b) and (d). As a rule, if data are acquired in a longer time window, the exponent μ tends to be larger. For RD we find the change from weak dependence at short time windows to steeper increase when large windows are applied. For CD the exponent is constantly large for large time windows, and changes rapidly when the windows are smaller than the typical TWIN ≈ 500 time steps in these simulations. In fact, for CD we find that the dispersion between the groups of nodes exhibiting the scaling with large μ exponent is gradually reduced with decreasing time window and eventually the group becomes so condensed that an exponent cannot be defined. Simultaneously another group emerges with the scaling exponent close to μ = 1/2.\nZoom In\nDownload figure: Standard Export PowerPoint slide\n3.2. Scaling of flow at preferred edges\nWe apply a similar multi-channel analysis to the data on traffic flow fluctuations. The flow along an edge between nodes i and j is the sum of flow from i → j and from j → i. In figure  4 we plot the dispersion of the flow time series σij against the average flow along that edge\nfij\n. Each point on the plot represents one edge on the network. As figure  4 (a) shows, in the case of CD navigated diffusion, flow fluctuations obtained at a large number of edges follow the same scaling pattern as that described in equation ( 1 ) for noise fluctuations at nodes. However, in the case of edges, the situation becomes different when RD is used: the edges form a dense group on the plot, representing almost equal fluctuation properties. This implies that the dynamical preference in edges, which is built into the CD navigation rules, introduces both an uneven flow along different links and a different fluctuation pattern of the flow. The exponent that is measured from the data in figure  4 (a) is close to μ = 1. In the same plot we find another group of edges for which the scaling exponent cannot be defined. When the width of the time window is reduced the fraction of edges that belongs to the scaling regime with μ ≈ 1 is reduced, and a number of edges appear in a new group, for which the scaling exponent is close to μ ≈ 0.5. The transition between these two groups is quite sharp for the deterministic CD navigation (see figure  4 (b)). We investigate this question further by considering a simplified, probabilistic version of the edge-preferred navigation, called the D algorithm [ 22 ], in which a packet moves from node i to its neighbour j with probability\nwhere Cij is the adjacency matrix and as before kj is the degree of node j. Hence packets are more likely to move towards neighbours with a low degree. With this navigation rule, we find the flow fluctuations, shown in figure  5 (a), exhibiting two distinct groups of edges with a smooth transition. Furthermore, the size of the group of nodes exhibiting the scaling with larger exponent μ ~ 1 grows with the increase of the time window, as shown in figure  5 (b).\nZoom In\nDownload figure: Standard Export PowerPoint slide\nStudy of the flow fluctuations suggests that the dynamical preference of edges, as in our navigation rules, introduces the necessary distinction between edges that leads to the scaling behaviour. In contrast to the noise fluctuations studied above, in flow fluctuations we did not observe a unique scaling exponent with a smooth dependence of the acquisition time window. According to their flow fluctuations, all edges appear to be in one of the two groups of well defined scaling exponents, either 1/2 or 1. The relative population of these groups changes and the size of the group with the larger exponent increases with the length of the time window.\n4. Origin of scaling on complex networks\nIn the previous section a comparative analysis of the fluctuations of noise signal at nodes and flow at edges suggested that in the diffusion processes a preference between network elements, that can be achieved in an inhomogeneous network, is necessary for the scaling in equation ( 1 ) to occur. In order to further clarify this point, we have analysed different geometries including regular and homogeneous substrates.\nIn figures  6 (a) and (b) we show the fluctuations of packets in RD recorded on nodes and edges of a square lattice and of a random graph. Clearly, fluctuations of flow at edges on these structures appear to belong to one group within a statistical dispersion. However, the record of noise at different nodes already shows grouping according to their connectivity: on the square lattice one can distinguish between fluctuations in the number of packets processed by the four corner nodes, by nodes at the boundaries and by the rest of the nodes, whose the connectivity is four. A larger range of groups of nodes is found on a random graph, with connectivities ranging from 2 to 8 edges per node, where the larger connectivity nodes are shifted to the right part of the plot. In the same spirit, on the scale-free network the span of different groups of nodes with different connectivities is even larger, also visible in figure  3 (a), and it is related to the connectivity profile. Therefore, the direct relationship between the node connectivity and the number of processed packets by that node (its dynamic centrality) occurs in the RD. This represents the basis of the observed scaling of noise fluctuations on the scale-free networks.\nZoom In\nDownload figure: Standard Export PowerPoint slide\nHence, nodes with different connectivity play a different role in the diffusion processes on networks. Clearly, this idea of topological dissimilarity of nodes cannot be extended to edges in the graph, as each edge has two nodes at its ends. However, when the dynamic flow is considered, with diffusion rules such as our CD navigation, the edge dissimilarity emerges. Again, we observe distinct groups of edges which have different flow fluctuations, with more 'important' groups having proportionally larger flow and large fluctuations.\nIt is an intrinsic property of the diffusive dynamics that different groups of nodes or edges develop a cooperative behaviour and fall on a line with a well defined profile, as given in equation ( 1 ). Our results for the diffusive dynamics of information packets suggest that stationarity of the time series is a necessary condition for such cooperativity to occur, whereas the dynamic continuity need not be strictly observed (in our model sources and sinks of packets occur, which are balanced on average). Our results show that in topologically or dynamically inhomogeneous systems nodes or edges may develop different levels of cooperative behaviour that leads to non-universal scaling. The non-universality is represented by the fact that the scaling exponent depends on the dynamics, with either a continuous change between the two limiting values 0.5 ≤ μ ≤ 1, or with two exponents defined for different groups of edges. A possible origin of these two limiting values of the scaling exponent has been discussed in [ 23 , 33 , 34 ].\n5. Return-times to nodes and edges\nAnother type of dynamic measure collected at individual nodes and edges, that depends on the dynamic behaviour of the whole network, is the statistics of return-times ΔT, defined as time intervals between the successive events at a given node or an edge. In collective dynamical systems such as earthquakes [ 35 ]–[ 37 ], critical sandpiles [ 38 , 39 ], and stock market dynamics [ 40 , 41 ], a broad distribution of return times (sometimes called waiting times or recurrent times) is always found, with power-law tails suggesting the occurrence of long-range dynamic correlations between the events. In this work we address the question of return times to nodes and to edges in order to investigate further the nature of collective dynamic behaviour in our model of diffusion of packets on a scale-free network. Note that the return time we study is the time taken for a node (or edge) to receive its next packet, and not the time taken for the same packet to return to that node (or edge).\n5.1. Return-time to nodes\nIn the case of RD (random walks) on networks the return time distribution has been studied in other parts of the theoretical physics literature. In particular, the first return time to the origin of a random walker on sparse random graphs, with nodes representing states of a system, was considered by Bray and Rodgers [ 42 ] as a model of non-exponential relaxation in spin glasses and other non-ergodic systems. With the help of some heuristic arguments, they arrived at the conclusion that on a random graph the long-time behaviour of the diffusion in the phase space is dominated by the parts of the network with linear chains (no loops), leading to the expression P(Δ T) ~ exp(−A(k)(ΔT)1/3), where k is the average connectivity of the random graph and A(k) is known.\nThese arguments can be generalized to introduce a power-law distribution of connectivities. If the distribution of k behaves like ~k−τ, and using the result in that for small k, P(ΔT) ~ k exp(−2ΔT/k), then integrating over k leads to\nwith\nThus, the inhomogeneous connectivity creates a power-law distribution in the return times distribution for RD. Recently a more rigorous treatment of random walks on scale-free networks was carried out by Noh and Rieger, that yielded identical results. The results of our simulations for different diffusion processes are shown in figure  7 (a). The return-time distributions in different cases studied here seem to have a power-law behaviour before a cutoff. (The cutoff can be related to the network size in the case of single random walker. Note also a characteristic splitting at small ΔT with an inherent preference for even return times, caused by the lack of clustering and the low density of walkers.) In the case of non-interacting random walks, i.e. RD without queuing, the results agree, within error bars, with the above theoretical prediction. We have the exponent τΔ = 0.56 ± 0.03, whereas the distribution of the network's connectivity has a power-law exponent τ ≈ 2.5 (see section  2 ).\nZoom In\nDownload figure: Standard Export PowerPoint slide\nIncreasing the traffic density reduces the value of the cutoff, but the slope remains practically unchanged. However, when the navigated diffusion is considered, both the slope and the cut-off of the distribution are changed. In figure  7 (b) we show the results for navigated diffusion with the CD algorithm, RD with one-depth layer search and RD at low packet density.\n5.2. Return-time to edges\nThe situation is entirely different from the point of view of edges on the same network. The results are shown in figure  8 . We find a pronounced difference between the RD and navigated diffusion in the tails of the distributions. In both cases, however, a unique functional form can be found. For larger ΔT the distributions of the return times to edges can be fitted with a q-exponential form, which is often related to non-ergodic behaviour in dynamical systems [ 43 ]:\nIn the case of RD, shown in figure  8 (a), the distribution is very close to the exponential form, which corresponds to the q → 1 limit of equation ( 6 ). In fact, we find q = 1.08 in the case of RD, whereas in the case of edge-preferred CD navigation q = 1.33.\nZoom In\nDownload figure: Standard Export PowerPoint slide\n6. Conclusions and discussion\nWe have performed an analysis of the diffusive dynamics on a scale free network with a power-law connectivity distribution but without any other form of structural inhomogeneity. Using the transport of information packets, where the diffusion rules can be modified in various ways by adjusting the navigation of packets at nodes, we were able to show that several dynamical effects appear to be related to the the microscopic diffusion rules. Our approach indicates that these findings will be relevant to more realistic transport problems on networks, which are very different from simple random-walks.\nIn particular, we pinpointed the importance of not just topological but also dynamic preference to the occurrence of dynamic scaling. We implemented navigation rules that involve preferences between links, which is possible on topologically inhomogeneous scale-free networks. The edge-preferential navigation rules appear to dynamically homogenize the network (at large connectivity nodes) and yield new dynamical phenomena. We focused on two types of scaling behaviour that can be obtained from the point of view of individual structural elements, nodes and edges of the network, and are potentially related to each other: scaling of noise and flow fluctuations, on one hand, and scaling of return-time distributions, on the other. While the noise fluctuations and/or return times at nodes have been studied extensively on different types of networks [ 1 ], [ 23 ]–[ 25 ], our work presents the first systematic study of the fluctuations of flow on edges and return times to edges, and a comparison with the quantities obtained at nodes within the same dynamics. Owing to the different roles that nodes and edges play in these diffusion processes on an inhomogeneous network, these comparative studies lead to the conclusion that certain types of preferential behaviour in either nodes or edges is necessary for the occurrence of scaling. The scaling is characterized by the exponents μ and τΔ and the parameter q.\nSpecifically, no scaling behaviour was found in the fluctuations of flow and in the return times to edges for RD. On the other hand, when edge-preferred navigation is turned on, both a non-trivial scaling of the flow fluctuations and a power-law tail in the return-times to edges is observed. The differences in node connectivities, studied in regular, random graph, and the scale-free structures, leads to differences in the noise fluctuations both in RD and in CD navigated diffusion. Accordingly, we find non-trivial distributions of the return times to nodes, that are power-law (up to a finite-size cutoff), in agreement with theoretical predictions [ 32 , 42 ]. The exponents, however, depend on the navigation rules. Only in the case of RD do the return times scale with a power which is determined by the network's connectivity distribution.\nFurthermore, we show that the scaling properties of noise fluctuations are non-universal, with both the topological inhomogeneity but also details of the dynamics playing a role in the emergent scaling behaviour. In addition to a well pronounced dependence on the width of the time window, that was also observed in other studies [ 1 , 24 , 25 , 27 ], we found that navigation rules affect the universality of noise fluctuations. Again, we found a qualitative difference between the scaling properties at nodes and at edges. A unique scaling exponent μ(TWIN) is always found in the case of noise fluctuations at nodes, whereas in our navigated diffusion the flow fluctuations at edges are bi-universal.\nIt is interesting to discuss our results for fluctuations at nodes in a fixed time window in view of the random-walk model with an amplified impact depending on the node degree, which is introduced in [ 34 ]. In both cases, the average number of hits to a node depends on the degree of the node in a nonlinear way. This deviation from the linear dependence leads to the nonuniversal exponent of the fluctuations. In our model such deviations emerge naturally through the dynamics, i.e. due to the CD navigation rules. Whereas in the model of amplified random walks [ 34 ] a kind of 'cost function' is fixed for each node in advance, acting as an external constraint to the dynamics.\nFinally, we have demonstrated that by looking beyond the random walk dynamics on sparse topologies, one may find a number of new dynamical phenomena, that are both interesting from the point of theory, but also practically important for many real transport processes on networks.\nAcknowledgments\nWe acknowledge support from Programme P1-0044 of the Ministry of Higher Education, Science and Technology of the Republic of Slovenia, the British Council Partnerships in Science Project 22/2006 and the EC Marie Curie NET-ACE (MEST-CT-2004-6724).\nReferences\n""","0.22097777","""http://iopscience.iop.org/article/10.1088/1367-2630/9/5/154/meta;jsessionid=A6B9855CFC3794D42BFA721772DC799C.c3.iopscience.cld.iop.org""","[-0.472855,51.532848]"
"""Aston_University""","""Voltage control on an uninhabited autonomous vehicle electrical distribution system - Research Explorer : Aston University""","""Voltage control on an uninhabited autonomous vehicle electrical distribution system\nResearch output: Chapter in Book/Report/Conference proceeding › Conference contribution\nPower Engineering and Power Electronics Research Group\nAbstract\nMore-electric vehicle technology is becoming prevalent in a number of transportation systems because of its ability to improve efficiency and reduce costs. This paper examines the specific case of an Uninhabited Autonomous Vehicle (UAV), and the system topology and control elements required to achieve adequate dc distribution voltage bus regulation. Voltage control methods are investigated and a droop control scheme is implemented on the system. Simulation results are also presented.\nDetails\n""","1.2265964","""https://research.aston.ac.uk/portal/en/researchoutput/voltage-control-on-an-uninhabited-autonomous-vehicle-electrical-distribution-system(9c6e97c5-130c-4b01-93c3-5133ffa3dd59).html""","[-1.888803,52.487018]"
"""Cranfield_University""","""Driver Stress and Performance on a Driving SimulatorHuman Factors - Gerald Matthews, Lisa Dorn, Thomas W. Hoyes, D. Roy Davies, A. Ian Glendon, Ray G. Taylor, 1998""","""PDF\nAbstract\nEffects of stress on driving performance can depend on the nature of driver's stress reactions and on the traffic environment. In an experimental study, we assessed multiple dimensions of vulnerability to driver stress by a questionnaire that was validated in previous field studies and related those dimensions to performance on a driving simulator. Results were broadly consistent with prediction. A dimension of habitual dislike of driving was associated with reduced control skills, greater caution, and disturbance of moods. A measure of aggressive driving predicted more frequent and more error-prone overtaking, which are effects attributed to the use of confrontive coping strategies in interaction with other vehicles. An alertness measure predicted speed of reaction to pedestrian hazards. This research has practical applications for system design, automated monitoring of driver performance, selection and assessment of drivers, and training.\nAnderson, J. R. (1982). Acquisition of cognitive skill. sychological Review, 89, 369–406. Google Scholar Crossref\nArthur, W. A., Jr., Strong, M. H., & Williamson, J. (1994). validation of a visual attention test as a predictor of driving accident involvement. Journal of Occupational and Organizational Psychology, 67, 173–182. Google Scholar Crossref\nBrenner, B. & Selzer, M. L. (1969). Risk of causing a fatal accident associated with alcoholism: Psychopathology and stress: Further analysis of previous data. Behavioral Science, 14, 490–495. Google Scholar Crossref , Medline\nDorn, L. & Matthews, G. (1992). Two further studies of personality correlates of driver stress. Personality and Individual Differences, 13, 949–952. Google Scholar Crossref\nDorn, L. & Matthews, G. (1995). Prediction of mood and risk appraisals from trait measures: Two studies of simulated driving. European Journal of Personality, 9, 25–42. Google Scholar Crossref\nEysenck, H. J., & Eysenck, S. B. G. (1964). The Eysenck personality inventory. London: London University Press. Google Scholar\nGlendon, A. I., Dorn, L., Matthews, G., Gulian, E., Davies, D. R., & Debney, L. M. (1993). Reliability of the driving behaviour inventory. Ergonomics, 36, 719–726. Google Scholar Crossref\nGulian, E., Debney, L. M., Glendon, A. I., Davies, D. R., & Matthews, G. (1989). Coping with driver stress. In M. G. McGuigan & W. E. Sime (Eds.), Stress and tension control (Vol. 3, pp. 173–186). New York: Plenum. Google Scholar Crossref\nGulian, E., Glendon, A. I., Matthews, G., Davies, D. R., & Debney, L. M. (1990). The stress of driving: A diary study. Work and Stress, 4, 7–16. Google Scholar Crossref\nGulian, E., Matthews, G., Glendon, A. I., Davies, D. R., & Debney, L. M. (1989). Dimensions of driver stress. Ergonomics, 32, 585–602. Google Scholar Crossref\nHancock, P. A., & Parasuraman, R. (1992). Human factors and safety in the design of intelligent vehicle-highway systems (IHVS). Journal of Safety Research, 23, 181–198. Google Scholar Crossref\nLazarus, R. S., & Folkman, S. (1984). Stress, appraisal and coping. New York: Springer. Google Scholar\nMatthews, G. (1993). Cognitive processes in driver stress. In Proceedings of the 1993 International Congress of Health Psychology (pp. 90–93). Tokyo: International Congress of Health Psychology. Google Scholar\nMatthews, G. & Desmond, P. A. (1995). Stress as a factor in the design of in-car driving enhancement systems. Le Travail Humain, 58, 109–129. Google Scholar\nMatthews, G., Desmond, P. A., Joyner, L. A., Carcary, B. & Gilliland, K. (1997). A comprehensive questionnaire measure of driver stress and affect. In E. C. Vaya & J. A. Rothengatter (Eds.), Traffic & transport psychology: Theory and application (pp. 317–324). Amsterdam: Pergamon. Google Scholar\nMatthews, G., Dorn, L. & Glendon, A. I. (1991). Personality correlates of driver stress. Personality and Individual Differences, 12, 535–549. Google Scholar Crossref\nMatthews, G., Jones, D. M., & Chamberlain, A. G. (1990). Refining the measurement of mood: The UWIST Mood Adjective Checklist. British Journal of Psychology, 81, 17–42. Google Scholar Crossref\nMatthews, G., & Tsuda, A. (1996). Individual differences in driver stress vulnerability in a Japanese sample. Manuscript submitted for publication. Google Scholar\nMayer, R. E., & Treat, J. R. (1977). Psychological, social and cognitive characteristics of high-risk drivers: A pilot study. Accident Analysis and Prevention, 19, 1–8. Google Scholar Crossref\nMcKenna, F. P., Stanier, R. & Lewis, C. (1991). Factors underlying illusory self-assessment of driving skill in males and females. Accident Analysis and Prevention, 23, 45–52. Google Scholar Crossref , Medline\nOwens, D. A., Helmers, G. & Sivak, M. (1993). Intelligent Vehicle Highway Systems: A call for user-centred design. Ergonomics, 36, 363–369. Google Scholar Crossref\nPedhazur, E. (1982). Multiple regression in behavioral research: Explanation and prediction. London: Holt, Rinehart and Winston. Google Scholar\nRabbitt, P. M. A., & Abson, V. (1990). “Lost and found”: Some logical and methodological limitations of self-report questionnaires as tools to study cognitive ageing. British Journal of Psychology, 81, 1–16. Google Scholar Crossref , Medline\nRichardson, J. (1994). The development of a driver monitoring system. In Proceedings of the Conference on Driver Impairment, Fatigue and Driving Simulation (chap. 14). Applecross, Western Australia: Promaco Conventions. Google Scholar\nSanders, A. F. (1991). Simulation as a tool in the measurement of human performance. Ergonomics, 34, 995–1025. Google Scholar Medline\nSarason, I. G., Sarason, B. R., & Pierce, G. R. (1995). Cognitive interference: At the intelligence-personality crossroads. In D. H. Saklofske & M. Zeidner (Eds.), International handbook of personality and intelligence (pp. 285–298). New York: Plenum. Google Scholar Crossref\nSelzer, M. L., & Vinokur, A. (1975). Role of life events in accident causation. Mental Health and Society, 2, 36–54. Google Scholar Medline\nSivak, M. (1981). Human factors and highway-accident causation: Some theoretical considerations. Accident Analysis and Prevention, 13, 61–64. Google Scholar Crossref\nSummala, H. (1988). Risk control is not risk adjustment: The zero-risk theory of driver behaviour and its implications. Ergonomics, 31, 491–506. Google Scholar Crossref\nTaylor, R. G., Dorn, L., Glendon, A. I., Davies, D. R., & Matthews, G. (1991). Age and gender differences in driving performance: Some preliminary findings from the Aston driving simulator. In G. B. Grayson & J. F. Lester (Eds.), Behavioural research in road safety (pp. 30–38). Crowthorne, England: Transport and Road Research Laboratory. Google Scholar\nTsuang, M. T., Boor, M. & Fleming, J. A. (1985). Psychiatric aspects of traffic accidents. American Journal of Psychiatry, 142, 538–546. Google Scholar Crossref , Medline\nWells, A. & Matthews, G. (1994). Attention and emotion: A clinicacal perspective. London: Erlbaum. Google Scholar\nZuckerman, M. (1979). Sensation seeking: Beyond the optimal level of arousal. Hillsdale, NJ: Erlbaum. Google Scholar\n""","0.3622089","""http://journals.sagepub.com/doi/10.1518/001872098779480569""","[-0.629225,52.074389]"
"""Brunel_University_London""","""Inderscience Publishers - linking academia, business and industry through research""","""Inderscience Publishers\nThe full text of this article\n \nInternational Journal of Vehicle Design (IJVD) , Vol. 22, No. 3/4, 1999\n \nAbstract: The paper presents the development of an engine simulation program and its application to the analysis of a spark ignition (SI) engine with stratified charge. The engine simulation program has been developed to predict engine combustion, auto-ignition, performance and emissions. Full NO\nx\nformation is included in the model with a refined method to calculate the equilibrium burnt gas composition. To predict the onset of knocking combustion, an auto-ignition model involving 31 different chemical reactions is included. The thermodynamic and auto-ignition models are coupled through cylinder pressure and unburned gas temperature. The inclusion of a geometry sub-model permits the modelling of SI engines with complicated cylinder head geometry. The model was then applied to a SI engine with stratified fuel or diluent. The effects of the charge stratification on engines combustion, performance and emissions are discussed.\nOnline publication date: Sun, 14-Dec-2003\n \nis only available to individual subscribers or to users at subscribing institutions.\n \nGo to Inderscience Online Journals to access the Full Text of this article.\n \nPay per view:\nIf you are not a subscriber and you just want to read the full contents of this article, buy online access here .\n \nComplimentary Subscribers, Editors or Members of the Editorial Board of the International Journal of Vehicle Design (IJVD):\nLogin with your Inderscience username and password:\n \n""","0.6948358","""http://www.inderscience.com/offer.php?id=1864""","[-0.472855,51.532848]"
"""Imperial_College_London""","""Principal component analysis of spectra with application to acoustic emissions from mechanical equipmentTransactions of the Institute of Measurement and Control - C. C. Tan, N. F. Thornhill, R. M. Belchamber, 2002""","""PDF\nAbstract\nThis paper discusses principal component analysis (PCA) of integral transforms (spectra and autocovariance functions) of time-domain signals. It is illustrated using acoustic emissions from mechanical equipment. It was found that acoustic signals from different stages of operation appeared as distinct clusters in the PCA analysis. The clusters moved when machinery faults were present and the modelling errors also increased under fault conditions; thus, each type of fault had a distinctive signature and could be diagnosed. PCA using autocovariance functions that were derived from the full power spectrum had better performance than spectral PCA using averaged periodograms, and both gave a significant improvement over time-domain PCA.\nAldrich, C. and Theron, D. A. 2000: Acoustic estimation of the particle size distributions of sulphide ores in a laboratory ball mill. Journal of the South African Institute of Mining and Metallurgy 100, 243-248. Google Scholar\nBelchamber, R. M. and Collins, M. P. 1993: Method for monitoring acoustic emissions. European Patent Office, Publication No. 0 317 322 B1. Google Scholar\nBelchamber, R. M. and Collins, M. P. 1999: Sound for process monitoring. American Laboratory 31, 48-52. Google Scholar Medline\nBetteridge, D., Joslin, M. T. and Lilley, T. 1981: Acoustic emissions from chemical reactions. Analytical Chemistry 53, 1064-1073. Google Scholar Crossref\nBoyd, J. W. R. and Varley, J. 2001: The uses of passive measurement of acoustic emissions from chemical engineering processes. Chemical Engineering Science 56, 1749-1767. Google Scholar Crossref\nChatfield, C. and Collins, A. J. 1980: Introduction to multivariate analysis. London: Chapman and Hall. Google Scholar Crossref\nCody, G. D., Bellows, R. J., Goldfarb, D. J., Wolf, H. A. and Storch, G. V. 2000: A novel non-intrusive probe of particle motion and gas generation in the feed injection zone of the feed riser of a ‘uidized bed catalytic cracking unit. Powder Technology 110, 12-142. Google Scholar\nDe Belie, N., De Smeldt, V. and De Baerdemaeker, J. 2000: Principal component analysis of chewing sounds to detect differences in apple crispness. Postharvest Biology Technology 18, 109-119. Google Scholar Crossref\nDornfeld, D. 1992: Application of acoustic emission techniques in manufacturing. NDT&E International 25, 259-269. Google Scholar Crossref\nHolroyd, T. J. and Randall, N. 1993: Use of acoustic emission for machine condition monitoring. British Journal of Non-destructive Testing 35, 75-83. Google Scholar\nHolroyd, T. J. and Bradshaw, C. 2000: A critical appraisal of monitoring elastic waves as a means of detecting and diagnosing machine faults. Insight 42, 26-28. Google Scholar\nHou, R., Hunt, A. and Williams, R. A. 1999: Acoustic monitoring of pipeline ‘ows: particulate slurries. Powder Technology 106, 30-36. Google Scholar Crossref\nJackson, J. E. and Mudholkar, G. S. 1979: Control procedures for residuals associated with principal component analysis. Technometrics 21, 341-349. Google Scholar Crossref\nKarstang, T. V. and Henriksen, A. 1992: Infrared spectroscopy and multivariate calibration used in quantitative analysis of additives in high density polyethylene. Chemometrics and Intell Laboratory System 14, 331-339. Google Scholar Crossref\nKourti, T. and MacGregor, J. F. 1996: Control of multivariate processes. Journal of Quality Control 28, 409-428. Google Scholar\nKresta, J. V., MacGregor, J. F. and Marlin, T. E. 1991: Multivariate statistical monitoring of process operating performance. Canadian Journal of Chemical Engineering 69, 35-47. Google Scholar Crossref\nRiley M. R., Rhiel M., Zhou X., Arnold M. A. and Murhammer D. W. 1997: Simultaneous measurement of glucose and glutamine in insect cell culture media by near infrared spectroscopy. Biotechnology and Bioengineering 55, 11-15. Google Scholar Crossref , Medline\nSeasholtz, M. B. 1999: Making money with chemometrics. Chemometrics and Intelligent Laboratory Systems 45, 55-64. Google Scholar Crossref\nSharif, M. A. and Grosvenor, R. I. 1998: Internal valve leakage detection using an acoustic emission measurement system. Transactions of the Institute of Measurement and Control 20, 233-242. Google Scholar Link\nSwindelhurst, W. 1973: Acoustic emission - Introduction. Non-Destructive Testing 6, 152-158. Google Scholar Crossref\nTabe, H. T., Chow, K. C., Tan, K-J., Zhang, J. and Thornhill, N. F. 1998: Dynamic principal component analysis using integral transforms. AIChE Annual Meeting, Miami Beach. Google Scholar\nValle, S., Li, W. H. and Qin, S. J. 1999: Selection of the number of principal components: The variance of the reconstruction error criterion with a comparison to other methods. Industrial and Engineering Chemistry Research 38, 4389-4401. Google Scholar Crossref\nWade, A. P., Sibbald, D. B., Bailey, M. N., Belchamber, R. M., Bittman, S., McLean, J. A. and Wentzell, P. D. 1991: An analytical perspective on acoustic emission. Analytical Chemistry 63, 497-507. Google Scholar Crossref\nWelch, P. D. 1967: The use of fast Fourier transforms for the estimation of power spectra. IEEE Transactions on Audio & Electroacoustics AU-15, 70-73. Google Scholar Crossref\nWhitaker, M., Baker, G. R., Westrup, J., Goulding, P. A., Rudd, D. R., Belchamber, R. M. and Collins, M. P. 2000: Application of acoustic emission to the monitoring and end point determination of a high shear granulation process. International Journal of Pharmacy 205, 79-91. Google Scholar Crossref\nWise, B. M. and Gallagher, N. B. 1996: The process chemometrics approach to process monitoring and fault detection. Journal of Process Control 6, 329-348. Google Scholar Crossref\nWise, B. M., Ricker, N. L., Veltkamp, D. F. and Kowalski, B. R. 1990: A theoretical basis for the use of principal component models for monitoring multivariate processes. Process Control and Quality 1, 41-51. Google Scholar\nWold, S., Esbensen, K. and Geladi, P. 1987: Principal component analysis. Chemometrics and Intelligent Laboratory Systems 2, 37-52. Google Scholar Crossref\nWood, B. R. A. and Harris, R. W. 2000: Structural integrity and remnant life evaluation of pressure equipment from acoustic emission monitoring. International Journal of Pressure Vessels and Piping 77, 125-132. Google Scholar Crossref\nWu, H. D., Siegel, M., Khosla, P. 1999: Vehicle sound signature recognition by frequency vector principal component analysis. IEEE Transactions on Instrumentation and Measurement 48, 1005-1009. Google Scholar Crossref\nYeung, K. S. Y., Hoare, M., Thornhill, N. F., Williams, T. and Vaghjiani, J. D. 1999: Near infra red spectroscopy for bioprocess monitoring and control. Biotechnology and Bioengineering 63, 684-693. Google Scholar Crossref , Medline\n""","0.39329705","""http://journals.sagepub.com/doi/10.1191/0142331202tm067oa""","[-0.178219,51.500505]"
"""Imperial_College_London""","""Combined exome and whole-genome sequencing identifies mutations in ARMC4 as a cause of primary ciliary dyskinesia with defects in the outer dynein arm | Journal of Medical Genetics""","""Combined exome and whole-genome sequencing identifies mutations in ARMC4 as a cause of primary ciliary dyskinesia with defects in the outer dynein arm\nNew loci\nShort report\nCombined exome and whole-genome sequencing identifies mutations in ARMC4 as a cause of primary ciliary dyskinesia with defects in the outer dynein arm\nUK10K 12 ,\nHannah M Mitchison 1\n1Molecular Medicine Unit, Birth Defects Research Centre, Institute of Child Health, University College London, London, UK\n2Department of Paediatric Respiratory Medicine, Royal Brompton and Harefield NHS Trust, London, UK\n3Molecular Immunology Unit, Institute of Child Health, University College London, London, UK\n4Centre for Translational Genomics-GOSgene, Institute of Child Health, University College London, London, UK\n5Clinical Genetics Unit, Great Ormond Street Hospital, London, UK\n6Department of Pediatrics, Atrium Medical Center, Heerlen, The Netherlands\n7UCL Institute of Ophthalmology, Moorfields Eye Hospital, London, UK\n8School of Veterinary Medicine and Science, University of Nottingham, Nottingham, Leicestershire, UK\n9Advanced Data Analysis Centre, University of Nottingham, Sutton Bonington Campus, Nottingham, Leicestershire, UK\n10Department of Clinical Genetics, VU University Medical Center, Amsterdam, The Netherlands\n11General and Adolescent Paediatric Unit, Institute of Child Health, University College London, London, UK\n12http://www.uk10k.org/\nCorrespondence to Dr Hannah M Mitchison, Molecular Medicine Unit, University College London (UCL) Institute of Child Health, London WC1N 1EH, UK; h.mitchison{at}ucl.ac.uk\nAbstract\nBackground Primary ciliary dyskinesia (PCD) is a rare, genetically heterogeneous ciliopathy disorder affecting cilia and sperm motility. A range of ultrastructural defects of the axoneme underlie the disease, which is characterised by chronic respiratory symptoms and obstructive lung disease, infertility and body axis laterality defects. We applied a next-generation sequencing approach to identify the gene responsible for this phenotype in two consanguineous families.\nMethods and results Data from whole-exome sequencing in a consanguineous Turkish family, and whole-genome sequencing in the obligate carrier parents of a consanguineous Pakistani family was combined to identify homozygous loss-of-function mutations in ARMC4, segregating in all five affected individuals from both families. Both families carried nonsense mutations within the highly conserved armadillo repeat region of ARMC4: c.2675C>A; pSer892* and c.1972G>T; p.Glu658*. A deficiency of ARMC4 protein was seen in patient's respiratory cilia accompanied by loss of the distal outer dynein arm motors responsible for generating ciliary beating, giving rise to cilia immotility. ARMC4 gene expression is upregulated during ciliogenesis, and we found a predicted interaction with the outer dynein arm protein DNAI2, mutations in which also cause PCD.\nConclusions We report the first use of whole-genome sequencing to identify gene mutations causing PCD. Loss-of-function mutations in ARMC4 cause PCD with situs inversus and cilia immotility, associated with a loss of the distal outer (but not inner) dynein arms. This addition of ARMC4 to the list of genes associated with ciliary outer dynein arm defects expands our understanding of the complexities of PCD genetics.\nClinical Genetics\nOther Respiratory Medicine\nPrimary ciliary dyskinesia (PCD; MIM244400) is a heterogeneous genetic disorder arising from ultrastructural defects that cause abnormal function of motile cilia and sperm flagella. 1 The disease has an autosomal recessive mode of inheritance and affects one in every 15 000–30 000 births. Motile cilia are hair-like organelles found on the epithelial surface of the respiratory airway tract, the brain ependyma and fallopian tubes. Their axonemal structure consists of nine peripheral outer doublet microtubules surrounding a central microtubular pair (9+2 arrangement), a highly similar structure to that found in sperm tail flagella. During embryogenesis, motile monocilia at the node lack the central pair apparatus (9+0 arrangement). Microtubule-associated protein complexes are attached along the length of the axoneme at regularly intervals, which regulate axonemal stability and ciliary motility. Of these, the inner and outer dynein arms (IDA and ODA) are responsible for beat generation together with radial spoke and nexin-dynein regulatory complexes.\nAbnormal motility of respiratory cilia leads to congestion of the body's mucociliary clearance mechanism, causing a number of symptoms in PCD patients which include neonatal respiratory distress, chronic respiratory infections, sinusitis, otitis media and destructive lung disease (bronchiectasis). 2 Other features include subfertility in both sexes and left-right organ laterality abnormalities, predominantly situs inversus, and occasional hydrocephalus. In a proportion of patients, severe heterotaxic isomerisms and cardiac malformations can occur. 3 So far, genetic studies have identified mutations in over 20 genes leading to various ultrastructural defects, including RPGR which causes a syndromic form of PCD. 4 Large-scale transmission electon microscopy (TEM) studies in patients suggest that 65% of PCD arises from defects involving the outer dynein arms. 5 , 6 Of the genes which are known to cause these defects (reduction or loss of the ODAs) when mutated, DNAH5, DNAH11, DNAI1, DNAI2, DNAL1 and NME8 (previously TXNDC3) encode subunits of the axonemal outer dynein arm components, and CCDC114 encodes an outer dynein arm-docking complex component. Mutations causing PCD with ODA defects were also recently described by Hjeij et al in ARMC4, encoding a protein involved in assembling outer dynein arms into cilia which is likely involved in their targeting and/or anchoring onto microtubules. 7 Mutations involving deficiency of both the outer and inner dynein arms have also been identified in genes that encode a group of cytoplasmic proteins (DNAAF1/LRRC50, DNAAF2/KTU, DNAAF3, CCDC103, HEATR2, LRRC6 and DYX1C1), which are likely to play a role in the preassembly of the dynein arm components and/or in their axonemal transport. 4 , 8 Additionally, mutations have been reported in genes that encode protein subunits of the radial spoke heads (RSPH4A, RSPH9), proteins linked to the nexin-dynein regulatory complexes (CCDC39, CCDC40, CCDC164) and the central pair apparatus (HYDIN). 4\nIn order to determine the genetic basis of disease in PCD families, we have employed a next-generation sequencing approach. All patient samples in this study were obtained with informed consent according to the protocols approved by the ethical committees of the Institute of Child Health/Great Ormond Street Hospital (#08/H0713/82) and those of collaborating institutions. First, whole-exome sequencing was performed in one affected individual (II:1) of a consanguineous Turkish family PCD-221 at the Wellcome Trust Sanger Institute (Cambridge, UK) as part of the UK10K project. 9 PCD-221 II:1 is one of two affected siblings who present with a classic clinical course, both having laterality defects, respiratory symptoms and recurrent chest infections since a young age, compromised lung function, chronic ear, nose and throat (ENT) symptoms including rhinitis and otitis media. PCD-221 II:1 suffers from frequent pneumonias and bronchiectasis, and II:2 has had surgery for hydronephrosis. Additionally, both siblings have intellectual and developmental delay, and an unusual ocular phenotype of bilateral ptosis, variable divergent strabismus and upgaze paresis with poor horizontal saccades, suggestive of a brain stem or cranial nerve disinnervation syndrome. Exome sequencing and variant calling was performed as previously described, using approximately 3 µg of genomic DNA and the Agilent Technologies Human All Exon 50 Mb kit. 4 , 9 Over 3 Gb of sequence was generated, such that >68% of the target exome was present at greater than 20-fold coverage (see online supplementary table S1). Analysis of the exome variant profile was performed using the EVAR software tool V0.2.2 β. Copy number variations (CNV) were analysed from the exome data using ExomeDepth. 10\nTo prioritise candidate genes, we based our analysis on the rare-recessive disease model, with the knowledge that PCD is largely caused by mutations affecting the protein-coding region of genes. Since the PCD-221 II:1 individual is the offspring of a consanguineous marriage, we focused on homozygous variants predicted to cause non-synonymous or splice-site substitutions or indels. We also filtered to prioritise only those that were either novel or present in the 1000 Genomes Project exome database with a frequency <0.01. We next used our in-house internal allele count data, removing variants detected more than 10 times across a database of 500 exomes available from the UK10K_RARE cohort ( http://www.uk10k.org/studies/rarediseases.html ), because PCD-causing mutations would not be predicted as likely to appear in multiple well-phenotyped non-PCD patients. This filtering strategy revealed eight homozygous variants of interest that met these criteria, which are listed in online supplementary table S2. We proceeded to search for the presence of these genes and their species-conserved homologues in the Cilia Proteome database, 11 and this identified three genes EEF1D, MYO1D, ARMC4 (see online supplementary table S2). Of these, EEF1D encoding a translation elongation factor was excluded on gene function grounds 12 and also since further analysis showed that the missense change identified was only in a highly truncated transcript of unknown functional significance (ENST00000532400). The MYO1D variant was also excluded based on putative gene function despite the suggested link between MYO1D and left-right asymmetry determination since it is a widely expressed cytoskeleton-associated unconventional myosin. 13 , 14 Furthermore, the identified variant was a missense mutation scored as ‘benign’ (score 0.292) in Polyphen-2 and ‘tolerated’ in Sorting Intolerant From Tolerant software (SIFT) for its effect on protein function (c.2585A>T; p.His862Leu). This left a single homozygous protein-truncating nonsense variant (c.2675C>A; pSer892*) in ARMC4. The expected damaging effect of this variant, which was the only predicted null-effect allele in the final filtered set, provides strong support for its likely pathogenic role. Segregation analysis in all available members of the family including the affected sibling confirmed correct recessive inheritance of this variant ( figure 1 A and see online supplementary figure S1).\nDownload powerpoint\nFigure 1\nARMC4 mutations, protein analysis and upregulation during ciliogenesis. (A) Pedigree structure and segregation analysis of the two primary ciliary dyskinesia (PCD) families in whom ARMC4 mutations were identified. Asterisk indicates situs inversus, hash indicates dextrocardia. (B) Model of ARMC4 protein with ARM repeats in purple (residues 482–523, 524–564, 565–620, 621–661, 662–702, 703–744, 745–785, 786–826, 868–910, 911–951, 952–992, 993–1033) and low complexity regions in yellow (residues 73–84, 174–189, 424–438). The predicted ARM repeat superhelix is shown below the linear representation, with dark blue indicating the region lost by the Ser892* mutation, and dark plus light blue the region lost by the Glu658* mutation. (C) STRING predicted protein interactions for ARMC4. (D) ARMC4 expression is induced upon ciliogenesis. A marked increase in ARMC4 mRNA levels and the control PCD-associated gene DNAI1 was observed in ciliated normal human bronchial epithelial cells compared to non-ciliated cells. Normal human bronchial epithelial cells (NHBE; Lonza) were cultured submerged on collagen-coated plates with Bronchial Epithelial Growth Media (Lonza), seeded onto transwells and cultured at an air–liquid interface for 28 days essentially as previously described, 26 then analysed by qPCR performed with TaqMan primer probes and PCR products detected with an Applied Biosystems (ABI) Prism 7000 Sequence Detection System (Applied Biosystems). The fold difference in gene expression between the two was assessed normalised to GAPDH as an endogenous control, using the delta-delta Ct method. The TaqMan probes were DNAI1, Hs00201755_m1; ARMC4, Hs00216318_m1; GAPDH, Hs02758991_g1. Data are plotted as the mean, and error bars represent the SEM of triplicate repeats experiments.\nIn parallel, whole-genome sequencing (WGS) was performed as part of the UK10K project in the two unaffected, obligate carrier parents of a consanguineous Pakistani PCD family PCD-141 (individuals I:1 and I:2 figure 1A), since material from their affected offspring was not sufficient for exome sequencing. In this family, there are three affected siblings, all of whom display situs inversus and classic disease symptoms similar to those described for PCD221, including repeated infections of the chest, chronic nasal discharges and bronchiectasis. Additionally, all three siblings have had surgery to remove nasal polyps. For WGS, approximately 3 µg of genomic DNA was sheared to 100–1000 bp (Covaris) and the sheared DNA subjected to Illumina Paired-end DNA library preparation. Following size selection (300–500 bp insert size), DNA libraries were sequenced as 100 bp paired-end reads on the HiSeq platform (Illumina). For each subject, more than 91% of genomic bases were represented by at least 24 reads (see online supplementary table S3). We filtered per chromosome, to identify protein-altering heterozygous variants shared by both parents with a MAF<0.01 in the 1000 Genomes Project exome database, using the same criteria as for the exome sequencing. 522 heterozygous variants meeting the filtering criteria were shared between the two parents, out of more than nearly three million heterozygous variants per parental sample. Of these, just 16 shared variants were found in genes represented in the Cilia Proteome database, and only one, ARMC4, had any functional annotation suggestive of a role in cilia motility. Thus, this strategy as detailed in online supplementary table S4 revealed a second ARMC4 protein-truncating nonsense variant (c.1972G>T; p.Glu658*). Notably, of the 16 variants that were shared and homozygous, this was the only stop-gained effect allele, providing further support for a disease-causing effect. Segregation analysis by Sanger sequencing in all available family members confirmed recessive inheritance with consistent genotypes ( figure 1 A and see online supplementary figure S1). The lack of an ocular phenotype in anyone from family PCD-141 suggests that this finding in family PCD-221 is unconnected to ARMC4 mutations, and further analysis of the PCD-221 exome data is ongoing to investigate potential other loci.\nAnother study of mutations in ARMC4 causing PCD recently reported that the protein is involved in outer dynein arm assembly into the cilia and probably has a role in their correct axonemal docking and targeting. 7 Furthermore ARMC4, encoding the 1044 amino acid Armadillo repeat-containing protein 4, has previously been implicated in ciliogenesis. 15 We also used the UMCG Groningen Gene Network tool which analyses data from 80 000 Gene Expression Omnibus microarrays to predict gene function in Gene Ontology Consortium terms, and found the top-scoring predictions for ARMC4 were highly significant and all involved in cilia functions: ciliary or flagella motility (p=6.10×10−19), microtubule-based movement (p=1.16×10−9) and cilium assembly (p=1.16×10−9). Interestingly, ARMC4 was previously proposed to be an axonemal protein equivalent to radial spoke protein 8 (RSP8) of Chlamydomonas, however, this was acknowledged to be a low-scoring homology. 16 There appears to be no misfunction of the radial spokes in ARMC4-deficient cilia, and this seems to be an erroneous homology, due to the multiple armadillo repeats present in ARMC4 and RSP8 proteins. 17\nWe proceeded to use protein modelling to further investigate ARMC4 function. We could not detect a clear homologue in the PCD model species, Chlamydomonas, but BLAST and SMART 18 protein domain homology searches showed that there are 12 predicted ARM repeats at the C-terminus, in addition to three low amino acid complexity regions of unknown significance in the N-terminus ( figure 1 B). This contrasts with the study of Hjeij et al 7 which predicts 10 ARM motifs and one HEAT repeat in ARMC4, as is annotated in the Swissprot database ( http://www.ncbi.nlm.nih.gov/protein/74744660 ). Both models are based on predictions rather than experimental evidence. The N-terminus did not contain sufficient similarity to any known protein domains to allow modelling, however, a structural model could be generated for the C-terminus using I-TASSER 3D-structural model prediction. This predicts that the tandem ARM-repeat domains of ARMC4 fold together as a series of tandem helices forming a superhelix, that creates a surface or groove for protein interaction similar to that of the β-catenin ARM repeat structure ( figure 1 B). 19 , 20 The two nonsense mutations identified in the PCD families are most likely to be non-functional through nonsense-mediated decay (NMD); as shown in figure 1 B, they would both remove multiple ARM domains and that by inference would likely influence the protein binding capabilities of ARMC4 if a truncated form was present.\nWe then performed a STRING search to look for predicted protein–protein interactions for ARMC4. This interactome analysis generated a small network ( figure 1 C) including a predicted direct interaction between ARMC4 and the dynein intermediate chain protein DNAI2, a known component of the outer dynein arm located at the ODA base, mutations in which are also responsible for causing PCD with outer dynein arm defects and cilia immotility. 21 Notably, a direct interaction with FOXJ1 the master regulator of motile ciliogenesis was also predicted in this analysis. FOXJ1 is essential for assembly of motile cilia in vertebrates, through the regulation of genes specific to motile cilia. 22 Last, we investigated ARMC4 expression during ciliogenesis of normal human ciliated bronchial epithelial (NHBE) cells by TaqMan qPCR. ARMC4 transcript levels were undetectable in non-ciliated basal NHBE cells, whereas after ciliogenesis, a significant upregulation (over 1000-fold) of ARMC4 expression was observed. Similar results were obtained for DNAI1, a known ciliary gene ( figure 1 D).\nTo understand the impact of mutations in ARMC4, we examined transmission electron microscopy (TEM) of respiratory cilia cross-sections from nasal samples collected from the two families carrying ARMC4 mutations. TEM was performed as previously described. 6 All affected individuals displayed a loss of the outer dynein arms, as demonstrated in figure 2 A for the affected individuals PCD-221 II:1 and PCD-141 II:5. In order to further investigate ARMC4 function, we analysed its subcellular localisation by high-resolution immunofluorescence microscopy in the patient's ciliated epithelial cells as previously described. 23 In control cells, ARMC4 protein was observed to localise along the whole length of the cilia axoneme ( figure 2 B). However, in the PCD patient, PCD-221 II:1, severely reduced levels of ARMC4 along the cilia axoneme were observed in contrast to the control individual, in comparison to the axonemal marker acetylated α-tubulin which was unaffected ( figure 2 B). There was a notable accumulation of ARMC4 staining in the cell body in the patient's cells, apparently clustered directly underneath the ciliary base. This needs further investigation but could conceivably represent an accumulation of truncated protein not subject to NMD, and it is also seen in the previous study of Hjeij et al 7 in patients carrying ARMC4 termination mutations. We next used two well-established diagnostic markers of axoneme integrity, DNAH5 and DNALI1, to examine cilia structure in ARMC4 patients. DNAH5 detects both the different types of outer dynein arms that have previously been described in respiratory cilia: one class at the distal half of the axoneme (DNAH5-positive, DNAH9-positive) and one class at the proximal end (DNAH5-positive, DNAH9-negative). 24 DNALI1 stains the inner dynein arms along the entire axoneme length. 21 This analysis confirmed the presence of the IDAs in cilia of PCD-221 II:1 (see online supplementary figure S2). However, in contrast there was a complete loss of DNAH5 staining at the distal ends of the cilia, but a retention of a reduced level of DNAH5 staining in the proximal ends of cilia ( figure 2 B). This indicates the loss of distal DNAH5-positive ODAs but retention of proximal DNAH5-positive ODAs which is in agreement with previous observations by Hjeij et al 7 in ARMC4-deficient cilia.\nDownload powerpoint\nFigure 2\nARMC4 mutations result in outer dynein arms defects. (A) Transmission electron microscopy of nasal respiratory epithelial cell cilia demonstrates loss of the outer dynein arms (indicated by the arrows) in primary ciliary dyskinesia (PCD) patients carrying ARMC4 mutations compared to controls. Scale bar, 100 nm. A close-up of the peripheral outer doublet microtubules in the PCD-221 II:1 patient is indicated in a red box, to highlight the loss of the outer arms with retention of inner arms. (B) In healthy individuals, both ARMC4 and DNAH5 are localised along the length of the axoneme of respiratory epithelial cells. In individual PCD-221 II:1, ARMC4 is markedly reduced along the full length of the axoneme and DNAH5 is present only in the proximal portion of the cilia closest to the basal body, but significantly reduced at the distal end of the cilia. Cilia axonemal immunostaining was performed using antisera against ARMC4 (Sigma HPA037829) and the outer dynein arm protein DNAH5 (Sigma HPA037470) (both green). Axoneme-specific anti-acetylated-α-tubulin antibody (Sigma) was used as a control to stain the entire axoneme (red), and (DAPI is 4',6-diamidino-2-phenylindole) (Invitrogen) was used to stain DNA (blue). Scale bars, 10 μm.\nTo demonstrate the effect of ARMC4 deficiency on ciliary beat frequency, we also performed high-speed videomicroscopic analysis of patient's nasal cilia as previously described. 23 In both the affected siblings PCD-221 II:1 and II:2, the cilia were immotile compared with controls, which is a consistent pattern as seen in many other patients with outer dynein arm defects due to mutations in various different genes. The occasional twitch was seen in some cilia but in the majority they were completely static (see online supplementary video s 1–2). Taken together, these findings suggest that genetic defects in ARMC4 result in loss of selected ODAs.\nIn summary, here we show that loss-of-function mutations in ARMC4 cause PCD associated with left-right axis defects and a loss of the cilia's distal outer dynein arms. Both the nonsense mutations identified result in a deficiency of the ARMC4 protein along the length of the ciliary axoneme with an accompanying loss of the distal but not the proximal outer dynein arms, as defined by DNAH5 immunostaining, and this is associated with cilia immotility. Both mutations affect the highly conserved ARM repeat superhelix at the protein's C-terminus, likely disrupting its interactions with other protein partners. ARMC4 is, therefore, the eighth gene to be associated with a deficiency of outer dynein arms, and retention of the inner dynein arms. A previous report 7 has shown that ARMC4 is not likely to be an integral component of the outer dynein arm, but is more probably involved in ODA targeting, docking or attachment. It is known that armadillo repeat-containing proteins can have more than one function in cells, potentially interacting with different protein partners. 19 The putative interaction we detected between ARMC4 and DNAI2 requires further experimental proof, however if true, it would potentially localise ARMC4 close to DNAI2 within the axonemal outer dynein arm structures, towards the base of the outer dynein arm. Notably, Hjeij have shown in ARMC4-deficient cilia that DNAI2 similarly to DNAH5 is present proximally but absent distally from the ciliary axonemes.\nOur findings have clinical application since we have demonstrated for the first time that mutations in genes causing PCD can be identified by combining whole-exome and whole-genome sequencing data. Furthermore, we conclude that the downstream analysis of WGS data can enable the identification of mutations in genes causing disease in cases where genetic material of patients is unavailable or hard to obtain. Our analysis of parental sequencing data of PCD patients shows this can be used to assist the genetic diagnosis of the disease. ARMC4 joins an important group of highly conserved ARM repeat-containing proteins associated with the ciliary axoneme that play roles in motility which includes RSP8, RSP14 and PF16. 17 , 19 , 25 The exact nature of the essential role of ARMC4 in targeting the outer dynein arms to cilia remains to be fully characterised, however, these results further expand our understanding of the molecular genetic basis of PCD, and facilitate the rapidly growing application of genetics in PCD diagnostics.\nWeb resources\nSWISSPROT, http://www.uniprot.org/\nAcknowledgments\nWe would like to thank the PCD families for their participation in the study, and the PCD Family Support Group. We are also grateful to the physicians involved in analysis of the families especially Alison Male and Siobhan Carr. We thank Sarah Ollosson and Andrew Rogers for light and electron microscopy. The Centre for Translational Genomics-GOSgene at the UCL Institute of Child Health is supported by the National Institute for Health Research Biomedical Research Centre at Great Ormond Street Hospital for Children NHS Foundation Trust and UCL Institute of Child Health. We are grateful to the UK10K consortium in particular the Rare Diseases Group for making this study possible; a full list of the UK10K investigators is available at http://www.uk10k.org/publications_and_posters.html .\nReferences\n""","0.13033825","""http://jmg.bmj.com/content/51/1/61""","[-0.178219,51.500505]"
"""Aston_University""","""Voltage control on an uninhabited autonomous vehicle electrical distribution system - Research Explorer : Aston University""","""Voltage control on an uninhabited autonomous vehicle electrical distribution system\nResearch output: Chapter in Book/Report/Conference proceeding › Conference contribution\nPower Engineering and Power Electronics Research Group\nAbstract\nMore-electric vehicle technology is becoming prevalent in a number of transportation systems because of its ability to improve efficiency and reduce costs. This paper examines the specific case of an Uninhabited Autonomous Vehicle (UAV), and the system topology and control elements required to achieve adequate dc distribution voltage bus regulation. Voltage control methods are investigated and a droop control scheme is implemented on the system. Simulation results are also presented.\nDetails\n""","1.1750696","""https://research.aston.ac.uk/portal/en/researchoutput/voltage-control-on-an-uninhabited-autonomous-vehicle-electrical-distribution-system(9c6e97c5-130c-4b01-93c3-5133ffa3dd59).html""","[-1.888803,52.487018]"
"""University_of_Surrey""","""Finding effective pathways to sustainable mobility: bridging the science–policy gap: Journal of Sustainable Tourism: Vol 24, No 3""","""关键词: 气候变化 ,  社会技术因素 ,  科技神话 ,  运输禁忌 ,  理想期货\nIntroduction\nDemand is increasing for all transport modes. The transport sector, including tourism and all other transport motivations, is growing more rapidly than most other sectors and is currently responsible for approximately 23% of global energy-related CO2 emissions (Creutzig et al., 2015 Creutzig, F., Jochem, P., Edelenbosch, O.Y., Mattauch, L., van Vuuren, D.P., McCollum, D., & Minx, J. (2015). Transport: A roadblock to climate change mitigation? Science, 350(6263), 911–912. [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] ). Because of the sector's rising contributions to climate change, considerable effort has recently been invested by researchers to try to understand if people are willing to voluntarily change their tourism and transport behaviour (e.g. Becken, 2007 Becken, S. (2007). Tourists' perception of international air travel's impact on the global climate and potential climate change policies. Journal of Sustainable Tourism, 15, 351–368. [Taylor & Francis Online]   [Google Scholar] ; Higham, Cohen, Cavaliere, Reis, & Finkler, 2016 Higham, J.E.S., Cohen, S.A., Cavaliere, C.T., Reis, A.C., & Finkler, W. (2016). Climate change, tourist air travel and radical emissions reduction. Journal of Cleaner Production, 111, 336–347. [Crossref] , [Web of Science ®]   [Google Scholar] ; Kroesen, 2013 Kroesen, M. (2013). Exploring people's viewpoints on air travel and climate change: Understanding inconsistencies. Journal of Sustainable Tourism, 21(2), 271–290. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ; Miller, Rathouse, Scarles, Holmes, & Tribe, 2010 Miller, G., Rathouse, K., Scarles, C., Holmes, K., & Tribe, J. (2010). Public understanding of sustainable tourism. Annals of Tourism Research, 37(3), 627–645. [Crossref] , [Web of Science ®]   [Google Scholar] ). The weight of evidence clearly shows that, while awareness of the impact of mobility on climate change, and particularly that of air travel, is growing, there has been little if any actual behavioural change by tourists to travel less or to change travel modes (Higham, Cohen, Peeters, & Gössling, 2013 Higham, J.E.S., Cohen, S.A., Peeters, P., & Gössling, S. (2013). Psychological and behavioural approaches to understanding and governing sustainable mobility. Journal of Sustainable Tourism, 21(7), 949–967. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ). This realisation has been captured in numerous publications evidencing or attempting to explain an awareness–attitude or attitude–behaviour gap (e.g. Antimova, Nawijn, & Peeters, 2012 Antimova, R., Nawijn, J., & Peeters, P. (2012). The awareness/attitude gap in sustainable tourism: A theoretical perspective. Tourism Review, 67(3), 7–16. [Crossref]   [Google Scholar] ; Cohen, Higham, & Reis, 2013 Cohen, S.A., Higham, J., & Reis, A. (2013). Sociological barriers to sustainable discretionary air travel behaviour. Journal of Sustainable Tourism, 21(7), 982–998. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ; Hares, Dickinson, & Wilkes, 2010 Hares, A., Dickinson, J., & Wilkes, K. (2010). Climate change and the air travel decisions of UK tourists. Journal of Transport Geography, 18(3), 466–473. [Crossref] , [Web of Science ®]   [Google Scholar] ; Juvan & Dolnicar, 2014 Juvan, E., & Dolnicar, S. (2014). The attitude-behaviour gap in sustainable tourism. Annals of Tourism Research, 48, 76–95. [Crossref] , [Web of Science ®]   [Google Scholar] ). Meanwhile, calls were sounding that the very concept of voluntary behaviour change itself was trapped within the constraints of neoliberalism (Barr, Gilg, & Shaw, 2011 Barr, S., Gilg, A., & Shaw, G. (2011). Citizens, consumers and sustainability: (Re)framing environmental practice in an age of climate change. Global Environmental Change, 21, 1224–1233. [Crossref] , [Web of Science ®]   [Google Scholar] ; Schwanen, Banister, & Anable, 2011 Schwanen, T., Banister, D., & Anable, J. (2011). Scientific research about climate change mitigation in transport: A critical review. Transportation Research Part A, 45, 993–1006. [Crossref]   [Google Scholar] ). These calls urged the academy to pay closer attention to the political, social and material systems in which consumption practices are structured, arguing that the “carbon capability” (Whitmarsh, Seyfang, & O'Neill, 2011 Whitmarsh, L., Seyfang, G., & O'Neill, S. (2011). Public engagement with carbon and climate change: To what extent is the public “carbon capable”? Global Environmental Change, 21, 56–65. [Crossref] , [Web of Science ®]   [Google Scholar] ) of the public is limited by the “systems of provision” (Hall, 2013 Hall, C.M. (2013). Framing behavioural approaches to understanding and governing sustainable tourism consumption: Beyond neoliberalism, ‘nudging’ and ‘green growth’? Journal of Sustainable Tourism, 21(7), 1091–1109. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ), which create what Schwanen et al. ( 2011 Schwanen, T., & Lucas, K. (2011). Understanding auto motives. In K. Lucas, E. Blumenberg, & R. Weinberger (Eds.), Auto motives: Understanding car use behaviours. (pp. 3–38). Emerald: Bingley. [Crossref]   [Google Scholar] ) refer to as “path dependencies”.\nA turn towards path dependencies does not suggest that attempts to achieve public behavioural change should be abandoned. Rather it emphasises that devolving the problem of tourism and transport's impacts on climate change to individuals is a limited framing. In addition to social marketing efforts aimed downstream at effecting behavioural change in publics (see Hall, in press Hall, C.M. (in press). Intervening in academic interventions: Using the lens of social marketing to examine the potential for successful sustainable tourism behavioural change. Journal of Sustainable Tourism, DOI: 10.1080/09669582.2015.1088861. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] , this issue), and a continued drive by industry towards marginal efficiency gains available in aviation technologies (Cumpsty et al., 2010 Cumpsty, N., Alonso, J., Eury, S., Maurice, L., Nas, B., Ralph, M., & Sawyer, R. (2010). Report of the independent experts on medium and long term goals for aviation fuel burn reduction from technology. Montreal: ICAO.  [Google Scholar] ; Peeters & Middel, 2007 Peeters, P.M., & Middel, J. (2007). Historical and future development of air transport fuel efficiency. In R. Sausen, A. Blum, D.S. Lee, & C. Brüning (Eds.), Proceedings of an International Conference on Transport, Atmosphere and Climate (TAC), Oxford, United Kingdom, 26–29 June 2006 (pp. 42–47). Oberpfaffenhofen: DLR Institut für Physic der Atmosphäre.  [Google Scholar] ), it is imperative that research focuses on how the radical socio-technical transitions that are necessary to put the tourism and transport sectors on a sustainable emissions path can be achieved. Technical solutions alone will be too little and too late (Chèze, Chevallier, & Gastineau, 2013 Chèze, B., Chevallier, J., & Gastineau, P. (2013). Will technological progress be sufficient to stabilize CO2 emissions from air transport in the mid-term? (No. Les cahiers de l'économie – no. 94). Rueil-Malmaison: Centre Économie et Gestion.  [Google Scholar] ; Peeters, Higham, Kutzner, Cohen, & Gössling, under review Peeters, P., Higham, J.E.S., Kutzner, D., Cohen, S., & Gössling, S. Are technology myths stalling aviation climate policy? Transportation Research Part D: Transport and Environment, under review. [Web of Science ®]   [Google Scholar] ). This includes not only a recognition that the present socio-technical landscape is dominated by neoliberal, techno-centric and ecological modernisation values (Hall, 2013 Hall, C.M. (2013). Framing behavioural approaches to understanding and governing sustainable tourism consumption: Beyond neoliberalism, ‘nudging’ and ‘green growth’? Journal of Sustainable Tourism, 21(7), 1091–1109. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ; Hopkins & Higham, 2012 Hopkins, D., & Higham, J.E.S. (2012). Framework conventions for climate change: An analysis of global framework conventions with reference to resource governance and environmental management approaches in New Zealand. In A. Holden & D. Fennell (Eds.), A handbook of tourism and the environment (pp. 227–240). London: Routledge.  [Google Scholar] ), but also the need for a concerted effort by tourism and transport researchers to become active advocates of pathways to structural change, influence policy learning and provide politicians with tools to simulate policy-making and its effects.\nThe Freiburg 2014 workshop\nThe Freiburg 2014 workshop, held in Freiburg im Breisgau in Germany (1–4 July 2014), sought to address the inability of policy-makers and other stakeholders to change the tourism mobility system towards sustainable development. Its objectives stemmed directly from the Freiburg 2012 workshop, the results of which were disseminated in the Journal of Sustainable Tourism (volume 21, issue 7; see Higham et al., 2013 Higham, J.E.S., Cohen, S.A., Peeters, P., & Gössling, S. (2013). Psychological and behavioural approaches to understanding and governing sustainable mobility. Journal of Sustainable Tourism, 21(7), 949–967. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ) and in an edited book (Cohen, Higham, Peeters, & Gössling, 2014 Cohen, S.A., Higham, J.E.S., Peeters, P., & Gössling, S. (2014). Understanding and governing sustainable tourism mobility: Psychological and behavioural approaches. London: Routledge.  [Google Scholar] ).\nA key outcome from Freiburg 2012 was the conclusion that the public are generally unwilling or unable to change tourism and transport behaviour based on an awareness of environmental impacts, and specifically climate change. It was concluded that “the autonomy of individual pro-environmental response, when set within the systems of provision in late-capitalist consumer society, is fraught with challenge” (Higham et al., 2013 Higham, J.E.S., Cohen, S.A., Peeters, P., & Gössling, S. (2013). Psychological and behavioural approaches to understanding and governing sustainable mobility. Journal of Sustainable Tourism, 21(7), 949–967. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] , p. 14) and that the “low sustainability of the current tourism system is embedded in structures that make it easy and often cheaper to travel unsustainably … raising a wide range of questions regarding transport infrastructures, taxation, management and governance” (Cohen et al. 2014 Cohen, S.A., Higham, J.E.S., Peeters, P., & Gössling, S. (2014). Understanding and governing sustainable tourism mobility: Psychological and behavioural approaches. London: Routledge.  [Google Scholar] , p. 301). This conclusion illustrated the need to move beyond voluntary behavioural change in order to achieve sustainable mobility, and to explore the socio-technical landscapes in which individuals are embedded, through which public behaviour is conditioned and patterned.\nA further crucial conclusion from Freiburg 2012 was that policy-makers had shown limited interest in adopting policy measures that would achieve significant changes in sustainable transport behaviour. This lack of political initiative, wherein it was clear that politicians have far more links to industry than to science, and particularly to the social sciences, suggested that the reasons behind the inaction in transport governance needed to be urgently and critically explored. Overall, it was evident that while a comprehensive understanding of the psychologies of tourism and transport consumption is necessary to inform policy-makers, this alone would not be enough to bring the sectors onto a climatically sustainable pathway, and that radical transitions in the systems of provision and deeper understandings of political psychologies are needed (Cohen et al., 2014 Cohen, S.A., Higham, J.E.S., Peeters, P., & Gössling, S. (2014). Understanding and governing sustainable tourism mobility: Psychological and behavioural approaches. London: Routledge.  [Google Scholar] ; Hall, 2013 Hall, C.M. (2013). Framing behavioural approaches to understanding and governing sustainable tourism consumption: Beyond neoliberalism, ‘nudging’ and ‘green growth’? Journal of Sustainable Tourism, 21(7), 1091–1109. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ; Higham et al., 2013 Higham, J.E.S., Cohen, S.A., Peeters, P., & Gössling, S. (2013). Psychological and behavioural approaches to understanding and governing sustainable mobility. Journal of Sustainable Tourism, 21(7), 949–967. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ).\nThese insights formed the basis for the Freiburg 2014 workshop, which expanded its discussions to focus on public behaviour change, but also on how to change the behaviour of policy-makers, industry stakeholders and researchers themselves, to help achieve changes in tourism and transport systems for environmental reasons. Central to this endeavour was the question of how to bridge the science–policy gap: it was abundantly clear that despite the substantial and expanding body of research on tourism and climate change (Hall et al., 2015 Hall, C.M., Amelung, B., Cohen, S., Eijgelaar, E., Gössling, S., Higham, J., … Scott, D. (2015). On climate change skepticism and denial in tourism. Journal of Sustainable Tourism, 23(1), 4–25. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ), and on transport and climate change (Schwanen, et al., 2011 Schwanen, T., & Lucas, K. (2011). Understanding auto motives. In K. Lucas, E. Blumenberg, & R. Weinberger (Eds.), Auto motives: Understanding car use behaviours. (pp. 3–38). Emerald: Bingley. [Crossref]   [Google Scholar] ), this corpus of knowledge was having little to no effect in practice on governance.\nThe Freiburg 2014 workshop is the basis for this special issue presenting 10 papers, including this overview paper, exploring the dimensions and details of the science–policy gap in sustainable mobility. Having established the context in which the workshop was set, and before introducing the papers in this special issue, we now discuss three essential themes that are vital to understanding why, despite clear scientific evidence as to the growing environmental impacts of tourism transport, and particularly air travel, there is large-scale inertia in structural transitions and a lack of political willpower to enact meaningful policy change: (1) the importance of addressing socio-technical factors, (2) the barriers posed by placing faith in “technology myths” and (3) the need to overcome “transport taboos” in policy-making. The paper concludes by setting a research agenda that forms the basis for the forthcoming Freiburg 2016 workshop (28 June to 1 July 2016).\nSocio-technical factors\nCurrent growth trajectories indicate that transport emissions will double by 2050: the global fleet of light-duty vehicles is expected to double during that time period, and “demand for freight transport (road, rail, shipping, and air) and passenger aviation is projected to surge as well” (Creutzig et al., 2015 Creutzig, F., Jochem, P., Edelenbosch, O.Y., Mattauch, L., van Vuuren, D.P., McCollum, D., & Minx, J. (2015). Transport: A roadblock to climate change mitigation? Science, 350(6263), 911–912. [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] , p. 911). Air travel in particular offers an example of largely intractable public travel behaviours that are entrenched in Europe and North America and being rapidly adopted in the emerging regions of the world (Freire-Medeiros & Name, 2013 Freire-Medeiros, B., & Name, L. (2013). Flying for the very first time: Mobilities, social class and environmental concerns in a Rio de Janeiro favela. Mobilities, 8(2), 167–184. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ; Higham, Cohen, & Cavaliere, 2014 Higham, J., Cohen, S., & Cavaliere, C. (2014). Climate change, discretionary air travel and the ‘flyers’ dilemma'. Journal of Travel Research, 53(4), 462–475. [Crossref] , [Web of Science ®]   [Google Scholar] ). The development of low-cost, high-volume aviation, initially in Europe and North America, and latterly in Brazil, Russia, India and China, is now powering similar air travel growth trajectories in the emerging neoliberal economies of Mexico, South Africa, Indonesia and Turkey (Boeing, 2014 Boeing. (2014). Current market outlook 2014-2033. Seattle, WA: Boeing Commercial Airplanes.  [Google Scholar] ). Growth in air travel over the last two decades has been rapid (Gössling & Upham, 2009 Gössling, S., & Upham, P. (Eds.). (2009). Climate change and aviation: Issues, challenges and solutions. London: Earthscan.  [Google Scholar] ), and the current growth trajectory is projected to continue at a rate of 3.3% per annum to 2030 (Hall, 2013 Hall, C.M. (2013). Framing behavioural approaches to understanding and governing sustainable tourism consumption: Beyond neoliberalism, ‘nudging’ and ‘green growth’? Journal of Sustainable Tourism, 21(7), 1091–1109. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ).\nCalls for tourism to move onto a sustainable emissions path (Becken, 2007 Becken, S. (2007). Tourists' perception of international air travel's impact on the global climate and potential climate change policies. Journal of Sustainable Tourism, 15, 351–368. [Taylor & Francis Online]   [Google Scholar] ) have been especially challenged by growing demand for air travel. This growth has been driven by significant structural changes in the transportation sector (Ryley, Davison, Bristow, & Pridmore, 2010 Ryley, T., Davison, L., Bristow, A., & Pridmore, A. (2010). Public engagement on aviation taxes in the United Kingdom. International Journal of Sustainable Transportation, 4(2), 112–128. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ). Neoliberalism has been embraced by the aviation industry through airline deregulation, the deployment of frequent flyer loyalty programmes and notably by the unrestrained growth of low-cost carriers (LCCs) (Duval, 2013 Duval, D.T. (2013). Critical issues in air transport and tourism. Tourism Geographies, 15(3), 494–510. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ). Network airlines offering full service and traditional routes have been drawn into intense competition with LCCs, transforming the travel market through the uptake of technology to substantially reduce labour costs (Holloway, Humphreys, & Davidson, 2009 Holloway, J.C., Humphreys, C., & Davidson, R. (2009). The business of tourism (8th ed.). Harlow: Pearson Education.  [Google Scholar] ). The LCCs have developed direct sales systems (i.e. internet booking systems), online check-in and product itemisation (e.g. priority boarding, seat allocation, baggage allowances, in-flight food and entertainment services) to de-personalise airport and air travel experiences, while increasing aircraft utilisation and flight loadings, while reducing fares (Boeing, 2014 Boeing. (2014). Current market outlook 2014-2033. Seattle, WA: Boeing Commercial Airplanes.  [Google Scholar] ; Casey, 2010 Casey, M.E. (2010). Low cost air travel: Welcome aboard? Tourist Studies, 10(2), 175–191. [Crossref]   [Google Scholar] ). The LCC business model includes operating with a single aircraft type, providing a single-class product, serving secondary airports and avoiding the costs of frequent flyer programmes (Boeing, 2014 Boeing. (2014). Current market outlook 2014-2033. Seattle, WA: Boeing Commercial Airplanes.  [Google Scholar] ).\nThe consequential growth in demand for low-cost air travel is recognised as “one of the biggest revolutions in tourism and travel since the package holiday's arrival half a century earlier” (Casey, 2010 Casey, M.E. (2010). Low cost air travel: Welcome aboard? Tourist Studies, 10(2), 175–191. [Crossref]   [Google Scholar] , p. 176). The success of the LCCs is reflected in the increasingly ordinary nature of air travel in certain sections of some societies (Randles & Mander, 2009a Randles, S., & Mander, S. (2009a). Practice(s) and ratchet(s): A sociological examination of frequent flying. In S. Gössling & P. Upham (Eds.), Climate change and aviation: Issues, challenges and solutions (pp. 245–271). London: Earthscan.  [Google Scholar] ; Urry, 2010 Urry, J. (2010). Sociology and climate change. The Sociological Review, 57(2), 84–100. [Crossref]   [Google Scholar] ). New structures of air travel provision have created flying as a highly accessible consumer product, shifting leisure travel into the domain of everyday consumer capitalism (Young, Higham, & Reis, 2014 Young, M., Higham, J.E.S., & Reis, A. (2014). Up in the air: A conceptual critique of flying addiction. Annals of Tourism Research, 41, 51–64. [Crossref] , [Web of Science ®]   [Google Scholar] ). Indeed the extent to which these structures have shaped and influenced everyday consumer practices has, in some cases, reached absurd proportions. Ben Schlappig – “the man who flies around the world for free” – is “… one of the biggest stars among an elite group of obsessive flyers whose mission is to outwit the airlines” (Wofford, 2015 Wofford, B. (2015). Up in the air: Meet the man who flies around the world for free. Rolling Stone Magazine, 20 July 2014.  [Google Scholar] , p. 3). Perfecting the art of “travel hacking” – known among its members as “The Hobby” – Schlappig seeks perfection in the art of non-stop air travel and consumer luxury that is paid for by a “… gargantuan cache of frequent flier miles that grows only bigger by the day” (Wofford, 2015 Wofford, B. (2015). Up in the air: Meet the man who flies around the world for free. Rolling Stone Magazine, 20 July 2014.  [Google Scholar] , p. 5). Schlappig's claim is to be “beating the airlines at their own game”; through the gaming of frequent flyer programmes using techniques that he shares with a half million strong following through the “FlyerTalk” website.\nThe gaming of frequent flyer programmes offers an, albeit extreme, insight into consumer air travel behaviour that is anchored in and enabled by the socio-technical system. It forms part of a wider pattern of increasing affordability and uptake of air travel across an expanding range of social classes and societies (Randles & Mander, 2009b Randles, S., & Mander, S. (2009b). Aviation, consumption and the climate change debate: ‘Are you going to tell me off for flying?’ Technology Analysis & Strategic Management, 21(1), 93–113. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ). It is this growth in demand for air travel that contributes significantly to driving up tourism transport emissions (Gössling & Peeters, 2015 Gössling, S., & Peeters, P. (2015). Assessing tourism's global environmental impact 1900–2050. Journal of Sustainable Tourism, 23(5), 639–659. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ). With current and projected growth in aviation emissions has come recognition that the freedom to engage in unrestrained air travel comes with significant environmental costs (IPCC, 2013 IPCC. (2013). Climate change 2013: The physical science basis. Retrieved 28 November 2013 from IPCC web site: http://www.ipcc.ch/report/ar5/wg1/#.Uu70df0p8ds  [Google Scholar] ). While the environmental costs of air travel are now widely understood and accepted by the travelling public, the necessary responses in terms of consumer demand have not followed (Gössling, 2009 Gössling, S., & Upham, P. (Eds.). (2009). Climate change and aviation: Issues, challenges and solutions. London: Earthscan.  [Google Scholar] ; Higham, Cohen, Peeters, & Gössling, 2013 Higham, J.E.S., Cohen, S.A., Peeters, P., & Gössling, S. (2013). Psychological and behavioural approaches to understanding and governing sustainable mobility. Journal of Sustainable Tourism, 21(7), 949–967. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ).\nIt is ironic that the increasingly aeromobile middle classes can be the same people who claim to be environmentally aware and moral consumers (Dolnicar, Juvan, Ring, & Leisch, in press Dolnicar, S., Juvan, E., Ring, A. & Leisch, F. (in press). Tourist segments' justifications for behaving in an environmentally unsustainable way. Journal of Sustainable Tourism, DOI: 10.1080/09669582.2015.10248861 [Crossref] , [Web of Science ®]   [Google Scholar] ; Young et al., 2014 Young, M., Higham, J.E.S., & Reis, A. (2014). Up in the air: A conceptual critique of flying addiction. Annals of Tourism Research, 41, 51–64. [Crossref] , [Web of Science ®]   [Google Scholar] ). Within the context of air travel the “flyers’ dilemma” describes the tension between the self-identity of consumers who feel moral responsibility for their consumer decisions, and the high environmental costs of flying (Higham, Cohen, & Cavaliere, 2014 Higham, J., Cohen, S., & Cavaliere, C. (2014). Climate change, discretionary air travel and the ‘flyers’ dilemma'. Journal of Travel Research, 53(4), 462–475. [Crossref] , [Web of Science ®]   [Google Scholar] ; Rosenthal, 2010 Rosenthal, E. (2010, May 24). Can we kick our addiction to flying? Retrieved 13 September 2010 from The Guardian web site: http://www.guardian.co.uk/environment/2010/may/24/kick-addiction-flying/  [Google Scholar] ). The anxieties arising from the “flyers’ dilemma” have been empirically examined in various European societies (Higham, et al., 2016 Higham, J.E.S., Cohen, S.A., Cavaliere, C.T., Reis, A.C., & Finkler, W. (2016). Climate change, tourist air travel and radical emissions reduction. Journal of Cleaner Production, 111, 336–347. [Crossref] , [Web of Science ®]   [Google Scholar] ). Various studies have highlighted that air travel practices are largely unconstrained because flying is a cheap, convenient and socially desirable form of leisure consumption (Cohen & Higham, 2011 Cohen, S.A., & Higham, J.E.S. (2011). Eyes wide shut? UK consumer perceptions on aviation climate impacts and travel decisions to New Zealand. Current Issues in Tourism, 14(4), 323–335. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ; Higham & Cohen, 2011 Higham, J.E.S., & Cohen, S.A. (2011). Canary in the coalmine: Norwegian attitudes towards climate change and extreme long-haul air travel to Aotearoa/New Zealand. Tourism Management, 32(1), 98–105. [Crossref] , [Web of Science ®]   [Google Scholar] ).\nIt emerges that a focus on the demand-side of travel, in an attempt to address issues of sustainability through behaviour change, should not ignore the fundamental socio-structural factors that underpin the tourism system (Cornelissen, 2005 Cornelissen, S. (2005). The global tourism system. Aldershot: Ashgate.  [Google Scholar] ). Young, Markham, Reis, and Higham ( 2015 Young, M., Markham, F., Reis, A.C., & Higham, J.E.S. (2015). Flights of fantasy: A reformulation of the flyers' dilemma. Annals of Tourism Research, 54, 1–15. [Crossref] , [Web of Science ®]   [Google Scholar] ) argue that the locus of responsibility is critical to debates around sustainable aviation and sustainable mobility more broadly. Hall ( 2013 Hall, C.M. (2013). Framing behavioural approaches to understanding and governing sustainable tourism consumption: Beyond neoliberalism, ‘nudging’ and ‘green growth’? Journal of Sustainable Tourism, 21(7), 1091–1109. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] , p. 1101) observes that “mutual reinforcement between modes of governance and intervention … creates a path dependency in which solutions to sustainable tourism mobility are only identified within ‘green growth’ arguments for greater efficiency and market-based solutions.” Hall ( 2013 Hall, C.M. (2013). Framing behavioural approaches to understanding and governing sustainable tourism consumption: Beyond neoliberalism, ‘nudging’ and ‘green growth’? Journal of Sustainable Tourism, 21(7), 1091–1109. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ) argues that as long as the focus of government tourism policies remains situated in a GDP growth paradigm, the structures of transport provision will remain unchanged and the environment required to empower a consumer-led shift to a sustainable transport emissions path will not exist.\nYoung et al. ( 2015 Young, M., Markham, F., Reis, A.C., & Higham, J.E.S. (2015). Flights of fantasy: A reformulation of the flyers' dilemma. Annals of Tourism Research, 54, 1–15. [Crossref] , [Web of Science ®]   [Google Scholar] ) suggest that appealing to individuals to reduce or otherwise moderate their tourist travel consumption practices is a flawed response. It lacks the necessary government policy response to an industry that is environmentally damaging. Appealing to consumer sacrifice ignores the fundamental socio-structural underpinnings of an unsustainable travel industry. Young et al. ( 2015 Young, M., Markham, F., Reis, A.C., & Higham, J.E.S. (2015). Flights of fantasy: A reformulation of the flyers' dilemma. Annals of Tourism Research, 54, 1–15. [Crossref] , [Web of Science ®]   [Google Scholar] ) critically consider the social, institutional and economic forces that produce excessive and unsustainable travel consumption. They highlight, first and foremost, that within the existing structures of the aviation industry, currently no alternative options are available to avoid the high environmental costs of air travel (Young et al., 2014 Young, M., Higham, J.E.S., & Reis, A. (2014). Up in the air: A conceptual critique of flying addiction. Annals of Tourism Research, 41, 51–64. [Crossref] , [Web of Science ®]   [Google Scholar] ). No low-emission form of aviation exists to serve flyers who are concerned about climate change and aviation emissions (Peeters & Middel, 2007 Peeters, P.M., & Middel, J. (2007). Historical and future development of air transport fuel efficiency. In R. Sausen, A. Blum, D.S. Lee, & C. Brüning (Eds.), Proceedings of an International Conference on Transport, Atmosphere and Climate (TAC), Oxford, United Kingdom, 26–29 June 2006 (pp. 42–47). Oberpfaffenhofen: DLR Institut für Physic der Atmosphäre.  [Google Scholar] ), and neither is there any real prospect of major gains in aviation fuel efficiency in the short–medium term future (Peeters et al., under review) Peeters, P., Higham, J.E.S., Kutzner, D., Cohen, S., & Gössling, S. Are technology myths stalling aviation climate policy? Transportation Research Part D: Transport and Environment, under review. [Web of Science ®]   [Google Scholar] .\nWhile the airline industry has made significant gains in efficiency since the advent of jet aviation (Peeters & Dubois, 2010 Peeters, P., & Dubois, G. (2010). Tourism travel under climate change mitigation constraints. Journal of Transport Geography, 18(3), 447–457. [Crossref] , [Web of Science ®]   [Google Scholar] ), current technologies are locked in for periods of time that reach well beyond the urgent time frame required to achieve radical emission reductions (Higham et al., 2016 Higham, J.E.S., Cohen, S.A., Cavaliere, C.T., Reis, A.C., & Finkler, W. (2016). Climate change, tourist air travel and radical emissions reduction. Journal of Cleaner Production, 111, 336–347. [Crossref] , [Web of Science ®]   [Google Scholar] ). Jet aviation is highly efficient in terms of time/distance/cost thresholds (Howitt, Revol, Smith, & Rodger, 2010 Howitt, O.J.A., Revol, V.G.N., Smith, I.J., & Rodger, C.J. (2010). Carbon emissions from international cruise ship passengers' travel to and from New Zealand. Energy Policy, 38, 2552–2560. [Crossref] , [Web of Science ®]   [Google Scholar] ), but those energy efficiencies have been overwhelmed in real terms by growth in demand (Peeters & Dubois, 2010 Peeters, P., & Dubois, G. (2010). Tourism travel under climate change mitigation constraints. Journal of Transport Geography, 18(3), 447–457. [Crossref] , [Web of Science ®]   [Google Scholar] ), such that the environmental costs of air travel have become unacceptably high (Gössling, Hall, Peeters, and Scott 2010 Scott, D., Peeters, P. & Gössling, S. (2010). Can tourism deliver its aspiration greenhouse gas emission reduction targets? Journal of Sustainable Tourism, 18(3), 393–408. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ; Hall, 2013 Hall, C.M. (2013). Framing behavioural approaches to understanding and governing sustainable tourism consumption: Beyond neoliberalism, ‘nudging’ and ‘green growth’? Journal of Sustainable Tourism, 21(7), 1091–1109. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ). The current structure of the aviation industry and the absence of further substantial technical gains in aircraft efficiency (Scott, Peeters, & Gössling, 2010 Scott, D. (2016). The Paris Climate Change Conference and the tourism industry. Journal of Sustainable Tourism, under review  [Google Scholar] ) are such that aviation emissions are expected to double within a 25–45 year time frame (Gössling & Peeters, 2015 Gössling, S., & Peeters, P. (2015). Assessing tourism's global environmental impact 1900–2050. Journal of Sustainable Tourism, 23(5), 639–659. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ).\nDespite growing sustainability concerns, aviation, like the automobile (Dennis & Urry, 2009 Dennis, K., & Urry, J. (2009). After the car. Cambridge: John Wiley & Sons.  [Google Scholar] ), has become an integral part of contemporary mobility in many societies (Sheller & Urry, 2004 Sheller, M., & Urry, J. (Eds.). (2004). Tourism mobilities: Places to play, places in play. London: Routledge.  [Google Scholar] ; Urry, 2012 Urry, J. (2012). Social networks, mobile lives and social inequalities. Journal of Transport Geography, 21, 24–30. [Crossref] , [Web of Science ®]   [Google Scholar] ). Flying now out-competes other transport modes not only on convenience and time efficiency but – most critically – in terms of cost (Casey, 2010 Casey, M.E. (2010). Low cost air travel: Welcome aboard? Tourist Studies, 10(2), 175–191. [Crossref]   [Google Scholar] ). The time, cost and convenience advantages of air travel are structural factors that explain the deeply embedded nature of air travel practices (Higham, Cohen, & Cavaliere, 2014 Higham, J., Cohen, S., & Cavaliere, C. (2014). Climate change, discretionary air travel and the ‘flyers’ dilemma'. Journal of Travel Research, 53(4), 462–475. [Crossref] , [Web of Science ®]   [Google Scholar] ). The aviation system allows the production of tourism (and other forms of mobility) to be accelerated in terms of fit within the capitalist working day, week and calendar year (Young et al., 2015 Young, M., Markham, F., Reis, A.C., & Higham, J.E.S. (2015). Flights of fantasy: A reformulation of the flyers' dilemma. Annals of Tourism Research, 54, 1–15. [Crossref] , [Web of Science ®]   [Google Scholar] ). Given the fundamentally energy-intensive nature of the tourism system (Becken, 2016 Becken, S. (2016). Peak oil: A hidden issue? Social representations of professional tourism perspectives. Journal of Sustainable Tourism, 24(1), 31–51. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ), mitigating tourism transport emissions has proved a very imposing challenge (Schwanen et al., 2011 Schwanen, T., & Lucas, K. (2011). Understanding auto motives. In K. Lucas, E. Blumenberg, & R. Weinberger (Eds.), Auto motives: Understanding car use behaviours. (pp. 3–38). Emerald: Bingley. [Crossref]   [Google Scholar] ). Not least, neither car nor rail nor even high-speed rail can match the cost, convenience and flexibility of response that air travel can, especially if sea crossings are involved.\nIt is also apparent that travellers, even those who are concerned about their personal leisure travel emissions, are able to disregard their environmental concerns and take advantage of cheap and convenient air travel opportunities (Higham et al., 2016 Higham, J.E.S., Cohen, S.A., Cavaliere, C.T., Reis, A.C., & Finkler, W. (2016). Climate change, tourist air travel and radical emissions reduction. Journal of Cleaner Production, 111, 336–347. [Crossref] , [Web of Science ®]   [Google Scholar] ; Young et al., 2015 Young, M., Markham, F., Reis, A.C., & Higham, J.E.S. (2015). Flights of fantasy: A reformulation of the flyers' dilemma. Annals of Tourism Research, 54, 1–15. [Crossref] , [Web of Science ®]   [Google Scholar] ). Even for those who are deeply concerned about climate change (see Cohen, & Higham, 2011 Cohen, S.A., & Higham, J.E.S. (2011). Eyes wide shut? UK consumer perceptions on aviation climate impacts and travel decisions to New Zealand. Current Issues in Tourism, 14(4), 323–335. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ; Higham & Cohen, 2011 Higham, J.E.S., & Cohen, S.A. (2011). Canary in the coalmine: Norwegian attitudes towards climate change and extreme long-haul air travel to Aotearoa/New Zealand. Tourism Management, 32(1), 98–105. [Crossref] , [Web of Science ®]   [Google Scholar] ), the time and costs advantages of air travel undermine the competitiveness of alternative, more sustainable transport modes (Higham et al., 2014 Higham, J., Cohen, S., & Cavaliere, C. (2014). Climate change, discretionary air travel and the ‘flyers’ dilemma'. Journal of Travel Research, 53(4), 462–475. [Crossref] , [Web of Science ®]   [Google Scholar] ). The time/distance/cost dimensions of air travel have also allowed the consumption of distant tourist destinations to fit within narrow windows of time (e.g. the EasyJet generation of weekend “escape artists”). The act of flying has become integral to significant parts of the contemporary tourism transport system (Young et al., 2015 Young, M., Markham, F., Reis, A.C., & Higham, J.E.S. (2015). Flights of fantasy: A reformulation of the flyers' dilemma. Annals of Tourism Research, 54, 1–15. [Crossref] , [Web of Science ®]   [Google Scholar] ).\nAs Young et al. ( 2014 Young, M., Higham, J.E.S., & Reis, A. (2014). Up in the air: A conceptual critique of flying addiction. Annals of Tourism Research, 41, 51–64. [Crossref] , [Web of Science ®]   [Google Scholar] ) observe, aviation has proven to be resistant to consumer-led change, in contrast to other aspects of consumer behaviour, such as food purchases, recycling, the use of public land transport and the conscious uptake of active transport modes, which are relatively open to modification by individuals (Barr, Shaw, Coles, & Prillwitz, 2010 Barr, S., Shaw, G., Coles, T., & Prillwitz, J. (2010). ‘A holiday is a holiday’: Practicing sustainability, home and away. Journal of Transport Geography, 18(3), 474–481. [Crossref] , [Web of Science ®]   [Google Scholar] ; Lassen, 2010 Lassen, C. (2010). Environmentalist in business class: An analysis of air travel and environmental attitude. Transport Reviews, 30(6), 733–751. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ). The intractability of air travel behaviour change occurs not only because air travel has become a desirable and affordable gateway to tourism in many societies (Casey, 2010 Casey, M.E. (2010). Low cost air travel: Welcome aboard? Tourist Studies, 10(2), 175–191. [Crossref]   [Google Scholar] ), but also because “… the environmental risks associated with air travel are global and systemic, as opposed to specific and individual, and tend not to be prioritised within a flyers' environmental consciousness” (Young et al., 2014 Young, M., Higham, J.E.S., & Reis, A. (2014). Up in the air: A conceptual critique of flying addiction. Annals of Tourism Research, 41, 51–64. [Crossref] , [Web of Science ®]   [Google Scholar] , p. 60). As a result climate concerns may be temporarily suspended with impunity so that consumers can continue to consume leisure travel that involves flying (Watson, 2014 Watson, C. (Ed.). (2014). Beyond flying: Rethinking air travel in a globally connected world. Cambridge: Green Books.  [Google Scholar] ).\nThe current structures of aviation provision foster the willingness of the public to temporarily suspend their climate concerns when engaging in tourism practices (Barr et al., 2010 Barr, S., Shaw, G., Coles, T., & Prillwitz, J. (2010). ‘A holiday is a holiday’: Practicing sustainability, home and away. Journal of Transport Geography, 18(3), 474–481. [Crossref] , [Web of Science ®]   [Google Scholar] ; Cohen, Higham, & Reis, 2013 Cohen, S.A., Higham, J., & Reis, A. (2013). Sociological barriers to sustainable discretionary air travel behaviour. Journal of Sustainable Tourism, 21(7), 982–998. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ). The aviation industry facilitates a range of spatio-temporal fixes (Young et al., 2014 Young, M., Higham, J.E.S., & Reis, A. (2014). Up in the air: A conceptual critique of flying addiction. Annals of Tourism Research, 41, 51–64. [Crossref] , [Web of Science ®]   [Google Scholar] ) that invite the consumer to offset their aviation carbon emissions through various schemes (Barr et al., 2010 Barr, S., Shaw, G., Coles, T., & Prillwitz, J. (2010). ‘A holiday is a holiday’: Practicing sustainability, home and away. Journal of Transport Geography, 18(3), 474–481. [Crossref] , [Web of Science ®]   [Google Scholar] ; Gössling et al., 2007 Gössling, S., Broderick, J., Upham, P., Peeters, P., Strasdas, W., Ceron, J.-P., & Dubois, G. (2007). Voluntary carbon offsetting schemes for aviation: Efficiency and credibility. Journal of Sustainable Tourism, 15(3), 223–248. [Taylor & Francis Online]   [Google Scholar] ). Offset schemes encourage concerned travellers to assume responsibility for a profligate industry, by incurring an additional cost to mitigate the externalities of aviation consumption (Young et al., 2014 Young, M., Higham, J.E.S., & Reis, A. (2014). Up in the air: A conceptual critique of flying addiction. Annals of Tourism Research, 41, 51–64. [Crossref] , [Web of Science ®]   [Google Scholar] ). In doing so offsetting “… actually plays into the hands of an environmentally destructive industry by allowing it to legitimate its practices while simultaneously absolving itself from responsibility for the environmental destruction from which it profits” (Young et al., 2014 Young, M., Higham, J.E.S., & Reis, A. (2014). Up in the air: A conceptual critique of flying addiction. Annals of Tourism Research, 41, 51–64. [Crossref] , [Web of Science ®]   [Google Scholar] , p. 52). This absolution of individual responsibility is an important factor in the accelerating aviation emissions problem (Creutzig et al., 2015 Creutzig, F., Jochem, P., Edelenbosch, O.Y., Mattauch, L., van Vuuren, D.P., McCollum, D., & Minx, J. (2015). Transport: A roadblock to climate change mitigation? Science, 350(6263), 911–912. [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] ). It relates closely to what Hall ( 2013 Hall, C.M. (2013). Framing behavioural approaches to understanding and governing sustainable tourism consumption: Beyond neoliberalism, ‘nudging’ and ‘green growth’? Journal of Sustainable Tourism, 21(7), 1091–1109. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ) refers to as “structures of provision”; the social and institutional structures that underpin unsustainable consumption practices. Expecting the consumer to accept responsibility and respond individually to unsustainable contemporary travel mobilities, in the absence of meaningful industry and policy responses, has proven to be futile (Higham et al., 2016 Higham, J.E.S., Cohen, S.A., Cavaliere, C.T., Reis, A.C., & Finkler, W. (2016). Climate change, tourist air travel and radical emissions reduction. Journal of Cleaner Production, 111, 336–347. [Crossref] , [Web of Science ®]   [Google Scholar] ).\nTechnology myths\nA further vital reason why there is inertia in policy responses to growing aviation emissions is the ongoing industry-led myth, perpetuated by the media and transport policy-makers, that decarbonisation is in progress using radical technological innovation. Gotesky ( 1952 Gotesky, R. (1952). The nature of myth and society. American Anthropologist, 54(4), 523–531. [Crossref] , [Web of Science ®]   [Google Scholar] , p. 530) describes the function of a myth as to “preserve institutions and institutional process”. A “myth” is defined as an idea, story or narrative believed by many people, including decision-makers, even though unfounded or false. As Edelman ( 1998 Edelman, M. (1998). Language, myths and rhetoric. Society, 35(2), 131–139. [Crossref] , [Web of Science ®]   [Google Scholar] , p. 131) reminds us, “[p]olitical language can evoke a set of mythic beliefs in subtle and powerful ways.” Misleading information from the transport and tourism sectors is not new. Gössling and Peeters ( 2007 Gössling, S., Broderick, J., Upham, P., Peeters, P., Strasdas, W., Ceron, J.-P., & Dubois, G. (2007). Voluntary carbon offsetting schemes for aviation: Efficiency and credibility. Journal of Sustainable Tourism, 15(3), 223–248. [Taylor & Francis Online]   [Google Scholar] , p. 402), found four major industry discourses: “air travel is energy efficient; air travel's share of total emissions is negligible; fuel use is constantly minimised and new technology will solve the problem.” All four were deconstructed as being not representative of reality. This section explores the existence and role of “technology myths” in the discourse of sustainable aviation.\nMyths also play a role in other transport modes. Within automobility, for instance, Volkswagen created a green myth around low-emission diesel cars, even though this was largely based on cheating regulations (Franco, Sánchez, German, & Mock, 2014 Franco, V., Sánchez, F.P., German, J., & Mock, P. (2014). Real-world exhaust emissions from modern diesel cars. Berlin: International Council on Clean Transportation Europe.  [Google Scholar] ). So why concentrate on aviation within the domain of sustainable tourism? First because the tourism sector is a central part of passenger aviation, although we cannot be sure exactly how central it is: leisure travel is interlinked with business travel, visiting friends and relatives and other visit motivations. The tourism sector consequently needs to be seen as integral to air transport; the tourism industry cannot be absolved of responsibility for aviation emissions more generally.\nThe second reason is that air transport, though a relatively small part of tourism in terms of total trips (19% in 2010), represents a high share (52% in 2010) of tourism's global emissions, a share that is growing (62% in 2015), which means that aviation's emissions are increasing faster than those of accommodation, car and rail (Gössling & Peeters, 2015 Gössling, S., & Peeters, P. (2015). Assessing tourism's global environmental impact 1900–2050. Journal of Sustainable Tourism, 23(5), 639–659. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ). There is a large body of literature showing that future emissions of aviation are growing fast and that this growth is inevitable given transport volume growth projections (Mayor & Tol, 2010 Mayor, K., & Tol, R.S.J. (2010). Scenarios of carbon dioxide emissions from aviation. Global Environmental Change, 20(1), 65–73. [Crossref] , [Web of Science ®]   [Google Scholar] ; Owen, Lee, & Lim, 2010 Owen, B., Lee, D.S., & Lim, L. (2010). Flying into the future: Aviation emissions scenarios to 2050. Environmental Science & Technology, 44(7), 2255–2260. [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] ; Peeters & Dubois, 2010 Peeters, P., & Dubois, G. (2010). Tourism travel under climate change mitigation constraints. Journal of Transport Geography, 18(3), 447–457. [Crossref] , [Web of Science ®]   [Google Scholar] ; Sgouridis, Bonnefoy, & Hansman, 2010 Sgouridis, S., Bonnefoy, P.A., & Hansman, R.J. (2010). Air transportation in a carbon constrained world: Long-term dynamics of policies and strategies for mitigating the carbon footprint of commercial aviation. Transportation Research Part A: Policy and Practice, 45(10), 1077–1091. [Crossref] , [Web of Science ®]   [Google Scholar] ; Vorster, Ungerer, & Volschenk, 2012 Vorster, S., Ungerer, M., & Volschenk, J. (2012). 2050 scenarios for long-haul tourism in the evolving global climate change regime. Sustainability, 5(1), 1–51. [Crossref] , [Web of Science ®]   [Google Scholar] ).\nFrom a recent study (Peeters et al., under review) Peeters, P., Higham, J.E.S., Kutzner, D., Cohen, S., & Gössling, S. Are technology myths stalling aviation climate policy? Transportation Research Part D: Transport and Environment, under review. [Web of Science ®]   [Google Scholar] it was found that the aviation industry creates “technology myths” that may hamper political initiatives that would enforce mitigation on the aviation sector. Industry commonly wields terms such as “efficiency”, “constantly minimised” or “negligible shares” as discursive devices to perpetuate the myth that technological innovation will neutralise the problem of aviation emissions. Technology myths were identified by Peeters et al. ( under review Peeters, P., Higham, J.E.S., Kutzner, D., Cohen, S., & Gössling, S. Are technology myths stalling aviation climate policy? Transportation Research Part D: Transport and Environment, under review. [Web of Science ®]   [Google Scholar] ) for airframe design (laminar flow, composite structures and blended wing body), engines/propulsion (solar flight, electric flight and propfan) and alternative fuels (Jatropha, animal fats, hydrogen and micro-algae). For these 10 technologies media coverage in newspapers was measured over the past two decades and content analysed.\nLaminar flow and composite structures are widely applied already, with the newest types of planes, like the Boeing B787 and Airbus A350, using, for instance, composites in up to 50% of the construction by weight (Lee, 2010 Lee, J.J. (2010). Can we accelerate the improvement of energy efficiency in aircraft systems? Energy Conversion and Management, 51(1), 189–196. [Crossref] , [Web of Science ®]   [Google Scholar] ). But composite structures allow for weight savings of between 14% and 25% (Raymer et al., 2011 Raymer, D.P., Wilson, J., Perkins, H.D., Rizzi, A., Zhang, M., & Puentes, A.R. (2011). Advanced technology subsonic transport study n+3 technologies and design concepts (No. NASA/TM-2011-217130). Cleveland, OH: Glenn Research Center.  [Google Scholar] ) for the structure to which it is applied. So overall weight reduction of the Boeing B787 would be between 7% and 13%. The impact of this weight savings on fuel efficiency depends on how the designer uses the gains, but it may translate in the end to an approximate 5% fuel efficiency improvement (Peeters, 2000 Peeters, P., & Dubois, G. (2010). Tourism travel under climate change mitigation constraints. Journal of Transport Geography, 18(3), 447–457. [Crossref] , [Web of Science ®]   [Google Scholar] ). This Boeing 787 example clearly shows the strength of myths: the impressive 50% share of new materials is hyped in the media to a lay audience and impressed upon politicians, even though composite structures only offer small and evolutionary efficiency improvements, although coupled with improved engine design and materials, the Boeing 787 and Airbus A350 can offer fuel savings of up to 25% per seat mile over the 15–20 year old aircraft that they are replacing. The latter is an impressive figure, but it also means that fares can be reduced, encouraging more people to travel.\nBlended wing body aircraft have a long history of promises but have never emerged and are unlikely to in the near to mid-term future, or even later. Solar flight has recently attracted much attention. Basic physics tells us that it will never play a serious transport role (Noth, 2008 Noth, A. (2008). Design of solar powered airplanes for continuous flight (Unpublished PhD). ETH Zürich.  [Google Scholar] ), but the ICAO ( 2014 ICAO. (2014). 2013 environmental report. Destination green. Montreal: Author.  [Google Scholar] , p. 12) propagates discourses suggesting that it could solve environmental problems: “the Solar Impulse demonstrated that a solar-powered airplane can fly day and night without fuel.” Public interest in electric flight has followed the same strong rise since the mid-2000s. The main issue with electric flight is the requirement for high performance batteries. Current lithium batteries have a power density that falls short of the requirements for full electric flight by a factor of 100 (Kivits, Charles, & Ryan, 2010 Kivits, R., Charles, M.B., & Ryan, N. (2010). A post-carbon aviation future: Airports and the transition to a cleaner aviation sector. Futures, 42, 199–211. [Crossref] , [Web of Science ®]   [Google Scholar] ). This makes the anticipated 2035 realisation of electric flight (The Australian, 2/11/2012), extremely unlikely.\nOf the four alternative fuels, Jatropha, animal fats and hydrogen were hyped by the media between 2008 and 2011 but are now little mentioned, with significant interest only in micro-algae. Still the sector widely cites alternative fuels as promising future replacements for fossil fuels (Air Transport Action Group [ATAG], 2011 Air Transport Action Group (ATAG). (2011). Powering the future of flight. The six easy steps to growing a viable aviation biofuels industry. Geneva: Author.  [Google Scholar] ; Airbus, 2011 Airbus. (2011). Delivering the future. Global market forecast 2011–2030. Paris: Author.  [Google Scholar] ; Boeing, 2012 Boeing. (2012). Current market outlook 2012-2031. Seattle, WA. Boeing Commercial Airplanes.  [Google Scholar] ; IATA, 2012 IATA. (2012). A global approach to reducing aviation emissions. First stop: Carbon-neutral growth from 2020. Montreal: Author.  [Google Scholar] ; ICAO, 2014 ICAO. (2014). 2013 environmental report. Destination green. Montreal: Author.  [Google Scholar] ; WTTC, 2009 WTTC. (2009). Leading the challenge on climate change. London: Author.  [Google Scholar] ). Jatropha faces issues of high water use (Rosillo-Calle, Thrän, Seiffert, & Teelucksingh, 2012 Rosillo-Calle, F., Thrän, D., Seiffert, M., & Teelucksingh, S. (2012). The potential role of biofuels in commercial air transport – biojetfuel. London: IEA Bioenergy Task 40 Sustainable International Bioenergy Trade.  [Google Scholar] ) and adverse socio-economic impacts (Ariza-Montobbio & Lele, 2010 Ariza-Montobbio, P., & Lele, S. (2010). Jatropha plantations for biodiesel in Tamil Nadu, India: Viability, livelihood trade-offs, and latent conflict. Ecological Economics, 70, 189–195. [Crossref] , [Web of Science ®]   [Google Scholar] ); animal fats face technical problems preventing them from being mixed at higher than 20% shares with kerosene (Vera-Morales & Schäfer, 2009 Vera-Morales, M., & Schäfer, A. (2009). Fuel-cycle assessment of alternative aviation fuels. Cambridge: Omega.  [Google Scholar] ); hydrogen is an old but unresolved idea (Brewer, 1991 Brewer, G.D. (1991). Hydrogen aircraft technology. London: CRC Press.  [Google Scholar] ); micro-algae suffer from land-use issues, at least in the European region (Skarka, 2012 Skarka, J. (2012). Microalgae biomass potential in Europe land availability as a key issue. Technikfolgenabschätzung – Theorie und Praxis, 21, 72–79.  [Google Scholar] ), and water use, low or negative life cycle CO2 emission reductions (Quinn & Davis, 2014 Quinn, J.C., & Davis, R. (2014). The potentials and challenges of algae based biofuels: A review of the techno-economic, life cycle, and resource assessment modeling. Bioresource Technology, 184, 444–452. [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] ), cost and more profitable alternative land uses (Coplin, 2012 Coplin, L.G. (2012). Sustainable development of algal biofuels in the United States. Washington, DC: National Academies Press.  [Google Scholar] ).\nPolicy-makers are required to make decisions that often have long-term effects and are clouded in uncertainties. The quality of such decision-making for the transport sector is significantly degraded by technology myths created by industry and perpetuated through the media (Peeters et al., under review Peeters, P., Higham, J.E.S., Kutzner, D., Cohen, S., & Gössling, S. Are technology myths stalling aviation climate policy? Transportation Research Part D: Transport and Environment, under review. [Web of Science ®]   [Google Scholar] ). Such myths foster political inertia in the development of effective sustainable transport policy measures, discouraging potentially difficult but necessary decisions (Peeters, Gössling, & Lane, 2009 Peeters, P., Gössling, S., & Lane, B. (2009). Moving towards low-carbon tourism. New opportunities for destinations and tour operators. In S. Gössling, C.M. Hall, & D.B. Weaver (Eds.), Sustainable tourism futures. Perspectives on systems, restructuring and innovations (pp. 240–257). New York, NY: Routledge.  [Google Scholar] ).\nTransport taboos\nThe final major theme we discuss in this section of paper is the notion of “taboo” issues in tourism and transport policy-making. The question of why politicians have not acted in more significant ways on climate change mitigation in these sectors, as well as more generally, given that sound evidence of climate change was presented 25 years ago in the Intergovernmental Panel on Climate Change first assessment report (IPCC, 1990 IPCC. (1990). IPCC first assessment report 1990. Cambridge: Cambridge University Press.  [Google Scholar] ), is itself a relatively underexplored area of research. The adverse consequences of climate change for ecosystems and humans have since been confirmed and well documented (IPCC, 2014 IPCC. (2014). Climate change 2014: Synthesis report. Contribution of Working Groups 1, 2, and 3 to the fifth assessment report of the Intergovernmental Panel on Climate Change. Cambridge: Cambridge University Press.  [Google Scholar] ), and climate change is no longer considered a future phenomenon but rather a current and ongoing process, as, for instance, recognised by reinsurers (Munich Re, 2014 Munich Re. (2014). Overall picture of natural catastrophes in 2013 dominated by weather extremes in Europe and Supertyphoon Haiyan. Retrieved 8 January 2015 from http://www.munichre.com/en/media_relations/press_releases/2014/2014_01_07_press_release.aspx   [Google Scholar] ). As an outcome of the IPCC reports, political consensus has been achieved to stabilise greenhouse gas emissions at a level that will prevent global warming from exceeding 2 °C compared to pre-industrial temperatures, an objective confirmed during various Conferences of Parties (UNFCCC, 2014 UNFCCC. (2014). Various documents. Retrieved 17 July 2015 from www.unfccc.int   [Google Scholar] ) and recently recognised at the landmark Paris Agreement (Scott, 2016 Scott, D. (2016). The Paris Climate Change Conference and the tourism industry. Journal of Sustainable Tourism, under review  [Google Scholar] ).\nFor the transport sector, responsible for about 25% of global emissions, the European Commission (EC) has outlined emission reduction goals of -60% by 2050 compared to 1990, with an interim goal of -20% by 2030 compared to 2008 (EC, 2011 European Commission (EC). (2011). White paper: Roadmap to a single European transport area – towards a competitive and resource efficient transport system. COM(2011) 144 final. Brussels: Author.  [Google Scholar] ). These emission reductions are considered in line with the 2 °C guardrail. Yet, while climate policy objectives have been defined for the EU, and while these could also be defined for any country based on national greenhouse gas inventories, there is limited evidence of transport policies that would help to achieve such significant emission reductions, and, controversially, the EC has even outlined that curbing mobility is not considered a viable option (EC, 2011 European Commission (EC). (2011). White paper: Roadmap to a single European transport area – towards a competitive and resource efficient transport system. COM(2011) 144 final. Brussels: Author.  [Google Scholar] ). In countries and regions outside Europe, and specifically for international aviation as a significant sub-sector of tourism, transport-related mitigation policies have thus remained insignificant (Gössling, Scott, & Hall, 2013 Gössling, S., Scott, D., & Hall, C.M. (2013). Challenges of tourism in a low-carbon economy. Wiley Interdisciplinary Reviews: Climate Change, 4(6), 525–538. [Crossref] , [Web of Science ®]   [Google Scholar] ).\nYet, if energy-intense forms of mobility do not decline, it is highly unlikely that absolute reductions in greenhouse gas emissions can be achieved (Anable, Brand, Tran, & Eyre, 2012 Anable, J., Brand, C., Tran, M., & Eyre, N. (2012). Modelling transport energy demand: A socio-technical approach. Energy Policy, 41, 125–138. [Crossref] , [Web of Science ®]   [Google Scholar] ; Banister, 2008 Banister, D. (2008). The sustainable mobility paradigm. Transportation Policy, 15(1), 73–80. [Crossref] , [Web of Science ®]   [Google Scholar] , 2011 Banister, D. (2011). Cities, mobility and climate change. Journal of Transport Geography, 19(6), 1538–1546. [Crossref] , [Web of Science ®]   [Google Scholar] ; Chapman, 2007 Chapman, L. (2007). Transport and climate change: A review. Journal of Transport Geography, 15(5), 354–367. [Crossref] , [Web of Science ®]   [Google Scholar] ; IEA, 2012 IEA. (2012). World energy outlook 2011. Paris: Author.  [Google Scholar] ; Schäfer et al., 2009 Schäfer, A., Heywood, J.B., Jacoby, H.D., & Waitz, I.A., (2009). Transportation in a climate-constrained world. Cambridge, MA: MIT Press.  [Google Scholar] ; UNWTO, UNEP, & WMO, 2008 UNWTO, UNEP, & WMO. (2008). Climate change and tourism: Responding to global challenges. Madrid, Paris & Geneva: UNWTO, UNEP & WMO.  [Google Scholar] ). This has resulted in a situation where there are clear policy goals, and a wide range of market-based, command-and-control and soft policy measures available to achieve these goals (e.g. Friman, Larhult, & Gärling, 2012 Friman, M., Larhult, L., & Gärling, T. (2012). An analysis of soft transport policy measures implemented in Sweden to reduce private car use. Transportation, 40(1), 109–129. [Crossref] , [Web of Science ®]   [Google Scholar] ; OECD & UNEP, 2011 OECD & UNEP. (2011). Climate change and tourism policy in OECD countries. Paris: Author.  [Google Scholar] ; Sterner, 2007 Sterner, T. (2007). Fuel taxes: An important instrument for climate policy. Energy Policy, 35, 3194–3202. [Crossref] , [Web of Science ®]   [Google Scholar] ), but a dearth of implementation, with evidence that only soft policies focusing on voluntary behavioural change appear to be considered politically viable to reduce emissions from transportation. This paradox has been described as an “implementation gap” (Banister & Hickman, 2013 Banister, D., & Hickman, R. (2013). Transport futures: Thinking the unthinkable. Transportation Policy, 29, 283–293. [Crossref] , [Web of Science ®]   [Google Scholar] , p. 292), and led to growing academic interest in barriers to significant climate policy.\nVarious explanations have been provided to explain why governments have been reluctant to implement policies. From a governance viewpoint, Rietveld et al. ( 2005 Rietveld, P., & Stough, R. (Eds.). 2005. Barriers to sustainable transport: Institutions, regulation and sustainability. Abingdon: Spon Press.  [Google Scholar] ) have suggested that institutions rule and structure public and private actions, and that these can be informal, formal, governance-, and resource allocation/employment related. Informal institutions would comprise values, norms, practices, habits and traditions, and are considered conditioners of behaviour (see Schwanen & Lucas, 2011 Schwanen, T., & Lucas, K. (2011). Understanding auto motives. In K. Lucas, E. Blumenberg, & R. Weinberger (Eds.), Auto motives: Understanding car use behaviours. (pp. 3–38). Emerald: Bingley. [Crossref]   [Google Scholar] in the context of automobility). Formal institutions include “codified statutes, constitutions, provisions, laws, regulations, and high level administrative orders” (Rietveld et al., 2005 Rietveld, P., & Stough, R. (Eds.). 2005. Barriers to sustainable transport: Institutions, regulation and sustainability. Abingdon: Spon Press.  [Google Scholar] , p. 3). Governance institutions are a third type of institution focused on rules, including laws, regulations and policy directives, such as planning and zoning issues, or transactions involving actors and agents. Finally, resource allocation refers to government agencies, firms and non-profit associations allocating financial resources. These four categories can be used to identify and address barriers from various viewpoints, including, for instance, the notion that transport planning cannot be questioned, as transportation is important for society and economic growth. This has, for instance, been discussed by Miciukiewicz and Vigar ( 2012 Miciukiewicz, K., & Vigar, G. (2012). Mobility and social cohesion in the splintered city: Challenging technocentric transport research and policy-making practices. Urban Studies, 49(9), 1941–1957. [Crossref] , [Web of Science ®]   [Google Scholar] ) in terms of technological fixation among transport researchers and subsequent technocentric policy-making. In a similar vein, Hutton ( 2013 Hutton, B. (2013). Planning sustainable transport. London: Routledge.  [Google Scholar] ) describes how the turn from meeting predicted transport growth to managing transport demand has only recently been considered in UK transport policy. Ultimately, “barriers” thus often resemble embedded beliefs of ecological modernisation, i.e. the assumption that transport growth can be balanced environmentally, based on technological progress, as also evident in UNEP's ( 2011 UNEP. (2011). Towards a green economy: Pathways to sustainable development and poverty eradication. Retrieved 29 September 2015 from www.unep.org/greeneconomy   [Google Scholar] ) Green Growth focus, which may be seen as another ecological modernisation paradigm without real-world implications for emission growth (Hall, 2009 Hall, C.M. (2009). Degrowing tourism: Décroissance, sustainable consumption and steady-state tourism. Anatolia: An International Journal of Tourism and Hospitality Research, 20(1), 46–61. [Taylor & Francis Online]   [Google Scholar] , 2013 Hall, C.M. (2013). Framing behavioural approaches to understanding and governing sustainable tourism consumption: Beyond neoliberalism, ‘nudging’ and ‘green growth’? Journal of Sustainable Tourism, 21(7), 1091–1109. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] , 2015 Hall, C.M. (2015). Economic greenwash: On the absurdity of tourism and green growth. In M.V. Reddy & K. Wilkes (Eds.), Tourism in the green economy. (pp. 339–358). London: Earthscan by Routledge.  [Google Scholar] ).\nNew understandings of the reasons for inaction on climate change in transport contexts are thus required: “barriers” were discussed with regard to their cognitive and affective dimensions during the Freiburg 2014 workshop, where they were framed as “taboos” (Gössling & Cohen, 2014 Gössling, S., & Cohen, S. (2014). Why sustainable transport policies will fail: European Union climate policy in the light of transport taboos. Journal of Transport Geography, 39, 197–207. [Crossref] , [Web of Science ®]   [Google Scholar] ). Taboos are different from barriers of implementation, because they cannot be addressed politically without considerable (political) danger to the person taking up a given issue. To touch a taboo implies to violate an existing norm, i.e. a situation that is usually in the interest of powerful individuals, (lobby) organisations, or the broader public or community. A “transport taboo” thus describes an issue that cannot be raised without risks, possibly jeopardising the political future of any person raising the taboo. A wide range of transport taboos that politicians are unwilling to touch has been identified, such as the watering down of transport policy by lobbyism, the skewed share of transport emissions contributed by higher income classes and the broader societal glamorisation of high-energy transport consumption (Cohen & Gössling, 2015 Cohen, S.A., & Gössling, S. (2015). A darker side of hypermobility. Environment and Planning A, 47, 1661–1679. [Crossref] , [Web of Science ®]   [Google Scholar] ; for further details on transport taboos see Gössling & Cohen, 2014 Gössling, S., & Cohen, S. (2014). Why sustainable transport policies will fail: European Union climate policy in the light of transport taboos. Journal of Transport Geography, 39, 197–207. [Crossref] , [Web of Science ®]   [Google Scholar] ).\nTransport taboos are consequently issues that would appear obvious, as some solutions are ready at hand, demanding political action; yet, they are characterised by silence. A further example may be the 20 years of OECD reports recommending to remove fossil fuel subsidies, and to introduce carbon pricing ( 1991 OECD. (1991). Energy prices, taxes and carbon dioxide emissions (OECD economic studies 17). Paris: Author.  [Google Scholar] , 1999 OECD. (1999). Project on environmentally sustainable transport (EST) (Report NV/EPOC/PPC/T(99)3/FINAL/REV1). Paris: Author.  [Google Scholar] , 2008, 2015 OECD. (2015). OECD companion to the inventory of support measures for fossil fuels 2015. Retrieved 12 November 2015 from http://www.keepeek.com/Digital-Asset-Management/oecd/energy/oecd-companion-to-the-inventory-of-support-measures-for-fossil-fuels-2015_9789264239616-en#page1   [Google Scholar] ). However, the issue remains politically untouched, because this would lead to outrage by industry associations, who are powerful agents in public discourse. Yet, overcoming taboos is essential if more sustainable tourism and transport policies are to be implemented, specifically regarding climate change. At the very least, this would require political parties to stop using public sentiment to undermine sustainable transport policy initiatives by political opponents in order to gain votes on less popular measures related to climate change mitigation.\nThe papers in this special issue\nThis special issue presents nine further papers that explore avenues for behaviour change by various stakeholders in tourism and transport in order to bridge the science–policy gap in sustainable mobility. The contributions cover a wide spectrum of interests and stakeholders, and connect in various ways to the themes discussed above, notably socio-technical factors and transport taboos.\nThe first three papers investigate the role of researchers in the sustainable mobility debate, and their capacities and shortcomings to contribute to behaviour change. Hall ( in press Hall, C.M. (in press). Intervening in academic interventions: Using the lens of social marketing to examine the potential for successful sustainable tourism behavioural change. Journal of Sustainable Tourism, DOI: 10.1080/09669582.2015.1088861. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ) does this by employing social marketing themes. He questions both the theoretical knowledge base of sustainable tourism and the positioning of sustainability within the wider (tourism) literature, noting that, despite a growing body of research on sustainable tourism and mobilities, concern about these topics in tourism research is still minor, particularly in popular areas such as achieving growth in visitor numbers and expenditure. Substantive change is not evident in most destinations, or among organisations that have adopted sustainable tourism. As a way forward, Hall discusses the need for more advocacy- and participatory-based approaches so that scientists can better communicate with policy-makers and work collaboratively/co-productively with them and other upstream stakeholders. Downstream and (more activist and interventionist) upstream social marketing to the public, taking in the lessons learned from other disciplines and debates (such as that on anti-smoking), may (re)glamorise/make fashionable forms of more sustainable tourism or encourage more conventional but low transport intensity local tourism.\nMelissen and Koens ( in press Melissen, F., & Koens, K. (in press). Adding researchers' behaviour to the research agenda: Bridging the science–policy gap in sustainable tourism mobility. Journal of Sustainable Tourism, DOI: 10.1080/09669582.2015.1071384 [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ) echo Hall, arguing that researchers should not only focus on understanding the structures behind tourist behaviour, but also on how to mobilise policy and business stakeholders to contribute to the sustainable development of tourism. They find several factors or tensions (Jones, Jones, & Walsh, 2008 Jones, N., Jones, H., & Walsh, C. (2008). Political science? Strengthening science-policy dialogue in developing countries. London: Overseas Development Institute.  [Google Scholar] ) hindering researcher behaviour change towards bridging the science–policy gap in sustainable tourism mobility, and make a case for adding researchers' behaviour to the corresponding research agenda. Researchers may need to position themselves closer to the policy arena, without politicising science or moving from engaged to activist research.\nMounting sustainable tourism and transport advocacy will also lead to more attention to the environmental sustainability imperatives of researchers themselves, and the institutions for which they work. Thus the paper by Hopkins, Higham, Tapp, and Duncan ( in press Hopkins, D., Higham, J., Tapp, S., & Duncan, T. (in press). Academic mobility in the Anthropocene era: A comparative study of university policy at three New Zealand institutions. Journal of Sustainable Tourism, DOI: 10.1080/09669582.2015.1071383 [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ) in this issue links to the transport taboo of questioning academic mobility and associated carbon emissions. Set in a New Zealand university context it investigates the perceived lock-in of academic performance being dependent on, or equal to, international mobility. This can be linked back to the pioneering work of the late Karl Georg Høyer (Høyer, 2000 Høyer, K.G. (2000). Sustainable tourism – or sustainable mobility? Journal of Sustainable Tourism, 8(2), 147–161. [Taylor & Francis Online]   [Google Scholar] ; Høyer & Næss, 2001 Høyer, K.G., & Næss, P. (2001). Conference tourism: A problem for the environment as well as for research? Journal of Sustainable Tourism, 9(6), 451–470. [Taylor & Francis Online]   [Google Scholar] ). The authors find academic travel to be embedded in university policy, for example through international partnerships, the need to present research at international conferences and recruitment processes. Acknowledging New Zealand's particular geographical location, they still recommend that academic institutions consider and address the carbon emissions related to academic mobility, and to integrate sustainability more systematically into university (travel) policy.\nAnother highly mobile group possibly caught in a (socio-cultural) lock-in of flight-dependent practices is that of the younger generation in many western countries taking a gap year. Luzecka ( in press Luzecka, P. (in press). “Take a gap year!” A social practice perspective on air travel and potential transitions towards sustainable tourism mobility. Journal of Sustainable Tourism, DOI: 10.1080/09669582.2015.1115513 [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ) explores ways in which conventions related to “appropriate” gap year destinations are developed, sustained and reproduced. Numerous social mechanisms were found to facilitate overseas travel in the context of gap years, including a shared perception of difference and physical distance, which links personal development to the challenges of distant countries. This paper highlights the fact that some long-haul destinations are actually easier or cheaper to travel to than more nearby destinations. Luzecka warns that widening participation in gap year travel may further the normalisation – and psychological lock-in – of long-haul travel. The length of gap years would make them suitable for slow, and potentially more sustainable, travel, but for such a sustainable mobility transition, the socio-cultural forces that shape current gap year practices need to be taken into account.\nThe two following papers acknowledge the reality of consumers not accepting responsibility and responding to unsustainable travel mobilities, and seek ways to influence consumer decision-making through the provision of carbon information with travel products. Araña and León ( in press Araña, J.E., & León, C.J. (in press). Are tourists animal spirits? Evidence from a field experiment exploring the use of non-market based interventions advocating sustainable tourism. Journal of Sustainable Tourism, DOI: 10.1080/09669582.2015.1101128 [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ) experiment with the role of emotions and time pressure in decision-making, hypothesising that many traveller decisions are of an experiential nature. In a Spanish social tourism programme setting, they carried out a field experiment in which they manipulate the choice context of travellers, when deciding where to travel. Travel plans involved different levels of CO2 emissions, contexts about the emotional state, and decision time. Araña and León find that emotional states and the decision context can indeed affect the sustainability of travel choices. These findings have several implications for pro-environmental behaviour policies and campaigns in tourism and the effectiveness of tax incentives. Subjects showing more empathy with future generations are more likely to accept low-carbon travel options.\nEijgelaar, Nawijn, Barten, Okuhn, and Dijkstra ( in press Eijgelaar, E., Nawijn, J., Barten, C., Okuhn, L., & Dijkstra, L. (in press). Consumer attitudes and preferences on holiday carbon footprint information in the Netherlands. Journal of Sustainable Tourism, DOI: 10.1080/09669582.2015.1101129 [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ) investigate carbon labels, as a soft measure towards more sustainable travel choices that is more likely to receive industry acceptance than direct volume-reducing measures. Their case is linked to the desire of Dutch tour operators to offer such a label. Hence, they explore preferences for carbon label design in tourism. The authors tested label designs in a number of consecutive research phases under Dutch consumers. They find a number of preconditions for a tourism carbon label: it should be simple in design and connect to existing well-known EU labels for energy efficiency. But at the same time they note that sustainability is still of low priority during holiday decision-making.\nAn interesting case in science–policy interaction is Antarctica, as the continent is not controlled by a state, but through a 29-party governance regime, the Antarctic Treaty System. As little progress was made on tourism issues through the Treaty's meetings, the International Association of Antarctica Tour Operators filled this gap by self-regulating Antarctic tourism. However, their capability to self-regulate is increasingly questioned. Student, Lamers, and Amelung ( in press Student, J., Lamers, M., & Amelung, B. (in press). Towards a tipping point? Exploring the capacity to self-regulate Antarctic tourism using agent-based modelling. Journal of Sustainable Tourism, DOI: 10.1080/09669582.2015.1107079 [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ) apply agent-based modelling (ABM) to identify the challenges for the self-regulation of this carbon-intensive form of tourism. They find a number of potentially destabilising factors connected to likely future tourism development, whereby optimum group size and membership cost are crucial. More importantly, they stress the strength of ABM as a method to safely experiment with uncertainties in Antarctica, and help to provide insights for an environmentally optimised application in (sustainable Antarctic tourism) policy.\nThe final two papers investigate sustainable transport policy-making and practices at destinations. This local/regional level work reveals key aspects of the realpolitik of policy-making in ways not open to most researchers at national or international levels. Scuttari, Volgger, and Pechlaner ( in press Scuttari, A., Volgger,M., & Pechlaner, H. (in press). Transition management towards sustainable mobility in alpine destinations: Realities and realpolitik in Italy's South Tyrol region. Journal of Sustainable Tourism, DOI: 10.1080/09669582.2015.XXXXXX [Crossref] , [Web of Science ®]   [Google Scholar] ) seek ways for governing the transition towards more sustainable tourism mobility by applying a system approach. Their research in a South Tyrolean context indicates that the transition towards more sustainable transport solutions is complex and requires both public and private sector unpredictability and risk aversion to be taken into account. Scuttari et al. identify three conditions relevant to performing the transition, each one linked to a different sub-system (socio-ecological, socio-technical and governance). The transition to sustainable solutions is a complex task that can only be successful when all sub-systems – tourism, transport, governance and social-ecological – interact in informal or formal partnership. To be successful, three conditions were identified: (1) an improved understanding of what sustainable transport entails, (2) adoption of the best available technology and (3) courage and leadership to take risks with new solutions without knowing what they will bring with absolute certainty. The latter means that science should provide a better understanding of how to mitigate risk aversion or even better, how to shift the focus of risk aversion towards avoiding the risks of unsustainable development and climate change, as opposed to the risks associated with introducing, managing and using novel transport systems.\nFinally, Stanford and Guiver (in press) Stanford, D., & Guiver, J. (in press). Driving pro-environmental change in tourist destinations: Encouraging sustainable travel in national parks via partnership project creation and implementation. Journal of Sustainable Tourism, DOI: 10.1080.09669582.2015.1122018 [Web of Science ®]   [Google Scholar] explore public–private partnership led projects providing alternatives to car travel in three UK national parks as mechanisms of modal shift and pro-environmental change. They identify a number of success factors and provide practical advice on understanding and guiding future multi-partnership pro-environmental change processes in complex networks. As in the previous paper, strong local governance structures, awareness creating, trust and learning are important, and the effective communication of benefits to stakeholders appeared most significant.\nConclusions and research agenda\nThis paper has discussed three areas crucial for understanding why, despite clear scientific evidence about the growing environmental impacts of tourism transport, there is large-scale inertia in structural transitions and a lack of political willpower to enact meaningful policy change. These included the importance of addressing socio-technical factors, the barriers posed by placing faith in “technology myths” and the need to overcome “transport taboos” in policy-making. These areas shed significant light on why a science–policy gap in sustainable mobility exists, and on the issues that must be overcome if this gap is to be bridged. The societal challenge of transitioning the tourism and transport sectors to a sustainable emissions path must not be devolved entirely to the public and the marketplace, as suggested by neoliberal values. It is vital that both governments and the tourism and transport industries take a more cautious approach to the technological optimism that is fostering policy inertia: technological innovation alone will not save the day anytime soon. They must invest more in research, in operational procedures and in encouraging the development of and marketing alternatives to air travel. But most importantly, policy-makers must take a more open approach to implementing sustainable transport policies that affect the structures of provision; they will need to be lobbied to touch issues that may be politically risky, but nonetheless have been shown in other contexts to be successful in fostering desirable sustainable transport outcomes.\nBuilding on these insights, the Freiburg 2016 workshop will consequently focus on desirable transport futures, i.e. visions of desirable sustainable transport systems that have the potential to be actively taken up by wide cross sections of society (c.f. Banister & Hickman, 2013 Banister, D., & Hickman, R. (2013). Transport futures: Thinking the unthinkable. Transportation Policy, 29, 283–293. [Crossref] , [Web of Science ®]   [Google Scholar] ). A starting point for this is the analysis of sustainable transport transitions that are now underway, and the analysis of the structural, political, institutional and social/psychological factors underlying those transitions. The e-bike revolution is one example of societal change involving a low-carbon technological innovation, with uptake and adoption motivated by convenience, speed, health and cost. Many cities in Europe have re-discovered the bicycle as a transport mode with diverse benefits, and there now exists widespread and growing demand for infrastructures that facilitate cycling and other active forms of transport (Gössling & Choi, 2015 Gössling, S., & Choi, A.S. (2015). Transport transitions in Copenhagen: Comparing the cost of cars and bicycles. Ecological Economics, 113, 106–113. [Crossref] , [Web of Science ®]   [Google Scholar] ; Pucher & Buehler, 2012 Pucher, J., & Buehler, R. (2012). City cycling. Cambridge, MA: MIT Press.  [Google Scholar] ). Cycling cities have become a desirable transport future but the health and cost benefits of cycling demand that issues of cyclist safety are addressed in infrastructural provision. The rise of car sharing systems, in place of car ownership, is another timely example of a mobility transition, but is not without rebound effects, as the media suggests that it has cannibalisation effects at the expense of public transport (Schwarz, 2015 Schwarz, K. (2015, December 11). Carsharing: Wie umweltschädlich sind Car2go und Drivenow wirklich? [Carsharing: How environmentally harmful are Car2go and Drivenow actually?]. The Huffington Post (German Edition). Retrieved 1 December 2015 from http://www.huffingtonpost.de/2015/02/13/carsharing-klima-umfrage-wirtschaftswoche_n_6675908.html   [Google Scholar] ).\nIn contrast to desirable futures, while flying is highly desirable for many, continued growth in air travel on a global scale is incompatible with a sustainable transport future, and it is here that the need for urgent transition is now widely accepted. However, before entertaining alternatives to the current unsustainable transport system, it is essential to know what desirable transport futures may look like. The critical analysis of mobility transitions, including barriers confronting the achievement of desirable transport futures, is needed. A concerted research effort in the following key areas is consequently required:\nDesired transport\nFuture visions must be built upon desired transport systems. Critical examination is needed of spontaneous market uptake of desired new transport systems and their rebound effects. How have e-bike, car sharing, high-speed rail and successful public transport systems emerged in certain societies? What factors have acted as facilitators of change and how were barriers overcome? How important are individuals, i.e. specific people, in initiating change? What were the key roles of stakeholders and were low-carbon transitions an objective from the outset or a coincidental outcome? What lessons can be learned from these revolutions and what wider roles may such successes play in developing towards low-carbon transport and tourism?\nThe role of fashion\nMany trends in tourism and travel are fashion driven. Certain destinations can rise and fall substantially in a very short time. In the Netherlands long-haul travel grew rapidly until 2008 when it stabilised and started to decline. What factors influence significant changes in established patterns of consumption? Why has “environmental consciousness”, with the exception of European car purchasing, proved largely ineffective in driving low-carbon transport transitions? What potential do social marketing, celebrity endorsement and role model advocacy offer, and how can the effectiveness of these strategies be maximised? What other strategies may exist to influence and encourage the fashionability of more sustainable forms of tourism (e.g. caravanning, train journeys, “loca-tourism”, slow tourism and staycationing)? How can industry, government, the media and public organisations engage in such processes, and what in particular is the role of science and researchers?\nEconomic issues\nThe economic arguments for growth in aviation are well established, even though many assessments appear to remain partial. But what are the economic arguments that support the development of sustainable transport systems? What economic growth scenarios may be associated with low-carbon transitions to rail and electric vehicle fleets, and the new infrastructures required to facilitate active transport modes? What do economic models predict for the redistribution of travel flows under low-carbon transport scenarios? Contributions to a more complete understanding of the economics of low-carbon transport scenarios are critically important to the shift towards desired transport futures.\nPublic health and well-being\nCritical issues arise when contemplating how the sustainable transportation agenda is coupled with questions of public health and well-being. Policy outcomes driven by a public health and well-being agenda may have the potential for achieving significant environmental benefits. What potential do desirable transport futures offer to overcome personal well-being and public health risks, such as the negative health dimensions of frequent flying (Cohen & Gössling, 2015) Cohen, S.A., & Gössling, S. (2015). A darker side of hypermobility. Environment and Planning A, 47, 1661–1679. [Crossref] , [Web of Science ®]   [Google Scholar] , or the risk of pandemic associated with long-haul flights? And where mobility transitions are already in progress, can, for instance, the rising public health costs of serious injuries and deaths of cyclists be mitigated by dedicated cycle infrastructure?\nIssues of equity and ethics\nThere is a need to move beyond the Eurocentrism (c.f. Cohen & Cohen, 2015 Cohen, E., & Cohen, S.A. (2015). Beyond Eurocentrism in tourism: A paradigm shift to mobilities. Tourism Recreation Research, 40(2), 157–168. [Taylor & Francis Online]   [Google Scholar] ) that has framed debate around these issues. While the West has contributed disproportionately to the environmental crisis, emissions of unsustainable transportation are globally dispersed. Insights that are theoretically, methodologically and practically informed are required to understand sustainable transportation issues as they apply to emerging world regions (e.g. Dillimono & Dickinson, 2015 Dillimono, H.D., & Dickinson, J.E. (2015). Travel, tourism, climate change, and behavioral change: Travelers' perspectives from a developing country, Nigeria. Journal of Sustainable Tourism, 23(3), 437–454. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] on Nigerian perspectives). Growth from the middle classes in parts of Asia, Latin America, South America and Africa is also driving up global transport emissions. What equity issues arise in association with the transition from old to new transport systems? What ethical issues arise with the growth of unsustainable transportation in less developed countries? How will the continuing but declining emission footprint be distributed between countries and sectors globally? What will be the impacts of emission trading, taxation regimes, subsidies and infrastructure planning, and how will they vary between regions in light of the recent Paris Agreement?\nAdvocacy- and participatory-based approaches\nThe need exists for advocacy- and participatory-based approaches (see Bramwell, Higham, Lane, & Miller, 2016 Bramwell, B., Higham, J., Lane, B., & Miller, G. (2016). Advocacy or neutrality? Disseminating research findings and driving change toward sustainable tourism in a fast changing world. Journal of Sustainable Tourism, 24(1), 1–7. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ; Hall, in press Hall, C.M. (in press). Intervening in academic interventions: Using the lens of social marketing to examine the potential for successful sustainable tourism behavioural change. Journal of Sustainable Tourism, DOI: 10.1080/09669582.2015.1088861. [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ) to enable more effective communication with policy communities, and to facilitate collaboration and co-production with policy-makers and other upstream stakeholders. What opportunities exist to implement new or underutilised methods such as simulation, serious gaming and in-depth multi-stakeholder approaches? What potential do new approaches offer to communicate the science of climate change, and internalise the challenges inherent in responding to climate change? How can new approaches serve to highlight the contribution of travel in global GHG emissions, the inherent difficulties in responding to unsustainable transportation, and potential pathways to desirable transport futures? These key areas form the basis for a continued research agenda aimed at transitioning the tourism and transport sectors to a sustainable emissions path.\nAcknowledgments\nThe convenors of the Freiburg 2014 workshop (1–4 July 2014) gratefully acknowledge the members of its Scientific Advisory Board, all of whom contributed to the success of the workshop: Dr Stewart Barr (University of Exeter, UK), Dr Jo Guiver (University of Central Lancashire, UK), Professor Michael Hall (University of Canterbury, NZ), Dr Julia Hibbert (Bournemouth University, UK), Professor Daniel Scott (University of Waterloo, Canada) and Professor David Banister (TSI, University of Oxford, UK).\nDisclosure statement\nScott A. Cohen is a reader at the University of Surrey (United Kingdom).\nJames Higham\nJames Higham is a professor at the Department of Tourism, University of Otago (New Zealand).\nStefan Gössling\nStefan Gössling is a professor at Lund University and Linnaeus University (Sweden). He is also research coordinator at the Western Norway Research Institute's Research Centre for Sustainable Tourism.\nPaul Peeters\nPaul Peeters is an associate professor at NHTV Breda University of Applied Sciences (The Netherlands).\nEke Eijgelaar\nEke Eijgelaar is a researcher at the Centre for Sustainable Tourism and Transport at NHTV Breda University for Applied Sciences (The Netherlands).\nArticle Metrics\n""","0.29722506","""http://www.tandfonline.com/doi/full/10.1080/09669582.2015.1136637""","[-0.589514,51.242722]"
"""Imperial_College_London""","""CONTINUUM LIMIT OF SELF-DRIVEN PARTICLES WITH ORIENTATION INTERACTION | Mathematical Models and Methods in Applied Sciences , Vol 18, No supp01 | World Scientific""","""Mathematical Models and Methods in Applied Sciences\nCONTINUUM LIMIT OF SELF-DRIVEN PARTICLES WITH ORIENTATION INTERACTION\nPIERRE DEGOND\nInstitute of Mathematics of Toulouse UMR 5219, (CNRS-UPS-INSA-UT1-UT2), Université Paul Sabatier, 118, Route de Narbonne, 31062 Toulouse Cedex, France\nSÉBASTIEN MOTSCH\nInstitute of Mathematics of Toulouse UMR 5219, (CNRS-UPS-INSA-UT1-UT2), Université Paul Sabatier, 118, Route de Narbonne, 31062 Toulouse Cedex, France\nReceived: 25 September 2007\nThe discrete Couzin–Vicsek algorithm (CVA), which describes the interactions of individuals among animal societies such as fish schools is considered. In this paper, a kinetic (mean-field) version of the CVA model is proposed and its formal macroscopic limit is provided. The final macroscopic model involves a conservation equation for the density of the individuals and a non-conservative equation for the director of the mean velocity and is proved to be hyperbolic. The derivation is based on the introduction of a non-conventional concept of a collisional invariant of a collision operator.\nKeywords: Individual based model; fish behavior; Couzin–Vicsek algorithm; asymptotic analysis; orientation interaction; hydrodynamic limit; collision invariants\nAMSC: 35Q80, 35L60, 82C22, 82C70, 92D50\nCited by (135):\nAlessio Figalli , Moon-Jin Kang , Javier Morales .  (2018) Global Well-posedness of the Spatially Homogeneous Kolmogorov–Vicsek Model as a Gradient Flow. Archive for Rational Mechanics and Analysis 227:3, 869-896.  Online publication date: 1-Mar-2018. [Crossref]\nMartin Burger , Bertram Düring , Lisa Maria Kreusser , Peter A. Markowich , Carola-Bibiane Schönlieb .  (2018) Pattern formation of a nonlocal, anisotropic interaction model. Mathematical Models and Methods in Applied Sciences 28:03, 409-451.  Online publication date: 1-Mar-2018. [ Abstract | PDF (1179 KB) | PDF Plus (1182 KB) ]\nPiotr B. Mucha , Jan Peszek .  (2018) The Cucker–Smale Equation: Singular Communication Weight, Measure-Valued Solutions and Weak-Atomic Uniqueness. Archive for Rational Mechanics and Analysis 227:1, 273-308.  Online publication date: 1-Jan-2018. [Crossref]\nSara Bernardi , Annachiara Colombi , Marco Scianna .  (2018) A discrete particle model reproducing collective dynamics of a bee swarm. Computers in Biology and Medicine.  Online publication date: 1-Jan-2018. [Crossref]\nPierre Degond , Amic Frouvelle , Sara Merino-Aceituno , Ariane Trescases .  (2018) Quaternions in Collective Dynamics. Multiscale Modeling & Simulation 16:1, 28-77.  Online publication date: 1-Jan-2018. [Crossref]\nJ. Barré , C. Bernardin , R. Chetrite .  (2017) Density Large Deviations for Multidimensional Stochastic Hyperbolic Conservation Laws. Journal of Statistical Physics 57.  Online publication date: 7-Dec-2017. [Crossref]\nAdrien Blanchet , Pierre Degond .  (2017) Kinetic Models for Topological Nearest-Neighbor Interactions. Journal of Statistical Physics 169:5, 929-950.  Online publication date: 1-Dec-2017. [Crossref]\nMihai Bostan , Jose Antonio Carrillo .  (2017) Reduced fluid models for self-propelled particles interacting through alignment. Mathematical Models and Methods in Applied Sciences 27:07, 1255-1299.  Online publication date: 30-Jun-2017. [ Abstract | PDF (537 KB) | PDF Plus (595 KB) ]\nDavid Poyato , Juan Soler .  (2017) Euler-type equations and commutators in singular and hyperbolic limits of kinetic Cucker–Smale models. Mathematical Models and Methods in Applied Sciences 27:06, 1089-1152.  Online publication date: 15-Jun-2017. [ Abstract | PDF (672 KB) | PDF Plus (727 KB) ]\nL. Müller , A. Meurer , F. Schneider , A. Klar .  (2017) A numerical investigation of flux-limited approximations for pedestrian dynamics. Mathematical Models and Methods in Applied Sciences 27:06, 1177-1197.  Online publication date: 15-Jun-2017. [ Abstract | PDF (1279 KB) | PDF Plus (1323 KB) ]\nNicola Bellomo , Seung-Yeal Ha .  (2017) A quest toward a mathematical theory of the dynamics of swarms. Mathematical Models and Methods in Applied Sciences 27:04, 745-770.  Online publication date: 1-Apr-2017. [ Abstract | PDF (379 KB) | PDF Plus (422 KB) ]\nTeng-Fei Zhang , Ning Jiang .  (2017) A local existence of viscous self-organized hydrodynamic model. Nonlinear Analysis: Real World Applications 34, 495-506.  Online publication date: 1-Apr-2017. [Crossref]\nDieter Armbruster , Sébastien Motsch , Andrea Thatcher .  (2017) Swarming in bounded domains. Physica D: Nonlinear Phenomena 344, 58-67.  Online publication date: 1-Apr-2017. [Crossref]\nPierre Degond , Angelika Manhart , Hui Yu .  (2017) A continuum model for nematic alignment of self-propelled particles. Discrete and Continuous Dynamical Systems - Series B 22:4, 1295-1327.  Online publication date: 1-Feb-2017. [Crossref]\nAlesandro Arcuri , Nicolas Lanchier .  (2017) Stochastic spatial model for the division of labor in social insects. Mathematical Models and Methods in Applied Sciences 27:01, 45-73.  Online publication date: 1-Jan-2017. [ Abstract | PDF (391 KB) | PDF Plus (438 KB) ]\nAylin Aydoğdu , Marco Caponigro , Sean McQuade , Benedetto Piccoli , Nastassia Pouradier Duteil , Francesco Rossi , Emmanuel Trélat . 2017. Interaction Network, State Space, and Control in Social Dynamics. Active Particles, Volume 1, 99-140. [Crossref]\nSeung-Yeal Ha , Dongnam Ko , Yinglong Zhang , Xiongtao Zhang .  (2016) Emergent dynamics in the interactions of Cucker-Smale ensembles. Kinetic and Related Models 10:3, 689-723.  Online publication date: 1-Dec-2016. [Crossref]\nAlex Mogilner , Angelika Manhart , David G. Drubin .  (2016) Agent-based modeling: case study in cleavage furrow models. Molecular Biology of the Cell 27:22, 3379-3384.  Online publication date: 7-Nov-2016. [Crossref]\nPierre Degond , Silke Henkes , Hui Yu .  (2016) Self-organized hydrodynamics with density-dependent velocity. Kinetic and Related Models 10:1, 193-213.  Online publication date: 1-Nov-2016. [Crossref]\nJunghee Cho , Seung-Yeal Ha , Feimin Huang , Chunyin Jin , Dongnam Ko .  (2016) Emergence of bi-cluster flocking for agent-based models with unit speed constraint. Analysis and Applications 14:01, 39-73.  Online publication date: 1-Jan-2016. [ Abstract | PDF (1472 KB) | PDF Plus (1500 KB) ]\nMihai Bostan .  (2016) MultiScale Analysis for Linear First Order PDEs. The Finite Larmor Radius Regime. SIAM Journal on Mathematical Analysis 48:3, 2133-2188.  Online publication date: 1-Jan-2016. [Crossref]\nNing Jiang , Linjie Xiong , Teng-Fei Zhang .  (2016) Hydrodynamic Limits of the Kinetic Self-Organized Models. SIAM Journal on Mathematical Analysis 48:5, 3383-3411.  Online publication date: 1-Jan-2016. [Crossref]\nAlethea B. T. Barbaro , José A. Can͂izo , José A. Carrillo , Pierre Degond .  (2016) Phase Transitions in a Kinetic Flocking Model of Cucker--Smale Type. Multiscale Modeling & Simulation 14:3, 1063-1088.  Online publication date: 1-Jan-2016. [Crossref]\nIrene M. Gamba , Moon-Jin Kang .  (2016) Global Weak Solutions for Kolmogorov–Vicsek Type Equations with Orientational Interactions. Archive for Rational Mechanics and Analysis 222:1, 317. [Crossref]\nD. Peurichard .  (2016) Macroscopic Model for Cross-Linked Fibers with Alignment Interactions: Existence Theory and Numerical Simulations. Multiscale Modeling & Simulation 14:4, 1175-1210.  Online publication date: 1-Jan-2016. [Crossref]\nMiguel A. Herrero , Juan Soler .  (2015) Cooperation, competition, organization: The dynamics of interacting living populations. Mathematical Models and Methods in Applied Sciences 25:13, 2407-2415.  Online publication date: 15-Dec-2015. [ Abstract | PDF (157 KB) | PDF Plus (223 KB) ]\nPierre Degond , Laurent Navoret .  (2015) A multi-layer model for self-propelled disks interacting through alignment and volume exclusion. Mathematical Models and Methods in Applied Sciences 25:13, 2439-2475.  Online publication date: 15-Dec-2015. [ Abstract | PDF (873 KB) | PDF Plus (862 KB) ]\nDenis F. Hinz , Alexander Panchenko , Tae-Yeon Kim , Eliot Fried .  (2015) Particle-based simulations of self-motile suspensions. Computer Physics Communications 196, 45-57.  Online publication date: 1-Nov-2015. [Crossref]\nMartin Parisot , Mirosław Lachowicz .  (2015) A kinetic model for the formation of swarms with nonlinear interactions. Kinetic and Related Models 9:1, 131-164.  Online publication date: 1-Oct-2015. [Crossref]\nIrene M. Gamba , Jeffrey R. Haack , Sebastien Motsch .  (2015) Spectral method for a kinetic swarming model. Journal of Computational Physics 297, 32-46.  Online publication date: 1-Sep-2015. [Crossref]\nThi-Bich-Ngoc Mac .  (2015) Existence of solution for a system of repulsion and alignment: Comparison between theory and simulation. Discrete and Continuous Dynamical Systems - Series B 20:9, 3013-3027.  Online publication date: 1-Sep-2015. [Crossref]\nMichael Herty , Lorenzo Pareschi , Sonja Steffensen .  (2015) Mean--field control and Riccati equations. Networks and Heterogeneous Media 10:3, 699-715.  Online publication date: 1-Jul-2015. [Crossref]\nEric Carlen , Maria C Carvalho , Pierre Degond , Bernt Wennberg .  (2015) A Boltzmann model for rod alignment and schooling fish. Nonlinearity 28:6, 1783-1803.  Online publication date: 1-Jun-2015. [Crossref]\nPierre Degond , Amic Frouvelle , Jian-Guo Liu .  (2015) Phase Transitions, Hysteresis, and Hyperbolicity for Self-Organized Alignment Dynamics. Archive for Rational Mechanics and Analysis 216:1, 63-115.  Online publication date: 1-Apr-2015. [Crossref]\nPierre Degond , Hui Yu .  (2015) Self-organized hydrodynamics in an annular domain: Modal analysis and nonlinear effects. Mathematical Models and Methods in Applied Sciences 25:03, 495-519.  Online publication date: 1-Mar-2015. [ Abstract | PDF (2216 KB) | PDF Plus (2248 KB) ]\nL. Michailidis , M. Herty , M. Ziegler .  (2015) Kinetic part-feeding models for assembly lines in automotive industries. Mathematical Models and Methods in Applied Sciences 25:02, 283-308.  Online publication date: 1-Feb-2015. [ Abstract | PDF (1566 KB) | PDF Plus (495 KB) ]\nSeung-Yeal Ha , Jinyeong Park , Sang Woo Ryoo .  (2015) Emergence of phase-locked states for the Winfree model in a large coupling regime. Discrete and Continuous Dynamical Systems 35:8, 3417-3436.  Online publication date: 1-Feb-2015. [Crossref]\nGil Ariel , Oren Rimer , Eshel Ben-Jacob .  (2015) Order–Disorder Phase Transition in Heterogeneous Populations of Self-propelled Particles. Journal of Statistical Physics 158:3, 579-588.  Online publication date: 1-Feb-2015. [Crossref]\nJulien Barré , Raphaël Chétrite , Massimiliano Muratori , Fernando Peruani .  (2015) Motility-Induced Phase Separation of Active Particles in the Presence of Velocity Alignment. Journal of Statistical Physics 158:3, 589-600.  Online publication date: 1-Feb-2015. [Crossref]\nTrygve K. Karper , Antoine Mellet , Konstantina Trivisa .  (2015) Hydrodynamic limit of the kinetic Cucker–Smale flocking model. Mathematical Models and Methods in Applied Sciences 25:01, 131-163.  Online publication date: 1-Jan-2015. [ Abstract | PDF (403 KB) | PDF Plus (426 KB) ]\nJan Peszek .  (2015) Discrete Cucker--Smale Flocking Model with a Weakly Singular Weight. SIAM Journal on Mathematical Analysis 47:5, 3671-3686.  Online publication date: 1-Jan-2015. [Crossref]\nBenedetto Piccoli , Francesco Rossi , Emmanuel Trélat .  (2015) Control to Flocking of the Kinetic Cucker--Smale Model. SIAM Journal on Mathematical Analysis 47:6, 4685-4719.  Online publication date: 1-Jan-2015. [Crossref]\nOleksandr Chepizhko , Vladimir Kulinskii .  (2014) The hydrodynamic description for the system of self-propelled particles: Ideal Viscek fluid. Physica A: Statistical Mechanics and its Applications 415, 493-502.  Online publication date: 1-Dec-2014. [Crossref]\nA. Roth , A. Klar , B. Simeon , E. Zharovsky .  (2014) A Semi-Lagrangian Method for 3-D Fokker Planck Equations for Stochastic Dynamical Systems on the Sphere. Journal of Scientific Computing 61:3, 513-532.  Online publication date: 1-Dec-2014. [Crossref]\nR. Etikyala , S. Göttlich , A. Klar , S. Tiwari .  (2014) Particle methods for pedestrian flow models: From microscopic to nonlocal continuum models. Mathematical Models and Methods in Applied Sciences 24:12, 2503-2523.  Online publication date: 1-Nov-2014. [ Abstract | PDF (1642 KB) | PDF Plus (780 KB) ]\nM. Burger , L. Caffarelli , P. A. Markowich .  (2014) Partial differential equation models in the socio-economic sciences. Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences 372:2028, 20130406-20130406.  Online publication date: 6-Oct-2014. [Crossref]\nP. Degond , J.-G. Liu , C. Ringhofer .  (2014) Evolution of wealth in a non-conservative economy driven by local Nash equilibria. Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences 372:2028, 20130394-20130394.  Online publication date: 6-Oct-2014. [Crossref]\nSeung-Yeal Ha , Moon-Jin Kang , Bongsuk Kwon .  (2014) A hydrodynamic model for the interaction of Cucker–Smale particles and incompressible fluid. Mathematical Models and Methods in Applied Sciences 24:11, 2311-2359.  Online publication date: 1-Oct-2014. [ Abstract | PDF (557 KB) | PDF Plus (591 KB) ]\nPierre Degond , Amic Frouvelle , Gaël Raoul .  (2014) Local Stability of Perfect Alignment for a Spatially Homogeneous Kinetic Model. Journal of Statistical Physics 157:1, 84-112.  Online publication date: 1-Oct-2014. [Crossref]\nJan Peszek .  (2014) Existence of piecewise weak solutions of a discrete Cucker–Smale's flocking model with a singular communication weight. Journal of Differential Equations 257:8, 2900-2925.  Online publication date: 1-Oct-2014. [Crossref]\nD J G Pearce , M S Turner .  (2014) Density regulation in strictly metric-free swarms. New Journal of Physics 16:8, 082002.  Online publication date: 1-Aug-2014. [Crossref]\nAxel Klar , Florian Schneider , Oliver Tse .  (2014) Approximate models for stochastic dynamic systems with velocities on the sphere and associated Fokker--Planck equations. Kinetic and Related Models 7:3, 509-529.  Online publication date: 1-Jul-2014. [Crossref]\nMichele Gianfelice , Enza Orlandi .  (2014) Dynamics and kinetic limit for a system of noiseless $d$-dimensional Vicsek-type particles. Networks and Heterogeneous Media 9:2, 269-297.  Online publication date: 1-Jul-2014. [Crossref]\nZhuchun Li , Seung-Yeal Ha , Xiaoping Xue .  (2014) Emergent phenomena in an ensemble of Cucker–Smale particles under joint rooted leadership. Mathematical Models and Methods in Applied Sciences 24:07, 1389-1419.  Online publication date: 30-Jun-2014. [ Abstract | PDF (481 KB) | PDF Plus (462 KB) ]\nJ.A. Carrillo , Y. Huang , S. Martin .  (2014) Nonlinear stability of flock solutions in second-order swarming models. Nonlinear Analysis: Real World Applications 17, 332-343.  Online publication date: 1-Jun-2014. [Crossref]\nAlethea B. T. Barbaro , Pierre Degond .  (2014) Phase transition and diffusion among socially interacting self-propelled agents. Discrete and Continuous Dynamical Systems - Series B 19:5, 1249-1278.  Online publication date: 1-Apr-2014. [Crossref]\nRong Yang , Li Chen .  (2014) Mean-field limit for a collision-avoiding flocking system and the time-asymptotic flocking dynamics for the kinetic equation. Kinetic and Related Models 7:2, 381-400.  Online publication date: 1-Mar-2014. [Crossref]\nPIERRE DEGOND , GIACOMO DIMARCO , THI BICH NGOC MAC .  (2014) HYDRODYNAMICS OF THE KURAMOTO–VICSEK MODEL OF ROTATING SELF-PROPELLED PARTICLES. Mathematical Models and Methods in Applied Sciences 24:02, 277-325.  Online publication date: 1-Feb-2014. [ Abstract | PDF (1046 KB) | PDF Plus (1097 KB) ]\nPierre Degond , Jian-Guo Liu , Christian Ringhofer .  (2014) Large-Scale Dynamics of Mean-Field Games Driven by Local Nash Equilibria. Journal of Nonlinear Science 24:1, 93-115.  Online publication date: 1-Feb-2014. [Crossref]\nG. Albi , D. Balagué , J. A. Carrillo , J. von Brecht .  (2014) Stability Analysis of Flock and Mill Rings for Second Order Models in Swarming. SIAM Journal on Applied Mathematics 74:3, 794-818.  Online publication date: 1-Jan-2014. [Crossref]\nSebastien Motsch , Eitan Tadmor .  (2014) Heterophilious Dynamics Enhances Consensus. SIAM Review 56:4, 577-621.  Online publication date: 1-Jan-2014. [Crossref]\nA. Klar , S. Tiwari .  (2014) A Multiscale Meshfree Method for Macroscopic Approximations of Interacting Particle Systems. Multiscale Modeling & Simulation 12:3, 1167-1192.  Online publication date: 1-Jan-2014. [Crossref]\nQunhui Han , Pak-Wing Fok .  (2014) Reconstructing the Transition Rate Function of a Broadwell Random Walk from Exit Times. SIAM Journal on Applied Mathematics 74:3, 676-696.  Online publication date: 1-Jan-2014. [Crossref]\nMIHAI BOSTAN , JOSE ANTONIO CARRILLO .  (2013) ASYMPTOTIC FIXED-SPEED REDUCED DYNAMICS FOR KINETIC EQUATIONS IN SWARMING. Mathematical Models and Methods in Applied Sciences 23:13, 2353-2393.  Online publication date: 1-Dec-2013. [ Abstract | PDF (487 KB) | PDF Plus (521 KB) ]\nR. C. Fetecau , J. Meskas .  (2013) A nonlocal kinetic model for predator–prey interactions. Swarm Intelligence 7:4, 279-305.  Online publication date: 1-Dec-2013. [Crossref]\nFrancesco Vecil , Pauline Lafitte , Jesús Rosado Linares .  (2013) A numerical study of attraction/repulsion collective behavior models: 3D particle analyses and 1D kinetic simulations. Physica D: Nonlinear Phenomena 260, 127-144.  Online publication date: 1-Oct-2013. [Crossref]\nE. Carlen , R. Chatelin , P. Degond , B. Wennberg .  (2013) Kinetic hierarchy and propagation of chaos in biological swarm models. Physica D: Nonlinear Phenomena 260, 90-111.  Online publication date: 1-Oct-2013. [Crossref]\nTheodore Kolokolnikov , José A. Carrillo , Andrea Bertozzi , Razvan Fetecau , Mark Lewis .  (2013) Emergent behaviour in multi-particle systems with non-local interactions. Physica D: Nonlinear Phenomena 260, 1-4.  Online publication date: 1-Oct-2013. [Crossref]\nJ.A. Carrillo , S. Martin , V. Panferov .  (2013) A new interaction potential for swarming models. Physica D: Nonlinear Phenomena 260, 112-126.  Online publication date: 1-Oct-2013. [Crossref]\nAmanda Galante , Doron Levy .  (2013) Modeling selective local interactions with memory. Physica D: Nonlinear Phenomena 260, 176-190.  Online publication date: 1-Oct-2013. [Crossref]\nERIC CARLEN , PIERRE DEGOND , BERNT WENNBERG .  (2013) KINETIC LIMITS FOR PAIR-INTERACTION DRIVEN MASTER EQUATIONS AND BIOLOGICAL SWARM MODELS. Mathematical Models and Methods in Applied Sciences 23:07, 1339-1376.  Online publication date: 30-Jun-2013. [ Abstract | PDF (469 KB) | PDF Plus (500 KB) ]\nLAURENT NAVORET .  (2013) A TWO-SPECIES HYDRODYNAMIC MODEL OF PARTICLES INTERACTING THROUGH SELF-ALIGNMENT. Mathematical Models and Methods in Applied Sciences 23:06, 1067-1098.  Online publication date: 1-Jun-2013. [ Abstract | PDF (436 KB) | PDF Plus (473 KB) ]\nPierre Degond , Amic Frouvelle , Jian-Guo Liu .  (2013) Macroscopic Limits and Phase Transition in a System of Self-propelled Particles. Journal of Nonlinear Science 23:3, 427-456.  Online publication date: 1-Jun-2013. [Crossref]\nM. Aurangzeb , F. L. Lewis , M. Huber .  (2013) Efficient, swarm-based path finding in unknown graphs using reinforcement learning. 2013 10th IEEE International Conference on Control and Automation (ICCA), 870-877. [Crossref]\nPierre Degond , Jiale Hua .  (2013) Self-organized hydrodynamics with congestion and path formation in crowds. Journal of Computational Physics 237, 299-319.  Online publication date: 1-Mar-2013. [Crossref]\nAmanda Galante , Susanne Wisen , Devaki Bhaya , Doron Levy .  (2012) Modeling local interactions during the motion of cyanobacteria. Journal of Theoretical Biology 309, 147-158.  Online publication date: 1-Sep-2012. [Crossref]\nSEUNG-YEAL HA , MOON-JIN KANG , CORRADO LATTANZIO , BRUNO RUBINO .  (2012) A CLASS OF INTERACTING PARTICLE SYSTEMS ON THE INFINITE CYLINDER WITH FLOCKING PHENOMENA. Mathematical Models and Methods in Applied Sciences 22:07.  Online publication date: 1-Jul-2012. [ Abstract | PDF (422 KB) | PDF Plus (462 KB) ]\nAMIC FROUVELLE .  (2012) A CONTINUUM MODEL FOR ALIGNMENT OF SELF-PROPELLED PARTICLES WITH ANISOTROPY AND DENSITY-DEPENDENT PARAMETERS. Mathematical Models and Methods in Applied Sciences 22:07.  Online publication date: 1-Jul-2012. [ Abstract | PDF (1506 KB) | PDF Plus (575 KB) ]\nAndrew Morozov , Jean-Christophe Poggiale .  (2012) From spatially explicit ecological models to mean-field dynamics: The state of the art and perspectives. Ecological Complexity 10, 1-11.  Online publication date: 1-Jun-2012. [Crossref]\nJAMES H. VON BRECHT , DAVID UMINSKY , THEODORE KOLOKOLNIKOV , ANDREA L. BERTOZZI .  (2012) PREDICTING PATTERN FORMATION IN PARTICLE INTERACTIONS. Mathematical Models and Methods in Applied Sciences 22:supp01.  Online publication date: 1-Apr-2012. [ Abstract | PDF (4998 KB) | PDF Plus (656 KB) ]\nPIERRE DEGOND , JIAN-GUO LIU .  (2012) HYDRODYNAMICS OF SELF-ALIGNMENT INTERACTIONS WITH PRECESSION AND DERIVATION OF THE LANDAU–LIFSCHITZ–GILBERT EQUATION. Mathematical Models and Methods in Applied Sciences 22:supp01.  Online publication date: 1-Apr-2012. [ Abstract | PDF (258 KB) | PDF Plus (280 KB) ]\nN. BELLOMO , J. SOLER .  (2012) ON THE MATHEMATICAL THEORY OF THE DYNAMICS OF SWARMS VIEWED AS COMPLEX SYSTEMS. Mathematical Models and Methods in Applied Sciences 22:supp01.  Online publication date: 1-Apr-2012. [ Abstract | PDF (979 KB) | PDF Plus (553 KB) ]\nFrançois Bolley , José A. Cañizo , José A. Carrillo .  (2012) Mean-field limit for the stochastic Vicsek model. Applied Mathematics Letters 25:3, 339-343.  Online publication date: 1-Mar-2012. [Crossref]\nSeung-Yeal Ha , Sungeun Jung , Marshall Slemrod .  (2012) Fast–slow dynamics of planar particle models for flocking and swarming. Journal of Differential Equations 252:3, 2563-2579.  Online publication date: 1-Feb-2012. [Crossref]\nAmic Frouvelle , Jian-Guo Liu .  (2012) Dynamics in a Kinetic Model of Oriented Particles with Phase Transition. SIAM Journal on Mathematical Analysis 44:2, 791-826.  Online publication date: 1-Jan-2012. [Crossref]\nFRANÇOIS BOLLEY , JOSÉ A. CAÑIZO , JOSÉ A. CARRILLO .  (2011) STOCHASTIC MEAN-FIELD LIMIT: NON-LIPSCHITZ FORCES AND SWARMING. Mathematical Models and Methods in Applied Sciences 21:11, 2179-2210.  Online publication date: 1-Nov-2011. [ Abstract | PDF (436 KB) | PDF Plus (463 KB) ]\nSebastien Motsch , Eitan Tadmor .  (2011) A New Model for Self-organized Dynamics and Its Flocking Behavior. Journal of Statistical Physics 144:5, 923-947.  Online publication date: 1-Sep-2011. [Crossref]\nAbdelghani Bellouquid , Nicola Bellomo .  (2011) On the modeling of crowd dynamics: Looking at the beautiful shapes of swarms. Networks and Heterogeneous Media 6:3, 383-399.  Online publication date: 1-Aug-2011. [Crossref]\nRAZVAN C. FETECAU .  (2011) COLLECTIVE BEHAVIOR OF BIOLOGICAL AGGREGATIONS IN TWO DIMENSIONS: A NONLOCAL KINETIC MODEL. Mathematical Models and Methods in Applied Sciences 21:07, 1539-1569.  Online publication date: 1-Jul-2011. [ Abstract | PDF (427 KB) | PDF Plus (458 KB) ]\nSebastien Motsch , Laurent Navoret .  (2011) Numerical Simulations of a Nonconservative Hyperbolic System with Geometric Constraints Describing Swarming Behavior. Multiscale Modeling & Simulation 9:3, 1253-1275.  Online publication date: 1-Jul-2011. [Crossref]\nPierre Degond , Sébastien Motsch .  (2011) A Macroscopic Model for a System of Swarming Agents Using Curvature Control. Journal of Statistical Physics 143:4, 685-714.  Online publication date: 1-May-2011. [Crossref]\nN. Bellomo , C. Bianca , V. Coscia .  (2011) On the modeling of crowd dynamics: An overview and research perspectives. SeMA Journal 54:1, 25-46.  Online publication date: 1-Apr-2011. [Crossref]\nMartial Agueh , Reinhard Illner , Ashlin Richardson .  (2011) Analysis and simulations of a refined flocking and swarming model of Cucker-Smale type. Kinetic and Related Models 4:1, 1-16.  Online publication date: 1-Jan-2011. [Crossref]\nNicola Bellomo , Christian Dogbe .  (2011) On the Modeling of Traffic and Crowds: A Survey of Models, Speculations, and Perspectives. SIAM Review 53:3, 409-463.  Online publication date: 1-Jan-2011. [Crossref]\nSeung-Yeal Ha , Eunhee Jeong , Moon-Jin Kang .  (2010) Emergent behaviour of a generalized Viscek-type flocking model. Nonlinearity 23:12, 3139-3156.  Online publication date: 1-Dec-2010. [Crossref]\nRenjun Duan , Massimo Fornasier , Giuseppe Toscani .  (2010) A Kinetic Flocking Model with Diffusion. Communications in Mathematical Physics 300:1, 95-145.  Online publication date: 1-Nov-2010. [Crossref]\nN. Bellomo , C. Bianca , M.S. Mongiovì .  (2010) On the modeling of nonlinear interactions in large complex systems. Applied Mathematics Letters 23:11, 1372-1377.  Online publication date: 1-Nov-2010. [Crossref]\nPIERRE DEGOND , TONG YANG .  (2010) DIFFUSION IN A CONTINUUM MODEL OF SELF-PROPELLED PARTICLES WITH ALIGNMENT INTERACTION. Mathematical Models and Methods in Applied Sciences 20:supp01, 1459-1490.  Online publication date: 1-Sep-2010. [ Abstract | PDF (452 KB) | PDF Plus (484 KB) ]\nN. BELLOMO , H. BERESTYCKI , F. BREZZI , J.-P. NADAL .  (2010) MATHEMATICS AND COMPLEXITY IN LIFE AND HUMAN SCIENCES. Mathematical Models and Methods in Applied Sciences 20:supp01, 1391-1395.  Online publication date: 1-Sep-2010. [ Abstract | PDF (95 KB) | PDF Plus (109 KB) ]\nI. Bonzani .  (2010) Some theoretical reasonings on the use and abuse of empirical data for vehicular traffic modelling. Mathematical and Computer Modelling 52:5-6, 715-723.  Online publication date: 1-Sep-2010. [Crossref]\nSeung-Yeal Ha , Taeyoung Ha , Jong-Ho Kim .  (2010) Asymptotic dynamics for the Cucker–Smale-type model with the Rayleigh friction. Journal of Physics A: Mathematical and Theoretical 43:31, 315201.  Online publication date: 6-Aug-2010. [Crossref]\nN. Bellomo .  (2010) Modeling the hiding–learning dynamics in large living systems. Applied Mathematics Letters 23:8, 907-911.  Online publication date: 1-Aug-2010. [Crossref]\nPierre Degond , Laurent Navoret , Richard Bon , David Sanchez .  (2010) Congestion in a Macroscopic Model of Self-driven Particles Modeling Gregariousness. Journal of Statistical Physics 138:1-3, 85-125.  Online publication date: 1-Feb-2010. [Crossref]\nC. Bianca .  (2010) On the modelling of space dynamics in the kinetic theory for active particles. Mathematical and Computer Modelling 51:1-2, 72-83.  Online publication date: 1-Jan-2010. [Crossref]\nJ. A. Carrillo , M. Fornasier , J. Rosado , G. Toscani .  (2010) Asymptotic Flocking Dynamics for the Kinetic Cucker–Smale Model. SIAM Journal on Mathematical Analysis 42:1, 218-236.  Online publication date: 1-Jan-2010. [Crossref]\nI. Bonzani , L. Mussone .  (2009) On the derivation of the velocity and fundamental traffic flow diagram from the modelling of the vehicle–driver behaviors. Mathematical and Computer Modelling 50:7-8, 1107-1112.  Online publication date: 1-Oct-2009. [Crossref]\nN. BELLOMO , H. BERESTYCKI , F. BREZZI , J.-P. NADAL .  (2009) MATHEMATICS AND COMPLEXITY IN LIFE AND HUMAN SCIENCES. Mathematical Models and Methods in Applied Sciences 19:supp01, 1385-1389.  Online publication date: 1-Aug-2009. [ Abstract | PDF (85 KB) | PDF Plus (95 KB) ]\nI. Bonzani , L.M. Gramani Cumin .  (2009) Critical analysis and perspectives on the hydrodynamic approach for the mathematical theory of vehicular traffic. Mathematical and Computer Modelling 50:3-4, 526-541.  Online publication date: 1-Aug-2009. [Crossref]\nE. De Angelis , R. Revelli , L. Ridolfi .  (2009) Transport–diffusion models with nonlinear boundary conditions and solution by generalized collocation methods. Computers & Mathematics with Applications 58:3, 558-565.  Online publication date: 1-Aug-2009. [Crossref]\nN. Bellomo , M. Delitala .  (2009) On the coupling of higher and lower scales using the mathematical kinetic theory of active particles. Applied Mathematics Letters 22:5, 646-650.  Online publication date: 1-May-2009. [Crossref]\nN. Bellomo , A. Bellouquid .  (2009) On the derivation of macroscopic hyperbolic equations for binary multicellular growing mixtures. Computers & Mathematics with Applications 57:5, 744-756.  Online publication date: 1-Mar-2009. [Crossref]\nN. Bellomo , M. Delitala .  (2008) From the mathematical kinetic, and stochastic game theory to modelling mutations, onset, progression and immune competition of cancer cells. Physics of Life Reviews 5:4, 183-206.  Online publication date: 1-Dec-2008. [Crossref]\n""","0.17413512","""http://www.worldscientific.com/doi/abs/10.1142/S0218202508003005""","[-0.178219,51.500505]"
"""UCL""","""Iris Publication""","""http://discovery.ucl.ac.uk/1502222/\nAbstract\nDeveloping countries are facing increasing challenges to make urban mobility sustainable and more specifically to tackle the continuously growing air pollution and congestion caused by rapid increase in car ownership. As part of a broad strategy to achieve sustainable urban mobility, bike-sharing service can help reduce car use, especially in city centre area. There is currently a lack of knowledge in developing countries about the factors affecting bike-sharing choice, hindering policy making to effectively improve existing bike-sharing schemes and launch more schemes. This research investigates the factors affecting bike-sharing choice in China with a particular focus on the impacts of air pollution and weather conditions. Multinomial logit model is used to analyse transport mode choice behaviour based on the short-distance stated preference data collected in the case study city, Taiyuan, which currently operates the most demanded bike-sharing scheme in China. The results confirm the strong and significant impacts of air pollution on bike-sharing usage as well as other exposed alternatives such as walk and electric bike. Thus, it is concluded that tackling air pollution can create a virtuous circle to deliver sustainable urban mobility. The impacts of a number of other factors are also found to be significant (e.g. trip purpose, travel cost, age, income and educational level etc.) and can lead to corresponding policy implications.\nPublication data is maintained in RPS. Visit https://rps.ucl.ac.uk\n› More search options\n""","0.52247447","""http://iris.ucl.ac.uk/iris/publication/1139371/1""",
"""Imperial_College_London""","""Influence of the pavement surface on the vibrations induced by heavy traffic in road bridges - Canadian Journal of Civil Engineering""","""Canadian Journal of Civil Engineering\nA. Camara, a V.F. Vázquez, b A.M. Ruiz-Teran, c S.E. Paje b\naDepartment of Civil Engineering at City, University of London, Northampton Square, EC1V 0HB, London, United Kingdom.\nbLaboratory of Acoustics Applied to Civil Engineering, University of Castilla-La Mancha, Avda. Camilo José Cela s/n, 13071 Ciudad Real, Spain.\ncDepartment of Civil and Environmental Engineering. Imperial College London. South Kensington Campus. Exhibition Rd, London SW7 2AZ, United Kingdom.\nCorresponding author: Alfredo Camara (email: alfredo.\nCopyright remains with the author(s) or their institution(s). Permission for reuse (free in most cases) can be obtained from RightsLink .\nPublished on the web 7 September 2017.\nReceived May 17, 2017. Accepted August 26, 2017.\nCanadian Journal of Civil Engineering, 2017, 44(12): 1099-1111, https://doi.org/10.1139/cjce-2017-0310\nAbstract\nThe irregularity of the pavement surface governs the traffic-induced vibrations in road bridges, but it is either ignored or simulated by means of ideal pavements that differ significantly from real cases. This work presents a detailed dynamic analysis of a heavy truck crossing a 40 m span composite deck bridge using on-site measurements of different existing road profiles, as well as code-based ideal pavements. By activating or deactivating certain spatial frequency bands of the pavement, it is observed that the ranges 0.2–1 and 0.02–0.2 cycles/m are critical for the comfort of the pedestrians and the vehicle users, respectively. Well maintained roads with low values of the displacement power spectral density (PSD) associated with these spatial frequency ranges could reduce significantly the vibration on the sidewalks and, specially, in the vehicle cabin. Finally, a consistent road categorization for vibration assessment based on the PSD of the pavement irregularity evaluated at the dominant frequencies is proposed.\nKeywords: bridge dynamics , pavement irregularity , vibrations , vehicle–bridge interaction models , pedestrians\nReferences\nAASHTO. 1998. Load and resistance and factor design: Bridge design specifications. 2nd ed. American Association of State Highway and Transportation Officials.\nAbaqus. 2011. Finite element analysis program. Version 6.11. Providence, USA.\nBoggs, D., and Petersen, C. 1995. Acceleration indexes for human comfort in tall buildings–peak or rms?\nBogsjö, K., Podgorsky, K., and Rychlik, I. 2010. Models for road surface roughness. Department of Mathematical Sciences, University of Gothemburg.\nCamara A,  Ruiz-Teran AM.                 2015. Multi-mode traffic-induced vibrations in composite ladder-deck bridges under heavy moving vehicles. Journal of Sound and Vibration 355: 264-283 Crossref .\nCamara A,  Nguyen K,  Ruiz-Teran AM,  Stafford PJ.                 2014. Serviceability limit state of vibrations in under-deck cable-stayed bridges accounting for vehicle-structure interaction. Engineering Structures 61: 61-72 Crossref .\nCaptain KM,  Boghani AB,  Wormley DN.                 1979. Analytical tire models for dynamic vehicle simulation. Vehicle System Dynamics 8: 1-32 Crossref .\nChang KC,  Wu FB,  Yang YB.                 2011. Disk model for wheels moving over highway bridges with rough surfaces. Journal of Sound and Vibration 330: 4930-4944 Crossref .\nCoussy O,  Said M,  Van Hoove, J-P.                 1989. The influence of random surface irregularities on the dynamic response of bridges under suspended moving loads. Journal of Sound and Vibration 130(2): 313-320 Crossref , ISI .\nDeng L,  Cai CS.                 2009. Identification of parameters of vehicles moving on bridges. Engineering Structures 31(10): 2474-2485 Crossref .\nDeng L,  Cai CS.                 2010. Development of dynamic impact factor for performance evaluation of existing multi-girder concrete bridges. Engineering Structures 32(1): 21-31 Crossref .\nDescornet, G. 1990. Reference road surfaces for vehicle testing. Roads PIARC. No. 272.\nDodds, C. 1972. Generalised terrain dynamic inputs to vehicles. BSI document 72/34562 (ISO/TC/108/WG9 (MEE/158/3/1)).\nDodds CJ,  Robson JD.                 1973. The description of road surface roughness. Journal of Sound and Vibration 31(2): 175-183 Crossref , ISI .\nHan W,  Wu J,  Cai C,  Chen S.                 2014. Characteristics and dynamic impact of overloaded extra heavy trucks on typical highway bridges. Journal of Bridge Engineering 20(2): 05014011 Crossref .\nHenchi K,  Fafard M,  Talbot M,  Dhatt G.                 1998. An efficient algorithm for dynamic analysis of bridges under moving vehicles using a coupled modal and physical components approach. Journal of Sound and Vibration 214(4): 663-683 Crossref .\nHilber HM,  Hughes TJR,  Taylor RL.                 1977. Improved numerical dissipation for time integration algorithms in structural dynamics. Earthquake Engineering & Structural Dynamics 5: 283-292 Crossref , ISI .\nISO 8608. 1995. Mechanical vibration–Road surface profiles–Reporting of measured data. International Organization for Standardization (ISO).\nJanoff, M., and Mayhoe, G. 1990. The development of a simple instrument for measuring pavement roughness and predicting pavement rideability. Surface characteristic of roadways: international research and technologies. ASTM, STP 1031.\nKamash KMA,  Robson JD.                 1978. The application of isotropy in road surface modelling. Journal of Sound and Vibration 57(1): 89-100 Crossref .\nLabarre, R., Forbes, R., and Andrew, S. 1969. The measurement and analysis of road surface roughness. Motor Industry Research Association. Report No. 1970/5.\nMarchesiello S,  Fasana A,  Garibaldi L,  Piombo B.                 1999. Dynamics of multi-span continuous straight bridges subject to multi-degrees of freedom moving vehicle excitation. Journal of Sound and Vibration 224(3): 541-561 Crossref .\nMarcondes, J., Singh, S., and Burgess, G. 1988. Dynamic analysis of a less than truck load shipment. Paper 88-WA/EEP-17. ASME, New York.\nMarcondes J,  Burgess G,  Harichandran R,  Snyder M.                 1990. Spectral analysis of highway pavement roughness. Journal of Transportation Engineering 117(5): 540-549 Crossref .\nMcLean, J., and Ramsay, E. 1996. Interpretations of road profile-roughness data: review and research needs. ARRB Transport Research Report, ARR 295.\nPaje SE,  Luong J,  Vázquez VF,  Bueno M,  Miró R.                 2013. Road pavement rehabilitation using a binder with a high content of crumb rubber: Influence on noise reduction. Construction and building Materials 47: 789-798 Crossref .\nShahabadi, A. 1977. Bridge vibration studies. joint highway research project. Purdue University & Indiana State Highway Commission (September). Report. No. JHRP 77-17.\nUys PE,  Els PS,  Thoresson M.                 2007. Suspension settings for optimal ride comfort of off-road vehicles travelling on roads with different roughness and speeds. Journal of Terramechanics 44: 163-175 Crossref .\nVázquez V,  Luong J,  Bueno M,  Terán F,  Paje S.                 2016. Assessment of an action against environmental noise: Acoustic durability of a pavement surface with crumb rubber. Science of the Total Environment 542: 223-230 Crossref , Medline .\nZhou Y,  Chen S.                 2016. Vehicle ride comfort analysis with whole-body vibration on long-span bridges subjected to crosswind. Journal of Wind Engineering and Structural Dynamics 155: 126-140 Crossref .\nZhu XQ,  Law SS.                 2002. Dynamic load on continuous multi-lane bridge deck from moving vehicles. Journal of Sound and Vibration 251(4): 697-716 Crossref .\nList of symbols\n""","0.5617863","""http://www.nrcresearchpress.com/doi/10.1139/cjce-2017-0310""","[-0.178219,51.500505]"
"""University_of_Birmingham""","""Development and design of a narrow-gauge hydrogen-hybrid locomotiveProceedings of the Institution of Mechanical Engineers, Part F: Journal of Rail and Rapid Transit - Duncan Coombe, Peter Fisher, Andreas Hoffrichter, Stephen Kent, Daniel Reed, Hamed Rowshandel, Jonathan Tutcher, Mani Entezami, Stuart Hillmansen, Alexander Bevan, David Book, Rory Dickerson, Ivor Harris, Clive Roberts, Kevin Sperin, Edward Stewart, Graeme Yeo, Adnan Zentani, 2016""","""Introduction\nSection:\nCurrently, petroleum-based diesel is the primary fuel for railway motive power on a global level. 1 The combustion of diesel releases emissions at the point of use that are undesirable and are subject to increasing regulation. 2 , 3 Furthermore, concerns about energy security and increasing diesel prices have prompted the railway industry to explore alternative fuel sources 4 – 7 ; hydrogen is one of these potential sources. 8 – 11 This energy carrier can be made from several feedstocks, and when combusted with oxygen, creates only water and heat or, if utilised in a fuel cell, also produces electrical energy. 12\nIn this paper, the authors describe the design methodology for a prototype hydrogen fuel cell locomotive in order to demonstrate a proof of the concept of using hydrogen technology for railway motive power. The locomotive was constructed in order to participate in the Institution of Mechanical Engineers’ (IMechE) inaugural railway challenge. 13 – 15 Teams that participated in this competition had to design, construct and demonstrate a railway locomotive that was to operate on 10.25 inch (260.35 mm) gauge track. The competition comprised several challenges, and those based on the physical performance were: ride comfort, energy storage and traction performance. 14 , 16 The Birmingham Centre of Railway Research and Education (BCRRE) at the University of Birmingham entered the Railway Challenge with a multidisciplinary team consisting of members from: the School of Chemical Engineering, the School of Metallurgy and Materials, and from the BCRRE. The development and design of the resulting locomotive, called the Hydrogen Pioneer, is described in this paper. The vehicle was designed as a proof-of-concept vehicle, and the proof lay in the successful completion of the physical performance challenges or requirements as set by the IMechE for any contending team. To the authors’ knowledge the Hydrogen Pioneer is the UK’s first practical hydrogen-powered locomotive.\nDesign of the Hydrogen Pioneer\nSection:\nThe IMechE challenge had a number of detailed performance and mandatory requirements that reflect the design challenges faced by engineers of main-line and metro railway vehicles. The locomotive design team adopted the systems engineering approach, in which each stage of the design process was assessed against the high-level requirements provided by the specification and performance documents. The design tasks were organised into the key sub-systems, which included: the mechanical design, the control and electrical systems and the power plant and hydrogen supply design. The concept design and the individual sub-system designs are described in the remainder of this section.\nConcepts behind the design\nTo fulfil the basic requirements, such as regenerative braking capability, a hybrid design with a power plant and an energy storage device was employed. In order to meet the high-level requirements of hydrogen operation and minimal emissions, a fuel-cell-based system was selected. The system consisted of a fuel cell stack and DC/DC converter with an extra low-voltage DC output, and this formed the power plant of the locomotive. An energy storage system to meet the peak power demand and to enable the capture of braking energy was required. This was achieved using an electro-chemical battery system that had a DC output, which interfaced with the power plant. Two low-voltage DC motors and associated controllers were used to provide motive power and an interface with the outputs of the power plant and the battery pack. The conceptual design of the drive-train is shown in Figure 1 .\n""","0.39644516","""http://journals.sagepub.com/doi/10.1177/0954409714532921""","[-1.933663,52.454008]"
"""Imperial_College_London""","""Using Activity-Based Modeling to Simulate Urban Resource Demands at High Spatial and Temporal Resolutions - Keirstead - 2012 - Journal of Industrial Ecology - Wiley Online Library""","""Journal of Industrial Ecology\nPrevious article in issue: Greenhouse Gas Emission Scenario Modeling for Cities Using the PURGE Model\nPrevious article in issue: Greenhouse Gas Emission Scenario Modeling for Cities Using the PURGE Model\nSpecial Issue: Sustainable Urban Systems\nRESEARCH AND ANALYSIS\nUsing Activity-Based Modeling to Simulate Urban Resource Demands at High Spatial and Temporal Resolutions\nAuthors\nCited by (CrossRef): 15 articles Check for updates\nCitation tools\nAddress correspondence to: James Keirstead, 407 Skempton Building, Department of Civil and Environmental Engineering, Imperial College London, London, SW7 2AZ, United Kingdom. Email: j.keirstead@imperial.ac.uk\nSummary\nUrban metabolism is an important technique for understanding the relationship between cities and the wider environment. Such analyses are typically performed at the scale of the whole city using annual average data, a feature that is driven largely by restrictions in data availability. However, in order to assess the resource implications of policy interventions and to design and operate efficient urban infrastructures such as energy systems, greater spatial and temporal resolutions are required in the underlying resource demand data. As this information is rarely available, we propose that these demand profiles might be simulated using activity-based modeling. This is a microsimulation approach that calculates the activity schedules of individuals within the city and then converts this information into resource demands. The method is demonstrated by simulating electricity and natural gas demands in London and by examining how these nontransport energy demands might change in response to a shift in commuting patterns, for example, in response to a congestion charge or similar policy. The article concludes by discussing the strengths and weaknesses of the approach, as well as highlighting future research directions. Key challenges include the simulation of in-home activities, assessing the transferability of the complex data sets and models supporting such analyses, and determining which aspects of urban metabolism would benefit most from this technique.\nUrban Energy Systems project at Imperial College London\nRelated content\nArticles related to the one you are viewing\nCiting Literature\nNumber of times cited: 15\n1\nIsabel M. Horta, James Keirstead, Downscaling Aggregate Urban Metabolism Accounts to Local Districts, Journal of Industrial Ecology, 2017, 21, 2, 294\nWiley Online Library\n2\nMartin Dijst, Ernst Worrell, Lars Böcker, Paul Brunner, Simin Davoudi, Stan Geertman, Robert Harmsen, Marco Helbich, Albert A.M. Holtslag, Mei-Po Kwan, Barbara Lenz, Glenn Lyons, Patricia L. Mokhtarian, Peter Newman, Adriaan Perrels, Ana Poças Ribeiro, Jesus Rosales Carreón, Giles Thomson, Diana Urge-Vorsatz, Marianne Zeyringer, Exploring urban metabolism—Towards an interdisciplinary perspective, Resources, Conservation and Recycling, 2017\nCrossRef\n3\nJulia Sokol, Carlos Cerezo Davila, Christoph F. Reinhart, Validation of a Bayesian-based method for defining residential archetypes in urban building energy models, Energy and Buildings, 2017, 134, 11\nCrossRef\n4\nF. Kraxner, K. Aoki, G. Kindermann, S. Leduc, F. Albrecht, J. Liu, Y. Yamagata, Bioenergy and the city – What can urban forests contribute?, Applied Energy, 2016, 165, 990\n5\nEoghan McKenna, Murray Thomson, High-resolution stochastic integrated thermal–electrical domestic demand model, Applied Energy, 2016, 165, 445\nCrossRef\n6\nK. Kuriyan, 12th International Symposium on Process Systems Engineering and 25th European Symposium on Computer Aided Process Engineering, 2015, 37, 971\nCrossRef\n7\nMerkebe Getachew Demissie, Gonçalo Correia, Carlos Bento, Analysis of the pattern and intensity of urban activities through aggregate cellphone usage, Transportmetrica A: Transport Science, 2015, 11, 6, 502\nCrossRef\n8\nMing Xu, Hua Cai, Sai Liang, Big Data and Industrial Ecology, Journal of Industrial Ecology, 2015, 19, 2, 205\nWiley Online Library\n9\nAndrea L. Hicks, Thomas L. Theis, Moira L. Zellner, Emergent Effects of Residential Lighting Choices: Prospects for Energy Savings, Journal of Industrial Ecology, 2015, 19, 2, 285\nWiley Online Library\n10\nHossein Shahrokni, David Lazarevic, Nils Brandt, Smart Urban Metabolism: Towards a Real-Time Understanding of the Energy and Material Flows of a City and Its Citizens, Journal of Urban Technology, 2015, 22, 1, 65\nCrossRef\n11\nAndrea L. Hicks, Thomas L. Theis, An agent based approach to the potential for rebound resulting from evolution of residential lighting technologies, The International Journal of Life Cycle Assessment, 2014, 19, 2, 370\nCrossRef\n12\nStephanie Pincetl, Mikhail Chester, Giovanni Circella, Andrew Fraser, Caroline Mini, Sinnott Murphy, Janet Reyna, Deepak Sivaraman, Enabling Future Sustainability Transitions, Journal of Industrial Ecology, 2014, 18, 6, 871\nWiley Online Library\n13\nMacarena Rodriguez, Carlos Calderon, Modelling approaches for retrofitting energy systems in cities, disP - The Planning Review, 2014, 50, 3, 76\nCrossRef\n14\nA. Overeem, J. C. R. Robinson, H. Leijnse, G. J. Steeneveld, B. K. P. Horn, R. Uijlenhoet, Crowdsourcing urban air temperatures from smartphone battery temperatures, Geophysical Research Letters, 2013, 40, 15, 4081\nWiley Online Library\n15\nChristopher Kennedy, Lawrence Baker, Shobhakar Dhakal, Anu Ramaswami, Sustainable Urban Systems, Journal of Industrial Ecology, 2012, 16, 6, 775\n""","0.29529765","""http://onlinelibrary.wiley.com/doi/10.1111/j.1530-9290.2012.00486.x/abstract""","[-0.178219,51.500505]"
"""Imperial_College_London""","""Global and local information in traffic congestion - IOPscience""","""Global and local information in traffic congestion\nG. Petri1,2, H. Jeldtoft Jensen2,3 and J. W. Polak1\nPublished 6 November 2009 • Europhysics Letters Association\nh.jensen@imperial.ac.uk\nAuthor affiliations\n1 Centre for Transport Studies, Department of Civil and Environmental Engineering, Imperial College London South Kensington Campus, London SW7 2AZ, UK, EU\n2 Institute for Mathematical Sciences, Imperial College London - 53 Princes Gate, London SW7 2PG, UK, EU\n3 Department of Mathematics, Imperial College London - South Kensington Campus, London SW7 2AZ, UK, EU\nDates\n0295-5075/88/2/20010\nAbstract\nA generic network flow model of transport (of relevance to information transport as well as physical transport) is studied under two different control protocols. The first involves information concerning the global state of the network, the second only information about nodes' nearest neighbors. The global protocol allows for a larger external drive before jamming sets in, at the price of significant larger flow fluctuations. By triggering jams in neighboring nodes, the jamming perturbation grows as a pulsating core. This feature explains the different results for the two information protocols.\nExport citation and abstract\n""","0.92322886","""http://iopscience.iop.org/article/10.1209/0295-5075/88/20010/meta""","[-0.178219,51.500505]"
"""Queen's_University_Belfast""","""Numerical Analysis on a Dual-Loop Waste Heat Recovery System Coupled with an ORC for Vehicle Applications - Queen's University Belfast Research Portal - Research Directory & Institutional Repository for QUB""","""Numerical Analysis on a Dual-Loop Waste Heat Recovery System Coupled with an ORC for Vehicle Applications\nResearch output: Chapter in Book/Report/Conference proceeding › Conference contribution\nPublished\nView graph of relations\nThe internal combustion (IC) engines exploits only about 30% of the chemical energy ejected through combustion, whereas the remaining part is rejected by means of cooling system and exhausted gas. Nowadays, a major global concern is finding sustainable solutions for better fuel economy which in turn results in a decrease of carbon dioxide (CO2) emissions. The Waste Heat Recovery (WHR) is one of the most promising techniques to increase the overall efficiency of a vehicle system, allowing the recovery of the heat rejected by the exhaust and cooling systems. In this context, Organic Rankine Cycles (ORCs) are widely recognized as a potential technology to exploit the heat rejected by engines to produce electricity. The aim of the present paper is to investigate a WHR system, designed to collect both coolant and exhausted gas heats, coupled with an ORC cycle for vehicle applications. In particular, a coolant heat exchanger (CLT) allows the heat exchange between the water coolant and the ORC working fluid, whereas the exhausted gas heat is recovered by using a secondary circuit with diathermic oil. By using an in-house numerical model, a wide range of working conditions and ORC design parameters are investigated. In particular, the analyses are focused on the regenerator location inside the ORC circuits. Five organic fluids, working in both subcritical and supercritical conditions, have been selected in order to detect the most suitable configuration in terms of energy and exergy efficiencies.\nDOI\n""","0.68598664","""http://pure.qub.ac.uk/portal/en/publications/numerical-analysis-on-a-dualloop-waste-heat-recovery-system-coupled-with-an-orc-for-vehicle-applications(39902913-4f58-4a00-9d04-585b32b8ba27).html""","[-5.934759,54.583863]"
"""StaffOxfordUniversityPhysics""","""Trace gas and aerosol interactions in the fully coupled model of aerosol-chemistry-climate ECHAM5-HAMMOZ: 1. Model description and insights from the spring 2001 TRACE-P experiment - Pozzoli - 2008 - Journal of Geophysical Research: Atmospheres - Wiley Online Library""","""Journal of Geophysical Research: Atmospheres\nPrevious article in issue: Characterization of the composition, structure, and seasonal variation of the mixing layer above the extratropical tropopause as revealed by MOZAIC measurements\nPrevious article in issue: Characterization of the composition, structure, and seasonal variation of the mixing layer above the extratropical tropopause as revealed by MOZAIC measurements\n16 April 2008\nComposition and Chemistry\nTrace gas and aerosol interactions in the fully coupled model of aerosol-chemistry-climate ECHAM5-HAMMOZ: 1. Model description and insights from the spring 2001 TRACE-P experiment\nAuthors\nLaboratoire de Modélisation de la Chimie Atmosphérique, École Polytechnique Fédérale de Lausanne, Lausanne, Switzerland\nNow at Atmosphere in Earth System, Max Planck Institute for Meteorology, Hamburg, Germany.\nDepartment of Environmental Science and Engineering, California Institute of Technology, Pasadena, California, USA\nNow at Atmospheric, Oceanic and Planetary Physics, University of Oxford, Oxford, UK.\nCited by (CrossRef): 13 articles Check for updates\nCitation tools\nCiting literature\nAbstract\n[1] In this paper, we introduce the ECHAM5-HAMMOZ aerosol-chemistry-climate model that includes fully interactive simulations of Ox-NOx-hydrocarbons chemistry and of aerosol microphysics (including prognostic size distribution and mixing state of aerosols) implemented in the General Circulation Model ECHAM5. The photolysis rates used in the gas chemistry account for aerosol and cloud distributions and a comprehensive set of heterogeneous reactions is implemented. The model is evaluated with trace gas and aerosol observations provided by the TRACE-P aircraft experiment. Sulfate concentrations are well captured but black carbon concentrations are underestimated. The number concentrations, surface areas, and optical properties are reproduced fairly well near the surface but underestimated in the upper troposphere. CO concentrations are well reproduced in general while O3 concentrations are overestimated by 10–20 ppbv. We find that heterogeneous chemistry significantly influences the regional and global distributions of a number of key trace gases. Heterogeneous reactions reduce the ozone surface concentrations by 18–23% over the TRACE-P region and the global annual mean O3 burden by 7%. The annual global mean OH concentration decreases by 10% inducing a 7% increase in the global CO burden. Annual global mean HNO3 surface concentration decreases by 15% because of heterogenous reaction on mineral dust. A comparison of our results to those from previous studies suggests that the choice of uptake coefficients for a given species is the critical parameter that determines the global impact of heterogeneous chemistry on a trace gas (rather than the description of aerosol properties and distributions). A prognostic description of the size distribution and mixing state of the aerosols is important, however, to account for the effect of heterogeneous chemistry on aerosols as further discussed in the second part of this two-part series.\nSupporting Information\nAuxiliary material for this article contains one text file, 14 figures, and three tables.\nAuxiliary material files may require downloading to a local drive depending on platform, browser, configuration, and size. To open auxiliary materials in a browser, click on the label. To download, Right-click and select “Save Target As…” (PC) or CTRL-click and select “Download Link to Disk” (Mac).\nSee Plugins for a list of applications and supported file formats.\nAdditional file information is provided in the readme.txt.\nFilename\njgrd14161-sup-0001-readme.txt plain text document, 4K\nreadme.txt\nFigure S1. Map of the TRACE-P DC8 and P3B flights.\njgrd14161-sup-0005-fs02.eps PS document, 649K\nFigure S2. Vertical profiles of simulated versus observed meteorological parameters for the ensemble of TRACE-P P3B flights.\njgrd14161-sup-0006-fs03.eps PS document, 615K\nFigure S3. Vertical profiles of simulated versus observed trace gases (CO, OH, O3) for the ensemble of TRACE-P P3B flights.\njgrd14161-sup-0007-fs04.eps PS document, 549K\nFigure S4. Vertical profiles of simulated versus observed trace gases (SO2, NO, NO2) for the ensemble of TRACE-P P3B flights.\njgrd14161-sup-0008-fs05.eps PS document, 439K\nFigure S5. Vertical profiles of simulated versus observed photolysis rates for the ensemble of TRACE-P P3B flights.\njgrd14161-sup-0009-fs06.eps PS document, 645K\nFigure S6. Vertical profiles of simulated versus observed aerosol concentrations and optical properties for the ensemble of TRACE-P P3B flights.\njgrd14161-sup-0010-fs07.eps PS document, 675K\nFigure S7. Vertical profiles of simulated versus observed aerosol size distributions for the ensemble of TRACE-P P3B flights.\njgrd14161-sup-0011-fs08.eps PS document, 75K\nFigure S8. Taylor diagrams comparing the ECHAM5-HAMMOZ BASE simulation to the DC8 flight and P3B flight TRACE-P observations.\njgrd14161-sup-0012-fs09.eps PS document, 80K\nFigure S9. Simulated mean vertical profiles of aerosol concentrations and contributions (%) of each aerosol species to the total aerosol surface in two different regions.\njgrd14161-sup-0013-fs10.eps PS document, 446K\nFigure S10. Flight tracks of DC8-06 and DC8-13.\njgrd14161-sup-0014-fs11.eps PS document, 1318K\nFigure S11. CO concentration at 1000, 725 and 500 hPa over the Trace-P region during flight DC8-06.\njgrd14161-sup-0015-fs12.eps PS document, 1313K\nFigure S12. CO concentration at 1000, 725 and 500 hPa over the Trace-P region during flight DC8-13.\njgrd14161-sup-0016-fs13.eps PS document, 143K\nFigure S13. Vertical profiles of aerosol surface contribution for each aerosol species and vertical profiles of O3, OH, SO2, HNO3, sulfate, mineral dust, and black carbon at 0800 (UTC) of flight DC8-06.\njgrd14161-sup-0017-fs14.eps PS document, 146K\nFigure S14. Vertical profiles of aerosol surface contribution for each aerosol species and vertical profiles of O3, OH, SO2, HNO3, sulfate, mineral dust, and black carbon at 0800 (UTC) of flight DC8-13.\njgrd14161-sup-0024-t01.txt plain text document, 2K\nTab-delimited Table 1.\njgrd14161-sup-0025-t02.txt plain text document, 2K\nTab-delimited Table 2.\njgrd14161-sup-0026-t03.txt plain text document, 1K\nTab-delimited Table 3.\njgrd14161-sup-0027-t04.txt plain text document, 1K\nTab-delimited Table 4.\njgrd14161-sup-0028-t05.txt plain text document, 1K\nTab-delimited Table 5.\njgrd14161-sup-0029-t06.txt plain text document, 1K\nTab-delimited Table 6.\njgrd14161-sup-0030-t07.txt plain text document, 1K\nTab-delimited Table 7.\njgrd14161-sup-0031-t08.txt plain text document, 1K\nTab-delimited Table 8.\njgrd14161-sup-0032-t09.txt plain text document, 1K\nTab-delimited Table 9.\njgrd14161-sup-0033-t10.txt plain text document, 1K\nTab-delimited Table 10.\njgrd14161-sup-0034-t11.txt plain text document, 1K\nTab-delimited Table 11.\njgrd14161-sup-0035-t12.txt plain text document, 1K\nTab-delimited Table 12.\nPlease note: Wiley-Blackwell is not responsible for the content or functionality of any supporting information supplied by the authors. Any queries (other than missing content) should be directed to the corresponding author for the article.\nRelated content\nArticles related to the one you are viewing\nCiting Literature\nNumber of times cited: 13\n1\nAnoop S. Mahajan, Isabelle De Smedt, Mriganka Sekhar Biswas, Sachin Ghude, Suvarna Fadnavis, Chaitri Roy, Michel van Roozendael, Inter-annual variations in satellite observations of nitrogen dioxide and formaldehyde over India, Atmospheric Environment, 2015, 116, 194\nCrossRef\n2\nSijia Lou, Hong Liao, Bin Zhu, Impacts of aerosols on surface-layer ozone concentrations in China through heterogeneous reactions and changes in photolysis rates, Atmospheric Environment, 2014, 85, 123\n3\nMohanad El-Harbawi, Air quality modelling, simulation, and computational methods: a review, Environmental Reviews, 2013, 21, 3, 149\nCrossRef\n4\nBjorn Stevens, Marco Giorgetta, Monika Esch, Thorsten Mauritsen, Traute Crueger, Sebastian Rast, Marc Salzmann, Hauke Schmidt, Jürgen Bader, Karoline Block, Renate Brokopf, Irina Fast, Stefan Kinne, Luis Kornblueh, Ulrike Lohmann, Robert Pincus, Thomas Reichler, Erich Roeckner, Atmospheric component of the MPI-M Earth System Model: ECHAM6, Journal of Advances in Modeling Earth Systems, 2013, 5, 2, 146\nWiley Online Library\n5\nE. Harris, B. Sinha, D. van Pinxteren, A. Tilgner, K. W. Fomba, J. Schneider, A. Roth, T. Gnauk, B. Fahlbusch, S. Mertes, T. Lee, J. Collett, S. Foley, S. Borrmann, P. Hoppe, H. Herrmann, Enhanced Role of Transition Metal Ion Catalysis During In-Cloud Oxidation of SO2, Science, 2013, 340, 6133, 727\nCrossRef\n6\nEliza Harris, Bärbel Sinha, Peter Hoppe, Shuhei Ono, High-Precision Measurements of33S and34S Fractionation during SO2Oxidation Reveal Causes of Seasonality in SO2and Sulfate Isotopic Composition, Environmental Science & Technology, 2013, 47, 21, 12174\nCrossRef\n7\nArlene M. Fiore, Vaishali Naik, Dominick V. Spracklen, Allison Steiner, Nadine Unger, Michael Prather, Dan Bergmann, Philip J. Cameron-Smith, Irene Cionni, William J. Collins, Stig Dalsøren, Veronika Eyring, Gerd A. Folberth, Paul Ginoux, Larry W. Horowitz, Béatrice Josse, Jean-François Lamarque, Ian A. MacKenzie, Tatsuya Nagashima, Fiona M. O'Connor, Mattia Righi, Steven T. Rumbold, Drew T. Shindell, Ragnhild B. Skeie, Kengo Sudo, Sophie Szopa, Toshihiko Takemura, Guang Zeng, Global air quality and climate, Chemical Society Reviews, 2012, 41, 19, 6663\nCrossRef\n8\nSusan C. Anenberg, Joel Schwartz, Drew Shindell, Markus Amann, Greg Faluvegi, Zbigniew Klimont, Greet Janssens-Maenhout, Luca Pozzoli, Rita Van Dingenen, Elisabetta Vignati, Lisa Emberson, Nicholas Z. Muller, J. Jason West, Martin Williams, Volodymyr Demkine, W. Kevin Hicks, Johan Kuylenstierna, Frank Raes, Veerabhadran Ramanathan, Global Air Quality and Health Co-benefits of Mitigating Near-Term Climate Change through Methane and Black Carbon Emission Controls, Environmental Health Perspectives, 2012, 120, 6, 831\nCrossRef\n9\nD. Shindell, J. C. I. Kuylenstierna, E. Vignati, R. van Dingenen, M. Amann, Z. Klimont, S. C. Anenberg, N. Muller, G. Janssens-Maenhout, F. Raes, J. Schwartz, G. Faluvegi, L. Pozzoli, K. Kupiainen, L. Hoglund-Isaksson, L. Emberson, D. Streets, V. Ramanathan, K. Hicks, N. T. K. Oanh, G. Milly, M. Williams, V. Demkine, D. Fowler, Simultaneously Mitigating Near-Term Climate Change and Improving Human Health and Food Security, Science, 2012, 335, 6065, 183\nCrossRef\n10\nQuentin Bourgeois, Isabelle Bey, Pollution transport efficiency toward the Arctic: Sensitivity to aerosol scavenging and source regions, Journal of Geophysical Research, 2011, 116, D8\nWiley Online Library\n11\nA.W. Strawa, T.W. Kirchstetter, A.G. Hallar, G.A. Ban-Weiss, J.P. McLaughlin, R.A. Harley, M.M. Lunden, Optical and physical properties of primary on-road vehicle particle emissions and their implications for climate change, Journal of Aerosol Science, 2010, 41, 1, 36\nCrossRef\n12\nA. Vlasenko, T. Huthwelker, H. W. Gäggeler, M. Ammann, Kinetics of the heterogeneous reaction of nitric acid with mineral dust particles: an aerosol flowtube study, Physical Chemistry Chemical Physics, 2009, 11, 36, 7921\nCrossRef\n13\nL. Pozzoli, I. Bey, S. Rast, M. G. Schultz, P. Stier, J. Feichter, Trace gas and aerosol interactions in the fully coupled model of aerosol-chemistry-climate ECHAM5-HAMMOZ: 2. Impact of heterogeneous chemistry on the global aerosol distributions, Journal of Geophysical Research, 2008, 113, D7\n""","0.17547253","""http://onlinelibrary.wiley.com/doi/10.1029/2007JD009007/abstract""",
"""Imperial_College_London""","""Renewable energy investment in China: the impact of low oil prices: Economic and Political Studies: Vol 4, No 3""","""Economic and Political Studies\nGet access /doi/full/10.1080/20954816.2016.1218688?needAccess=true\nAbstract\nThe promotion of renewable energy (RE) technology in China has been paramount in the country’s policy to reinforce energy security, reduce air pollution from coal, oil and gas, and tackle climate change. This study examines whether the RE sector in China (primarily solar and wind) might suffer an immediate or long-term backlash as the result of cuts in oil import costs. The demand for oil in China has increased at an astounding rate since the 1980s. In the face of its burgeoning economy and multiplying vehicle fleet, energy security has become a significant preoccupation for policy makers. The rapid fall in oil prices on the international market since June 2014 is likely to improve security of supply and positively impact the nation’s economy. However, the fate of another energy sector, RE technology is less predictable. The article proposes a quantitative model to compare oil demand and prices over recent years with the impact on investment in RE, taking into account that the main competitor of RE is coal rather than oil. How energy policy has evolved and adapted over this period is also discussed. It is observed that lower oil prices decrease RE investments but reduce concerns over energy security. But, the strength of the impact depends on the duration of low oil prices and its volatility. The commitment of the government to reduce global CO2 emissions may not be overlooked.\n""","0.49057585","""http://www.tandfonline.com/doi/full/10.1080/20954816.2016.1218688""","[-0.178219,51.500505]"
"""Imperial_College_London""","""The vehicle emissions and performance monitoring system: analysis of tailpipe emissions and vehicle performance: Transportation Planning and Technology: Vol 27, No 6""","""Get access /doi/full/10.1080/0308106042000293480?needAccess=true\nAbstract\nThis paper describes tailpipe emission results generated by the Vehicle Performance and Emissions Monitoring system (VPEMS). VPEMS integrates on‐board emissions and vehicle/driver performance measurements with positioning and communications technologies, to transmit a coherent spatio‐temporally referenced dataset to a central base station in near real time. These results focus on relationships between tailpipe emissions of CO, CO2, NOx and speed and acceleration. Emissions produced by different driving modes are also presented. Results are generally as one would expect, showing variation between vehicle speed, vehicle acceleration and emissions. Data is based upon a test run in central London on urban streets with speeds not exceeding about 65 km/h. The results presented demonstrate the capabilities of the system. Various issues remain with regard to validation of the data and expansion of the system capability to obtain additional vehicle performance data.\n""","1.4961343","""http://www.tandfonline.com/doi/abs/10.1080/0308106042000293480""","[-0.178219,51.500505]"
"""Queen's_University_Belfast""","""A Conventional Internal Combustion Engine Versus a Range Extended Electric Vehicle Under the Current Regulatory Regime in the United Kingdom - Queen's University Belfast Research Portal - Research Directory & Institutional Repository for QUB""","""A Conventional Internal Combustion Engine Versus a Range Extended Electric Vehicle Under the Current Regulatory Regime in the United Kingdom\nResearch output: Contribution to conference › Paper\nPublished\nView graph of relations\nTransport accounts for 22% of greenhouse gas emissions in the United Kingdom and cars are expected tomore than double by 2050. Car manufacturers are continually aiming for a substantially reduced carbonfootprint through improved fuel efficiency and better powertrain performance due to the strict EuropeanUnion emissions standards. However, road tax, not just fuel efficiency, is a key consideration of consumerswhen purchasing a car. While measures have been taken to reduce emissions through stricter standards, infuture, alternative technologies will be used. Electric vehicles, hybrid vehicles and range extended electricvehicles have been identified as some of these future technologies. In this research a virtual test bed of aconventional internal combustion engine and a range extended electric vehicle family saloon car were builtin AVL’s vehicle and powertrain system level simulation tool, CRUISE, to simulate the New EuropeanDrive Cycle and the results were then soft-linked to a techno-economic model to compare the effectivenessof current support mechanisms over the full life cycle of both cars. The key finding indicates that althoughcarbon emissions are substantially reduced, switching is still not financially the best option for either theconsumer or the government in the long run.\nOriginal language\n""","1.0416589","""http://pure.qub.ac.uk/portal/en/publications/a-conventional-internal-combustion-engine-versus-a-range-extended-electric-vehicle-under-the-current-regulatory-regime-in-the-united-kingdom(03198126-2cdf-4adc-9de1-c6ca0ec29aa2).html""","[-5.934759,54.583863]"
"""Imperial_College_London""","""Technologies to measure indicators for road user charging | Proceedings of the Institution of Civil Engineers - Transport""","""Proceedings of the Institution of Civil Engineers - Transport\nProceedings of the Institution of Civil Engineers - Transport\nISSN 0965-092X | E-ISSN 1751-7710\nTechnologies to measure indicators for road user charging\nAuthors: \nMSc, PhD, FRIN, FInstCES, MICE, MIHT\nx\nEdward J. Bloustein School of Planning and Public Policy, Rutgers University, New Brunswick, NJ, USA\n, ,\nPublished Online: May 25, 2015\nKey:\nTrial content\nAbstract\nA technically and economically feasible road user charging scheme should be based on quantities that are readily and accurately measurable, as well as being directly variable with the amount of road use and its impact on the environment and society. A key requirement for a pricing scheme is that the charging regime used should be easy for motorists to understand, but at the same time flexible enough for the operator to implement a wide range of policies to meet different aims. A set of variable road user charging indicators is identified herein by considering both the associated costs of a trip and the operational requirements for a feasible road pricing scheme. The study then focused on identifying a set of currently feasible technologies to measure these variables in real-time with high accuracy. Particular attention was paid to the need accurately to track vehicle movements and link these movements to geographical areas and road types, and the key pollutants and particulate matter, all of which have different potential effects that are in some cases dependent on location and time of emissions. Other issues, such as congestion measurement, are also discussed.\nKeywords:\n""","0.49132305","""https://www.icevirtuallibrary.com/doi/10.1680/tran.2010.163.2.63""","[-0.178219,51.500505]"
"""Cardiff_University""","""Locational analysis: highlights of growth to maturity | SpringerLink""",""", Volume 60, Supplement 1 , pp S140–S148 | Cite as\nLocational analysis: highlights of growth to maturity\nAuthors\nH K Smith Email author\nG Laporte\n28 Citations\nAbstract\nLocational analysis has grown to maturity over the last decades, from its earliest roots, to fruitfulness in a wide-ranging number of strands that join with other disciplines and applications such as environmental planning and supply chain management. This paper charts the progress of location theory in three stages: a period of early contributions, when a number of seminal geometrical and geographical problems were studied; a ‘coming of age’ with the development of defining or classical problems that have proved fundamental to much later research and a third period of new models and new applications.\nKeywords\nlocation history of OR \nReferences\nAikens CH (1985). Facility location models for distribution planning. Eur J Opl Res 22: 263–279. CrossRef Google Scholar\nAlbareda-Sambola M, Fernández E and Laporte G (2007). Heuristic and lower bound for a stochastic location-routing problem. Eur J Opl Res 179: 940–955. CrossRef Google Scholar\nAndersson T and Värbrand P (2007). Decision support tools for ambulance dispatch and relocation. J Opl Res Soc 58: 195–201. CrossRef Google Scholar\nAykin T (1994). Lagrangian relaxation based approaches to capacitated hub-and-spoke network design problem. Eur J Opl Res 79: 501–523. CrossRef Google Scholar\nBalinski ML (1966). On Finding Integer Solutions to Linear Programs . Mathematica: Princeton, NJ. Google Scholar\nBalinski ML and Wolfe P (1963). On Benders decomposition and a plant location problem. Working paper ARO-27. Mathematica: Princeton, NJ.. Google Scholar\nBallou RH (1968). Dynamic warehouse location analysis. J of Market Res 5: 271–276. CrossRef Google Scholar\nBanerji SH and Fisher HB (1974). Hierarchical location analysis for integrated area planning in rural India. Pap Region Sci Assoc 33: 177–194. CrossRef Google Scholar\nBatta R and Chiu SS (1988). Optimal obnoxious paths on a network: Transportation of hazardous materials. Opns Res 36: 84–92. CrossRef Google Scholar\nBeasley JE (1993). Lagrangean heuristics for location problems. Eur J Opl Res 65: 383–399. CrossRef Google Scholar\nBerman O and Krass D (2002). Facility location problems with stochastic demands and congestion. In: Drezner Z. and Hamacher H. (eds). Facility Location: Applications and Theory. Springer-Verlag: Berlin, pp. 329–371. CrossRef Google Scholar\nBerman O and Wang Q (2008). Locating a semi-obnoxious facility with expropriation. Comput Opns Res 35: 392–403. CrossRef Google Scholar\nBerman O, Larson RC and Chiu SS (1985). Optimal server location on a network operating as a M/G/1 queue. Opns Res 33: 746–770. CrossRef Google Scholar\nBerman O, Hodgson MJ and Krass D (1995). Flow-interception problems. In: Drezner Z. (ed). Facility Location: A survey of Applications and Methods. Springer: New York, pp. 389–426. CrossRef Google Scholar\nBerman O, Drezner Z and Wesolowsky GO (2003). Locating service facilities whose reliability is distance dependent. Comput Opns Res 30: 1683–1695. CrossRef Google Scholar\nBoffey TB and Karkazis J (1993). Models and methods for location and routing decisions relating to hazardous materials. Stud Location Anal 5: 149–166. Google Scholar\nBoffey TB and Karkazis J (1995). Location, routing and the environment. In: Drezner Z. (ed). Facility Location: A Survey of Applications and Methods. Springer: New York, pp. 453–466. CrossRef Google Scholar\nBrandeau ML and Larson RC (1986). Extending and applying the hypercube model to deploy ambulances in Boston. In: Swersey A.J. and Ignall E.J. (eds). Delivery of Urban Service: With a View Towards Applications in Management Science and Operations Research. TIMS Studies in the Management Sciences Vol. 22. North-Holland: Amsterdam, pp. 121–153. Google Scholar\nBrotcorne L, Laporte G and Semet F (2003). Ambulance location and relocation models. Eur J Opl Res 147: 451–468. CrossRef Google Scholar\nBrimberg J, Juel H and Schöbel A (2007). Locating a circle on a sphere. Opns Res 55: 782–791. CrossRef Google Scholar\nBryan DL (1998). Extensions to the hub location problem: Formulations and numerical examples. Geogr Anal 30: 315–330. CrossRef Google Scholar\nCáceres T, Mesa JA and Ortega FA (2007). Locating waste pipelines to minimize their impact on marine environment. Eur J Opl Res 179: 1143–1159. CrossRef Google Scholar\nCampbell JF (1994). Integer programming of formulations of discrete hub location problems. Eur J Opl Res 72: 387–405. CrossRef Google Scholar\nCampbell JF, Ernst AT and Krishnamoorthy M (2002). Hub location problems. In: Drezner Z. and Hamacher H. (eds). Facility Location: Applications and Theory. Springer-Verlag: Berlin, pp. 373–407. CrossRef Google Scholar\nCampbell JF, Ernst AT and Krishnamoorthy M (2005a). Hub arc location problems: Part I—Introduction and results. Mngt Sci 51: 1540–1555. CrossRef Google Scholar\nCampbell JF, Ernst AT and Krishnamoorthy M (2005b). Hub arc location problems: Part II—Formulations and optimal algorithms. Mngt Sci 51: 1556–1571. CrossRef Google Scholar\nCarrizosa E, Conde E, Munoz-Marquez M and Puerto J (1995). The generalized Weber problem with expected distances. Rech Opér 29: 35–57. Google Scholar\nChan Y, Carter WB and Burnes MD (2001). A multiple-depot, multiple-vehicle, location-routing problem with stochastically processed demands. Comput Opns Res 28: 803–826. CrossRef Google Scholar\nChapman SC and White JA (1974). Probabilistic formulations of emergency service facilities location problems. Reprint series 7407, IEOR Dept., VPI&SV. Google Scholar\nChurch RL and Garfinkel RS (1978). Locating an obnoxious facility on a network. Transport Sci 12: 107–118. CrossRef Google Scholar\nChurch RL and ReVelle CS (1974). The maximal covering location problem. Pap Region Sci Assoc 32: 101–118. CrossRef Google Scholar\nChurch RL and Scaparra MP (2007). Protecting critical assets: The r-interdiction median problem with fortification. Geog Anal 39: 129–146. CrossRef Google Scholar\nChurch RL, Stoms DM and Davis FW (1996). Reserve selection as a maximal covering location problem. Biol Conserv 76: 105–112. CrossRef Google Scholar\nChurch RL, Murray AT and Weintraub A (1998). Locational issues in forest management. Locat Sci 6: 137–153. CrossRef Google Scholar\nChurch RL, Scaparra MP and Middleton R (2004). Identifying critical infrastructure: The median and covering facility interdiction problems. Ann Assoc Am Geogr 94: 491–502. CrossRef Google Scholar\nCooper L (1963). Location–allocation problems. Opns Res 11: 331–343. CrossRef Google Scholar\nCooper L (1964). Heuristic methods for location-allocation problems. SIAM Rev 6: 37–53. CrossRef Google Scholar\nDasci A and Laporte G (2005). A continuous model for multi-store competitive location. Opns Res 53: 263–280. CrossRef Google Scholar\nDaskin MS (1983). A maximum expected covering location model: Formulation, properties and heuristic solution. Transport Sci 17: 48–70. CrossRef Google Scholar\nDaskin MS (2008). What you should know about location modeling. Naval Res Logis 55: 283–294. CrossRef Google Scholar\nDaskin MS and Stern E (1981). A hierarchical objective set covering model for emergency medical service deployment. Transport Sci 25: 137–152. CrossRef Google Scholar\nDaskin MS, Coullard C and Shen Z-JM (2002). An inventory-location model: Formulation, solution algorithm and computational results. Ann Opns Res 110: 83–106. CrossRef Google Scholar\nDelaunay B (1934). Sur la sphère vide. Izvestia Akademii Nauk SSSR, Otdelenie Matematicheskikh i Estestvennykh Nauk 7: 793–800. Google Scholar\nDrezner Z, Klamroth K, Schöbel A and Wesolowsky GO (2002). The Weber problem. In: Drezner Z. and Hamacher H. (eds). Facility Location: Applications and Theory. Springer-Verlag: Berlin, pp. 1–36. CrossRef Google Scholar\nEaton DJ, Church RL, Bennett VL and Hamon BL (1981). On deployment of health resources in rural Valle del Cauca, Colombia. TIMS Stud Mngt Sci 17: 331–359. Google Scholar\nEaton DJ, Sánchez HML, Lantigua RR and Morgan J (1986). Determining ambulance deployment in Santo Domingo, Dominican Republic. J Opl Res Soc 37: 113–126. CrossRef Google Scholar\nEfroymson MA and Ray TL (1966). A branch-bound algorithm for plant location. Opns Res 14: 361–368. CrossRef Google Scholar\nEiselt HA (2007). Locating landfills—Optimization vs. reality. Eur J Opl Res 179: 1040–1049. CrossRef Google Scholar\nEiselt HA and Laporte G (1996). Sequential location problems. Eur J Opl Res 96: 217–231. CrossRef Google Scholar\nEiselt HA, Laporte G and Thisse J-F (1993). Competitive location models: A framework and bibliography. Transport Sci 27: 44–54. CrossRef Google Scholar\nElshafei AN (1977). Hospital layout as a quadratic assignment problem. Opl Res Quart 28: 167–179. CrossRef Google Scholar\nErkut E and Verter V (1995). Hazardous materials logistics. In: Drezner Z. (ed). Facility Location: A Survey of Applications and Methods. Springer: New York, pp. 467–506. CrossRef Google Scholar\nErlenkotter D (1978). A dual-based procedure for uncapacitated facility location. Opns Res 26: 992–1009. CrossRef Google Scholar\nErnst AT and Krishnamoorthy M (1996). An exact solution approach based on shortest-paths for p-hub median problems. INFORMS J Comput 10: 149–162. CrossRef Google Scholar\nErnst AT and Krishnamoorthy M (1998). Exact and heuristic algorithms for the uncapacitated multiple allocation p-hub median problem. Eur J Opl Res 104: 100–112. CrossRef Google Scholar\nFleischmann M, Bloemhof-Ruwaard JM, Dekker R, van der Laan E, van Nunen JAEE and Van Wassenhove LN (1997). Quantitative models for reverse logistics: A review. Eur J Opl Res 103: 1–17. CrossRef Google Scholar\nGeoffrion AM and Powers RF (1995). Twenty years of strategic distribution system design: An evolutionary perspective. Interfaces 25(5): 105–127. CrossRef Google Scholar\nGendreau M, Laporte G and Parent I (2000). Heuristics for the location of inspection stations on a network. Naval Res Logis 47: 287–303. CrossRef Google Scholar\nGoldman AJ (1969). Optimal locations for centers in a network. Transport Sci 3: 352–360. CrossRef Google Scholar\nGoldman AJ and Dearing PM (1975). Concepts of optimal location for partially noxious facilities. ORSA Bull 23(1): B-31. Google Scholar\nGottinger HW (1988). A computational model for solid waste management with application. Eur J Opl Res 35: 350–364. CrossRef Google Scholar\nHakimi SL (1964). Optimum locations of switching centers and the absolute centers and medians of a graph. Opns Res 12: 445–450. CrossRef Google Scholar\nHakimi SL (1965). Optimum distribution of switching centers in a communication network and some related graph theoretic problems. Opns Res 13: 462–475. CrossRef Google Scholar\nHakimi SL (1983). On locating new facilities in a competitive environment. Eur J Opl Res 12: 29–55. CrossRef Google Scholar\nHarper PR, Shahani AK, Gallagher J and Bowie C (2005). Planning health services with explicit geographical considerations: A stochastic location–allocation approach. Omega 33: 141–152. CrossRef Google Scholar\nHinojosa Y, Kalcsics J, Nickel S, Puerto J and Velten S (2008). Dynamic supply chain design with inventory. Comput Opns Res 35: 373–391. CrossRef Google Scholar\nHodgson MJ (1981). The location of public facilities intermediate to the journey to work. Eur J Opl Res 6: 199–204. CrossRef Google Scholar\nHodgson MJ (1988). An hierarchical location-allocation model for primary health care delivery in a developing area. Soc Sci Med 26: 153–161. CrossRef Google Scholar\nHotelling H (1929). Stability in competition. Econ J 39: 41–57. CrossRef Google Scholar\nIsard W (1969). General Theory: Social, Political, Economic, and Regional, with Particular Reference to Decision-making Analysis . MIT Press: Cambridge, MA. Google Scholar\nKlincewicz JG and Luss H (1987). A dual-based algorithm for multiproduct uncapacitated facility location. Transport Sci 21: 198–206. CrossRef Google Scholar\nKariv O and Hakimi SL (1979a). An algorithmic approach to network location problems. Part I: The P-centers. SIAM J Appl Math 37: 515–538. Google Scholar\nKariv O and Hakimi SL (1979b). An algorithmic approach to network location problems. Part II: The P-median. SIAM J Appl Math 37: 539–560. CrossRef Google Scholar\nKoopmans TC and Beckmann MJ (1957). Assignment problems and the location of economic activities. Econometrica 25: 52–76. CrossRef Google Scholar\nKrarup J and Pruzan PM (1983). The simple plant location problem: Survey and synthesis. Eur J Opl Res 12: 36–81. CrossRef Google Scholar\nKuehn AA and Hamburger MJ (1963). A heuristic program for locating warehouses. Mngt Sci 9: 643–666. CrossRef Google Scholar\nKuhn HW (1967). On a pair of dual nonlinear programs. In: Abadie J. (ed). Nonlinear Programming. North-Holland: Amsterdam, pp. 37–54. Google Scholar\nLabbé M, Laporte G and Rodríguez-Martín I (1998). Path, Tree and Cycle Location. In: Crainic T.G. and Laporte G. (eds). Fleet Management and Logistics. Kluwer: Boston, pp. 187–204. CrossRef Google Scholar\nLaporte G (1988). Location-Routing problems. In: Golden B.L. and Assad A.A. (eds). Vehicle Routing: Methods and Studies. North-Holland: Amsterdam, pp. 163–198. Google Scholar\nLaporte G and Rodríguez-Martín I (2007). Locating a cycle in a transportation or a telecommunications network. Networks 50: 92–108. CrossRef Google Scholar\nLaporte G, Mesa JA and Ortega FA (2000). Optimization methods for the planning of rapid transit systems. Eur J Opl Res 122: 1–10. CrossRef Google Scholar\nLaporte G, Nobert Y and Arpin D (1986). An exact algorithm for solving a capacitated location-routing problem. Ann Opns Res 6: 293–310. CrossRef Google Scholar\nLarson RC (1974). A hypercube queuing model for facility location and redistricting in urban emergency services. Comput Ops Res 1: 67–95. CrossRef Google Scholar\nLawler EL (1963). The quadratic assignment problem. Mngt Sci 9: 586–599. CrossRef Google Scholar\nLogendran R and Terrell MP (1988). Uncapacitated plant location–allocation problems with price sensitive stochastic demands. Comput Opns Res 15: 189–198. CrossRef Google Scholar\nLoiola EM, Maia de Abreu NM, Boaventura-Netto PO, Hahn P and Querido T (2007). A survey for the quadratic assignment problem. Eur J Opl Res 176: 657–690. CrossRef Google Scholar\nLouveaux FV (1993). Stochastic location analysis. Locat Sci 1: 127–154. Google Scholar\nMaranzana FE (1964). On the location of supply points to minimize transport costs. Opl Res Quart 15: 261–270. CrossRef Google Scholar\nMarianov V and ReVelle CS (1995). Siting emergency services. In: Drezner Z. (ed). Facility Location: A Survey of Applications and Methods. Springer: New York, pp. 199–223. CrossRef Google Scholar\nMarianov V and Serra D (1998). Probabilistic, maximal covering location–allocation models for congested systems. J Region Sci 38: 401–424. CrossRef Google Scholar\nMarianov V and Serra D (2001). Hierarchical location–allocation models for congested systems. Eur J Opl Res 135: 195–208. CrossRef Google Scholar\nMarianov V, ReVelle CS and Snyder S (2008). Selecting compact habitat reserves for species with differential habitat size needs. Comput Opns Res 35: 475–487. CrossRef Google Scholar\nMarín A and Pelegrin B (1998). The return plant location problem: Modelling and resolution. Eur J Opl Res 104: 375–392. CrossRef Google Scholar\nMelo MT, Nickel S and Saldanha da Gama F (2005). Dynamic multi-commodity capacitated facility location: A mathematical modeling framework for strategic supply chain planning. Comput Opns Res 33: 181–208. CrossRef Google Scholar\nMelo MT, Nickel S and Saldanha da Gama F (2009). Facility location and supply chain management–A review. Eur J Opl Res 196: 401–412. Google Scholar\nMesa JA and Boffey TB (1998). A review of extensive facility location in networks. Eur J Opl Res 95: 592–603. CrossRef Google Scholar\nMiranda G, Luna HPL, Mateus GR and Ferreira RPM (2005). A performance guarantee heuristic for electronic components placement problems including thermal effects. Comput Ops Res 32: 2937–2957. CrossRef Google Scholar\nMirchandani PB and Odoni AR (1979). Location of medians on stochastic networks. Transport Sci 13: 85–97. CrossRef Google Scholar\nNagy G and Salhi S (2007). Location-routing: Issues, models and methods. Eur J Opl Res 177: 649–672. CrossRef Google Scholar\nO'Kelly ME (1986a). The location of interacting hub facilities. Transport Sci 20: 92–106. CrossRef Google Scholar\nO'Kelly ME (1986b). Activity levels at hub facilities in interacting networks. Geogr Anal 18: 343–353. CrossRef Google Scholar\nO'Kelly ME (1987). A quadratic integer program for the location of interacting hub facilities. Eur J Opl Res 32: 393–404. CrossRef Google Scholar\nO'Kelly ME (1998). On the allocation of a subset of nodes to a mini-hub in a package delivery network. Papers in Regional Science. J RSAI 77: 77–99. Google Scholar\nÖnal H and Wang Y (2007). A graph theory approach for designing conservation reserve networks with minimal fragmentation. Networks 51: 142–152. CrossRef Google Scholar\nRahman S and Smith DK (2000). Use of location–allocation models in health service development planning in developing nations. Eur J Opl Res 123: 437–452. CrossRef Google Scholar\nRepede JF and Bernardo JJ (1994). Developing and validating a decision support system for locating emergency medical vehicles in Louisville, Kentucky. Eur J Opl Res 75: 567–581. CrossRef Google Scholar\nReVelle CS and Eiselt HA (2005). Location analysis: A synthesis and survey. Eur J Opl Res 165: 1–19. CrossRef Google Scholar\nReVelle CS and Swain R (1970). Central facilities location. Geogr Anal 2: 30–42. CrossRef Google Scholar\nReVelle CS and Williams JC (2002). Reserve design and facility siting. In: Drezner Z. and Hamacher H. (eds). Facility Location: Applications and Theory. Springer-Verlag: Berlin, pp. 307–328. CrossRef Google Scholar\nReVelle CS, Eiselt HA and Daskin MS (2008). A bibliography for some fundamental problem categories in discrete location science. Eur J Opl Res 184: 817–848. CrossRef Google Scholar\nRosing KE and Hodgson MJ (1996). A systematic classification of applications of location-allocation models. Belgian J Opns Res, Stat Comput Sci 36: 77–108. Google Scholar\nSalema MIG, Barbosa-Povoa AP and Novais AQ (2007). An optimization model for the design of a capacitated multi-product reverse logistics network with uncertainty. Eur J Opl Res 179: 1063–1077. CrossRef Google Scholar\nSlater PJ (1975). Maximum facility location. J Res NBS B Math Sci 79: 107–115. Google Scholar\nSlater PJ (1982). Locating central paths in a graph. Transport Sci 16: 1–18. CrossRef Google Scholar\nSmith HK, Harper PR, Potts CN and Thyle A (2009). Planning sustainable community health schemes in rural areas of developing countries. Eur J Opl Res 193: 768–777. CrossRef Google Scholar\nSnyder LV (2006). Facility location under uncertainty: A review. IIE Trans 38: 547–564. CrossRef Google Scholar\nSrivastava SK (2008). Network design for reverse logistics. Omega 36: 535–548. CrossRef Google Scholar\nSuzuki A and Okabe A (1995). Using Voronoi diagrams. In: Drezner Z. (ed). Facility Location: A Survey of Applications and Methods. Springer: New York, pp. 103–118. CrossRef Google Scholar\nTalluri S and Baker RC (2002). A multi-phase mathematical programming approach for effective supply chain design. Eur J Opl Res 141: 544–558. CrossRef Google Scholar\nTansel BC, Francis RL and Lowe TJ (1983a). Location on networks: A survey, Parts I and II. Mngt Sci 29: 482–497. CrossRef Google Scholar\nTansel BC, Francis RL and Lowe TJ (1983b). Location on networks: A survey, Parts I and II. Mngt Sci 29: 498–511. CrossRef Google Scholar\nTeitz MB and Bart P (1968). Heuristic methods for estimating the generalized vertex median of a weighted graph. Opns Res 16: 955–961. CrossRef Google Scholar\nToregas C, Swain R, ReVelle C and Bergman L (1971). The location of emergency service facilities. Opns Res 19: 1363–1373. CrossRef Google Scholar\nUnderhill LG (1994). Optimal and suboptimal reserve selection algorithms. Biol Conserv 70: 85–87. CrossRef Google Scholar\nVerter V and Dasci A (2002). The plant location and flexible technology acquisition problem. Eur J Opl Res 136: 366–382. CrossRef Google Scholar\nVerter V and Dincer MC (1995). Global manufacturing strategy. In: Drezner Z. (ed). Facility Location: A Survey of Applications and Methods. Springer-Verlag: New York, pp. 263–282. CrossRef Google Scholar\nVan Roy T and Erlenkotter D (1982). A dual-based procedure for dynamic facility location. Mngt Sci 28: 1091–1195. CrossRef Google Scholar\nVidal CJ and Goetschalckx M (1997). Strategic production-distribution models: A critical review with emphasis on global supply chain models. Eur J Opl Res 98: 1–18. CrossRef Google Scholar\nVoronoi G (1907). Nouvelles applications des paramètres continus à la théorie des formes quadratiques. J Reine Angew Math 133: 97–178. Google Scholar\nWang Q, Batta R and Rump CM (2003). Facility location models for immobile servers with stochastic demand. Naval Res Logis 51: 137–152. CrossRef Google Scholar\nWarszawski A (1973). Multidimensional location problems. Opl Res Quart 24: 165–179. CrossRef Google Scholar\nWasner M and Zäpfel G (2004). An integrated multi-depot hub-location vehicle routing model for network planning of parcel service. Int J Prod Econ 90: 403–419. CrossRef Google Scholar\nWatson-Gandy CDT and Dohrn PJ (1973). Depot location with van salesmen—A practical approach. Omega 1: 321–329. CrossRef Google Scholar\nWebb MHJ (1968). Cost functions in the location of depots for multi-delivery journeys. Opl Res Quart 19: 311–320. CrossRef Google Scholar\nWeber A (1909). Über den Standort der Industrien . Mohr: Tübingen, Germany. Google Scholar\nWeiszfeld E (1937). Sur le point pour lequel la somme des distances de n points donnés est minimum. Tôhoko Math J 43: 355–386. Google Scholar\nWilliams AC (1963). A stochastic transportation problem. Opns Res 11: 759–770. CrossRef Google Scholar\nWilliams JC (2008). Optimal reserve site selection with distance requirements. Comput Opns Res 35: 475–487. CrossRef Google Scholar\nYasenovskiy VS and Hodgson MJ (2007). Hierarchical location–allocation with spatial choice interaction modeling. Ann Assoc Am Geogr 97: 496–511. CrossRef Google Scholar\nYi W and Özdamar L (2007). A dynamic logistics coordination model for evacuation and support in disaster response activities. Eur J Opl Res 179: 1177–1193. CrossRef Google Scholar\nZhou J and Liu B (2003). New stochastic models for capacitated location–allocation problem. Comput Indust Eng 45: 111–125. CrossRef Google Scholar\nCopyright information\nSmith, H., Laporte, G. & Harper, P. J Oper Res Soc (2009) 60(Suppl 1): S140. https://doi.org/10.1057/jors.2008.172\nDOI https://doi.org/10.1057/jors.2008.172\nPublisher Name Palgrave Macmillan UK\nPrint ISSN 0160-5682\n""","0.23298302","""https://link.springer.com/article/10.1057%2Fjors.2008.172""","[-3.178864,51.486627]"
"""Imperial_College_London""","""Environmental Health Perspectives – Traffic-Related Air Pollution, Oxidative Stress Genes, and Asthma (ECHRS)""","""Research December 2009 | Volume 117 | Issue 12\nEnviron Health Perspect; DOI:Environ Health Perspect; DOI:10.1289/ehp.0900589\nTraffic-Related Air Pollution, Oxidative Stress Genes, and Asthma (ECHRS)\nFrancesc Castro-Giner,1,2,3 Nino Künzli,1,2,3,4 Bénédicte Jacquemin,1,5 Bertil Forsberg,6 Rafael de Cid,3,7 Jordi Sunyer,1,2,3,8 Deborah Jarvis,9 David Briggs,10 Danielle Vienneau,10 Dan Norback,11 Juan R. González,1,2,3 Stefano Guerra,1,2,3 Christer Janson,12 Josep-Maria Antó,1,2,3,8 Matthias Wjst,13 Joachim Heinrich,14 Xavier Estivill,3,7,8 Manolis Kogevinas1,2,3,15\nAuthor Affiliations open\n1Centre for Research in Environmental Epidemiology, Barcelona, Spain; 2Municipal Institute of Medical Research, Hospital del Mar, Barcelona, Spain; 3CIBER Epidemiología y Salud Pública, Barcelona, Spain; 4Institució Catalana de Recerca i Estudis Avançats (ICREA), Barcelona, Spain; 5Institut national de la santé et de la recherche médicale, U780, Epidemiology and Biostatistics, Villejuif, France; 6Occupational and Environmental Medicine, Department of Public Health and Clinical Medicine, Umeå University, Umeå, Sweden; 7Genes and Disease Program, Center for Genomic Regulation, Barcelona, Spain; 8Department of Health and Experimental Sciences, University Pompeu Fabra, Barcelona, Spain; 9Respiratory Epidemiology and Public Health Group, National Heart and Lung Institute, and; 10Epidemiology and Public Health, Imperial College, London, United Kingdom; 11Department of Medical Sciences, Uppsala University and University Hospital, Uppsala, Sweden; 12Department of Medical Sciences, Respiratory Medicine and Allergology, Uppsala University, Uppsala, Sweden; 13Helmholtz Zentrum München, German Research Centre for Environmental Health, Munich, Germany; 14Institute of Epidemiology, Helmholtz Zentrum München, Munich, Germany; 15National School of Public Health, Athens, Greece\nSimilar to other studies, we used NO2 level as a marker of traffic-related air pollution ( Emenius et al. 2003 ; Forastiere et al. 2006 ; Jacquemin et al. 2009 ; Melén et al. 2008 ; Modig et al. 2006 ; Morgenstern et al. 2008 ). Thus, the observed associations and interactions may be mediated by other ambient air pollutants, which are highly spatially correlated with NO2. However, NO2 is a strong oxidant per se, with a range of well-known adverse effects ( Forastiere et al. 2006 ; Janssen-Heininger et al. 2002 ), and NO2 either alone or combined with other pollutants may contribute to the observed effects ( Forastiere et al. 2006 ).\nIn our study, we found a nonsignificant reduction of the NO2 effects among carriers of at least one NQO1 Ser187 allele. The polymorphism that was associated with the most significant p-value in our study (rs2917666) is not known to be functional but is located in the 5´ upstream region of the gene. This region contains elements essential for the expression and induction of NQO1, such as the antioxidant response element that is required for NQO1 transcription in response to oxidative stress ( Jaiswal 2000 ; Nioi and Hayes 2004 ). The three SNPs in the NQO1 gene were in relatively weak linkage disequilibrium with the highest r2 (0.53) found for the functional Pro187Ser (rs1800566) and rs2917666. Furthermore, the association between asthma and modeled NO2 was significant for the most prevalent haplotype that contained the C allele of the rs2917666, which showed a significant interaction with NO2 in the single SNP analysis. A few studies have evaluated the role of NQO1 in relation to exposure to O3 [reviewed by Yang et al. (2008) ] and have shown that the Pro187Ser (rs1800566) polymorphism was protective in response to O3 when GSTM1 was present ( Bergamaschi et al. 2001 ; Corradi et al. 2002 ; David et al. 2003 ). Susceptibility variants on oxidative stress genes GSTM1 and GSTP1 have been associated with an increased effect of air pollution and specific pollutants ( Gilliland et al. 2004 ; Lee et al. 2004 ; Li et al. 2006 ; Melén et al. 2008 ; Romieu et al. 2004 , 2006 ). In this study, we did not observe significant associations of GSTM1 or GSTP1 polymorphisms with asthma either alone or in combination with NQO1 SNPs. Lack of consistence with previous analyses could be related to the heterogeneity of effects in adults compared with children ( Salam et al. 2008 ).\nOur findings on NQO1 reinforce the role of antioxidant system in response to air pollution ( Kelly 2003 ; Romieu et al. 2008 ). An in vitro approach proposed a hierarchical model to explain the dose-dependent response to oxidant chemicals in DEP ( Xiao et al. 2003 ) that will probably extend to gaseous pollutants like NO2 ( Saxon and Diaz-Sanchez 2005 ). With low exposure, the formation of ROS activates the transcription of genes involved in antioxidant responses, such as phase II enzymes (e.g., NQO1 and GST genes). Higher exposure activates the transcription of nuclear factor-κB and activator protein-1, resulting in increased expression of proinflammatory cytokines (e.g., TNF-α), leading to additional generation of ROS ( Romieu et al. 2008 ; Saxon and Diaz-Sanchez 2005 ).\nThe ECRHS is a large population-based international cohort that overcomes limitations of studies done in selected populations. The main limitations of this analysis include limited statistical power to detect interactions, some exposure misclassification, and heterogeneity and potential confounding concerning environmental exposures and genetic variation.\nStatistical power to detect interactions was relatively low ( Garcia-Closas et al. 1999 ). False-positive results have been shown to be frequent in studies on genetic variation and gene–environment interactions ( Clayton and McKeigue 2001 ), and for these reason these results should be interpreted with caution. In this study we did not perform correction for multiple comparisons. However, traditional methods based on Bonferroni are overconservative because polymorphisms within a gene are not completely independent due to linkage disequilibrium. In addition, this correction may be acceptable when searching for significant associations without preestablished hypotheses, but we selected genes in this analysis on the basis of strong prior evidence.\nStrengths and limitations of the NO2 exposure assessment have been discussed previously ( Jacquemin et al. 2009 ). The individual assignment of exposure to NO2 should result in a reduction of exposure misclassification. We evaluated NO2 exposure by geocoding home addresses of ECRHS participants and assigned ambient modeled NO2 concentration derived from the APMoSPHERE map to each subject. The year of modeled NO2 (2001) was concordant with the years of the administration of the ECRHS II questionnaire (1999–2002). However, the spatial scale of the APMoSPHERE model was relatively broad (1 × 1 km), and the model did not include monitors placed close to traffic. Thus, spatial and temporal contrasts in exposure due to very local emissions and dispersion patterns, such as those occurring in street canyons are unlikely to be captured. NO2 does also capture part of that space but as a secondary gas is certainly more homogeneously distributed than, for example, ultrafine tail pipe particles. The misclassification is random in nature so, if anything, some bias toward the null may be expected. If those local peak concentrations were particularly relevant sources of exposure to oxidants, the APMoSPHERE-based results would likely underestimate true effects and interactions.\nBecause of the lack of repeated measurements during follow-up, exposure was assigned only to residences in ECRHS II. Although levels of air pollution did not remain constant during the follow-up period, the ranking in the spatial distribution of traffic-related pollutants is likely to remain similar. Exposure misclassification is thus particularly large among those who moved after ECRHS I, possibly explaining the smaller effects observed among movers ( Beelen et al. 2008 ; Gotschi et al. 2008a ).\nLevels of air pollution and prevalence of asthma varied substantially across centers in ECRHS, showing a south–north gradient ( Gotschi et al. 2008b ; Jacquemin et al. 2009 ; Sunyer et al. 2004 ). Median levels of modeled NO2 varied from 12 µg/m3 in Umeå to more than 50 µg/m3 in Barcelona and Paris ( Jacquemin et al. 2009 ). Variables correlated with center, such as pollution composition, climatic factors, and diet, determine the individual response to air pollution ( D’Amato et al. 2005 ). All results were adjusted by center, and random-effects meta-analysis suggested that NO2 estimates and interactions with the genes were not center specific, although we acknowledge the limited power to detect this heterogeneity. In addition, recent analyses of population stratification among Europeans found correspondence between genetic variation and geographic distances, although levels of genetic diversity were low ( Heath et al. 2008 ). Previous analyses in the ECRHS have shown little evidence of population stratification ( Castro-Giner et al. 2008 ). However, this was based on an insufficient set of markers.\nAn important source of NO2 exposure in the general population originates from the use of gas cookers ( D’Amato et al. 2005 ). Several studies reported the association of indoor exposures with NO2 outcomes and respiratory or allergic outcomes ( Bernstein et al. 2008 ). In our data, outdoor NO2 was not correlated with gas cooking, and adjustment for cooking with gas did not affect the observed effects of outdoor NO2 and its interaction with the NQO1 polymorphism.\nDifferences were observed by sex, with females showing an increase in risk. However, the sample sizes of specific strata are smaller than the total population, and interpretation of these results should be done with caution. Our findings, if corroborated by others, may have significant public health implications because we identified a large group of susceptible subjects defined by the genetic makeup for whom the effect of modeled NO2-related air pollution on asthma was substantial. The affected subgroup was large, with a 46% prevalence of the C/C genotype for NQO1 rs2917666. Moreover, the number of people exposed to traffic-related pollution on a regular basis is large and as a consequence the burden of asthma related to ambient air pollution may be large not only in children, as previously documented, but also in adults.\nConclusions\nFindings from this study suggest that genetic polymorphisms in the NQO1 gene are associated with susceptibility to asthma in adults among those exposed to traffic-related air pollution. This result points to the importance of antioxidant pathways in the effects of air pollution on asthma.\nReferences\nAPMoSPHERE. 2007. APMoSPHERE: Air Pollution Modelling for Support to Policy on Health and Environmental Risk in Europe. Available: http://www.apmosphere.org [accessed 27 April 2009].\nBeelen R, Hoek G, van den Brandt PA, Goldbohm RA, Fischer P, Schouten LJ, et al. 2008. Long-term effects of traffic-related air pollution on mortality in a Dutch cohort (NLCS-AIR study). Environ Health Perspect 116:196–202.\nBergamaschi E, De Palma G, Mozzoni P, Vanni S, Vettori MV, Broeckaert F, et al. 2001. Polymorphism of quinone-metabolizing enzymes and susceptibility to ozone-induced acute effects. Am J Respir Crit Care Med 163:1426–1431.\nBernstein JA, Alexis N, Bacchus H, Bernstein IL, Fritz P, Horner E, et al. 2008. The health effects of non-industrial indoor air pollution. J Allergy Clin Immunol 121:585–591.\nBrauer M, Hoek G, Smit HA, de Jongste JC, Gerritsen J, Postma DS, et al. 2007. Air pollution and development of asthma, allergy and infections in a birth cohort. Eur Respir J 29:879–888.\nBurney PG, Luczynska C, Chinn S, Jarvis D. 1994. The European Community Respiratory Health Survey. Eur Respir J 7:954–960.\nCastro-Giner F, Kauffmann F, de Cid R, Kogevinas M. 2006. Gene-environment interactions in asthma. Occup Environ Med 63:776–786.\nCastro-Giner F, Kogevinas M, Machler M, de Cid R, Van Steen K, Imboden M, et al. 2008. TNFA –308G > A in two international population-based cohorts and risk of asthma. Eur Respir J 32:350–361.\nCentro Nacional de Genotipado. 2009. ¿Qué es el CeGen?. Available: http://www.cegen.org [accessed 27 April 2009].\nChinn S, Burney P, Jarvis D, Luczynska C. 1997. Variation in bronchial responsiveness in the European Community Respiratory Health Survey (ECRHS). Eur Respir J 10:2495–2501.\nClayton D, McKeigue PM. 2001. Epidemiological methods for studying genes and environmental factors in complex diseases. Lancet 358:1356–1360.\nCorradi M, Alinovi R, Goldoni M, Vettori M, Folesani G, Mozzoni P, et al. 2002. Biomarkers of oxidative stress after controlled human exposure to ozone. Toxicol Lett 134:219–225.\nD’Amato G, Liccardi G, D’Amato M, Holgate S. 2005. Environmental risk factors and allergic bronchial asthma. Clin Exp Allergy 35:1113–1124.\nDavid GL, Romieu I, Sienra-Monge JJ, Collins WJ, Ramirez-Aguilar M, Rio-Navarro BE, et al. 2003. Nicotinamide adenine dinucleotide (phosphate) reduced:quinone oxidoreductase and glutathione S-transferase M1 polymorphisms and childhood asthma. Am J Respir Crit Care Med 168:1199–1204.\nDevlin B, Roeder K. 1999. Genomic control for association studies. Biometrics 55:997–1004.\nECRHS II Steering Committee. 2002. The European Community Respiratory Health Survey II. Eur Respir J 20:1071–1079.\nEmenius G, Pershagen G, Berglind N, Kwon HJ, Lewne M, Nordvall SL, et al. 2003. NO2, as a marker of air pollution, and recurrent wheezing in children: a nested case-control study within the BAMSE birth cohort. Occup Environ Med 60:876–881.\nEntrez Gene. 2008. Homepage. Available: http://www.ncbi.nlm.nih.gov/gene [accessed 27 November 2008].\nForastiere F, Peters A, Kelly FJ, Holgate ST. 2006. Nitrogen dioxide. In: WHO Air Quality Guidelines: Global Updates 2005. Copenhagen, Denmark:World Health Organization, 331–394.\nGarcia-Closas M, Rothman N, Lubin J. 1999. Misclassification in case-control studies of gene-environment interactions: assessment of bias and sample size. Cancer Epidemiol Biomarkers Prev 8:1043–1050.\nGehring U, Cyrys J, Sedlmeir G, Brunekreef B, Bellander T, Fischer P, et al. 2002. Traffic-related air pollution and respiratory health during the first 2 yrs of life. Eur Respir J 19:690–698.\nGilliland FD, Li YF, Gong H Jr, Diaz-Sanchez D. 2006. Glutathione S-transferases M1 and P1 prevent aggravation of allergic responses by secondhand smoke. Am J Respir Crit Care Med 174:1335–1341.\nGilliland FD, Li YF, Saxon A, Diaz-Sanchez D. 2004. Effect of glutathione-S-transferase M1 and P1 genotypes on xenobiotic enhancement of allergic responses: randomised, placebo-controlled crossover study. Lancet 363:119–125.\nGonzalez JR, Armengol L, Sole X, Guino E, Mercader JM, Estivill X, et al. 2007. SNPassoc: an R package to perform whole genome association studies. Bioinformatics 23:644–645.\nGotschi T, Heinrich J, Sunyer J, Künzli N. 2008. Long-term effects of ambient air pollution on lung function: a review. Epidemiology 19:690–701.\nGotschi T, Sunyer J, Chinn S, de Marco R, Forsberg B, Gauderman JW, et al. 2008. Air pollution and lung function in the European Community Respiratory Health Survey. Int J Epidemiol 37(6):1349–1358.\nHeath SC, Gut IG, Brennan P, McKay JD, Bencko V, Fabianova E, et al. 2008. Investigation of the fine structure of European populations with applications to disease association studies. Eur J Hum Genet 16:1413–1429.\nHeinrich J, Wichmann HE. 2004. Traffic related pollutants in Europe and their effect on allergic disease. Curr Opin Allergy Clin Immunol 4:341–348.\nJacquemin B, Sunyer J, Forsberg B, Aguilera I, Briggs D, García-Esteban R, et al. 2009. Home outdoor NO2 and new onset of self-reported asthma in adults. Epidemiology 20(1):119–126.\nJaiswal AK. 2000. Regulation of genes encoding NAD(P)H:quinone oxidoreductases. Free Radic Biol Med 29:254–262.\nJanssen-Heininger YM, Persinger RL, Korn SH, Pantano C, McElhinney B, Reynaert NL, et al. 2002. Reactive nitrogen species and cell signaling: implications for death or survival of lung epithelium. Am J Respir Crit Care Med 166:S9–S16.\nJoos L, Weir TD, Connett JE, Anthonisen NR, Woods R, Pare PD, et al. 2003. Polymorphisms in the beta2 adrenergic receptor and bronchodilator response, bronchial hyperresponsiveness, and rate of decline in lung function in smokers. Thorax 58:703–707.\nKelly FJ. 2003. Oxidative stress: its role in air pollution and adverse health effects. Occup Environ Med 60:612–616.\nKleeberger SR, Reddy SP, Zhang LY, Cho HY, Jedlicka AE. 2001. Toll-like receptor 4 mediates ozone-induced murine lung hyperpermeability via inducible nitric oxide synthase. Am J Physiol Lung Cell Mol Physiol 280:L326–L333.\nKleeberger SR, Reddy S, Zhang LY, Jedlicka AE. 2000. Genetic susceptibility to ozone-induced lung hyperpermeability: role of toll-like receptor 4. Am J Respir Cell Mol Biol 22:620–627.\nKünzli N, Kaiser R, Medina S, Studnicka M, Chanel O, Filliger P, et al. 2000. Public-health impact of outdoor and traffic-related air pollution: a European assessment. Lancet 356:795–801.\nLee YL, Lin YC, Lee YC, Wang JY, Hsiue TR, Guo YL. 2004. Glutathione S-transferase P1 gene polymorphism and air pollution as interactive risk factors for childhood asthma. Clin Exp Allergy 34:1707–1713.\nLi YF, Gauderman WJ, Avol E, Dubeau L, Gilliland FD. 2006. Associations of tumor necrosis factor G-308A with childhood asthma and wheezing. Am J Respir Crit Care Med 173:970–976.\nLitonjua AA, Silverman EK, Tantisira KG, Sparrow D, Sylvia JS, Weiss ST. 2004. Beta 2-adrenergic receptor polymorphisms and haplotypes are associated with airways hyperresponsiveness among nonsmoking men. Chest 126:66–74.\nLondon SJ. 2007. Gene-air pollution interactions in asthma. Proc Am Thorac Soc 4:217–220.\nMcConnell R, Berhane K, Yao L, Jerrett M, Lurmann F, Gilliland F, et al. 2006. Traffic, susceptibility, and childhood asthma. Environ Health Perspect 114:766–772.\nMelén E, Nyberg F, Lindgren CM, Berglind N, Zucchelli M, Nordling E, et al. 2008. Interactions between glutathione S-transferase P1, tumor necrosis factor, and traffic-related air pollution for development of childhood allergic disease. Environ Health Perspect 116:1077–1084.\nModig L, Jarvholm B, Ronnmark E, Nystrom L, Lundback B, Andersson C, et al. 2006. Vehicle exhaust exposure in an incident case-control study of adult asthma. Eur Respir J 28:75–81.\nMorgenstern V, Zutavern A, Cyrys J, Brockow I, Koletzko S, Kramer U, et al. 2008. Atopic diseases, allergic sensitization, and exposure to traffic-related air pollution in children. Am J Respir Crit Care Med 177:1331–1337.\nNel A. 2005. Atmosphere. Air pollution-related illness: effects of particles. Science 308:804–806.\nNioi P, Hayes JD. 2004. Contribution of NAD(P)H:quinone oxidoreductase 1 to protection against carcinogenesis, and regulation of its gene by the Nrf2 basic-region leucine zipper and the arylhydrocarbon receptor basic helix-loop-helix transcription factors. Mutat Res 555:149–171.\nPrice AL, Patterson NJ, Plenge RM, Weinblatt ME, Shadick NA, Reich D. 2006. Principal components analysis corrects for stratification in genome-wide association studies. Nat Genet 38:904–909.\nRomieu I, Castro-Giner F, Künzli N, Sunyer J. 2008. Air pollution, oxidative stress and dietary supplementation: a review. Eur Respir J 31:179–197.\nRomieu I, Ramirez-Aguilar M, Sienra-Monge JJ, Moreno-Macias H, Rio-Navarro BE, David G, et al. 2006. GSTM1 and GSTP1 and respiratory health in asthmatic children exposed to ozone. Eur Respir J 28:953–959.\nRomieu I, Sienra-Monge JJ, Ramirez-Aguilar M, Moreno-Macias H, Reyes-Ruiz NI, Estela del Río-Navarro B, et al. 2004. Genetic polymorphism of GSTM1 and antioxidant supplementation influence lung function in relation to ozone exposure in asthmatic children in Mexico City. Thorax 59:8–10.\nSalam MT, Islam T, Gilliland FD. 2008. Recent evidence for adverse effects of residential proximity to traffic sources on asthma. Curr Opin Pulm Med 14:3–8.\nSaxon A, Diaz-Sanchez D. 2005. Air pollution and allergy: you are what you breathe. Nat Immunol 6:223–226.\nSchaid DJ, Rowland CM, Tines DE, Jacobson RM, Poland GA. 2002. Score tests for association between traits and haplotypes when linkage phase is ambiguous. Am J Hum Genet 70:425–434.\nSunyer J, Jarvis D, Pekkanen J, Chinn S, Janson C, Leynaert B, et al. 2004. Geographic variations in the effect of atopy on asthma in the European Community Respiratory Health Study. J Allergy Clin Immunol 114:1033–1039.\nWang C, Salam MT, Islam T, Wenten M, Gauderman WJ, Gilliland FD. 2008. Effects of in utero and childhood tobacco smoke exposure and beta2-adrenergic receptor genotype on childhood asthma and wheezing. Pediatrics 122:e107–e114.\nWang Z, Chen C, Niu T, Wu D, Yang J, Wang B, et al. 2001. Association of asthma with beta(2)-adrenergic receptor gene polymorphism and cigarette smoking. Am J Respir Crit Care Med 163:1404–1409.\nWigginton JE, Cutler DJ, Abecasis GR. 2005. A note on exact tests of Hardy-Weinberg equilibrium. Am J Hum Genet 76:887–893.\nWinterton DL, Kaufman J, Keener CV, Quigley S, Farin FM, Williams PV, et al. 2001. Genetic polymorphisms as biomarkers of sensitivity to inhaled sulfur dioxide in subjects with asthma. Ann Allergy Asthma Immunol 86:232–238.\nXiao GG, Wang M, Li N, Loo JA, Nel AE. 2003. Use of proteomics to demonstrate a hierarchical oxidative stress response to diesel exhaust particle chemicals in a macrophage cell line. J Biol Chem 278:50781–50790.\nYang IA, Fong KM, Zimmerman PV, Holgate ST, Holloway JW. 2008. Genetic susceptibility to the respiratory effects of air pollution. Thorax 63:555–563.\nYang IA, Holz O, Jorres RA, Magnussen H, Barton SJ, Rodriguez S, et al. 2005. Association of tumor necrosis factor-alpha polymorphisms and ozone-induced change in lung function. Am J Respir Crit Care Med 171:171–176.\nZhang G, Hayden CM, Khoo SK, Candelaria P, Laing IA, Turner S, et al. 2007. Beta2-adrenoceptor polymorphisms and asthma phenotypes: interactions with passive smoking. Eur Respir J 30:48–55.\nAnnouncements\n""","0.14137141","""https://ehp.niehs.nih.gov/0900589/""","[-0.178219,51.500505]"
"""University_of_Aberdeen""","""The effect of exposure to biomass smoke on respiratory symptoms in adult rural and urban Nepalese populations | Environmental Health | Full Text""","""The effect of exposure to biomass smoke on respiratory symptoms in adult rural and urban Nepalese populations\nOm P Kurmi 1 ,\nWilliam CS Smith 6 and\nJon G Ayres 4\n©  Kurmi et al.; licensee BioMed Central Ltd. 2014\nReceived: 18 June 2014\nAbstract\nBackground\nHalf of the world’s population is exposed to household air pollution from biomass burning. This study aimed to assess the relationship between respiratory symptoms and biomass smoke exposure in rural and urban Nepal.\nMethods\nA cross-sectional study of adults (16+ years) in a rural population (n = 846) exposed to biomass smoke and a non-exposed urban population (n = 802) in Nepal. A validated questionnaire was used along with measures of indoor air quality (PM2.5 and CO) and outdoor PM2.5.\nResults\nBoth men and women exposed to biomass smoke reported more respiratory symptoms compared to those exposed to clean fuel. Women exposed to biomass were more likely to complain of ever wheeze (32.0 % vs. 23.5%; p = 0.004) and breathlessness (17.8% vs. 12.0%, p = 0.017) compared to males with tobacco smoking being a major risk factor. Chronic cough was similar in both the biomass and non-biomass smoke exposed groups whereas chronic phlegm was reported less frequently by participants exposed to biomass smoke. Higher PM2.5 levels (≥2 SDs of the 24-hour mean) were associated with breathlessness (OR = 2.10, 95% CI 1.47, 2.99) and wheeze (1.76, 1.37, 2.26).\nConclusions\nThe study suggests that while those exposed to biomass smoke had higher prevalence of respiratory symptoms, urban dwellers (who were exposed to higher ambient air pollution) were more at risk of having productive cough.\nKeywords\nRespiratory symptomsBreathlessnessPhlegmSolid fuelHousehold air pollution\nIntroduction\nWhile the major cause of respiratory health problems among adults in the developed world is smoking, exposure to particles generated from biomass smoke is a major cause of respiratory diseases in low income countries [ 1 , 2 ].\nSeveral studies have reported higher prevalence of respiratory ill-health among adults exposed to biomass smoke with estimated risk ratios between 1.2 and 7.9 [ 3 ]. Most studies showing an association between household air pollution and respiratory health problems used proxy measurements of exposure such as the number of hours spent on cooking, or simply ever used particular fuels. In addition, not all of the important confounders, particularly socio-economic status, smoking, fuel types and age, have been adjusted for in earlier studies. Although positive associations between chronic bronchitis and household air pollution have been reported, there were large variations in the prevalence of different respiratory symptoms [ 4 , 5 ]. A meta-analysis [ 3 ] reported positive associations between the use of solid fuels and both chronic obstructive pulmonary disease (COPD) (OR = 2.80, 95% CI 1.85, 4.00) and chronic bronchitis (OR = 2.32, 95% CI 1.92, 2.80) but also highlighted considerable heterogeneity in design, measurement, and sizes of effect estimates in studies from different low and middle income countries. To date, only one study from Nepal has reported a relationship between directly measured household exposure and respiratory symptoms although the exposure assessment was carried out only during cooking [ 6 ].\nThis study aimed to investigate the relationship between respiratory symptoms and lung function and direct measures of exposure to emissions from biomass and non-biomass (particularly liquefied petroleum gas [LPG]) fuels in rural and urban households in Nepal. We previously reported a 20% prevalence of COPD in the biomass exposed population compared to 11% in the urban population based on spirometry data [ 7 ]. In this report we focus on the respiratory symptoms.\nMethods\nDesign and study sample\nThis cross-sectional study was carried out between April 2006 and February 2007. The biomass-exposed population (98.9% used wood) was sampled from two village development committees (VDCs) in the Kathmandu Valley. Four wards (out of nine) in each VDC were randomly selected and all individuals in the selected wards aged ≥16 years were eligible if they met the inclusion criteria (no doctor diagnosed major respiratory or cardiovascular health problems and agreement to 24-h continuous airborne exposure monitoring in their homes). The non-exposed population (98.4% used LPG) were selected from six wards (from a total of 35) in the Kathmandu municipality: three were selected randomly near the ring road and the other three selected from 1–2 km inside the ring road. Further details were published elsewhere [ 7 , 8 ]. The sample size was based on lung function assuming a prevalence of COPD of 10% in the non-exposed and 20% in the exposed populations, the latter being twice the reported prevalence for Nepalese populations [ 7 ].\nAn interviewer-administered questionnaire was used to collect data on smoking, socio-economic status, literacy, kitchen characteristics, cooking details, history of fuel use, and respiratory symptoms. The questionnaire was translated into Nepalese and back translated into English by an independent translator and a pilot study was conducted to identify issues of logistics and understanding. The study protocol was approved by the Nepal Health Research Council. Written, informed consent was obtained from all study participants.\nMeasurements of exposure\nLevels of particulate matter with an aerodynamic diameter <2.5 μm (PM2.5) were measured over a continuous 24-h period in most dwellings (n = 490) using photometric devices (SidePak AM510 and DustTrak Model 8520, TSI Inc., Shoreview, MN, USA), from which mean 24-h PM2.5 (in μg/m3) was derived. We report here the results from 442 households (206 biomass burning; 236 non-biomass burning) which had at least 20 h data. Outdoor PM2.5 concentrations were measured in both rural and urban areas on the veranda (for logistic and security reasons) in 118 homes (46 biomass burning, 72 non-biomass burning). Indoor 24-h carbon monoxide (CO) concentrations (in ppm) were measured in 126 homes (40 biomass burning, 86 non-biomass burning) using HOBO CO loggers (MicroDAQ, Contoocook, NH, USA). The direct reading photometric instruments were calibrated using data from co-located gravimetric samplers [ 8 ].\nAssessment of respiratory outcomes\nRespiratory symptoms were based on the Medical Research Council (MRC) questionnaire and included cough, phlegm, breathlessness, and wheezing/whistling. Breathlessness was measured using the five-level modified MRC (mMRC) dyspnoea scale [ 9 ]. In this report we define breathlessness as those falling into Grade 2 or above. Participants who reported to have cough or bring up phlegm first thing in the morning for at least three months each year were considered to have chronic cough or phlegm, respectively. Chronic bronchitis was defined as the presence of both chronic cough and chronic phlegm. Participants also underwent spirometry as reported elsewhere [ 9 ]. For comparability with previous studies, we defined airflow obstruction in two ways: (i) forced expiratory volume in 1 s (FEV1) to forced vital capacity (FVC) ratio less than the lower limit of normal (LLN); or (ii) FEV1/FVC <0.70 [ 7 ].\nCovariates\nHeight and weight were measured using standard protocols [ 10 ], from which body mass index (BMI) was computed (in kg/m2). Participants were classified as non-, ex- and current smokers, where the latter two categories had smoked at least 20 packs of cigarettes or 360 g of tobacco in a lifetime, or at least one cigarette per day or one cigar a week for one year. We also collected information on exposure to environmental tobacco smoke and current occupation. We used monthly household income (in Nepalese Rupees where 1 US$ ≈ 100 Rs) and educational level as proxies for socio-economic status.\nStatistical analysis\nStatistical analyses were performed using STATA (version 12, College Station, TX, USA). Results for PM2.5 and CO concentrations are expressed as geometric means and geometric standard deviations unless indicated otherwise. Mean indoor PM2.5 concentrations >2 standard deviations (SD) of the arithmetic means over the entire sampling window were also calculated from the real time exposure data and are reported here to assess any associations between dependent variables and maximal exposures (i.e. during cooking). Baseline demographic characteristics were compared between biomass and non-biomass exposed participants separately for men and women by regression taking into account the household clustering effect. Regression models were constructed to evaluate the effect of pollutants (biomass, exposure to PM2.5 and CO independently) on respiratory symptoms. All known and potential confounders (age, income, educational level, smoking status, and BMI) were adjusted for to obtain regression coefficients (β) with robust variance estimates to allow for household clustering.\nResults\nAmong 1648 participants (762 men and 886 women) enrolled, 846 (51%) used biomass and 802 (49%) used non-biomass fuels (primarily LPG), respectively. The proportion of current smokers, underweight, illiterate and those having lower income were higher among biomass users (Table  1 ). Around 35% of rural women had smoked at some point in their lives compared to only 9% of urban dwellers.\nTable 1\n*Adjustments for age, sex, educational level, income, BMI, smoking status.\n†OR for 10-fold increase in pollutant level.\nThere was an inverse association between FEV1 and dyspnoea, ever wheeze and chest illness in the last 12 months in women and with chronic phlegm in men after adjusting for height, age, education, BMI, income and smoking status (Additional file 3 : Table S2).\nDiscussion\nThis study shows that the risk of reporting wheeze (ever and on most days and nights) and dyspnoea (mMRC scale ≥2) were significantly higher among those exposed to biomass smoke, particularly in women. These respiratory symptoms were also positively associated with quantitative measures of PM2.5 greater than two standard deviation of the mean but not to the 24-h average mean, suggesting that peaks of pollution may be more important than average exposures. Those exposed to biomass smoke who had respiratory symptoms were more likely to have lower lung function and the prevalence of airflow obstruction was significantly higher amongst the older individuals.\nAll respiratory symptoms were self-reported without further clinical assessment, which may have resulted in misclassification. People in low-income countries often consider wheeze, breathlessness and bringing up phlegm to some extent as normal which may result in under-reporting of symptoms and if this was differentially expressed between exposed and non-exposed groups this may underestimate the true risk. The respiratory questionnaire used was developed and validated in developed countries and although our version was back translated to ensure best delivery of questions interpretative issues may have arisen. For instance, there is no terminology in Nepali for the term “wheeze” which could have caused some confusion among interviewees but efforts were made to minimise these by using bilingual speakers from their local communities trained in questionnaire delivery.\nThe major strengths of this study are its size, the use of a comparator group (studying biomass smoke exposed and non-exposed groups) and the adjustment for confounders, often inadequately dealt with in previous studies. We included young adults (≥16 years) because in Nepal cooking is usually delegated to adolescents, particularly girls and those living in the rural areas.\nPrevious work has studied populations using different types of biomass smoke for varying lengths of time making comparisons difficult especially when the issues of confounding is inconsistently addressed. Behera and Jindal [ 11 ] reported prevalences of respiratory symptoms for different types of fuel users (biomass, kerosene, LPG and mixed) in Indian women and found that respiratory symptoms did not follow any clear pattern: chronic bronchitis was greater in biomass users, cough greater in kerosene users and breathlessness in mixed fuel users. Other studies [ 12 , 13 ] have not found an association between exposures to wood smoke and respiratory symptoms but a randomised controlled trial study in Guatemala [ 14 ] of respiratory symptoms in women involved in cooking reported that women provided with improved cook stoves reported significantly less wheeze compared to baseline but with no significant reduction in other respiratory symptoms.\nOur study recorded significantly higher “ever wheeze” in the rural compared to the urban area, similar to previous reports from Nepal (wood smoke) [ 6 , 15 ], Canada [ 16 , 17 ] (smoke from burning agricultural residue and wood), India [ 11 ] (biomass smoke), China [ 18 , 19 ] (coal smoke) and Guatemala [ 20 ] (wood smoke). The presence of significantly higher prevalence of wheeze (ever, on most days/nights, and in the last 12 months) in the rural, life-long non-smoking population further suggests that the risk of being wheezy is likely to increase in populations exposed to biomass smoke. The risk of ever wheeze in biomass smoke exposed women was 60% higher compared to men but there were no significant differences between urban males and females. The risk of ever wheeziness increased with age for the biomass exposed population but not for the non-exposed population suggesting that prolonged exposure to biomass smoke increases the risk although in other studies respiratory symptoms have generally increased with age. Ex-smokers showed more than a six-fold increase in ever wheeze in the biomass smoke exposed population and a three-fold increase in the urban population compared to life-long non-smokers whereas the additional risks in current smokers were nearly three and two fold respectively. The higher risk in the ex-smokers could be explained as the ex-smokers gave up smoking only after they were medically diagnosed with respiratory problems which might have persuaded them to quit smoking. Similar results for ex- and current smokers were found for wheeze in the last 12 months.\nSelf-reported chronic phlegm was significantly higher in non-smoking, non-biomass exposed men (6.7%) and women (4.9%) compared to the exposed group (men 2.7%, women 2.0%), contrary to the findings reported by other studies in Nepal [ 6 ] and other countries [ 11 , 19 ]. This finding is both marked and surprising and while this might be due to bias in reporting, the risk in the urban population might be real. Most of the urban dwellers were exposed to biomass at some point in their early years and there might have been a residual effect of that early pollutant exposure but this should not overwhelm current exposure. This finding could also possibly be due to the higher urban outdoor air pollution concentrations from vehicle generated pollutants although other causes unrelated to air quality such as post nasal discharge may be a possibility. There have been abundant studies in industrialised countries on the short and long term health effects of vehicle generated ambient air pollution, with special emphasis on respiratory and cardiovascular health effects [ 21 – 23 ] showing positive correlations between these health outcomes and concentrations of ambient air pollutants. It is possible that vehicle generated particles released in ambient air are more toxic in the context of mucus hyper-secretion compared to biomass smoke and thus cause more respiratory symptoms but future studies are needed to assess the differential toxicity due to different types of fuel [ 24 , 25 ] and also compare with existing toxicity data from vehicle generated particles.\nUnsurprisingly production of cough and phlegm was more common in both current and ex-smokers and also in older age groups. Phlegm production was greatest in the biomass exposed illiterate population indicating that socio-economic status is a risk factor and living within a kitchen with no ventilation increased phlegm production in both the rural and urban populations but not statistically significantly so. This indicates that exposure to kitchen fumes (smoke from fuel burning and also mist from cooking oil when heated) might be a risk factor, again a potential surrogate indicator of exposure.\nBiomass smoke exposed men and women reported more breathlessness compared to their non-exposed counterparts but the difference was only significant for biomass smoked compared to non-biomass exposed males. Recorded breathlessness in this study is lower compared to other published studies. As the biomass smoke exposed area was in a hilly region, the population might have attributed breathlessness to exertion rather than to inhalation of biomass smoke, especially as females do a lot of manual work in the fields. It is also possible that our sample is relatively young (mean age 35 years), hence less likely to have (and admit to have) dyspnoea. Cooking with kerosene increased the risk of developing breathlessness in urban dwellers (results not shown) but this result was based on a very small number of individuals and could just be a chance finding.\nDirect measurement of exposure as mean 24-h indoor PM2.5 in this study failed to show any significant associations with respiratory symptoms but some of the proxy measurements such as use of biomass, illiteracy and poor ventilation (data not shown) showed a relationship suggesting that exposure to biomass smoke might be a risk for respiratory symptoms. Of interest is that when we considered peak smoke exposures (taken as mean PM2.5 >2 SDs above the 24-h mean) a relationship between respiratory symptoms and exposures emerged, suggesting that time spent at concentrations that are considerably higher than background may be more important than consistently high exposures.\nThe odds of presence of airflow obstruction was greater amongst those exposed to biomass although it did not reach statistical significance. The higher prevalence of respiratory symptoms such as wheeze and breathlessness without having airflow obstruction could be due to the high proportion of younger individuals in our sample. Alternatively, it is possible that spirometry was not sensitive enough to detect the very early stage of airflow obstruction.\nConclusions\nIn summary, in this study the prevalence of wheeze in a biomass smoke exposed population is in line with most of the previous findings in Nepal and other low-income countries but the results for cough differ. This ambiguity regarding the cough and phlegm results from urban Nepal should be interpreted with special attention. Future studies in urban Nepal looking at respiratory symptoms should be looking at all the aspects like toxicity of outdoor pollutants and whether any other risk factors are confounding the results.\nAbbreviations\nDeclarations\nAcknowledgements\nWe would like to thank all the participants for taking part in this study. We are extremely grateful to the local research staff (Kundan Kumar Jha, Naniram Timalsina, Anita Dhungana, Bishnumaya Adhikar, Indra Kumar Bohara, Bhola Dhungana, Pratichha Dali and Rajeev Shrestha) for their help in sampling and Krishna Kunwar, Lava Dhungana, Pradip Raj Dali and Bigyan Kafle for their help in the selection of the sampling locations and co-ordinating with the house members. We are also grateful to George Henderson for his help with arranging the sampling equipment.\nElectronic supplementary material\n12940_2014_794_MOESM1_ESM.docx Additional file 1: Figure S1: Typical temporal profiles of PM2.5 and CO concentrations. (DOCX 5 MB)\n12940_2014_794_MOESM2_ESM.docx Additional file 2: Table S1: Respiratory symptoms in Nepalese adult men and women according to household fuel type, stratifying for age in tertiles. (DOCX 36 KB)\n12940_2014_794_MOESM3_ESM.docx Additional file 3: Table S2: Regression coefficients of lung function indices using robust variance estimates. (DOCX 38 KB)\nCompeting interests\nThe authors declare that they have no competing interests.\nAuthors’ contributions\nOK is the guarantor of the paper, taking responsibility for the integrity of the work as a whole, from inception to published articles. OK, SSemple, PS, WCS and JA conceived and designed the study, interpreted results, and contributed to authorship of the manuscript. OK, GSD, MS, KBHL and SSadhra processed the data, contributed to the analysis plan and editing the manuscript. SG helped in the data entry, cleaning and editing the manuscript. All authors read and approved the final manuscript.\nAuthors’ Affiliations\nSchool of Medicine and Dentistry, University of Aberdeen\nReferences\nNaeher LP, Brauer M, Lipsett M, Zelikoff JT, Simpson CD, Koenig JQ, Smith KR: Woodsmoke health effects: a review. Inhal Toxicol. 2007, 19: 67-106. View Article Google Scholar\nKurmi OP, Lam KB, Ayres JG: Indoor air pollution and the lung in low- and medium-income countries. Eur Respir J. 2012, 40: 239-254. View Article Google Scholar\nKurmi OP, Semple S, Simkhada P, Smith WC, Ayres JG: COPD and chronic bronchitis risk of indoor air pollution from solid fuel: a systematic review and meta-analysis. Thorax. 2010, 65: 221-228. View Article Google Scholar\nBruce N, Neufeld L, Boy E, West C: Indoor biofuel air pollution and respiratory health: the role of confounding factors among women in highland Guatemala. Int J Epidemiol. 1998, 27: 454-458. View Article Google Scholar\nZhong N, Wang C, Yao W, Chen P, Kang J, Huang S, Chen B, Wang C, Ni D, Zhou Y, Liu S, Wang X, Wang D, Lu J, Zheng J, Ran P: Prevalence of chronic obstructive pulmonary disease in China: a large, population-based survey. Am J Respir Crit Care Med. 2007, 176: 753-760. View Article Google Scholar\nShrestha IL, Shrestha SL: Indoor air pollution from biomass fuels and respiratory health of the exposed population in Nepalese households. Int J Occup Environ Health. 2005, 11: 150-160. View Article Google Scholar\nKurmi OP, Devereux GS, Smith WC, Semple S, Steiner MF, Simkhada P, Lam KB, Ayres JG: Reduced lung function due to biomass smoke exposure in young adults in rural Nepal. Eur Respir J. 2013, 41: 25-30. View Article Google Scholar\nKurmi OP, Semple S, Steiner M, Henderson GD, Ayres JG: Particulate matter exposure during domestic work in Nepal. Ann Occup Hyg. 2008, 52: 509-517. View Article Google Scholar\nMahler DA, Wells CK: Evaluation of clinical methods for rating dyspnea. Chest. 1988, 93: 580-586. View Article Google Scholar\nWorld Health Organization: Physical status: The use and interpretation of anthropometry. Report of a WHO Expert Committee. Technical Report Series No. 854. 1995, Geneva: WHO Google Scholar\nBehera D, Jindal SK: Respiratory symptoms in Indian women using domestic cooking fuels. Chest. 1991, 100: 385-388. View Article Google Scholar\nMaier WC, Arrighi HM, Morray B, Llewellyn C, Redding GJ: Indoor risk factors for asthma and wheezing among Seattle school children. Environ Health Perspect. 1997, 105: 208-214. View Article Google Scholar\nEllegard A: Cooking fuel smoke and respiratory symptoms among women in low-income areas in Maputo. Environ Health Perspect. 1996, 104: 980-985. View Article Google Scholar\nSmith-Sivertsen T, Diaz E, Pope D, Lie RT, Diaz A, McCracken J, Bakke P, Arana B, Smith KR, Bruce N: Effect of reducing indoor air pollution on women’s respiratory symptoms and lung function: The RESPIRE Randomized Trial, Guatemala. Am J Epidemiol. 2009, 170: 211-220. View Article Google Scholar\nPandey MR: Domestic smoke pollution and chronic bronchitis in a rural community of the Hill Region of Nepal. Thorax. 1984, 39: 337-339. View Article Google Scholar\nLong WQ, Tate RB, Neuman M, Manfreda J, Becker AB, Anthonisen NR: Respiratory symptoms in a susceptible population due to burning of agricultural residue. Chest. 1998, 113: 351-357. View Article Google Scholar\nGuggisberg M, Hessel PA, Michaelchuk D, Ahmed I: Respiratory symptoms and exposure to wood smoke in an isolated northern community. Can J Public Health. 2003, 94: 372-376. Google Scholar\nZhang LX, Enarson DA, He GX, Li B, Chan-Yeung M: Occupational and environmental risk factors for respiratory symptoms in rural Beijing, China. Eur Respir J. 2002, 20: 1525-1231. View Article Google Scholar\nSalo PM, Xia J, Johnson CA, Li Y, Kissling GE, Avol EL, Liu C, London SJ: Respiratory symptoms in relation to residential coal burning and environmental tobacco smoke among early adolescents in Wuhan, China: a cross-sectional study. Environ Health. 2004, 3: 14- View Article Google Scholar\nDiaz E, Bruce N, Pope D, Lie RT, Diaz A, Arana B, Smith KR, Smith-Sivertsen T: Lung function and symptoms among indigenous Mayan women exposed to high levels of indoor air pollution. Int J Tuberc Lung Dis. 2007, 11: 1372-1379. Google Scholar\nFrew AJ, Salvi SS: Diesel exhaust particles and respiratory allergy. Clin Exp Allergy. 1997, 27: 237-239. View Article Google Scholar\nBrunekreef B, Holgate ST: Air pollution and health. Lancet. 2002, 360: 1233-1242. View Article Google Scholar\nvan Vliet P, Knape M, de Hartog J, Janssen N, Harssema H, Brunekreef B: Motor vehicle exhaust and chronic respiratory symptoms in children living near freeways. Environ Res. 1997, 74: 122-132. View Article Google Scholar\nKurmi OP, Dunster C, Ayres JG, Kelly FJ: Oxidative potential of smoke from burning wood and mixed biomass fuels. Free Radic Res. 2013, 47: 829-835. View Article Google Scholar\nMudway I, Duggan S, Venkataraman C, Habib G, Kelly F, Grigg J: Combustion of dried animal dung as biofuel results in the generation of highly redox active fine particulates. Part Fibre Toxicol. 2005, 2: 6- View Article Google Scholar\nCopyright\n© Kurmi et al.; licensee BioMed Central Ltd. 2014\nThis article is published under license to BioMed Central Ltd. This is an Open Access article distributed under the terms of the Creative Commons Attribution License ( http://creativecommons.org/licenses/by/4.0 ), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly credited. The Creative Commons Public Domain Dedication waiver ( http://creativecommons.org/publicdomain/zero/1.0/ ) applies to the data made available in this article, unless otherwise stated.\n""","0.20128244","""https://ehjournal.biomedcentral.com/articles/10.1186/1476-069X-13-92""","[-2.099122,57.165019]"
"""Imperial_College_London""","""Multi-class dynamic traffic assignment with physical queues: intersection-movement-based formulation and paradox: Transportmetrica A: Transport Science: Vol 12, No 10""","""KEYWORDS: Multi-class dynamic traffic assignment ,  approach proportion ,  variational inequality ,  extragradient method ,  paradox\n1.  Introduction\nDynamic traffic assignment (DTA) is an important topic due to its wide applications in transport planning and management (Szeto and Lo 2006 Szeto, W. Y., and H. K. Lo. 2006. “Dynamic Traffic Assignment: Properties and Extensions.” Transportmetrica 2 (1): 31–52. doi: 10.1080/18128600608685654 [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ). In general, DTA can be classified into the simulation-based approach (e.g. Yagar 1971 Yagar, S. 1971. “Dynamic Traffic Assignment by Individual Path Minimisation and Queuing.” Transportation Research 5 (3): 179–196. doi: 10.1016/0041-1647(71)90020-7 [Crossref]   [Google Scholar] ; Mahmassani, Hu, and Jayakrishnan 1995 Mahmassani, H. S., T. Hu, and R. Jayakrishnan. 1992. “Dynamic Traffic Assignment and Simulation for Advanced Network Informatics (DYNASMART).” Proceedings of the 2nd international CAPRI seminar on Urban Traffic Networks. Capri, July.  [Google Scholar] ; Mahut and Florian 2010 Mahut, M., and M. Florian. 2010. “Traffic Simulation with Dynameq.” In Fundamentals of Traffic Simulation, edited by Jaume Barceló, 323–361.\nNew York\n: Springer. [Crossref]   [Google Scholar] ) and the analytical approach (see Ran and Boyce 1996 Ran, B., and D. E. Boyce. 1996. Modeling Dynamic Transportation Network: An Intelligent Transportation System Oriented Approach.\nSpringer\n: Heidelberg. [Crossref]   [Google Scholar] ; Peeta and Ziliaskopoulos 2001 Peeta, S., and A. K. Ziliaskopoulos. 2001. “Foundations of Dynamic Traffic Assignment: The Past, the Present and the Future.” Networks and Spatial Economics 1 (3–4): 233–265. doi: 10.1023/A:1012827724856 [Crossref]   [Google Scholar] ; Szeto and Lo 2005 Szeto, W. Y., and H. K. Lo. 2005. “Dynamic Traffic Assignment: Review and Future Research Directions.” Journal of Transportation Systems Engineering and Information Technology 5 (5): 85–100.  [Google Scholar] ; and Szeto and Wong 2012 Szeto, W. Y., and S. C. Wong. 2012. “Dynamic Traffic Assignment: Model Classifications and Recent Advances in Travel Choice Principles.” Central European Journal of Engineering 2 (1): 1–18. [Crossref]   [Google Scholar] for comprehensive reviews). The simulation-based approach focuses on enabling practical deployment for realistic networks, its applicability in real-life networks, and its ability to capture traffic dynamics and microscopic driver behaviour such as lane-changing behaviour. However, the solution properties of the corresponding models, such as solution existence and uniqueness, are not guaranteed and cannot be determined in advance.\nIn contrast, the analytical approach is more suitable for analysing the properties of DTA via various frameworks. These frameworks include the optimisation model (Merchant and Nemhauser 1978a Merchant, D. K., and G. L. Nemhauser. 1978a. “A Model and an Algorithm for the Dynamic Traffic Assignment Problems.” Transportation Science 12 (3): 183–199. doi: 10.1287/trsc.12.3.183 [Crossref]   [Google Scholar] , 1978b Merchant, D. K., and G. L. Nemhauser. 1978b. “Optimality Conditions for a Dynamic Traffic Assignment Model.” Transportation Science 12 (3): 200–207. doi: 10.1287/trsc.12.3.200 [Crossref]   [Google Scholar] ; Carey 1987 Carey, M. 1987. “Optimal Time-Varying Flows on Congested Networks.” Operations Research 35 (1): 58–69. doi: 10.1287/opre.35.1.58 [Crossref] , [Web of Science ®]   [Google Scholar] ; Carey and Watling 2012 Carey, M., and D. Watling. 2012. “Dynamic Traffic Assignment Approximating the Kinematic Wave Model: System Optimum, Marginal Costs, Externalities and Tolls.” Transportation Research Part B: Methodological 46 (5): 634–648. doi: 10.1016/j.trb.2012.01.008 [Crossref] , [Web of Science ®]   [Google Scholar] ), optimal control (Friesz et al. 1989 Friesz, T. L., J. Luque, R. L. Tobin, and B. W. Wie. 1989. “Dynamic Network Traffic Assignment Considered as a Continuous Time Optimal Control Problem.” Operations Research 37 (6): 893–901. doi: 10.1287/opre.37.6.893 [Crossref] , [Web of Science ®]   [Google Scholar] ; Ran, Boyce, and LeBlanc 1993 Ran, B., D. E. Boyce, and L. J. LeBlanc. 1993. “A New Class of Instantaneous Dynamic User-Optimal Traffic Assignment Models.” Operations Research 41 (1): 192–202. doi: 10.1287/opre.41.1.192 [Crossref] , [Web of Science ®]   [Google Scholar] ; Chow 2009a Chow, A. H. F. 2009a. “Dynamic System Optimal Traffic Assignment – A State-Dependent Control Theoretic Approach.” Transportmetrica 5 (2): 85–106. doi: 10.1080/18128600902717483 [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] , 2009b Chow, A. H. F. 2009b. “Properties of System Optimal Traffic Assignment with Departure Time Choice and Its Solution Method.” Transportation Research Part B: Methodological 43(3): 325–344. doi: 10.1016/j.trb.2008.07.006 [Crossref] , [Web of Science ®]   [Google Scholar] ; Ma et al. 2014a Ma, R., X. J. Ban, and J.-S. Pang. 2014a. “Continuous-time Dynamic System Optimum for Single-Destination Traffic Networks with Queue Spillbacks.” Transportation Research Part B: Methodological 68: 98–122. doi: 10.1016/j.trb.2014.06.003 [Crossref] , [Web of Science ®]   [Google Scholar] , 2014b Ma, R., X. J. Ban, and J.-S. Pang. 2014b. “Continuous-time Dynamic User Equilibrium Model with Departure-Time Choice and Capacitated Queue.” Proceedings of the 5th International Symposium on Dynamic Traffic Assignment, Salerno, Italy, 17–19 June.  [Google Scholar] ), variational inequality (Friesz et al. 1993 Friesz, T. L., D. Bernstein, T. E. Smith, R. L. Tobin, and B. W. Wie. 1993. “A Variational Inequality Formulation of the Dynamic Network User Equilibrium Problem.” Operations Research 41 (1): 179–191. doi: 10.1287/opre.41.1.179 [Crossref] , [Web of Science ®]   [Google Scholar] ; Ran and Boyce 1996 Ran, B., and D. E. Boyce. 1996. Modeling Dynamic Transportation Network: An Intelligent Transportation System Oriented Approach.\nSpringer\n: Heidelberg. [Crossref]   [Google Scholar] ; Chen and Hsueh 1998 Chen, H. K., and C. F. Hsueh. 1998. “A Model and an Algorithm for the Dynamic User-Optimal Route Choice Problem.” Transportation Research Part B: Methodological 32 (3): 219–234. doi: 10.1016/S0191-2615(97)00026-X [Crossref] , [Web of Science ®]   [Google Scholar] ; Huang and Lam 2002 Huang, H. J., and W. H. K. Lam. 2002. “Modeling and Solving the Dynamic User Equilibrium Route and Departure Time Choice Problem in Network With Queues.” Transportation Research Part B: Methodological 36 (3): 253–273. doi: 10.1016/S0191-2615(00)00049-7 [Crossref] , [Web of Science ®]   [Google Scholar] ; Lo and Szeto 2002a Lo, H. K., and W. Y. Szeto. 2002a. “A Cell-Based Variational Inequality Formulation of the Dynamic User Optimal Assignment Problem.” Transportation Research Part B: Methodological 36 (5): 421–443. doi: 10.1016/S0191-2615(01)00011-X [Crossref] , [Web of Science ®]   [Google Scholar] , 2002b Lo, H. K., and W. Y. Szeto. 2002b. “A Cell-Based Dynamic Traffic Assignment Model: Formulation and Properties.” Mathematical and Computer Modelling 35 (7–8): 849–865. doi: 10.1016/S0895-7177(02)00055-9 [Crossref] , [Web of Science ®]   [Google Scholar] ; Szeto and Lo 2004 Szeto, W. Y., and H. K. Lo. 2004. “A Cell-Based Simultaneous Route and Departure Time Choice Model with Elastic Demand.” Transportation Research Part B: Methodological 38 (7): 593–612. doi: 10.1016/j.trb.2003.05.001 [Crossref] , [Web of Science ®]   [Google Scholar] , 2006 Szeto, W. Y., and H. K. Lo. 2006. “Dynamic Traffic Assignment: Properties and Extensions.” Transportmetrica 2 (1): 31–52. doi: 10.1080/18128600608685654 [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ; Han, Friesz, and Yao 2013c Han, K., T. L. Friesz, and T. Yao. 2013c. “Existence of Simultaneous Route and Departure Choice Dynamic User Equilibrium.” Transportation Research Part B: Methodological 53: 17–30. doi: 10.1016/j.trb.2013.01.009 [Crossref] , [Web of Science ®]   [Google Scholar] ), nonlinear complementarity problem (NCP) (Wie, Tobin, and Carey 2002 Wie, B. W., R. L. Tobin, and M. Carey. 2002. “The Existence, Uniqueness and Computation of an Arc-Based Dynamic Network User Equilibrium Formulation.” Transportation Research Part B: Methodological 36 (10): 897–918. doi: 10.1016/S0191-2615(01)00041-8 [Crossref] , [Web of Science ®]   [Google Scholar] ; Ban et al. 2008 Ban, X. J., H. X. Liu, M. C. Ferris, and B. Ran. 2008. “A Link-Node Complementarity Model and Solution Algorithm for Dynamic User Equilibria with Exact Flow Propagations.” Transportation Research Part B: Methodological 42 (9): 823–842. doi: 10.1016/j.trb.2008.01.006 [Crossref] , [Web of Science ®]   [Google Scholar] ), nonlinear equation system (Long et al. 2015b Long, J. C., W. Y. Szeto, Q. Shi, Z. Y. Gao, and H. J. Huang. 2015b. “A Nonlinear Equation System Approach to the Dynamic Stochastic User Equilibrium Simultaneous Route and Departure Time Choice Problem.” Transportmetrica A: Transport Science 11 (5): 388–419. doi: 10.1080/23249935.2014.1003112 [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ), fixed point problem (Szeto, Jiang, and Sumalee 2011 Szeto, W. Y., Y. Jiang, and A. Sumalee. 2011. “A Cell-Based Model for Multi-Class Doubly Stochastic Dynamic Traffic Assignment.” Computer-Aided Civil and Infrastructure Engineering 26: 595–611. doi: 10.1111/j.1467-8667.2011.00717.x [Crossref] , [Web of Science ®]   [Google Scholar] ; Meng and Khoo 2012 Meng, Q., and H. L. Khoo. 2012. “A Computational Model for the Probit-Based Dynamic Stochastic User Optimal Traffic Assignment Problem.” Journal of Advanced Transportation 46 (1): 80–94. doi: 10.1002/atr.149 [Crossref] , [Web of Science ®]   [Google Scholar] ), differential variational inequality (Friesz et al. 2013 Friesz, T. L., K. Han, P. A. Neto, A. Meimand, and T. Yao. 2013. “Dynamic User Equilibrium Based on a Hydrodynamic Model.” Transportation Research Part B: Methodological 47 (1): 102–126. doi: 10.1016/j.trb.2012.10.001 [Crossref] , [Web of Science ®]   [Google Scholar] ; Friesz and Meimand 2014 Friesz, T. L., and A. Meimand. 2014. “A Differential Variational Inequality Formulation of Dynamic Network User Equilibrium with Elastic Demand.” Transportmetrica A: Transport Science 10 (7): 661–668. doi: 10.1080/18128602.2012.751684 [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ), and differential complementarity problem (Ban et al. 2012b Ban, X. J., J. S. Pang, H. X. Liu, and R. Ma. 2012b. “Modeling and Solving Continuous-Time Instantaneous Dynamic User Equilibria: A Differential Complementarity Systems Approach.” Transportation Research Part B: Methodological 46 (3): 389–408. doi: 10.1016/j.trb.2011.11.002 [Crossref] , [Web of Science ®]   [Google Scholar] ) frameworks.\nAll of the preceding analytical frameworks are formulated as either path-based models (e.g. Friesz et al. 1993 Friesz, T. L., D. Bernstein, T. E. Smith, R. L. Tobin, and B. W. Wie. 1993. “A Variational Inequality Formulation of the Dynamic Network User Equilibrium Problem.” Operations Research 41 (1): 179–191. doi: 10.1287/opre.41.1.179 [Crossref] , [Web of Science ®]   [Google Scholar] ; Huang and Lam 2002 Huang, H. J., and W. H. K. Lam. 2002. “Modeling and Solving the Dynamic User Equilibrium Route and Departure Time Choice Problem in Network With Queues.” Transportation Research Part B: Methodological 36 (3): 253–273. doi: 10.1016/S0191-2615(00)00049-7 [Crossref] , [Web of Science ®]   [Google Scholar] ; Lo and Szeto 2002a Lo, H. K., and W. Y. Szeto. 2002a. “A Cell-Based Variational Inequality Formulation of the Dynamic User Optimal Assignment Problem.” Transportation Research Part B: Methodological 36 (5): 421–443. doi: 10.1016/S0191-2615(01)00011-X [Crossref] , [Web of Science ®]   [Google Scholar] , 2002b Lo, H. K., and W. Y. Szeto. 2002b. “A Cell-Based Dynamic Traffic Assignment Model: Formulation and Properties.” Mathematical and Computer Modelling 35 (7–8): 849–865. doi: 10.1016/S0895-7177(02)00055-9 [Crossref] , [Web of Science ®]   [Google Scholar] ; Szeto and Lo 2004 Szeto, W. Y., and H. K. Lo. 2004. “A Cell-Based Simultaneous Route and Departure Time Choice Model with Elastic Demand.” Transportation Research Part B: Methodological 38 (7): 593–612. doi: 10.1016/j.trb.2003.05.001 [Crossref] , [Web of Science ®]   [Google Scholar] , 2006 Szeto, W. Y., and H. K. Lo. 2006. “Dynamic Traffic Assignment: Properties and Extensions.” Transportmetrica 2 (1): 31–52. doi: 10.1080/18128600608685654 [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ; Perakis and Roels 2006 Perakis, G., and Roels, G. 2006. “An Analytical Model for Traffic Delays and the Dynamic User Equilibrium Problem.” Operations Research 54 (6): 1151–1171. doi: 10.1287/opre.1060.0307 [Crossref] , [Web of Science ®]   [Google Scholar] ; Szeto 2008 Szeto, W. Y.. 2008. “Enhanced Lagged Cell-Transmission Model for Dynamic Traffic Assignment.” Transportation Research Record: Journal of the Transportation Research Board 2085: 76–85. doi: 10.3141/2085-09 [Crossref] , [Web of Science ®]   [Google Scholar] ; Szeto, Jiang, and Sumalee 2011 Szeto, W. Y., Y. Jiang, and A. Sumalee. 2011. “A Cell-Based Model for Multi-Class Doubly Stochastic Dynamic Traffic Assignment.” Computer-Aided Civil and Infrastructure Engineering 26: 595–611. doi: 10.1111/j.1467-8667.2011.00717.x [Crossref] , [Web of Science ®]   [Google Scholar] ) or link-based models (e.g. Carey 1987 Carey, M. 1987. “Optimal Time-Varying Flows on Congested Networks.” Operations Research 35 (1): 58–69. doi: 10.1287/opre.35.1.58 [Crossref] , [Web of Science ®]   [Google Scholar] ; Ran and Boyce 1996 Ran, B., and D. E. Boyce. 1996. Modeling Dynamic Transportation Network: An Intelligent Transportation System Oriented Approach.\nSpringer\n: Heidelberg. [Crossref]   [Google Scholar] ; Chen and Hsueh 1998 Chen, H. K., and C. F. Hsueh. 1998. “A Model and an Algorithm for the Dynamic User-Optimal Route Choice Problem.” Transportation Research Part B: Methodological 32 (3): 219–234. doi: 10.1016/S0191-2615(97)00026-X [Crossref] , [Web of Science ®]   [Google Scholar] ; Wie, Tobin, and Carey 2002 Wie, B. W., R. L. Tobin, and M. Carey. 2002. “The Existence, Uniqueness and Computation of an Arc-Based Dynamic Network User Equilibrium Formulation.” Transportation Research Part B: Methodological 36 (10): 897–918. doi: 10.1016/S0191-2615(01)00041-8 [Crossref] , [Web of Science ®]   [Google Scholar] ; Ban et al. 2008 Ban, X. J., H. X. Liu, M. C. Ferris, and B. Ran. 2008. “A Link-Node Complementarity Model and Solution Algorithm for Dynamic User Equilibria with Exact Flow Propagations.” Transportation Research Part B: Methodological 42 (9): 823–842. doi: 10.1016/j.trb.2008.01.006 [Crossref] , [Web of Science ®]   [Google Scholar] ). The merit of path-based models is that the path-related information, such as path flows and sets, can be obtained and imported to dynamic network loading (DNL) models to model flow propagation at merges and diverges and track spillback queues. Nevertheless, a path-based model normally suffers from the computational burden of path enumeration or relies on path-generation heuristics with no guarantee on convergence to handle huge path sets, even for medium networks. Instead, link-based models can avoid these two demerits and thus be applied to large networks. However, link-based models cannot be used to capture realistic traffic dynamics such as queue spillback (in one exception, Ma et al. ( 2014b Ma, R., X. J. Ban, and J.-S. Pang. 2014b. “Continuous-time Dynamic User Equilibrium Model with Departure-Time Choice and Capacitated Queue.” Proceedings of the 5th International Symposium on Dynamic Traffic Assignment, Salerno, Italy, 17–19 June.  [Google Scholar] ) proposed a link-based dynamic user optimal (DUO) model that could capture queue spillback for single-destination cases). If it is not captured, the flow pattern and locations of severe congestion may be estimated incorrectly and the strategy adopted may actually worsen network performance (Lo and Szeto 2004 Lo, H. K., and W. Y. Szeto. 2004. “Modeling Advanced Traveler Information Services: Static Versus Dynamic Paradigms.” Transportation Research Part B: Methodological 38 (6): 495–515. doi: 10.1016/j.trb.2003.06.001 [Crossref] , [Web of Science ®]   [Google Scholar] , 2005 Lo, H. K., and W. Y. Szeto. 2005. “Road Pricing for Hyper-congestion.” Transportation Research Part A 39 (7–9): 705–722.  [Google Scholar] ).\nTo retain the benefits of both the link- and path-based models, Long et al. ( 2013 Long, J. C., H. J. Huang, Z. Y. Gao, and W. Y. Szeto. 2013. “An Intersection-Movement-Based Dynamic User Optimal Route Choice Problem.” Operations Research 61 (5): 1134–1147. doi: 10.1287/opre.2013.1202 [Crossref] , [Web of Science ®]   [Google Scholar] , 2015a Long, J. C., W. Y. Szeto, H. J. Huang, and Z. Y. Gao. 2015a. “An Intersection-Movement-Based Stochastic Dynamic User Optimal Route Choice Model for Assessing Network Performance.” Transportation Research Part B: Methodological 74: 182–217. doi: 10.1016/j.trb.2014.12.008 [Crossref] , [Web of Science ®]   [Google Scholar] ) developed intersection-movement-based DTA models for general networks with multiple destinations. They formulated the traffic assignment problem in terms of approach proportions, that is, the proportion of traffic on the current link or node that selects a downstream link when leaving an intersection (or a node). This definition requires either two adjacent links or one origin link and one outgoing link to define an intersection movement. This is different from the classical definition, according to which only downstream links are used to define the proportion. An approach-proportion implicitly contains the traveller’s path information, as a path can be deduced by checking the downstream links involved in defining the approach proportions from origin to destination. As a result, this type of model can retain the advantages of both the link- and path-based models. First, as in link-based models, path enumeration and path-set generation can be avoided in the solution procedure for intersection-movement-based models. Second, as in path-based models, the realistic effects of physical queues can be captured in intersection-movement-based models when a physical queue DNL model is adopted, as the approach proportions contain the traveller’s path information. However, compared with link-based models, intersection-movement-based models have more decision variables, as each link flow or demand rate is disaggregated by downstream links (which very often number more than one) to define intersection movements and the corresponding approach proportions.\nMost of the preceding models, including the intersection-movement-based DTA models, consider only a single vehicle class. It is important to capture multiple vehicle classes in a DTA model and the interactions between different types of vehicles for several reasons. First, interactions between vehicle classes have been identified as a cause of traffic hysteresis, capacity decreases, and the wide scattering of flow–density relationships in a congested regime (Ngoduy 2010 Ngoduy, D. 2010. “Multi-Class First-Order Modelling of Traffic Networks Using Discontinuous Flow-Density Relationships.” Transportmetrica 6 (2): 121–141. doi: 10.1080/18128600902857925 [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ). Second, it is clear that trucks have a great influence on highway capacity, as they travel more slowly than cars and can become moving bottlenecks. Therefore, without considering different vehicle types and their interactions, realistic traffic dynamics and queue spillback cannot be modelled properly and the total system travel time cannot be estimated precisely. Third, many empirical studies have shown that vehicle emissions are closely related to speed and vehicle type; for example, the emissions of trucks are greater than those of cars. Therefore, it is important to capture traffic heterogeneity in estimating total vehicle emissions. Fourth, it is essential to distinguish user classes in the application of class-specific or priority control or when different types of traffic information are available to different user classes (Ngoduy 2010 Ngoduy, D. 2010. “Multi-Class First-Order Modelling of Traffic Networks Using Discontinuous Flow-Density Relationships.” Transportmetrica 6 (2): 121–141. doi: 10.1080/18128600902857925 [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] ).\nThis paper develops a multi-class intersection-movement-based DTA model based on the DUO principle and concept of approach proportion. The problem is formulated as a VI problem. The DNL model proposed by Bliemer ( 2007 Bliemer, M. C. J. 2007. “Dynamic Queuing and Spillback in Analytical Multi-Class Dynamic Network Loading Model.” Transportation Research Record: Journal of the Transportation Research Board 2029 (1): 14–21. doi: 10.3141/2029-02 [Crossref] , [Web of Science ®]   [Google Scholar] ) is modified and incorporated into the VI formulation. Unlike some single-class DNL models (Ban et al. 2012a Ban, X. J., J. S. Pang, H. X. Liu, and R. Ma. 2012a. “Continuous-Time Point-Queue Models in Dynamic Network Loading.” Transportation Research Part B: Methodological 46 (3): 360–380. doi: 10.1016/j.trb.2011.11.004 [Crossref] , [Web of Science ®]   [Google Scholar] ; Han, Friesz, and Yao 2013a Han, K., T. L. Friesz, and T. Yao. 2013a. “A Partial Differential Equation Formulation of Vickrey’s Bottleneck Model, Part I: Methodology and Theoretical Analysis.” Transportation Research Part B: Methodological 49: 55–74. doi: 10.1016/j.trb.2012.10.003 [Crossref] , [Web of Science ®]   [Google Scholar] , 2013b Han, K., T. L. Friesz, and T. Yao. 2013b. “A Partial Differential Equation Formulation of Vickrey’s Bottleneck Model, Part II: Numerical Analysis and Computation.” Transportation Research Part B: Methodological 49: 75–93. doi: 10.1016/j.trb.2012.10.004 [Crossref] , [Web of Science ®]   [Google Scholar] ), this DNL model can capture car–truck interactions and allow approach proportions to be used as inputs. An extragradient method that requires only mild assumptions is adopted to solve the problem. Numerical examples are set to illustrate the importance of considering multiple vehicle classes. In addition, a car–truck interaction paradox, which states that allowing trucks to travel in a network or increasing the demand of trucks can improve total car travel time, is proposed, discussed, and examined. The findings have important implications for managing road networks with multiple types of traffic. For example, it is possible to relax road restrictions for trucks or large vehicles so that the total car travel time can be further improved or vice versa. The findings also open up new research directions for traffic management such as road restrictions and priority control for specific vehicle classes. This paper makes two main contributions. First, it proposes a multi-class intersection-movement-based DTA model that considers interactions between different types of vehicles and physical queues. Second, it proposes and examines the paradox associated with the interactions between trucks and cars.\nThe remainder of this paper proceeds as follows. Section 2 introduces the VI formulation for the intersection-movement-based multi-class DTA problem. It then depicts the DNL model encapsulated for calculating the mapping function in the VI formulation. Section 3 presents the extragradient solution method. Numerical examples are given in Section 4. Finally, Section 5 provides our conclusions and future research directions.\n2.  Formulation\n2.1  Notations\nWe consider a network with multiple origins and destinations and various classes of vehicles according to vehicle type. The network is formed by nodes and links. To simplify the presentation of the formulation, the network is designed to have the following properties. First, a node in a network can only have one status, that is, an origin, a destination, or an intermediate node. Second, at least two links are required to connect an origin and a destination. Third, there is one dummy link coming out from a destination with an infinite capacity. The first requirement can easily be satisfied by designing the network carefully. The second requirement is always satisfied for large networks. For small networks, this requirement can be satisfied by breaking down each link directly connecting an origin and a destination into a pair of links: one going into an intermediate node, and one coming out from the node. The third requirement aims to avoid developing additional sub-models to deal with flow propagation for the links going into a destination.\nThe following notations are used throughout this paper.\n2.1.1  Sets\n""","0.37964696","""http://www.tandfonline.com/doi/full/10.1080/23249935.2016.1190421""","[-0.178219,51.500505]"
"""Imperial_College_London""","""Calibration and Validation of a Shared Space Model | Case Study""","""Calibration and Validation of a Shared Space Model\nCase Study\nPDF\nAbstract\nShared space is an innovative streetscape design that seeks minimum separation between vehicle traffic and pedestrians. Urban design is moving toward space sharing as a means of increasing the community texture of street surroundings. Its unique features aim to balance priorities and allow cars and pedestrians to coexist harmoniously without the need to dictate behavior. There is, however, a need for a simulation tool to model future shared space schemes and to help judge whether they might represent suitable alternatives to traditional street layouts. This paper builds on the authors’ previously published work in which a shared space microscopic mixed traffic model based on the social force model (SFM) was presented, calibrated, and evaluated with data from the shared space link typology of New Road in Brighton, United Kingdom. Here, the goal is to explore the transferability of the authors’ model to a similar shared space typology and investigate the effect of flow and ratio of traffic modes. Data recorded from the shared space scheme of Exhibition Road, London, were collected and analyzed. The flow and speed of cars and segregation between pedestrians and cars are greater on Exhibition Road than on New Road. The rule-based SFM for shared space modeling is calibrated and validated with the real data. On the basis of the results, it can be concluded that shared space schemes are context dependent and that factors such as the infrastructural design of the environment and the flow and speed of pedestrians and vehicles affect the willingness to share space.\n< >\nTransportation Research Record: Journal of the Transportation Research Board\nTransportation Research Record: Journal of the Transportation Research Board\nPrint ISSN: 0361-1981\n""","0.85805273","""http://trrjournalonline.trb.org/doi/10.3141/2588-05""","[-0.178219,51.500505]"
"""Imperial_College_London""","""Numerical Investigation on the Hot Forming and Cold-Die Quenching of an Aluminium-Magnesium Alloy into a Complex Component""","""Numerical Investigation on the Hot Forming and Cold-Die Quenching of an Aluminium-Magnesium Alloy into a Complex Component\nNumerical Investigation on the Hot Forming and...\nNumerical Investigation on the Hot Forming and Cold-Die Quenching of an Aluminium-Magnesium Alloy into a Complex Component\nAbstract:\nArticle Preview\nAn FE model for the hot forming and cold-die quenching (HFQ) process was developed. This model was verified by HFQ experiments through a comparison of the thickness distribution between the simulated and experimental results; good correlation with a deviation of less than 5% was achieved. In addition, this FE model was used to study the effects of forming speed on the thickness distribution of a HFQ formed part, and it was found that a higher forming speed is beneficial for HFQ forming, as it led to improved thickness homogeneity and less thinning.\nInfo:\nIan Stone, Brian McKay and Zhongyun Fan\nPages:\nhttps://doi.org/10.4028/www.scientific.net/MSF.765.368\nCitation:\nO. El Fakir et al., \""Numerical Investigation on the Hot Forming and Cold-Die Quenching of an Aluminium-Magnesium Alloy into a Complex Component\"", Materials Science Forum, Vol. 765, pp. 368-372, 2013\nOnline since:\nJuly 2013\nAuthors:\nReferences\n[1] S. Birch, X.J. Jaguar Remakes, SAE Vehicle Engineering, (2010).\n[2] N.P. Lutsey, Review of technical literature and trends related to automobile mass-reduction technology. Institute of Transportation Studies, UC Davis, (2010).\n[3] L. Wang, M. Strangwood, D. Balint, J. Lin, T.A. Dean, Formability and failure mechanisms of AA2024 under hot forming conditions, Mat. Sci. Eng. A 528 (2011) 2648-2656.\nDOI: 10.1016/j.jmatprotec.2005.06.026\n[6] M.F. Ashby, Engineering Materials 2: An Introduction to Microstructures, Processing and Design, third ed, Elsevier Butteworth-Heinemann, Oxford, (2006).\n[7] M.F. Ashby, Engineering Materials 1: An Introduction to Properties, Applications and Design. third ed, Elsevier Butterworth-Heinemann, London, (2005).\n[8] J. Lin, Y. Liu, T.A. Dean, A review on damage mechanisms, models and calibration methods under various deformation conditions, Int. J. Damage Mech. 14 (2005) 299-319.\nRelated Articles\nPaper TitlePages\nA Study on the Process Sequence Design of a Tub for Washing Machine Container by Finite Element Analysis\nAuthors: Joong Yeon Lim, Dong Hwan Jang\nAbstract: A design methodology was applied to manufacturing a tub for washing machine container. The finite element method was employed to investigate the forming process. The forming process of sheet metal into a tub for washing machine container was selected as a model process to demonstrate the design of improved process sequence which has fewer operation stages than in conventional process. The design procedures made extensive use of the finite element method which can deal with elastic-plastic modeling. A one stage process sequence to form an initial blank to final product has been simulated to obtain information on metal flow requirements. Loading simulation for conventional manufacturing process sequence has been also simulated to evaluate the design criteria. From the simulation results of conventional process sequence, it is concluded that the design criteria should include thickness uniformity in finished tub and maximum punch load within the limit of available press capacity. The newly designed sequence has two forming operations and can achieve net-shape manufacturing, while the conventional process sequence has three forming operations. The design procedure proposed in this study could be considered for the method applied to the development of process sequence design in general.\n809\nSimulation and Experiments for Hot Forming of Rectangular Pans in Fine-Grained Aluminum Alloy AA5083\nAuthors: Paul A. Sherek, Louis G. Hector, John R. Bradley, Paul E. Krajewski, Eric M. Taleff\nAbstract: Accurate numerical simulation capability is critical to the development and implementation of hot forming technologies.  Numerical simulations were developed for gas-pressure forming of commercial, fine-grained aluminum-magnesium (AA5083) material into deep pan shapes at 450°C.  These simulations utilize a material constitutive model recently developed for fine-grained AA5083 materials as a user-defined routine in commercial Finite Element Method (FEM) software.  Results from simulations are compared against data from gas-pressure forming experiments, which used the same forming conditions and die geometries.  Specifically, local sheet thinning and radius of curvature in edges and corners are compared between simulation and experiment.  Numerical simulations are in good agreement with experiments for local sheet thinning of up to 50%.  For locations where sheet thinning exceeds 50%, simulations predict less thinning and larger formed radii than observed in experiments.  It is likely that cavitation, which is not accounted for in simulations, plays a significant role in causing a decrease in simulation prediction accuracy for thinning values greater than 50%.  This study demonstrates a simulation capability that is potentially of significant practical use for predicting the hot gas-pressure forming of fine-grained AA5083 material.\n185\nOptimization for Stamping Process Parameters of Front Fender Based on Numerical Simulation Technology\nAuthors: Zhi Feng Liu, Qi Zhang, Wen Tong Yang, Jian Hua Wang, Yong Sheng Zhao\nAbstract: According to the characteristic which is more and difficult to determine about the automotive panel forming factors, based on the dynamic explicit method, taking the typical automobile front fender for example, do the simulation analysis by using of DYNAFORM. On the premise of taking springback factors into account, analog the best stamping process parameters has been optimized from the analysis results after simulation such as sheet metal forming limited drawing(FLD)and sheet metal thinning drawing.\n232\nNumerical Simulation of the Effect of Punch Paths on the Quality of Sheet Metal Stretch Forming\nAuthors: Chang Jiang Wang, Diane J Mynors, Tarsem Sihra\nAbstract: Presented here is the simulation of uniaxial stretch forming using two punches in a sheet metal forming operation. In the finite element modelling, the sheet metal strip was held by two bank holders and two punches are able to move in two directions to stretch the sheet metal. Due to the friction between the punch and sheet metal, it was found that friction affects the sheet metal forming quality, however by adopting an optimal punch path the effect of friction in sheet metal forming can be reduced. The effect of punch paths on the quality of the sheet metal are also reported in this paper.\n2002\nNumerical Simulation and Analysis of Ironing Process for Deep Cup Shaped Workpiece\nAuthors: Li Li Huang, Xiao Yang Lu, Xiang Wei Zhang\nAbstract: The numerical simulation of the ironing process of deep cup shaped part was conducted by finite element software Deform 3D. The influences of interface friction and deformation velocity on the forming load and blank damage were studied in this paper. The simulation results showed that the forming load and damage increased obviously with the increase of the friction between the blank and cavity die. The blank damage increased and the forming load decreased with the increase of deformation velocity. These conclusions provide a reliable theoretical basis for the optimization of the ironing process of deep cup shaped part.\n191\n""","0.4575286","""https://www.scientific.net/MSF.765.368""","[-0.178219,51.500505]"
"""University_of_Aberdeen""","""‘Quite destitute and … very desirous of going to North America’: The Roots and Repercussions of Emigration from Sutherland and Caithness | Northern Scotland""","""‘Quite destitute and … very desirous of going to North America’: The Roots and Repercussions of Emigration from Sutherland and Caithness\nShare\n‘Quite destitute and … very desirous of going to North America’: The Roots and Repercussions of Emigration from Sutherland and Caithness\nAbstract\nSection:\nThis paper explores the roots and repercussions of emigration from the northern Highlands since the 1770s, through the lens of personal testimony, press accounts, estate papers, and recruitment agents' reports, along with some observations from novels and poetry. It studies the particular exodus from Scotland's two most northerly mainland counties – Sutherland and Caithness – within the wider context of Scottish emigration as a whole, and considers how settlement in Canada, the dominant destination, compares with the experiences of Highland emigrants elsewhere. The investigation has three sections, each of which follows a chronological path. It begins with the practical mechanisms through which emigration was promoted and implemented, and the attitudes that underpinned recruitment and sponsorship. The second section reflects on the attitudes of those who opposed emigration, while the third section dips into the emigrants' own testimony to analyse their motives and experiences. Overarching questions are the extent to which there were unique elements in emigration from the far north; whether the participants were passive victims in a process that was determined by others, or had agency, ambition and agendas of their own; and whether the narrative is characterised by continuity or change during the two centuries under scrutiny.\nKeywords: emigration , Highlands , diaspora , Sutherland , Caithness , Canada\nSection:\nIn early July 1773 the streets of Thurso were crowded, as the town's population was swelled by 280 would-be emigrants from Caithness and Sutherland who gathered in the expectation of imminent embarkation for North Carolina. In late August they were still there. The ship, Bachelor of Leith, on which they were booked, had been delayed on her return journey from America with a cargo of rice. The emigrants’ food supply, already depleted by that unexpected delay, was further eroded during the eighteen days it took to load the ship. When they eventually set sail, far too late in the season, they immediately ran into equinoctial gales in the Pentland Firth, which forced them first into Stromness in Orkney and then into Walls on Shetland. A second attempt to sail, after repairs, saw the ship driven onto rocks. By that time, eleven passengers had died and the rest were mostly destitute, having used up all their meagre supplies. When the Leith-based ship owner ordered the captain to leave the passengers at Thurso before bringing the ship back to her home port for repair, most refused, knowing they were unlikely either to see the vessel again or to have their fares refunded. All but twenty-eight came down to Leith and Edinburgh, where some settled, a few booked passages on other ships, and others returned to the Highlands. It was a fiasco of the first order. 1\nThe Bachelor debacle was not the only misfortune to befall emigrants from the northern Highlands. In the same year, 1773, the Nancy sailed from Meikle Ferry in the Dornoch Firth with 250 emigrants for New York, but lost eighty-one passengers, including fifty children, before it reached its destination. 2 In 1806, following the first clearance of the Strathnaver and Lairg districts of the Sutherland estate by two Northumbrian sheep farmers, Messrs Atkinson and Marshall of Alnwick, about seventy-seven families were evicted from the upper part of the strath. With no provision for their future having been made, either in terms of land to farm or a village in which to settle, many chose to emigrate, but the ship sank off Newfoundland with all 140 passengers on board. 3 Seven years later, Thomas Douglas, the fifth earl of Selkirk, was present in Stromness to witness the embarkation on the Prince of Wales of 100 emigrants from Sutherland for the colony he had recently established at Red River. Selected from 700 applicants who saw no future in their native Highlands, many were victims of the infamous Kildonan clearances. In mid-Atlantic, they had to contend with an outbreak of typhus, which led to the panic-stricken captain landing them, not at York Factory, as expected, but 150 miles away at Fort Churchill in the hostile environment of Hudson's Bay. By the time they reached Red River, more than a year had elapsed since the party had left Scotland. 4\nWhy did individuals and families put themselves through the ordeal of a transatlantic voyage which, even at the best of times, was always a major test of endurance? How was emigration perceived, by those who sponsored and opposed it, as well as by those who undertook it? Highland emigration, not least from the northernmost counties, continued to be painted in sombre hues throughout the nineteenth and twentieth centuries. It was commonly portrayed as a bedfellow and consequence of clearance and eviction, and a manifestation of the pessimistic belief that the region had only a past and not a future. Through the written and oral testimony of participants, sponsors, activists and observers, as well as through the very different lens of fictional writings, this study offers an overview of the causes and consequences of the outflow from the northern Highlands, particularly to British North America, from the time of the Bachelor's abortive voyage in 1773-4 until the mid-twentieth century. It adjudges whether emigrants were invariably hapless and helpless victims in the decision-making process, or whether they had agency, ambition and agendas of their own. It considers the nature and impact of propaganda generated by proponents and opponents of emigration alike, and debates the roots and repercussions of the return movement that was an integral, but less scrutinised, part of the whole phenomenon.\nOf course, any such evaluation is only meaningful if it is undertaken within the wider context. We need to consider how the outflow from Scotland's most northerly mainland counties fits into the bigger statistical canvas of perhaps 100,000 Scottish emigrants in the eighteenth century, and about two million in each of the two succeeding centuries. The Canadian experience, which lies at the core of the analysis, has to be compared with settlement or sojourning in other locations, within Scotland as well as overseas. The study falls into three sections, each of which follows a chronological pattern. It begins by examining the practical mechanisms of recruitment and sponsorship through which emigration was promoted and implemented, along with the attitudes that underpinned the provision of those facilities. It then reflects on the perceptions of those who opposed emigration before turning, finally, to the insights offered by the emigrants’ own testimony. Integral to each section are three overarching questions. These are: the extent to which there are unique elements to the exodus from the north of Scotland; whether that emigration was characterised more by continuity or change; and whether the verb ‘to emigrate’ should be used in the passive or active sense.\nSection:\nPersuaders and procedures\nThe unfortunate passengers on the Bachelor would not have ended up in Thurso in July 1773 if they had not been recruited by James Hogg, a tacksman who had moved from East Lothian to Caithness in 1765, and who liaised with James Inglis, the ship owner in Leith. 5 In the eighteenth century the recruitment of Highland emigrants was often in the hands of tacksmen, who were ideal brokers or intermediaries. They usually knew personally the individuals whom they were recruiting from estates from which they were all being displaced in various ways; their objective was generally to lead those people in reconstituting traditional ways of life in the New World; and they liaised with ship owners or agents in ports like Leith or Greenock to provide the transatlantic transport. Such bulk community recruitment, on an intermittent basis, distinguished Highland emigration from the more atomised and targeted movement, often of indentured servants, from the Lowlands.\nHighland emigration to North America burst onto public consciousness in the second half of the eighteenth century. Mobility did not emerge out of a complete vacuum, for Highland mercenaries (galloglas) had played a significant part in medieval and early modern military campaigns in Ireland. Seasonal – and permanent – migration from the Highlands to the Lowlands was a prominent part of Scotland's demographic fabric. The latter was perhaps most notable at New Lanark, where ‘a great proportion’ of the workforce for David Dale's cotton mill came from Caithness, Inverness and Argyll, their origins being commemorated in the street name, Caithness Row, and on gravestones in the little hilltop cemetery. 6 By the time Dale set up his mill in 1786, significant numbers of Scots had begun to take advantage of opportunities in the North American colonies created by the parliamentary union almost eighty years earlier, although statistics of overseas movement are notoriously elusive, not least because no agency on either side of the Atlantic systematically recorded departures or arrivals. The exception was an eighteen-month period from 1773 to 1775, when the government's concern about national security led it to institute an enquiry into the extent of transatlantic emigration, and to the compilation of a heavily annotated Register of Emigrants. Evidence – albeit patchy – from a variety of sources 7 suggests that around 80 per cent of Scotland's 75,000 emigrants who left between 1700 and 1780 were Lowlanders, but the balance changed radically towards the end of the century, when over 66 per cent of emigrant Scots – around 10,000 individuals – came from the Highlands. Within a wider context, Ireland experienced the heaviest numerical exodus in the eighteenth century, followed by Scotland, and then England. 8\nBy the later 1810s, when emigration began to take off again after the dislocation caused by the American, French Revolutionary and Napoleonic wars, the Highland component of Scottish emigration had increased, and the pattern of destinations had changed. Notably, following the loss of the American colonies, the spotlight shifted from North Carolina, which had been the Highlanders’ favoured destination, to Upper Canada and Nova Scotia. Recruitment mechanisms had also changed. Gone were the tacksmen-agents, and in their place came recruiters whose involvement was driven primarily by the trade in timber, imported from the Maritimes and the St Lawrence to ports right around Britain. 9 Donald Logan from Rogart, a timber merchant who had settled in Nova Scotia in 1803, saw an opportunity to harness his commercial interests to ongoing socio-economic dislocation in his native Sutherland. In 1818, after orchestrating the emigration of about 120 fellow Highlanders, who, he said, had been induced to emigrate because they had been ‘put out of their lands and otherwise rendered uncomfortable’, he petitioned the government for funding to enable him to continue the work. 10 At that time Westminster was being bombarded with petitions for state-aided emigration from all quarters, not just from the Highlands, but there was persistent pressure from the north. In the same year, 1818, we find among the petitions a similar plea from Donald Sinclair of Dunbeath, who had previously recruited emigrants on behalf of Lord Selkirk and later sent them out on his own account. He asked the government to assist the emigration of several thousand families in the north, who had been removed and their possessions turned into sheep walks. They were, he said, ‘quite destitute and … very desirous of going to North America’. 11\nSinclair's comments indicate a shift since the late eighteenth century in the balance of volition and coercion that shaped patterns of Highland emigration. His reference to destitution was corroborated and amplified by an unnamed tourist in Sutherland in 1819.\nComing on my way from Brora to Port Gorver [sic] in Sutherland, I was much shocked with the appearance of late fires in every cottage on the road. Every roof was stripped in the township of Kintredual. This is part of the immense property of the Countess of Sutherland, now Marchioness of Stafford, and had just been newly leased to a Mr Reid, formerly one of Sir John Sinclair's shepherds, for a sheep farm; so, in order to give him entire possession, 300 cottages were burnt, and at least 3000 poor creatures turned out of doors to make room for as many sheep. A Mr Gordon and a Mr Mackay, farmers in the neighbourhood, humanely came forward, and offered them all settlements on their farms. This same thing occurred a few years back at a place called Kildonan. The Earl of Selkirk happened then to be in that part of the country, and transported the outcasts all to his colony at Red river. This is more barbarous than any thing I ever heard of in Ireland or any where else. 12\nWith some minor exceptions, government aid was not forthcoming. What was provided in that era of major recession, however, was funding from landlords, who – having previously opposed emigration tooth and nail – were becoming convinced that assisted passages were the only alternative to tenant starvation, as well as proprietorial bankruptcy. According to Adam Hope, a Scots-born merchant and politician who emigrated to Upper Canada in 1834, the duke of Sutherland was to be praised for his generosity in shipping out tenants. Hope was a firm advocate of landlord-subsidised emigration as a remedy for land congestion in the Highlands, though he was sceptical about the extent of emigrant poverty. Writing to his brother George in East Lothian in 1847, at the height of the potato famine in Ireland and the Highlands, he contrasted the tidal wave of sick, destitute Irish refugees with the arrival of 287 healthy Sutherland emigrants who had been given a free passage on the Panama, a vessel which had been chartered by the duke. They had settled among fellow Sutherlanders in the township of Zorra, where, he predicted, they would be a valuable asset to the area. 13\nAdam Hope's optimism was in stark contrast to criticism in the Upper Canadian press of the subsequent arrival of 400 Sutherlanders, many ‘in destitute circumstances’ and including ‘two lunatics stark mad – who had not a single relative among their fellow-passengers’. 14 Hope's silence on the displacement of indigenous peoples also typified the ‘cultural amnesia’ of settler society. While sending home ‘Indian’ bracelets for his mother and ‘Indian’ moccasins for his sister in 1835, he was oblivious to the expropriation of Mohawk lands in the Grand River Valley for incoming colonists. 15 It is particularly ironic that Highlanders, ostensibly dispossessed to make way for sheep, were actively engaged in dispossessing indigenous peoples on the other side of the Atlantic as well as – more notoriously – in Australia. 16\nUntil the 1830s landlords who wanted to ship tenants to British North America were most likely to use the services of William Allan, who virtually monopolised recruitment from the Highlands. He was a Leith-based shipping agent who operated through a network of sub-agents – innkeepers, merchants, and postmasters – men who sold the tickets and organised steamers to take emigrants to the regional embarkation ports of Cromarty, Thurso and Lochinver. Allan was succeeded by John Sutherland and Duncan MacLennan, who also operated through sub-agents, and had good contacts in the main timber ports. Their recruitment skills, combined with widespread estate clearance policies, made it worthwhile for the owners of timber ships in Leith and Aberdeen to call at Cromarty, Scrabster and Lochinver on their outward journeys to a range of ports: particularly Quebec and Pictou, but also Sydney, Cape Breton; Charlottetown, Prince Edward Island; and New York. The northern counties were, according to the Inverness Journal in 1842, ‘peculiarly indebted’ to John Sutherland for laying on vessels locally, thus saving emigrants the expense of getting down to Greenock, and it claimed he had sent out nearly 2,000 individuals within a two-year period. 17\nJohn Sutherland, who was based in Wick, staked his claim to trustworthiness on the grounds that he had actually lived in Sydney, Nova Scotia, for twenty years, and accompanied some of his emigrant parties across the Atlantic. He was a good self-publicist, who emphasised that not only did he bring ships to the people rather than people to the ports, but also brokered farming and employment opportunities in the ‘Lower Provinces’. 18 His own pen was probably behind a lengthy ‘good news’ feature in the John O'Groat Journal in June 1849, which reported the imminent departure of a ship, the Prince Albert, from Scrabster, bound for Quebec. Readers were assured of comfortable accommodation on a well-equipped and provisioned vessel, whose passengers were, on the eve of departure, allegedly universally happy, content, and sure to succeed. 19 In the same year, 1849, Sutherland was presented with a silver snuff box, the inscription on which bore a reference to his role as a government emigration agent. That made him responsible for supervising the Passenger Acts which from 1827 to 1855 supposedly regulated conditions on emigrant ships, but in practice were of very limited effect. Indeed, perhaps all was not as it seemed even on Sutherland's vessels, for letters to the Inverness Advertiser on 11 and 18 September 1849 and 26 February 1850 complained about inadequate water, food and fuel, and cramped accommodation on the Prince Albert. These deficiencies were, according to one emigrant, far short of their statutory rights, and were ‘severely felt by the passengers’, who charged Sutherland with having ‘acted very improperly in putting them to sea in such a state’. 20 The allegation was hotly refuted by the agent in the paper's next issue, a defence which he reiterated six months later, after another damning letter had resurrected complaints about ‘bad usage’ of passengers on the Prince Albert, and warned that season's would-be emigrants to avoid the vessel which Sutherland was then preparing to send to North America. 21 The Inverness Advertiser was not particularly sympathetic towards Sutherland either, arguing that it was the newspaper's ‘bounden duty’ to publicise ‘authenticated complaints’, and suggesting that Sutherland's assurances were disingenuous. ‘Shabby shipowners can never be controlled by paper regulations of the Government, or the flying peep of their officials’, was the barbed editorial comment inserted in response to the agent's letter. 22\nFollowing the creation of the Dominion of Canada in 1867 the Canadian federal government tried to promote settlement by sending its own resident recruitment agents to Britain, Ireland, a few parts of continental Europe, and the United States. Initially the whole of Scotland was overseen by one agent, based in Glasgow; in 1907 responsibility for the north of Scotland was devolved to an Aberdeen-based agency; then in 1923, in response to increasing demand from the Highlands and Islands, a third agent was appointed, with headquarters in Inverness. Like their predecessors in the shipping business, these professional recruiters operated through a network of amateur sub-agents who arranged their public lectures in a range of locations, and usually made the actual bookings.\nBy the 1860s, of course, steam had replaced sail, embarkations were centralised on the major ports of Greenock and Liverpool, and emigration from the Highlands was a less distinctive part of a national outflow that was rooted more and more in the central belt and embraced a range of destinations, dominated by the USA. Since the highly competitive environment also saw sustained antipodean activity, the agents regularly (but fruitlessly) urged their employers in Ottawa to adopt a measure of state-funded assistance. Their frustration was articulated in 1874 by Angus Nicholson, Canada's special agent in the Highlands, when he complained that ‘the New Zealand and Australian authorities are particularly alert, the streets of every town and village being always well ornamented with their bills and placards offering free passages and other inducements to emigrants’. Moreover, he continued, ‘nearly all the newspapers being subsidised by means of their advertisements, are doing their full share in the same direction’. 23 Fifty years later, the federal government's parsimony was still at the root of the frustration of many Canadian recruiters in the field, including Anne MacDonald, one of the few female agents, who ran the Highland agency out of an office in the centre of Inverness. Following a visit to a family of would-be emigrants on a croft near Bilbster in Caithness, she complained that while she had been able to supply the husband with pamphlets, she could not give his anxious wife anything more than verbal assurance because her office had not been supplied with any relevant literature. 24 It is unlikely that the cost-cutting Canadian Immigration Department in Ottawa acceded to MacDonald's request for a supply of women's literature.\nSection:\nDisputation and denunciation\nRecruitment agents clearly peddled a positive message: their objective was to generate passengers for their ships, or settlers for the land that they owned or the employer whom they represented. But the funding challenges faced by Canada's federal agents were a minor internal irritation compared to the more fundamental external denunciation of agency activity that came from a range of vested interests. While host lands complained about being saddled with the dregs of a redundant population, donor countries and communities bewailed the spiriting away of the cream of the crop.\nAntagonism against recruiters was evident back in the eighteenth century, when they were vilified as traitors, who threatened the security and stability of the nation. As already hinted, the story of the Bachelor, like that of many other emigrant embarkations at that time, became well known primarily because landlords and the government were so worried about the rumoured extent of emigration from the Highlands – much of it allegedly stirred up by land agents – that two official enquiries were launched to try to quantify it. The second of those enquiries, commissioned by the Treasury, required customs officers at all ports in England and Scotland to submit details about each individual embarking on every emigrant ship that had left from their port in 1774 and 1775. The total of 9,868 passengers identified by that enquiry, and the evidence collected for the Register of Emigrants, so alarmed the government that in 1775 it imposed a ban on transatlantic emigration for the duration of the American War of Independence. 25\nThe government's main concern was national security, not least because the departure of Highland emigrants in particular meant a loss of potential soldiers from an area which since the mid-eighteenth century had begun to establish itself as a key recruitment nursery for the military. The landlords’ preoccupation, which pre-dated the American war and persisted for three decades after the loss of the thirteen colonies, was that emigration was threatening the implementation of estate development policies, as well as removing considerable sums of money from the Highlands. The early stages of clearance involved the internal relocation of tenants, not their complete expulsion or expatriation, and since landlords needed a substantial workforce in order to carry out their integrated ‘improvement’ policies, they opposed emigration vehemently. Some tenants were quick to see that they could use the estates’ opposition to emigration as a bargaining tool to secure favourable leases. As early as 1763, Alexander Mackenzie of Ardoch, Ledbeg, factor to the seventeenth earl of Sutherland, wrote to John Mackenzie of Delvine, one of the earl's main financial advisers and managers, about the newly acquired estate of Assynt. He had received disturbing letters from America, probably from ex-soldiers, who had just been discharged at the end of the Seven Years’ War. While these natives of Assynt hoped to secure tacks on the estate, they were determined to do so on their own terms by threatening that, if their demands were not met, they would opt instead to take up lands in the colonies directly from the Crown as part of their payment for military service. As Alexander Mackenzie wrote:\nSince my last to you from Dunrobin I had letters from some young men in America natives of Assynt proposing to get tacks on this estate, what they offer is, to add five per cent yearly to the present rent till it comes to be a fourth part more than it is now, for example, that a tack of £20 comes to £25. And when it comes to that height that they have leases for 40 or 50 years thereafter, they have brothers and other friends in the country to enter into these possessions, till they can appear themselves. How far these proposals shall please the Earl you can acquaint. 26\nBy the early nineteenth century, as we have seen, crisis management had replaced grand economic designs on many Highland estates, and this in turn significantly reshaped – indeed, totally reversed – the attitudes of proprietors and factors to population loss and retention. Assisted emigration became a key tool in tackling the problem, and was a strategy favoured in limited measure by the duke of Sutherland's advisers, as long as the estate did not have to fund it and the emigrants were superintended by agents whom they trusted. In 1817 factor Francis Suther wrote to James Loch, who was in overall charge of estate policy, to commend Allan and warn against a potentially fraudulent agent.\nI hope the government plans of assisting emigration will have some effect with Allan of Leith in inducing him to endeavour to pick up a cargo or two of the people in the Estate, unless it is him or some such person who can command money to come forward with the deposit required the plan will come to nothing … There is a person at present by the name of Fraser … I heard yesterday had gone to Strathnaver to endeavour to induce the people to go to America with him. This Fraser is from America and has come to this country for the sole purpose of taking out people. 27\nThomas Dudgeon, a farmer from Ross-shire, definitely did not have the confidence of the Sutherland estate management. Along with two associates, Messrs Gibson and Thomson, who were, respectively, a teacher at Tain Academy and the innkeeper at Meikle Ferry, Dudgeon sought to raise public subscriptions in 1819 through the formation of an organisation called the Sutherland and Transatlantic Friendly Association. He was anathema to the Sutherlands because his attacks in The Scotsman on James Loch and on Loch's protégé, Francis Suther, turned an unwelcome public spotlight on the estate clearances. 28 His interest in emigration was not inspired, according to Suther, by any concern for the emigrants, but simply in order ‘to satisfy an old grudge he has to the family’. 29 In July 1819 Suther wrote scathingly in his letter book about a meeting at Meikle Ferry to which Dudgeon had enticed, from as far away at Caithness, over 1,000 people, who were then duped into giving him money without any clear idea why. 30 The Friendly Association was suspected of having covert links with urban radicals in the south of Scotland, and therefore being a front for encouraging rebellion in the north. It was dissolved after only six months by magistrates sympathetic to the Sutherlands. 31\nThroughout the nineteenth century the main indictment of Highland emigration – and the agents who promoted it – came not from estate factors but from the growing body of press and public opinion that saw it as a morally reprehensible consequence of landlord greed, exploitation and clearance. Donald McLeod, who witnessed the clearance of the township of Rossal in Strathnaver in 1814, initially vented his anger against the Sutherland clearances in twenty-one letters published in the Edinburgh Weekly Chronicle in the 1840s. After emigrating to Woodstock, Upper Canada, he wrote Gloomy Memories in the Highlands of Scotland to counteract Mrs Harriet Beecher Stowe's Sunny Memories, which she had written from the perspective of Dunrobin Castle when she was a guest of the Countess. 32 In 1883 McLeod's Gloomy Memories were reprinted by Alexander MacKenzie in his immensely popular History of the Highland Clearances, a book in which he reinforced the theme of unwilling exile, blended with retributive justice, as exiled Highlanders exchanged domestic adversity for overseas achievement. 33 In the same decade, the Scottish Highlander newspaper was, not surprisingly, a platform for a lot of anti-emigration sentiment, including a letter from a Ross-shire emigrant, published in 1887, which warned his fellow countrymen against coming to western Canada. He wrote: ‘You will recall the Gaelic books which were distributed over the Highlands three years ago in order to recommend Manitoba and the North-West Territory? I say that if those books had been published in Hell they could not have been more full of lies than they were; because they were designed to deceive the population.’ 34\nThe theme of unjust exile continued well into the twentieth century, though by that time it displayed more of an economic and political emphasis which embraced the whole nation, not just the Highlands. Nationalist commentators were particularly vocal. From Sutherland, the Reverend Archibald Scott of Helmsdale began his letter to the Scots Independent in 1927 by attacking the government's failure to preserve the ‘vitality and virility’ of the Scottish people by obstructing the enlargement of holdings, and preferring sportsmen and sheep farmers to crofters and fishermen. Emigration was, in his opinion, ‘a token of national stupidity’, and emigrants who were lured by images of waving prairie wheat fields and sun-kissed orchards were more likely to encounter drought, pests, failed harvests, unemployment and bankruptcy. The ‘Paradise’ that was peddled in advertisements was, he said, ‘for the middlemen who exploit his labour, and for the agencies that order transport and implements, and for the banks into whose hands he falls sooner or later’. 35 Scott's denunciation of agents was reinforced three years later by a warning letter from Canada, printed in the John O'Groat Journal. In that era of international depression, agents were, the anonymous writer alleged, knowingly making fraudulent promises about better prospects on farms, whereas the reality was either unemployment or ‘very hard work, long hours and little pay’. His warning and recommendation were stark: ‘The fact is the immigration agents are telling people about a country they know nothing about from actual experience. So my advice is: stay in the Old Country if you have a job at all.’ 36\nSection:\nEmigrant testimony: expectations and experiences\nWe turn, finally, to the emigrants’ own insights into their expectations and experiences, for as the Helmsdale minister, Archibald Scott, observed, ‘The emigrated Highlander is a good correspondent’. 37 Personal testimony, written and oral, is necessarily anecdotal and uncontextualised. Handled with care, however, it can illuminate further our understanding of why, in the face of two centuries of denunciations of emigration, so many people persistently left the Highlands. Archibald Scott's adjectival use of the term ‘emigrated’ also reminds us of the need to interrogate the traditional perception that the Highlander was indeed ‘emigrated’ in the passive sense, and did not write his or her own agenda.\nTestimony given to customs officials by several passengers on the ill-fated Bachelor in 1773 indicates clearly that individual and family agency, as well as socio-economic pressure, played a part in decision-making. Sixty-year-old William Gordon, a tenant farmer on the lands of William Baillie of Rosehall in the parish of Clyne, explained succinctly the blend of dislocation and incentive that led him to leave with his extended family.\nHaving two sons already settled in Carolina, who wrote him encouraging him to come there, and finding the rents of lands raised so much … he was induced to emigrate for the greater benefit of his children being himself an old man and lame so that it was indifferent to him in what country he died. … His circumstances were greatly reduced not only by the rise of rents but by the loss of cattle, particularly in the severe winter 1771. … The lands on which he lived have often changed masters, and … the rents have been raised on every change. 38\nSimilarly, William McKay from Farr (aged thirty), confronted by low cattle prices, failed crops, and a high cost of living, ‘was encouraged to emigrate by the accounts received from his countrymen who had gone to America before him, assuring him that he might procure a comfortable subsistence in that country’. 39 Seventy-five-year-old Hector McDonald from Rogart had ‘suffered much by the death of cattle, and still more by oppressive services exacted by the factor’. At the same time ‘he was assured by some of his children already in America that his family might subsist more comfortably there’, and had therefore made up his mind to emigrate with three sons and two grandchildren. 40 The female perspective offered by Elizabeth McDonald (aged twenty-nine) was very similar. An unmarried domestic servant in Farr, she was leaving because ‘several of her friends having gone to Carolina before her, had assured her that she would get much better service and greater encouragement in Carolina than in her own country’. 41\nThat testimony is typical of the Bachelor's passengers, although we have to beware of a formulaic element in their responses, most of which seem to conform to the same template of expulsion twinned with attraction. The two most striking and recurring themes in the testimony are the dislocating effects of the commercialisation of estates in the northern Highlands, and the prospect of betterment held out by family members or acquaintances who were already settled in North Carolina. Both those general themes are maintained in emigrant testimony throughout the nineteenth century.\nThe significance of precedent, and chain migration, is equally evident when the spotlight shifted north. We have already seen how in 1818 Donald Logan from Rogart brought fellow Highlanders out to Nova Scotia where sixteen years earlier he had settled in Pictou County. 42 Studies by Alan MacNeil and Rosemary Ommer have also demonstrated the importance of family links for, respectively, Highlanders settling in Antigonish County, Nova Scotia prior to 1815, and secondary Highland migrants who moved from Cape Breton to western Newfoundland. 43 Further west the township of Zorra in Upper Canada was first established in 1820 by Sutherland emigrants, Angus and William Mackay, who then persuaded large numbers of their compatriots to join them in the 1830s and 1840s. 44 Some of those who arrived in 1830 reportedly brought significant amounts of ‘metallic currency’, 45 but by the 1840s poverty had become the driving force. That was probably the case with Hugh Mackay, of Badnabay, Lairg, who in 1847 received assistance from the second duke of Sutherland to emigrate to Zorra. Just after he arrived, he wrote, in slightly garbled tones, to commend the settlement to his brother back in Sutherland. ‘[B]elieve me John the Rea Country is nothing at all to this place[.] It is a fine country and I never saw any place to call a nice place until I came here. A man lives here when he gets no land paid much better than any Gentleman in the old country.’ 46\nThe key difference between the 1770s and the mid-nineteenth century was the deterioration of conditions in the Highlands. The passengers on the Bachelor had chosen to emigrate in order to escape unacceptable social changes which had negative economic implications for the future, and they did so in the teeth of landlord opposition. The tacksmen aimed to regain the status they had lost in the reconfiguration of Highland society. The tenants whom they recruited similarly wanted to retain, at a lower level, elements of a way of life that was being eroded. And the offer of colonial land seemed to provide that opportunity: grants were offered initially to ex-soldiers for their military service, and the facility was later extended to civilians by land speculators, land companies, and the Crown.\nIn the nineteenth century – as has been demonstrated – that element of choice was eroded by poverty, famine and clearance. Even in 1819 Donald Logan petitioned the government on the grounds that, of the displaced people whom he had assisted, ‘many were unable to pay the half of their passage and some not able to pay almost anything at all after settling their debts’. He informed Lord Bathurst that ‘several hundred of the minor tenants who understood no other line of business than farming and whose farms the proprietors have considered more lucrative to lay under sheep are removed to either waste ground or other allotments so exceedingly unsuitable as to render it alike the interest and the desire of those unhappy people to seek shelter in some more propitious quarter of the world’. 47\nBy the middle of the century the major waves of clearance and emigration were over. Retrospective evaluations in a wealth of documentation – not least newspaper editorials and the reports of select committees – highlighted the challenges of transplanting and preserving the Highlanders’ identities. Bitter memories were rekindled with particular passion during the skirmishes of the 1880s, when land reformers and protagonists of the Gaelic literary revival campaigned for the ‘Highland problem’ to be addressed. At the same time crofter witnesses to the Napier Commission drew heavily on oral tradition to construct a picture of landlord betrayal, eviction and enforced exile over a century and more. 48\nExilic lament and retributive justice are also recurring themes in Gaelic poetry and in novels concerned with Highland emigration such as George Macdonald's What's Mine's Mine or Ralph Connor's The Man from Glengarry. 49 Musically, a similar message was conveyed through the symbolism of the bagpipe invoked in Margaret Laurence's novel, The Diviners, where Piper Gunn strove to put heart into the disconsolate emigrants from Kildonan as they embarked on the Prince of Wales.\nThen Piper Gunn spoke to the people. Dolts and draggards and daft loons and gutless as gutted herring you are, he calls out in his voice like the voice of the wind from the north isles. Why do you sit on these rocks, weeping? says he. For there is a ship coming, says he, on the wings of the morning, and I have heard tell of it, and we must gather our pots and kettles and our shawls and our young ones, and go with it into a new world across the waters … Then Piper Gunn changed his music, and he played the battle music there on the rocks … Then what happened? What happened then, to all of them people there homeless on the rocks? They rose and followed! Yes, they rose, then, and they followed, for Piper Gunn's music could put the heart into them and they would have followed him all the way to hell or to heaven with the sound of the pipes in their ears. 50\nFiction, of course, provides a very different lens through which to view the history of Scotland and its diaspora, and Margaret Laurence's flashback novel is a particularly complex example of the genre. Piper Gunn is a fiction within a fiction, created by the character Christie Logan, to give his foster-daughter a sense of identity and self-esteem. As ‘one of the North Logans’, Christie's own name commemorated his Highland origins, but while as a child Morag was inspired by the romantic Highland past he portrayed, as an adult she was alienated and sceptical. It was only when visiting the Highlands that she came to accept ‘the myths are my reality’, and was enabled to integrate her constructed Scottish ancestry into a wider identity that also addressed her Métis background. The forbears of her lover, Jules Tonnerre, were allied to Louis Riel in the same romantic fashion as Morag's Highland ancestors, allowing the novel to explore relations between settler and Métis society in Manitoba. 51\nFrom the same northern side of the Moray Firth as Morag Gunn's putative ancestors, one of Neil Gunn's characters in The Grey Coast portrayed Canada in the 1920s as a place where failures went. Maggie, reflecting on the inter-war depression in the fishing industry, lamented:\nNo fishing, no croft. There remained the slums of Glasgow, or the remote world of Canada. And to Canada they all went. If you had a trade at your finger-ends you might do well; otherwise you took your chance, with a hand ever ready to turn to anything. The young fisher fellows would be the worst off of all … None of those who had gone out in the last six years had yet managed back to see the old folk. That was Canada. 52\nWhen we turn from poetry, literature and oral tradition to the personal testimony of real emigrants, we are more likely to find in their letters bold statements of hope and well-being to temper expressions of regret and nostalgia. Alex Douglas emigrated from Watten in Caithness to the vicinity of Kingston in Upper Canada, in 1840. 53 He clearly over-egged the qualities of the country in his determination to contrast the benefits of British North America with the ills of Scotland. The ‘noble St Lawrence’, he told readers of the John O'Groat Journal, ‘yields to no river in the world in beauty and usefulness’ and passed through a country with a ‘delightful appearance’. In Montreal, ‘a very handsome town’, where provisions of all kinds were very cheap, he had met ‘with the greatest civility every where’ and expressed himself ‘quite pleased with the people’. Opting not to take up the ‘excellent offers of land’ made to him there, he proceeded to Kingston, where he settled, his only regret being that he had not taken the step twenty years earlier. He concluded with this ringing endorsement:\nMany of the good folks in Scotland form most erroneous opinions regarding this country, which is anything but one teeming with savages and wild beasts. The people are fully as civilised, as with you, and the country is not pestered with beggars. Theft is unknown; and in the country, locks on their keeping places are very rare. To finish, I may add, we live better here than any man in Caithness, be his rank what it may.\nWhile Douglas's paean of praise clearly demonstrates the need for considerable caution in analysing emigrant correspondence, we should not dismiss the usefulness of letters and memoirs. Those that were written for private family consumption rather than for circulation are often more measured and realistic than their published counterparts, despite the temptation to present a positive story to those back home. In 1928 Mary Campbell emigrated from Caithness to Olds, Alberta, with her husband and two children. They went under the 3,000 Families Scheme, one of the shared funding ventures that had been introduced under the Empire Settlement Act of 1922. 54 They were warmly welcomed by Scottish neighbours, the Anglican Church and various voluntary organisations, and the Land Settlement Board supported them well with both practical advice and Christmas gifts. A year later, Mary was hopeful about the family's prospects, but also realistic, when she wrote: ‘we know that we have much more learning and living to do before we can truly say that yes, it has been worthwhile’. 55\nThe wanderlust and adventurous spirit that propelled many emigrants overseas were sometimes harnessed to precedent, specific job opportunities, and a sense of familiarity with the host land because there were already so many compatriots there. They were traits found across the world, for while British North America was the north Highlanders’ favourite destination, it did not have a monopoly on the region's emigrants. Testimony from the antipodes was just as varied as the North American letters. Dr William Sutherland wrote to his sisters in 1852 from Portland, Victoria, complaining that gold fever was a curse rather than a blessing, because of the disruption it had brought to the labour market, as everyone, not least shepherds, had fled to the mines in the hope of making a fortune. Servants were as rare as the elusive gold dust. ‘We have only one little girl to whom we give £14 per annum whom you in Thurso would hardly give house room to’, he complained. 56\nShepherding was the main employment that drew significant numbers of Scots out to Patagonia in the early twentieth century, not least from Caithness. 57 Seven of the children of William Bain, a fisherman from Lybster, went to the Santa Cruz region, where William, Donald, Angus and George owned three estancias. From the same area, letters written back to Caithness by Robert and Donald Nicolson speak of the hardships and hazards of sheep farming on the pampa. The Nicolsons also demonstrate the strong links that emigrants often maintained with their homeland, through remittances, questions about the crofting and fishing economy, visits home and – in some cases – permanent return. On 3 September 1913 Robert wrote to an unnamed brother in Scotland, that ‘Angus Bain might be home this year after shearing. I was thinking of coming myself, but I am not sure yet … Write soon and tell me how you are getting on in your croft and if Father is doing anything at the fishing.’ 58\nBack in North America, but on the other side of the border, sheep farming was also the main reason for a steady exodus of men from Assynt to Montana in the late nineteenth and early twentieth centuries. Sandy MacLeod of Ullapool recalled in an interview in 2009 that his father was one of the last in a line of sheep-herders from Coigach who had been going to that state since the 1890s. ‘I think this was probably due to the word of mouth, and people writing letters home or actually sending money so that a brother or whoever could get passage out there’, Sandy speculated. 59 According to his father, the workforce on some ranches was 50 per cent Gaelic-speaking Highlanders and 50 per cent Native Americans. When the ‘Celtic cowboys’ returned to Sutherland, as many did, their silver dollars were allegedly accepted as currency for many years in the pubs of Achiltibuie. 60\nSojourning – rather than permanent settlement – was always an integral part of the tapestry of migration, and involved women as well as men. In 1926 Minnie Anne Fraser from Halladale left her position in service with the bank manager at Dornoch to try her luck in Detroit, along with a friend from Embo. ‘I suppose just because I wanted to wander’, she replied when her daughter asked how she had become interested in America. She came back for a visit in 1932 armed with an American accent and a ticket to return. But it was not to be, for three brothers had died in 1927, followed by her father in 1930, and her mother told her that ‘home is where you are to be’. 61\nSection:\nConclusion\nPersonal testimony – written or oral – does not simply provide anecdotal padding: it can be a useful tool in the task of evaluating two centuries of emigration from Caithness and Sutherland. Firstly, it demonstrates, from the participants’ own perspective, that these northern counties maintained longstanding, vibrant and multifaceted links with the Atlantic world, as well as further afield, making the area much less isolated than it is often depicted. It therefore helps us to answer one of the overarching questions posed at the beginning of this study, for, notwithstanding the changes in processes and procedures resulting from economic and political conditions or technological developments, emigration remained a persistent part of the warp and weft of life in the northern Highlands throughout the two centuries under scrutiny. Moreover, the range of testimony adduced – from letters and literature, as well as oral recollection – demonstrates that emigrants could be both passive victims and active agents of their own destiny, an interweaving of influences which is also encapsulated in the opening title. Yet, even when Highlanders emigrated of their own volition, the legacy of clearance and expulsion cast a persistently negative shadow over their decisions, which coloured their own interpretations, as well as historiographical and literary perspectives, throughout the nineteenth and twentieth centuries.\nFinally, we need to root the exodus from Caithness and Sutherland back within the wider context of Highland, Scottish, and European emigration, and avoid making any claims for exceptionalism. The outflow from the northern counties, important though it was to donor and host communities alike, was simply part of a much bigger jigsaw of complex intercontinental mobility that was shaped by the same generic influences of persuasion and pessimism that have been examined in other contexts. 62\nNotes\n1 For discussion of the abortive voyage of the Bachelor, see Ian Adams and Meredyth Somerville, Cargoes of Despair and Hope. Scottish Emigration to North America, 1603–1803 (Edinburgh, 1993), 100–6; Bernard Bailyn, Voyagers to the West. Emigration from Britain to America on the Eve of the Revolution (London, 1986), 499–544; David Dobson, Scottish Emigration to Colonial America, 1607–1785 (Athens, GA, 2004), 158. For passenger details, see Viola Root Cameron (ed.), Emigrants from Scotland to America 1774–1775: copied from a loose bundle of Treasury papers in the Public Record Office, London, England (Baltimore, MD, 1965, originally published London, 1930).\n2 Scots Magazine, XXXV (December 1773), 667; Adams and Somerville, Cargoes of Despair and Hope, 106–7. See also Thelma W. Foote, Black and White Manhattan: The History of Racial Formation in Colonial New York City, 1624–1783 (New York and Oxford, 2003), 61–3.\n3 Eric Richards, The Leviathan of Wealth: The Sutherland Fortune in the Industrial Revolution (Abingdon, 2007, originally published 1963), 170.\n4 James Hunter, Set Adrift upon the World. The Sutherland Clearances (Edinburgh, 2015), Chapter 2.\n5 Bailyn, Voyagers to the West, 507–10.\n""","0.101616025","""http://www.euppublishing.com/doi/10.3366/nor.2017.0126""","[-2.099122,57.165019]"
"""Imperial_College_London""","""Environmental Health Perspectives – Long-Term Exposure to Ambient Air Pollution and Incidence of Postmenopausal Breast Cancer in 15 European Cohorts within the ESCAPE Project""","""Research October 2017 | Volume 125 | Issue 10\nEnviron Health Perspect; DOI:10.1289/EHP1742\nLong-Term Exposure to Ambient Air Pollution and Incidence of Postmenopausal Breast Cancer in 15 European Cohorts within the ESCAPE Project\nZorana J. Andersen,1 Massimo Stafoggia,2,3 Gudrun Weinmayr,4 Marie Pedersen,1,5 Claudia Galassi,6 Jeanette T. Jørgensen,1 Anna Oudin,7 Bertil Forsberg,7 David Olsson,7 Bente Oftedal,8 Gunn Marit Aasvang,8 Geir Aamodt,8 Andrei Pyko,3 Göran Pershagen,3 Michal Korek,3 Ulf De Faire,3 Nancy L. Pedersen,9 Claes-Göran Östenson,10 Laura Fratiglioni,11 Kirsten T. Eriksen,5 Anne Tjønneland,5 Petra H. Peeters,12,13 Bas Bueno-de-Mesquita,13,14,15 Michelle Plusquin,13 Timothy J. Key,16 Andrea Jaensch,4 Gabriele Nagel,4,17 Alois Lang,18 Meng Wang,19 Ming-Yi Tsai,19,20,21 Agnes Fournier,22,23 Marie-Christine Boutron-Ruault,22,23 Laura Baglietto,22,23 Sara Grioni,24 Alessandro Marcon,25 Vittorio Krogh,24 Fulvio Ricceri,6,26 Carlotta Sacerdote,6 Enrica Migliore,6 Ibon Tamayo-Uria,27,28,29 Pilar Amiano,28,30 Miren Dorronsoro,28,30 Roel Vermeulen,12,13,31 Ranjeet Sokhi,32 Menno Keuken,33 Kees de Hoogh,20,21 Rob Beelen,31,34 Paolo Vineis,13,35 Giulia Cesaroni,2 Bert Brunekreef,12,28 Gerard Hoek,12,31 and Ole Raaschou-Nielsen5,36\nAuthor Affiliations open\n1Centre for Epidemiology and Screening, Department of Public Health, University of Copenhagen, Copenhagen, Denmark\n2Department of Epidemiology, Lazio Regional Health Service, Local Health Unit Azienda Sanitaria Locale Roma 1 (ASL RM1), Rome, Italy\n3Institute of Environmental Medicine, Karolinska Institute, Stockholm, Sweden\n4Institute of Epidemiology and Medical Biometry, Ulm University, Ulm, Germany\n5The Danish Cancer Society Research Center, Copenhagen, Denmark\n6Unit of Cancer Epidemiology, Città della Salute e della Scienza University-Hospital and Center for Cancer Prevention (CPO), Turin, Italy\n7Occupational and Environmental Medicine, Department of Public Health and Clinical Medicine, Umeå University, Umeå, Sweden\n8Norwegian Institute of Public Health, Oslo, Norway\n9Department of Medical Epidemiology and Biostatistics, Karolinska Institute, Stockholm, Sweden\n10Department of Molecular Medicine and Surgery, Karolinska Institute, Stockholm, Sweden\n11Aging Research Center, Department of Neurobiology Care Science and Society, Karolinska Institute, Stockholm, Sweden\n12Julius Center for Health Sciences and Primary Care, University Medical Center Utrecht, Utrecht, Netherlands\n13MRC-PHE Centre for Environment and Health, Department of Epidemiology and Biostatistics, School of Public Health, Imperial College, London, UK\n14Department for Determinants of Chronic Diseases (DCD), National Institute for Public Health and the Environment (RIVM), Bilthoven, Netherlands\n15Department of Social and Preventive Medicine, Faculty of Medicine, University of Malaya, Kuala Lumpur, Malaysia\n16Cancer Epidemiology Unit, Nuffield Department of Population Health, University of Oxford, Oxford, UK\n17Agency for Preventive and Social Medicine, Bregenz, Austria\n18Vorarlberg Cancer Registry, Agency for Preventive and Social Medicine (aks), Bregenz, Austria\n19Department of Environmental and Occupational Health Sciences, University of Washington, Seattle, Washington, USA\n20Swiss Tropical and Public Health Institute, Basel, Switzerland\n21University of Basel, Basel, Switzerland\n22Centre de recherche en Épidémiologie et Santé des Populations (CESP) “Health across Generations”, Institut national de la santé et de la recherche médicale (Inserm), Université Paris-Saclay, Villejuif, France\n23Institut Gustave Roussy, Villejuif, France\n24Epidemiology and Prevention Unit, Department of Preventive and Predictive Medicine, Fondazione Istituto di ricovero e cura a carattere scientifico (IRCCS) Istituto Nazionale dei Tumori, Milan, Italy\n25Unit of Epidemiology and Medical Statistics, Department of Diagnostics and Public Health, University of Verona, Verona, Italy\n26Unit of Epidemiology, Regional Health Service Azienda Sanitaria Locale Torino 3 (ASL TO3), Grugliasco, Italy\n27ISGlobal Institute de Salut Global Barcelona, Barcelona, Spain\n28Consortium for Biomedical Research in Epidemiology and Public Health (CIBER en Epidemiología y Salud Pública–CIBERESP), Madrid, Spain\n29Universitat Pompeu Fabra, Barcelona, Spain\n30Public Health Department of Gipuzkoa, BioDonostia Research Institute, San Sebastian, Spain\n31Institute for Risk Assessment Sciences, Utrecht University, Utrecht, Netherlands\n32Centre for Atmospheric and Instrumentation Research, University of Hertfordshire, Hatfield, UK\n33Netherlands Organization for Applied Scientific Research, Utrecht, Netherlands\n34National Institute for Public Health and the Environment (RIVM), Bilthoven, Netherlands\n35Molecular and Epidemiology Unit, Human Genetics Foundation (HuGeF), Torino, Italy\n36Department of Environmental Science, Aarhus University, Roskilde, Denmark\nOf the existing studies on air pollution and breast cancer, one focused on postmenopausal women only ( Crouse et al. 2010 ), whereas the majority included data on both pre- and postmenopausal women ( Andersen et al. 2016 ; Bonner et al. 2005 ; Hart et al. 2016 ; Hystad et al. 2015 ; Lewis-Michl et al. 1996 ; Nie et al. 2007 ; Reding et al. 2015 ; Raaschou-Nielsen et al. 2011b ). It remains unclear whether associations between air pollution and breast cancer differ by menopausal status because three studies found stronger associations with postmenopausal breast cancer ( Bonner et al. 2005 ; Lewis-Michl et al. 1996 ; Nie et al. 2007 ), three found stronger associations with premenopausal breast cancer ( Andersen et al. 2016 ; Hart et al. 2016 ; Hystad et al. 2015 ), and two studies did not report air pollution estimates separately by menopausal status ( Reding et al. 2015 ; Raaschou-Nielsen et al. 2011b ).\nParticle Composition Findings\nWe present a novel finding of the relevance of the nickel and possibly the vanadium components of PM to breast cancer development ( Tables 6 and 7 , Figure 4 ; see also Figure S2). Nickel and vanadium are heavy metals, originating mainly from mixed oil-burning and industrial production emissions. The nickel component of PM10 was also the element that showed the strongest association with lung cancer incidence [HR=1.59 (95% CI: 1.12, 2.26) per 2 ng/m3] in a related ESCAPE study in 14 European cohorts ( Raaschou-Nielsen et al. 2016 ). Furthermore, our finding is consistent with those of an Italian study examining the effects of living near incinerators, which detected an increased risk of breast cancer mortality [OR=2.00 (95% CI: 1.00, 3.99)] among women living in areas with the highest (>2 ng/m3) compared with the lowest (<0.5 ng/m3) concentration of heavy metals combined, including not only nickel and vanadium but also lead, cadmium, mercury, antimony, arsenic, chromium, cobalt, copper, and manganese ( Ranzi et al. 2011 ). Nickel has been hypothesized to play a role in breast cancer development by acting as a metalloestrogen, a heavy metal that binds to estrogen receptors, mimicking actions of estrogen ( Aquino et al. 2012 ). A study of 112,379 women from the California Teachers Study in the United States (5,361 of whom developed breast cancer) failed to find an association between any of 11 estrogen disruptors (modeled at the participants’ residences) and breast cancer risk but found some evidence of association between inorganic arsenic and breast cancer in nonsmoking nonmovers and between cadmium and ER−/PR− breast cancer ( Liu et al. 2015 ). A related study in the same cohort examined the role of modeled levels of 24 mammary gland carcinogens (MGCs) at the residence and found associations between propylene oxide and vinyl chloride and overall breast cancer risk, as well as associations for acylamide, benzidine, carbon tetrachloride, ethylidene dichloride, and vinyl chloride with ER+/PR+ breast cancer and for benzene with ER−/PR− breast cancer ( Garcia et al. 2015 ). More studies with data on elemental components of PM exposures and breast cancer are needed to further explore the relevance of specific chemical compounds to breast cancer risk.\nStrengths and Limitations\nOur study benefited from a multicenter design and from a large number of women recruited from general populations from around Europe with large variations in air pollution levels, well-defined information on the most important breast cancer risk factors, and a standardized definition of breast cancer from national and regional cancer registries. Breast cancer diagnoses available from the national registry have been validated in Denmark against clinical records in a study that found that incidence data were complete, with no tumors missing and with correct data on malignancy and date of diagnosis ( Jensen et al. 2002 ); national and regional cancer registries in other similar European countries likely have data of similar quality. The major strength of our study is the standardized exposure assessment and standardized statistical analyses across all cohorts. The air pollution LUR models have been validated and were previously linked to lung cancer ( Raaschou-Nielsen et al. 2013 ). We adjusted the analyses for a number of potential confounders but found little evidence of confounding in air pollution estimates, minimizing the possibility of residual confounding in cohorts that had missing data on the confounders, typically on reproductive factors or HT use.\nA weakness of our study is the lack of data on breast cancer subtypes by ER and PR status: A recent study found that association with NO2 was limited to ER+/PR+ breast cancer [HR=1.10 (95% CI: 1.02, 1.19) per 3.6 μg/m3] ( Reding et al. 2015 ), and a similar trend, although without statistically significant effect modification, was found for PM exposures ( Hart et al. 2016 ). We lacked data on premenopausal breast cancer, and some of the most recent studies suggest stronger associations for air pollution and premenopausal breast cancer than for postmenopausal breast cancer ( Andersen et al. 2016 ; Hart et al. 2016 ; Hystad et al. 2015 ). We lacked information on mammographic screening participation, but the screening-related bias in breast cancer epidemiology (the timing of breast cancer diagnoses) is more relevant for premenopausal breast cancer. Breast cancer screening affects the timing of breast cancer diagnosis and results in an increased rate of diagnosis in the early period, the so-called incidence peak, which is compensated by lower incidence in the later period of screening after screening age. In 2003, the European Commission recommended breast cancer screening for women 50–69 y old, and in 2007, organized breast cancer screening was in place in all of the countries included in this analysis (initiated in 1974 in Austria; in the 1990s in the United Kingdom, Sweden, and Netherlands; and between 2004 and 2007 in France, Italy, and Denmark) ( Altobelli and Lattanzi 2014 ). Screening participation in 2014 varied between 57% and 80% in these countries ( Altobelli and Lattanzi 2014 ). It is not known whether women who participated in breast cancer screening would have had higher or lower air pollution at their residences, although a single Canadian study with data on mammographic screening participation found higher levels of NO2 among women who participated in screening ( Hystad et al. 2015 ). That study also found an attenuation of associations with NO2 in women participating in screening programs, but for premenopausal women only, suggesting that lack of adjustment for breast cancer screening participation would not change our results in postmenopausal women. Furthermore, we lacked data on detailed occupational exposures to chemicals that may be related to breast cancer risk apart from a crude definition of night-shift work (defined as occupation as nurse or physician) that was available in only one cohort (see Table S1). We used exposure levels in adulthood, assessed close to the time of the breast cancer diagnosis, and we lack data on early-life exposures to air pollution, specifically before and around first childbirth, which have been found to be relevant in studies on air pollution ( Bonner et al. 2005 ; Nie et al. 2007 ). Notably, active tobacco smoking early in life, particularly before first childbirth, has recently been established as a risk factor for breast cancer ( Dossus et al. 2014 ), increasing the plausibility that exposure to air pollution early in life, when mammary tissue is still in development and not fully differentiated, could be a critical factor for breast cancer carcinogenesis. Similarly, a study on occupational exposures and postmenopausal breast cancer also found that exposures to some compounds before 36 y of age were most relevant ( Labrèche et al. 2010 ).\nIn this study, we used LUR models that were developed on air pollution measurements obtained between 2008 and 2011, but we applied them to baseline addresses typically 10 to 15 y earlier, which likely resulted in some exposure misclassification. Several studies have documented stable spatial contrast of NO2 over study periods of 10–15 y ( Cesaroni et al. 2012 ; Eeftens et al. 2011 ; Gulliver et al. 2013 ). A study found stable traffic intensities on Dutch streets over a 10-y period ( Beelen et al. 2007 ), and spatial models for black smoke in the United Kingdom provided reasonable predictions going back to the 1960s ( Gulliver et al. 2011 ). In analyses of nonmovers, we found identical associations with NOx ( Table 4 ) to those found in the main analyses but with high heterogeneity between the individual cohort estimates. This finding is likely explained by the smaller exposure misclassification in nonmovers, which, as expected, resulted in detecting stronger associations than in the entire cohort, but in cohorts with HRs >1 and in two cohorts with HRs <1, which contributed to an increase in the range of HRs and to higher heterogeneity. Exposure misclassification may have also resulted from using predicted concentrations of the pollutants and from a lack of information about participants’ activity patterns. Finally, we had no data to examine associations between air pollution and breast cancer in men, limiting the generalizability of the results.\nConclusion\nIn a large, multicenter European study on long-term exposure to ambient air pollution and postmenopausal breast cancer incidence, we found suggestive evidence of an association between air pollution and incidence of postmenopausal breast cancer.\nAcknowledgements\nThis work was supported by the European Community’s Seventh Framework Programme (FP7/2007–2011) as part of the European Study of Cohorts for Air Pollution Effects (ESCAPE) (grant no. 211250) and Transport related Air Pollution and Health impacts – Integrated Methodologies for Assessing Particulate Matter (TRANSPHORM) (grant no. 243406) projects. Z.J.A. holds a grant from Novo Nordisk Foundation (NNF6935). G.W. and G.N. hold a grant from the German Cancer Aid (DKH ref. 111010). M. Pedersen holds a fellowship from the Danish Council for Independent Research (grant DFF-4004-00179). M. Plusquin was supported by a Marie Curie Intra European Fellowship within the 7th European Community Framework Programme. Financial support and mortality data for European Prospective Investigation into Cancer and Nutrition (EPIC)-MORGEN and EPIC-Prospect were received by the Dutch Ministry of Public Health, Welfare and Sport (VWS), Netherlands Cancer Registry (NKR), LK Research Funds, Dutch Prevention Funds, Dutch ZON (Zorg Onderzoek Nederland), World Cancer Research Fund (WCRF), and Statistics Netherlands (Netherlands). The EPIC-E3N cohort is supported by the Mutuelle Générale de l’Education Nationale (MGEN), the European Community; the French League against Cancer (LNCC), Gustave Roussy, and the French National Institutes for Health and Medical Research (Inserm). The data collection for Oslo Health Study (HUBRO), Norway was conducted as part of the Oslo Health Study 2000–2001 in collaboration with the Norwegian Institute of Public Health. The study used data from the Cancer Registry of Norway. The interpretation and reporting of these data are the sole responsibility of the authors, and no endorsement by the Cancer Registry of Norway is intended nor should be inferred. The authors would like to thank J. Wickmann for his efforts to coordinate the Oslo group and to assure the quality of exposure assessment in the HUBRO cohort. EPIC-Oxford is supported by CRUK C570/A16491 and C8221/A19170 and by MRC MR/M012190/1. For data sharing for EPIC-Oxford, please see https://www.ceu.ox.ac.uk/policies2 .\nReferences\nAltobelli E, Lattanzi A. 2014. Breast cancer in European Union: An update of screening programmes as of March 2014 (review). Int J Oncol 45(5):1785–1792, PMID: 25174328 , 10.3892/ijo.2014.2632 .\nAndersen ZJ, Ravnskjaer L, Andersen KK, Loft S, Brandt J, Becker T. 2016. Long-term exposure to fine particulate matter and breast cancer incidence in the Danish Nurse Cohort Study. Cancer Epidemiol Biomarkers Prev 26(3):428–430, PMID: 27913396 , 10.1158/1055-9965.EPI-16-0578 .\nAquino NB, Sevigny MB, Sabangan J, Louie MC. 2012. The role of cadmium and nickel in estrogen receptor signaling and breast cancer: Metalloestrogens or not?. J Environ Sci Health C Environ Carcinog Ecotoxicol Rev 30(3):189–224, PMID: 22970719 , 10.1080/10590501.2012.705159 .\nBeelen R, Hoek G, Fischer P, Brandt PA, van den Brunekreef B. 2007. Estimated long-term outdoor air pollution concentrations in a cohort study. Atmos Environ 41:1343–1358, 10.1016/j.atmosenv.2006.10.020 .\nBeelen R, Hoek G, Vienneau D, Eeftens M, Dimakopoulou K, Pedeli X, et al. 2013. Development of NO2 and NOx land use regression models for estimating air pollution exposure in 36 study areas in Europe – The ESCAPE project. Atmos Environ 72:10–23, 10.1016/j.atmosenv.2013.02.037 .\nBeelen R, Raaschou-Nielsen O, Stafoggia M, Andersen ZJ, Weinmayr G, Hoffmann B, et al. 2014. Effects of long-term exposure to air pollution on natural-cause mortality: an analysis of 22 European cohorts within the multicentre ESCAPE project. Lancet 383(9919):785–795, PMID: 24332274 , 10.1016/S0140-6736(13)62158-3 .\nBinachon B, Dossus L, Danjou AM, Clavel-Chapelon F, Fervers B. 2014. Life in urban areas and breast cancer risk in the French E3N cohort. Eur J Epidemiol 29(10):743–751, PMID: 25139141 , 10.1007/s10654-014-9942-z .\nBonner MR, Han D, Nie J, Rogerson P, Vena JE, Muti P, et al. 2005. Breast cancer risk and exposure in early life to polycyclic aromatic hydrocarbons using total suspended particulates as a proxy measure. Cancer Epidemiol Biomarkers Prev 14(1):53–60, PMID: 15668476 .\nBoyd NF. 2013. Mammographic density and risk of breast cancer. Am Soc Clin Oncol Educ Book 57–62, 10.1200/EdBook_AM.2013.33.e57 .\nBrody JG, Moysich KB, Humblet O, Attfield KR, Beehler GP, Rudel RA. 2007a. Environmental pollutants and breast cancer: Epidemiologic studies. Cancer 109(suppl12):2667–2711, PMID: 17503436 , 10.1002/cncr.22655 .\nBrody JG, Rudel RA, Michels KB, Moysich KB, Bernstein L, Attfield KR, et al. 2007b. Environmental pollutants, diet, physical activity, body size, and breast cancer: Where do we stand in research to identify opportunities for prevention?. Cancer 109(suppl12):2627–2634, PMID: 17503444 , 10.1002/cncr.22656 .\nCesaroni G, Porta D, Badaloni C, Stafoggia M, Eeftens M, Meliefste K, et al. 2012. Nitrogen dioxide levels estimated from land use regression models several years apart and association with mortality in a large cohort study. Environ Health 11:48, PMID: 22808928 , 10.1186/1476-069X-11-48 .\nChen F, Bina WF. 2012. Correlation of white female breast cancer incidence trends with nitrogen dioxide emission levels and motor vehicle density patterns. Breast Cancer Res Treat 132(1):327–333, PMID: 22076479 , 10.1007/s10549-011-1861-z .\nChen S-T, Lin C-C, Liu Y-S, Lin C, Hung P-T, Jao C-W, et al. 2013. Airborne particulate collected from central Taiwan induces DNA strand breaks, Poly(ADP-ribose) polymerase-1 activation, and estrogen-disrupting activity in human breast carcinoma cell lines. J Environ Sci Health A Tox Hazard Subst Environ Eng 48(2):173–181, PMID: 23043339 , 10.1080/10934529.2012.717809 .\nCrouse DL, Goldberg MS, Ross NA, Chen H, Labrèche F. 2010. Postmenopausal breast cancer is associated with exposure to traffic-related air pollution in Montreal, Canada: A case-control study. Environ Health Perspect 118(11):1578–1583, PMID: 20923746 , 10.1289/ehp.1002221 .\nCyrys J, Eeftens M, Heinrich J, Ampe C, Armengaud A, Beelen R, et al. 2012. Variation of NO2 and NOx concentrations between and within 36 European study areas: Results from the ESCAPE study. Atmos Environ 62:374–390, 10.1016/j.atmosenv.2012.07.080 .\nde Hoogh K, Wang M, Adam M, Badaloni C, Beelen R, Birk M, et al. 2013. Development of land use regression models for particle composition in twenty study areas in Europe. Environ Sci Technol 47(11):5778–5786, PMID: 23651082 , 10.1021/es400156t .\nDerSimonian R, Laird N. 1986. Meta-analysis in clinical trials. Control Clin Trials 7(3):177–188, PMID: 3802833 , 10.1016/0197-2456(86)90046-2 .\nDossus L, Boutron-Ruault M-C, Kaaks R, Gram IT, Vilier A, Fervers B, et al. 2014. Active and passive cigarette smoking and breast cancer risk: results from the EPIC cohort. Int J Cancer 134(8):1871–1888, PMID: 24590452 , 10.1002/ijc.28508 .\nEeftens M, Beelen R, de Hoogh K, Bellander T, Cesaroni G, Cirach M, et al. 2012a. Development of Land Use Regression models for PM2.5, PM2.5 absorbance, PM10 and PMcoarse in 20 European study areas; results of the ESCAPE project. Environ Sci Technol 46(20):11195–11205, PMID: 22963366 , 10.1021/es301948k .\nEeftens M, Beelen R, Fischer P, Brunekreef B, Meliefste K, Hoek G. 2011. Stability of measured and modelled spatial contrasts in NO(2) over time. Occup Environ Med 68(10):765–770, PMID: 21285243 , 10.1136/oem.2010.061135 .\nEeftens M, Hoek G, Gruzieva O, Mölter A, Agius R, Beelen R, et al. 2014. Elemental composition of particulate matter and the association with lung function. Epidemiology 25(5):648–657, PMID: 25061921 , 10.1097/EDE.0000000000000136 .\nEeftens M, Tsai MY, Ampe C, Anwander B, Beelen R, Bellander T, et al. 2012b. Spatial variation of PM2.5, PM10, PM2.5 absorbance and PMcoarse concentrations between and within 20 European study areas and the relationship with NO2 – Results of the ESCAPE project. Atmos. Environ 62:303–317, 10.1016/j.atmosenv.2012.08.038 .\nEuropean Commission (EC). 2013. Air Quality Standards. http://ec.europa.eu/environment/air/quality/standards.htm [accessed 1 September 2017].\nGarcia E, Hurley S, Nelson DO, Hertz A, Reynolds P. 2015. Hazardous air pollutants and breast cancer risk in California teachers: A cohort study. Environ Health 14:14, PMID: 25636809 , 10.1186/1476-069X-14-14 .\nGulliver J, de Hoogh K, Hansell A, Vienneau D. 2013. Development and back-extrapolation of NO2 land use regression models for historic exposure assessment in Great Britain. Environ Sci Technol 47(14):7804–7811, PMID: 23763440 , 10.1021/es4008849 .\nGulliver J, Morris C, Lee K, Vienneau D, Briggs D, Hansell A. 2011. Land use regression modeling to estimate historic (1962–1991) concentrations of black smoke and sulfur dioxide for Great Britain. Environ Sci Technol 45(8):3526–3532, 10.1021/es103821y .\nHamra GB, Laden F, Cohen AJ, Raaschou-Nielsen O, Brauer M, Loomis D. 2015. Lung cancer and exposure to nitrogen dioxide and traffic: A systematic review and meta-analysis. Environ Health Perspect 123(11):1107–1112, PMID: 25870974 , 10.1289/ehp.1408882 .\nHart JE, Bertrand KA, DuPre N, James P, Vieira VM, Tamimi RM, et al. 2016. Long-term particulate matter exposures during adulthood and risk of breast cancer incidence in the Nurses’ Health Study II prospective cohort. Cancer Epidemiol Biomarkers Prev 25(8):1274–1276, PMID: 27257091 , 10.1158/1055-9965.EPI-16-0246 .\nHiggins JPT, Thompson SG. 2002. Quantifying heterogeneity in a meta-analysis. Stat Med 21(11):1539–1558, PMID: 12111919 , 10.1002/sim.1186 .\nHuff JE, Haseman JK, DeMarini DM, Eustis S, Maronpot RR, Peters AC, et al. 1989. Multiple-site carcinogenicity of benzene in Fischer 344 rats and B6C3F1 mice. Environ Health Perspect 82:125–163, PMID: 2676495 , 10.1289/ehp.8982125 .\nHuynh S, von Euler-Chelpin M, Raaschou-Nielsen O, Hertel O, Tjønneland A, Lynge E, et al. 2015. Long-term exposure to air pollution and mammographic density in the Danish Diet, Cancer and Health cohort. Environ Health 14:31, PMID: 25879829 , 10.1186/s12940-015-0017-8 .\nHystad P, Villeneuve PJ, Goldberg MS, Crouse DL, Johnson K. 2015. Exposure to traffic-related air pollution and the risk of developing breast cancer among women in eight Canadian provinces: A case-control study. Environ. Int 74:240–248, PMID: 25454241 , 10.1016/j.envint.2014.09.004 .\nJensen AR, Overgaard J, Storm HH. 2002. Validity of breast cancer in the Danish Cancer Registry. A study based on clinical records from one county in Denmark. Eur J Cancer Prev 11(4):359–364, PMID: 12195162 , 10.1097/00008469-200208000-00007 .\nKwasny F, Madl P, Hofmann W. 2010. Correlation of air quality data to ultrafine particles (UFP) concentration and size distribution in ambient air. Atmosphere 1(1):3–14, 10.3390/atmos1010003 .\nLabrèche F, Goldberg MS, Valois M-F, Nadon L. 2010. Postmenopausal breast cancer and occupational exposures. Occup Environ Med 67(4):263–269, PMID: 20360196 , 10.1136/oem.2009.049817 .\nLewis-Michl EL, Melius JM, Kallenbach LR, Ju CL, Talbot TO, Orr MF, et al. 1996. Breast cancer risk and residence near industry or traffic in Nassau and Suffolk Counties, Long Island, New York. Arch Environ Health 51(4):255–265, PMID: 8757405 , 10.1080/00039896.1996.9936024 .\nLiu R, Nelson DO, Hurley S, Hertz A, Reynolds P. 2015. Residential exposure to estrogen disrupting hazardous air pollutants and breast cancer risk: the California Teachers Study. Epidemiology 26(3):365–373, PMID: 25760782 , 10.1097/EDE.0000000000000277 .\nLoomis D, Huang W, Chen G. 2014. The International Agency for Research on Cancer (IARC) evaluation of the carcinogenicity of outdoor air pollution: Focus on China. Chin J Cancer 33(4):189–196, PMID: 24694836 , 10.5732/cjc.014.10028 .\nMordukhovich I, Beyea J, Herring AH, Hatch M, Stellman SD, Teitelbaum SL, et al. 2016. Polymorphisms in DNA repair genes, traffic-related polycyclic aromatic hydrocarbon exposure and breast cancer incidence. Int J Cancer 139(2):310–321, PMID: 26946191 , 10.1002/ijc.30079 .\nMordukhovich I, Beyea J, Herring AH, Hatch M, Stellman SD, Teitelbaum SL, et al. 2015. Vehicular traffic–related polycyclic aromatic hydrocarbon exposure and breast cancer incidence: The Long Island Breast Cancer Study Project (LIBCSP). Environ Health Perspect 124(1):30–38, PMID: 26008800 , 10.1289/ehp.1307736 .\nMordukhovich I, Rossner P, Terry MB, Santella R, Zhang Y-J, Hibshoosh H, et al. 2010. Associations between polycyclic aromatic hydrocarbon-related exposures and p53 mutations in breast tumors. Environ Health Perspect 118(4):511–518, PMID: 20064791 , 10.1289/ehp.0901233 .\nMostofsky E, Schwartz J, Coull BA, Koutrakis P, Wellenius GA, Suh HH, et al. 2012. Modeling the association between particle constituents of air pollution and health outcomes. Am J Epidemiol 176(4):317–326, PMID: 22850792 , 10.1093/aje/kws018 .\nNie J, Beyea J, Bonner MR, Han D, Vena JE, Rogerson P, et al. 2007. Exposure to traffic emissions throughout life and risk of breast cancer: The Western New York Exposures and Breast Cancer (WEB) study. Cancer Causes Control 18(9):947–955, PMID: 17632764 , 10.1007/s10552-007-9036-2 .\nPark B, Shin A, Jung-Choi K, Ha E, Kim HJ, Park KH, et al. 2014. Correlation of breast cancer incidence with the number of motor vehicles and consumption of gasoline in Korea. Asian Pac J Cancer Prev 15(7):2959–2964, PMID: 24815431 , 10.7314/APJCP.2014.15.7.2959 .\nRaaschou-Nielsen O, Andersen ZJ, Beelen R, Samoli E, Stafoggia M, Weinmayr G, et al. 2013. Air pollution and lung cancer incidence in 17 European cohorts: Prospective analyses from the European Study of Cohorts for Air Pollution Effects (ESCAPE). Lancet Oncol 14(9):813–822, PMID: 23849838 , 10.1016/S1470-2045(13)70279-1 .\nRaaschou-Nielsen O, Andersen ZJ, Hvidberg M, Jensen SS, Ketzel M, Sørensen M, et al. 2011a. Lung cancer incidence and long-term exposure to air pollution from traffic. Environ Health Perspect 119(6):860–865, PMID: 21227886 , 10.1289/ehp.1002353 .\nRaaschou-Nielsen O, Andersen ZJ, Hvidberg M, Jensen SS, Ketzel M, Sørensen M, et al. 2011b. Air pollution from traffic and cancer incidence: A Danish cohort study. Environ Health 10:67, PMID: 21771295 , 10.1186/1476-069X-10-67 .\nRaaschou-Nielsen O, Beelen R, Wang M, Hoek G, Andersen ZJ, Hoffmann B, et al. 2016. Particulate matter air pollution components and risk for lung cancer. Environ Int 87:66–73, PMID: 26641521 , 10.1016/j.envint.2015.11.007 .\nRanzi A, Fano V, Erspamer L, Lauriola P, Perucci CA, Forastiere F. 2011. Mortality and morbidity among people living close to incinerators: a cohort study based on dispersion modeling for exposure assessment. Environ Health 10:22, PMID: 21435200 , 10.1186/1476-069X-10-22 .\nReding KW, Young MT, Szpiro AA, Han CJ, DeRoo LA, Weinberg C, et al. 2015. Breast cancer risk in relation to ambient air pollution exposure at residences in the Sister Study Cohort. Cancer Epidemiol Biomarkers Prev 24(12):1907–1909, PMID: 26464427 , 10.1158/1055-9965.EPI-15-0787 .\nReynolds P, Hurley S, Goldberg DE, Anton-Culver H, Bernstein L, Deapen D, et al. 2004. Regional variations in breast cancer among california teachers. Epidemiology 15(6):746–754, PMID: 15475725 , 10.1097/01.ede.0000134863.45834.50 .\nvan der Heijden GJMG, Donders ART, Stijnen T, Moons KGM. 2006. Imputation of missing values is superior to complete case analysis and the missing-indicator method in multivariable diagnostic research: A clinical example. J Clin Epidemiol 59(10):1102–1109, PMID: 16980151 , 10.1016/j.jclinepi.2006.01.015 .\nViana M, Kuhlbusch T., Querol X, Alastuey A, Harrison RM, Hopke PK, et al. 2008. Source apportionment of particulate matter in Europe: A review of methods and results. J Aerosol Sci 39(10):827–849, 10.1016/j.jaerosci.2008.05.007 .\nWang F, Ketzel M, Ellermann T, Wåhlin P, Jensen SS, Fang D, et al. 2010. Particle number, particle mass and NOx emission factors at a highway and an urban street in Copenhagen. Atmos Chem Phys 10(6):2745–2764, 10.5194/acp-10-2745-2010 .\nWang M, Beelen R, Stafoggia M, Raaschou-Nielsen O, Andersen ZJ, Hoffmann B, et al. 2014. Long-term exposure to elemental constituents of particulate matter and cardiovascular mortality in 19 European cohorts: Results from the ESCAPE and TRANSPHORM projects. Environ Int 66:97–106, PMID: 24561271 , 10.1016/j.envint.2014.01.026 .\nWei Y, Davis J, Bina WF. 2012. Ambient air pollution is associated with the increased incidence of breast cancer in US. Int J Environ Health Res 22(1):12–21, PMID: 21644128 , 10.1080/09603123.2011.588321 .\nWhite AJ, Chen J, Teitelbaum SL, McCullough LE, Xu X, Hee Cho Y, et al. 2016. Sources of polycyclic aromatic hydrocarbons are associated with gene-specific promoter methylation in women with breast cancer. Environ Res 145:93–100, PMID: 26671626 , 10.1016/j.envres.2015.11.033 .\nWHO (World Health Organization). 1955. International Statistical Classification of Diseases 7th Revision. Geneva, Switzerland:World Health Organization. http://apps.who.int/iris/bitstream/10665/130913/1/EB17_34_eng.pdf [accessed 1 September 2017].\nWHO. 1977. International Statistical Classification of Diseases 9th Revision. Geneva, Switzerland:World Health Organization. http://apps.who.int/iris/handle/10665/40492 [accessed 1 September 2017].\nWHO. 1990. International Statistical Classification of Diseases 10th Revision. Geneva, Switzerland:World Health Organization. http://apps.who.int/classifications/icd10/browse/2016/en [accessed 1 September 2017].\nWHO. 2006. Air quality guidelines. Global update 2005. Particulate matter, ozone, nitrogen dioxide and sulfur dioxide. Geneva, Switzerland:WHO. http://www.who.int/phe/health_topics/outdoorair/outdoorair_aqg/en/ [accessed 1 September 2017].\nYaghjyan L, Arao R, Brokamp C, O’Meara ES, Sprague BL, Ghita G, et al. 2017. Association between air pollution and mammographic breast density in the Breast Cancer Surveillance Consortium. Breast Cancer Res 19(1):36, PMID: 28381271 , 10.1186/s13058-017-0828-3 .\nHighlighted Sections\n""","0.14712417","""https://ehp.niehs.nih.gov/EHP1742/""","[-0.178219,51.500505]"
"""Imperial_College_London""","""A Risk-Based Method for Modeling Traffic Fatalities - Bhalla - 2007 - Risk Analysis - Wiley Online Library""","""A Risk-Based Method for Modeling Traffic Fatalities\nAuthors\nCited by (CrossRef): 18 articles Check for updates\nCitation tools\n*Address correspondence to Kavi Bhalla, Harvard Initiative for Global Health, 104 Mt. Auburn Street, Cambridge, MA 02138, USA; tel: 617-233-7700; kavi_bhalla@harvard.edu .\nAbstract\nWe describe a risk-based analytical framework for estimating traffic fatalities that combines the probability of a crash and the probability of fatality in the event of a crash. As an illustrative application, we use the methodology to explore the role of vehicle mix and vehicle prevalence on long-run fatality trends for a range of transportation growth scenarios that may be relevant to developing societies. We assume crash rates between different road users are proportional to their roadway use and estimate case fatality ratios (CFRs) for the different vehicle-vehicle and vehicle-pedestrian combinations. We find that in the absence of road safety interventions, the historical trend of initially rising and then falling fatalities observed in industrialized nations occurred only if motorization was through car ownership. In all other cases studied (scenarios dominated by scooter use, bus use, and mixed use), traffic fatalities rose monotonically. Fatalities per vehicle had a falling trend similar to that observed in historical data from industrialized nations. Regional adaptations of the model validated with local data can be used to evaluate the impacts of transportation planning and safety interventions, such as helmets, seat belts, and enforcement of traffic laws, on traffic fatalities.\nArticles related to the one you are viewing\nCiting Literature\nNumber of times cited: 18\n1\nGeetam Tiwari, Deepty Jain, Kalaga Ramachandra Rao, Impact of public transport and non-motorized transport infrastructure on travel mode shares, energy, emissions and safety: Case of Indian cities, Transportation Research Part D: Transport and Environment, 2016, 44, 277\nCrossRef\n5\nHuan He, Nino Paichadze, Adnan A. Hyder, David Bishai, Economic development and road traffic fatalities in Russia: analysis of federal regions 2004–2011, Injury Epidemiology, 2015, 2, 1\nCrossRef\n6\nTeik Hua Law, Factors associated with the relationship between non-fatal road injuries and economic growth, Transport Policy, 2015, 42, 166\nCrossRef\n7\nSamuel Nunn, William Newby, Landscapes of Risk: The Geography of Fatal Traffic Collisions in Indiana, 2003 to 2011, The Professional Geographer, 2015, 67, 2, 269\nCrossRef\n8\nRonan Doorley, Vikram Pakrashi, Bidisha Ghosh, Quantifying the Health Impacts of Active Travel: Assessment of Methodologies, Transport Reviews, 2015, 35, 5, 559\nCrossRef\n9\nJason Thompson, Giovanni Savino, Mark Stevenson, Reconsidering the Safety in Numbers Effect for Vulnerable Road Users: An Application of Agent-Based Modeling, Traffic Injury Prevention, 2015, 16, 2, 147\nCrossRef\n10\nJunrui Xu, James H. Lambert, Risk-Cost-Benefit Analysis for Transportation Corridors with Interval Uncertainties of Heterogeneous Data, Risk Analysis, 2015, 35, 4, 624\nWiley Online Library\n11\nVeronica Conti, Anjali Mahendra, Assessments of Health Impacts of Transportation Projects in an Urban Indian Context, Transportation Research Record: Journal of the Transportation Research Board, 2014, 2452, 81\n12\nCameron A. MacKenzie, Summarizing Risk Using Risk Measures and Risk Indices, Risk Analysis, 2014, 34, 12, 2143\nWiley Online Library\n13\nAhmed Anwaar, Panagiotis Anastasopoulos, Ghim Ping Ong, Samuel Labi, Mouyid Bin Islam, Factors Affecting Highway Safety, Health Care Services, and Motorization—An Exploratory Empirical Analysis using Aggregate Data, Journal of Transportation Safety & Security, 2012, 4, 2, 94\nCrossRef\n14\nTeik Hua Law, Robert B. Noland, Andrew W. Evans, The sources of the Kuznets relationship between road fatalities and economic growth, Journal of Transport Geography, 2011, 19, 2, 355\nCrossRef\n15\nRoni Factor, Gad Yair, David Mahalel, Who by Accident? The Social Morphology of Car Accidents, Risk Analysis, 2010, 30, 9, 1411\nWiley Online Library\n16\nTeik Hua Law, Robert B. Noland, Andrew W. Evans, Factors associated with the relationship between motorcycle deaths and economic growth, Accident Analysis & Prevention, 2009, 41, 2, 234\nCrossRef\n17\nKavi Bhalla, Saeid Shahraz, David Bartels, Jerry Abraham, Methods for developing country level estimates of the incidence of deaths and non-fatal injuries from road traffic crashes, International Journal of Injury Control and Safety Promotion, 2009, 16, 4, 239\nCrossRef\n18\nJames Woodcock, Phil Edwards, Cathryn Tonne, Ben G Armstrong, Olu Ashiru, David Banister, Sean Beevers, Zaid Chalabi, Zohir Chowdhury, Aaron Cohen, Oscar H Franco, Andy Haines, Robin Hickman, Graeme Lindsay, Ishaan Mittal, Dinesh Mohan, Geetam Tiwari, Alistair Woodward, Ian Roberts, Public health benefits of strategies to reduce greenhouse-gas emissions: urban land transport, The Lancet, 2009, 374, 9705, 1930\n""","0.5449349","""http://onlinelibrary.wiley.com/doi/10.1111/j.1539-6924.2006.00864.x/abstract""","[-0.178219,51.500505]"
"""Imperial_College_London""","""Agglomeration, accessibility and productivity: Evidence for large metropolitan areas in the USUrban Studies - Patricia C Melo, Daniel J Graham, David Levinson, Sarah Aarabi, 2017""","""PDF\nAbstract\nThis paper estimates the productivity gains from agglomeration economies for a sample of the largest metropolitan areas in the United States using measures of urban agglomeration based on employment density and employment accessibility. The latter is a more accurate measure of economic proximity and allows testing for the spatial decay of agglomeration effects with increasing travel time. We find that the productivity gains from urban agglomeration are consistent between measures, with elasticity values between 0.07 and 0.10. The large majority of the productivity gains occur within the first 20 minutes, and do not appear to exhibit significant nonlinearities.\nReferences\nSection:\nCarlino GA, Voith R (1992) Accounting for differences in aggregatestate productivity. Regional Science and Urban Economics 22: 597–617. Google Scholar Crossref\nChamberlain G (1982) Multivariate regression models for panel data. Journal of Econometrics 1: 5–46. Google Scholar Crossref\nChatman DG, Noland RB (2014) Transit service, physical agglomeration and productivity in US metropolitan areas. Urban Studies 51: 917–937. Google Scholar Link\nCiccone A (2002) Agglomeration effects in Europe. European Economic Review 46: 213–227. Google Scholar Crossref\nCiccone A, Hall RE (1996) Productivity and the density of economic activity. American Economic Review 86: 54–70. Google Scholar\nCombes P-P, Duranton G, Gobillon L, . (2010) Estimating agglomeration economies with history, geology, and worker effects. In: Glaeser EL (ed.) Agglomeration Economics. Chicago, IL: University of Chicago Press, 15–65. Google Scholar Crossref\nDi Addario S, Patacchini E (2008) Wages and the city. Evidence from Italy. Labour Economics 15: 1040–1061. Google Scholar Crossref\nFingleton B (2003) Increasing returns: Evidence from local wage rates in Great Britain. Oxford Economic Papers 55: 716–739. Google Scholar Crossref\nFingleton B (2006) The new economic geography versus urban economics: An evaluation using local wage rates in Great Britain. Oxford Economic Papers 58: 501–530. Google Scholar Crossref\nFujita MM, Thisse J-F (2002) Economics of Agglomeration-Cities, Industrial Location and Regional Growth. Cambridge: Cambridge University Press. Google Scholar Crossref\nGlaeser EL, Gottlieb JD (2009) The wealth of cities: Agglomeration economies and spatial equilibrium in the United States. Journal of Economic Literature 47: 983–1028. Google Scholar Crossref\nGlaeser EL, Kolko J, Saiz A (2001) Consumer city. Journal of Economic Geography 1: 27–50. Google Scholar Crossref\nGlaeser EL, Mare DC (2001) Cities and skills. Journal of Labor Economics 19: 316–342. Google Scholar Crossref\nGlaeser EL, Resseger MG (2010) The complementarity between cities and skills. Journal of Regional Science 50: 221–244. Google Scholar Crossref\nGraham DJ (2007) Variable returns to urbanization and the effect of road traffic congestion. Journal of Urban Economics 62: 103–120. Google Scholar Crossref\nGraham DJ, Dender KV (2011) Estimating the agglomeration benefits of transport investments: Some tests for stability. Transportation 38: 409–426. Google Scholar Crossref\nHoll A (2012) Market potential and firm-level productivity in Spain. Journal of Economic Geography 12: 1191–1215. Google Scholar Crossref\nHuang J, Levinson DM (2015) Circuity in urban transit networks. Journal of Transport Geography 48: 145–153. Google Scholar Crossref\nKarl TR, Koss WJ (1984) Regional and national monthly, seasonal, and annual temperature weighted by area, 1895–1983. Historical Climatology Series 4–3. Asheville, NC: National Climatic Data Center. Google Scholar\nKawashima T (1975) Urban agglomeration economies in manufacturing industries. Papers in Regional Science 34: 157–175. Google Scholar Crossref\nKrugman P (1991) Geography and Trade. London: MIT Press. Google Scholar\nLall SV, Shalizi Z, Deichmann U (2004) Agglomeration economies and productivity in Indian industry. Journal of Development Economics 73: 643–673. Google Scholar Crossref\nLe Néchet F, Melo PC, Graham DJ (2012) The role of transport induced agglomeration effects on firm productivity in mega-city regions: Evidence for Bassin Parisien. Transportation Research Record: Journal of the Transportation Research Board 2307: 21–30. Google Scholar Crossref\nLevinson D (2012) Network structure and city size. PLoS One 7(1): e29721. DOI:10.1371/journal.pone.0029721. Google Scholar Crossref\nLevinson D, El-Geneidy A (2009) The minimum circuity frontier and the journey to work. Regional Science and Urban Economics 39: 732–738. Google Scholar Crossref\nMckenzie B (2015) Who drives to work? Commuting by automobile in the United States: 2013. American Community Survey Reports. Washington, DC: US Bureau of the Census. Google Scholar\nMckenzie B, Rapino M (2011) Commuting in the United States: 2009. American Community Survey Reports, ACS-15. Washington, DC: US Census Bureau. Google Scholar\nMelo PC, Graham DJ (2009) Agglomeration economies and labour productivity: Evidence from longitudinal worker data for GB’s travel-to-work areas. SERC Discussion Paper 31, pp. 1–48. Google Scholar\nMoomaw RL (1983) Is population scale a worthless surrogate for business agglomeration economies? Regional Science and Urban Economics 13: 525–545. Google Scholar Crossref\nMoretti E (2004a) Estimating the social return to higher education: Evidence from longitudinal and repeated cross-sectional data. Journal of Econometrics 121: 175–212. Google Scholar Crossref\nMoretti E (2004b) Human capital externalities in cities. In: Henderson JV, Thisse JF (eds) Handbook of Regional and Urban Economics. Amsterdam: North-Holland, pp. 2243–2291. Google Scholar\nMundlak Y (1978) On the pooling of time series and cross section data. Econometrica 46: 69–85. Google Scholar Crossref\nOwen A, Levinson DM (2014) Access Across America: Transit 2014. Report no. CTS 14-11, 1-104. Accessibility Observatory, University of Minnesota. Google Scholar\nRauch JE (1993) Productivity gains from geographic concentration of human capital: Evidence from the cities. Journal of Urban Economics 34: 380–400. Google Scholar Crossref\nRice P, Venables AJ, Patacchini E (2006) Spatial determinants of productivity: Analysis for the regions of Great Britain. Regional Science and Urban Economics 36: 727–752. Google Scholar Crossref\nRoback J (1982) Wages, rents, and the quality of life. Journal of Political Economy 90: 1257–1278. Google Scholar Crossref\nRosenthal SS, Strange WC (2008) The attenuation of human capital spillovers. Journal of Urban Economics 64: 373–389. Google Scholar Crossref\nRuppert D, Wand MP, Carroll RJ (2003) Semiparametric Regression. Cambridge: Cambridge University Press. Google Scholar Crossref\nWood SN (2006) Generalized Additive Models: An Introduction with R. Boca Rantom, FL: Chapman and Hall/CRC. Google Scholar\n""","0.30624494","""http://journals.sagepub.com/doi/10.1177/0042098015624850""","[-0.178219,51.500505]"
"""Imperial_College_London""","""The Effect of Process and Model Parameters in Temperature Prediction for Hot Stamping of Boron SteelAdvances in Mechanical Engineering - Chaoyang Sun, Qian Bai, Jianguo Lin, Takeki Matsumoto, Trevor A. Dean, 2013""","""Abstract\nSection:\nFinite element models of the hot stamping and cold die quenching process for boron steel sheet were developed using either rigid or elastic tools. The effect of tool elasticity and process parameters on workpiece temperature was investigated. Heat transfer coefficient between blank and tools was modelled as a function of gap and contact pressure. Temperature distribution and thermal history in the blank were predicted, and thickness distribution of the blank was obtained. Tests were carried out and the test results are used for the validation of numerical predictions. The effect of holding load and the size of cooling ducts on temperature distribution during the forming and the cool die quenching process was also studied by using two models. The results show that higher accuracy predictions of blank thickness and temperature distribution during deformation were obtained using the elastic tool model. However, temperature results obtained using the rigid tool model were close to those using the elastic tool model for a range of holding load.\n1. Introduction\nSection:\nHot stamping of boron alloyed steels is a process for manufacturing high strength, lightweight, and sheet metal parts. It plays a major role in the automobile manufacturing industry, where the aim is to reduce vehicle weight while enhancing strength, particularly of safety-relevant parts [ 1 ]. In the process, a heated blank sheet is simultaneously formed and quenched by pressing it between unheated tools. The strong martensitic structure thus produced enables components of thinner gauge to be substituted for conventionally cold formed weaker parts. The process comprises coupled thermomechanical forming to obtain an intended phase transformation [ 2 ], which strongly depends on temperature history and mechanical deformation [ 3 ]. Therefore, the prediction of product properties arising from the manufacturing process requires detailed knowledge of heat transfer during the entire manufacturing process, which includes hot forming and cool die quenching from approximately 900°C to room temperature [ 4 ].\nCoupled thermomechanical analysis has been used to predict material behaviour during the hot stamping process [ 5 ]. In the coupled system, interaction between mechanical and thermal fields must be considered. Knowledge of temperature and strain rate dependent material flow behaviour is also required to characterise the plastic deformation. Heat transfer between the blank and the tools as well as heat loss due to convection and radiation from the blank is essential for accurate FE thermomechanical analyses. Recently, FE simulation using proprietary software such as LS-DYNA, Auto-Form, PamStamp, and ABAQUS was used to analyse the hot stamping process. For example, analysis using the FE software LS-DYNA was performed using thermally coupled mechanical shell elements for the metal sheet [ 3 ].\nTemperature distribution and history have a significant effect on microstructural evolution and hence mechanical properties [ 6 – 8 ], within a formed part therefore, accurate prediction of temperature in a blank plays a very important role in FE simulation. Temperature with a blank depends on starting temperature, temperature changes during transport, and temperature transfer at the tool interface. Therefore, knowledge of the value of the boundary condition, tool/workpiece heat transfer coefficient, is necessary for prediction of the temperature field [ 3 ]. An experimental procedure to estimate the thermal conductance at the blank to tool interface during a hot stamping procedure has been presented [ 9 ]. In their research temperature change of the dies was obtained, and the heat transfer coefficient between the steel blank and dies for different materials was identified. It has been found that heat transfer coefficient strongly depends on contact pressure at the interface [ 10 ].\nWith regard to tool definition in FE simulation, the hot stamping of a U-channel with 22MnB5 boron steel has been simulated using thermal shell elements to define the tools [ 4 ]. Due to the finite thickness of shell elements, the FE model with shell element tools cannot be used to describe the heat transfer phenomenon. Akerström et al. [ 5 ] have used rigid solid element tools to simulate the hot stamping process. However, the elastic deformation of tools cannot be predicted using rigid elements.\nTo obtain maximum strength and hardness, a work-piece must be quenched in the tools rapidly and this requires the temperature of the tools to be low. In mass production frequent contact of workpiece and tools under pressure causes tool temperature to rise and thus quench rate to fall. Therefore, to ensure that tool temperature is always low enough for the quench rate to be sufficient to obtain the desired phase transformation, the tools are cooled normally using water flowing in subsurface cooling ducts [ 11 ]. More efficient cooling is obtained by increasing the total cross-sectional area of the cooling ducts and situating them as close as possible to the tool surface, and, in general, the size and disposition of the ducts are limited by tool strength considerations. However, the size and disposition of cooling ducts often are based on knowledge and intuition; hence the aim of the work described in this paper is to demonstrate a methodology using finite element modelling and simulation to study the effect of tools with cooling ducts and process conditions on tool/workpiece heat transfer and tool temperature when hot stamping boron steel.\nGenerally tools can be modelled as rigid or elastic parts and an FE model with rigid tools costs less computational time. However, elastic tool deformation will affect tool/workpiece contact pressure distribution and tool/workpiece clearance, which will affect heat conduction. Therefore the use of elastic tools is likely to result in greater accuracy, particularly for high forming loads. For comparison, forming with either rigid or elastic tools has been simulated. Heat loss prior to forming and during forming is calculated using mathematical models taken from the literature.\nIn order to determine the thermomechanical characteristics of 22MnB2 steel, a set of dislocation-based hardening constitutive equations was embedded in FE software. The FE model was validated by comparing experimental and FE results, for temperature distribution and workpiece thickness distribution. Also the effect of forming load on heat transfer was investigated.\n2. Experimental Setup and Method\nSection:\nThe blank material was boron steel of initial thickness 1.6 mm. The length and the width of the blank were 120 mm and 100 mm, respectively. As shown in Figure 1 , the tool set consisted of a punch and a die of constant dimensions along their length. Three cooling ducts were located in the punch, and four cooling ducts were located in the die. The material of the tools was H13 steel. The geometric dimensions of the die and the punch are as shown in Figure 1 . By increasing the number and the size of the cooling ducts, the cooling rate of the blank during the cool die holding period could be increased. However, on the other hand, a smaller number and size of cooling ducts would reduce the elastic deformation of the tools, that is, die deflection, during the forming process and also tool stresses. In this study, the cooling ducts had a radius of 3.5 mm and the minimum distance between the nearest duct surface and tool surface was 10 mm. The ducts were filled with flowing water.\n""","0.31939775","""http://journals.sagepub.com/doi/10.1155/2013/829379""","[-0.178219,51.500505]"
"""University_of_Glasgow""","""Homogeneous charge compression ignition in lowering soot and other emissions for internal combustion engines  - Enlighten: Publications""","""Enlighten: Publications\nIn this section\nHomogeneous charge compression ignition in lowering soot and other emissions for internal combustion engines\nSherazi, H. and Li, Y. (2012)     Homogeneous charge compression ignition in lowering soot and other emissions for internal combustion engines.                   In: Paul, M.C. (ed.) Soot: Sources, Formation and Health Effects. Nova Science Publishers, pp. 179-196.          ISBN 9781619429413\nFull text not currently available from Enlighten.\nPublisher's URL: https://www.novapublishers.com/catalog/product_info.php?products_id=31939\nAbstract\nAir pollution and global warming are two challenging issues that scientists and engineers are currently tackling with high priority. Within the automotive industry, these challenges mainly lie in reducing vehicle exhaust emissions and improving fuel and combustion efficiency. In this chapter, problems concerning exhaust emissions of soot, NOx, CO2, and unburned hydrocarbons from an internal combustion engine (ICE) are discussed first, including laws and regulations governing emission levels in various countries. Further, analysis is made on the recent shift from increasing mechanical power while maintaining fuel consumption to significantly reducing fuel consumption and emissions while maintaining power. Methods to reduce emissions and to improve performance in conventional engines are also discussed. The chapter then focuses on the latest development in ignition and combustion technology for new engine types. Homogeneous charge compression ignition (HCCI) which combines the concepts and advantages of petrol and diesel engines is discussed in detail. The combustion temperature of HCCI is about 500K below conventional diesel and spark ignition engines. As a result, an HCCI engine emits near zero levels of soot or particulate matter and achieves about 90-98% reduction in NOx raw emissions.\nItem Type:\n""","0.92643017","""http://eprints.gla.ac.uk/90115/""","[-4.28836,55.871751]"
"""University_of_Lancaster""","""An agent-based vehicle routing simulation tool for road networks with time-variant data - Research Portal | Lancaster University""","""An agent-based vehicle routing simulation tool for road networks with time-variant data\nResearch output: Contribution in Book/Report/Proceedings › Paper\nPublished\nProceedings of the 27th European Simulation and Modeling Conference\nPlace of Publication\n27th Annual European Simulation and Modelling Conference - Lancaster, United Kingdom\nConference\n27th Annual European Simulation and Modelling Conference\nCountry\n27th Annual European Simulation and Modelling Conference\nCountry\n23/10/13 → 25/10/13\nAbstract\nSimulation modeling is one of the analytic techniques commonly used for transportation management; it includes such activities as route planning and post-operation analysis. One of the simulation methods, agent-based simulation, has become increasingly popular due to the availability of good micro-level data collected through technologies such as GPS-enabled devices and road sensors. This paper presents the design and implementation of an agent-based simulation tool that can be used to analyse vehicle routing algorithms. We demonstrate how the tool can be used in practice by implementing two vehicle routing algorithms: shortest-path and LANTIME. LANTIME is an algorithm that can be used to minimize CO2 emissions.\nLancaster University Bailrigg Lancaster United Kingdom LA1 4YW\n+44 (0)1524 65201\n""","0.9201484","""http://www.research.lancs.ac.uk/portal/en/publications/an-agentbased-vehicle-routing-simulation-tool-for-road-networks-with-timevariant-data(bb842266-f5b8-4491-858c-1ce2901a30c5).html""","[-2.787729,54.010394]"
"""The_University_of_Edinburgh""","""Energy and carbon audit of a rooftop wind turbineProceedings of the Institution of Mechanical Engineers, Part A: Journal of Power and Energy - R. K. Rankine, J. P. Chick, G. P. Harrison, 2006""","""Department of Trade and Industry. The renewables obligation order 2002, 2002 (Stationary Office, London). Google Scholar\n2.\nBialek, J. W. Attempts to introduce locational marginal loss charging in the UK. 6th International Conference Advances in Power System Control, Operation and Management, vol. 1, Hong Kong, 11–14 November 2003, pp. 108–116. Google Scholar\n3.\nJamasb, T., Nuehoff, K., Newberry, D., Pollitt, M. Long-term framework for electricity distribution access charges, March 2005 (Office of Gas and Electricity Markets, London). Google Scholar\n4.\nInternational Federation of Institutes for Advanced Studies. Workshop report energy analysis and economics. Res. Energy, 1978, 1, 151–204. Google Scholar , Crossref\n5.\nMcCulloch, M., Raynolds, M., Laurie, M. Life cycle value assessment of a wind turbine, 2000 (Pembina Institute for Appropriable Development, Alberta, Canada), available from www.pembina.org/pdf/publications/windlcva.pdf Google Scholar\n6.\nSchleisner, L. Life cycle assessment of a wind farm and related externalities. Renew. Energy, 2000, 20, 279–288. Google Scholar , Crossref\n7.\nElsam Engineering A/S. Life cycle assessment of offshore and onshore sited wind power plants based on Vestas V80-2.0MW turbines, 2004 (Vestas Wind Power Systems A/S, Randers, Denmark), available from www.vestas.com Google Scholar\n8.\nSociety of Environmental Toxicology and Chemistry. A conceptual framework for life-cycle impact assessment, 1992, Workshop report, Sandestin, Florida, USA (Society of Environmental Toxicology and Chemistry, Florida). Google Scholar\n9.\nHunkler, D., Rebitzer, G. The future of life cycle assessment. Int. J. Life Cycle Anal., 2005, 10 (5), 305–308. Google Scholar , Crossref\n10.\nCiambrone, D. F. Environmental life cycle analysis, 1997 (CRC Press, New York). Google Scholar\n11.\nRenewable Devices Ltd. SWIFT rooftop wind energy system product data sheet, 2006 (Renewable Devices, Edinburgh), available from www.renewabledevices.com/swift Google Scholar\n12.\nDepartment of Trade and Industry. UK energy in brief, 2005 (DTI, London). Google Scholar\n13.\nDutton, A. G., Halliday, J. A., Blanch, M. J. The feasibility of building-mounted/integrated wind turbines (BUWTs): Achieving their potential for carbon emission reductions. Final Report, 4 May 2005, p. 109. Google Scholar\n14.\nMertens, S. The energy yield of roof mounted wind turbines. Wind Eng., 2003, 27 (6), 507–518. Google Scholar , Link\n15.\nManwell, J. F., McGowan, J. G., Rogers, A. L. Wind energy explained: theory, design and application, 2002 (J. Wiley & Sons, Chichester). Google Scholar , Crossref\n16.\nHarrison, G. P., Wallace, A. R. Climate sensitivity of marine energy. Renew. Energy, 2005, 30 (12), 1801–1817. Google Scholar , Crossref\n17.\nDepartment of Trade and Industry. Fuel mix disclosure data table, current UK fuel mix and emissions, 2005 (DTI, London), available from www.dti.gov.uk/energy/consumers/fuel_mix/index.shtml Google Scholar\n18.\nInternational Standards Organisation. ISO 14040: 1997 environmental management, life cycle assessment, principles and framework, 1997 (ISO, Geneva). Google Scholar\n19.\nInternational Aluminium Institute. Life cycle inventory of the worldwide aluminium industry with regard to energy consumption and emissions of greenhouse gases, March 2003 (IAI, London), available from www.world-aluminium.org Google Scholar\n20.\nInternational Iron and Steel Institute. LCI data for steel products, 2005 (IISI, Brussels), available from www.IISI.org Google Scholar\n21.\nInternational Iron and Steel Forum. World steel life cycle inventory methodology report (1999/2000), 2002 (IISF, Brussels), available from www.worldstainless.org Google Scholar\n22.\nEuropean Copper Institute. Life cycle analysis for copper products, June 2005 (Deutches Kupferinstitut, Dusseldorf, Germany), available from www.kupferinstitut.de/lifecycle/ Google Scholar\n23.\nAssociation of Plastics Manufacturers in Europe. Eco-profiles of the European plastics industry - liquid epoxy resins, 2005 (PlasticsEurope, Brussels), available from www.plasticseurope.org Google Scholar\n24.\nRydh, C. J., Sun, M. Life cycle inventory data for materials grouped according to environmental and material properties. J. Clean. Prod., 2005, 13, 1258–1268. Google Scholar , Crossref\n25.\nEuropean Aluminium Association. Aluminium recycling in LCA, 2005 (EEA, Brussels), available from www.eaa.net Google Scholar\n26.\nDahmus, J., Gutowski, G. An environmental analysis of machining. ASME International Mechanical Engineering Congress and RD&D Expo, IMechE 2004, Anaheim, CA, USA, 13–19 November 2004. Google Scholar , Crossref\n27.\nAshby, M. Materials selection in mechanical design, 2nd edition, 1999 (Butterworth-Heinemann, Oxford, UK). Google Scholar\n28.\nSuzuki, T., Takahashi, J. Prediction of energy intensity of carbon fiber reinforced plastics for mass-produced passenger cars. 9th Japan International SAMPE Symposium JISSE-9, Tokyo, Japan, 29 November-2 December, 2005. Google Scholar\n29.\nTakayoshi, U., Shiino, T., Ouishi, H. Evaluation of electronic components in life cycle assessment. J. Mater. Cycles Waste Manag., 1999, 1, 25–32. Google Scholar\n30.\nRevenues HM and Customs. Foreign exchange rates: Japan, 2006 (HMRC, London), available from www.hmrc.gov.uk/exrate/japan.htm Google Scholar\n31.\nAutomobile Association. AA 2003 road atlas, 2002 (Automobile Association, London). Google Scholar\n32.\nDEFRA. Guidelines for companies reporting on greenhouse gas emissions, 2001 (Department for Environment and Rural Affairs, London). Google Scholar\n33.\nVehicle Certification Agency. Vehicle data for ford transit, 2005 (VCA, Bristol), available from www.vcacarfueldata.org.uk Google Scholar\n34.\nKhron, S. The energy balance of modern wind turbines, Wind Power Note, 1997 (Danish Wind Energy Association, Denmark). Google Scholar\n35.\nFujii, H., Nagaiwa, T., Kusuno, H., Malm, S. How to quantify the environmental profile of stainless steel. Society of Environmental Toxicology and Chemistry North America 26th Annual Meeting, November 2005 (SETAC, Pensacola, Florida, USA). Google Scholar\n36.\nLenzen, M., Munksgaard, J. Energy and CO2 life cycle analysis of wind turbines-reviews and applications. Renew. Energy, 2002, 26, 339–362. Google Scholar , Crossref\n37.\nVoorspools, K. R., Brouwers, E. A., D'haeseleer, W. D. Energy content and indirect greenhouse gas emissions embedded in âemission-freeâ™ power plants: Results for the low countries. Appl. Energy, 2000, 67 (3), 307–330. Google Scholar , Crossref\n38.\nMeier, P. J., Wilson, P. P. H., Kulcinski, G. L., Denholm, P. L. US electric industry response to carbon constraint: A life-cycle assessment of supply side alternatives. Energy Policy, 2005, 33, 1099–1108. Google Scholar , Crossref\n39.\nTahara, K., Kojima, T., Inaba, A. Evaluation of CO2 payback time of power plants by LCA. Energy Conserv. Manage., 1997, 38, 615–620. Google Scholar , Crossref\n40.\nAEA Technology. Environmental product declaration of electricity from torness nuclear power station - summary of results, May 2005 (British Energy, London). Google Scholar\n""","0.41612998","""http://journals.sagepub.com/doi/10.1243/09576509JPE306""","[-3.187347,55.947691]"
"""University_of_Glasgow""","""Towards Physarum engines  - Enlighten: Publications""","""Enlighten: Publications\nIn this section\nTowards Physarum engines\nTsuda, S. , Jones, J. and Adamatzky, A. (2012)     Towards Physarum engines. Applied Bionics and Biomechanics , 9(3),    pp. 221-240. (doi: 10.3233/ABB-2012-0059 )\nFull text not currently available from Enlighten.\nAbstract\nThe slime mould Physarumpolycephalum is a suitable candidate organism for soft-matter robotics because it exhibits controllable transport, movement and guidance behaviour. Physarum may be considered as a smart computing and actuating material since both its motor and control systems are distributed within its undifferentiated tissue and can survive trauma such as excision, fission and fusion of plasmodia. Thus it may be suitable for exploring the generation and distribution of micro-actuation in individual units or planar arrays. We experimentally show how the plasmodium of Physarum is shaped to execute controllable oscillatory transport behaviour applicable in small hybrid engines. We measure the lifting force of the plasmodium and demonstrate how protoplasmic transport can be influenced by externally applied illumination stimuli. We provide an exemplar vehicle mechanism by coupling the oscillations of the plasmodium to drive the wheels of a Braitenberg vehicle and use light stimuli to effect a steering mechanism. Using a particle model of Physarum we show how emergent travelling wave patterns produced by competing oscillatory domains may be used to to generate spatially represented actuation patterns. We demonstrate different patterns of controllable motion, including linear, reciprocal, rotational and helical, and demonstrate in simulation how dynamic oscillatory patterns may be translated into motive forces for simple transport of substances within a patterned environment.\nItem Type:\n""","0.74889195","""http://eprints.gla.ac.uk/103770/""","[-4.28836,55.871751]"
"""Imperial_College_London""","""Calibration and Validation of a Shared Space Model | Case Study""","""Calibration and Validation of a Shared Space Model\nCase Study\nPDF\nAbstract\nShared space is an innovative streetscape design that seeks minimum separation between vehicle traffic and pedestrians. Urban design is moving toward space sharing as a means of increasing the community texture of street surroundings. Its unique features aim to balance priorities and allow cars and pedestrians to coexist harmoniously without the need to dictate behavior. There is, however, a need for a simulation tool to model future shared space schemes and to help judge whether they might represent suitable alternatives to traditional street layouts. This paper builds on the authors’ previously published work in which a shared space microscopic mixed traffic model based on the social force model (SFM) was presented, calibrated, and evaluated with data from the shared space link typology of New Road in Brighton, United Kingdom. Here, the goal is to explore the transferability of the authors’ model to a similar shared space typology and investigate the effect of flow and ratio of traffic modes. Data recorded from the shared space scheme of Exhibition Road, London, were collected and analyzed. The flow and speed of cars and segregation between pedestrians and cars are greater on Exhibition Road than on New Road. The rule-based SFM for shared space modeling is calibrated and validated with the real data. On the basis of the results, it can be concluded that shared space schemes are context dependent and that factors such as the infrastructural design of the environment and the flow and speed of pedestrians and vehicles affect the willingness to share space.\n< >\nTransportation Research Record: Journal of the Transportation Research Board\nTransportation Research Record: Journal of the Transportation Research Board\nPrint ISSN: 0361-1981\n""","0.5122407","""http://trrjournalonline.trb.org/doi/10.3141/2588-05""","[-0.178219,51.500505]"
"""Cranfield_University""","""Fuzzy-hybrid land vehicle driveline modelling based on a moving window subtractive clustering approach: International Journal of Systems Science: Vol 42, No 2""","""Original Articles\nFuzzy-hybrid land vehicle driveline modelling based on a moving window subtractive clustering approach\nGet access /doi/full/10.1080/00207720903199572?needAccess=true\nAbstract\nIn this article, the fuzzy-hybrid modelling (FHM) approach is used and compared to the input–output system Takagi–Sugeno (TS) modelling approach which correlates the drivetrain power flow equations with the vehicle dynamics. The output power relations were related to the drivetrain bounded efficiencies and also to the wheel slips. The model relates also to the wheel and ground interactions via suitable friction coefficient models relative to the wheel slip profiles. The wheel slip had a significant efficiency contribution to the overall driveline system efficiency. The peak friction slip and peak coefficient of friction values are known a priori during the analysis. Lastly, the rigid body dynamical power has been verified through both simulation and experimental results. The mathematical analysis has been supported throughout the paper via experimental data for a specific electric robotic vehicle. The identification of the localised and input–output TS models for the fuzzy hybrid and the experimental data were obtained utilising the subtractive clustering (SC) methodology. These results were also compared to a real-time TS SC approach operating on periodic time windows. This article concludes with the benefits of the real-time FHM method for the vehicle electric driveline due to the advantage of both the analytical TS sub-model and the physical system modelling for the remaining process which can be clearly utilised for control purposes.\n""","0.80624276","""http://www.tandfonline.com/doi/abs/10.1080/00207720903199572""","[-0.629225,52.074389]"
"""Brunel_University_London""","""A study of the human ability to detect road surface type on the basis of steering wheel vibration feedbackProceedings of the Institution of Mechanical Engineers, Part D: Journal of Automobile Engineering - J Giacomin, Y J Woo, 2005""","""Gillespie T. D. Fundamentals of vehicle dynamics, 1992 (SAE International, Warrendale, Pennsylvania). Google Scholar Crossref\n2.\nMorioka M. Effect of contact location on vibration perception thresholds in the glabrous skin of the human hand. In Proceedings of 34th UK Group Meeting on Human Responses to Vibration, 22–24 September 1999 (Ford Motor Company, Dunton, Essex). Google Scholar\n3.\nLee S. I. Human sensitivity responses to vibrotactile stimulation on the hand: measurement of absolute thresholds J. Ergonomics Soc. South Korea, 1998, 17 (2), 1–10. Google Scholar\n4.\nMeh D., Denišlič M. Influenċe of age, temperature, sex, height and diazepam on vibration perception J. Neurol. Sci., 1995, 134, 136–142. Google Scholar Crossref , Medline\n5.\nGiacomin J., Shayaa M. S., Dormegnie E., Richard L. Frequency, weighting for the evaluation of steering wheel rotational vibration Int. J. Ind. Ergonomics, 2004, 33, 527–541. Google Scholar Crossref\n6.\nPottinger M. G., Marshall K. D., Lawther J. M., Thrasher D. B. A review of tire/pavement interaction induced noise and vibration In The tire pavement interface (Eds Pottinger M. G., Yager T. J.), 1986, ASTP STP 929, pp. 183–287 (American Society for Testing and Materials, Philadelphia, Pennsylvania). Google Scholar Crossref\n7.\nPak C. H., Lee U. S., Hong S. C., Song S. K., Kim J. H., Kim K. S. A study on the tangential vibration of the steering wheel of passenger car, SAEtechnical paper series, paper 912565, 1991, pp. 961–968. Google Scholar\n8.\nFujikawa K. Analysis of steering column vibration, Motion and Control, 1998, 4, 37–41. Google Scholar\n9.\nGiacomin J., Abrahams O. Human fatigue due to automobile steering wheel vibration. In Proceedings of SIA Conference on Car and Train Comfort, Le Mans, France, 15–16 November 2000. Google Scholar\n10.\nJurgen R. K. Electronic steering and suspensions systems, 1999 (SAE International, Warrendale, Pennsylvania). Google Scholar\n11.\nBritish Standards Institution BS6842: Measurement and evaluation of human exposure to vibration transmitted to the hand, British Standards Institution, London, 1987. Google Scholar\n12.\nInternational Organization for Standardization ISO5349–1: Mechanical vibration - measurement and assessment of human exposure to hand-transmitted vibration. Part 1: general guidelines, International Organization for Standardization, Geneva, 2001. Google Scholar\n13.\nSchoeggl P., Ramschak E. Neural networks for development, calibration and quality tests. SAE paper 01-0702, 2001. Google Scholar\n14.\nQuek F., Petro M. Human-machine perceptual cooperation. In Proceedings of International Conference on Computer-Human Interaction INTERCHI'93: Human Factors in Computing Systems, Amsterdam, the Netherlands, 24–29 April 1993, pp. 123–130. Google Scholar\n15.\nRombaut M. Prolab2: a driving assistance system, Mathl and Comput. Modelling, 1995, 22 (4–7), 103–118. Google Scholar Crossref\n16.\nStanton N. A., Pinto M. Behavioral compensation by drivers of a simulator when using a vision enhancement system Ergonomics, 2000, 43 (9), 1359–1370. Google Scholar Crossref , Medline\n17.\nToffin D., Reymond G., Kemeny A., Droulez J. Influence of steering wheel torque feedback in dynamic driving simulator In Proceedings of DSC North America Driving Simulation Conference, Dearborn, Michigan, 8–10 October 2003. Google Scholar\n18.\nShannon C. E. A mathematical theory of communication, 1949 (University of Illinois Press, Illinois). Google Scholar\n19.\nCorning P. A. Control information: the missing element in Norbert Wiener's cybernetic paradigm Kybernetes, 2001, 30 (9–10), 1272–1288. Google Scholar Crossref\n20.\nBea J. A., Marijuan P. C. The information patterns of laughter Entropy, 2003, 5, 205–213. Google Scholar Crossref\n21.\nNakayama O., Futami T., Nakamura T., Boer E. R. Development of a steering entropy method for evaluating driver workload. SAE paper 01–0892, 1999. Google Scholar\n22.\nGiacomin J., Woo Y. J. Beyond comfort: information content and perception enhancement Engng Integrity, 2004, 16 (July), 8–16. Google Scholar\n23.\nTanner W. P., Swets J. A. A. A decision-making theory of visual detection Psychol. Rev., 1954, 61, 401–409. Google Scholar Crossref , Medline\n24.\nGesheider A. G. Psychophysics: the fundamentals, 1997 (Lawrence Erlbaum Associates, London). Google Scholar\n25.\nCoombs S. Signal detection theory, lateral-line excitation pattern and prey capture behaviour of mottled sculpin Anim. Behaviour, 1999, 58, 421–430. Google Scholar Crossref , Medline\n26.\nGiacomin J., Steinwolf A., Staszewski W. J. An algorithm for mildly nonstationary mission synthesis (MNMS) Engng Integrity, 2000, 7 (January), 44–56. Google Scholar\n27.\nWilliams C. S. Designing digital filters, 1986 (Prentice Hall, Englewood Cliffs, New Jersey). Google Scholar\n28.\nBritish Standards Institution BS7085: Safety aspects of experiments in which people are exposed to mechanical vibration and shock, British Standards Institution, London, 1989. Google Scholar\n29.\nLakoff G. Women, fire and dangerous things, what categories reveal about the mind, 1987 (University of Chicago Press, Chicago). Google Scholar Crossref\n""","0.29161578","""http://journals.sagepub.com/doi/10.1243/095440705X34955""","[-0.472855,51.532848]"
"""Imperial_College_London""","""Fishing for Space: Fine-Scale Multi-Sector Maritime Activities Influence Fisher Location Choice""","""Fishing for Space: Fine-Scale Multi-Sector Maritime Activities Influence Fisher Location Choice\n* E-mail: alext@spc.int\nAffiliations SPC, BP D5, 98848, Noumea, New Caledonia,      Cefas, Pakefield Road, Lowestoft, Suffolk, NR33 0HT, United Kingdom\n⨯\nAffiliation IFREMER, Département Ressources Biologiques et Environnement Responsable de l’Unité Halieutique Manche-Mer du Nord, Unit 150, Quai Gambetta, BP 699 62321, Boulogne sur mer, France\n⨯\nAffiliation IFREMER, Département Ressources Biologiques et Environnement Responsable de l’Unité Halieutique Manche-Mer du Nord, Unit 150, Quai Gambetta, BP 699 62321, Boulogne sur mer, France\n⨯\nAffiliation Cefas, Pakefield Road, Lowestoft, Suffolk, NR33 0HT, United Kingdom\n⨯\nAffiliation Department of Animal and Plant Sciences, University of Sheffield, Alfred Denny Building, Western Bank, Sheffield, S10 2TN, United Kingdom\n⨯\nAffiliation Department of Life Sciences, Imperial College London, Silwood Park Campus, Ascot, SL5 7PY, United Kingdom\n⨯\nFishing for Space: Fine-Scale Multi-Sector Maritime Activities Influence Fisher Location Choice\nAlex N. Tidd, \nFigures\nCorrection\n19 Mar 2015: The PLOS ONE Staff     (2015) Correction: Fishing for Space: Fine-Scale Multi-Sector Maritime Activities Influence Fisher Location Choice.  PLOS ONE  10(3): e0121498. https://doi.org/10.1371/journal.pone.0121498 View correction\nFigures\nAbstract\nThe European Union and other states are moving towards Ecosystem Based Fisheries Management to balance food production and security with wider ecosystem concerns. Fishing is only one of several sectors operating within the ocean environment, competing for renewable and non-renewable resources that overlap in a limited space. Other sectors include marine mining, energy generation, recreation, transport and conservation. Trade-offs of these competing sectors are already part of the process but attempts to detail how the seas are being utilised have been primarily based on compilations of data on human activity at large spatial scales. Advances including satellite and shipping automatic tracking enable investigation of factors influencing fishers’ choice of fishing grounds at spatial scales relevant to decision-making, including the presence or avoidance of activities by other sectors. We analyse the determinants of English and Welsh scallop-dredging fleet behaviour, including competing sectors, operating in the eastern English Channel. Results indicate aggregate mining activity, maritime traffic, increased fishing costs, and the English inshore 6 and French 12 nautical mile limits negatively impact fishers’ likelihood of fishing in otherwise suitable areas. Past success, net-benefits and fishing within the 12 NM predispose fishers to use areas. Systematic conservation planning has yet to be widely applied in marine systems, and the dynamics of spatial overlap of fishing with other activities have not been studied at scales relevant to fisher decision-making. This study demonstrates fisher decision-making is indeed affected by the real-time presence of other sectors in an area, and therefore trade-offs which need to be accounted for in marine planning. As marine resource extraction demands intensify, governments will need to take a more proactive approach to resolving these trade-offs, and studies such as this will be required as the evidential foundation for future seascape planning.\nCitation: Tidd AN, Vermard Y, Marchal P, Pinnegar J, Blanchard JL, Milner-Gulland EJ (2015) Fishing for Space: Fine-Scale Multi-Sector Maritime Activities Influence Fisher Location Choice. PLoS ONE 10(1):            e0116335.                  https://doi.org/10.1371/journal.pone.0116335\nAcademic Editor: Jan Geert Hiddink,  Bangor University, UNITED KINGDOM\nReceived: July 13, 2014; Accepted: December 5, 2014; Published: January 27, 2015\nCopyright: © 2015 Tidd et al. This is an open access article distributed under the terms of the Creative Commons Attribution License , which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited\nData Availability: The data used in the study are the property of the following organisations: Department for Environment and Rural Affairs, Royal Haskoning, Maritime Coastguard Agency, Institut Français de Recherche pour l’exploitation de la Mer, Department of Energy and Climate Change. The data are confidential in nature and the reader would have to seek access by writing to the organisations mentioned above. An administration cost for the data, clauses specifying terms of data usage and a data confidentiality agreement should be expected. All requests for data can be sent to the following organization listed below. 1. Royal Haskoning; http://www.royalhaskoningdhv.com/en-gb/united-kingdom/contact-us . 2. Department for Environment and Rural Affairs (Defra); Marine and Fisheries Evidence Unit, Defra, Nobel House, 17 Smith Square, London SW1P 3JR; 3. Maritime Coastguard Agency (MCA): Spring Place, 105 Commercial Road, Southampton SO15 1EG; 4. Department of Energy and Climate Change (DECC); 3 Whitehall Place, London SW1A 2AW; 5. Institut Français de Recherche pour l’exploitation de la Mer (IFREMER): 150 Quai Gambetta, 62200 Boulogne-sur-Mer, France.\nFunding: The research leading to these results has received funding from the European Union’s Seventh Framework Programme for research, technological development and demonstration (FP7/2007–2013) within the Ocean of Tomorrow call under Grant Agreement No.266445 for the project Vectors of Change in Oceans and Seas Marine Life, Impact on Economic Sectors “(VECTORS)“ and Cefas United Kingdom (Project Cefas Seedcorn). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.\nCompeting interests: The authors have declared that no competing interests exist.\nIntroduction\nAs human population growth continues to increase there is a need to balance competing demands for natural resources. Traditionally seen as a common property resource, the sea is confronted increasingly with competition for space by competing sectors, e.g. fisheries, oil and gas exploitation, aggregate extraction, wind energy, shipping and transport, recreation, dumping and the military activities. Spatial planning and the regulation of human activities and pressures at sea are therefore becoming a concern, especially given that some resources are limited in space and quantity. Since 2008, the European Union has placed a responsibility on member states to achieve common principles based on the “Roadmap for spatial planning” [ 1 ], which falls under the Integrated Maritime Policy (IMP; [ 2 ]), and is generally referred to as Maritime Spatial Planning (MSP). The objectives of MSP are to manage anthropogenic activities in space and time, precluding or minimising conflicts between competing sectors without negatively impacting the ecosystem, operating within the Marine Strategy Framework Directive (MFSD; [ 3 ]). However, because sectors at sea can change rapidly and the complexities of natural systems are linked and inter-reliant, a management decision for one sector may affect others, and MSP needs to be treated as a process of continuous, adaptive management process.\nGiven the importance of MSP, several writers have stressed the importance of fleet-based spatial management in the commercial fisheries sector [ 4 ], [ 5 ], accounting for different fleet activities at a scale fine enough to be integrated into the MFSD process. To date, integration has been difficult owing to the broad scale (ICES statistical rectangle ∼900 nautical miles2) at which some data (e.g. landings) are reported. With the emergence of Vessel Monitoring Systems (VMS) over the past decade, however, MSP is now potentially possible at a finer scale. Issues of data confidentiality between member states have hampered the use of this information, and there is also a historic reluctance of fishers to provide accurate landings information for fear of conceding knowledge of profitable fishing grounds [ 6 ], and that the information might be used against their interests by other authorities. For example [ 7 ] suggested that fishers are concerned that conservationists might identify productive fishing grounds as suitable for Marine Protected Areas (MPAs), or fisheries managers might implement tighter enforcement constraints. In the light of the limited data availability and confidentiality, fisheries managers are looking now for alternative approaches to assist spatial planning, which will reduce implementation error i.e. where the effects of management differ from that intended [ 8 ].\nOne such approach involves anticipating fisher behaviour in response to regulation. Fisher behaviour cannot be predicted with certainty because of the many factors which influence where and when a fisher will operate. However, if managers can better anticipate fisher behaviour, then they may be able to reduce the unanticipated side-effects of management actions aimed both at the fishery sector and at other sectors. Traditional fisheries management treats fishers as static and homogenous with no consideration of their behaviour and individual aims [ 9 ], [ 10 ]. Recent studies have applied random utility model (RUM) methodology [ 11 ]–[ 13 ] to this issue, because such models offer an opportunity to study individual behaviour at a finer scale of space and time than previous approaches [ 14 ].\nThe objective of the present study was to model the key determinants of where fishers choose to fish, building on retrospective time-series and including interactions with a selection of key sectors also competing for space in the area. In this study we acquired data for the English and Welsh scallop-dredging fleet operating in the eastern English Channel (ICES Division VIId) and these fleets form the basis of our case study. This area also contains one of the busiest shipping lanes in the world, the route between the Atlantic Ocean and the North Sea, which we hypothesise might have a negative impact on commercial fishers. There are also several active marine aggregate extraction sites and fishers have expressed concerns about the accumulation of such sites and the effect of fishing pressure concentrating elsewhere for fear of gear damage, and the sustainability of fish stocks that are already heavily exploited in these areas [ 15 ]. The fishing restrictions in the area consist of local English bylaws prohibiting beam trawlers of > = 300 horsepower or 70 gross registered tons from the 12 mile belt of sovereign waters around the English coast to restrict competition with the inshore sole fishing fleet ( Fig. 1 ). This ruling also prevents fishing by any international fishing vessel, though the area can be used for safe passage. There is a further 6 mile restricted zone to assist inshore vessels by prohibiting some fishing vessels of size >14m (depending on which regional Inshore Fishery and Conservation Area—IFCA they fall under) and limitations on scallop vessels with a certain number of dredges. Most of the vessels operating in the region are small (<10 m) inshore boats that deploy gillnets, trawls, longlines, traps and pots, and target sole (Solea solea), plaice (Pleuronectes platessa), cod (Gadus morhua), bass (Dicentrarchus labrax) and some skates and rays (Rajidae; [ 16 ]).\nDownload:\noriginal image\nFigure 1. Spatial overlap of sectors (coloured pixels represent maritime traffic densities, thick and thin white lines the12 and 6 mile limits respectively, aggregate mining sites (labelled) and the dashed black line proposed Special Areas of Conservation) within the English Channel.\nhttps://doi.org/10.1371/journal.pone.0116335.g001\nA mixed logit RUM was developed to analyse the determinants of fisher behaviour at a fine scale using English and Welsh VMS data. This model evaluates the effect of the key potential competing sectors on fishing behaviour. Suggestions are then made as to how the method can be used in integrated MSP in anticipation of the potential establishment of Special Areas of Conservation (SACs) in the area as part of UK commitments to the EU’s Habitats Directive [ 17 ] or Marine Conservation Zones (MCZs) under the UK Marine and Coastal Access Act 2009.\nMaterials and Methods\nEthics Statement\nI confirm that the author adhered to general guidelines for the ethical use of humans and animals.\nThe UK scallop fleet\nThe UK scallop (Pecten maximus) industry is one of the UKs most valuable fisheries and was valued at >£66.9 million (58000 tonnes), £16 million in the Channel alone in 2012 [ 18 ], employing >13000 people in the catching sector and 17 000 in the processing sector [ 19 ]. Scallops are fished in one of three ways, dredging, trawling and hand-diving. Dredging is the most common method (95% of king scallops landed in UK are caught using dredges [ 20 ] and 2–4% of king scallops are hand collected by divers, [ 21 ]). Scallop dredges consist of a heavy metal frame with a chain mesh and a set of spring-loaded teeth pointed downwards to assist in raking out the scallops into the dredge’s chain mesh. These dredges are connected to a beam, which in turn is connected to warps that are towed over the seabed by the fishing vessel. Queen scallops (Aequipecten opercularis) are typically caught in much the same way however queen scallops are active swimmers and fishers are able to engage in trawling for them during seasonal king scallop dredging restrictions.\nVariability in landings and in number of vessels operating, resulting from fluctuations in good recruitment, market demand, regulations and more recently fuel price, are common features of scallop fisheries. Generally current management of scallop fisheries is through minimum landing sizes and the numbers of dredges regulated by local sea fisheries committees, as there are no catch limitations. The UK scallop-dredging fleet is said to be nomadic in nature, moving around the UK coast to fish wherever scallop abundance is best and operating there until those grounds become economically non-viable. They then return a few years later when stocks there have recovered [ 19 ]. In recent years, there has been an increase in the number of vessels operating in the eastern English Channel fishery. This may partly be due to more restricted fishing opportunities elsewhere, such as in Cardigan Bay [ 22 ], but also the Prohibition of Fishing for Scallops (Scotland) Order 2003 banning the use of more than 14 dredges per side anywhere in Scottish waters [ 23 ] hence displacing larger vessels which use a greater number of dredges to other locations. However Defra [ 19 ] suggest that this increase is predominantly among the larger (≥15 m long), more powerful, vessels and is also due to an increase in scallop abundance resulting from enhanced recruitment.\nData\nThe UK’s Department for the Environment, Food and Rural Affairs (Defra) database for fishing activity and the fleet register were used to select commercial landing and vessel data from the English and Welsh fleet (excluding Scottish and Northern Irish data due to confidentiality issues). Individual trip data for commercial scallopers were collated for the years 2005–2010. The data collected for each vessel included species landed, hours fished, landed weight per ICES statistical rectangle (kg), month of fishing, year of fishing and total value of the catch by species, vessel and trip. Within the EU, it is currently only a requirement for vessels >10 m long to submit logbooks, but the database also contains a subset of catch from <10 m vessels that historically reported their catches.\nMethodology for the definition of fleets was based on the European Commission’s Data Collection Regulation (DCR; [ 24 ]). VMS monitoring in the European Union [ 25 ], [ 26 ] has been in place since 2000, initially for fishing vessels of ≥24 m long, post-2005 for vessels ≥15 m long, and in 2012 ≥12 m long. The data are required by regulatory authorities for vessel monitoring purposes (and nowadays, increasingly for scientific research) and are characterised by a ping every 2h giving position, course and speed. Over the past few years, authors such as [ 27 ], [ 28 ] and [ 29 ] have described methods to determine fishing or steaming activities from unprocessed VMS data. No individual method has been adopted as definitive, so the data for the years 2005–2010 were processed as described by [ 28 ]. Logbook data and VMS fishing records were combined by vessel and ICES rectangle, forming a detailed dataset of fishing activity. The ICES rectangle was further formatted into 200 (3′ × 3′) squares and all the coordinates from the VMS data were assigned into these spatial units.\nMarine diesel prices, excluding value-added tax and duty, were obtained from the UK Department of Energy and Climate Change. Aggregate-extraction intensity data by month for the years 2005–2010 were obtained from the UK’s Royal Haskoning and the Institut Français de Recherche pour l’Exploitation de la Mer. Shipping/transport traffic information was obtained from the Automatic Identification System (AIS) of the UK Maritime Coastguard Agency. UK 6-mile and French 12-mile limits were added to the maritime activities dataset because it was thought that competition for space with the local inshore fleet would be an influencing factor.\nThe model\nHaving populated the dataset with all covariates, we developed a mixed RUM to determine the key determinants of fisher behaviour in relation to competing sectors and fishing-specific covariates. We hypothesise that key competing sectors of activity as well as fishing costs (i.e. fuel price) negatively impact the spatial coverage of fishing operations (as presented in Fig. 2 ), in contrast to expected vpue and past effort (knowledge or habit) which positively influence fishing operations. Pioneering research by [ 30 ], [ 31 ] on the use of discrete choice and economics methodologies demonstrated the relationship between utility maximization and discrete choice, where utility influences individual choice with a deterministic and stochastic error component. RUM derives its name from discrete utility maximization and assumes that the choices are random to the analyst. A mixed logit choice RUM was implemented because it relaxes the non-IIA (Independence of Irrelevant Alternatives) assumptions associated with preference heterogeneity among fishers. This approach is efficient in dealing with panel data for repeated individual choices, as is the case within this study. For a detailed explanation of mixed logit, see [ 32 ] and [ 33 ]. Succinctly, the total utility μnjt of fisher n for site j in trip t is\n(1) where β′n xnjt represents the observed utility and ϵnjt is the error distribution that is part-correlated and part independently and identically distributed (iid) over alternatives and individuals[ 31 ], [ 34 ]. Within the mixed logit framework, βn was assumed to follow a normal distribution, and for a given value of n (for simplicity disregarding t), the conditional probability of choice j across all other choices j = 1 to J is estimated by drawing random values β by simulation using\n(2) where βn is a vector of coefficients that varies across individuals, and xnj is a vector of the attributes of each of the choices made. All covariates met the normality assumption following log-transformation. The analysis on 3019 observations was carried out in the SAS package PROC MDC [ 35 ] using quasi-Newton optimisation and 100 Halton draws.\nDownload:\nhttps://doi.org/10.1371/journal.pone.0116335.t001\nSensitivity analysis\nTo test the sensitivity to different variables the mean choice probabilities were calculated from the model output and then compared with mean choice probabilities after re-running the model under alternative scenarios where each variable was doubled/halved one at a time. The differences in probability of location choice, under each of these scenarios, show the magnitude of the effect on location choice and how sensitive the variables are to changes i.e. how the variables that penalise fishing operations (e.g. aggregate extraction, marine traffic, and fuel costs) affect fishers, in contrast to expected vpue which should encourage fishing operations.\nResults\nThe mixed model showed a McFadden’s pseudo-R 2 of 0.19, suggesting a very good fit [ 44 ]. Theoretically, the range for McFadden’s pseudo-R 2 is between 0 and 1, but the general rule of thumb is that any value from 0.2 to 0.4 suggests an excellent fit, comparable to an ordinary least squares (OLS) R 2 of 0.7–0.9 [ 45 ].\nAll mixed model coefficients were statistically significant (p < 0.01) except the coefficient for the average vpue of scallop from fishing in the same location in the same month as in the previous year and the proxy for congestion/social influence in the previous month of the current year for the French fleet ( Table 2 ). The estimated standard deviations of the estimates were not significantly different from the mean (indicating that the parameters do not vary significantly in the population of fishers) for past vpue, cost, average percentage coverage by marine traffic and average hours occupied by fishing activity by English/other fishing vessels. Conversely, the effort to the location in the previous month in the current year, the average percentage coverage by aggregate activity and the average effort in the same month the previous year did vary, perhaps relating to variations in characteristics of the fishers not captured in the model.\nDownload:\nhttps://doi.org/10.1371/journal.pone.0116335.t002\nThe effort distribution maps in Fig. 2 , coupled with the model results ( Table 2 ) show how the scallop dredges interact with the shipping traffic separation scheme, aggregates and fisheries outside the English 6 and French 12-mile limits. In general the mean coefficients show the signs one would expect: English scallop fishers are negatively affected by the English 6 and French 12 mile restrictions, as well as aggregate activity and marine traffic. Despite this, in every year of the study there was a large amount of fishing effort in these areas, even more so in 2010 within the high-traffic area, perhaps because of a trade-off with larger expected vpue in these areas. There is a significant positive influence of vpue in the previous month on the tactics of fishers, but not of vpue in the same month of the previous year, which strongly suggests in-year variability is the key driver of behaviour. In contrast, cost was a negative influence as expected. Past effort variables, which were included to depict habit or knowledge of past success of fishing grounds, have positive coefficients, suggesting they are important drivers of fisher location choice.\nAs part of a ‘what if analysis’ a series of numerical simulations revealed that fishers responded to a 50% decrease in % area covered by aggregate extraction differently depending on the spatial position of the activity. In an area close to shore associated with aggregate extraction (30E9G), there was a relatively large difference in probability of fishing, of +0.012, while there were small noticeable increases in nearby areas 30E9F and 29F0C. Doubling the coverage of aggregate extraction resulted in fishers moving out of these locations (notably these same areas, 30E9G, 30E9F and 29F0C) with a change of probability of −0.018, −0.012 and −0.004 respectively. Fishers moved into a more offshore site of existing extraction (29F0B), which recently has contained very high fishing effort, with a change in probability of +0.014. These observations suggest that aggregate mining activity heavily influences fisher decision making, possibly due to knowledge of the habitat that scallops live in, coupled with past experience ( Fig. 2 ).\nMost of the main scallop grounds are located within busy marine traffic areas ( Fig. 2 ) and therefore one would expect that with a decrease in traffic intensity there would be less competition for space and fishers would move into these areas. Maritime traffic, however, showed relatively small effects. Doubling the coefficient of maritime traffic intensity resulted in fishing effort being displaced out of the traffic lanes, essentially spreading out, whereas halving the coefficient led to an increase in predicted effort into the traffic lanes, most notably 29F0A, 29F0B and 29F0C. Changes in expected fuel cost did not result in large significant differences in probabilities of site choice. When fuel prices are halved fishers move closer in shore to the English ports, in contrast when they are doubled fishers move to areas offshore where the concentration of fishers and expected vpue is at its highest (e.g. areas, 29F0B, 29F0C and 29F0D) or nearer to French landing ports, resulting in a ‘complimentary effect’ with expected costs and expected vpue ( Fig. 4 ).\nDownload:\nhttps://doi.org/10.1371/journal.pone.0116335.g004\nDiscussion\nIt is widely recognised that decision-makers and managers desire an ecosystem-based approach to address interlinked drivers of social well-being [ 46 ]. Marine Spatial Planning necessitating the balancing of multiple objectives; fisheries managers need to understand the implications of effort displacement from closing an area and the unforeseen consequences of their management actions (e.g. effects on other marine life, economic implications and effects on other maritime sectors). Several authors have stressed the importance of anticipating fisher behaviour in response to management regulation, in order to reduce implementation error [ 47 ]–[ 49 ]. Here, a mixed logit RUM was applied at fine-scale resolution to assess the key determinants of scallop fisher behaviour in the eastern English Channel, so that if a regulation or new activity emerges, fishing effort re-allocation can potentially be predicted.\nA key finding was that past fishing success in a location within the previous month was a good predictor of continued fishing in that location. This can be interpreted as a proxy for habit, knowledge or experience, as in other studies [ 40 ], [ 10 ]. Similarly, the expected marginal net revenue of visiting one fishing site rather than another, in terms of vpue, was significant as expected [ 50 ]. This is more apparent for the vpue in the previous month, rather than in the same month the year before, potentially capturing either seasonality or more likely short-term temporal correlations in stock abundance (see Table 2 ). Surprisingly, perceived fuel costs were not a major driver in choice of fishing grounds, possibly because of the proximity of grounds to landing ports in the eastern English Channel. The French12-mile limit and English 6 mile limit unsurprisingly had negative influences on fisher site choice, possibly because of productive fishing grounds within limits, which are rendered unavailable to the scallop vessels. Nevertheless competition from the inshore national fleet could become an issue if the fleet is forced to occupy a reduced spatial geographic footprint than was previously the case, for example by spatial closures. Of further policy importance are the effects of other commercial maritime activities (e.g. transport, aggregates mining) on the behaviour of the scallop fleet. If interactions with these sectors are better characterised then the implications for the scallop fleet of other maritime sectors can be assessed in advance.\nThe analysis indicates that this fleet exhibits some risky behaviour in their responses, as the mean of the coefficients determining site choice and the estimated standard deviation of the coefficients in Table 2 show highly significant estimates of some of the drivers, suggesting that the parameters vary within the wider population of fishers [ 40 ]. The signs of the standard deviations in some instances are negative, but for estimation purposes they are free to take any sign, because the normal distribution is symmetrical around its mean, and the absolute value can be taken to estimate the variance. For the coefficients that do vary between fishers (i.e. previous effort (last month and last year) and presence of aggregate extraction) we can assess what proportion of the population of fishers see these factors as positive or negative when making decisions about site choice. Taking the mean and standard deviation together the point estimates of the coefficients can be calculated by standardising the scores (z scores) and thus a probability can be calculated. The model suggests that 88% of the population of fishers see effort in the past month as a positive inducement to fishing in the same location again and 12% see it as a negative inducement, which will be dependent on the time they spent in the location previously and their success in terms removing the harvestable biomass, if they ‘fished out’ an area they are unlikely to return. Similarly past effort in the same month of the previous year is a positive influence on location choice for 58% of fishers. The areas occupied by aggregates mining are chosen more than expected with about 40% preferring fishing in these areas, in contrast to the other 60% seeing it as a negative influence, confirming the assumption that the aggregate industry does impact scallop fishing. [ 15 ] found that by setting aside marine areas for aggregates mining, this resulted in reduced fishing effort. Since 2005, aggregate extraction licences have been granted over large areas [ 51 ]. This is contrary to [ 52 ] findings for sole, which suggests that aggregate mining can have a positive effect on the catchability of sole by beam trawlers and hence on profitability. Perhaps, increased turbidity increases sole catchability (by reducing visual cues for escape and/or fish being disturbed from the seabed) or the dispersal of food into the water column encourages sole to move away from the bottom to feed or they may favour the previously mined area because of changed food resources or substrate. In stark contrast however, a recent study by [ 53 ] using time series cross correlation approach concluded that aggregate extraction activity, proximity and intensity didn’t have any impact on fisher activity. The differences could be attributed to the different statistical approaches employed. In the approach adopted by [ 53 ], only one sector of activity was investigated, in contrast to this study whereby two competing sectors were studied with the inclusion of economic data. ARIMA models (such as those employed by [ 53 ]) do not take account of individual behavioural interactions and are purely based on past time series behaviour, however they remain an excellent tool to support expert judgment.\nThe shipping Traffic Separation Scheme (TSS) in the English Channel controls one of the busiest shipping lanes in the world and attempts to mitigate against the possibility of maritime accidents, but can also impede fishing. The output from the model suggests that the presence of a TSS significantly reduces the probability of a fisher choosing a location, suggesting that the policy is having the desired effect of separating fishing from other activities, though at the cost of reduced ability to choose areas of potential high profitability.\nThis study gives clues to policy makers about the likely impact of their actions on fisher behaviour. For example, an increase in traffic densities would have a high chance of displacing effort to local inshore waters ( Fig. 4 ). Conversely, the fleet responds to higher fuel cost by going further offshore with the expectation of the reward of higher returns, and when costs are lower they fish equally between inshore and offshore locations as they are not forced to cover higher costs by fishing in areas with highest vpues. Fig. 4 suggests that when aggregate mining is doubled there is a greater increase in fishing activity offshore and when halved there appears to be movement of fishing into the location of extraction. Also of note is the movement of vessels towards the French 12 mile limit, resulting in shorter distances to land to French ports.\nA further important observation is that if one of the parameters that disadvantages fishers’ (e.g. shipping traffic densities) is altered, the competition for space effectively increases and the fishery spreads out. This may be because the traffic lanes are home to the best scallop fishing grounds and the specific location a vessel relocates to is the one with the next best trade-off between expected catch rates and distance to landing ports. This is also apparent for the competition with the aggregate sites, which are located in the heart of good scallop fishing grounds. Any reduction of the space taken up by aggregate mining, especially inshore results in an increase in effort allocation to those locations. This “fishing for space” where observed, could be viewed as symptomatic of competition within the fleet as well as a response to other sectors, and hence this could be used as a direct measure of spatial conflicts.\nConclusions and Future Work\nThe Eastern English Channel is a shared resource and there is increasing competition for space and resources, requiring novel management approaches that account for all or some of the interactions between sectors. To our knowledge, no other study has used a mixed RUM at fine resolution to assess key determinants of human behaviour in relation to different maritime sectors and as a possible tool for MSP. The results are promising and lay the foundations for future work that could include adding Marine Conservation Zones (MCZs) to the model. Final decisions on where MCZs will be introduced in the English Channel and what activities will be excluded are still to be clarified or have only recently been resolved, so it was not appropriate to incorporate simulated closures into the model. Nevertheless, the approach taken could be applied to other fleets, as RUMs offer the capacity to model individual behaviour at fine spatial and temporal scales needed for assessing the implications of policy decisions [ 54 ]. It would also be desirable to re-fit the data to recent data where fishing effort is more stable (during the investigated time period effort gradually increased) and as such results could appear somewhat different. Further work might include the Scottish fleet which represent a large proportion of scallop fishing effort in the eastern English Channel, evaluating trade-offs with both socio-economic and conservation objectives using efficient and effective spatial planning tools such as Marxan and MinPatch.\nAcknowledgments\nThe research leading to these results has received funding from the European Union’s Seventh Framework Programme for research, technological development and demonstration (FP7/2007–2013) within the Ocean of Tomorrow call under Grant Agreement No.266445 for the project Vectors of Change in Oceans and Seas Marine Life, Impact on Economic Sectors “(VECTORS)” and time under Cefas contract (Seedcorn 67100G). We thank Andy Payne and Jim Ellis (Cefas) for their constructive advice and inputs to the work and paper, the UK’s Department of Energy and Climate Change (DECC) for providing data on fuel price, Royal Haskoning for supplying the commercial aggregate data and the Marine Coastguard Agency (MCA) for the AIS maritime traffic data. The paper is a contribution to Imperial College’s Grand Challenges in Ecosystems and the Environment initiative.\nAuthor Contributions\nConceived and designed the experiments: AT PM YV. Performed the experiments: AT PM YV. Analyzed the data: AT YV. Contributed reagents/materials/analysis tools: AT YV. Wrote the paper: AT JB JP EJMG.\nReferences\n1. EC (2008) Communication from the Commission: Roadmap for Maritime Spatial Planning: Achieving Common Principles in the EU. Brussels, 25.11.2008, COM(2008) 791 final.\n2. EC (2007) “Communication from the Commission to the European Parliament, the Council, the European Economic and Social Committee and the Committee of the Regions”, An Integrated Maritime Policy for the European Union, COM (2007) 575 final, Brussels, 10.10.2007.\n3. EC (2008) Directive 2008/56/EC of the European Parliament and the Council of 17 June 2008 establishing a Framework for Community Action in the Field of Marine Environmental Policy. Official Journal L 164, 25/06/2008.  P. 0019–0040.  pmid:22494853\n""","0.1409923","""http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0116335""","[-0.178219,51.500505]"
"""University_of_Lancaster""","""An agent-based vehicle routing simulation tool for road networks with time-variant data - Research Portal | Lancaster University""","""An agent-based vehicle routing simulation tool for road networks with time-variant data\nResearch output: Contribution in Book/Report/Proceedings › Paper\nPublished\nProceedings of the 27th European Simulation and Modeling Conference\nPlace of Publication\n27th Annual European Simulation and Modelling Conference - Lancaster, United Kingdom\nConference\n27th Annual European Simulation and Modelling Conference\nCountry\n27th Annual European Simulation and Modelling Conference\nCountry\n23/10/13 → 25/10/13\nAbstract\nSimulation modeling is one of the analytic techniques commonly used for transportation management; it includes such activities as route planning and post-operation analysis. One of the simulation methods, agent-based simulation, has become increasingly popular due to the availability of good micro-level data collected through technologies such as GPS-enabled devices and road sensors. This paper presents the design and implementation of an agent-based simulation tool that can be used to analyse vehicle routing algorithms. We demonstrate how the tool can be used in practice by implementing two vehicle routing algorithms: shortest-path and LANTIME. LANTIME is an algorithm that can be used to minimize CO2 emissions.\nLancaster University Bailrigg Lancaster United Kingdom LA1 4YW\n+44 (0)1524 65201\n""","1.2689223","""http://www.research.lancs.ac.uk/portal/en/publications/an-agentbased-vehicle-routing-simulation-tool-for-road-networks-with-timevariant-data(bb842266-f5b8-4491-858c-1ce2901a30c5).html""","[-2.787729,54.010394]"
"""Cranfield_University""","""Multi-objective optimisation for battery electric vehicle powertrain topologiesProceedings of the Institution of Mechanical Engineers, Part D: Journal of Automobile Engineering - Pongpun Othaganont, Francis Assadian, Daniel J Auger, 2017""","""[UK] Department for Transport. Policy, Transport emissions, https://www.gov.uk/government/publications/plug-in-car-grant,Plug-incargrant (2014, accessed 27 August, 2014). Google Scholar\n3.\nGuzzella L, Sciarretta A. Vehicle propulsion systems: introduction to modeling and optimization. Berlin: Springer, 2005. Google Scholar\n4.\nDextreit C, Assadian F, Kolmanovsky V, . Hybrid electric vehicle energy management using game theory. SAE paper 2008-01-1317, 2008. Google Scholar\n5.\nDextreit C, Kolmanovsky V. Game theory controller for hybrid electric vehicles. IEEE Trans Control Systems Technol 2014; 22(2): 652–663. Google Scholar Crossref\n6.\nWeissinger C, Buecherl D, Herzog H. Conceptual design of a pure electric vehicle. In: 2010 IEEE vehicle power and propulsion conference, Lille, France, 1–3 September 2010, pp. 1–5. New York: IEEE. Google Scholar\n7.\nHayes JG, Oliveria RPR, Vaughan S, Egan MG. Simplified electric vehicle power train models and range estimation. In: 2011 IEEE vehicle power and propulsion conference, Chicago, Illinois, USA, 6–9 September 2011, pp. 1–5. New York: IEEE. Google Scholar\n8.\nPearre NS, Kempton W, Guensler RL, Elango V. Electric vehicles: how much range is required for a day’s driving? Transpn Res Part C: Emerging Technol 2011; 19(6): 1171–1184. Google Scholar Crossref\n9.\nEhsani M, Gao Y, Emadi A. Modern electric, hybrid electric, and fuel cell vehicles: fundamentals, theory, and design. 2nd edition.Boca Raton, Florida: CRC Press, 2009, p. 557. Google Scholar\n10.\nGuiron Z, Henghai Z, Houyu L. The driving control of pure electric vehicle. Procedia Environ Sci 2011; 10(A): 433–438. Google Scholar Crossref\n11.\nWang R, Chen Y, Feng D, . Development and performance characterization of an electric ground vehicle with independently actuated in-wheel motors. J Power Sources 2011; 196(8): 3962–3971. Google Scholar Crossref\n12.\nLightning Car Company. A new way of motoring, http://www.lightningcarcompany.co.uk (2014, accessed 27 August 2014). Google Scholar\n13.\nvan Schalkwyk DJ, Kamper MJ. Effect of hub motor mass on stability and comfort of electric vehicles. In: 2006 IEEE vehicle power and propulsion conference, Windsor, Ontario, Canada, 6–8 September 2006, pp. 1–6. New York: IEEE. Google Scholar\n14.\nJain M, Williamson SS. Suitability analysis of in-wheel motor direct drives for electric and hybrid electric vehicles. In: 2009 IEEE electrical power and energy conference, Montreal, Quebec, Canada, 22–23 October 2009, pp. 1–5. New York: IEEE. Google Scholar\n15.\nYan X, Patterson D. Improvement of drive range, acceleration and deceleration performance in an electric vehicle propulsion system. In: 30th annual IEEE power electronics specialists conference, Charleston, South Carolina, USA, 1 July 1999, Vol 2, pp. 638–643. New York: IEEE. Google Scholar\n16.\nBenysek G, Jarnut M. Electric vehicle charging infrastructure in Poland. Renewable Sustainable Energy Rev 2012; 16(1): 320–328. Google Scholar Crossref\n17.\nZhou B, Jiang Q, Yang Y, Wang J. Analysis of energy consumption and powertrain parameters optimization of BEV based on running cycle. In: 2010 IEEE 11th international conference on computer-aided industrial design and conceptual design, Yiwu, Zhejiang, People’s Republic of China, 17–19 November 2010, pp. 1284–1290. New York: IEEE. Google Scholar\n18.\nHu X, Murgovski N, Johannesson LM, Egardt B. Optimal dimensioning and power management of a fuel cell/battery hybrid bus via convex programming. IEEE/ASME Trans Mechatronics 2016; 20(1): 457–468. Google Scholar Crossref\n19.\nOthaganont P, Assadian F, Auger D. Sensitivity analyses for cross-coupled parameters in automotive powertrain optimization. Energies 2014; 7(6): 3733–3747. Google Scholar Crossref\n20.\nWipke KB, Cuddy MR, Burch SD. ADVISOR 2.1: a user-friendly advanced powertrain simulation using a combined backward/forward approach. IEEE Trans Veh Technol 1999; 48(6): 1751–1761. Google Scholar Crossref\n21.\nMohan G, Assadian F, Longo S. Comparative analysis of forward-facing models vs backward-facing models in powertrain component sizing. In: 2013 4th IET hybrid and electric vehicles conference, London, UK, 6–7 November 2013, pp. 1–6. New York: IEEE. Google Scholar\n22.\nYang Y, Hu X, Pei H, Peng Z. Comparison of power-split and parallel hybrid powertrain architectures with a single electric machine: dynamic programming approach. Appl Energy 2016; 168: 683–690. Google Scholar Crossref\n23.\nMohan G, Assadian F, Longo S. An optimization framework for comparative analysis of multiple vehicle powertrains. Energies 2013; 6: 5507–5537. Google Scholar Crossref\n24.\nLeitman S, Brant B. Build your own electric vehicle. 2nd edition.New York: McGraw-Hill, 2009. Google Scholar\n25.\nLarminie J, Lowry J. Electric vehicle technology explained. Chichester, West Sussex: John Wiley, 2004. Google Scholar\n26.\nChen GH, Tseng KJ. Design of a permanent-magnet direct-driven wheel motor drive for electric vehicle. In: 27th annual IEEE power electronics specialists conference, Baveno, Italy, 23–27 June 1996, Vol 2, pp. 1933–1939. New York: IEEE. Google Scholar\n27.\nQian H, Xu G, Yan Q, . Energy management for four-wheel independent driving vehicle. In: 2010 IEEE/RSJ international conference on intelligent robots and systems, Taipei, Republic of China, 18–22 October 2010, pp. 5532–5537. New York: IEEE. Google Scholar\n28.\nTesla Motors. Home page, http://www.teslamotors.com (2014, accessed 27 August 2014). Google Scholar\n29.\nCaricchi F, Crescimbini F, Di Napoli A, Marcheggiani M. Prototype of electric vehicle drive with twin water-cooled wheel direct drive motors. In: 27th annual IEEE power electronics specialists conference, Baveno, Italy, 23–27 June 1996, Vol 2, pp. 1926–1932. New York: IEEE. Google Scholar\n30.\nQian H, Lam TL, Li W, . System and design of an omni-directional vehicle. In: IEEE international conference on robotics and biomimetics, Bangkok, Thailand, 21–26 February 2008, pp. 389–394. New York: IEEE. Google Scholar\n31.\nRahman KM, Patel NR, Ward TG, . Application of direct-drive wheel motor for fuel cell electric and hybrid electric vehicle propulsion system. IEEE Trans Ind Applic 2006; 42(5): 1185–1192. Google Scholar Crossref\n32.\nTao G, Ma Z, Zhou L, Li L. A novel driving and control system for direct-wheel-driven electric vehicle. In: 2004 12th symposium on electromagnetic launch technology, Snowbird, Utah, USA, 25–28 May 2004, pp. 514–517. New York: IEEE. Google Scholar\n33.\nYang Y-P, Hu T-H. A new energy management system of directly-driven electric vehicle with electronic gearshift and regenerative braking. In: 2007 American control conference, New York, USA, 9–13 July 2007, pp. 4419–4424. New York: IEEE. Google Scholar\n34.\nTie SF, Tan CW. A review of energy sources and energy management system in electric vehicles. Renewable Sustainable Energy Rev 2013; 20: 82–102. Google Scholar Crossref\n35.\nDejun Y, Hori Y. A novel traction control of EV based on maximum effective torque. In: IEEE 2008 vehicle power and propulsion conference, Harbin, Heilongjiang, People’s Republic of China, 3–5 September 2008, pp. 1–6. New York: IEEE. Google Scholar\n36.\nHori Y. Future vehicle driven by electricity and control-research on four wheel motored “UOT Electric March II”. In: 2002 7th international workshop on advanced motion control, Maribor, Slovenia, 3–5 July 2002, pp. 1–14. New York: IEEE. Google Scholar\n37.\nSakai S, Sado H, Hori Y. Motion control in an electric vehicle with four independently driven in-wheel motors. IEEE/ASME Trans Mechatronics 1999; 4(1): 9–16. Google Scholar Crossref\n38.\nWang J, Wang Q, Jin L, Song C. Independent wheel torque control of 4WD electric vehicle for differential drive assisted steering. Mechatronics 2011; 21(1): 63–76. Google Scholar Crossref\n39.\nSorniotti A, Boscolo M, Turner A, Cavallino C. Optimization of a multi-speed electric axle as a function of the electric motor properties. In: 2010 IEEE vehicle power and propulsion conference, Lille, France, 1–3 September 2010, pp. 1–6. New York: IEEE. Google Scholar\n40.\nLukic SM, Emado A. Modeling of electric machines for automotive applications using efficiency maps. In: Electrical insulation conference and electrical manufacturing coil winding technology conference, Indianapolis, Indiana, USA, 23–25 September 2003, pp. 543–550. New York: IEEE. Google Scholar\n41.\nSato Y, Ishikawa S, Okubo T, . Development of high response motor and inverter system for the Nissan LEAF electric vehicle. SAE paper 2011-01-0350, 2011. Google Scholar\n42.\nProtean Electric. In-wheel motor, torque-speed characteristics. Company website, www.proteanelectric.com/specifications (2015, accessed 7 July 2015). Google Scholar\n43.\nYASA. In-wheel motor torque–speed characteristics, http://www.yasamotors.com/products (2015, accessed 7 July 2015). Google Scholar\n44.\nSimpson A. Cost–benefit analysis of plug-in hybrid electric vehicle technology. In: 22nd international battery, hybrid and fuel cell electric vehicle symposium and exhibition, Yokohama, Japan, 22–28 October 2006, paper NREL/CP-540-40485. Golden, Colorado: National Renewable Energy Laboratory. Google Scholar\n45.\nNissan Motor Co. EV/HEV safety, LEAF battery specifications, www.nhtsa.gov/pdf/ev/Nissan_Presentation-Bob_Yakushi.pptx (2012, accessed 7 July 2015). Google Scholar\n46.\nThe MathWorks, Inc. Global Optimization Toolbox R2014a user’s guide. Natick, Massachusetts The MathWorks, Inc., 2014, section 5.3. Google Scholar\n47.\nOthaganont P, Assadian F, Marco J. Battery electric vehicle powertrain simulation to optimise range and performance’. In: International conference on powertrain modelling and control, Bradford, West Yorkshire, UK, 4–6 September 2012. The University of Bradford School of Engineering, Design and Technology. Google Scholar\nVol 231, Issue 8, 2017\nVehicle model and simulation technique\nVehicle simulations without optimisation\nMulti-objective optimisation for different BEV topologies\nConclusions\n""","0.71887636","""http://journals.sagepub.com/doi/abs/10.1177/0954407016671275""","[-0.629225,52.074389]"
"""Imperial_College_London""","""Inderscience Publishers - linking academia, business and industry through research""","""Inderscience Publishers\nThe full text of this article\n \nInternational Journal of Vehicle Design (IJVD) , Vol. 44, No. 1/2, 2007\n \nAbstract: Homogeneous charge compression ignition (HCCI) combustion is a method of internal engine combustion that incorporates principles from both spark ignition (SI) and compression ignition (CI) engines. The advantages of HCCI combustion are low NO\nx\nand soot emissions and high volumetric efficiency. Knocking at high loads is among the disadvantages of HCCI and fuel stratification can offer the possibility of reducing the knocking effect. In this study, infrared (IR) absorption was used to quantify the charge stratification in the engine, and pressure traces and fast camera images were acquired to investigate any variations between a strongly and a weakly stratified mixture.\nOnline publication date: Thu, 12-Apr-2007\n \nis only available to individual subscribers or to users at subscribing institutions.\n \nGo to Inderscience Online Journals to access the Full Text of this article.\n \nPay per view:\nIf you are not a subscriber and you just want to read the full contents of this article, buy online access here .\n \nComplimentary Subscribers, Editors or Members of the Editorial Board of the International Journal of Vehicle Design (IJVD):\nLogin with your Inderscience username and password:\n \n""","0.6759218","""http://www.inderscience.com/offer.php?id=13218""","[-0.178219,51.500505]"
"""Brunel_University_London""","""Editorial | Proceedings of the Institution of Civil Engineers - Transport""","""Proceedings of the Institution of Civil Engineers - Transport\nProceedings of the Institution of Civil Engineers - Transport\nISSN 0965-092X | E-ISSN 1751-7710\nPhD, CEng, MCIHT, MICE, PGCHE, FHEA\nx\nDepartment of Mechanical, Aerospace and Civil Engineering, Brunel University, London, UK\nAuthor Affiliations\nPublished Online: July 11, 2016\nKey:\nFree content\nTrial content\nWelcome to the August 2016 issue of Transport. This edition presents six papers covering important theoretical and practical aspects of transportation engineering. On behalf of the editorial board, I thank the authors for their hard work and valuable contributions to the journal. I would also like to extend my appreciation to our esteemed reviewers for their invaluable support.\nTransport networks are one of the most important national assets. Economic prosperity, rapid urbanisation, increasing traffic and ageing infrastructures all have immense impact on safe and efficient operation of this vital asset. Some of these factors are addressed in this issue.\nThe first paper ( Appiah et al., 2016 ) deals with truck characteristics in traffic micro-simulation. The authors present an approach to incorporating the operating characteristics of a local truck fleet in the calibration of micro-simulation models. This approach is different from conventional model calibration where focus is given to adjusting the parameters of driving behaviour logic. The second paper ( Mohapatra et al., 2016 ) reports the influence of conflicting traffic on U-turns at uncontrolled median openings under mixed traffic conditions in an Indian context. With rapid urbanisation and increased traffic volume, most urban roads in India are constructed as multi-lane roads, while many existing two-lane roads are also being widened to multi-lane roads. These multi-lane roads are generally constructed with a raised median, in order to segregate the opposing traffic movements. The authors showed that the impact of conflicting traffic is greater on four-lane roads compared to six-lane roads. In the third paper ( Zong et al., 2016 ), the authors present a model for investigating the feasibility of an integrated transportation demand management (TDM) programme in the Nanhai district of China to mitigate the traffic congestion and reduce exhaust gas emission from motor vehicles. The TDM programme includes a bus priority policy, a motorcycle restriction policy and a congestion pricing policy. The authors demonstrate that all three policies would have a positive effect on Nanhai's transport system. All three papers address key transport issues which traffic engineers and researchers will find very useful.\nIn recent years, railway industries have faced a massive demand for increasing train speeds. However, switch and turnout parts of the track are two critical parts where speed reduction is necessary. In order to develop a more efficient system, the fourth paper ( Sadeghi et al., 2016 ) presents a mathematical model of the impact of railway geometry on the safety of train running and permissible speed. The model is based on the railway vehicle and track parameters such as curve radius, switch initial angle and track gauge with running speed. The model accuracy is verified in field trials. This paper is a good example of how theoretical modelling could help to solve practical issues.\nThe fifth and sixth papers address concrete pavement rehabilitation. The fifth paper ( Lu and Rong, 2016 ), presents the impact of gradation on rubblised Portland cement concrete pavement. Rubblisation is a popular technique for upgrading severely deteriorated concrete pavement. Many previous studies have shown that rubblised concrete with a hot-mix asphalt (HMA) overlay improves pavement performance, especially its cracking resistance. The authors present two studies and demonstrate that if the rubblised gradation matches the requirement for the crushed stone base of the flexible pavement, tensile strains at the HMA overlay bottom develop at a slower pace, indicating an improvement in deterioration resistance (namely cracking) of the overlay system. This article should be a good resource for practitioners and researchers alike. The final paper ( Gao, 2016 ), presents a mathematical model for evaluating the impact of top-down surface cracking in concrete pavement. Surface cracks of concrete pavement not only impact safety and ride quality, but also reduce service life. The author shows that crack length and load position significantly influence the stress intensity factors, and that stress intensity factors are less affected by the elastic modulus of the pavement material than might be expected. Observing that studies on the mechanism of crack propagation in a cement concrete pavement are rather limited, this paper should serve to enhance current knowledge in this field.\nWe trust you find these papers useful and rewarding to read. Comments on this issue or on general journal-related matters will be received with great interest.\nReferences\n""","0.45519352","""https://www.icevirtuallibrary.com/doi/10.1680/jtran.2016.169.4.185""","[-0.472855,51.532848]"
"""University_of_Lancaster""","""Scalability improvement of the real time control protocol - Research Portal | Lancaster University""","""Scalability improvement of the real time control protocol\nResearch output: Contribution to journal › Journal article\nPublished\n<mark>Journal publication date</mark>\n10/02/2005\nEnglish\nAbstract\nScalability problems arise when the Real Time Control Protocol (RTCP), which is the control protocol of the Real-time Transport Protocol (RTP), is used in large multicast groups. The problems include: increased feedback delay, increased storage state at every member, and ineffective RTCP bandwidth usage.\nWe have designed a Scalable RTCP (S-RTCP) which is based on a hierarchical structure in which members are grouped into local regions. For every region, there is an Aggregator (AG) which receives the feedback Receiver Reports (RRs) sent by its local members. The AG summarizes important information in the RRs, derives some statistics, and sends them to a Manager. The Manager performs additional statistical analysis to monitor the transmission quality and to identify regions suffering massively from congestion.\nA simulation of S-RTCP using the Network Simulator (NS) showed that S-RTCP alleviates some of the RTCP scalability problems and makes effective use of RRs. Consequently, the feedback provides timely and useful QoS information required for network monitors and for adaptive applications. Details of the simulations and performance analysis are presented and described which show the advantages of using S-RTCP over the original RTCP.\nLancaster University Bailrigg Lancaster United Kingdom LA1 4YW\n+44 (0)1524 65201\n""","0.5137794","""http://www.research.lancs.ac.uk/portal/en/publications/scalability-improvement-of-the-real-time-control-protocol(617495ef-11f4-40a5-9755-550b907e2bc3).html""","[-2.787729,54.010394]"
"""University_of_Exeter""","""Proximity-based modelling of cross-contamination through agent-based simulation: a feasibility study | SpringerLink""",""", Volume 2, Issue 1 , pp 61–71 | Cite as\nProximity-based modelling of cross-contamination through agent-based simulation: a feasibility study\nAuthors\n2 Shares\nAbstract\nProximity-based modelling methodology enables mathematical representation of a real system that is characterised by the existence of entities that come into physical contact. Healthcare systems can benefit from this methodology since physical proximity between entities (e.g., patients, clinical items like surgical equipment and blood units) can result in the spread of infectious diseases and cross-contamination. The existing analytical techniques, which are mainly based on differential equations, are unsuitable for representing the fine-grained, micro-world view of the entity interactions that we intend to model. We therefore extend Agent-Based Simulation (ABS) by enabling individual agents to be aware of the physical location of the other agents being modelled in a 3-dimensional space – this is a perquisite for our proximity-based modelling methodology. To demonstrate the feasibility of our approach, we experiment with a scenario wherein boxes of degradable clinical items, modelled as agents, are stored in close proximity. We use Cutting and Packing Optimisation (CPO) algorithms from literature to define the arrangement of these agents in the 3-D space and to make the individual agents ‘location-aware’. An ABS model then simulates cross-contamination by modelling the spread of contaminants among the agents confined in the well-defined space. Our approach can be used to model analogous situations wherein physical proximity between entities in the underlying system is a necessary condition for entity interactions.\nKeywords\nagents agent-based simulation container loading algorithm cutting and packing optimisation cross-contamination proximity modelling \nReferences\nAcharyulu GVRK and Madhavedi S (2011) Factors contributing to perishability in traditional fresh produce distribution system: a study on tomato and banana chains in Andhra Pradesh, India. International Journal of Advanced Economics and Business Management 1 (1), 1–5. Google Scholar\nAckerley N, Sertkaya A and Lange R (2010) Food transportation safety: characterizing risks and controls by use of expert opinion. Food Protection Trends 30 (4), 212–222. Google Scholar\nAshby BH (1995) Protecting perishable foods during transport by truck. Handbook no. 669, U.S. Department of Agriculture, Argicultural Marketing Service [WWW document] http://www.ams.usda.gov/AMSv1.0/getfile?dDocName=STELDEV3021003 (accessed 29 June 2012).\nBagni R, Berchi R and Cariello P (2002) A comparison of simulation models applied to epidemics. Journal of Artificial Societies and Social Simulation 5 (3), http://jasss.soc.surrey.ac.uk/5/3/5.html , (accessed 28 September 2012).\nBischoff EE (2006) 3-D packing of items with limited load bearing strength. European Journal of Operational Research 168 (3), 952–966. CrossRef Google Scholar\nBhat RV (1988) Mould deterioration of agricultural commodities during transit: problems faced by developing countries. International Journal of Food Microbiology 7 (3), 219–225. CrossRef Google Scholar\nBunn DW and Oliveira FS (2001) Agent-based simulation - an application to the new electricity trading. IEEE Transactions on Evolutionary Computation 5 (5), 493–503. CrossRef Google Scholar\nCarley KM, et al (2006) Bio war: scalable agent-based model of bioattacks. IEEE Transactions on Systems, Man, and Cybernetics, Part A: Systems and Humans 36 (2), 252–265. CrossRef Google Scholar\nCASOS (2012) Center for Computational Analysis of Social and Organizational Systems. School of Computer Science, Carnegie Mellon [WWW document] http://www.casos.cs.cmu.edu/ (accessed 30 June 2012).\nChen H-K, Hsueh C-F and Chang M-S (2009) Production scheduling and vehicle routing with time windows for perishable food products. Computers & Operations Research 36 (7), 2311–2319. CrossRef Google Scholar\nCoburn BJ, Wagner BG and Blower S (2009) Modelling influenza epidemics and pandemics: insights into the future of swine flu (H1N1). BMC Medicine 7:30. CrossRef Google Scholar\nDowning TE, Moss S and Pahl-Wostl C (2001) Understanding climate policy using participatory agent-based social simulation. In Multi‐agent Based Simulation. Lecture Notes in Computer Science 1979/2001. (Moss S & Davidsson P, Eds) pp. 127–140, Springer-Verlag, Berlin. Google Scholar\nDunham JB (2005) An agent-based spatially explicit epidemiological model in mason. Journal of Artificial Societies and Social Simulation 9, (1), http://jasss.soc.surrey.ac.uk/9/1/3.html (accessed 28 September 2012). Google Scholar\nEidelson BM and Lustick I (2004) VIR-pox: an agent-based analysis of smallpox preparedness and response policy. Journal of Artificial Societies and Social Simulation 7 (3), http://jasss.soc.surrey.ac.uk/7/3/6.html (accessed 28 September 2012).\nEmrich S, Suslov S and Judex F (2007) Fully agent based modellings of epidemic spread using AnyLogic. In Proceedings of EUROSIM (Zupančič B, Karba R and Blažič S, Eds) 9–13 September 2007, Ljubljana, Slovenia. Google Scholar\nEubank S, et al (2004) Modelling disease outbreaks in realistic urban social networks. Nature 429 (6988), 180–184. CrossRef Google Scholar\nFerguson NM, Cummings DAT, Fraser C, Cajka JC, Cooley PC and Burke DS (2006) Strategies for mitigating an influenza pandemic. Nature 442 (7101), 448–452. CrossRef Google Scholar\nGordon TJ (2003) A simple agent model of an epidemic. Technological Forecasting and Social Change 70 (5), 397–417. CrossRef Google Scholar\nGotts NM, Polhill JG and Law ANR (2003) Agent-based simulation in the study of social dilemmas. Artificial Intelligence Review 19 (1), 3–92. CrossRef Google Scholar\nHalloran ME et al (2008) Modelling targeted layered containment of an influenza pandemic in the United States. Proceedings of the National Academy of Sciences of the United States of America 105 (12), 4639–4644. CrossRef Google Scholar\nHalloran ME, Longini Jr. IM, Nizam A and Yang Y (2002) Containing bioterrorist smallpox. Science 298 (5597), 1428–1432. CrossRef Google Scholar\nHarding PL and Dyer Jr. RMM (1942) Effect of thinning on some of the phyical and chemical characters of Valencia oranges. In Proceeding of the Florida State Hortricultural Society, 55: 34–38 [WWW document] http://www.fshs.org (accessed 29 June 2012).\nHotchkiss JR, Strike DG, Simonson DA, Broccard AF and Crooke PS (2005) An agent-based and spatially explicit model of pathogen dissemination in the intensive care unit. Critical Care Medicine 33 (1), 168–176. CrossRef Google Scholar\nKatsaliaki K and Mustafee N (2011) Applications of simulation research within the healthcare context. Journal of the Operation Research Society 62 (8), 1431–1451. CrossRef Google Scholar\nMacal CM and North MJ (2006) Tutorial on agent-based modelling and simulation part 2: how to model with agents. In Proceedings of the 2006 Winter Simulation Conference (Perrone LF, Wieland FP, Liu J, Lawson BG, Nicol DM, Fujimoto RM, Eds), pp 73–83. Google Scholar\nMacal CM and North MJ (2010) Tutorial on agent-based modelling and simulation. Journal of Simulation 4 (3), 151–162. CrossRef Google Scholar\nMustafee N, Katsaliaki K and Taylor SJE (2010) Profiling literature in healthcare simulation. SIMULATION: Transactions of the Society of Modelling and Simulation International 86 (8–9), 543–558. CrossRef Google Scholar\nPatlolla P, Gunupudi V, Mikler AR and Jacob RT (2004) Agent-based simulation tools in computational epidemiology. In Innovative Internet Community Systems, Lecture Notes in Computer Science 3473/2006. (Böhme, T, Rosillo VML, Unger H and Unger H Eds), pp. 212–223, Springer-Verlag, Berlin. Google Scholar\nPisinger D (2002) Heuristics for the container loading problem. European Journal of Operational Research 141 (2), 292–382. CrossRef Google Scholar\nRaberto M, Cincottia S, Focardib SM and Marchesic M (2001) Agent-based simulation of a financial market. Physica A: Statistical Mechanics and its Applications 299 (1–2), 319–327. CrossRef Google Scholar\nRobinson EA and McLeod J (1989) Packaging device and method. United States Patent, Patent Number: 4807424, Date of Patent: 28 February1989 [WWW document] http://www.google.com/patents/US4807424 (accessed 29 June 2012).\nShaliz CR (2006) Methods and techniques of complex systems science: an overview. In Complex Systems Science in Biomedicine (Deisboeck TS and Kresh JY, Eds), pp 33–114, Springer, New York. CrossRef Google Scholar\nSibbel R and Urban C (2001) Agent-based modelling and simulation for hospital management. In Cooperative Agent: Applications in the Social Sciences (Saam NJ and Schmidt B, Eds), pp 183–202, Kluwer Academic Publishers, the Netherlands. CrossRef Google Scholar\nSilcowitz-Hansen M (2010) Jinngine – a physics engine written in java. [WWW document] http://code.google.com/p/jinngine/ (accessed 29 June 2012).\nSong J, Haasb CT and Caldas CH (2007) A proximity-based method for locating RFID tagged objects. Advanced Engineering Informatics 21 (4), 367–376. CrossRef Google Scholar\nStainsby H, Taboada M and Luque E (2009) Towards an Agent-Based Simulation of Hospital Emergency Departments. In Proceedings of the 2009 IEEE International Conference on Services Computing, 21–25 September, Bangalore, Indiapp 536–539, IEEE Computer Society. Google Scholar\nTournas VH and Katsoudas E (2005) Mould and yeast flora in fresh berries, grapes and citrus fruits. International Journal of Food Microbiology 105 (1), 11–17. CrossRef Google Scholar\nVaught JB (2006) Blood collection, shipment, processing, and storage. Cancer Epidemiology, Biomarkers & Prevention 15 (9), 1582–1584. CrossRef Google Scholar\nWascher G, Haubner H and Schumann H (2007) An improved typology of cutting and packing problems. European Journal of Operational Research 183 (3), 1109–1130. CrossRef Google Scholar\nWorld Health Organisation (2002) Guidelines on Prevention and Control of Hospital Associated Infections. WHO, Regional Office for South-East Asia, New Delhi. Google Scholar\nWorld Health Organisation (2003) Guide to good storage practices for pharmaceuticals. WHO Technical Report Series No. 908, WHO, Geneva, Switzerland. Google Scholar\nWorld Health Organisation (2009) WHO guiding principles on human organ transplantation. Report of the Regional Meeting, WHO Western Pacific Region, Malaysia. Google Scholar\nXJ Technologies (2011) AnyLogic agent based modelling – help files. [WWW document] http://www.xjtek.com/anylogic/help (accessed 3 November 2011).\nCopyright information\n""","0.43663695","""https://link.springer.com/article/10.1057%2Fhs.2012.16""","[-3.533832,50.735262]"
"""Imperial_College_London""","""Realising transition pathways for a more electric, low-carbon energy system in the United Kingdom: Challenges, insights and opportunitiesProceedings of the Institution of Mechanical Engineers, Part A: Journal of Power and Energy - Jason Chilvers, Timothy J Foxon, Stuart Galloway, Geoffrey P Hammond, David Infield, Matthew Leach, Peter JG Pearson, Neil Strachan, Goran Strbac, Murray Thomson, 2017""","""Figure 5. The dynamic relationship between energy security, framing of energy and governance logics.\nSource: Johnson et al. 30\nShifting views about how security affected the framing of energy emerged between WWI and WWII; leading to the prevalence again of hybrid governance. A relational approach was used by Johnson et al. 30 to explore the emergence of policy support for fuels and their final withdrawal. That showed how and why emerging technological substitutes can founder and transitions fail in times of economic instability. It led to shifting hybrid state and market governance between incumbents (i.e. the oil majors) and newcomers (e.g. DCL and ICI). These studies consequently reflect a partial historical analogue for the hybrid roles of the state and the market in energy governance (e.g. UK Electricity Market Reform (EMR)), as well as the changing priorities within the energy policy trilemma between climate change mitigation and the provision of secure and affordable energy services. The case studies also provide insights about technological substitutes and new infrastructures (electrifying transport and heat), as well as concerns about the influence of incumbent actors and institutions influence to either advance or constrain low-carbon transitions.\nA further supply-side study of the development of the integrated UK natural gas system over the period 1960–2010 by Arapostathis et al. 31 has illustrated the way in which such integration was closely linked to governance patterns. This explored the development of the gas system in two transitions: (i) from town to natural gas with state governance logic (under the management of the nationalised British Gas Corporation); and (ii) then privatisation and liberalisation after 1987. The latter major structural change is regulated by Ofgem, with a Uniform Network Code (UNC) overseen by the Joint Office of Gas Transporters. Vertical integration has been aided by new control and communication technologies, together with internationalisation via gas interconnectors. That reduced uncertainties, but increased the system’s complexity. This case study 31 provided an analogue for the challenges of integrating large, infrastructural technical systems for a sustainability transition. It is inscribed within the MLP approach yet concentrates on system integration as a complex and uncertain socio-technical process. It indicates how quite dramatic changes in the UK natural gas structure are mirrored in regime formation (see Figure 1 ).\nLittle historical work has been undertaken on energy demand reduction. A study of electric heating in early post-war Britain 32 when electric fires were used at peak times and were therefore particularly problematic in terms of energy end-use, offers insights into the challenges often associated with demand reduction. The Electricity Development Association (EDA), originally established as a public relations arm of the UK electricity industry, tried simultaneously to reduce undesirable peak demand, whilst encouraging increased demand more generally. In the late 1940s, it recommended that electric fires should not be used to meet peak demand. However, in the 1950s and 1960s it concentrated on promoting off-peak heating appliances. It first sought to do this in the United Kingdom via under-floor heating, and then block storage heaters typically composed of clay bricks or other ceramic material. The study under the auspices of the transition pathways consortium by Carlsson-Hyslop 32 analysed the way in which the London County Council (LCC) and its tenants adopted and adapted electric underfloor heating. It concluded that attempts by the electricity industry during the period 1945–1964 had only a limited effect on the trend towards rising energy end-use demand. This was, in part, due to EDA promotional efforts. This analysis is consistent with that on households’ engagement with customer-facing elements of a smarter grid, such as smart meters or energy monitors (see, e.g. a predecessor consortium study by Hargreaves et al. 33 ). Social variables like daily routines, individual preferences and social relations in a household were found by Hargreaves et al. 33 to be important for energy demand reduction. This may reflect a co-evolution of technology with social practices, changing routines, and behaviour. It illustrates the kinds of processes, practices, interactions and modes of governance that need to be considered if demand management/energy efficiency are to succeed in containing energy use and GHGs, whilst enhancing the quality of people’s lives.\nPolicy makers tend to have little institutional memory of what has worked or has not worked in terms of energy sector interventions, because job changes are used to enable UK civil servants to gain experience and avoid accumulating positional or departmental loyalty, and because ministers often serve for short periods (from 2008 to 2015 of the four Secretaries of State for Energy and Climate Change, one served for less than 2 years and another for just over 1 year). Historical analyses/stories of past transitions therefore help them (and other stakeholders) to understand how and why transitions have previously succeeded or failed. They also indicate how long they can take to implement and the reasons why. Overall insights and lessons from such studies can be summarised as:\nThe historical studies have shown that rapid change is possible, but not necessarily frequent. It may require a recognition of the need to change, openness to experiment and a high degree of co-ordination (e.g. the natural gas transition). These studies illustrate how co-evolutionary and co-constructed are the material or physical aspects with the social, political and institutional aspects. For example, the 1966–1977 conversion from town gas to natural gas required both technical changes, including building the national gas grid and installing new burners in millions of gas appliances, along with major institutional reorganisation, new workforce training and political support. 31\nHistorical studies of two alternatives to petrol in the inter-war period 30 show how and why emerging technological substitutes can founder and potential transitions fail in times of economic instability, shifting governance and competition between incumbents and newcomers.\nA further supply-side study of the development of the integrated UK natural gas system over the period 1960–201031 suggests that such integration was closely linked to governance patterns. It indicated how quite dramatic changes in the UK natural gas structure are largely reflected in regime formation and change.\nThere is little historical work on demand reduction. However, the recent study of the EDA and domestic electric heating in post-war Britain 32 suggests that their attempts had limited impacts on the trend of rising demand, and thereby illustrates the challenges facing demand reduction today.\nHorizon scanning and technology assessment of energy systems\nSection:\nTechnological choices in the UK power sector are likely to vary significantly out to 2050. For example, over the last few years the outlook for both coal-fired power stations with CCS and nuclear power has changed dramatically. The UK Government indicated (in November 2015) their wish to phase out unabated coal-fired power stations by 2025, and giving new gas-fired power stations priority. Likewise, the prospects of new nuclear build has been hit by both concerns following the 2011 Fukushima disaster in Japan and a reassessment of the economics of nuclear power by some of the big players, such as the investment decision by the French utility eDF Energy in regard to the construction of the Hinkley Point C nuclear power plant (in Somerset). These short-term changes in attitudes to low-carbon technologies mean that the technology choices implicit in each of the existing pathways need to be kept under continuous review. Horizon scanning involves a portfolio of methods that enable energy researchers and other power sector stakeholders to increase their awareness of important emerging influences on the UK energy system and its environment. It provides a major strand in proactive risk management 11 and strategic thinking as the UK energy sector moves forward. Parker et al., 34 for example, used a modified Delphi technique for horizon scanning in order to identify some 30 emergent policy issues, which strongly featured science and technology, and which would necessitate public engagement as the policies were being developed. This was driven, in part, by concerns over the use of hydraulic fracturing (or fracking) by fossil fuel companies for shale gas extraction in the United Kingdom. A disparate group of people with interests over the science and policy interface (e.g. policy makers and advisers, academics and the private sector) initially elicited a long list of issues. These were then refined into a shorter list that were viewed as being of top priority for policy makers. They included challenges related to energy and environment, such as policies concerning interdisciplinary whole energy systems science (incorporated by a partner in the Realising Transition Pathways Consortium (Jason Chilvers) 34 ). A variety of alternative techniques are available for use in identifying emerging issues in the UK energy sector. Arup Foresight (part of the independent firm of designers, planners, engineers and consultants) have, for example, employed STEEP (social, technological, economic, environmental, political) analysis to examine drivers for change in both the energy and climate change fields. The Realising Transition Pathways Consortium have used a similar approach, in conjunction with more formal methods of Technology Assessment 35 , 36 to evaluate a number of the main disruptive energy technologies. These studies have sought to identify the components of a balance sheet of technological credits and debits in order to evaluate their societal impacts, and to determine whether they are compatible with Britain’s move towards a low-carbon future in 2050 and beyond.\nIndicative energy technology assessments (ETAs) have been carried out for a variety of energy technologies, e.g. UK shale gas extraction, 37 carbon capture and storage (CCS), 38 , 39 advanced rechargeable batteries, 40 rare earth elements (REE) as a constraint on clean energy technologies, 41 nuclear power plants 42 and tidal power barrages. 43 These ETAs were all indicative in the sense of being a simplified evaluation and illustration of the performance of state-of-the-art devices. Nevertheless, such assessments provide a valuable evidence base for developers, policy makers and other stakeholders. Each technology was evaluated using a combination of quantitative and qualitative methods within the spirit of the STEEP approach. The most controversial of these studies was arguably that concerning the benefits and ‘costs’ of shale gas fracking in Britain. 34 , 37 Exploratory drilling in the United Kingdom is at an early stage, with great uncertainty over the scale of the potential shale gas resource. 37 However, such activities are already meeting fierce community resistance. Like all energy technologies, it exhibits unwanted side-effects that simply differ in their level of severity compared to other options. Successful extraction might contribute positively in terms of fuel security and independence, as well as jobs and growth. 37 Shale gas may also make a contribution to attaining the UK’s statutory GHG emissions targets, although potentially harmful environmental impacts need to be satisfactorily resolved via appropriate monitoring and robust regulation. It is unlikely that gas bills for UK household and industrial consumers would fall dramatically as they have done in North America, because Britain is linked to the wider European gas market. Anything produced in the United Kingdom would be a ‘drop in the ocean’ compared to imports via either pipelines or by way of liquefied natural gas (LNG) tankers. Finally, the socio-economic advantages and disadvantages of shale gas fracking are not evenly distributed between various communities and demographic groups. 37 Community engagement in a genuinely participative process – where the government is prepared to change course in response to the evidence and public opinion – will consequently be critically important for the adoption of any new energy option.\nCCS facilities coupled to fossil fuelled power plants or industrial sites provide a key climate change mitigation strategy that potentially permits the continued use of fossil fuel resources, whilst reducing the CO2 emissions. Hammond and Spargo 39 highlight the potential design routes for the capture, transport, clustering and storage of CO2 from UK power plants. Both currently available and novel CCS technologies were evaluated. Due to lower operating efficiencies, the CCS plants showed a longer energy payback period and a lower energy gain ratio than conventional plant. There are also several technical and financial obstacles that need to be overcome, 38 including the adoption of an appropriate legislative framework and the need for full CCS chain risk assessments. There are uncertainties over the full-scale power plant CCS technical performance and costs, which may only become clearer when the first demonstrators are operational. Unfortunately, the UK Government cancelled (on 25 November 2015) their £1 bn CCS competition shortly before the winning consortium was due to be announced. Inevitably, the bidding companies were dismayed by this outcome and the prospects for CCS in Britain in the short term now looks rather bleak. Prior to this, the Government had established a CCS Cost Reduction Task Force 44 as an industry-led joint venture to assist with the challenge of making CCS a commercially viable operation by the early 2020s. The main cost-reduction opportunities were seen as being 44 : (i) transport and storage scale and utilisation, (ii) improved financeability for the CCS chain, and finally (iii) improved engineering designs and performance. Greater financial incentives for carbon abatement could, in principal, be secured through a higher carbon price from the European Union Emissions Trading Scheme (EU ETS), although that has been a significant disappointment in terms of the carbon price level. A collaborative study between the Energy Technologies Institute (ETI), a public-private partnership of key industrial companies and UK funders of energy RD&D, and the Ecofin Research Foundation (ERF) 45 has recently examined the conditions required for mobilising private sector financing of CCS in the United Kingdom. They argue that this technology would be a ‘huge prize’ that could cut the annual costs of meeting the 2050 carbon target by up to 1% of gross domestic product (GDP). 38 , 39 , 45 But they noted that the prevailing financial market conditions are demanding. In order to meet this challenge, they suggest that the United Kingdom needs to build confidence in long-term policy, develop attractive pricing for CCS contracts with suitable risk sharing, put in place an appropriate regulatory and market framework, and devise new ways to offset North Sea storage liability risks. 45 Many believe that the UK Government will need to return to CCS deployment in order to meet its 2050 GHG emissions reduction target in a cost-effective way. 46\nTwo other large-scale power generators that could be available to help secure a low-carbon future for the United Kingdom are nuclear power plants 42 and tidal barrages. 43 The lives of existing nuclear plant has typically been extended to around 40 years (e.g. Hunterston B was financed for 25 years with an expectation of 35 years, and subsequently extended by 7 years). Nevertheless Britain, as with other nuclear-powered European countries, will be progressively decommissioning its older nuclear power stations during the next decade or so. This will leave only the Sizewell B pressurised water reactor (PWR) station in the United Kingdom, with nuclear power holding a considerably reduced share of electricity generation (perhaps as low as 3% by 2020 from around 20% in the winter of 2013–2014). A new generation of nuclear power stations may therefore need to be part of the power generation mix in order to decarbonise the electricity sector by around 2030–2050. In Europe these plants are likely to be variants of the third-generation European pressurised reactor (EPR) design. Emerging (novel) nuclear reactor designs are thought to be inherently safer and less costly 42 ; perhaps having a 25% lower generating cost than present systems. However, the research by the former UK Sustainable Development Commission 47 suggests that a doubling of Britain’s existing nuclear capacity would only yield an 8% cut on CO2 emissions by 2035. Over the longer term, it is likely that the European governments will want to keep a watching brief on advanced nuclear reactors (including modular designs) that are currently being developed in France/Germany, South Africa and the United States. Nevertheless, they will no doubt want to be reassured that such new technologies will be commercially viable. 42 The adoption of either short- or medium-term technologies would obviously be critically dependent on public attitudes to nuclear power in Britain and elsewhere. 1 , 11 , 42 Both the Cardiff-Weston and the smaller Shoots barrages on the River Severn between Somerset and south Wales have been evaluated by Hammond et al. 43 using various ETA techniques to determine their net energy output, carbon footprint and financial investment criteria, alongside various critical technical and environmental issues. These tidal power schemes were assessed over their foreseen lifespan of 120 years in terms of its cradle-to-site, operation and maintenance requirements. The proposed Cardiff-Weston Barrage would yield relatively attractive figures of merit in terms of its net energy and carbon emissions, although its financial performance is poorer than alternative power generators. Comparisons were made with the much smaller, Shoots Barrage scheme that would be located up-river of the Severn road crossings, and which is favoured by environmental groups, because of its more benign ecological and environmental impacts. 43\nThe suitability of advanced rechargeable battery technologies (ARBT) for different applications, such as electric vehicles (EV), consumer electronics, load levelling and stationary power storage, has been the subject of another ETA. 40 These energy storage devices were compared to more mature nickel–cadmium (Ni–Cd) batteries in order to gain a sense of perspective regarding the performance of the ARBT. Lithium (Li)-ion batteries (LIB) currently dominate the rechargeable battery market and are likely to continue to do so in the short term in view of their excellent all-round performance, 40 and firm grip on consumer electronics. However, in view of the competition from Li-Ion Polymer (LIP) batteries their long-term future is uncertain. Although, if safety concerns are overcome and costs fall significantly, there may be growth in the EV sector and to a lesser extent load-levelling, where LIB can exploit their relatively high cycle life. 40 Rare earth batteries and magnets are key elements of hybrid vehicles and gearless wind turbines, and phosphors are critical in energy saving lighting. Hammond and Mitchell 41 argued that ‘rare earth elements' (REE) may place a significant constraint on the development of some low-carbon (or clean) energy technologies. These materials are not actually rare in terms of their abundance, but the number and location of mines are restricted due, in part, to economic considerations. Current REE reserves stand at about 110 million tonnes with around half in the People’s Republic of China (PRC), although other countries like the United States, Commonwealth of Independent States (CIS) (the former Soviet Republics) and Australia hold substantial reserves. Production in China dominates the market, with ∼97% of the global total, and this will remain so until new mines are developed. The PRC has limited its export of REE in order to give preference to the export of manufactured products. Diversity of the global supply chain is therefore a crucial issue moving forward (see Figure 6 ). It is likely that supply constraints will become less critical in the medium to long term as more mines come into operation, and thus further reserves become available. 41 Such constraints could be eased by reducing the amount of material required per application, or changing the technology altogether. LIB, 40 for example, are already a viable replacement for nickel-metal-hydride units in hybrid vehicles. Their costs have fallen from >£1680/kWh in 1990 to <£140/kWh today. REE are not currently recycled, either pre or post-use. There are processes available that could be utilised for this purpose, although they do not currently appear to be economically viable options. 41\nDownload in PowerPoint\nFigure 6. Diversity of global ‘rare earth elements’ (REE) supply over the medium term. Note: ‘Current’ reflects the 2011 baseline. 41\nIn order to round-off these ETA-like studies, an evaluation of the energy densities and spatial footprints of both conventional and renewable generators was undertaken by Cheng and Hammond 48 on a life-cycle (or cradle-to-gate) basis. It was stimulated by a desire to test an assertion by Fells 49 that renewable energy technologies for electricity generation (such as bioenergy plants, solar PV cell arrays, wind turbines and the like) have a low energy density in comparison with fossil fuel or nuclear power stations. He suggested, for example, that if all the wind farms operating in the world in about the year 2000 were to be concentrated on the South Downs of England, then only 10% of UK electricity demand would be met. On a similar basis, he argued 49 that in order to replace Scotland’s two nuclear power stations a total of 10,000 250 kW LIMPET-type wave power generators (i.e. shoreline oscillating water column devices) would be required of the type installed on the island of Islay (one of the Hebridean islands; off the north west coast of Scotland). In the case of biomass energy, Fells 49 postulated that an area the size of the county of Kent would have to be covered in coppiced willow in order to replace half of the output from Dungeness B nuclear power station (a 1040 MW plant consisting of two AGRs, and located in the same county). The nuclear fuel cycle (both with diffusion and centrifuge enrichment) was found by Cheng and Hammond 48 to have the highest energy density of the technologies they examined, with bioenergy plants having the lowest. Their results are summarised in Table 2 , where they are compared with those of Gagnon et al. 50 and of the US Environmental Working Group (EWG). 51 Onshore wind power exhibited a relatively promising energy density and is greater than that of its offshore counterpart, the energy density of the latter fell below that of solar PV arrays. Thus, renewables were found to produce dilute electricity overall with a spatial footprint that is orders-of-magnitude higher than for conventional sources. That was in line with the views of Fells, 49 although there are many other sustainability criteria that will determine their usefulness in the transition towards a low carbon future. 48\nTable 2. A comparison of the spatial footprints per unit of output from various power generators.\nTable 2. A comparison of the spatial footprints per unit of output from various power generators.\nSource: Adapted from Cheng and Hammond. 48\nView larger version\nThe horizon scanning and technology assessment of the energy options 34 – 36 that will influence the three UK transition pathways contributes to an understanding the future interplay of the energy policy trilemma, i.e. achieving deep GHG emission cuts, whilst maintaining a secure and affordable energy system, and addressing how resulting tensions might be resolved. Overall insights and lessons from such studies can be summarised, for example, as:\nShale gas extraction has potential unwanted side-effects, and is already meeting community resistance and controversy. A balance sheet approach has been used to determine the benefits and disbenefits of shale gas fracking. 37 It may contribute to energy security, jobs and growth, as well as attaining national GHG targets over the medium term. Thus, it might form the basis of a transitional energy strategy for the United Kingdom, although the wider environmental impacts will require appropriate and robust regulations to be enforced.\nCarbon capture and storage (CCS) from fossil-fuel power stations is likely to be a key technology in achieving a low carbon future in the United Kingdom at a reasonable cost. 38 Energy and carbon analyses have been undertaken, along with indicative cost estimates, for fossil-fuelled power stations with and without CCS. 39 It could significantly cut GHG emissions, provided technological and financial obstacles can be overcome.\nLarge-scale nuclear power plants and tidal power barrages both exhibit attractive figures of merit in terms of their overall energy performance and near-zero carbon emissions, but have very long financial payback periods. 40 , 43 The latter makes them difficult to undertake with the support of only private sector investors. Nuclear power also gives rise to ongoing problems with high and intermediate-level waste disposal, 40 although a deep underground repository is the preferred option. The siting of such a facility has yet to be resolved in the United Kingdom. A tidal barrage built across the Severn Estuary would inevitably give rise to significant ecological modifications to the aquatic environment. 43\nThe suitability of ARBT have been evaluated for different applications. 40 While LIBs are likely to continue to dominate the rechargeable battery market in the short term, their long-term future is uncertain, because of competition from LIP batteries. There may be some LIBs growth in the electric vehicle sector, if safety concerns are overcome and costs fall significantly, and somewhat less in load-levelling, through their relatively high cycle life.\nRare earth batteries and magnets are key elements in the hybrid vehicles and gearless wind turbines, as are phosphors in energy-saving lighting, but short-term economic mining constraints on REE may limit their development. 41 Such concerns could also be eased by using less material per application, recycling REE, either pre- or post-use, or changing the technology altogether.\nThe energy densities and spatial footprints of various power generators were evaluated on a life-cycle basis. 48 The nuclear fuel cycle was found to have the highest energy density, with bioenergy plants having the lowest. Onshore wind power exhibited a relatively promising energy density; being greater than that for its offshore counterpart. The energy density of the latter fell below that of solar PV arrays.\nElectricity system and network modelling and evaluation\nSection:\nBackground\nA number of reputable studies have been undertaken over recent years that support low or zero carbon energy scenarios for the United Kingdom. These include those produced by the British Government’s Department of Energy and Climate Change (the DECC 2050 Calculator 52 ), the UK Energy Research Centre (the UKERC Energy 2050 Project 53 ), and the Tyndall Centre for Climate Change Research. 54 They all enable insights to be drawn regarding the realism of each scenario set, and reflect a range of aspirations from those wishing to achieve 2050 carbon reduction targets: 80% in the case of DECC 52 and UKERC 53 projections. However, the five Tyndall decarbonisation scenarios 54 focused on an earlier 60% carbon reduction target for 2050, although they employ a distinctive backcasting approach generated and reviewed with the aid of stakeholders. On the other hand, the DECC 2050 Calculator is basically an engineering-based, Excel spreadsheet model that is open source and arguably transparent. The tool permits users to select their own combination of technologies to achieve an 80% reduction in GHG emissions by 2050, whilst ensuring that energy supply and demand are balanced. The UKERC Energy 2050 Project 53 employed a core four-scenario core set that was underpinned by a single cost-optimisation model (UK MARKAL). It took ‘an eclectic approach to scenario building’ 53 with a backcasting dimension to achieve a combination of UK energy resilience and climate change mitigation. In contrast, the quantification of the three pathways developed by the Realising Transition Pathways Consortium was underpinned by a suite of multiple models.\nFrom narrative descriptions of the transition pathways to model formulation\nA range of models were developed to elaborate/explore demand, supply and infrastructure aspects 26 and feed into revising the pathways, both quantitatively and qualitatively in the second iteration for version 2.1 of the transition pathways. Qualitatively this has involved building narrative stories out to 2050, whilst quantitatively it has necessitated the construction of matching, consistent spreadsheets of demand, supply, technologies and (implicit) infrastructure. This was a challenging and time-consuming process, but one that yielded a valuable learning experience. Electricity models were used to variously address hourly, annual and seasonal balancing on regional, national and international scales. An informative multi-modelling comparison of the pathways was then undertaken to innovatively link and embed narrative storylines to technological, economic, social and institutional drivers and constraints. The framework of eight models and appraisal tools (see Figure 7 for the suite of individual models as of April 2013) were iteratively linked and checked for consistency between the various tools and the narrative descriptions of the pathways. This exercise was undertaken by the postgraduate researchers functioning as what was known in the Realising Transition Pathways Consortium as the Engine Room 55 the researchers working independently of the consortium leadership (the academic co-investigators).\nFigure 7. The framework of quantitative models utilised within the Realising Transition Pathways project.\nSource: The Transition Pathways Consortium. 55\nThis cross-scale study was based on the storyline or narrative description of the CC pathway, 8 , 24 which was then evaluated via six power system models and two appraisal techniques. It was used to iteratively link the CC narrative with the models/appraisal tools. Harmonised assumptions on power system inputs and system output targets for each model or tool were initially extracted from the CC pathway storyline. 8 , 24 The framework of models (see again Figure 7 ) was then employed to map the key features of each model/appraisal tool in terms of their temporal, spatial and disciplinary perspectives. Clearly, the narrative description of the CC pathway 8 , 24 was found to be critical for transmitting information about governance logic and the choices of key actors. Nevertheless, many of these parameters were found to be inconsistent. Typically, the CC storyline resulted in an overestimate of demand reduction levels, the uptake of CCS and marine renewables. This is because the narrative storyline tends to underestimate the technical and economic challenges associated with these levels of demand reduction and uptake of CCS and marine renewables. These were subsequently highlighted through the quantitative modelling analysis. Likewise, the narrative description led to an underestimate of the supply-demand balancing requirement, the need for back-up capacity, and the role of nuclear power and interconnectors with Europe, compared to the challenges identified through the modelling in achieving these outcomes.\nThe eight models and appraisal tools (in the order of their breadth of power system boundaries, and in line with the sequence indicated in Figure 7 ) were:\nDemand: This energy demand model (for full details see Barton et al. 28 ) is a highly disaggregated simulation model of UK energy demand for both the domestic and non-domestic sectors. Its primary inputs are a range of characteristics, 26 , 52 including energy service levels, user practices, choices of appliances, building fabric, fuels, deployment of distributed generation, and other parameters, with its main output being final energy demand across the UK building stock.\nFESA: The future energy scenario analysis (FESA) model (for full details see Barnacle et al. 27 ) is a single-year UK power generation and demand simulation model, incorporating 1-hour time steps for dispatch modelling. The overall structure of this model is depicted in Figure 8 . It utilises 2001 UK Met Office weather data on temperature, wind speeds, solar radiation and wave height. The FESA model incorporates technical feasibility constraints on the power network, and enables hourly grid-balancing.\nD-EXPANSE: This model (dynamic version ofexploration ofpatterns innear-optimal energyscenarios; for full details see Trutnevyte 56 ) is a power system optimisation model. D-EXPANSE systematically explores the various near-cost-optimal pathways, as well as the structural uncertainty, based on key inputs of demand, technology costs and characteristics, fuel prices and power system transmission topology. Its main output in terms of UK power systems configuration and costs has been validated by comparing its outputs with that for a variety of existing, well-established whole system models and their cost estimates for the UK. 55\nEconA: The economic appraisal (EconA) appraisal technique (for full details see Trutnevyte et al. 55 ), is an accounting model that systematically calculate and compare investment and total system costs for power generation, transmission and distribution under the three UK transition pathways. The key inputs are the ranges of component technology costs, efficiencies and other technical characteristics. The quantitative output is disaggregated into shares of different power generation technologies, thereby allowing the assessment of economic feasibility of any given pathway (such as the CC pathway in the contribution of Trutnevyte et al. 55 ).\nBLUE-MLP: This model (behaviourlifestyles anduncertaintyenergy model withmulti-levelperspective on transitions) is a probabilistic systems dynamics simulation model (for full details see Trutnevyte et al. 55 ). Its key inputs derive from sector- and actor-specific behavioural elements 55 that arise from the MLP transitions approach 17 , 20 (see again the schema depicted in Figure 1 ), and include the macro-landscape pressures landscape (including government decisions or developments in the international context), the social-technical regime (e.g. the current UK power system structure and its regulation), and niche innovations (e.g. lifestyle-influenced changes in demand). Its key outputs are technology and demand change uncertainty ranges for future energy and emissions pathways.\nEEA: The tool designated as energy and environmental appraisal (EEA) is an accounting framework based on the environmental life-cycle assessment (LCA) of the UK power system (for full details see Hammond et al. 57 and see section ‘Whole systems energy and environmental appraisal of the different energy mixes’ below). Based on a broad inputs set of technology-specific emissions factors, 26 , 58 the key outputs are 18 environmental impact categories 57 that are evaluated from cradle-to-gate, accounting for both upstream and operational (or stack) emissions. The categories included climate change (via GHG emissions), fossil fuel depletion, human toxicity, particulate matter formation and agricultural land use change.\nHESA/UK+: This optimisation model is an enhanced version of the hybrid energy system analysis (HESA) tool (for full details see Barnacle et al. 27 ). The model cost-optimises the UK electricity network, based on the energy hub concept, using key inputs of national power demand and generation mixes as input assumptions/parameters. The principal output is spatial disaggregation of generation, storage, transmission and distribution in terms of 17 onshore nodes, five offshore zones and 39 connections.\nHAPSO: The holistic approach to power system optimisation (HAPSO) model is a bottom-up, cost-minimisation power system model (for full details see Strbac et al. 59 ), with key inputs of technology costs and characteristics as well as electricity system topology. The model’s key output is the optimal power generation, storage, transmission, and distribution network infrastructure requirements, as well as their associated cost. The model then simultaneously estimates long-term investment requirements and short-term operational decisions, including in regard to hourly dispatch, demand side response (DSR; whereby customers are financially incentivised to lower, or shift, their electricity use in order to reduce demand at peak times), storage cycles and power interconnection.\nDownload in PowerPoint\nFigure 8. A schematic representation of the Future Energy Scenario Analysis (FESA) model. Source: Updated from Barton et al. 28\nThese models and appraisals yield a broad spectrum of cross-scales insights 55 covering system boundaries, time, space, and disciplines (see Figure 7 ). They were found to reveal a rather fragile nature of the transition pathway narrative descriptions or storylines. 55 The CC pathway storyline was found, for example, to imply an overestimation of the potential for power demand reduction and for the uptake of marine renewables. The necessity for CCS to meet the 2050 UK GHG emissions target was likewise overestimated. However, they were found to downplay the challenge of supply-demand balancing and the need to use gas power plants as a back-up capacity, as well as the role of nuclear power and electricity interconnectors with Europe.\nThese and other findings have benefited from a whole systems and collaborative working aimed at elaborating and examining pathways for realising a transition to a low carbon, secure and affordable UK energy system by 2050. Thus,\nA critical review of quantitative models for exploring socio-technical transitions has aided interdisciplinary learning between the different developers and users of the storylines, models and appraisal tools. 8 , 24 , 26 – 28 , 55 – 58\nThe iterative improvement of the qualitative narrative descriptions for the pathways, combined with that for a diverse range of models and appraisal techniques, is likely to be a key element in the robust development of future transition pathways and energy scenarios. 55\nAnnual demand modelling\nThe Demand model 28 , 55 assembles trends for the overall annual demand for electricity and fuels to 2050. The model builds from bottom-up representations of the energy service demands in the major sectors, the performance of existing buildings and end-use equipment, and the prospects for technological improvements and behaviour changes. Heating technologies in the domestic, service and commercial sectors are modelled in detail; industrial process heat is represented through underlying sub-sector demands and expected trends. Data were drawn initially from the Energy Consumption in the United Kingdom (ECUK) 60 database with further disaggregation by end-use and service employing assumptions about future technical change developed based on multiple sources. 28 The trends for electrification of transport are modelled, linked to work within the project. 61 Assumptions were compared to those in the DECC 2050 Calculator. 52\nIntroducing the spatial dimension to demand, the HESA model 26 , 27 utilises network theory to calculate flows, the energy hub concept to represent the conversion of energy between carriers (i.e. generation, including renewable energy sources), and deterministic least-cost optimisation (of fuel, generation, transport). The UK+ model includes physical descriptors of all generators, energy demands and storage requirements. It contains the 17 UK onshore nodes, as well as having nodes representing five offshore zones (Norway, Belgium, Netherlands, France and the UK Continental Shelf (UKCS)). The model contains multiple carrier transportation networks to/from international nodes (39 connections facilitate the transportation of electricity, gas, coal, oil, biomass and CO2) with demand and supply capability to represent international nodes (thereby facilitating international trade in energy carriers). HESA and UK+ have been used in combination to model an integrated multi-energy carrier network and applied to local, regional and national scale case studies in the context of the transition pathways, e.g. combined gas and electricity bulk flows with constraints across the United Kingdom.\nThis combination of models 55 indicates a temporal mismatch between low-carbon supply and demand may lead to very low utilisation factors of dispatchable generation, i.e. power plants that can be turned on, off, or have their output varied in a relatively short time at the request of the network operator or plant owner. This affects financing of gas-fired power stations, as well as hampering the prospects for CCS. Supply-demand balancing leads to increasing curtailment of renewables and additional fossil fuel use, illustrates the potential for electricity storage, but suggests that innovation would be required for longer term storage. This combination of models has also been employed for stress testing, optimisation and uncertainty analysis of the pathways. Different technology mixes were found to drive different regional patterns of investment as displayed in Figure 9 . Consistently high investment is required in the South East, South West, East of England and in Scotland. Other regions, such as the North East of England, were found to be exposed to large swings in potential investment under different pathways. Thus, the lessons learned from annual demand modelling were:\nAn increase in capacity of the electrical North-South corridor is essential for the success of all three pathways. A decrease in use of the national natural gas transmission system as a result of decarbonisation means an under-utilisation of the network. Total transmission and generation costs are likely to increase out to 2050 across all three of the UK transition pathways.\nEven in a system with greater localised energy sources (such as under the TF pathway) there is still a need for national energy infrastructures for electricity and gas.\nNote: Estimated via the FESA model. 27 , 28 , 55\nThe temporal mismatch between low-carbon generation and demand profiles may lead to very low utilisation factors of dispatchable generation. This is likely to affect financing of gas-fired power stations, and hampers prospects for CCS, which will need to be fitted to fossil-fired generation to achieve long-term carbon budgets. The supply-demand balancing issues will lead to increasing curtailment of renewables and additional consumption of fossil fuel. This leads to significant potential for electricity storage, although innovation will be needed to bring forward options for longer term storage. Thus, overall insights and lessons from hourly grid-balancing can therefore be summarised as:\nOne year, hourly modelling of Great Britain (GB) – the UK less Northern Ireland – grid balancing using the FESA model indicates a temporal mismatch of low-carbon generation against conventional demand profiles. This presents a much greater challenge to grid balancing than often assumed, e.g. in the DECC 2050 Calculator. 52\nAmbitious low-carbon pathways can lead to very low utilisation factors of dispatchable generation, including that with CCS, which could undermine the economic viability of this innovative, disruptive technology.\nA future system operator (in 2050 or beyond) will need to bear in mind a number of factors in order to secure grid-balancing 27 : the size of the interconnector compared to the peak surplus power requirements; the economic value of exported electricity (which may be quite low) compared to the value of fuel saved by using more resistive heating; and the necessity of maintaining a stable electricity grid (in the frequency and voltage domains) in the absence of conventional, thermal electricity generators.\nIn the absence of very large-scale long-term energy storage, significant curtailment of renewables and additional consumption of fossil fuel may arise at times.\nThe role and value of demand side response\nDemand response is a key option for supply-demand balancing 28 , 59 , 61 – 65 (see Figure 11 ), which offers benefits to all parts of the energy system that have been estimated to amount to some £4 bn per year. Electrification of heating and transport services may provide new opportunities for DSR. For example, research into social practices and service expectations combined with technical modelling (see the subsequent section) indicate that, if householders would tolerate a drop in indoor temperature of 1 ℃ for up to ten days a year, between 3 and 9 GW of peak supply capacity could be avoided. The key aim of DSR is therefore to explore the technical performance of various demand response concepts via time-step modelling techniques, but recognising the critical sensitivity to input assumptions regarding the level of expectations of the users. In order to model the potential demand response characteristics of individual load types, data was initially collected on multiple building loads for incorporation into the HESA/UK+ model combination. The data were then exchanged with the Demand and FESA models. An integrated scheduling algorithm was devised as an extension and redevelopment of the FESA model 26 – 28 (see again Figure 8 ) to allow demand response to compete on a level field against storage and controllable generation. The main calculations were translated into the VBA (i.e. visual basic for applications) code for greater visibility and future flexibility. It has been recognised that changes in the supplier/consumer relationship and in service expectations of consumers will inevitably impact on energy demand out to 2050 and beyond. Consequently, it is important to at least qualitatively ‘model’ consumer practices (see again the subsequent section) and to explore the relationships among customers, suppliers and consumers/prosumers. (Energy prosumers (see Figure 12 ) are those that produce (via distributed energy resources (DERs)), consume, manage or trade energy according to their own requirements and aspirations.) Smart DSP 28 can help to meet the challenges of flexible demand. Thus, water heating has been found to be capable of time-shifting (see again Figure 11 ) by around 50% for up to 7 h, space heating by 100% for up to 1 h, and EVs and plug-in hybrid electric vehicles (PHEVs) charging by 100% for up to 7 h.\nDownload in PowerPoint\nFigure 12. Structural opportunities to control flexible demand, including an illustration of the roles of the transmission network operator (TNO), distribution network operator (DNO), and flexible prosumers.\nThe penetration of renewable generation, particularly onshore and offshore wind turbine arrays, in the UK energy mix may reach as much as 15% by 2020. By that time the number of EVs in use may have reached over one million. Thus, the UK power system will be affected by an increasing imbalance, due to this rise in electricity demand (from EVs) and uncontrolled supply (from wind). Smart EV charging strategies 61 can therefore help the power system cope with high penetrations of local renewable energy sources (RES). Huang and Infield 61 recognised that domestic vehicles are typically parked for around 95% of the time, and hence EVs can be utilised as a ready form of responsive demand. They adopted a Monte Carlo model together with state-of-charge (SOC) information, as part of a whole systems framework, in order to estimate EV charging profiles. Wind farm data was taken from operational sites in Scotland. It was found that the cost over several small EV charging events was essentially free, provided that the surplus wind was greater than 1 MW. Likewise, the impact of the widespread adoption of high-performance heat pumps, alongside the large-scale penetration of wind generators, was recently studied by Cooper et al. 62 They devised a model using dynamic simulations of individual (air-sourced) heat pumps and dwellings, which indicated that increases in peak net-demand is highly sensitive to assumptions regarding the heat pumps themselves, their installation, building fabric (i.e. thermal insulation) performance and grid characteristics. If 80% of dwellings in the United Kingdom were to adopt such heat pumps, for example, then peak net-demand could rise by around 100% (54 GW), although this increase could fall to just 30% (16 GW) under favourable conditions. 62 Smart DSP could reduce this further to 20%, or even 15% with extensive use of thermal storage (as depicted in Figure 11 ). In contrast, should 60% of dwellings take up heat pumps, then the rise in peak net-demand could be as low as 5.5 GW, and consequently the electrification of heating would be more manageable for the network. 62\nAnother study by Teng et al. 63 examined the demand for ancillary services under a future GB electricity system as a result of the high penetration of wind generators with limited inertia capability. Under these circumstances, the network may be required to deal with sudden frequency drops following a loss of generator. An advanced stochastic generation scheduling model was employed to quantify the frequency response requirements and the contribution that could be made by DSR. 63 It suggested that the provision of frequency response from DSR could greatly reduce the system operation cost and wind curtailment. These DSR benefits were found to have significant diurnal and seasonal variation, whereas an even more rapid (near-instant) delivery of frequency response from DSR could yield substantial additional value. Competing technologies to DSR that can provide frequency regulation, such as battery storage 41 or more flexible conventional generation could potentially reduce its value by between 15% and 35%. 63 This would still leave significant room to deploy DSR as a cost-efficient frequency response provider within a future low-carbon electricity system.\nIt is critical to reflect how investors will take decisions to invest in (or to retire) generation plant within a market and policy context. Accounting for the incentives provided to companies through the trading arrangements is hence fundamental for modelling how investors take decisions going forward. As well as power market revenues, renewable and low-carbon generators are also reliant on subsidies to ensure their profitability, which is important for the investment decision-making process. Investors will form ‘rational expectations’ regarding the future when making investment decisions, taking into account power market conditions (e.g. electricity prices, demand growth, demand flexibility, changes in trading and regulatory arrangements, etc.) over the life of the asset based on all the information available to them at the time. Quantitative modelling studies have therefore been conducted in order to evaluate the competitiveness of demand response against other technologies, using a range of GB network case studies related to the transition pathways. A holistic approach (via the whole-electricity system investment model (WeSIM) 64 ; a successor to the HAPSO model 55 ) has been employed to assess the benefits of demand responses on power generation, transmission and distribution systems under each of the three pathways scenarios (see Figure 13 ). WeSIM, employed by Pudjianto et al., 64 is an enhanced model with respect to the modelling of demand and has more functionalities. It was used to provide useful insights on the characteristics of different pathways in terms of the expected increase in future peak demand, driven primarily by electrification of heating and transport sectors, 61 , 62 as well as the consequences for future power system infrastructure requirements. This approach 64 simultaneously optimised investment into new generation, network and storage capacity, while minimising system operation cost, and also considering reserve and security requirements. The analysis distinguished between bulk and distributed storage applications, while also considering the competition against other technologies, such as flexible generation, interconnection and DSR 64 (see again Figure 13 ). The results demonstrated that the DSR savings are potentially significant and that the MR pathway, for example, could save up to £90 bn of investment by 2050. A key issue arising from these studies is that the postulated generation capacity under the pathways may not be sufficient to meet security standards. This highlights the importance of considering the security of supply aspect in the development of future generation portfolios. Analysis of the electricity price characteristics of the three pathways showed that some generators with relatively very low load factors bring into question the feasibility of generation in an energy-only market. There are significant multi-stream savings that arise from DSR (multiple applications, including energy arbitrage, system balancing and capacity) across all pathways (amounting to some £4 bn/year by 2050). The benefits of whole-system based DSR applications are higher than those of the (non-coordinated) transmission network operator (TNO) or distribution network operator (DNO)-centric DSR applications: see again Figure 12 . This highlights the need for such whole system control co-ordination between the TNO and DNO in order to improve the interaction with DSR control.\nDownload in PowerPoint\nFigure 13. Annual versus peak electricity demand under the three UK transition pathways. Note: Estimated via WeSIM 64 ; a successor to the HAPSO model. 55\nEnergy storage (ES) represents one of the key enabling technologies to facilitate an efficient system integration of intermittent RES in conjunction with the electrification of heating and transport demand (see Figure 11 ). A stochastic optimisation method was used to quantify the benefit of distributed energy storage from the owner perspective. 65 A large set of case studies were carried out 65 in order to quantify the commercial and emissions benefits of ES in respect to energy and ancillary service markets, the revenue obtained from feed-in tariffs (FiTs), and the consequent reduction in operational CO2 emissions. ES was found to be able to provide opportunities for temporal arbitrage, because of the volatility of day-ahead and real-time (balancing) energy prices with a value of between £100/kWh and £650/kWh. 65 Its value in terms of anciliary services, such as frequency response, was estimated to be up to about £200/kWh on top of the basic value of ES. The value of ES for FiT revenue maximisation was found to decrease with increasing capacity from £108/kWh to £38/kWh. 65 When ES is charged during low-emission periods and discharged in high-emission ones, then the carbon footprint falls by around 10% even with losses taken into account. Teng et al. 65 observed that current and near-term batteries did not appear to be cost-effective for power generation applications. Thus, they noted that LIBs were most effective (∼£480/kWh) for kW/kWh applications with reasonable charge/discharge cycle lives. 41 (The cost of LIBs are today about ∼£140/kWh (similar to the price in 2012 noted by Hammond and Hazeldine 40 of ∼£135/kWh) having fallen from >£1675/kWh in 1990.) This contrasts with sodium-nickel chloride devices (so-called ZEBRA 41 , 65 batteries) at ∼£329/kWh. Teng et al. 65 expect the costs of lithium ion batteries to halve by 2020, although they expect those for the ZEBRA battery technologies to remain largely unchanged.\nThe technical performance and social acceptability of a range of proposed DSR concepts has been examined via an integrated approach in order to quantify the changes in electricity load profiles of the type represented in Figure 11 . The benefits of DSR options to the various classes of consumers were quantified for a range of scenarios appropriate to the different transition pathways. McKenna and Thomson 66 examined, for example, the way in which domestic consumers with rooftop solar PV arrays could benefit financially from time-shifting. They used an internet discussion forum to determine whether consumers with such PV systems engage in DSR activities so that they benefit further from free, self-produced electricity. Washing machines, dishwashers and electric space and water heaters were the most commonly employed appliances to shift demand. 66 The results suggest that, while price is an effective driver of DSR, there are other factors that generate demand response of the sort depicted in Figure 11 . They indicate that consumers with PV are often willing to be more flexible than is commonly assumed. This behavioural response could possibly be used in future to devise innovative tariffs that might stimulate demand shifting. 68 These value assessments are important elements in assessing the take-up, scale and effectiveness of DSR that can be expected.\nThese and other findings have benefited from a whole systems and collaborative working approach for elaborating and examining the transition pathways for realising a low carbon, secure and affordable UK energy system by 2050. Thus, the insights and lessons learned from studying the role and value of DSR were:\nDemand side participation (DSP) concepts are mainly short term (minutes to hours), whereas flexibility is needed over several days or more. The rigid patterns of modern living and consumer expectations based on life-long experience of fossil-fuelled supplies make such flexibility challenging, but are important to explore. Fully automated DSR concepts, such as ‘smart’ controllers for EV charging and heat-pumps, have been studied in some detail.\nBattery energy storage and controlled EV charging helps cut peak demands, but typically provides only a few hours of storage, doing little to address longer term weather-related variations. A Monte Carlo model of EV movements and home based charging 61 has been used to analyse the impact on a typical low voltage distribution network with typical household loads, suggests voltage impacts to be the most critical: voltages could easily become unacceptable without demand side management. The extension of EV charging to allow workplace charging seems to relieve the distribution network loads and help avoid voltages outside the statutory range.\nDecarbonised electrification of heating could make a useful contribution to the reduction in UK CO2 emissions, but may cause a challenging increase in peak power demand, net of non-dispatchable generation. This can be reduced, although not entirely eliminated by thermal energy storage and DSP. In addition, it has been shown 62 that high-performance (air-sourced) heat pumps, with appropriate installation and better insulated buildings, could make the rise in peak net-demand far more manageable.\nAn integrated market model (developed in WeSIM 64 ) has been used to analyse the evolution in electricity prices in different system backgrounds with different DSR technologies, network development, carbon prices and energy policies (related to market integration with the EU). When viewed in the context of a high share of renewable generation (such as under the TF pathway), the magnitude and volatility of electricity prices tend to increase, particularly driven by higher carbon prices and greater variable generation. The price differential between exporting and importing regions also widens from increased congestion in the national/cross-border transmission system.\nThere are significant multi-stream savings from DSR (via multiple applications, including energy arbitrage, system balancing, capacity) across all pathways; amounting to £4bn/year by 2050. These benefits of whole-system based DSR applications are higher than those of (non-coordinated) transmission system operator (TSO) or distribution system operator (DSO)-centric DSR applications. This highlights the importance of whole system control co-ordination.\nThe transition pathways have been costed under very different governance and institutional arrangements. Economic feasibility of generation in all three pathways will depend on the revenue from secondary markets/sources, such as capacity (ancillary service) market, FiT, tax incentives, etc., although the ratio of the revenue needed from primary and secondary markets is case specific.\nAttending to the social dimensions of realising transition pathways\nSection:\nThere is growing awareness that meeting the challenges of a low-carbon transition will require socio-technical solutions, and that consequently the social sciences have a key role to play in devising them, including working with engineers and physical scientists in an interdisciplinary manner. 66 – 68 A team of social scientists worked work interactively in collaboration with engineers in the present consortium to enhance consideration of the social dimensions of the project. This included work to open up assumptions about actor dynamics and social change as well as roles of the public and civil society in realising the UK transitions pathways. 66 – 68\nBuilding on the concept of the action-space devised in the first phase of the Transition Pathways project 8 , 24 , 30 (see section ‘Insights from historical transitions’ above), a relational co-productionist approach grounded in ideas form science and technology studies (STS) was developed to map relations between social actors across the UK electricity system and the spaces through which they participate in energy system change was developed to described the way in which different patterns of interaction between market, government and civil society actors lead to particular modes and logics of governance. 8 , 24 , 30 An important means of mapping actors and action spaces was through a systematic qualitative analysis of twelve contrasting visions of the low-carbon transition. This analysis showed that while some visions assume a technologically focused transition driven by the energy trilemma and centred on economic growth, alternative visions (particularly those from of civil society actors) place more emphasis on social and cultural change, issues of equity and fairness, and do not assume or depend on existing models of economic growth. Chilvers and Longhurst 67 studied four diverse sites of civil society engagement in low carbon transitions: the DECC Energy 2050 Public Dialogue (DECC 2050), the Camp for Climate Action (CCA; direct action events at various coal-fired power stations over 2006–2011), the Visible Energy Trial 8 , 33 (VET) and the Dyfi Solar Club (DSC; a community energy initiative in Machynlleth, Powys, Wales). They revealed that powerful forms of enrolment, exclusion and the partiality of visions and actions are common to all form of participation in transitions. Such analyses play a valuable role in transition pathways analyses through revealing social dimensions and informing how modelling studies frame the energy problem, bound the study system, and communicate uncertainties. It helped the wider consortium and technical analysts realise that that transitions are never smooth and will always be subject to contestation, negotiation and social change.\nThe other way in which social dimensions of energy transitions were attended to during the second phase of the realising transitions pathways project was through taking forward novel interdisciplinary (ID) experiments to co-produce social science and engineering insights on energy demand response in real time. These studies included a meta-review of social science evidence, leading into the design of small-scale integration experiments. The first of the ID experiments was a Service expectation experiment (see Figure 14 , and the summary in Table 3 ) in which the social science input into existing models was evaluated in order to improve model assumptions about how indoor comfort expectations could change over time. Such service expectations are often held to be stable, but social science literature suggests they vary in different ways. A range of service expectation scenarios were studied based on the outcomes from the review (such as more demanding standards, wider comfort zone and local diversity). The FESA model 26 – 28 ( Figure 8 ) was employed in order to examine various behavioural scenarios with variable service expectations. The work indicated that if householders (consumers or flexible prosumers; see Figure 12 ) were tolerant of a small internal temperature change either side of their desired set-point, and even allowing these for just a few hours per year this could yield large reductions in peak demands (a few GW): see again Figure 11 . This opened up the prospect of new behavioural scenarios for models, new parameters and boundaries. The term framing, used in Table 3 , implies the inevitable process of selective influence over the perception of an individual (involved in the experiment) in such a way as to encourage particular (potentially biased) interpretations and to discourage others. This experiment suggested that new levels of detail are required in existing FESA-like models (e.g. around heating/cooling technologies, housing stock, etc.). 26 – 28\nView larger version\nThe second strain of social science-led, ID experiment (by Higginson et al. 68 ), termed Modelling practices experiment (and again summarised in Table 3 ), was designed to develop new approaches to modelling based on social science understandings of, and data about, social practices. It encouraged the social scientists to communicate their ideas more clearly, whilst allowing engineers to think critically about the embedded assumptions in their models in relation to society and social change. Social practice theory together with network analysis 68 was adopted to provide a network diagram to visualise different practices. ID participants then collaboratively generate mappings of ecologies of practices: see Figure 15 that illustrates various social activities and practices in the home. The elements of practices – represented by circles – are distinguished in terms of images, skills (e.g. washing) and stuff (e.g. dirty clothes). Thus, washing clothes as an energy service is not merely determined by the washing machine, tumble drier and iron, but depends on much else. These other social factors include the meaning of clean, the way the different schedules in the household come together, the organisation of laundry and the way it is done in the household, and so on, i.e. the images and skills that are part of the practice of laundry. Graphs of practice networks such as this can be populated with empirical survey data. Higginson et al. 68 recently used this approach to examine from a survey of different types (or variants) of laundry practice. They gleaned insights into energy intensity, flexibility and the rootedness of practices, i.e. the extent to which they were entrenched or established. It was argued that this permitted the social practices to be represented graphically using a quantitative format ( Figure 15 ) without being overly reductive. This modelling practices experiment opened up new socio-technical discussions about core/periphery elements, variants of practice and so on, but also closes down discussion about the situatedness of practices (see Table 3 ).\nDownload in PowerPoint\nFigure 15. A simplified network representation linking social activities and practices in the home: identifying ‘hubs’, ‘anchors’ and ‘clusters’.\nThrough these ID experiments engineers had become more aware and reflective of the tacit social assumptions and limitation of their models, while social scientists became more aware of the complexity of energy models and the difficulty of making even small changes to their inbuilt assumptions. Importantly, these collaborations produced new findings and insights only possible through interdisciplinary working. Bringing together practice theory with network analysis extended and scaled up understandings of energy-related practices, generating new insights on the constraints and potentials for modelling flexibility and energy demand response. In the service expectation experiment, integrating social science insights into the FESA model showed how even small changes in thermal comfort expectations can lead to significant savings in terms of energy demand, which could prove crucial in realising low carbon transitions.\nKey challenges, insights and opportunities identified in these studies attending to the social dimensions of energy transition pathways include:\nNew evidence that quantitative energy modelling approaches routinely neglect important social aspects of energy transitions and how society will influence future pathways, including changes in how energy problems are framed, service expectations of users, the roles of public engagement and institutional changes.\nSocial science analyses can provide important new evidence about the relations between actors and forms of participation in energy transitions, which is important evidence in its own right and in sensitising models to alternative framings, social futures and uncertainites inherent to scenarios and model projections.\nIf interdisciplinary collaboration is well designed, open, collaborative and based on trust it is possible to integrate engineering and social science expertise, which produces new insights beyond what is possible with single-discipline approaches – for example, showing prospects for energy demand flexibility and responsiveness greater than previously estimated.\nThere is no single best practice approach to interdisciplinary energy research. An effective approach is to develop forms of integration between social science and engineering modeling approaches that are appropriate, diverse and can be evaluated and learned from over time.\nInvolving social scientists in real-time interdisciplinary collaboration with physical scientists can hold the key to producing whole systems energy models that are more responsible, anticipatory and accountable to the social implications and effects of energy transition pathways.\nDistributed energy\nSection:\nThe TF pathway explores a low-carbon transition led by civil society, which focuses on decentralised or distributed solutions to energy problems. Currently, less than 1% of UK electricity demand is met by community- or local authority-owned distributed electricity generation. A major driver for the TF pathway is seen to be a step change in the role of the civic energy sector (communities, co-operatives, local authorities, town and parish councils, social housing providers) through participation in, and ownership of, electricity generation schemes. ESCos are presumed to emerge, with incentives aligned with energy efficiency improvements. Because this pathway deviates most from the current energy market, and has no recent precedent, it has interested bodies including the public-private ETI (e.g. their Patchwork scenario) and the UK energy market regulator (Ofgem). The consortium postgraduate researchers (the Engine Room (see section ‘From narrative descriptions of the transition pathways to model formulation’ above); again working independently of the consortium leadership – the academic co-investigators) were asked to evaluate the implications of this novel pathway, and they produced a Distributing Power report. 69 With strong demand reduction and management, 50% of 2050 final electricity usage could be met via distributed generation with emerging technologies, new infrastructures (including interconnections), and new institutions. Although challenging to the current power system operational norms, a transition to 50% distributed generation by 2050 was found to be technologically feasible. However, it would require the installation and full utilisation of smart grid technology, alongside DSP, demand management, and other techniques and technologies. A more distributed system would clearly need regional energy strategies and local capacity building for city regions, municipalities, communities and citizens. A distributed energy system opens up new avenues for energy transition finance, while challenging incumbent utility business models. (The integrated market simulation model (WeSIM 64 ), described in section ‘Hourly demand profile modelling’ above, can be used to optimise real-time dispatch in a chronological fashion, as well as reflecting entry and exit decisions by investors, using an iterative process.) The model for investment in conventional and renewable generation was used to calculate the electricity prices (including energy and scarcity prices that reflect the scarcity in generation capacity during peak demand), generation and transmission revenues. It highlighted the finding that electricity prices are expected to be more volatile in the future and that the impact of demand response on average electricity price is modest but it reduces significantly the volatility.\nThe Distributing Power report 69 draws on empirical research, engagement with a wide range of stakeholders from the energy sector, and from experience in Germany, Denmark and in the United Kingdom. It offers insights into the barriers and the technological transformation that might be required for a move to a highly distributed energy future. This decentralised generation would be required to satisfy the TF pathway with an increase in regional, national and international interconnection in order to ensure electricity imports from neighbouring countries. 69 Much of the energy value that currently leaks out of the UK economy could then be captured at the local level. Such distributed energy systems have often been equated with increased energy independence. But significant reduction in electricity demand would be necessary, including improved energy efficiency and conservation. Households, for example, would need to more than halve current levels of electricity consumption by 2050. 69 National energy planning with regional and local support for a civic energy sector would be needed. This implies a much greater role for national and local government. The traditional business models of the Big Six incumbent electricity suppliers would inevitably be challenged as they lose market share to local generation and supply businesses. New infrastructure, like smart grids and emerging decentralised technologies (such as in-home fuel cells), would be necessary; requiring a large-scale expansion from 2020 onwards. The impact to consumer bills would only be marginally more expensive out to 2030, 69 although they could be significantly cheaper in the long term (to 2050) compared to the MR and CC pathways. While the Distributing Power report 69 assesses the impact of one distributed generation future, there are others which might see a greater role for solar, onshore wind, or other generation mixes.\nTraditionally, renewable electricity generation capacity in the United Kingdom has been built by large-scale commercial developers and/or utilities, whose finances are globally mobile. The Distributing Power report 69 suggests a possible alternative of a proliferation of distributed energy generators, which are owned fully or in part by municipalities, communities, or small-scale investors. (A companion piece to the Distributing Power report, 69 produced by Johnson and Hall, 70 has examined the distributional implications of the TF pathway.) Citizens would thereby gain more control over their energy use. Centralised generation would still be necessary for base-load and peaking capacity. However, for this to be viable in a distributed generation future, the government would need to provide the right incentives for new large-scale plant and infrastructure. The civic energy sector, defined as energy generation by communities, co-operatives, local authorities, town and parish councils or social housing providers, currently relies on motivated individuals and communities and often, voluntary work. The development of a decentralised future along the lines proposed for the TF pathway would require strong project management and professional expertise to deal with a range of technical, financial, legal and administrative issues. In order to move to a distributed approach, regional energy strategies and local capacity building would be essential to aggregate these local energy schemes into a coherent civic energy generation sector. 69 , 70 This would mean complementing national energy planning with regional and local support for a civic energy sector and implies a much greater role for both national and local government.\nThe launch of the Distributing Power report 69 in February 2015 informed the wider UK energy debate, and is leading to further work with key stakeholders, including an invited submission to the Ofgem non-traditional business models process. The headline messages were: 69\nAll UK energy projections, including a distributed energy future (such as that encapsulated in the TF pathway), require international interconnection. In addition, the TF pathway relies heavily on energy demand reduction, DSP and demand-side management. Households would need to more than halve their current levels of electricity consumption by 2050.\nA distributed energy system opens up new avenues for energy transition finance, while challenging incumbent utility business models. Around 50% of final electricity demand by 2050 could be met via distributed generation, but new infrastructures and emerging technologies would be required: from smart grids at a national level and to the likes of in-home fuel cells locally. A large-scale expansion would need to occur under the TF pathway from 2020 onwards. Thus, national energy planning with regional and local support for a civic energy sector would be needed.\nA high-level of distributed generation would require an increase in regional, national and international interconnection, such as electricity imports from neighbouring countries. Distributed energy systems have often been equated with increased energy independence. Much of the energy value that currently leaks out of the UK economy could be captured at the local level.\nThe traditional business models of the Big Six incumbent electricity suppliers would be challenged as they lose market share to local generation and supply businesses. In order to move towards a more distributed system, regional energy strategies and local capacity building would be essential for city regions, municipalities, communities and citizens.\nThe impact to consumer bills within a highly distributed power system (of the sort proposed for the TF pathway) would only be marginally more expensive in the medium term out to 2030, although it could be significantly cheaper over the long term to 2050 in comparison to those under the alternative MR and CC pathways.\nWhole systems energy and environmental appraisal of the different energy mixes\nSection:\nThe energy and environmental appraisal of the three transition pathways and associated power technologies have been evaluated within the context of a transparent sustainability appraisal framework, i.e. economic, social, environmental and technical benefits. 57 , 58 , 71 This process employed a toolkit of techniques to explore and evaluate the whole systems consequences of the selected transition pathways, such as the (embodied and process) energy and carbon implications of the pathways and technology mixes, their environmental burdens (as indicated by environmental LCA 57 , 58 , 72 – 75 ), and aggregate carbon and environmental footprints. A comprehensive review of the LCA of energy systems 57 included an overview of the historic development of LCA from the early 1990s, and its subsequent codification by the International Standards Organization (ISO). Environmental appraisal of energy systems needs to be conducted on a life-cycle basis, i.e. embracing the full range of extraction, production, distribution, and end-of-life processes or technologies. 57 , 58 , 72 – 75 In a full or detailed LCA, the energy and materials used and pollutants or wastes released into the environment as a consequence of an activity or service are quantified over the whole life-cycle; typically from cradle-to-gate. 57 Such studies are often geographically diverse; i.e. the energy and material inputs associated with the activity may be drawn from any continent or geo-political region of the world. They involve four main LCA stages that follow a logical sequence of goal definition and scoping, inventory analysis, impact assessment, and interpretation. The current strengths and weaknesses of LCA have been identified for the benefit of energy practitioners and policy analysts 57 (see Table 4 ). Comparisons were made with related approaches, such as carbon and environmental footprinting. 71\nTable 4. An outline of the strengths and weaknesses of environmental LCA.\nTable 4. An outline of the strengths and weaknesses of environmental LCA.\nSource: Hammond et al. 57\nView larger version\nAn examination of the whole system environmental burdens of the present transition pathways (version 2.1) was undertaken by Hammond and O’Grady 58 (as an extension of the earlier LCA study by Hammond et al. 75 (of version 1.1 of the pathways)), whereby GHG emissions reflected the sum of both upstream and operational emissions. The latter (‘stack’) emissions are those directly associated with the combustion of fossil fuels within power stations. Thus, the whole system emissions amount to those related to the ‘cradle-to-gate’. The national electricity network (operated by TNOs and DNOs) represents the downstream boundary known as the gate (hence, cradle-to-gate 75 ). In the studies by Hammond et al. 75 and Hammond and O’Grady, 58 they highlighted the significance of upstream emissions and their (technological and policy) implications, in contrast to the emphasis on power plant operational emissions conventionally presented by other analysts. These upstream environmental impacts arise from the energy requirements for extraction, processing/refining, transport and fabrication, as well as methane leakages from coal mining activities – a major contribution – and natural gas pipelines. The total carbon dioxide equivalent (CO2e) emissions associated with various power generators and UK electricity transition pathways towards a low carbon future are depicted in Figure 16 . This illustrates the GHG trajectory under each of the three transition pathways out to 2050. It was also found that CO2e capture facilities coupled to fossil-fuelled plants deliver only a 70% reduction in GHG emissions (including both upstream and operational emissions), in contrast to the normal presumption of a 90% saving.\nFigure 16. ‘Whole systems’ (upstream plus operational (or ‘stack’)) GHG emissions under the three UK transition pathways (1990–2050).\nGHG: greenhouse gas.\nSource: Adapted from Hammond and O’Grady. 58\nThe transition pathways LCA study by Hammond et al. 75 yielded estimates of pollutants or wastes released into the environment as a consequence of the UK ESI in terms of 18 separate impact indicators (together with a tentative single score, aggregate LCA measure). The lower the resulting score for each category (or the single score indicator) the better, although they doesn’t adequately reflect, for example, the impacts associated with nuclear power generation. Nuclear is low carbon, but has a number of other health and environmental impacts associated with the potential release of ionising radiation from nuclear power stations and processing plants. These are generally not effectively accounted for in LCA software tools, 75 because they do not have an underlying basis in ecotoxicology. Statistical weighting of the different LCA categories is normally achieved by the engagement of a panel of experts. It is therefore highly subjective, and this process would not be advisable in many cases. Clearly, it is difficult to manage something like 18 different impact categories, and consequently it is necessary to focus on key categories. Large impacts were found in terms of categories such as Human Toxicity, Freshwater Eutrophication, Marine Ecotoxicity and Natural Land Transformation 75 particularly under the MR pathway. Carbon emissions are the currency of debate in a climate-constrained world, 4 , 58 and consequently GHG emissions are typically given greater emphasis. There is likely to be a significant fall in carbon emissions from the UK power generation sector (see Figure 16 ) of some 31–51% by 2020, 65–86% by 2030 and 78–93% in 2050. 58 The lower figures relate to the MR pathway, whilst the higher ones are associated with the TF pathway. Notwithstanding the emphasis on GHG emissions, some of the other environmental burdens may need to be monitored.\nThe British Government’s independent Committee on Climate Change (CCC) has advocated deep cuts in power sector operational emissions through the 2020s, 46 with UK electricity generation being largely decarbonised by 2030–2040. In contrast, the present transition pathways projections (see again Figure 16 ) 58 indicate that the UK ESI could not be fully decarbonised by 2050 on the whole systems basis employed in the process-LCA studies. 58 , 75 This is because the present estimates take account of upstream, fugitive GHG emissions, whereas the projections by bodies like the CCC and Department of Energy and Climate Change (DECC) generally do not. Nevertheless, the transition pathways suggest that the ESI will be able to bear a significant share of the overall 80% carbon reduction target by 2050. The CCC analysis indicates that average operational emissions from the power generation sector would fall to around 50 gCO2/kWhe by 2030. 46 In contrast, the present MR pathway ( Figure 16 ) indicates that whole system emissions from the UK ESI are likely to only fall, accounting for upstream emissions, to ∼202 gCO2e/kWhe by 2030 and ∼105 gCO2e/kWhe by 2050. 58 The least impactful pathway (TF) suggests 58 that GHG emissions will fall to only ∼108 gCO2e/kWhe by 2030 and ∼53 gCO2e/kWhe by 2050 ( Figure 16 ). If the United Kingdom is to genuinely meet its legally-binding carbon reduction targets, then it will be necessary to account for upstream emissions from power generation. 58 , 75 Otherwise, even if the current UK carbon reduction targets are met, there will remain further emissions upstream.\nAn alternative way of evaluating the environmental impacts of the three UK transition pathways is via carbon and environmental footprinting. 4 , 71 Environmental or ecological footprints have been widely used in recent years as indicators of resource consumption and waste absorption associated transformed on the basis of biologically productive land area (in global hectares (gha)) required per functional unit (such as kWhe). They represent a partial measure of the extent to which an activity is sustainable. 4 , 71 In contrast, carbon footprints are the amount of carbon (or carbon dioxide equivalent) emissions associated with such activities in units of mass or weight (like kilograms per functional unit), although they can be translated into a component of the environmental footprint (on a gha basis). In order to determine the footprints associated with three UK transition pathways, the overall environmental footprint has been disaggregated into various components 71 : bioproductive and built land, carbon emissions, embodied energy, materials and waste, transport, and water consumption (see Figure 17 ). The total environmental footprint in the baseline year of 2010 was found from historic data to be 43 Mgha. In this case, the carbon and embodied energy footprint components were responsible for 80% to the total environmental footprint.\nFigure 17. Environmental footprints of the three UK transition pathways in 2050.\nSource: Adapted from Hammond. 71\nFuture environmental footprints were estimated for each of the three transition pathways. 4 , 71 Electricity demand was projected to decrease significantly under the TF pathway by 2050, but its total environmental footprint was nevertheless greater than either that under the MR or CC pathways (see again Figure 17 ). This is mainly due to the increase in the contribution of the bioproductive and built land component and that of the carbon footprint (rising to 10.9 and 12.5 Mgha respectively by 2050), 71 which are both seen to be higher than in either of the MR and CC cases. Thus increase in these TF pathway components was mainly due to increased usage of solid biofuels for power generation. In order to reduce the overall TF footprint it would therefore be necessary to adopt other renewable power technologies, like offshore wind and solar PV arrays, to satisfy the increase demands caused by electrification of heat and transport. The MR and CC pathways gave rise (see again Figure 17 ) to footprints of 23 and 25 Mgha respectively in 2050, as compared to 43 Mgha in the 2010 base year. 71 Here, the embodied energy component was the largest amongst the various footprint components; rising to 14 and 13 Mgha respectively by 2050. This was due to the large-scale use of fossil-fuelled power plants. There is a large reduction in carbon emissions under the MR pathway (over an 86% reduction compared to 2010 levels), whilst the CC pathway exhibits a slightly smaller fall (albeit nearly an 80% reduction). On the other hand, the TF pathway displays only 42% reduction in carbon emissions by 2050 ( Figure 17 ). Water and waste footprint components made almost negligible contributions under all three transition pathways (only ∼1% footprint share), although this was recognised as probably being an artefact of the footprint methodology and assumptions adopted. 71 Bioenergy and biofuel footprints and land-take (see again Table 2 ) reflect relatively large environmental burdens when compared to other fuels.\nThe carbon and environmental burdens associated with the three UK transition pathways have been assessed via environmental LCA and footprinting methods. Overall insights and lessons from such studies can be summarised as:\nA critical state-of-the-art review of this environmental LCA methodology57 has identified its current strengths and weaknesses for energy practitioners and policy analysts.\nThe extraction and delivery of fuel requires energy and creates GHG emissions. The upstream emissions associated with various power generators and UK electricity transition pathways have been evaluated on a whole systems basis. There will remain further emissions upstream that are unaccounted for by the CCC and DECC. They only account for upstream fugitive GHG emissions beyond UK borders.58,75\nThe carbon and environmental footprints of the three UK transition pathways have also been evaluated.71 The overall environmental footprints were disaggregated into: built land, carbon emissions, embodied energy, materials and waste, transport, and water consumption. This component-based approach has enabled the sustainability challenges to be assessed quite broadly, along with specific issues (e.g. the linkages associated with the so-called energy-land-water nexus).\nEconomic analysis and appraisal\nSection:\nAny transition pathway in the UK energy system will require very large expenditures in the capital intensive energy sector. The costs and potential benefits of such investments, as well as how these investments position key market participants in relation to a range of economic risks, are a critical element to the economic appraisal of such pathways. Economic considerations are the core consideration of market-led actors, while the government – in its social planning role – has a wider consideration of costs under a multi-criteria approach, but one in which a socially optimal transition pathway would reduce costs as far as possible. Many analysis frameworks of possible future energy transitions conduct only a post-calculation of costs (e.g. via the DECC 2050 Calculator or analysis by the UK energy market regulator (Ofgem)), whereas costs are a critical input into the formulation and decision making process in any transition pathway.\nMany existing energy modelling studies have been criticised for their limited treatment of societal actors and associated socio-political dynamics, together with poor representation of the co-evolving nature of society and technology. 76 It has therefore been argued that they consequently find it demanding to analyse socio-technical change. In parallel, it is evident that some of the prominent conceptual frameworks of socio-technical energy transitions (STET) find it difficult to operationalise policy development requirements in quantitative energy analyses. A review and critique of quantitative models for exploring STET was therefore undertaken by Li et al., 76 alongside their application to the energy supply, buildings and transport sectors. They subsequently devised a novel taxonomy for describing STET models 76 for integrating both quantitative modelling and conceptual socio-technical transitions, which incorporated techno-economic detail, explicit actor heterogeneity, and transition pathway dynamics. This study also highlighted a number of the challenges associated with their theoretical and behavioural validation, and proposed future development priorities for STET models. 76\nA stylised probabilistic energy system model (BLUE-MLP) has been constructed with key behavioural parameters on price and non-price drivers. The model has been extended to incorporate alternative actors, spatial and temporal detail. The initial version of the BLUE model was critically reviewed and validated by embedding it in the multi-model comparison exercise (see section ‘From narrative descriptions of the transition pathways to model formulation’ above, and Trutnevyte et al. 55 ). In addition, a literature overview for understanding the state-of-the-art research in behaviour and transition modelling was carried out. Participation in the qualitative-quantitative knowledge integration for demand response (see the above section) helped to collect further ideas on developing BLUE. The initial Excel economic appraisal of the transition pathways covers electricity generation, transmission and distribution. It takes account of the temporal and market participant elements. 77 The Excel economic appraisal (EconA) was embedded in the afore-mentioned multi-model comparison activity (see again section ‘From narrative descriptions of the transition pathways to model formulation’ above 55 ) in order to validate its findings against other realising transition pathway models. The implications of the multi-model comparison activity for the EconA and D-EXPANSE model were summarised by Trutnevyte et al. 55 (see both the sections ‘From narrative descriptions of the transition pathways to model formulation’ and ‘Annual demand modelling’ above). The D-EXPANSE model was used to model the UK power sector transition between 1990 and 2010, in order to get insights about the structural uncertainty of cost optimisation, and to systematically translate the transition pathways narratives into quantitative representations.\nClearly the costs and affordability of energy transitions are one of the most influential drivers in terms of the energy policy trilemma. But so also are the interactions between the power sector and other key economic sectors that drive decarbonisation in line with climate targets. A collaborative study between energy-economic modellers and power systems engineers from the Realising Transition Pathways Consortium therefore undertook a cost appraisal of the UK transition to a low-carbon electricity system under alternate governance logics. 77 This novel approach linked the quantitative electricity system transition pathways and their economic appraisal. Retirement of existing power plant capacity and the installation of new build was based on either DECC planned retirements 77 or estimated lifetimes. Costs of the transmission and distribution network infrastructures (see Figure 12 ) were modelled via the WeSIM 64 model – a successor to the HAPSO model 55 , 77 (see both the sections ‘From narrative descriptions of the transition pathways to model formulation’ and ‘Hourly demand profile modelling’ above). Outside the power system, only the costs of heat-producing devices (such as resistive heaters and gas boilers, community-scale and micro-CHP, and heat pumps) were included in the analysis. It focused on monetary costs and did not account for externalities, associated with the costs of different impacts on the environment 77 (like those considered within an LCA study, such as that described in the above section). The results (see Figure 18 ) contrast the dominant market-led MR transition pathway with alternate pathways that have either stronger governmental control elements (CC pathway), or bottom-up proactive engagement of civil society (TF pathway). The MR pathway exhibited the lowest investment costs out to 2050, whereas the CC pathway had slightly higher total system costs; presuming its implied government policies could be enacted and maintained. The bottom-up, more decentralised (TF) pathway was found to come at the expense of higher investment costs, 77 although it encourages wider participation with civil society. It requires significantly higher investment in renewable electricity generation, electric heating, and particularly EV transport. The spatial distribution of investment requirements under each UK pathway was another issue explored by the partnership of energy-economic modellers and power systems engineers (see Figure 9 ) (and section ‘From narrative descriptions of the transition pathways to model formulation’ above).\nDownload in PowerPoint\nFigure 18. Relative capital investment costs for the three UK transition pathways out to 2050. Source: Updated estimates based on Trutnevyte et al. 77\nEconomic appraisal of the three UK transition pathways 55 , 76 , 77 contributes to an understanding the future interplay of the energy policy trilemma, i.e. achieving deep GHG emission cuts, whilst maintaining a secure and affordable energy system. The insights and lessons from these studies can be summarised as:\nInvestment costing of the three UK transition pathways under very different governance and institutional arrangements was achieved via a novel collaborative study between energy-economic modellers and power systems engineers. 77 It showed that the TF pathway gave rise to the highest investment costs, due to the need for large-scale renewables (such as wind farms), electric heating, and principally EVs and their transport/charging infrastructure.\nFrom this novel STET taxonomy for integrating both quantitative modelling and conceptual socio-technical transitions, 76 methodological improvements in economic analysis of transition pathways were identified as being as important as the analytical insights from any given modelling comparison. For example, firstly understanding the spatial and temporal boundaries of any cost calculation, and secondly assessing if demand reductions are induced by policy instruments (a welfare loss) or attributed to lifestyle evolutions (no welfare loss) are fundamental challenges.\nStimulating investment in low-carbon options\nSection:\nAnalysis of historical energy transitions 30 – 32 (see section ‘Insights from historical transitions’ above) demonstrates that rapid change is possible, but not frequent, and requires a high degree of co-ordination of actions, driven by recognised need to change, e.g. the shift from Town Gas to natural gas. Potential low-carbon investors in the United Kingdom are faced with uncertainty about national policy priorities, and there are structural constraints on low-carbon investment, including immaturity of the sector and mismatches between fund manager and renewable energy investment timescales. 80 The economic feasibility of generation under all three transition pathways will depend on revenues from secondary markets/sources (e.g. the capacity market, FiT and various tax incentives). However, the ratio of the revenue needed from primary and secondary markets is case specific. Comparison with the situation in Germany demonstrates the valuable role that can be played by locally focused institutions, where civic ownership is supported by a local banking sector. 83\nA review of socio-technical systems research by Bolton and Foxon 78 argued that this approach can be operationalised to assess policy and societal challenges of large-scale investments in the low-carbon infrastructure. They observed that the United Kingdom is moving into a new phase of energy governance with significant demand for new investment to meet long-term climate policy objectives, as well as shorter term energy security challenges. The UK Government’s recent EMR aims to promote investment in large-scale low carbon technologies, through incentive schemes such as the contract for difference (CfD) and FiTs. They provide a guaranteed price for low carbon generation and thereby remove one significant uncertainty, although policy and political risks still remain. In further research, Bolton et al. 79 interviewed a range of energy policy and industry stakeholders, revealing different views on governance of energy systems. Those in favour of a liberalised market approach thought that the government should just set the rules, but otherwise not interfere to address price and other risks. In contrast, the mainstream investment community continues to be concerned that other risks could prevent large-scale investment in low-carbon generation. The Levy Control Framework, which was put in place out to 2020 with no clarity as to if it will be extended beyond that, has created an additional policy uncertainty for investors. Capacity markets have been introduced in order to ensure security of energy supply, indicating that this has greater priority than meeting carbon budgets (as reflected in recent UK Government energy policy pronouncements). This again creates uncertainty for investors, as experience indicates that regulatory frameworks and incentives are liable to change over time. In order to bring in new actors, such as mainstream institutional investors, better understanding of how they perceive these risks and uncertainties is required.\nA socio-technical approach has been employed 78 to this important area of policy debate in three specific areas: understanding long-term uncertainty and investment risks; avoiding technological lock-in; and accelerating the diffusion of low carbon finance niches. It explored the dynamics of long-term structural change in capital intensive systems (such as energy, housing and water supply with the aim of seeking to redirect them towards more sustainable long-term trajectories. Bolton and Foxon 78 argue that interventions need to balance the demands of private investors with wider social objectives. A better understanding of investment risk and uncertainty is required. Insights from the MLP of transitions theory suggest that it is necessary to avoid lock-in to current technologies, and the need to support low carbon finance niches.\nIn a follow-up study, Bolton et al. 79 examined the way in which actors in the UK electricity sector are attempting to deliver investment in low-carbon technologies. Such generation capacity is relatively immature and is capital intensive, although they have low operational costs. Empirical research 79 investigating the agency of incumbent regime actors in the face of uncertainty was based on interviews with 36 stakeholders from private and civic energy companies, mainstream and alternative investors, renewables project developers, energy policy makers and civil society. It was found that low-carbon generation does not readily fit into existing electricity markets and investment templates that were designed for a fossil fuel based energy system. The findings of Bolton et al. 79 can inform contemporary debates on the politics and governance of sustainability transitions and offers critical insights on the role of markets and finance in shaping socio-technical change. Key electricity market and infrastructure policies in the United Kingdom were analysed 79 in order to determine ways that low carbon technologies could be made investable. This research argued that this could be achieved by reducing uncertainty, better management of investment risks, and repositioning actors within the electricity socio-technical regime.\nThe role of financial markets in capitalising low-carbon energy systems and long-term change has been explored. 80 Capital requirements for energy system transitions are typically very large, and yet the literature has been curiously quiet on the role of capital markets in financing energy transitions. Stakeholder interviews identified that there are relatively few deals, whilst learning and adaptation are slow. Economic incentives, such as the CfD and FiT strike prices, or renewable obligation certificates (ROCs), are only one type of driver for change. This implies that providing stable incentives may not lead to market penetration of renewables investment. Hall et al. 80 have analysed the UK EMR process and the provision of renewable energy finance, and argued that an adaptive market hypothesis provides a useful framework for understanding the evolution of electricity markets in response to low carbon policy incentives. They demonstrated that the market for renewable energy finance does not conform to the standard efficient markets hypothesis, due to structural and behavioural constraints on investment. However, considering financial markets as being adaptive enables the range of policy responses for the acquisition of low-carbon investment to be much broader. 80\nPrimary data collection was undertaken by Hall and Foxon 81 to characterise the importance of a smart grid infrastructure within a UK energy transition. The UK economy and electricity system have co-evolved, but there remains a mismatch between the distribution of benefits and costs of investing in this infrastructure; leading to a problem of value capture and redeployment. Some benefits of smart grids are less easy to price directly, and are more accurately classified as public goods, such as energy security and decarbonisation. Hall and Foxon 81 drew on semi-structured interviews and focus groups involving UK smart grid stakeholders. This led them to identify municipal-scale developments as potential sources for new business models to deliver smart infrastructure. Municipalities may thus pursue specific economic opportunities with DNOs to make smart grid investments. This supports recent practical interest in an expanded role for municipalities as partners and investors in smart grid infrastructures.\nTransforming energy distribution networks will also play a key enabling role in a low-carbon energy transition in the energy, water and mobility sectors. But Bolton and Foxon 82 have argued that there is relatively little understanding of the social and institutional dimension of these systems, or appropriate institutional challenges to their transformation. This may be because the prevalent model of infrastructure governance in the energy and other sectors has prioritised short-term time horizons and static efficiencies. Bolton and Foxon 82 therefore discuss the appropriate governance strategies for developing flexible and sustainable systems of energy distribution. They draw on ideas from the social shaping of technology in order to develop a broader understanding of infrastructure change as a dynamic socio-technical process. A range of governance challenges to the development of electricity and heat networks are examined along the different phases of the infrastructure life cycle. Lessons are then drawn for the development of governance frameworks for the transformation of energy infrastructure more widely. 82 In the case of electricity distribution in Britain, the regulator (Ofgem) has sought to design suitable incentives to overcome barriers to long-term investment and innovation, although these are at an early stage of implementation. UK local authorities, by contrast, have struggled to finance large-scale infrastructure investments in the area of district heating (so energy-efficient and popular in the Scandinavian countries).\nA comparative analysis of recent energy policy developments in selected European countries (e.g. the German Energiewende) and on the implications of developments at a European level on UK energy policy (e.g. carbon pricing and market unbundling) has been reported by Hall et al. 83 Field research on the German situation drew out the implications for ownership, governance and financing of low carbon energy infrastructure. The German system differs from UK system in at least four ways. It had a much greater degree of decentralisation and municipal ownership, following post-War reconstruction. Their low-carbon transition or Energiewende was seen as a national priority. More decentralised political institutions in the German federal system enable a greater degree of energy policy experimentation. Finally, a more bank-based financial system in Germany, including a well-developed local banking system, contrasts with the centralised and market-based financial system in the United Kingdom. These local German banks have often built on local knowledge and encouraged small-scale renewable investment. They became key promoters of civic and community ownership of electricity generation assets. Such municipal ownership might again enable a similar, more long-term perspective to be taken in the United Kingdom, with a focus on good, safe, reliant energy infrastructure. Further economic and social benefits might then accrue to local municipalities.\nThese roles of actors, governance arrangements and regulations have been analysed in relation to realising market-led, government-led and civil society-led low carbon transition pathways, leading to the following findings:\nEnergy systems can best be understood as socio-technical systems made up of interacting technological and institutional elements, coevolving over time. Governance and regulatory frameworks are critical in managing risks for decision-makers and investors.\nChanges to investment support for low-carbon electricity generation have led to increasing risks and uncertainties, and concerns that long-term governmental commitment to decarbonisation may be undermined if the salience of energy security and cost priorities grows.\nAnalyses of energy finance as an adaptive market 80 help identify the lack of a mature community of investors, mismatches between investment and fund manager timescales, and lack of suitable investment vehicles. Capital markets are likely to change over the long-term to yield more adaptive markets for energy finance.\nThe economic feasibility of generation in all three pathways will depend on the revenue from secondary markets/sources, such as the capacity (ancillary service) market, FiT, and various tax incentives, although the ratio of the revenue needed from primary and secondary markets is case specific.\nA comparative UK–Germany analysis 83 has shown the importance of the local banking sector in facilitating civic ownership structures there.\nThe possibility of a low-carbon, decentralised transition (like that envisaged under the TF pathway) driven by civic energy systems has highlighted the role of local banking systems, and of shared values (including public service and local economic development). 83\nConcluding remarks\nSection:\nThe British Government has set a legally binding target of reducing the nation’s CO2 emissions by 80% by 2050 in comparison to a 1990 baseline. 6 This would ideally require the UK ESI to be decarbonised by around 2030–2050 in order to give more head room for carbon mitigation in other, more challenging sectors (such as industry and transport). 46 A set of three low-carbon transition pathways were developed and analysed via an innovative collaboration between engineers, social scientists and policy analysts. The pathways focus on the power sector, including the potential for increasing use of low-carbon electricity for heating and transport, within the context of critical European Union developments and policies. Their development started from narrative storylines regarding different governance framings, drawing on interviews and workshops with stakeholders and analysis of historical analogies. The quantified UK pathways were named Market Rules (MR), Central Co-ordination (CC) and Thousand Flowers (TF); each representing a dominant logic of governance arrangements – recently described by the Chief Executive Officer of a prominent UK renewable electricity supplier and generator company (unconnected with the project) as reflecting blue, red and green pathways respectively. These pathways have been used to explore what is needed to realise a transition that successfully addresses the so-called energy policy trilemma, i.e. the simultaneous delivery of low carbon, secure and affordable energy services. Such energy transitions are never smooth and always subject to contestation, negotiation and social change. The UK ESI has already undergone quite rapid change over the last few years. 84 Coal power station closures, for example, have amounted to 15 GW between 2010 and 2015; with combined cycle gas turbine plant closures accounting for a further 4 GW. In contrast, there has been a rapid rise in solar PV systems that now stands at around 853,000 installations, for which rooftop solar alone now accounts for >1% of UK electricity supply. 84 The recent British Government energy policy reset, the components of which will only become clear during 2017 (although some senior executives in the UK power sector speculate that it will propose roughly 30% nuclear, 30% renewables, and 30% gas) will lead to additional changes going forward. Thus, if the three transition pathways were being developed today they would no doubt contain rather different energy mixes. The TF pathway might contain more solar PV, but less bioenergy, for instance. Nevertheless, the insights gained from this exercise still provide a valuable evidence base for developers, policy makers and other stakeholders.\nA fundamental requirement for identifying and addressing the multiple challenges and opportunities posed by energy policy and climate change necessitates a combination of academic knowledge with that from industry, commerce, regulatory bodies, political and societal communities. This ambitious goal appears to be more achievable in processes that combine the analytic (the systematic application of expert knowledge) with the ‘deliberative’ (the systematic application of opportunities for face-to-face discussions between experts, stakeholders and citizens). 85 , 86 The ‘Realising Transition Pathways’ Consortium has adopted the practice of the co-production of knowledge to explore and integrate different kinds of expertise in order to provide opportunities for reflection and evaluation. It has attempted to achieve a level of joint working that allows the effective sharing of disciplinary-specific and professional expertise. New evidence and case studies of UK energy transitions provide practical advice on how sustainable energy transitions will depend on science and policy institutions becoming more responsive and adaptive to distributed societal actions. Here the challenges, insights and opportunities that have been gleaned from this research are highlighted (via bullet point summaries at the end of each principal section above).\nAnalytical tools were developed and applied to assess the technical feasibility, social acceptability, and environmental and economic impacts of the pathways. Technological and behavioural developments were examined, alongside appropriate governance structures and regulations for these low-carbon transition pathways, as well as the roles of key energy system actors (both large and small). An assessment of the part that could possibly be played by future demand responses was also undertaken in order to understand the factors that drive energy demand and energy-using behaviour. A set of interacting and complementary engineering and techno-economic models or tools were then employed to analyse electricity network infrastructure investment and operational decisions to assist market design and subsidy mechanisms. This provided a basis for integrating the analysis within a whole systems framework of electricity system development, together with the evaluation of future economic benefits, costs and uncertainties. Likewise, the energy and environmental performance of the different energy mixes were appraised on a life-cycle basis to determine the GHG emissions and other ecological or health burdens associated with each of the three transition pathways. The UK Carbon Budgets 46 are presently on track for an 80% reduction (in production emissions) by 2050, although it has been observed here 58 that the impact of upstream (and consumption) GHG emissions are generally excluded. The impact of such upstream emissions on the carbon performance of technologies (such as combined heat and power (CHP) and CCS) and the transition pathways themselves 58 distinguish the present findings from those of other analysts, such as the CCC and DECC. None of the three pathways yield zero GHG emissions by 2050, which suggests that the UK electricity sector cannot realistically be decarbonised by 2030–2040 as advocated by the CCC. 46\nSocio-technical solutions are required on both the demand and supply-side of any future UK energy system. Reduction in energy demand for heat, power and transport will be a significant element of any energy strategy aimed at limiting global warming to <2 ℃ under whatever pathways actually results out to mid-century. 87 , 88 Improvements in energy efficiency can be obtained from better thermal insulation of the building fabric, smart appliances and controls, alongside the adoption of efficient heating systems, such as heat pumps, community energy schemes and the like. In addition, lifestyle or workplace changes, DSR and DSP may well be needed, but these will be partially offset by so-called rebound effects. Decarbonising the supply-side is likely to see the continued adoption of new nuclear build (although the whole system costs may be prohibitive), offshore wind, and rooftop solar PV. It will inevitably need the take-up of CCS (as well as carbon capture and utilisation (CCU)) for a cost-efficient transition, together with sustainable bioenergy and biofuels, and possibly hydrogen (H2) as a fuel and energy storage media in the long term. Unfortunately, there are constraints over the use of bioenergy resources, including uncertainties over the availability of UK sustainably-sourced biomass, land use challenges, and competition with food supply. Finally, the energy infrastructure in Britain will need renewal in order to make it more resilient (e.g. to climate change impacts) and to potentially accommodate greater decentralised or distributed generation, including greater use of both large and small energy storage devices. Significant generation, transmission and distribution network reinforcements (operating with much lower utilisation factors) will be needed to meet future changes in demand and generation patterns. However, smart power innovations (a combination of interconnectors, storage and demand flexibility (or DSR)) could generate £8 bn per year of savings (according to a report for the recently-established UK National Infrastructure Commission 89 ; for which a member of the Realising Transition Pathways Consortium (Goran Strbac and his team) played a key role 90 ). Indeed, in a risk assessment study of the UK power sector, Hammond and Waldron 11 found that lack of investment in new infrastructure to be ranked the second highest risk to the power sector by different stakeholder groups (academic researchers, civil servants, electricity companies, green groups, power system engineers and various others). The electricity grid was found to be arguably the most vulnerable part of the power system; reinforcing the case for UK network renewal and reconfiguration by the middle of the 21st century. 4 , 11 Innovation, systems integration, and whole systems thinking to identify sustainable energy options (sometimes termed optionality in industry), as examined in the present study, will therefore be critically important in the transition towards a low-carbon future.\nAcknowledgements\nThe authors are particularly grateful for the critical, but supportive, views of members of the project Advisory Board (chaired by James Smith, former chairman of Shell UK and presently chairman of the UK Carbon Trust) made up of industrial representatives, UK Government policy makers and other stakeholders. The authors are also grateful for insights provided by an anonymous reviewer from climate, energy and innovation policy perspectives. However, the views expressed in this paper are the responsibility of the authors alone and not the external collaborators or the funding body.\nThe authors’ names are listed alphabetically.\nDeclaration of Conflicting Interests\nThe author(s) declared no potential conflicts of interest with respect to the research, authorship, and/or publication of this article.\nFunding\nThe author(s) disclosed receipt of the following financial support for the research, authorship, and/or publication of this article: This work draws on research undertaken as part of a major research grant awarded by the UK Engineering and Physical Sciences Research Council (EPSRC) entitled ‘Realising Transition Pathways - Whole Systems Analysis for a UK More Electric Low Carbon Energy Future’ [under Grant EP/K005316/1]. The authors are grateful to this sponsor, as well as for the interchanges with the main UK-based post-doctoral researchers associated with the project (see the project website www.realisingtransitionpathways.org.uk for a full list of those involved).\nReferences\n""","0.13667734","""http://journals.sagepub.com/doi/10.1177/0957650917695448""","[-0.178219,51.500505]"
"""University_of_Aberdeen""","""56th AIAA/ASCE/AHS/ASC Structures, Structural Dynamics, and Materials Conference""","""56th AIAA/ASCE/AHS/ASC Structures, Structural Dynamics, and Materials Conference\n56th AIAA/ASCE/AHS/ASC Structures, Structural Dynamics, and Materials Conference\n5-9 January 2015\nList: $1500.00\nAdding the item to your cart\nYour cart has been updated. You can continue browsing, or you can go to your cart now. If you continue browsing, you can visit your cart at any time by clicking on the cart link at the top of the page.\n56th AIAA/ASCE/AHS/ASC Structures, Structural Dynamics, and Materials Conference\nMeeting Location: Kissimmee, Florida\nMDO: Aircraft Systems Design Applications\nMonday, 5 January 2015\nMDO: Fundamental Algorithms & Processes I\nMonday, 5 January 2015\n1130 hrs\nGraph Coarsening Method for KKT Matrices Arising from Orthogonal Collocation Methods for Optimal Control Problems (AIAA 2015-0142)\nCitation | PDF (2670 KB) | PDF Plus (615 KB)  \n1030 hrs\nAeroelastic Stability Predictions of a Business Jet Landing Gear Door using High Fidelity Fluid-Structure Interaction Tools (AIAA 2015-0173)\nCitation | PDF (1175 KB) | PDF Plus (1095 KB)  \n1130 hrs\nNonlinear Model Updating of a Cantilevered Plate and a Stiffened Skin Panel from a Lynx Helicopter (AIAA 2015-0180)\nVehicle/Component Dynamic Environment and Loads\nMonday, 5 January 2015\nCitation | PDF (1138 KB) | PDF Plus (1075 KB)  \n1100 hrs\nIntegrated Flexible Dynamic Maneuver Loads Models based on Aerodynamic Influence Coefficients of a 3D Panel Method (AIAA 2015-0185)\nSpecial Sessions in Honor of Prof. Harry H. Hilton I\nMonday, 5 January 2015\nCitation | PDF (2317 KB) | PDF Plus (1510 KB)  \n1200 hrs\nNonlinear Structural Analysis of a Icosahedron and Its Application to Lighter Than Air Vehicles Under an Internal Vacuum (AIAA 2015-0197)\n0930 hrs\nIntegrated Computational Materials Engineering for  Airframe Composite Structure Applications (AIAA 2015-0198)\n1130 hrs\nMicrostructural Influence on Deformation and Fatigue Life of Composites Using the Generalized Method of Cells (AIAA 2015-0202)\nICME Applications - Residual Stress Modeling and Measurement\nMonday, 5 January 2015\n1530 hrs\nThe Impact of Forging Residual Stress on Fatigue in Aluminum (AIAA 2015-0386)\nCitation | PDF (2026 KB) | PDF Plus (1311 KB)  \n1600 hrs\nResidual Stress Measurements for Model Validation As Applied in the United States Air Force Foundational Engineering Problem Program on ICME of Bulk Residual Stress in Ni Rotors (AIAA 2015-0387)\nMonday, 5 January 2015\n1400 hrs\nA Multiscale Model Coupling Molecular Dynamics Simulations and Micromechanics to Study the Behavior of CNT-Enhanced Nanocomposites (AIAA 2015-0390)\nFlutter, LCO and Aeroelastic Tailoring\nMonday, 5 January 2015\nEnergy Harvesting, Health Monitoring and Multifunctional Structures\nMonday, 5 January 2015\nSpecial Session: Composite Laminate Optimization\nMonday, 5 January 2015\n1530 hrs\nMass Optimisation of Variable Angle Tow, Variable Thickness Panels with Static Failure and Buckling Constraints (AIAA 2015-0452)\nFailure Analysis and Prediction I\nMonday, 5 January 2015\n1630 hrs\nProgressive Damage and Failure Prediction of Open Hole Tension and Open Hole Compression Specimens (AIAA 2015-0466)\nCitation | PDF (3068 KB) | PDF Plus (3096 KB)  \n1700 hrs\nComparative Studies of Residual Stress Effects on Fatigue Crack Growth of Welded Aluminum Structures under Block Spectrum Loading (AIAA 2015-0467)\nCitation | PDF (1880 KB) | PDF Plus (1319 KB)  \n1000 hrs\nThe process of validating Model and Software for applying Model-Based Development (MBD) to embedded systems more fruitfully (AIAA 2015-0563)\nTuesday, 6 January 2015\n0930 hrs\nAn Overview of the NASA High Speed ASE Project: Aeroelastic Analyses of a Low-Boom Supersonic Configuration (AIAA 2015-0684)\n1000 hrs\nResponse of a Panel to Shock Impingement: Modeling and Comparison with Experiments - Part 2 (AIAA 2015-0685)\nTuesday, 6 January 2015\n0930 hrs\nNonlinear Normal Modes in  Finite Element Model Validation of  Geometrically Nonlinear Flat and Curved Beams (AIAA 2015-0689)\n1100 hrs\nNonlinear Geometric Reduced Order Model for the Response of a Beam with a Piezoelectric Actuator (AIAA 2015-0692)\nSpecial Session: Challenges in the Design of Joined Wings I\nTuesday, 6 January 2015\nCitation | PDF (4451 KB) | PDF Plus (806 KB)  \n1000 hrs\nPerformance Based MDO of a Joined-Wing Regional Transport Aircraft (For Challenges in the Design of Joined Wings SPECIAL SESSION) (AIAA 2015-0696)\nSpecial Sessions in Honor of Prof. Harry H. Hilton  II\nTuesday, 6 January 2015\n0930 hrs\nMolecular Dynamics and Finite Element Investigation of Polymer Interphase Effects on Effective Stiffness of Wavy Aligned Carbon Nanotube Composites (AIAA 2015-0701)\nCitation | PDF (1070 KB) | PDF Plus (741 KB)  \n1200 hrs\nFurther Results on the Use of Material Tailoring to Improve Buckling Capacity of Elliptical Composite Cylinders (AIAA 2015-0706)\nCitation | PDF (1524 KB) | PDF Plus (1232 KB)  \n1430 hrs\nInterlaminar and Intralaminar Dynamic Fracture Behaviors of CFRP: An Investigation Using Digital Image Correlation and High-Speed Photography (AIAA 2015-0892)\n1530 hrs\nFatigue Life of Selective Laser Melted and Hot Isostatically Pressed Ti-6Al-4v Absent of Surface Machining (AIAA 2015-0894)\nMDO: Fundamental Algorithms & Processes II\nTuesday, 6 January 2015\nSpecial Session: Transformative Technologies for High-Speed/High-Efficiency Next-Gen Rotorcraft I\nTuesday, 6 January 2015\nSpecial Session: Impact Damage in Composites\nTuesday, 6 January 2015\n1400 hrs\nFace-on and Edge-on Impact Response of Composite Laminates (AIAA 2015-0956)\nCitation | PDF (1131 KB) | PDF Plus (1033 KB)  \n1630 hrs\nComparison of Delamination Threshold Load Prediction on Low Velocity Impact of Composite Panels with Different Thickness (AIAA 2015-0961)\nFailure Analysis and Prediction II\nTuesday, 6 January 2015\nWednesday, 7 January 2015\n0930 hrs\nModeling Rate Dependent Response of Shape Memory Alloys Using a Thermo-Mechanical Continuum Phase Field Approach (AIAA 2015-1118)\nCitation | PDF (2993 KB) | PDF Plus (3017 KB)  \n1030 hrs\nThe effective elastic and fracture properties of particulate reinforced composites using a new non-local particle method (AIAA 2015-1119)\n1000 hrs\nA Versatile In-Situ Ablation Recession and Thermal Sensor Adaptable for Different Types of Ablatives (AIAA 2015-1122)\n1130 hrs\nImproved Aircraft Tire Life through Laboratory Tire Wear Testing and Computational Modeling (AIAA 2015-1125)\nCitation | PDF (1214 KB) | PDF Plus (1131 KB)  \n1200 hrs\nEnvironmental Effects on Long Term Displacement Data of Woven Fabric Webbings Under Constant Load for Inflatable Structures (AIAA 2015-1126)\n1130 hrs\nRobust Design of Aeroelastically Tailored Composite Plates Using a New Formulation of Anti-Optimization and Optimization (AIAA 2015-1131)\nWednesday, 7 January 2015\n0930 hrs\nA Novel Scheme to Accurately Compute Higher Vibration Modes using the Ritz Method and a Two-point BVP Solver (AIAA 2015-1166)\nCitation | PDF (2858 KB) | PDF Plus (837 KB)  \n1000 hrs\nFree Vibration Analysis of an Integrally Stiffened Plate with Plate-Strip Stiffeners using a Set of Static Timoshenko Beam Functions (AIAA 2015-1167)\nSpecial Session: Subsonic Ultra Green Aircraft Research (SUGAR) Truss Braced Wing Aeroelasticity\nWednesday, 7 January 2015\n0930 hrs\nSUGAR Truss Braced Wing Full Scale Aeroelastic Analysis and Dynamically Scaled Wind Tunnel Model Development (AIAA 2015-1171)\n1000 hrs\nAeroservoelastic Wind-Tunnel Test of the SUGAR Truss Braced Wing Wind-Tunnel Model (AIAA 2015-1172)\n1100 hrs\nAeroelastic Analysis of SUGAR Truss-Braced Wing Wind-Tunnel Model Using FUN3D and a Nonlinear Structural Model (AIAA 2015-1174)\nSpecial Session: Challenges in the Design of Joined Wings II\nWednesday, 7 January 2015\n0930 hrs\nfor Challenges in the Design of Joined Wings Special Session: Comparison of Aeroelastic Stability of Conventional and Joined-Wing Highly Flexible Aircraft (AIAA 2015-1182)\nCitation | PDF (677 KB) | PDF Plus (681 KB)  \n1000 hrs\nFor Challenges in the Design of Joined Wings Special Session: Joined-wing Aircraft in the Twenty-First Century and Beyond (AIAA 2015-1183)\nSpecial Sessions in Honor of Prof. Harry H. Hilton III\nWednesday, 7 January 2015\n0930 hrs\nA Multi-Objective Nonlinear Piezoaeroelastic Wing Solution for Energy Harvesting and Load Alleviation: Modeling and Simulation (AIAA 2015-1188)\nCitation | PDF (1632 KB) | PDF Plus (1383 KB)  \n1130 hrs\nFor Special Session in Honor of Harry H. Hilton Manipulating Natural Frequencies with Tunable Spring Masses (AIAA 2015-1192)\nMaterials & Design for Additive Manufacturing\nWednesday, 7 January 2015\nCitation | PDF (443 KB) | PDF Plus (412 KB)  \n1530 hrs\nMultiscale Stochastic Analysis of FRP based on variability in fiber volume fraction, epoxy stiffness and strength (AIAA 2015-1361)\nMDO: Decision Making/Value Driven Design\nWednesday, 7 January 2015\nSpecial Session: Adaptive Aeroelastic Wing Shaping Control I\nWednesday, 7 January 2015\n1400 hrs\nAeroelastic Analysis of Wind Tunnel Test Data of a Flexible Wing with a Variable Camber Continuous Trailing Edge Flap (VCCTEF) (AIAA 2015-1405)\nCitation | PDF (1287 KB) | PDF Plus (1090 KB)  \n1430 hrs\nThe design, construction, and tests of a concept aeroelastic wind tunnel model of a high-lift variable camber continuous trailing edge flap (HL-VCCTEF) wing configuration (AIAA 2015-1406)\nCitation | PDF (1457 KB) | PDF Plus (642 KB)  \n1530 hrs\nMultidisciplinary Drag Optimization of Reduced Stiffness Flexible Wing Aircraft With Variable Camber Continuous Trailing Edge Flap (AIAA 2015-1408)\nSpecial Session: Transformative Technologies for High-Speed/High-Efficiency Next-Gen Rotorcraft II\nWednesday, 7 January 2015\nFlutter, LCO and Aeroelastic Instabilities\nWednesday, 7 January 2015\nCitation | PDF (282 KB) | PDF Plus (286 KB)  \n1630 hrs\nIn-Flight Aeroelastic Stability of the Thermal Protection System on the NASA HIAD, Part II: Nonlinear Theory and Extended Aerodynamics (AIAA 2015-1422)\nDesign, Test and Analysis I\nWednesday, 7 January 2015\nCitation | PDF (6224 KB) | PDF Plus (1906 KB)  \n1430 hrs\nMechanical Properties and Fatigue Behavior of 2D and 3D Woven PMC Airframe Structures at Elevated Temperature (AIAA 2015-1429)\nCitation | PDF (1129 KB) | PDF Plus (871 KB)  \n1500 hrs\nA Comparison of FEM and Semi-Analytical Method in the Buckling and Vibration of Non-Prismatic Columns under Tip Force and Self-Weight (AIAA 2015-1437)\nCitation | PDF (824 KB) | PDF Plus (559 KB)  \n1630 hrs\nOptimization of Damaged Composite Plates Under Buckling and Post buckling condition in Hygrothermal Environment employing an Inverse Hyperbolic Shear Deformation Theory (AIAA 2015-1440)\nThursday, 8 January 2015\n0930 hrs\nCitation | PDF (1571 KB) | PDF Plus (1392 KB)  \n1100 hrs\nA Phantom Paired Element Based Discrete Crack Network (DCN) Toolkit for Residual Strength Prediction of Laminated Composites (AIAA 2015-1579)\nActive and Passive Damping Systems\nThursday, 8 January 2015\nCitation | PDF (1262 KB) | PDF Plus (1198 KB)  \n1030 hrs\nEnergy Dissipation in a Riveted Lap Joint of Aircraft Structure under In-plane Tensile and Shear Loading (AIAA 2015-1636)\nCitation | PDF (697 KB) | PDF Plus (761 KB)  \n1530 hrs\nMulti-Objective WindFarm Optimization Simultaneously Optimizing COE and Land Footprint of Wind Farms under Different Land Plot Availability (AIAA 2015-1802)\nSpecial Session: Adaptive Aeroelastic Wing Shaping Control II\nThursday, 8 January 2015\n1400 hrs\nAerodynamic Load Analysis of a Variable Camber Continuous Trailing Edge Flap System on a Flexible Wing Aircraft (AIAA 2015-1839)\nTest and Evaluation and System Identification\nThursday, 8 January 2015\nCitation | PDF (1875 KB) | PDF Plus (1880 KB)  \n1430 hrs\nDesign and Testing of an Active Aeroelastic Test Bench (AATB) for Unsteady Aerodynamic and Aeroelastic Experiments (AIAA 2015-1857)\nCitation | PDF (5023 KB) | PDF Plus (1482 KB)  \n1600 hrs\nDesign and Analysis of a Wind Tunnel Test Model System for Rolling Maneuver Load Alleviation of Flying Wings (AIAA 2015-1860)\nDesign, Test and Analysis II\nThursday, 8 January 2015\nSpecial Session: USAF Benchmarking of Composite Damage Prediction Methods\nThursday, 8 January 2015\nCitation | PDF (1699 KB) | PDF Plus (1314 KB)  \n1430 hrs\nAssessment of Reduced Order Homogenization for Damage Tolerant Design Principles (DTDP) of Advanced Composite Aircraft Structures (AIAA 2015-1877)\n1500 hrs\nStatic Validation of  Composite Open Hole Analysis Technique for Standard and nonstandard Laminate -Part 1 (AIAA 2015-1878)\nCitation | PDF (689 KB) | PDF Plus (574 KB)  \n1530 hrs\nApplication of Reduced Order Multiscale Homogenization to ‘Assess and Quantify the Benefits of Applying Damage Tolerant Design Principles to Advanced Composite Aircraft Structures’ (AIAA 2015-1879)\n""","0.18192278","""https://arc.aiaa.org/doi/book/10.2514/MSDM15""","[-2.099122,57.165019]"
"""University_of_Aberdeen""","""Multivariate Simulation and Multimodal Dependence Modeling of Vehicle Axle Weights with Copulas | Journal of Transportation Engineering | Vol 132, No 12""","""Journal of Transportation Engineering\nShare\nAbstract\nSafety assessment and rational design of bridge structures requires the uncertainty associated with vehicle loads to be modeled as accurately as possible. This modeling is rendered difficult by the presence of vehicle axle weights that involve different combinations of unimodal and multimodal probability distributions with different dependence structures. In this paper, a transformation invariant approach using copula functions is proposed for the multivariate simulation of dependent axle weights of different vehicle classes. Copula based dependence modeling, which is widely used in the financial risk analysis, is applied to model and simulate three different vehicle cases with different combinations of marginal probability distributions for axle weights. The database of observed vehicle weights is based on the data collected at five locations on national highways in India. The dependence between multimodal distributions of axle weights is accurately considered and simulations are carried out. The simulated axle weights are found to be in very good agreement with the observed data. This type of simulation is useful in carrying out simulation-based reliability analysis of bridges and pavements.\n""","1.1309805","""http://ascelibrary.org/doi/10.1061/%28ASCE%290733-947X%282006%29132%3A12%28945%29""","[-2.099122,57.165019]"
"""Imperial_College_London""","""Influence of the pavement surface on the vibrations induced by heavy traffic in road bridges - Canadian Journal of Civil Engineering""","""Canadian Journal of Civil Engineering\nA. Camara, a V.F. Vázquez, b A.M. Ruiz-Teran, c S.E. Paje b\naDepartment of Civil Engineering at City, University of London, Northampton Square, EC1V 0HB, London, United Kingdom.\nbLaboratory of Acoustics Applied to Civil Engineering, University of Castilla-La Mancha, Avda. Camilo José Cela s/n, 13071 Ciudad Real, Spain.\ncDepartment of Civil and Environmental Engineering. Imperial College London. South Kensington Campus. Exhibition Rd, London SW7 2AZ, United Kingdom.\nCorresponding author: Alfredo Camara (email: alfredo.\nCopyright remains with the author(s) or their institution(s). Permission for reuse (free in most cases) can be obtained from RightsLink .\nPublished on the web 7 September 2017.\nReceived May 17, 2017. Accepted August 26, 2017.\nCanadian Journal of Civil Engineering, 2017, 44(12): 1099-1111, https://doi.org/10.1139/cjce-2017-0310\nAbstract\nThe irregularity of the pavement surface governs the traffic-induced vibrations in road bridges, but it is either ignored or simulated by means of ideal pavements that differ significantly from real cases. This work presents a detailed dynamic analysis of a heavy truck crossing a 40 m span composite deck bridge using on-site measurements of different existing road profiles, as well as code-based ideal pavements. By activating or deactivating certain spatial frequency bands of the pavement, it is observed that the ranges 0.2–1 and 0.02–0.2 cycles/m are critical for the comfort of the pedestrians and the vehicle users, respectively. Well maintained roads with low values of the displacement power spectral density (PSD) associated with these spatial frequency ranges could reduce significantly the vibration on the sidewalks and, specially, in the vehicle cabin. Finally, a consistent road categorization for vibration assessment based on the PSD of the pavement irregularity evaluated at the dominant frequencies is proposed.\nKeywords: bridge dynamics , pavement irregularity , vibrations , vehicle–bridge interaction models , pedestrians\nReferences\nAASHTO. 1998. Load and resistance and factor design: Bridge design specifications. 2nd ed. American Association of State Highway and Transportation Officials.\nAbaqus. 2011. Finite element analysis program. Version 6.11. Providence, USA.\nBoggs, D., and Petersen, C. 1995. Acceleration indexes for human comfort in tall buildings–peak or rms?\nBogsjö, K., Podgorsky, K., and Rychlik, I. 2010. Models for road surface roughness. Department of Mathematical Sciences, University of Gothemburg.\nCamara A,  Ruiz-Teran AM.                 2015. Multi-mode traffic-induced vibrations in composite ladder-deck bridges under heavy moving vehicles. Journal of Sound and Vibration 355: 264-283 Crossref .\nCamara A,  Nguyen K,  Ruiz-Teran AM,  Stafford PJ.                 2014. Serviceability limit state of vibrations in under-deck cable-stayed bridges accounting for vehicle-structure interaction. Engineering Structures 61: 61-72 Crossref .\nCaptain KM,  Boghani AB,  Wormley DN.                 1979. Analytical tire models for dynamic vehicle simulation. Vehicle System Dynamics 8: 1-32 Crossref .\nChang KC,  Wu FB,  Yang YB.                 2011. Disk model for wheels moving over highway bridges with rough surfaces. Journal of Sound and Vibration 330: 4930-4944 Crossref .\nCoussy O,  Said M,  Van Hoove, J-P.                 1989. The influence of random surface irregularities on the dynamic response of bridges under suspended moving loads. Journal of Sound and Vibration 130(2): 313-320 Crossref , ISI .\nDeng L,  Cai CS.                 2009. Identification of parameters of vehicles moving on bridges. Engineering Structures 31(10): 2474-2485 Crossref .\nDeng L,  Cai CS.                 2010. Development of dynamic impact factor for performance evaluation of existing multi-girder concrete bridges. Engineering Structures 32(1): 21-31 Crossref .\nDescornet, G. 1990. Reference road surfaces for vehicle testing. Roads PIARC. No. 272.\nDodds, C. 1972. Generalised terrain dynamic inputs to vehicles. BSI document 72/34562 (ISO/TC/108/WG9 (MEE/158/3/1)).\nDodds CJ,  Robson JD.                 1973. The description of road surface roughness. Journal of Sound and Vibration 31(2): 175-183 Crossref , ISI .\nHan W,  Wu J,  Cai C,  Chen S.                 2014. Characteristics and dynamic impact of overloaded extra heavy trucks on typical highway bridges. Journal of Bridge Engineering 20(2): 05014011 Crossref .\nHenchi K,  Fafard M,  Talbot M,  Dhatt G.                 1998. An efficient algorithm for dynamic analysis of bridges under moving vehicles using a coupled modal and physical components approach. Journal of Sound and Vibration 214(4): 663-683 Crossref .\nHilber HM,  Hughes TJR,  Taylor RL.                 1977. Improved numerical dissipation for time integration algorithms in structural dynamics. Earthquake Engineering & Structural Dynamics 5: 283-292 Crossref , ISI .\nISO 8608. 1995. Mechanical vibration–Road surface profiles–Reporting of measured data. International Organization for Standardization (ISO).\nJanoff, M., and Mayhoe, G. 1990. The development of a simple instrument for measuring pavement roughness and predicting pavement rideability. Surface characteristic of roadways: international research and technologies. ASTM, STP 1031.\nKamash KMA,  Robson JD.                 1978. The application of isotropy in road surface modelling. Journal of Sound and Vibration 57(1): 89-100 Crossref .\nLabarre, R., Forbes, R., and Andrew, S. 1969. The measurement and analysis of road surface roughness. Motor Industry Research Association. Report No. 1970/5.\nMarchesiello S,  Fasana A,  Garibaldi L,  Piombo B.                 1999. Dynamics of multi-span continuous straight bridges subject to multi-degrees of freedom moving vehicle excitation. Journal of Sound and Vibration 224(3): 541-561 Crossref .\nMarcondes, J., Singh, S., and Burgess, G. 1988. Dynamic analysis of a less than truck load shipment. Paper 88-WA/EEP-17. ASME, New York.\nMarcondes J,  Burgess G,  Harichandran R,  Snyder M.                 1990. Spectral analysis of highway pavement roughness. Journal of Transportation Engineering 117(5): 540-549 Crossref .\nMcLean, J., and Ramsay, E. 1996. Interpretations of road profile-roughness data: review and research needs. ARRB Transport Research Report, ARR 295.\nPaje SE,  Luong J,  Vázquez VF,  Bueno M,  Miró R.                 2013. Road pavement rehabilitation using a binder with a high content of crumb rubber: Influence on noise reduction. Construction and building Materials 47: 789-798 Crossref .\nShahabadi, A. 1977. Bridge vibration studies. joint highway research project. Purdue University & Indiana State Highway Commission (September). Report. No. JHRP 77-17.\nUys PE,  Els PS,  Thoresson M.                 2007. Suspension settings for optimal ride comfort of off-road vehicles travelling on roads with different roughness and speeds. Journal of Terramechanics 44: 163-175 Crossref .\nVázquez V,  Luong J,  Bueno M,  Terán F,  Paje S.                 2016. Assessment of an action against environmental noise: Acoustic durability of a pavement surface with crumb rubber. Science of the Total Environment 542: 223-230 Crossref , Medline .\nZhou Y,  Chen S.                 2016. Vehicle ride comfort analysis with whole-body vibration on long-span bridges subjected to crosswind. Journal of Wind Engineering and Structural Dynamics 155: 126-140 Crossref .\nZhu XQ,  Law SS.                 2002. Dynamic load on continuous multi-lane bridge deck from moving vehicles. Journal of Sound and Vibration 251(4): 697-716 Crossref .\nList of symbols\n""","0.4995443","""http://www.nrcresearchpress.com/doi/10.1139/cjce-2017-0310""","[-0.178219,51.500505]"
"""Imperial_College_London""","""Modeling the bilateral micro-searching behavior for urban taxi services using the absorbing markov chain approach - Wong - 2005 - Journal of Advanced Transportation - Wiley Online Library""","""Journal of Advanced Transportation\nModeling the bilateral micro-searching behavior for urban taxi services using the absorbing markov chain approach\nAuthors\nK.I. Wong and M.G.H. Bell, Centre for Transport Studies, Department of Civil and Environmental Engineering, Imperial College London, England, UK\nS. C. Wong,\nS.C. Wong, Department of Civil Engineering, The University of Hong Kong, Hong Kong. P.R., China\nM. G. H. Bell,\nK.I. Wong and M.G.H. Bell, Centre for Transport Studies, Department of Civil and Environmental Engineering, Imperial College London, England, UK\nHai Yang\nHai Yang, Department of Civil Engineering, The Hong Kong University of Science and Technology, Hong Kong, P.R., China\nFirst published:\nCited by (CrossRef): 22 articles Check for updates\nCitation tools\nFunding Information\nAbstract\nThis paper develops a mathematical model that is based on the absorbing Markov chain approach to describe taxi movements, taking into account the stochastic searching processes of taxis in a network. The local searching behavior of taxis is specified by a logit form, and the O-D demand of passengers is estimated as a logit model with a choice of taxi meeting point. The relationship between customer and taxi waiting times is modeled by a double-ended queuing system. The problem is solved with a set of non-linear equations, and some interesting results are presented. The research provides a novel and potentially useful formulation for describing the urban taxi services in a network.\nCroucher Foundation of Hong Kong\nResearch Grants Council of the Hong Kong Special Administrative Region. Grant Number: HKUST6107/03E and HKU7134/03E\nRelated content\nArticles related to the one you are viewing\nCiting Literature\nNumber of times cited: 22\n1\nZhong Zheng, Soora Rasouli, Harry Timmermans, Modeling taxi driver anticipatory behavior, Computers, Environment and Urban Systems, 2018\nCrossRef\n2\nYuxiong Ji, Yuchuan Du, Yue Liu, H. Michael Zhang, Empirical Behavioral Study of Airport-Serving Taxi Drivers Using Automatic Vehicle Location Data, Journal of Urban Planning and Development, 2017, 143, 1, 04016026\nCrossRef\n3\nLuliang Tang, Fei Sun, Zihan Kan, Chang Ren, Luling Cheng, Uncovering Distribution Patterns of High Performance Taxis from Big Trace Data, ISPRS International Journal of Geo-Information, 2017, 6, 12, 134\nCrossRef\n4\nYing Shi, Zhaotong Lian, Optimization and strategic behavior in a passenger–taxi service system, European Journal of Operational Research, 2016, 249, 3, 1024\nCrossRef\n5\nR.C.P. Wong, W.Y. Szeto, S.C. Wong, A two-stage approach to modeling vacant taxi movements, Transportation Research Part C: Emerging Technologies, 2015, 59, 147\nCrossRef\n6\nR.C.P. Wong, W.Y. Szeto, S.C. Wong, A Two-Stage Approach to Modeling Vacant Taxi Movements, Transportation Research Procedia, 2015, 7, 254\nCrossRef\n7\nLuis M. Martinez, Gonçalo H. A. Correia, José M. Viegas, An agent-based simulation model to assess the impacts of introducing a shared-taxi system: an application to Lisbon (Portugal), Journal of Advanced Transportation, 2015, 49, 3, 475\nWiley Online Library\n8\nR. C. P. Wong, W. Y. Szeto, S. C. Wong, Behavior of taxi customers in hailing vacant taxis: a nested logit model for policy analysis, Journal of Advanced Transportation, 2015, 49, 8, 867\nWiley Online Library\n9\nR.C.P. Wong, W.Y. Szeto, S.C. Wong, A cell-based logit-opportunity taxi customer-search model, Transportation Research Part C: Emerging Technologies, 2014, 48, 84\nCrossRef\n10\nR.C.P. Wong, W.Y. Szeto, S.C. Wong, Bi-level decisions of vacant taxi drivers traveling towards taxi stands in customer-search: Modeling methodology and policy implications, Transport Policy, 2014, 33, 73\nCrossRef\n11\nR.C.P. Wong, W.Y. Szeto, S.C. Wong, Hai Yang, Modelling multi-period customer-searching behaviour of taxi drivers, Transportmetrica B: Transport Dynamics, 2014, 2, 1, 40\nCrossRef\n12\nWai Yuen Szeto, Ryan Cheuk Pong Wong, Sze Chun Wong, Hai Yang, A time-dependent logit-based taxi customer-search model, International Journal of Urban Sciences, 2013, 17, 2, 184\nCrossRef\n13\nXianbiao Hu, Song Gao, Yi-Chang Chiu, Dung-Ying Lin, Modeling Routing Behavior for Vacant Taxicabs in Urban Traffic Networks, Transportation Research Record: Journal of the Transportation Research Board, 2012, 2284, 81\nCrossRef\n14\nJosep Maria Salanova, Miquel Estrada, Georgia Aifadopoulou, Evangelos Mitsakis, A review of the modeling of taxi services, Procedia - Social and Behavioral Sciences, 2011, 20, 150\nCrossRef\n16\nHai Yang, Teng Yang, Equilibrium properties of taxi markets with search frictions, Transportation Research Part B: Methodological, 2011, 45, 4, 696\nCrossRef\n17\nR. M. N. T. Sirisoma, S. C. Wong, W. H. K. Lam, D. Wang, H. Yang, P. Zhang, Empirical evidence for taxi customer-search model, Proceedings of the Institution of Civil Engineers - Transport, 2010, 163, 4, 203\nCrossRef\n18\nHai Yang, Cowina W.Y. Leung, S.C. Wong, Michael G.H. Bell, Equilibria of bilateral taxi–customer searching and meeting on networks, Transportation Research Part B: Methodological, 2010, 44, 8-9, 1067\nCrossRef\n19\nHai Yang, C.S. Fung, K.I. Wong, S.C. Wong, Nonlinear pricing of taxi services, Transportation Research Part A: Policy and Practice, 2010, 44, 5, 337\nCrossRef\n20\nK.I. Wong, S.C. Wong, Hai Yang, J.H. Wu, Modeling urban taxi services with multiple user classes and vehicle modes, Transportation Research Part B: Methodological, 2008, 42, 10, 985\n""","0.44574505","""http://onlinelibrary.wiley.com/doi/10.1002/atr.5670390107/abstract""","[-0.178219,51.500505]"
"""Brunel_University_London""","""Editorial | Proceedings of the Institution of Civil Engineers - Transport""","""Proceedings of the Institution of Civil Engineers - Transport\nProceedings of the Institution of Civil Engineers - Transport\nISSN 0965-092X | E-ISSN 1751-7710\nPhD, CEng, MCIHT, MICE, PGCHE, FHEA\nx\nDepartment of Mechanical, Aerospace and Civil Engineering, Brunel University, London, UK\nAuthor Affiliations\nPublished Online: July 11, 2016\nKey:\nFree content\nTrial content\nWelcome to the August 2016 issue of Transport. This edition presents six papers covering important theoretical and practical aspects of transportation engineering. On behalf of the editorial board, I thank the authors for their hard work and valuable contributions to the journal. I would also like to extend my appreciation to our esteemed reviewers for their invaluable support.\nTransport networks are one of the most important national assets. Economic prosperity, rapid urbanisation, increasing traffic and ageing infrastructures all have immense impact on safe and efficient operation of this vital asset. Some of these factors are addressed in this issue.\nThe first paper ( Appiah et al., 2016 ) deals with truck characteristics in traffic micro-simulation. The authors present an approach to incorporating the operating characteristics of a local truck fleet in the calibration of micro-simulation models. This approach is different from conventional model calibration where focus is given to adjusting the parameters of driving behaviour logic. The second paper ( Mohapatra et al., 2016 ) reports the influence of conflicting traffic on U-turns at uncontrolled median openings under mixed traffic conditions in an Indian context. With rapid urbanisation and increased traffic volume, most urban roads in India are constructed as multi-lane roads, while many existing two-lane roads are also being widened to multi-lane roads. These multi-lane roads are generally constructed with a raised median, in order to segregate the opposing traffic movements. The authors showed that the impact of conflicting traffic is greater on four-lane roads compared to six-lane roads. In the third paper ( Zong et al., 2016 ), the authors present a model for investigating the feasibility of an integrated transportation demand management (TDM) programme in the Nanhai district of China to mitigate the traffic congestion and reduce exhaust gas emission from motor vehicles. The TDM programme includes a bus priority policy, a motorcycle restriction policy and a congestion pricing policy. The authors demonstrate that all three policies would have a positive effect on Nanhai's transport system. All three papers address key transport issues which traffic engineers and researchers will find very useful.\nIn recent years, railway industries have faced a massive demand for increasing train speeds. However, switch and turnout parts of the track are two critical parts where speed reduction is necessary. In order to develop a more efficient system, the fourth paper ( Sadeghi et al., 2016 ) presents a mathematical model of the impact of railway geometry on the safety of train running and permissible speed. The model is based on the railway vehicle and track parameters such as curve radius, switch initial angle and track gauge with running speed. The model accuracy is verified in field trials. This paper is a good example of how theoretical modelling could help to solve practical issues.\nThe fifth and sixth papers address concrete pavement rehabilitation. The fifth paper ( Lu and Rong, 2016 ), presents the impact of gradation on rubblised Portland cement concrete pavement. Rubblisation is a popular technique for upgrading severely deteriorated concrete pavement. Many previous studies have shown that rubblised concrete with a hot-mix asphalt (HMA) overlay improves pavement performance, especially its cracking resistance. The authors present two studies and demonstrate that if the rubblised gradation matches the requirement for the crushed stone base of the flexible pavement, tensile strains at the HMA overlay bottom develop at a slower pace, indicating an improvement in deterioration resistance (namely cracking) of the overlay system. This article should be a good resource for practitioners and researchers alike. The final paper ( Gao, 2016 ), presents a mathematical model for evaluating the impact of top-down surface cracking in concrete pavement. Surface cracks of concrete pavement not only impact safety and ride quality, but also reduce service life. The author shows that crack length and load position significantly influence the stress intensity factors, and that stress intensity factors are less affected by the elastic modulus of the pavement material than might be expected. Observing that studies on the mechanism of crack propagation in a cement concrete pavement are rather limited, this paper should serve to enhance current knowledge in this field.\nWe trust you find these papers useful and rewarding to read. Comments on this issue or on general journal-related matters will be received with great interest.\nReferences\n""","0.42610314","""https://www.icevirtuallibrary.com/doi/10.1680/jtran.2016.169.4.185""","[-0.472855,51.532848]"
"""Cranfield_University""","""Methodology to assess the performance of an aircraft concept with distributed propulsion and boundary layer ingestion using a parametric approachProceedings of the Institution of Mechanical Engineers, Part G: Journal of Aerospace Engineering - Esteban A Valencia, Devaiah Nalianda, Panagiotis Laskaridis, Riti Singh, 2015""","""ACARE. Aeronautics and air transport: beyond vision 2020 (towards 2050) (2010, accessed March 2012). Google Scholar\n2.\nGreitzer E, Bonnefoy P, de la Rosa Blanco E, et al. N+3 aircraft concept designs and trade studies. Final report. Cr-2010-216794/vol1, NASA, Cleveland, Ohio, 2010. Google Scholar\n3.\nKim H, Jeffrey J and Scott M. Low noise cruise efficient short take-off and landing transport vehicle study. In: 6th AIAA aviation technology, integration and operations conference (ATIO), AIAA, Wichita, Kansas, 2006. Google Scholar\n4.\nHyoungjin K and Meng-Sing L. Flow simulation of n2b hybrid wing body configuration. In: 50th AIAA aerospace sciences meeting including the new horizons forum and aerospace exposition, AIAA, Nashville, Tennessee, 2012. Google Scholar\n5.\nManneville A. Propulsion system concepts for silent aircraft. (S.M.) Thesis, Department of Aeronautics and Astronautics, Massachusetts Institute of Technology, Master thesis, MIT, USA, 2004, pp.179–182. Google Scholar\n6.\nde la Rosa E, Hall C and Crichton D. Special session – towards a silent aircraft challenges in the silent aircraft engine design. In: 45th AIAA aerospace sciences meeting and exhibit, AIAA, Reno, Nevada, 2007. Google Scholar\n7.\nLiebeck R. Design of the blended wing body subsonic transport. J Aircraft 2004; 41: 10–25. Google Scholar Crossref\n8.\nBrown G. Weights and efficiencies of electric components of a turboelectric aircraft propulsion system. In: 49th AIAA aerospace sciences meeting including the new horizons forum and aerospace exposition, AIAA, Orlando, Florida, 2011. Google Scholar\n9.\nFelder J, Kim H and Brown G. An examination of the effect of boundary layer ingestion on turboelectric distributed propulsion systems. In: 49th AIAA aerospace sciences meeting including the new horizons forum and aerospace exposition, AIAA, Orlando, Florida, 2011. Google Scholar\n10.\nValencia E, Liu C, Laskaridis P, et al. An alternative configuration for distributed propulsion with boundary layer ingestion on a hybrid wing body airframe. In: 21st ISABE conference, ISABE, Busan, South Korea, 2013. Google Scholar\n11.\nRodriguez D. A multidisciplinary optimization method for designing boundary layer ingesting inlets. In: 9th Symposium on multidisciplinary analysis and optimization, AIAA/ISSMO, Atlanta, Georgia, 2002. Google Scholar\n12.\nRodriguez DL. A multidisciplinary optimization method for designing boundary layer ingesting inlets. PhD Thesis, Submitted to the Department of Aeronautics and Astronautics, Stanford University, 2001. Google Scholar\n13.\nPlas A. Performance of a boundary layer ingesting (BLI) propulsion system. In: 45th AIAA aerospace sciences meeting and exhibit, AIAA, Reno, Nevada, 2007. Google Scholar\n14.\nHall C and Crichton D. Engine and installation configurations for a silent aircraft. In: 17th international symposium on air breathing engines, ISABE, Munich, Germany, 2005. Google Scholar\n15.\nDrela M. Power balance in aerodynamic flows. In: 27th AIAA applied aerodynamics conference, AIAA, San Antonio, Texas, 2009. Google Scholar\n16.\nKim H and Felder J. Control volume analysis of boundary layer ingesting propulsion systems with or without shock wave ahead of the inlet. In: 49th AIAA aerospace sciences meeting including the new horizons forum and aerospace exposition, AIAA, Orlando, Florida, 2011. Google Scholar\n17.\nPlas A. Performance of a boundary layer ingesting propulsion system. (S.M.) Thesis, Department of Aeronautics and Astronautics, Massachusetts Institute of Technology, 2006. Google Scholar\n18.\nFelder J, Tong M and Chu J. Sensitivity of mission energy consumption to turboelectric distributed propulsion design assumptions on the N3-X hybrid wing body aircraft. In: 48th AIAA joint propulsion conference and exhibit, AIAA, Atlanta, Georgia, 2012. Google Scholar\n19.\nMasson P, Soban D, Upton E, . HTS motors in aircraft propulsion: design considerations. IEEE Trans Appl Supercond 2005; 15: 2218–2221. Google Scholar Crossref\n20.\nMasson P, Pienkos J, Luongo C. Scaling up of HTS motor based on trapped flux and flux concentration for large aircraft propulsion. IEEE Trans Appl Supercond 2007; 17: 1579–1582. Google Scholar Crossref\n21.\nFelder J, Kim H and Brown G. Turboelectric distributed propulsion engine cycle analysis for hybrid-wing-body aircraft. In: 47th AIAA aerospace sciences meeting including the new horizons forum and aerospace exposition, AIAA, Orlando, Florida, 2009. Google Scholar\n22.\nOsborn WM, Moore RD, et al. Aerodynamic performance of a 1.35-pressure-ratio axial-flow fan stage. NASA Technical Paper. NASA, Washington, D.C. Walter M.Osborn, Royce D Moore, Ronald J Steinke. Google Scholar\n23.\nLiu C, Doulgeris G, Laskaridis P, et al. Turboelectric distributed propulsion system modelling for hybrid-wing-body aircraft. American Institute of Aeronautics and Astronautics, 07/30; 2014/04. 21; M1: 0; doi:10.2514/6.2012-3700; M3: doi:10.2514/6.2012-3700. Google Scholar\n24.\nRodriguez D. Multidisciplinary optimization method for designing boundary-layer-ingesting inlets. J Aircraft AIAA 2009, pp. 883–894. Google Scholar Crossref\n25.\nMasson P and Luongo C. HTS machines for applications in all-electric aircraft. In: IEEE Power engineering society general meeting, Tampa, Florida, 2007. IEEE. Google Scholar\n26.\nLuongo C, Masson P, Nam T, . Next generation more-electric aircraft: a potential application for HTS superconductors. IEEE Trans Appl Supercond 2009; 19: 1055–1068. Google Scholar Crossref\n27.\nSaravanamuttoo H, Rogers G, Cohen H. Gas turbine theory, 5th ed. Harlow, England, New York: Prentice Hall, 2001. Google Scholar\n""","0.35246533","""http://journals.sagepub.com/doi/10.1177/0954410014539291""","[-0.629225,52.074389]"
"""UCL""","""Iris Publication""","""22/09/2012\nAbstract\nThe concept of social justice is increasingly called upon in the assessment of the social and environmental sustainability of urban transport. This paper brings together two strands of the literature on this topic: the role of accessibility in social inclusion and the distribution of the environmental impacts of transport. Using the Lisbon Metropolitan Area as case study, we test if there are cumulative social inequalities in terms of accessibility and pedestrian mobility, considering that the latter depends on local environmental quality. We use GIS methods to estimate a series of neighbourhood-level indicators, such as private and public transport accessibility to jobs and urban facilities, community severance and pedestrian exposure to traffic noise. Neighbourhoods are then classified based on the scores of those indicators at two moments in time. We found six clusters. Accessibility increases and pedestrian mobility decreases as we move from the ‘main centre’ towards the ‘suburban’, ‘small centres’, ‘semi-rural’ and ‘rural’ clusters. A sixth cluster is labelled ‘multiple disadvantages’ and groups dispersed neighbourhoods that fare poorly in all indicators. The clusters are then characterized in terms of their socio-economic composition. We find that central areas usually have elderly populations, while rural areas and the “multiple disadvantaged” cluster tend to have low-qualified populations. We also test if disadvantages based on a neighbourhood’s location persist after accounting for the daily destinations and travel modes used by its population. We find that ‘multiple disadvantaged’ areas have the poorest scores in time to work, effects of congestion, and pedestrian noise exposures for commuters on the way to work.  The main conclusion is that ‘hotspots’ of multiple transport-related disadvantages tend to have populations traditionally at risk of social exclusion. More emphasis should be put on locally-based interventions on and public participation methods in the definition of strategies for urban transport planning.\nPublication data is maintained in RPS. Visit https://rps.ucl.ac.uk\n› More search options\n""","0.5913847","""http://iris.ucl.ac.uk/iris/publication/917824/1""",
"""Imperial_College_London""","""Insights into Brown Adipose Tissue Physiology as Revealed by Imaging Studies: Adipocyte: Vol 4, No 1""","""Review\nInsights into Brown Adipose Tissue Physiology as Revealed by Imaging Studies\nAccepted author version posted online: 28 Oct 2014\nPublished online: 14 Nov 2014\nPDF\nAbstract\nThere has been resurgence in interest in brown adipose tissue (BAT) following radiological and histological identification of metabolically active BAT in adult humans. Imaging enables BAT to be studied non-invasively and therefore imaging studies have contributed a significant amount to what is known about BAT function in humans. In this review the current knowledge (derived from imaging studies) about the prevalence, function, activity and regulation of BAT in humans (as well as relevant rodent studies), will be summarized.\nAbbreviations:: 11C-MHED, [11C]-meta-hydroxyephedrine ,  18F-FDG, [18F]-fluorodeoxyglucose ,  99mTc-sestamibi, technetium-99m sestamibi ,  99mTc-tetrofosmin, technetium-99m tetrofosmin ,  ATP, adenosine triphosphate ,  BAT, brown adipose tissue ,  BMI, body mass index ,  BOLD, blood oxygen level dependent ,  CIT, cold-induced thermogenesis ,  IQR, interquartile range ,  MRI, magnetic resonance imaging ,  NST, non-shivering thermogenesis ,  PET-CT, positron emission tomography-computed tomography ,  SPECT, single photon emission CT ,  UCP-1, uncoupling protein 1 ,  WAT, white adipose tissue\nIntroduction\nRecent publications have unequivocally demonstrated the presence of thermogenically active brown adipose tissue (BAT) in adult humans and have led to renewed interest in the study of this type of adipose tissue. When activated, brown adipocytes release energy in the form of heat by uncoupling the protons generated by substrate oxidation from adenosine triphosphate (ATP) production. BAT cells express a special protein called UCP1 (uncoupling protein1/thermogenin) which enables them to do this. Since activated BAT increases energy expenditure, it may play an important role in energy homeostasis and thus could be utilised in the treatment of obesity. Many techniques have been employed to study this unique tissue and imaging techniques in particular have enabled in vivo studies to be performed. This review will highlight the main imaging modalities that have been used to study BAT and summarise how each of these modalities has contributed to our knowledge of the characteristics and function of BAT in humans.\nPositron emission tomography - computed tomography (PET-CT)\n18F-FDG ([18F]-fluorodeoxyglucose)\nPET-CT is the most widely used imaging modality currently used to study BAT. It consists of a functional scan in which metabolically or biochemically active tissues are detected (i.e. the PET scan) and an anatomic scan (i.e., CT scan) performed at the same time. Following acquisition and processing of the images from both scans, they can be viewed individually or superimposed on each other to produce a single fused (or co-registered) image. [18F]-fluorodeoxyglucose (18F-FDG) is a tracer that is used to detect highly metabolically active tissue(s). 18F-FDG enters the metabolically active cells via specific glucose transporters and is then phosphorylated by hexokinase to its 6-phosphate. The 6-phosphate cannot be metabolised any further and therefore it is effectively trapped within the cell. The radioactive fluorine component of the tracer decays, and the products of its decay are detected by the PET scanner. The metabolically active tissues that have taken up the tracer can then be identified.1\nPET-CT was initially used in clinical practice for identifying and staging malignant tumors. However, on these PET scans bilateral symmetric uptake was often noted in the neck and shoulder regions. Initially, this was thought to be due to active muscle, but CT scans of the same regions demonstrated that the tissues with this symmetrical uptake had the density of adipose tissue not muscle. These areas were called \""USA-fat\"" (uptake of 18F-FDG localizing to the supraclavicular area) 1 Nedergaard J, Bengtsson T, Cannon B. Unexpected evidence for active brown adipose tissue in adult humans. Am J Physiol Endocrinol Metab 2007; 293: E444-52; PMID:17473055; http://dx.doi.org/10.1152/ajpendo.00691.2006 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] and some authors felt that this represented BAT 2,3 Hany TF, Gharehpapagh E, Kamel EM, Buck A, Himms-Hagen J, von Schulthess GK. Brown adipose tissue: a factor to consider in symmetrical tracer uptake in the neck and upper chest region. Eur J Nucl Med Mol Imaging 2002; 29: 1393-8; PMID:12271425; http://dx.doi.org/10.1007/s00259-002-0902-6\nYeung HW, Grewal RK, Gonen M, Schoder H, Larson SM. Patterns of (18)F-FDG uptake in adipose tissue and muscle: a potential source of false positives for PET. J Nucl Med 2003; 44: 1789-96; PMID:14602861  especially as the prevalence of “USA-fat” was found to be 3 times higher in winter (when outdoor temperatures were low) than the rest of the year. 4 Cohade C, Mourtzikos KA, Wahl RL. “USA-fat”: prevalence is related to ambient outdoor temperature – evaluation with 18F-FDG PET/CT. J Nucl Med 2003; 44: 1267-70; PMID:12902417 [PubMed] , [Web of Science ®]   [Google Scholar]\nIn 2009, Virtanen et al. demonstrated that the cold-induced increased 18 Drubach LA, Palmer EL, Connolly LP, Baker A, Zurakowski D, Cypess AM. Pediatric brown adipose tissue: detection, epidemiology, and differences from adults. J Pediatr 2011; 159: 939-44; PMID:21839465; http://dx.doi.org/10.1016/j.jpeds.2011.06.028 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] F-FDG uptake seen on PET scans was due to paracervical and supraclavicular adipose tissue. 5 Virtanen KA, Lidell ME, Orava J, Heglind M, Westergreen R, Niemi T, Taittonen M, Laine J, Savisto N-J, Enerback S, et al. Functional brown adipose tissue in healthy adults. N Engl J Med 2009; 360: 1518-25; PMID:19357407; http://dx.doi.org/10.1056/NEJMoa0808949 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] These tissues were biopsied and found to have the cellular morphology of BAT and expressed UCP1 protein and mRNA. 5 Virtanen KA, Lidell ME, Orava J, Heglind M, Westergreen R, Niemi T, Taittonen M, Laine J, Savisto N-J, Enerback S, et al. Functional brown adipose tissue in healthy adults. N Engl J Med 2009; 360: 1518-25; PMID:19357407; http://dx.doi.org/10.1056/NEJMoa0808949 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] This study proved that not only is BAT present in adult humans, it is metabolically active and can be stimulated by cold. 5 Virtanen KA, Lidell ME, Orava J, Heglind M, Westergreen R, Niemi T, Taittonen M, Laine J, Savisto N-J, Enerback S, et al. Functional brown adipose tissue in healthy adults. N Engl J Med 2009; 360: 1518-25; PMID:19357407; http://dx.doi.org/10.1056/NEJMoa0808949 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] Two retrospective studies, which examined different series of over 3600 consecutive PET-CT scans, found a prevalence of active BAT of ∼3% in men and 7.2–7.5% in women. 6,7 Cypess AM, Lehman S, Williams G, Tal I, Rodman D, Goldfine AB, Kuo FC, Palmer EL, Tseng Y-H, Doria A, et al. Identification and importance of brown adipose tissue in adult humans. N Eng J Med 2009; 360: 1509-17; http://dx.doi.org/10.1056/NEJMoa0810780\nAu-Yong ITH, Thorn N, Ganatra R, Perkins AC, Symonds ME. Brown adipose tissue and seasonal variation in humans. Diabetes 2009; 58: 2583-7; PMID:19696186; http://dx.doi.org/10.2337/db09-0833  A more recent and much larger retrospective study found a prevalence of active BAT of 1.32% in 31,088 PET-CT scans performed for medical check-ups (n = 16,699) and cancer surveillance (n = 14,389). 8 Zhang Z, Cypess AM, Miao Q, Ye H, Liew CW, Zhang Q, Xue R, Zhang S, Zuo C, Xu Z, et al. The prevalence and predictors of active brown adipose tissue in Chinese adults. Eur J Endocrinol 2014; 170: 359-66; PMID:24288355; http://dx.doi.org/10.1530/EJE-13-0712 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] Smaller cohort studies have reported a higher prevalence of cold-activated BAT (confirmed histologically) of 34% (19/56) in healthy volunteers aged 23–65 y in winter, 9 Saito M, Okamatsu-Ogura Y, Matsushita M, Watanabe K, Yoneshiro T, Nio-Kobayashi J, Iwanga T, Miyagawa M, Kameya T, Nakada K, et al. High incidence of metabolically active brown adipose tissue in healthy adult humans: effects of cold exposure and adiposity. Diabetes 2009; 58: 1526-31; PMID:19401428; http://dx.doi.org/10.2337/db09-0530 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] 48% (125/260) in healthy volunteers aged 20–72 y in winter, 10 Matsushita M, Yoneshiro T, Kameya T, Sugie H, Saito M. Impact of brown adipose tissue on body fatness and glucose metabolism in healthy humans. Int J Obesity 2014; 38: 812-7; http://dx.doi.org/10.1038/ijo.2013.206 [Crossref] , [Web of Science ®]   [Google Scholar] 96% (23/24) of healthy men aged 20–32 y with BMIs (body mass indexes) ranging from 21.3–38.8, 11 van Marken Lichtenbelt W, Vanhommergig JW, Smulders NM, Drossaerts JM, Kemerink GJ, Bouvy ND, Schrauwen P, Jaap Teule GJ. Cold-activated brown adipose tissue in healthy men. N Eng J Med 2009; 360: 1500-8; http://dx.doi.org/10.1056/NEJMoa0808718 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] and 20% (3/15) in morbidly obese volunteers. 12 Vijgen GHE, Bouvy ND, Jaap Teule GJ, Brans B, Schrauwen P, van Marken Lichtenbelt WD. Brown adipose tissue in morbidly obese subjects. PLoS One 2011; 6: e17247. DOI:10.1371/journal.pone.0017247; PMID:21390318; http://dx.doi.org/10.1371/journal.pone.0017247 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar]\nIn these studies (which were performed in temperate regions) the prevalence and/or activity of detectable BAT was higher in winter/lower outdoor temperatures, younger subjects, females, in people with lower BMIs, lower blood glucose levels, lower percentages of body fat and lower quantities of visceral fat. In a study performed in a subtropical area, an inverse association between BAT 18 Drubach LA, Palmer EL, Connolly LP, Baker A, Zurakowski D, Cypess AM. Pediatric brown adipose tissue: detection, epidemiology, and differences from adults. J Pediatr 2011; 159: 939-44; PMID:21839465; http://dx.doi.org/10.1016/j.jpeds.2011.06.028 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] F-FDG uptake and outdoor temperature was also observed. 13 Perkins AC, Mshelia DS, Symonds ME, Sathekge M. Prevalence and pattern of brown adipose tissue distribution of 18F-FDG in patients undergoing PET-CT in subtropical climatic zone. Nucl Med Commun 2013; 34: 168-74; PMID:23196673; http://dx.doi.org/10.1097/MNM.0b013e32835bbbf0 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] Furthermore the mass of BAT detected on 18 Drubach LA, Palmer EL, Connolly LP, Baker A, Zurakowski D, Cypess AM. Pediatric brown adipose tissue: detection, epidemiology, and differences from adults. J Pediatr 2011; 159: 939-44; PMID:21839465; http://dx.doi.org/10.1016/j.jpeds.2011.06.028 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] F-FDG PET-CT scans decreases with increasing outdoor temperature, age and BMI, as well as being lower in men and in people with diabetes. 14 Ouellet V, Routhier-Labadie A, Bellemare W, Lakhal-Chaieb L, Turcotte E, Carpentier AC, Richard D. Outdoor temperature, age, sex, body mass index, an diabetic status determine the prevalence, mass and glucose-uptake activity of 18F-FDG-detected BAT in humans. J Clin Endocrinol Metab 2011; 96: 192-9; PMID:20943785; http://dx.doi.org/10.1210/jc.2010-0989 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] Although lower BMIs are associated with a higher prevalence of active BAT, none of the 14 people with anorexia nervosa (BMI 15.3±0.8 in those with ongoing reduced calorie intake and BMI 18.8±1.1 in those who had been re-fed) imaged with 18 Drubach LA, Palmer EL, Connolly LP, Baker A, Zurakowski D, Cypess AM. Pediatric brown adipose tissue: detection, epidemiology, and differences from adults. J Pediatr 2011; 159: 939-44; PMID:21839465; http://dx.doi.org/10.1016/j.jpeds.2011.06.028 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] F-FDG PET-CT in winter had increased uptake in BAT, but all of the 7 constitutionally lean people (BMI 16.2±0.9) had increased uptake in BAT. 15 Pasanisi F, Pace L, Fonti R, Marra M, Sgambati D, De Caprio C, De Filippo E, Vaccaro A, Salvatore M, Contaldo F. Evidence of brown fat activity in constitutional leanness. J Clin Endocrinol Metab 2013; 98: 1214-8; PMID:23393181; http://dx.doi.org/10.1210/jc.2012-2981 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] Therefore a low BMI does not necessarily predict the presence of active BAT, and chronic starvation in anorexia may reduce BAT activity.\nSome authors have investigated whether ethnicity influences BAT activity. A retrospective study of 386 scans did not reveal any differences in BAT uptake between Caucasians and Black Africans. 13 Perkins AC, Mshelia DS, Symonds ME, Sathekge M. Prevalence and pattern of brown adipose tissue distribution of 18F-FDG in patients undergoing PET-CT in subtropical climatic zone. Nucl Med Commun 2013; 34: 168-74; PMID:23196673; http://dx.doi.org/10.1097/MNM.0b013e32835bbbf0 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] Cold-stimulated BAT activity was found to be similar in Caucasians (n = 10) and South Asians (n = 10). 16 Admiraal WM, Verberne HJ, Karamat FA, Soeters MR, Hoekstra JBL, Holleman F. Cold-induced activity of brown adipose tissue in young lean men of South-Asian and European origin. Diabetologia 2013; 56: 2231-37; http://dx.doi.org/10.1007/s00125-013-2938-5 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] In another study, although cold-induced BAT activity was similar between age- and BMI-matched male Caucasians (n = 11) and South Asians (n = 12), the volume of activated BAT was significantly lower in South Asians. 17 Bakker LE, Boon MR, van der Linden RA, Arias-Bouda LP, van Klinken JB, Smit F, Verberne HJ, Jukema JW, Tamsma JT, Havekes LM, et al. Brown adipose tissue volume in healthy lean south Asian adults compared with white Caucasians: a prospective, case-controlled observational study. Lancet Diabetes Endocrinol 2014; 2: 210-7; PMID:24622751; http://dx.doi.org/10.1016/S2213-8587(13)70156-6 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] Additionally, cold-induced/non-shivering thermogenesis increased in Caucasians by 20% but did not increase in South Asians exposed to the same conditions. 17 Bakker LE, Boon MR, van der Linden RA, Arias-Bouda LP, van Klinken JB, Smit F, Verberne HJ, Jukema JW, Tamsma JT, Havekes LM, et al. Brown adipose tissue volume in healthy lean south Asian adults compared with white Caucasians: a prospective, case-controlled observational study. Lancet Diabetes Endocrinol 2014; 2: 210-7; PMID:24622751; http://dx.doi.org/10.1016/S2213-8587(13)70156-6 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] Larger studies are required to determine whether ethnic differences in BAT activity exist, and whether there are any correlations between BAT activity/thermogenesis and metabolic phenotypes between different ethnicities.\nIn children, the reported prevalence of active BAT in one retrospective review of 385 PET-CT scans performed on oncology patients aged 5-21 y was similar for boys (43.3%) and girls (45.3%), with peak activity seen in the 13–15 age group. 18 Drubach LA, Palmer EL, Connolly LP, Baker A, Zurakowski D, Cypess AM. Pediatric brown adipose tissue: detection, epidemiology, and differences from adults. J Pediatr 2011; 159: 939-44; PMID:21839465; http://dx.doi.org/10.1016/j.jpeds.2011.06.028 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] Similarly to adults, BAT activity was inversely correlated with BMI, but in contrast to adults there was no correlation between BAT activity and outdoor temperature. 18 Drubach LA, Palmer EL, Connolly LP, Baker A, Zurakowski D, Cypess AM. Pediatric brown adipose tissue: detection, epidemiology, and differences from adults. J Pediatr 2011; 159: 939-44; PMID:21839465; http://dx.doi.org/10.1016/j.jpeds.2011.06.028 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] However, in another study of scans performed during winter on people aged less than 21 years, 18 Drubach LA, Palmer EL, Connolly LP, Baker A, Zurakowski D, Cypess AM. Pediatric brown adipose tissue: detection, epidemiology, and differences from adults. J Pediatr 2011; 159: 939-44; PMID:21839465; http://dx.doi.org/10.1016/j.jpeds.2011.06.028 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] F-FDG uptake was reduced from 31% to 5% by maintaining the room temperature where the subjects were placed at 24°C from 30 mins pre-tracer injection to 1-hour post-injection. 19 Zukotynski KA, Fahey FH, Laffin S, Davis R, Treves ST, Grant FD, Drubach LA. Constant ambient temperature of 24°C significantly reduces FDG uptake by brown adipose tissue in children scanned during the winter. Eur J Nucl Med Mol Imaging 2009; 36: 602-6; PMID:19037639; http://dx.doi.org/10.1007/s00259-008-0983-y [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar]\nThe absence of increased 18 Drubach LA, Palmer EL, Connolly LP, Baker A, Zurakowski D, Cypess AM. Pediatric brown adipose tissue: detection, epidemiology, and differences from adults. J Pediatr 2011; 159: 939-44; PMID:21839465; http://dx.doi.org/10.1016/j.jpeds.2011.06.028 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] F-FDG uptake may not necessarily mean that BAT is absent. In a prospective study of 17 people with preoperative PET-CT staging scans who had head and neck surgery, 3/17 (17.6%) had BAT detected by 18 Drubach LA, Palmer EL, Connolly LP, Baker A, Zurakowski D, Cypess AM. Pediatric brown adipose tissue: detection, epidemiology, and differences from adults. J Pediatr 2011; 159: 939-44; PMID:21839465; http://dx.doi.org/10.1016/j.jpeds.2011.06.028 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] F-FDG with histological confirmation of BAT in regions corresponding to increased 18 Drubach LA, Palmer EL, Connolly LP, Baker A, Zurakowski D, Cypess AM. Pediatric brown adipose tissue: detection, epidemiology, and differences from adults. J Pediatr 2011; 159: 939-44; PMID:21839465; http://dx.doi.org/10.1016/j.jpeds.2011.06.028 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] F-FDG uptake. However, histological analysis of the supraclavicular fat in the other 14 subjects who did not have increased 18 Drubach LA, Palmer EL, Connolly LP, Baker A, Zurakowski D, Cypess AM. Pediatric brown adipose tissue: detection, epidemiology, and differences from adults. J Pediatr 2011; 159: 939-44; PMID:21839465; http://dx.doi.org/10.1016/j.jpeds.2011.06.028 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] F-FDG uptake on PET-CT revealed a mixture of adipocytes indistinguishable from white/subcutaneous fat and islands of adipocytes which contained multilobulated lipid droplets and expressed UCP1 (i.e. brown fat cells). 20 Lee P, Zhao JT, Swarbrick MM, Gracie G, Bova R, Greenfield JR, Freund J, Ho KKY. High prevalence of brown adipose tissue in adult humans. J Clin Endocrinol Metab 2011; 96: 2450-5; PMID:21613352; http://dx.doi.org/10.1210/jc.2011-0487 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] It is feasible that in some subjects, islands of brown fat exist that are metabolically active but are below the spatial resolution threshold required for detection by the scanner.\nTherefore the prevalence of active BAT as detected by 18 Drubach LA, Palmer EL, Connolly LP, Baker A, Zurakowski D, Cypess AM. Pediatric brown adipose tissue: detection, epidemiology, and differences from adults. J Pediatr 2011; 159: 939-44; PMID:21839465; http://dx.doi.org/10.1016/j.jpeds.2011.06.028 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] F-FDG PET-CT ranges from 3 to 100% ( Table 1 ) depending on the cohort studied, season, outdoor/indoor temperature and the nature of the study (retrospective review of scans vs. interventional study), and BAT may be present even though it is not detected by 18 Drubach LA, Palmer EL, Connolly LP, Baker A, Zurakowski D, Cypess AM. Pediatric brown adipose tissue: detection, epidemiology, and differences from adults. J Pediatr 2011; 159: 939-44; PMID:21839465; http://dx.doi.org/10.1016/j.jpeds.2011.06.028 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] F-FDG PET-CT. Additionally, there may be a diurnal or meal-related variation in 18 Drubach LA, Palmer EL, Connolly LP, Baker A, Zurakowski D, Cypess AM. Pediatric brown adipose tissue: detection, epidemiology, and differences from adults. J Pediatr 2011; 159: 939-44; PMID:21839465; http://dx.doi.org/10.1016/j.jpeds.2011.06.028 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] F-FDG uptake by BAT since in mice, 18 Drubach LA, Palmer EL, Connolly LP, Baker A, Zurakowski D, Cypess AM. Pediatric brown adipose tissue: detection, epidemiology, and differences from adults. J Pediatr 2011; 159: 939-44; PMID:21839465; http://dx.doi.org/10.1016/j.jpeds.2011.06.028 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] F-FDG uptake by BAT was found to peak 9 hours into the light phase (i.e., when mice are less active) of a 12-hour light/12-hour dark day. 31 van der Veen DR, Shao J, Chapman S, Leevy WM, Duffield GE. A diurnal rhythm in glucose uptake in brown adipose tissue revealed by in vivo PET-FDG imaging. Obesity (Silver Spring) 2012; 20: 1527-9; PMID:22447290; http://dx.doi.org/10.1038/oby.2012.78 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar]\nInsights into Brown Adipose Tissue Physiology as Revealed by Imaging Studies\nAll authors\nCSV Display Table\nThe use of PET-CT has facilitated the identification and study of various stimulators and inhibitors of BAT activity, which are summarised in Figure 1 . Cold exposure is the best known stimulator of BAT activity, and several 18 Drubach LA, Palmer EL, Connolly LP, Baker A, Zurakowski D, Cypess AM. Pediatric brown adipose tissue: detection, epidemiology, and differences from adults. J Pediatr 2011; 159: 939-44; PMID:21839465; http://dx.doi.org/10.1016/j.jpeds.2011.06.028 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] F-FDG PET-CT studies in humans using acute and/or chronic cold exposure are summarized in Table 1 . The issue of whether cold-activated BAT actually results in significantly increased energy expenditure in humans has been addressed by several studies. In a randomized single-blind crossover study, 25 Chen KY, Brychta RJ, Linderman JD, Smith S, Courville A, Dieckmann W, Herscovitch P, Millo CM, Remaley A, Lee P, et al. Brown fat activation mediates cold-induced thermogenesis in adult humans in response to a mild decrease in ambient temperature. J Clin Endocrinol Metab 2013; 98: E1218-23; PMID:23780370; http://dx.doi.org/10.1210/jc.2012-4213 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] 24 participants (14 male and 10 female, mean age 28 years) spent 12 hours in a whole-room indirect calorimeter maintained at 24°C or 19°C after which a PET-CT scan was performed. Thirty-six hours later the participants crossed over to the alternate study temperature followed by a second scan. During the study the participants received an individualized calorie-calculated caffeine-free diet consisting of 50% carbohydrate, 20% protein and 20% fat, wore hospital scrubs, slept with cotton sheets (and without blankets), and care was taken to ensure the participants did not shiver. This study demonstrated that cold-activated BAT results in a 5% increase in energy expenditure (with higher increases in energy expenditure in women and an inverse relationship between age and increased energy expenditure). 25 Chen KY, Brychta RJ, Linderman JD, Smith S, Courville A, Dieckmann W, Herscovitch P, Millo CM, Remaley A, Lee P, et al. Brown fat activation mediates cold-induced thermogenesis in adult humans in response to a mild decrease in ambient temperature. J Clin Endocrinol Metab 2013; 98: E1218-23; PMID:23780370; http://dx.doi.org/10.1210/jc.2012-4213 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] Other studies have demonstrated a mean increase in energy expenditure of 3.1 kcal/day after cold exposure (15.5°C for 1 hour) in adults with a mean age of 29.6 years, 26 Muzik O, Manger TJ, Leonard WR, Kumar A, Janisse J, Granneman JG. 15O PET measurement of blood flow and oxygen consumption in cold-activated human brown fat. J Nucl Med 2013; 54: 523-31; PMID:23362317; http://dx.doi.org/10.2967/jnumed.112.111336 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] and 250 kcal/day (after exposure to 19°C for 2 hours) in healthy young men with a mean age of 24.4 y 22 Yoneshiro T, Aita S, Matsushita M, Kameya T, Nakada K, Kawai Y, Saito M. Brown adipose tissue, whole-body energy expenditure, and thermogenesis in healthy adult men. Obesity 2011; 19: 13-6; PMID:20448535; http://dx.doi.org/10.1038/oby.2010.105 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] Also in the latter study, chronic cold exposure (17°C for 2 hours a day for 6 weeks) in subjects with absent or low 18 Drubach LA, Palmer EL, Connolly LP, Baker A, Zurakowski D, Cypess AM. Pediatric brown adipose tissue: detection, epidemiology, and differences from adults. J Pediatr 2011; 159: 939-44; PMID:21839465; http://dx.doi.org/10.1016/j.jpeds.2011.06.028 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] F-FDG uptake on baseline PET scanning resulted in increased 18 Drubach LA, Palmer EL, Connolly LP, Baker A, Zurakowski D, Cypess AM. Pediatric brown adipose tissue: detection, epidemiology, and differences from adults. J Pediatr 2011; 159: 939-44; PMID:21839465; http://dx.doi.org/10.1016/j.jpeds.2011.06.028 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] F-FDG uptake and increased energy expenditure at week 6. 22 Yoneshiro T, Aita S, Matsushita M, Kameya T, Nakada K, Kawai Y, Saito M. Brown adipose tissue, whole-body energy expenditure, and thermogenesis in healthy adult men. Obesity 2011; 19: 13-6; PMID:20448535; http://dx.doi.org/10.1038/oby.2010.105 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] In a different study, chronic cold exposure (10°C for 2 hours per day for 4 weeks) increased BAT volume by 45%, as well increased BAT oxidative metabolism and fractional glucose uptake. 30 Blondin DP, Labbe SM, Tingelstad HC, Noll C, Kunach M, Phoneix S, Guerin B, Turcotte EE, Carpentier AC, Richard D, et al. Increased brown adipose tissue oxidative capacity in cold-acclimated humans. J Clin Endocrinol Metab 2014; 99: E438-46; PMID:24423363 [PubMed] , [Web of Science ®]   [Google Scholar] These studies have demonstrated that BAT in adult humans can be activated (and recruited) resulting in significant increases in energy expenditure and metabolic activity, which can potentially be exploited to develop agents to treat obesity.\nInsights into Brown Adipose Tissue Physiology as Revealed by Imaging Studies\nAll authors\nPublished online:\n28 October 2014\nFigure 1 : Inhibitors and stimulators of brown adipose tissue activation identified by PET-CT studies. Warm temperatures, β-adrenoceptor antagonists, reserpine, fentanyl, inhaled anesthetics and obesity inhibit (- - -) brown adipose tissue thermogenesis. Cold temperatures, catecholamines, the sympathetic nervous system, β-adrenoceptor agoinists, nicotine, insulin and thyroid hormone stimulate ( ) brown adipose tissue.\nDisplay full size\nFigure 1 : Inhibitors and stimulators of brown adipose tissue activation identified by PET-CT studies. Warm temperatures, β-adrenoceptor antagonists, reserpine, fentanyl, inhaled anesthetics and obesity inhibit (- - -) brown adipose tissue thermogenesis. Cold temperatures, catecholamines, the sympathetic nervous system, β-adrenoceptor agoinists, nicotine, insulin and thyroid hormone stimulate ( ) brown adipose tissue.\n18 Drubach LA, Palmer EL, Connolly LP, Baker A, Zurakowski D, Cypess AM. Pediatric brown adipose tissue: detection, epidemiology, and differences from adults. J Pediatr 2011; 159: 939-44; PMID:21839465; http://dx.doi.org/10.1016/j.jpeds.2011.06.028 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] F-FDG imaging has also provided useful information about the pharmacological regulation of BAT activation. An ex-vivo rodent study demonstrated that 18 Drubach LA, Palmer EL, Connolly LP, Baker A, Zurakowski D, Cypess AM. Pediatric brown adipose tissue: detection, epidemiology, and differences from adults. J Pediatr 2011; 159: 939-44; PMID:21839465; http://dx.doi.org/10.1016/j.jpeds.2011.06.028 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] F-FDG uptake in BAT is increased 7.9-fold by nicotine, 3.7-fold by ephedrine, 12-fold by a combination of nicotine and ephedrine, and slightly but non-significantly by caffeine. 32 Baba S, Tatsumi M, Ishimori T, Lilien DL, Engles JM, Wahl RL. Effect of nicotine and ephedrine on the accumulation of 18F-FDG in brown adipose tissue. J Nucl Med 2007; 48: 981-6; PMID:17504863; http://dx.doi.org/10.2967/jnumed.106.039065 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] The increased 18 Drubach LA, Palmer EL, Connolly LP, Baker A, Zurakowski D, Cypess AM. Pediatric brown adipose tissue: detection, epidemiology, and differences from adults. J Pediatr 2011; 159: 939-44; PMID:21839465; http://dx.doi.org/10.1016/j.jpeds.2011.06.028 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] F-FDG uptake caused by nicotine administration is prevented by prior administration of propranolol or reserpine. 32 Baba S, Tatsumi M, Ishimori T, Lilien DL, Engles JM, Wahl RL. Effect of nicotine and ephedrine on the accumulation of 18F-FDG in brown adipose tissue. J Nucl Med 2007; 48: 981-6; PMID:17504863; http://dx.doi.org/10.2967/jnumed.106.039065 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] Cold-induced 18 Drubach LA, Palmer EL, Connolly LP, Baker A, Zurakowski D, Cypess AM. Pediatric brown adipose tissue: detection, epidemiology, and differences from adults. J Pediatr 2011; 159: 939-44; PMID:21839465; http://dx.doi.org/10.1016/j.jpeds.2011.06.028 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] F-FDG uptake is inhibited by both propranolol and reserpine in rodents, with diazepam having little or no effect. 33 Tatsumi M, Engles JM, Ishimori T, Nicely O’B, Cohade C, Wahl RL. Intense 18F-FDG uptake in brown fat can be reduced pharmacologically. J Nucl Med 2004; 45: 1189-93; PMID:15235065 [PubMed] , [Web of Science ®]   [Google Scholar] This data suggests that the effects of nicotine and cold on BAT activity are mediated by the sympathetic nervous system. Similarly, in humans, 18 Drubach LA, Palmer EL, Connolly LP, Baker A, Zurakowski D, Cypess AM. Pediatric brown adipose tissue: detection, epidemiology, and differences from adults. J Pediatr 2011; 159: 939-44; PMID:21839465; http://dx.doi.org/10.1016/j.jpeds.2011.06.028 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] F-FDG uptake by BAT can be reduced by intravenous fentanyl 34 Gelfand MJ, O’Hara SM, Curtwright LA, MacLean JR. Pre-medication to block [18F]FDG uptake in the brown adipose tissue of pediatric and adolescent patients. Pediatr Radiol 2005; 35: 984-90; PMID:15988582; http://dx.doi.org/10.1007/s00247-005-1505-8 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] and oral propranolol, 35,36 Parysow O, Mollerach AM, Jager V, Racioppi S, Roman JS, Gerbaudo VH. Oral propranolol could reduce brown adipose tissue F-18 FDG uptake in patients undergoing PET scans. Clin Nucl Med 2007; 32: 351-7; PMID:17452860; http://dx.doi.org/10.1097/01.rlu.0000259570.69163.04\nSoderlund V, Larsson SA, Jacobsson H. Reduction of FDG uptake in brown adipose tissue in clinical patients by a single dose of propranolol. Eur J Nucl Med Mol Imaging 2007; 34: 1018-22; PMID:17225118; http://dx.doi.org/10.1007/s00259-006-0318-9  but it is not significantly affected by diazepam. 34 Gelfand MJ, O’Hara SM, Curtwright LA, MacLean JR. Pre-medication to block [18F]FDG uptake in the brown adipose tissue of pediatric and adolescent patients. Pediatr Radiol 2005; 35: 984-90; PMID:15988582; http://dx.doi.org/10.1007/s00247-005-1505-8 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar]\nThe crucial role that the sympathetic nervous system plays in BAT activation may be utilized therapeutically. Atomoxetine (a potent highly selective inhibitor of presynaptic norepinephrine transport that increases synaptic concentrations of norepinephrine) increased 18 Drubach LA, Palmer EL, Connolly LP, Baker A, Zurakowski D, Cypess AM. Pediatric brown adipose tissue: detection, epidemiology, and differences from adults. J Pediatr 2011; 159: 939-44; PMID:21839465; http://dx.doi.org/10.1016/j.jpeds.2011.06.028 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] F-FDG uptake by BAT at ambient temperatures in fasted and non-fasted rats with corresponding decreases in blood glucose levels and increases in interscapular BAT temperature compared to controls. 37 Mirbolooki MR, Constantinescu CC, Pan M-L, Mukherjee J. Targeting presynaptic norepinephrine transporter in brown adipose tissue: a novel imaging approach and potential treatment for diabetes and obesity. Synapse 2013; 67: 79-93; PMID:23080264; http://dx.doi.org/10.1002/syn.21617 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] Additionally, it is important to be aware that inhaled anesthetics (including halothane, isoflurane and chloroform) have been shown to directly inhibit norepinephrine-induced BAT activation in cultured cells and in in vivo experiments. 38–40 Ohlson KB, Mohell N, Cannon B, Nedegaard J. Thermogenesis in brown adipocytes is inhibited by volatile anesthetic agents. A factor contributing to hypothermia in infants? Anesthesiology 1994; 81: 176-83; PMID:8042786; http://dx.doi.org/10.1097/00000542-199407000-00024\nDicker A, Ohlson KB, Johnson L, Cannon B, Nedegaard J. Halothane selectively inhibits nonshivering thermogenesis. Possible implications for thermoregulation during anesthesia of infants. Anesthesiology 1995; 82: 491-501; PMID:7856907; http://dx.doi.org/10.1097/00000542-199502000-00019\nOhlson KB, Lindahl SG, Cannon B, Nedergaard J. Thermogenesis inhibition in brown adipocytes is a specific property of volatile anesthetics. Anethesiology 2003; 98: 437-48; http://dx.doi.org/10.1097/00000542-200302000-00025 \nBAT is richly innervated by the sympathetic nervous system and norepinephrine increases glucose transport in brown adipocytes and increases the numbers of brown adipocytes. 41,42 Cannon B, Nedegaard J. Brown adipose tissue: function and physiological significance. Physiol Rev 2004; 84: 277-359; PMID:14715917; http://dx.doi.org/10.1152/physrev.00015.2003\nChernogubova E, Cannon B, Bengtsson T. Norepienphrine increases glucose transport in brown adipocytes via beta 3-adrenoreceptors through a cAMP, PKA, and PI3-kinase-dependent pathway stimulating conventional and novel PKCs. Endocrinology 2004; 145: 269-80; PMID:14551227; http://dx.doi.org/10.1210/en.2003-0857  Therefore conditions in which circulating catecholamine levels are chronically elevated (such as in patients with phaeochromocytomas) provide natural experiments for the study of BAT. Case reports have demonstrated greatly increased (non-cold stimulated) 18 Drubach LA, Palmer EL, Connolly LP, Baker A, Zurakowski D, Cypess AM. Pediatric brown adipose tissue: detection, epidemiology, and differences from adults. J Pediatr 2011; 159: 939-44; PMID:21839465; http://dx.doi.org/10.1016/j.jpeds.2011.06.028 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] F-FDG uptake in cervical, axillary, mediastinal, abdominal (including omental and mesenteric), paravertebral, and perirenal fat depots of patients with phaeochromocytomas and concomitantly increased catecholamines/metanephrines, 43–49 Kuji I, Imabayashi E, Minagawa A, Matsuda H, Miyauchi T. Brown adipose tissue demonstrating intense FDG uptake in a patient with mediastinal pheochromocytoma. Ann Nucl Med 2008; 22: 231-5; PMID:18498040; http://dx.doi.org/10.1007/s12149-007-0096-x\nYamaga LY, Thom AF, Wagner J, Baroni RH, Hidal JT, Funari MG. The effect of catecholamines on the glucose uptake in brown adipose tissue demonstrated by 18F-FDG PET/CT in a patient with adrenal pheochromocytoma. Eur J Nucl Med Mol Imaging 2008; 35: 446-667; PMID:17909796; http://dx.doi.org/10.1007/s00259-007-0538-7\nIyer RB, Guo CC, Perrier N. Adrenal pheochromocytoma with surrounding brown fat stimulation. Am J Roent 2009; 192: 300-1; http://dx.doi.org/10.2214/AJR.08.1166\nSekizawa N, Yoshimoto T, Izumiyama H, Hirata Y. Distinct uptake of 18F-fluorodeoxyglucose by brown adipose tissue with a catecholamine-secreting tumor. Inter Med 2010; 49: 2363; http://dx.doi.org/10.2169/internalmedicine.49.4293\nCheng W, Zhu Z, Jin X, Chen L, Zhuang H, Li F. Intense FDG activity in the brown adipose tissue in omental and mesenteric regions in a patient with malignant pheochromocytoma. Clin Nucl Med 2012; 37: 514-5; PMID:22475909; http://dx.doi.org/10.1097/RLU.0b013e31824d2121\nJoshi PV, Lele VR. Unexpected visitor on FDG PET/CT-Brown adipose tissue (BAT) in mesentery in a case of retroperitoneal extra-adrenal pheochromocytoma. Clin Nucl Med 2012; 37: e119-20; PMID:22475922; http://dx.doi.org/10.1097/RLU.0b013e31824437e7\nDong A, Wang Y, Lu J, Zuo C. Hypermetabolic mesenteric brown adipose tissue on dual-time point FDG PET/CT in a patient with benign retroperitoneal pheochromocytoma. Clin Nucl Med 2014; 39: e229-32; PMID:23455523; http://dx.doi.org/10.1097/RLU.0b013e3182816515  and surgical resection of the phaeochromocytomas with restoration of normal circulating catecholamine levels 43,46 Kuji I, Imabayashi E, Minagawa A, Matsuda H, Miyauchi T. Brown adipose tissue demonstrating intense FDG uptake in a patient with mediastinal pheochromocytoma. Ann Nucl Med 2008; 22: 231-5; PMID:18498040; http://dx.doi.org/10.1007/s12149-007-0096-x\nSekizawa N, Yoshimoto T, Izumiyama H, Hirata Y. Distinct uptake of 18F-fluorodeoxyglucose by brown adipose tissue with a catecholamine-secreting tumor. Inter Med 2010; 49: 2363; http://dx.doi.org/10.2169/internalmedicine.49.4293  or propranolol administration 47 Cheng W, Zhu Z, Jin X, Chen L, Zhuang H, Li F. Intense FDG activity in the brown adipose tissue in omental and mesenteric regions in a patient with malignant pheochromocytoma. Clin Nucl Med 2012; 37: 514-5; PMID:22475909; http://dx.doi.org/10.1097/RLU.0b013e31824d2121 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] abolished the increased uptake in these regions. In patients with phaeochromocytomas whose total plasma metanephrines were not elevated, BAT uptake of 18 Drubach LA, Palmer EL, Connolly LP, Baker A, Zurakowski D, Cypess AM. Pediatric brown adipose tissue: detection, epidemiology, and differences from adults. J Pediatr 2011; 159: 939-44; PMID:21839465; http://dx.doi.org/10.1016/j.jpeds.2011.06.028 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] F-FDG was not increased. Instead it was the same as the uptake seen in normal (non-phaeochromocytoma) controls. 50 Wang Q, Zhang M, Ning G, Gu W, Su T, Xu M, Li B, Wang W. Brown adipose tissue in humans is activated by elevated plasma catecholamine levels and is inversely related to central obesity. PLoS One 2011; 6: e21006. DOI: 10.1371; PMID:21701596; http://dx.doi.org/10.1371/journal.pone.0021006 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] Additionally in this study (which also included phaeochromocytoma patients with elevated total plasma metanephrine levels) BAT activity was inversely correlated with BMI and waist circumference, and positively correlated with total plasma metanephrine levels. 50 Wang Q, Zhang M, Ning G, Gu W, Su T, Xu M, Li B, Wang W. Brown adipose tissue in humans is activated by elevated plasma catecholamine levels and is inversely related to central obesity. PLoS One 2011; 6: e21006. DOI: 10.1371; PMID:21701596; http://dx.doi.org/10.1371/journal.pone.0021006 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar]\nHistological analysis of intra-abdominal fat obtained from 3 patients with phaeochromocytomas with high circulating catecholamine levels revealed that this fat possessed all the unique features of thermogenically active brown adipose tissue. 51 Lean ME, James WP, Jennings G, Trayhurn P. Brown adipose tissue in patients with phaeochromocytoma. Int J Obes 1986; 10: 219-27; PMID:3019909 [PubMed] , [Web of Science ®]   [Google Scholar] In a more recent study in which the omental fat from 12 patients with phaeochromocytoma was analyzed, UCP1-immunoreactivity (UCP1-ir) positive multilocular cells were present in samples from 6 patients and islands of BAT were identified within WAT from 4 of these 6 patients. 52 Frontini A, Vitali A, Perugini J, Murano I, Romiti C, Ricquier D, Guerrieri M, Cinti S. White-to-brown transdifferentiaition of omental adipocytes in patients affected by pheochromocytoma. Biochim Biophys Acta 2013; 1831: 950-9; PMID:23454374; http://dx.doi.org/10.1016/j.bbalip.2013.02.005 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] In contrast, none of the samples from 20 non-phaeochromocytoma patients who underwent cholecystectomy were UCP1-ir positive. 52 Frontini A, Vitali A, Perugini J, Murano I, Romiti C, Ricquier D, Guerrieri M, Cinti S. White-to-brown transdifferentiaition of omental adipocytes in patients affected by pheochromocytoma. Biochim Biophys Acta 2013; 1831: 950-9; PMID:23454374; http://dx.doi.org/10.1016/j.bbalip.2013.02.005 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] Therefore evidence from imaging case reports and histological studies indicate that chronic catecholamine excess increases BAT activity and may promote transdifferentiation of WAT to BAT.\nOther tracers\n15 Pasanisi F, Pace L, Fonti R, Marra M, Sgambati D, De Caprio C, De Filippo E, Vaccaro A, Salvatore M, Contaldo F. Evidence of brown fat activity in constitutional leanness. J Clin Endocrinol Metab 2013; 98: 1214-8; PMID:23393181; http://dx.doi.org/10.1210/jc.2012-2981 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] O-H2O (radiolabelled water) has been used as a tracer in PET-CT scans to detect and quantify the perfusion of BAT. The oxygen consumption of a tissue is matched by the perfusion rate of the tissue, therefore perfusion rate can be used as an approximation of oxygen consumption. 53 Segal SS. Regulation of blood flow in the microcirculation. Microcirculation 2005; 12: 33-45; PMID:15804972; http://dx.doi.org/10.1080/10739680590895028 [Taylor & Francis Online] , [Web of Science ®]   [Google Scholar] A study in which PET-CT scans performed in the same individuals using both 15 Pasanisi F, Pace L, Fonti R, Marra M, Sgambati D, De Caprio C, De Filippo E, Vaccaro A, Salvatore M, Contaldo F. Evidence of brown fat activity in constitutional leanness. J Clin Endocrinol Metab 2013; 98: 1214-8; PMID:23393181; http://dx.doi.org/10.1210/jc.2012-2981 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] O-H2O and 18 Drubach LA, Palmer EL, Connolly LP, Baker A, Zurakowski D, Cypess AM. Pediatric brown adipose tissue: detection, epidemiology, and differences from adults. J Pediatr 2011; 159: 939-44; PMID:21839465; http://dx.doi.org/10.1016/j.jpeds.2011.06.028 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] F-FDG as tracers demonstrated that in response to cold exposure both the perfusion and glucose uptake of BAT increased. 21 Orava J, Nuutila P, Lidell ME, Oikonen V, Noponen T, Viljanen T, Scheinin M, Taittonen M, Niemi T, Enerback S, et al. Cell Metab 2011; 14: 272-9; PMID:21803297; http://dx.doi.org/10.1016/j.cmet.2011.06.012 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] However in response to insulin infusion (with concurrent glucose infusion to maintain euglycaemia), BAT glucose uptake increased without a concomitant increase in BAT perfusion. 21 Orava J, Nuutila P, Lidell ME, Oikonen V, Noponen T, Viljanen T, Scheinin M, Taittonen M, Niemi T, Enerback S, et al. Cell Metab 2011; 14: 272-9; PMID:21803297; http://dx.doi.org/10.1016/j.cmet.2011.06.012 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] Glucose enters brown adipocytes via GLUT1 (an insulin-independent glucose transporter) and GLUT4 (an insulin-regulated glucose transporter). So the insulin-mediated increase in 18 Drubach LA, Palmer EL, Connolly LP, Baker A, Zurakowski D, Cypess AM. Pediatric brown adipose tissue: detection, epidemiology, and differences from adults. J Pediatr 2011; 159: 939-44; PMID:21839465; http://dx.doi.org/10.1016/j.jpeds.2011.06.028 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] F-FDG uptake by BAT does not appear to be accompanied by increased oxidation in BAT, and may represent increased glucose transport due to higher insulin concentrations during an insulin infusion. In a different study using these 2 tracers, hyperthyroidism increased glucose uptake in BAT (and muscle, but not in WAT) with increased lipid oxidation and whole body energy expenditure, but BAT perfusion was not increased (unlike muscle which had increased perfusion). 54 Lahesmaa M, Orava J, Schalin-Jantti C, Soinio M, Hannukainen JC, Noponen T, Kirjavainen A, Iida H, Kudomi N, Enerback S, et al. Hyperthyroidism increases brown fat metabolism in humans. J Clin Endocrinol Metab 2014; 99: E28-35; PMID:24152690; http://dx.doi.org/10.1210/jc.2013-2312 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] These changes were reversed by restoration of euthyroidism. 54 Lahesmaa M, Orava J, Schalin-Jantti C, Soinio M, Hannukainen JC, Noponen T, Kirjavainen A, Iida H, Kudomi N, Enerback S, et al. Hyperthyroidism increases brown fat metabolism in humans. J Clin Endocrinol Metab 2014; 99: E28-35; PMID:24152690; http://dx.doi.org/10.1210/jc.2013-2312 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] Therefore increased 18 Drubach LA, Palmer EL, Connolly LP, Baker A, Zurakowski D, Cypess AM. Pediatric brown adipose tissue: detection, epidemiology, and differences from adults. J Pediatr 2011; 159: 939-44; PMID:21839465; http://dx.doi.org/10.1016/j.jpeds.2011.06.028 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] F-FDG uptake by BAT in PET scans provides limited information about the metabolic activity of BAT.\nAnother PET-CT tracer that has been used to study BAT is 11C-meta-hydroxyephedrine ( 11 van Marken Lichtenbelt W, Vanhommergig JW, Smulders NM, Drossaerts JM, Kemerink GJ, Bouvy ND, Schrauwen P, Jaap Teule GJ. Cold-activated brown adipose tissue in healthy men. N Eng J Med 2009; 360: 1500-8; http://dx.doi.org/10.1056/NEJMoa0808718 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] C-MHED). 11 van Marken Lichtenbelt W, Vanhommergig JW, Smulders NM, Drossaerts JM, Kemerink GJ, Bouvy ND, Schrauwen P, Jaap Teule GJ. Cold-activated brown adipose tissue in healthy men. N Eng J Med 2009; 360: 1500-8; http://dx.doi.org/10.1056/NEJMoa0808718 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] C-MHED is a radioactive analog of norepinephrine, which emits positrons as it decays. 11 van Marken Lichtenbelt W, Vanhommergig JW, Smulders NM, Drossaerts JM, Kemerink GJ, Bouvy ND, Schrauwen P, Jaap Teule GJ. Cold-activated brown adipose tissue in healthy men. N Eng J Med 2009; 360: 1500-8; http://dx.doi.org/10.1056/NEJMoa0808718 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] C-MHED uptake by BAT was higher in mice kept at an ambient temperature of 21°C compared with mice kept at 26°C. 55 Quarta C, Lodi F, Mazza R, Giannone F, Boschi L, Nanni C, Nisoli E, Boschi S, Pasquali R, Fanti S, et al. 11C-meta-hydroxyephedrine PET/CT imaging allows in vivo study of adaptive thermogenesis and white-to-brown fat conversion. Mol Metab 2013; 2: 153-60; PMID:24049730; http://dx.doi.org/10.1016/j.molmet.2013.04.002 [Crossref] , [PubMed]   [Google Scholar] No 11 van Marken Lichtenbelt W, Vanhommergig JW, Smulders NM, Drossaerts JM, Kemerink GJ, Bouvy ND, Schrauwen P, Jaap Teule GJ. Cold-activated brown adipose tissue in healthy men. N Eng J Med 2009; 360: 1500-8; http://dx.doi.org/10.1056/NEJMoa0808718 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] C-MHED uptake was seen in denervated BAT and increased 11 van Marken Lichtenbelt W, Vanhommergig JW, Smulders NM, Drossaerts JM, Kemerink GJ, Bouvy ND, Schrauwen P, Jaap Teule GJ. Cold-activated brown adipose tissue in healthy men. N Eng J Med 2009; 360: 1500-8; http://dx.doi.org/10.1056/NEJMoa0808718 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] C-MHED uptake in sham-operated BAT was blocked by SR59230A (a selective β3-adrenoreceptor antagonist). 55 Quarta C, Lodi F, Mazza R, Giannone F, Boschi L, Nanni C, Nisoli E, Boschi S, Pasquali R, Fanti S, et al. 11C-meta-hydroxyephedrine PET/CT imaging allows in vivo study of adaptive thermogenesis and white-to-brown fat conversion. Mol Metab 2013; 2: 153-60; PMID:24049730; http://dx.doi.org/10.1016/j.molmet.2013.04.002 [Crossref] , [PubMed]   [Google Scholar] Furthermore, in mice treated with 1mg/kg/day CL316,243 (a potent β3-adrenoreceptor agonist) for 4 weeks, BAT 11 van Marken Lichtenbelt W, Vanhommergig JW, Smulders NM, Drossaerts JM, Kemerink GJ, Bouvy ND, Schrauwen P, Jaap Teule GJ. Cold-activated brown adipose tissue in healthy men. N Eng J Med 2009; 360: 1500-8; http://dx.doi.org/10.1056/NEJMoa0808718 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] C-MHED uptake was 2.5 times higher than in vehicle-treated mice. 55 Quarta C, Lodi F, Mazza R, Giannone F, Boschi L, Nanni C, Nisoli E, Boschi S, Pasquali R, Fanti S, et al. 11C-meta-hydroxyephedrine PET/CT imaging allows in vivo study of adaptive thermogenesis and white-to-brown fat conversion. Mol Metab 2013; 2: 153-60; PMID:24049730; http://dx.doi.org/10.1016/j.molmet.2013.04.002 [Crossref] , [PubMed]   [Google Scholar] This provides further evidence that cold-induced BAT thermogenesis is mediated by the sympathetic nervous system.\nOther experiments performed by the same group demonstrated reduced β3-adrenoreceptor mediated 11 van Marken Lichtenbelt W, Vanhommergig JW, Smulders NM, Drossaerts JM, Kemerink GJ, Bouvy ND, Schrauwen P, Jaap Teule GJ. Cold-activated brown adipose tissue in healthy men. N Eng J Med 2009; 360: 1500-8; http://dx.doi.org/10.1056/NEJMoa0808718 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] C-MHED and 18 Drubach LA, Palmer EL, Connolly LP, Baker A, Zurakowski D, Cypess AM. Pediatric brown adipose tissue: detection, epidemiology, and differences from adults. J Pediatr 2011; 159: 939-44; PMID:21839465; http://dx.doi.org/10.1016/j.jpeds.2011.06.028 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] F-FDG uptake by BAT in mice fed a high-fat diet compared to those fed a standard chow diet. 55 Quarta C, Lodi F, Mazza R, Giannone F, Boschi L, Nanni C, Nisoli E, Boschi S, Pasquali R, Fanti S, et al. 11C-meta-hydroxyephedrine PET/CT imaging allows in vivo study of adaptive thermogenesis and white-to-brown fat conversion. Mol Metab 2013; 2: 153-60; PMID:24049730; http://dx.doi.org/10.1016/j.molmet.2013.04.002 [Crossref] , [PubMed]   [Google Scholar] Additionally, a 3-fold increase in 11 van Marken Lichtenbelt W, Vanhommergig JW, Smulders NM, Drossaerts JM, Kemerink GJ, Bouvy ND, Schrauwen P, Jaap Teule GJ. Cold-activated brown adipose tissue in healthy men. N Eng J Med 2009; 360: 1500-8; http://dx.doi.org/10.1056/NEJMoa0808718 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] C-MHED and 18 Drubach LA, Palmer EL, Connolly LP, Baker A, Zurakowski D, Cypess AM. Pediatric brown adipose tissue: detection, epidemiology, and differences from adults. J Pediatr 2011; 159: 939-44; PMID:21839465; http://dx.doi.org/10.1016/j.jpeds.2011.06.028 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] F-FDG uptake was detected in the inguinal subcutaneous white adipose tissue (WAT) depot of chow-fed mice that were treated with 1mg/kg/day CL316,243 for 4 weeks compared with vehicle-treated controls. Post-mortem histological analysis of these inguinal adipose tissue depots revealed tissue similar to BAT (i.e. clusters of multi-locular adipocytes that expressed UCP-1 and peroxisome-proliferator activated receptor γ co-activator 1 α, which are hallmarks of BAT). 55 Quarta C, Lodi F, Mazza R, Giannone F, Boschi L, Nanni C, Nisoli E, Boschi S, Pasquali R, Fanti S, et al. 11C-meta-hydroxyephedrine PET/CT imaging allows in vivo study of adaptive thermogenesis and white-to-brown fat conversion. Mol Metab 2013; 2: 153-60; PMID:24049730; http://dx.doi.org/10.1016/j.molmet.2013.04.002 [Crossref] , [PubMed]   [Google Scholar] These experiments indicate that diet-induced obesity can adversely affect BAT function and chronic β3-adrenoreceptor activation induces transformation of WAT to BAT-like tissue.\nSingle-photon emission computed tomography (SPECT) – CT (CT)\nIn SPECT a gamma camera is used to obtain multiple 2 dimensional images from multiple angles, which are used by a computer to reconstruct a 3 dimensional image. Furthermore the emissions from the radioactive ligand reveal the capillary blood flow of the imaged region, and can also provide information about metabolism within the imaged tissue. Images from a CT scan can then be co-registered with the SPECT images to provide more detailed anatomical information.\nThere have been reported cases of activated BAT identified on SPECT-CT scans using technetium sestamibi (99mTc-sestamibi) as this tracer is taken up in the same distribution as 18FFDG uptake on a PET-CT scan. 56,57 Higuchi T, Kinuya S, Taki J, Nakajima K, Ikeda M, Namura M, Tonami N. Brown adipose tissue: Evaluation with 201Tl and 99mTc-sestamibi dual-tracer SPECT. Ann Nucl Med 2004; 18: 547-9; PMID:15515758; http://dx.doi.org/10.1007/BF02984575\nBelhocine T, Shastry A, Driedger A, Urbain J-L. Detection of 99mTc-sestamibi uptake in brown adipose tissue with SPECT-CT. Eur J Nucl Med Mol Imaging 2007; 34: 149; PMID:17021807; http://dx.doi.org/10.1007/s00259-006-0244-x  Furthermore the uptake of 99mTc-sestamibi is 4 times higher in BAT than in WAT, and in rats its uptake is inversely correlated to body weight. 58 Kyparos D, Arsos G, Georga S, Petridou A, Kyparos A, Papageorgiou E, Mougios V, Matziari C, Karakatsanis C. Assessment of brown adipose tissue activity in rats by 99mTc-sestamibi uptake. Physiol Res 2006; 55: 653-9; PMID:16497107 [PubMed] , [Web of Science ®]   [Google Scholar] A retrospective review of 205 99mTc-sestamibi SPECT-CT scans performed for evaluation of parathyroid adenomas, active BAT was detected in 6.3% of the scans (a prevalence similar to that obtained from retrospective reviews of 18 Drubach LA, Palmer EL, Connolly LP, Baker A, Zurakowski D, Cypess AM. Pediatric brown adipose tissue: detection, epidemiology, and differences from adults. J Pediatr 2011; 159: 939-44; PMID:21839465; http://dx.doi.org/10.1016/j.jpeds.2011.06.028 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] F-FDG PET-CT scans). 59 Goetze S, Lavely WC, Ziessman HA, Wahl RL. Visualization of brown adipose tissue with 99mTc-methoxyisobutylisonitrile on SPECT/CT. J Nucl Med 2008; 49: 752-6; PMID:18413387; http://dx.doi.org/10.2967/jnumed.107.048074 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] In another study, active BAT was detected in 5.4% of 74 99mTc-sestamibi SPECT-CT scans that had been performed for parathyroid imaging, and histological examination of biopsies taken from the cervical and supraclavicular regions of increased tracer uptake revealed adipocytes that possessed the morphological and genetic characteristics of BAT. 23 Cypess AM, Doyle AN, Sass CA, Huang TL, Mowschenson PM, Rosen HN, Tseng Y-H, Palmer EL, Kolodny GM. Quantification of human and rodent brown adipose tissue function using 99mTc-methoxyisobutylisonitrile SPECT/CT and 18F-FDG PET/CT. J Nucl Med 2013; 54: 1896-901; PMID:24071505; http://dx.doi.org/10.2967/jnumed.113.121012 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] In mice injected with a β3-adrenoreceptor agonist, perfusion of BAT (as revealed by 99mTc-sestamibi scanning) increased by 61%, while glucose uptake (as demonstrated by 18 Drubach LA, Palmer EL, Connolly LP, Baker A, Zurakowski D, Cypess AM. Pediatric brown adipose tissue: detection, epidemiology, and differences from adults. J Pediatr 2011; 159: 939-44; PMID:21839465; http://dx.doi.org/10.1016/j.jpeds.2011.06.028 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] F-FDG PET-CT scanning) increased by 440%. 23 Cypess AM, Doyle AN, Sass CA, Huang TL, Mowschenson PM, Rosen HN, Tseng Y-H, Palmer EL, Kolodny GM. Quantification of human and rodent brown adipose tissue function using 99mTc-methoxyisobutylisonitrile SPECT/CT and 18F-FDG PET/CT. J Nucl Med 2013; 54: 1896-901; PMID:24071505; http://dx.doi.org/10.2967/jnumed.113.121012 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] Therefore sympathetic activation of BAT results in both increased perfusion and glucose uptake. However the increased glucose uptake far exceeds the increased perfusion, which raises the possibility that glucose may be used for other non-thermogenic processes in active brown adipocytes.\nAnother tracer used in SPECT-CT is99mTc-tetrofosmin (technetium tetrofosmin), which is a tracer that is absorbed by functional mitochondria. In a retrospective study of 385 scans performed on 329 children (with cardiac conditions) with a mean age of 9.1 y (range 0–19), 99mTc-tetrofosmin uptake was increased in the neck and shoulder regions (i.e., areas known to contain deposits of BAT) in 17% (65/385) of the scans. 60 Fukuchi K, Ono Y, Nakahata Y, Okada Y, Hayashida K, Ishida Y. Visualization of interscapular brown adipose tissue using 99mTc-tetrofosmin in pediatric patients. J Nucl Med 2003; 44: 1582-5; PMID:14530470 [PubMed] , [Web of Science ®]   [Google Scholar] There was no relationship between the underlying cardiac disorder and increased tracer uptake. Similar to 18 Drubach LA, Palmer EL, Connolly LP, Baker A, Zurakowski D, Cypess AM. Pediatric brown adipose tissue: detection, epidemiology, and differences from adults. J Pediatr 2011; 159: 939-44; PMID:21839465; http://dx.doi.org/10.1016/j.jpeds.2011.06.028 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] F-FDG PET scans, the frequency of active BAT detection was significantly higher (P<0 .05) in winter (29%) than in spring (16%) or summer (9%). 60 Fukuchi K, Ono Y, Nakahata Y, Okada Y, Hayashida K, Ishida Y. Visualization of interscapular brown adipose tissue using 99mTc-tetrofosmin in pediatric patients. J Nucl Med 2003; 44: 1582-5; PMID:14530470 [PubMed] , [Web of Science ®]   [Google Scholar] However, the prevalence of active BAT as detected by this tracer (i.e. 17%) is much lower than that reported in children of similar ages using 18 Drubach LA, Palmer EL, Connolly LP, Baker A, Zurakowski D, Cypess AM. Pediatric brown adipose tissue: detection, epidemiology, and differences from adults. J Pediatr 2011; 159: 939-44; PMID:21839465; http://dx.doi.org/10.1016/j.jpeds.2011.06.028 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] F-FDG PET scans (43–45%). 18 Drubach LA, Palmer EL, Connolly LP, Baker A, Zurakowski D, Cypess AM. Pediatric brown adipose tissue: detection, epidemiology, and differences from adults. J Pediatr 2011; 159: 939-44; PMID:21839465; http://dx.doi.org/10.1016/j.jpeds.2011.06.028 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar]\n99mTc-sestamibi and 99mTc-tetrofosmin uptake are determined by the perfusion of a tissue (i.e., the higher the perfusion rate the greater the uptake of these tracers), and the accumulation of these tracers is proportional to the density and metabolic activity of the mitochondria within the tissues. Therefore SPECT-CT scans utilizing these tracers may offer more accurate information about the presence of activated BAT, since activated BAT requires increased perfusion as well as increased mitochondrial activity.\nMetaiodobenzylguanidine (MIBG) is derived from guanethidine and it acts like norepinephrine and accumulates in neuroendocrine tumors. In clinical practice, radiolabelled MIBG is used in SPECT scans for diagnosis and staging of these types of tumors. However, a rodent study (in which 123I-MIBG was administered to rats that were subsequently killed and their tissues examined) demonstrated that MIBG also accumulates in BAT (at concentrations 20–30 times that of WAT) and this accumulation increases after stimulation with a β3-receptor agonist. 61 Okuyama C, Sakane N, Yoshida T, Shima K, Kurosawa H, Kumamoto K, Ushijima Y, Nishimura T. 123I- or 125I-metaiodobenzylguanidine visualization of brown adipose tissue. J Nucl Med 2002; 43: 1234-40; PMID:12215564 [PubMed] , [Web of Science ®]   [Google Scholar] Similarly, 123I-MIBG uptake was noted on the left neck and shoulder region of a child with a neuroblastoma but no uptake was seen on the right where there had been surgical disruption of the sympathetic nerves in the neck and upper thorax (as evidenced by right sided Horner's syndrome). 62 Gelfand MJ. 123I-MIBG uptake in the neck and shoulders of a neuroblastoma patient: damage to sympathetic innervation blocks uptake in brown adipose tissue. Pediatr Radiol 2004; 34: 577-9; PMID:15205842; http://dx.doi.org/10.1007/s00247-003-1136-x [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] Furthermore, in a study of 10 lean young men (BMI 19–25 aged 18–32 years) who were exposed to cold (17°C) for 2 hours prior to 123I-MIBG SPECT-CT and 18 Drubach LA, Palmer EL, Connolly LP, Baker A, Zurakowski D, Cypess AM. Pediatric brown adipose tissue: detection, epidemiology, and differences from adults. J Pediatr 2011; 159: 939-44; PMID:21839465; http://dx.doi.org/10.1016/j.jpeds.2011.06.028 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] F-FDG PET-CT scanning, 123I-MIBG uptake occurred in the same anatomic areas (i.e. cervical, supraclavicular and superior mediastinal regions) as 18 Drubach LA, Palmer EL, Connolly LP, Baker A, Zurakowski D, Cypess AM. Pediatric brown adipose tissue: detection, epidemiology, and differences from adults. J Pediatr 2011; 159: 939-44; PMID:21839465; http://dx.doi.org/10.1016/j.jpeds.2011.06.028 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] F-FDG uptake. 63 Admiraal WM, Holleman F, Bahler L, Soeters MR, Hoekstra JB, Verberne HJ. Combining 123I-metaiodobenzylguanidine SPECT/CT and 18F-FDG PET/CT for the assessment of brown adipose tissue activity in humans during cold exposure. J Nucl Med 2013; 54: 208-12; PMID:23318291; http://dx.doi.org/10.2967/jnumed.112.111849 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] This is consistent with evidence from other studies that BAT activation due to cold exposure is mediated by the sympathetic nervous system.\nMagnetic resonance imaging (MRI)\nMRI scanners are used to create a strong magnetic field around an area to be imaged. Oscillation of this magnetic field provides energy to hydrogen atoms. This results in the excitation of the hydrogen atoms, which emit a radiofrequency signal. This signal is detected by the MRI scanner and is processed to produce an image. The differing rate at which excited hydrogen atoms (protons) return to equilibrium, enables different body tissues to be distinguished from each other. Furthermore, fat protons resonate at a frequency that is 3.5 ppm higher than water protons. 64 Hamilton G, Smith DL, Bydder M, Nayak KS, Hu HH.MR properties of brown and white adipose tissue. J Magn Reson Imaging 2011; 34: 468-73; PMID:21780237; http://dx.doi.org/10.1002/jmri.22623 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] The MRI signals of BAT are produced by both water protons and fat protons. In contrast, the MR signals from WAT are produced predominantly by fat protons, while that from muscle is produced almost entirely by water protons. 65 Sbarbarti A, Guerrni U, Marzola P, Asperio R, Osculati F. Chemical shift imaging at 4.7 tesla of brown adipose tissue. J Lipid Res 1997; 38: 343-7; PMID:9162753 [PubMed] , [Web of Science ®]   [Google Scholar] Furthermore, in rats BAT is composed of 20–50% fat, while WAT is made up of 70–90% fat, and the MRI estimate of the fat fraction of BAT post-mortem was 10% higher than in live rats. 66 Lunati E, Marzola P, Nicolato E, Fedrigo M, Sharbarti A. In vivo quantitative lipidic map of brown adipose tissue by chemical shift imaging at 4.7 tesla. J Lipid res 1999; 40: 1395-400; PMID:10428975 [PubMed] , [Web of Science ®]   [Google Scholar] In mice similar results have been obtained. In one mouse study the fat fraction of BAT was reported to be 40–80% and that of WAT was 90–93%, 67 Hu H, Smith DL, nayak KS, Goran MI, Nagy TR. Identification of brown adipose tissue in mice with fat-water IDEAL-MRI. J Magn Reson Imaging 2010; 31: 1195-202; PMID:20432356; http://dx.doi.org/10.1002/jmri.22162 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] while in another study (which used different MRI protocols) the mean fat fraction of BAT was 51.5% and the mean fat fraction of WAT was 92.9%. 64 Hamilton G, Smith DL, Bydder M, Nayak KS, Hu HH.MR properties of brown and white adipose tissue. J Magn Reson Imaging 2011; 34: 468-73; PMID:21780237; http://dx.doi.org/10.1002/jmri.22623 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] In mice housed at different room temperatures, the mean fat fraction of BAT decreased with decreasing room temperature (79.4% at 30°C, 61.8% at 23°C and 50.9% at 16°C). 68 Smith DL, Yang Y, Hu HH, Zhai G, Nagy TR. Measurement of interscapular brown adipose tissue of mice in differentally housed temperatures by chemical-shift-encoded water-fat MRI. J Magn Reson Imaging 2013; 38: 1425-33; PMID:23580443; http://dx.doi.org/10.1002/jmri.24138 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] This is in keeping with the fact that cold exposure activates BAT, leading to increased lipolysis in brown adipocytes.\nIn humans, the water-to-fat ratios of BAT and WAT have also been found to be significantly different. In human neonates, the mean fat fraction of BAT was 30.2%, while that of WAT was 67.7% (n = 22). 69 Rasmussen JM, Entringer S, Nguyen A, van Erp TGM, Guijarro A, Oveisi F, Swanson JM, Piomelli D, Wadhwa PD, Buss C, et al. Brown adipose tissue quantification in human neonates using water-fat separated MRI. PLOS One 2013; 8: e77907; PMID:24205024; http://dx.doi.org/10.1371/journal.pone.0077907 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] Furthermore, in children, in MRIs performed at a room temperature of 25°C, the fat fractions of both supraclavicular BAT and subcutaneous WAT increase with increasing BMI, and the fat fraction of supraclavicular BAT increases with increasing age. 70 Hu HH, Yin L, Aggabao PC, Perkins TG, Chia JM, Gilsanz V. Comparison of brown and white adipose tissues in infants and children with chemical-shift-encoded water-fat MRI. J Magn Reson Imaging 2013; 38: 885-96; PMID:23440739; http://dx.doi.org/10.1002/jmri.24053 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] In a study of 11 healthy volunteers aged 18–30 years, in response to cold stimulation 8/11 subjects had active BAT on 18 Drubach LA, Palmer EL, Connolly LP, Baker A, Zurakowski D, Cypess AM. Pediatric brown adipose tissue: detection, epidemiology, and differences from adults. J Pediatr 2011; 159: 939-44; PMID:21839465; http://dx.doi.org/10.1016/j.jpeds.2011.06.028 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] F-FDG scans, and in these subjects water-fat MRI showed that the mean fat fraction of BAT was 65.2% while the mean fat fraction of WAT was 81.5%. 28 van Rooijen BD, van der Lans AAJJ, Brans B, Wildberger JE, Mottaghy FM, Schrauwen P, Backes WH, van Marken Lichtenbelt WD. Imaging cold-activated brown adipose tissue using dynamic T2*-weighted magnetic resonance imaging and 2-deoxy-2-[18F]fluoro-D-glucose positron emission tomography. Invest Radiol 2013; 48: 708-14; PMID:23695084; http://dx.doi.org/10.1097/RLI.0b013e31829363b8 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar]\nFat-fraction MRI (performed at a room temperature of 22°C) has been used to identify BAT in a person in whom no BAT activity was detected on an 18 Drubach LA, Palmer EL, Connolly LP, Baker A, Zurakowski D, Cypess AM. Pediatric brown adipose tissue: detection, epidemiology, and differences from adults. J Pediatr 2011; 159: 939-44; PMID:21839465; http://dx.doi.org/10.1016/j.jpeds.2011.06.028 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] F-FDG PET-CT scan performed at 22°C. 71 Hu HH, Perkins TG, Chia JM, Gilsanz V. Characterization of human brown adipose tissue by chemical-shift water-fat MRI. 2013; 200: 177-83; PMID:23255760  [Google Scholar] In another study carried out in a patient with a parathyroid tumor, 83% of retrospectively identified regions of activated BAT from an 18 Drubach LA, Palmer EL, Connolly LP, Baker A, Zurakowski D, Cypess AM. Pediatric brown adipose tissue: detection, epidemiology, and differences from adults. J Pediatr 2011; 159: 939-44; PMID:21839465; http://dx.doi.org/10.1016/j.jpeds.2011.06.028 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] F-FDG PET-CT scan showed corresponding low signal (i.e., adipose tissue with a low fat fraction) on MRI, while prospectively 87% of low fat-fraction adipose tissue depots on a subsequent MRI scan demonstrated increased uptake on the second 18 Drubach LA, Palmer EL, Connolly LP, Baker A, Zurakowski D, Cypess AM. Pediatric brown adipose tissue: detection, epidemiology, and differences from adults. J Pediatr 2011; 159: 939-44; PMID:21839465; http://dx.doi.org/10.1016/j.jpeds.2011.06.028 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] F-FDG PET-CT scan. 72 Reddy NL, Jones TA, Wayte SC, Adesanya O, Sankar S, Yeo YC, Tripathi G, McTernan PG, Randeva HS, Kumar S, et al. Identification of brown adipsoe tissue using MR imaging in a human adult with histological and immunohistochemical confirmation. J Clin Endocrinol Metab 2014; 99: E117-21; PMID:24384025; http://dx.doi.org/10.1210/jc.2013-2036 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] Therefore these 2 imaging modalities appear to identify most, but not all of the BAT depots that are present in an adult human.\nMRI has also been used to study the perfusion of BAT before and after stimulation. Following an injection of 5mcg/kg of adrenaline (and a gadolinium-based contrast agent) to anaesthetized male rats, the signal intensity of interscapular BAT was found to be significantly higher than in rats that had not received adrenaline, indicating that adrenaline increases BAT perfusion. 73 Sbarbati A, Cavallini I, Marzola P, Nicolato E, Osculati F. Contrast-enhanced MRI of brown adipose tissue after pharmacological stimulation. Magn Reson Med 2006; 55: 715-8; PMID:16506160; http://dx.doi.org/10.1002/mrm.20851 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] Furthermore, in this study, following adrenaline administration, the perfusion of dorsal muscles (i.e. muscles adjacent to BAT) was also increased in comparison to limb muscles. 73 Sbarbati A, Cavallini I, Marzola P, Nicolato E, Osculati F. Contrast-enhanced MRI of brown adipose tissue after pharmacological stimulation. Magn Reson Med 2006; 55: 715-8; PMID:16506160; http://dx.doi.org/10.1002/mrm.20851 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar]\nFrom a functional point of view, blood oxygen level dependent (BOLD) contrast has been used in MRI for studying BAT. BOLD is based on the principle that activation of a highly vascularised specific tissue or organ results in increased blood flow to and oxygen consumption within that region with a corresponding change in the relative levels of oxy- and deoxyhaemoglobin and MRI signal intensity. BOLD has been proposed as a means of functionally assessing BAT because when BAT is activated, its oxygen consumption increases to a much greater extent than the increase in its perfusion, 21,23,74 Orava J, Nuutila P, Lidell ME, Oikonen V, Noponen T, Viljanen T, Scheinin M, Taittonen M, Niemi T, Enerback S, et al. Cell Metab 2011; 14: 272-9; PMID:21803297; http://dx.doi.org/10.1016/j.cmet.2011.06.012\nCypess AM, Doyle AN, Sass CA, Huang TL, Mowschenson PM, Rosen HN, Tseng Y-H, Palmer EL, Kolodny GM. Quantification of human and rodent brown adipose tissue function using 99mTc-methoxyisobutylisonitrile SPECT/CT and 18F-FDG PET/CT. J Nucl Med 2013; 54: 1896-901; PMID:24071505; http://dx.doi.org/10.2967/jnumed.113.121012\nMatthias A, Ohlson KB, Fredriksson JM, Jacobsson A, Nedegaard J, Cannon B. Thermogenic responses in brown fat cells are fully UCP-1dependent. UCP2 or UCP3 do not substitute for UCP1 adrenergically or fatty acid-induced thermogenesis. J Biol Chem 2000; 275: 25073-81; PMID:10825155; http://dx.doi.org/10.1074/jbc.M000547200  resulting in higher levels of deoxyhaemoglobin. In anesthetized female mice injected with an intraperitoneal bolus of 2.5mg/kg of norepinephrine, the signal intensity in BAT changed significantly (by ∼20%) and this was accompanied by a 5.5°C increase in BAT temperature (measured directly with a probe), which occurred within 40–50 minutes post-injection and declined to pre-injection levels after 140 minutes. 75 Khanna A, Branca RT. Detecting brown adipose tissue activity with BOLD MRI in mice. Magn Reson Med 2012; 68: 1285-90; PMID:22231619; http://dx.doi.org/10.1002/mrm.24118 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] The signal intensities of WAT and skeletal muscle did not change significantly following the norepinephrine injection. 75 Khanna A, Branca RT. Detecting brown adipose tissue activity with BOLD MRI in mice. Magn Reson Med 2012; 68: 1285-90; PMID:22231619; http://dx.doi.org/10.1002/mrm.24118 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] In a study in humans, water-fat MRI identified non-stimulated BAT in 5 adults in the same supraclavicular areas as cold-activated BAT was detected by previous 18 Drubach LA, Palmer EL, Connolly LP, Baker A, Zurakowski D, Cypess AM. Pediatric brown adipose tissue: detection, epidemiology, and differences from adults. J Pediatr 2011; 159: 939-44; PMID:21839465; http://dx.doi.org/10.1016/j.jpeds.2011.06.028 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] F-FDG PET-CT scans, and both types of scans yielded similar BAT volumes. 76 Chen Y-C I, Cypess AM, Chen Y-C, Palmer M, Kolodny G, Kahn CR, Kwong KK. Measurement of human brown adipose tissue volume and activity using anatomic MR imaging and functional MR imaging. J Nucl Med 2013; 54: 1584-7; PMID:23868958; http://dx.doi.org/10.2967/jnumed.112.117275 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] In this same study BOLD MRI detected a 10% change in signal intensity in BAT after it had been activated by cold. 76 Chen Y-C I, Cypess AM, Chen Y-C, Palmer M, Kolodny G, Kahn CR, Kwong KK. Measurement of human brown adipose tissue volume and activity using anatomic MR imaging and functional MR imaging. J Nucl Med 2013; 54: 1584-7; PMID:23868958; http://dx.doi.org/10.2967/jnumed.112.117275 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar]\nAn alternative method of functionally imaging BAT uses MRI with hyperpolarized [1–13C]-pyruvate as a contrast agent. 13C is a non-radioactive isotope of 12C and it produces a different signal from 12C on MRI scans. Oxidative phosphorylation increases in activated BAT, therefore within activated BAT there will be increased conversion of [1–13C]-pyruvate to 13C-bicarbonate and [1–13C]-lactate. A study using this technique demonstrated that following intravenous administration of [1–13C]-pyruvate and subsequent intraperitoneal injection of 2.5mg/kg of norepinephrine to anesthetized rats, compared to baseline, there was a 6.3-fold increase in BAT hyperpolarized bicarbonate signal and a 3.9-fold increase in hyperpolarized lactate signal. 77 Lau AZ, Chen AP, Ladouceur-Wodzak M, Nayak KS, Cunningham CH. Noninvasive identification and assessment of functional brown adipose tissue in rodents using hyperpolarized 13C imaging. Int J Obes 2013; 1-6; http://dx.doi.org/10.1155/2013/359763 [Crossref]   [Google Scholar] Significant increases in hyperpolarised lactate signals in the heart (3.4-fold) and kidneys (2.0-fold) were also reported. 77 Lau AZ, Chen AP, Ladouceur-Wodzak M, Nayak KS, Cunningham CH. Noninvasive identification and assessment of functional brown adipose tissue in rodents using hyperpolarized 13C imaging. Int J Obes 2013; 1-6; http://dx.doi.org/10.1155/2013/359763 [Crossref]   [Google Scholar] Since oxidative metabolism in BAT accounts for about 88% of its total oxygen consumption, 78 Ma SWY, Foster DO. Uptake of glucose and release of fatty acids and glycerol by rat brown adipose tissue in vivo. Can J Physiol Pharmacol 1986; 64: 609-14; PMID:3730946; http://dx.doi.org/10.1139/y86-101 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] this technique could also be used to investigate fatty acid metabolism in activated BAT.\nMRI may prove to be invaluable in the study of BAT because it has the potential to differentiate BAT from WAT, to identify non-activated BAT and activated BAT, as well as allow functional studies to be performed on BAT. Furthermore, since it is not dependent on the use of ionizing radiation it may be used for repeated imaging of the same subjects as well as imaging of groups of people who are often excluded (e.g. children, women of childbearing age) from studies involving imaging techniques utilizing ionizing radiation.\nInfrared thermography/thermal imaging\nInfrared radiation is emitted by objects at temperatures above absolute zero, and the amount of radiation an object emits increases as the temperature of that object rises. Thermal imaging cameras detect radiation in the infrared range of the electromagnetic spectrum and produce thermograms (i.e., images of variations in temperature). Since the temperature of BAT increases when it is activated, 75 Khanna A, Branca RT. Detecting brown adipose tissue activity with BOLD MRI in mice. Magn Reson Med 2012; 68: 1285-90; PMID:22231619; http://dx.doi.org/10.1002/mrm.24118 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] and some of this heat will be transferred to surrounding tissues including overlying skin, thermal imaging has been proposed as means of studying BAT activation in vivo in response to different stimuli, especially as it does not require the use of ionizing radiation.\nThis non-invasive technique has been used to demonstrate BAT activation in rodent studies. Mice with an R384C mutation in the central thyroid hormone receptor (TRα1) are hypermetabolic due to central overactivation of BAT. 79 Sjogren M, Alkemade A, Mittag J, Nordstrom K, Katz A, Rozell B, Westerblad H, Arner A, Vennstrom B. Hypermetabolism in mice caused by the central action of an unliganded thyroid hormone receptor alpha1. EMBO J 2007; 26: 4535-45; PMID:17932484; http://dx.doi.org/10.1038/sj.emboj.7601882 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] These mice had a significantly higher maximum interscapular skin temperature at thermoneutral room temperature (with increased whole body weight-adjusted oxygen consumption) when compared to wild type mice. 80 Warner A, Rahman A, Solsjo P, Gottschling K, Davis B, Vennstrom B, Arner A, Mittag J. Inappropriate heat dissipation ignites brown fat thermogenesis in mice with a mutant thyroid hormone receptor α1. Proc Natl Acad Sci USA 2013; 110: 16241-6; PMID:24046370; http://dx.doi.org/10.1073/pnas.1310300110 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] The body temperature of p62 knockout mice (as measured with a thermal camera), as well as energy expenditure, following cold exposure was lower than that of wild type mice. 81 Lee SJ, Pfluger PT, Kim JY, Nogueiras R, Duran A, Pages G, Pouyssegur J, Tschop MH, Diaz-Meco MT, Moscat J. A functional role for the p62-ERK1 axis in the control of energy homeostasis and adipogenesis. EMBO Rep 2010; 11: 226-32; PMID:20154642; http://dx.doi.org/10.1038/embor.2010.7 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] In this same study, p62 knockout mice gained more weight than wild type mice when both groups were fed normal chow diet and high fat diet. 81 Lee SJ, Pfluger PT, Kim JY, Nogueiras R, Duran A, Pages G, Pouyssegur J, Tschop MH, Diaz-Meco MT, Moscat J. A functional role for the p62-ERK1 axis in the control of energy homeostasis and adipogenesis. EMBO Rep 2010; 11: 226-32; PMID:20154642; http://dx.doi.org/10.1038/embor.2010.7 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] This provides further support for the theory that BAT activity plays a significant role in energy homeostasis.\nIn a study in which shaved mice where either kept in a room at 4°C for 24hours, stressed by causing full-thickness non-lethal burn injuries to 30% of their total body surface area or removal of a 1cm2 section of skin to cause a full thickness wound, accumulation of 18F-FDG in BAT increased by 15-fold in the cold and cutaneous wound animals and by 5-fold in the cold stress animals (in comparison to control mice). 82 Carter EA, Bonab AA, Paul K, Yerxa J, Tompkins RG, Fischman AJ. Association of heat production with 18F-FDG accumulation in murine brown adipose tissue after stress. J Nucl Med 2011; 52: 1616-20; PMID:21914754; http://dx.doi.org/10.2967/jnumed.111.090175 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] The temperature of skin overlying interscapular BAT (in comparison to adjacent non-BAT tissue), measured with a thermal imaging camera, was on average 1.7°C higher in the cold stress group, 1.5°C higher in the skin wound group, and 1.5°C higher in the skin burn group. This was significantly different from the 0.9°C difference between skin temperature overlying BAT and adjacent skin temperature that was not overlying BAT seen in the control group. 82 Carter EA, Bonab AA, Paul K, Yerxa J, Tompkins RG, Fischman AJ. Association of heat production with 18F-FDG accumulation in murine brown adipose tissue after stress. J Nucl Med 2011; 52: 1616-20; PMID:21914754; http://dx.doi.org/10.2967/jnumed.111.090175 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] Also, there was a strong linear correlation between 18 Drubach LA, Palmer EL, Connolly LP, Baker A, Zurakowski D, Cypess AM. Pediatric brown adipose tissue: detection, epidemiology, and differences from adults. J Pediatr 2011; 159: 939-44; PMID:21839465; http://dx.doi.org/10.1016/j.jpeds.2011.06.028 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] F-FDG accumulation in BAT and the increase in skin temperature detected by the thermal imaging camera (r2 = 0.835, P<0 .0001). 82 Carter EA, Bonab AA, Paul K, Yerxa J, Tompkins RG, Fischman AJ. Association of heat production with 18F-FDG accumulation in murine brown adipose tissue after stress. J Nucl Med 2011; 52: 1616-20; PMID:21914754; http://dx.doi.org/10.2967/jnumed.111.090175 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar]\nSeveral human studies using thermal imaging have been reported. In one study, volunteers sat in a room (with the temperature maintained at 19–21°C) and were asked to place one hand in water (maintained at a temperature of 19–20°C) for 5 minutes and thermal images were recorded during the 5 minutes immediately preceding the cold stimulus as well as throughout cold stimulation. The change (from baseline) in the mean of the upper 10th percentile of readings in the supraclavicular area was reported as +0.62±0.14°C in 3–8 y olds (n = 7), +0.25±0.08°C in 13–18 y olds (n = 12), and +0.20±0.08°C in 35–58 y olds (n = 7) (P<0 .05). 83 Symonds ME, Henderson K, Elvidge L, Bosman C, Sharkey D, Perkins AC, Budge H. Thermal imaging to assess age-related changes of skin temperature within the supraclavicular region co-locating with brown adipose tissue in healthy children. J Pediatr 2012; 161: 892-8; PMID:22677567; http://dx.doi.org/10.1016/j.jpeds.2012.04.056 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] These areas of increased temperature in response to cold stimulation corresponded with areas of increased 18 Drubach LA, Palmer EL, Connolly LP, Baker A, Zurakowski D, Cypess AM. Pediatric brown adipose tissue: detection, epidemiology, and differences from adults. J Pediatr 2011; 159: 939-44; PMID:21839465; http://dx.doi.org/10.1016/j.jpeds.2011.06.028 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] F-FDG uptake on PET-CT scans. 83 Symonds ME, Henderson K, Elvidge L, Bosman C, Sharkey D, Perkins AC, Budge H. Thermal imaging to assess age-related changes of skin temperature within the supraclavicular region co-locating with brown adipose tissue in healthy children. J Pediatr 2012; 161: 892-8; PMID:22677567; http://dx.doi.org/10.1016/j.jpeds.2012.04.056 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] In a second study performed by the same group during winter months, the median value of the hottest 25% of pixels in the thermal image of the skin in the supraclavicular area was measured. An inverse relationship was found between the baseline value and BMI percentile in 55 healthy children aged 6–11 y In 24 of these 55 children, the median temperature of the hottest 25% of the region of interest increased by 0.28±0.06°C within 5 minutes of immersing one hand in water maintained at a temperature of 20.1°C. 84 Robinson L, Ojha S, Symonds ME, Budge H. Body mass index as a determinant of brown adipose tissue in healthy children. J Pediatr 2014; 164: 318-22; PMID:24238856; http://dx.doi.org/10.1016/j.jpeds.2013.10.005 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] There was no significant change in the temperature of the sternum, which served as a control area. 84 Robinson L, Ojha S, Symonds ME, Budge H. Body mass index as a determinant of brown adipose tissue in healthy children. J Pediatr 2014; 164: 318-22; PMID:24238856; http://dx.doi.org/10.1016/j.jpeds.2013.10.005 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar]\nA case report of an 11 y old girl with untreated acquired primary hypothyroidism demonstrated a 1.7°C temperature difference (using infrared thermography) between the skin overlying the supraclavicular fat depot (36.0°C±0.16) and the skin overlying the sternum (34.3°C±0.19) at a room temperature of 22°C. 85 Kim MS, Hu HH, Aggabao PC, Geffner ME, Gilsanz V. Presence of brown adipose tissue in an adolescent with severe primary hypothyroidism. J Clin Endocrinol Metab 2014; http://dx.doi.org/10.1210/jc.2014-1343 [Crossref] , [Web of Science ®]   [Google Scholar] Interestingly, after 2 months of treatment with thyroid hormone replacement, which resultant clinical and biochemical euthyroidism, the skin temperature difference (at the same room temperature) fell to 0.7°C (supraclavicular skin temperature 37.1°C±0.13 vs. sternal skin temperature 36.4°C±0.13). 85 Kim MS, Hu HH, Aggabao PC, Geffner ME, Gilsanz V. Presence of brown adipose tissue in an adolescent with severe primary hypothyroidism. J Clin Endocrinol Metab 2014; http://dx.doi.org/10.1210/jc.2014-1343 [Crossref] , [Web of Science ®]   [Google Scholar] This raises the possibility that TSH (which was markedly elevated when her hypothyroidism was untreated with a subsequent reduction to normal levels post-treatment) may stimulate BAT thermogenesis, especially since brown adipocytes are known to have TSH receptors and TSH increases UCP1 mRNA in brown adipocytes. 86 Murakami M, Kamiya Y, Morimura T, Araki O, Imamura M, Ogiwara T, Mizuma H, Mori M. Thyrotropin receptors in brown adipose tissue: thyrotropin stimulates type II iodothyronine deiodinase and uncoupling protein-1 in brown adipocytes. Endocrinology 2001; 142: 1195-201; PMID:11181535 [PubMed] , [Web of Science ®]   [Google Scholar]\nUltrasound\nContrast ultrasound is used to estimate blood flow noninvasively by visualizing and quantifying intravenous echogenic microbubbles. These microbubbles are destroyed by a high-energy ultrasound pulse and the rate at which they are replenished can be used to estimate the blood flow to a tissue. Following the intravenous administration of 1mcg/kg/min of norepinephrine to anesthetized mice (kept at a room temperature of 37°C), blood flow to BAT as measured with contrast ultrasound was found to increase 15 to 20-fold compared to baseline in wild-type mice, and this effect of norepinephrine was present but diminished in UCP-1 deficient mice. 87 Baron DM, Clerte M, Brouckaert P, Raher MJ, Flynn AW, Zhang H, Carter EA, Picard MH, Block KD, buys ES, et al. in vivo characterization of brown adipose tissue blood flow by contrast ultrasound in mice. Circ Cardiovasc Imaging 2012; 5: 652-9; PMID:22776888; http://dx.doi.org/10.1161/CIRCIMAGING.112.975607 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] In a different study, infusion of the same dose of norepinephrine resulted in a similar increase in BAT blood flow (15–fold20- increase) in wild type mice fed a low fat diet or high fat diet for 2 months, with a higher increase in blood flow in the low fat diet mice. 88 Clerte M, Baron DM, Brouckaert P, Ernande L, Raher MJ, Flynn AW, Picard MH, Bloch KD, Buys ES, Scherrer-Crosbie M. Brown adipose tissue blood flow and mass in obesity: a contrast ultrasound study in mice. J Am Soc Echocardiogr 2013; 26: 1465-73; PMID:23993691; http://dx.doi.org/10.1016/j.echo.2013.07.015 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] In db/db (obese diabetic leptin receptor-deficient) mice, baseline blood flow to BAT was significantly lower than wild type and norepinephrine increased BAT blood flow to a lesser extent (about fold10- increase). 88 Clerte M, Baron DM, Brouckaert P, Ernande L, Raher MJ, Flynn AW, Picard MH, Bloch KD, Buys ES, Scherrer-Crosbie M. Brown adipose tissue blood flow and mass in obesity: a contrast ultrasound study in mice. J Am Soc Echocardiogr 2013; 26: 1465-73; PMID:23993691; http://dx.doi.org/10.1016/j.echo.2013.07.015 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] Additionally, these authors were able to estimate BAT mass using contrast ultrasound in the wild type mice, and the estimates correlated well with BAT mass measured at necropsy (r2 = 0.83, P<0 .001). 88 Clerte M, Baron DM, Brouckaert P, Ernande L, Raher MJ, Flynn AW, Picard MH, Bloch KD, Buys ES, Scherrer-Crosbie M. Brown adipose tissue blood flow and mass in obesity: a contrast ultrasound study in mice. J Am Soc Echocardiogr 2013; 26: 1465-73; PMID:23993691; http://dx.doi.org/10.1016/j.echo.2013.07.015 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar]\nContrast ultrasound is an established technique used in cardiology and its advantages include no use of ionizing radiation and its ability to quantify BAT blood flow and mass. However, one limitation is its inability to estimate BAT mass in poorly vascularised BAT (for instance in severely obese and diabetic db/db mice), 88 Clerte M, Baron DM, Brouckaert P, Ernande L, Raher MJ, Flynn AW, Picard MH, Bloch KD, Buys ES, Scherrer-Crosbie M. Brown adipose tissue blood flow and mass in obesity: a contrast ultrasound study in mice. J Am Soc Echocardiogr 2013; 26: 1465-73; PMID:23993691; http://dx.doi.org/10.1016/j.echo.2013.07.015 [Crossref] , [PubMed] , [Web of Science ®]   [Google Scholar] which may limit its utility in obese and/or diabetic humans.\nConclusions\nPET-CT is currently the most widely used imaging modality employed in studies of BAT prevalence and activity. It has provided important information about the prevalence and regulation of BAT in humans and with the use of different tracers it has facilitated the investigation of differential effects of stimuli such as cold, insulin and thyroid hormone have on BAT perfusion and glucose uptake. However, its main limitations are: it is expensive, it involves the use of ionizing radiation, it can only be used to detect BAT that is metabolically active and it may not be able to detect small depots of BAT that are below the spatial resolution threshold of the scanner. SPECT-CT utilizing technetium-based tracers may provide more accurate estimates of active BAT since the uptake of these tracers is proportional to the perfusion of a tissue as well as the density and metabolic activity of the intra-tissue mitochondria, and active BAT requires both increased perfusion and increased mitochondrial activity. The use of 123I-MIBG with SPECT-CT has provided further evidence that cold-induced BAT activation is mediated by the sympathetic nervous system. Its applications may be limited by the expense of this type of scan and the use of ionizing radiation.\nMRI has been used in the anatomical and functional imaging of BAT. Using a variety of tracers it is possible to study the changes in blood flow to and oxygen consumption by BAT in response to different stimuli, and has the potential to be used to study fatty acid metabolism in activated BAT. Additionally, it has the potential to be used to detect non-activated BAT (since WAT and BAT have distinct fat fractions), and MRI has the added advantage of not requiring the use of ionizing radiation.\nInfrared thermography and contrast ultrasound are other imaging modalities that do not require the use of ionizing radiation. There are much fewer published studies utilizing these techniques compared with other imaging modalities. Although its use in the study of BAT is in its infancy, thermal imaging has been used to successfully detect activated BAT (using the increase in the skin temperature overlying BAT as a marker of BAT activation) in rodents, children and adults in distributions similar to that seen in PET-CT studies. The use of contrast ultrasound is well established in several medical specialties, and it has been used to quantify BAT mass and BAT blood flow in response to sympathetic nervous system activation. However, its use might be limited by its inability to quantify BAT mass in poorly vascularised BAT such as in severely obese and diabetic rodents.\nImaging studies have made significant contributions to our understanding of BAT function. Although each imaging modality has its limitations, refinements of existing imaging techniques and the development of new techniques are likely to improve the non-invasive investigation of BAT. This is important because in vivo studies will be required if modulation of BAT activity is to be employed in the treatment of obesity.\nDisclosure of Potential Conflicts of Interest\nAll authors have completed the Unified Competing Interest form at www.icmje.org/coi_disclosure.pdf (available on request from the corresponding author) and declare that (1) none of the authors have any relationships with companies that might have an interest in the submitted work in the previous 3 years; (2) none of the authors’ spouses, partners, or children have a financial relationship that may be relevant to the submitted work; and (3) none of the authors have a non-financial interest that may be relevant to the submitted work.\nFunding\nThe Section of Investigative Medicine is funded by grants from the MRC, BBSRC, NIHR, an Integrative Mammalian Biology (IMB) Capacity Building Award, an FP7- HEALTH- 2009–241592 EuroCHIP grant and is supported by the NIHR Imperial Biomedical Research Centre Funding Scheme. CI is supported by an Imperial College Healthcare NHS Trust Charity Research Fellowship, VS is supported by an NIHR Clinical Lectureship, WSD is supported by an NIHR Career Development Fellowship.\nTable 1. 18F-FDG PET-CT Studies in Humans using Cold Stimulation of Brown Adipose Tissue\nStudy\n""","0.08514395","""http://www.tandfonline.com/doi/full/10.4161/21623945.2014.965609""","[-0.178219,51.500505]"
